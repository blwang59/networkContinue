Measuring and moderating opinion polarization in social networks,Antonis Matakos (University of Ioannina);Evimaria Terzi (Boston University);Panayiotis Tsaparas (University of Ioannina);,"2567106504,2110675235,2234654910",-,2017,Data Mining and Knowledge Discovery pp 1-26,-
Selective harvesting over networks,Fabricio Murai (University of Massachusetts Amherst);Diogo Rennó (Universidade Federal de Minas Gerais);Bruno Ribeiro (Purdue University);Gisele L. Pappa (Universidade Federal de Minas Gerais);Don Towsley (University of Massachusetts Amherst);Krista Gile (University of Massachusetts Amherst);,"1987779243,2511537095,2249226172,2089254527,2177075905,342346400","Active search on graphs focuses on collecting certain labeled nodes (targets) given global knowledge of the network topology and its edge weights (encoding pairwise similarities) under a query budget constraint. However, in most current networks, nodes, network topology, network size, and edge weights are all initially unknown. In this work we introduce selective harvesting, a variant of active search where the next node to be queried must be chosen among the neighbors of the current queried node set; the available training data for deciding which node to query is restricted to the subgraph induced by the queried set (and their node attributes) and their neighbors (without any node or edge attributes). Therefore, selective harvesting is a sequential decision problem, where we must decide which node to query at each step. A classifier trained in this scenario can suffer from what we call a tunnel vision effect: without any recourse to independent sampling, the urge to only query promising nodes forces classifiers to gather increasingly biased training data, which we show significantly hurts the performance of active search methods and standard classifiers. We demonstrate that it is possible to collect a much larger set of targets by using multiple classifiers, not by combining their predictions as a weighted ensemble, but switching between classifiers used at each step, as a way to ease the tunnel vision effect. We discover that switching classifiers collects more targets by (a) diversifying the training data and (b) broadening the choices of nodes that can be queried in the future. This highlights an exploration, exploitation, and diversification trade-off in our problem that goes beyond the exploration and exploitation duality found in classic sequential decision problems. Based on these observations we propose D\(^3\)TS, a method based on multi-armed bandits for non-stationary stochastic processes that enforces classifier diversity, which outperforms all competing methods on five real network datasets in our evaluation and exhibits comparable performance on the other two.",2017,Data Mining and Knowledge Discovery pp 1-31,model selection;data mining;artificial intelligence;machine learning;statistics;computer science;
MixedTrails: Bayesian hypothesis comparison on heterogeneous sequential data,Martin Becker (University of Würzburg);Florian Lemmerich (Leibniz Association);Philipp Singer (Leibniz Association);Markus Strohmaier (Leibniz Association);Andreas Hotho (University of Würzburg);,"2343475332,156522191,2167599249,142799918,20543882","Sequential traces of user data are frequently observed online and offline, e.g., as sequences of visited websites or as sequences of locations captured by GPS. However, understanding factors explaining the production of sequence data is a challenging task, especially since the data generation is often not homogeneous. For example, navigation behavior might change in different phases of browsing a website or movement behavior may vary between groups of users. In this work, we tackle this task and propose MixedTrails , a Bayesian approach for comparing the plausibility of hypotheses regarding the generative processes of heterogeneous sequence data. Each hypothesis is derived from existing literature, theory, or intuition and represents a belief about transition probabilities between a set of states that can vary between groups of observed transitions. For example, when trying to understand human movement in a city and given some data, a hypothesis assuming tourists to be more likely to move towards points of interests than locals can be shown to be more plausible than a hypothesis assuming the opposite. Our approach incorporates such hypotheses as Bayesian priors in a generative mixed transition Markov chain model, and compares their plausibility utilizing Bayes factors. We discuss analytical and approximate inference methods for calculating the marginal likelihoods for Bayes factors, give guidance on interpreting the results, and illustrate our approach with several experiments on synthetic and empirical data from Wikipedia and Flickr. Thus, this work enables a novel kind of analysis for studying sequential data in many application areas.",2017,Data Mining and Knowledge Discovery pp 1-32,bayes factor;markov chain;econometrics;data mining;machine learning;statistics;computer science;
Local community detection in multilayer networks,"Roberto Interdonato (University of Calabria);Andrea Tagarelli (University of Calabria);Dino Ienco (University of Turin);Arnaud Sallaberry (Paul Valéry University, Montpellier III);Pascal Poncelet (University of Montpellier);","1753498136,273425128,2288551980,198127655,733374064",-,2017,Data Mining and Knowledge Discovery pp 1-36,-
Fast and Accurate Mining of Correlated Heavy Hitters,Italo Epicoco (University of Salento);Massimo Cafaro (University of Salento);Marco Pulimeno (University of Salento);,"831550692,2122525326,1894818775","The problem of mining Correlated Heavy Hitters (CHH) from a bi-dimensional data stream has been introduced recently, and a deterministic algorithm based on the use of the Misra--Gries algorithm has been proposed to solve it. In this paper we present a new counter-based algorithm for tracking CHHs, formally prove its error bounds and correctness and show, through extensive experimental results, that our algorithm outperforms the Misra--Gries based algorithm with regard to accuracy and speed whilst requiring asymptotically much less space.",2017,Data Mining and Knowledge Discovery,fsa red algorithm;theoretical computer science;data mining;algorithm;mathematics;
Scalable density-based clustering with quality guarantees using random projections,Johannes Schneider (University of Liechtenstein);Michail Vlachos (IBM);,"2736000493,2146138755","Clustering offers significant insights in data analysis. Density-based algorithms have emerged as flexible and efficient techniques, able to discover high-quality and potentially irregularly shaped clusters. Here, we present scalable density-based clustering algorithms using random projections. Our clustering methodology achieves a speedup of two orders of magnitude compared with equivalent state-of-art density-based techniques, while offering analytical guarantees on the clustering quality in Euclidean space. Moreover, it does not introduce difficult to set parameters. We provide a comprehensive analysis of our algorithms and comparison with existing density-based algorithms.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 972-1005,k medians clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;cluster analysis;biclustering;theoretical computer science;data mining;machine learning;computer science;
Measuring discrimination in algorithmic decision making,Indrė Žliobaitė (University of Helsinki);,2132075515,"Society is increasingly relying on data-driven predictive models for automated decision making. This is not by design, but due to the nature and noisiness of observational data, such models may systematically disadvantage people belonging to certain categories or groups, instead of relying solely on individual merits. This may happen even if the computing process is fair and well-intentioned. Discrimination-aware data mining studies of how to make predictive models free from discrimination, when the historical data, on which they are built, may be biased, incomplete, or even contain past discriminatory decisions. Discrimination-aware data mining is an emerging research discipline, and there is no firm consensus yet of how to measure the performance of algorithms. The goal of this survey is to review various discrimination measures that have been used, analytically and computationally analyze their performance, and highlight implications of using one or another measure. We also describe measures from other disciplines, which have not been used for measuring discrimination, but potentially could be suitable for this purpose. This survey is primarily intended for researchers in data mining and machine learning as a step towards producing a unifying view of performance criteria when developing new algorithms for non-discriminatory predictive modeling. In addition, practitioners and policy makers could use this study when diagnosing potential discrimination by predictive models.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 1060-1089,predictive analytics;management science;data mining;machine learning;statistics;computer science;
FitMine: automatic mining for time-evolving signals of cardiotocography monitoring,Sun Hee Kim (Korea University);Hyung Jeong Yang (Chonnam National University);Seong Whan Lee (Korea University);,"2501061722,2180527834,2321956385","The monitoring and assessment of the fetus condition are considered to be among the most important obstetric issues to consider during pregnancy and the prenatal period. Monitoring the fetal condition is required to detect the presence of any abnormalities in the oxygen supply to the fetus early in the antenatal or labor period. Early detection can prevent permanent brain damage and death, both of which may arise from suffocation caused by fetal disease, hypoxic-ischemic injury in the neonatal brain, or chronic fetal asphyxia. In this paper, we propose a new signal-fitting method, FitMine, that identifies the fetal condition by analyzing fetal heart rate (FHR) and uterine contraction (UC) signals that are non-invasively measured by cardiotocography (CTG). FitMine is a novel nonlinear dynamic model that reflects the relation between the FHR and UC signals; it combines the chaotic population model and unscented Kalman filter algorithm. The proposed method has several benefits. These are: (a) change-point detection: the proposed method can detect significant pattern variations such as high or low peaks changing suddenly in the FHR and UC signals; (b) parameter-free: it is performed automatically without the requirement for the user to enter input parameters; (c) scalability: FitMine is linearly scalable according to the size of the input data; and (d) applicability: the proposed model can be applied to detect abnormal signs in various domains including electroencephalogram data, epidemic data, temperature data, in addition to CTG recordings.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 909-933,minimum description length;kalman filter;estimation theory;telecommunications;machine learning;statistics;computer science;
The PRIMPING routine—Tiling through proximal alternating linearized minimization,Sibylle Hess (Technical University of Dortmund);Katharina Morik (Technical University of Dortmund);Nico Piatkowski (Technical University of Dortmund);,"2521191643,2070565061,1739481293","Mining and exploring databases should provide users with knowledge and new insights. Tiles of data strive to unveil true underlying structure and distinguish valuable information from various kinds of noise. We propose a novel Boolean matrix factorization algorithm to solve the tiling problem, based on recent results from optimization theory. In contrast to existing work, the new algorithm minimizes the description length of the resulting factorization. This approach is well known for model selection and data compression, but not for finding suitable factorizations via numerical optimization. We demonstrate the superior robustness of the new approach in the presence of several kinds of noise and types of underlying structure. Moreover, our general framework can work with any cost measure having a suitable real-valued relaxation. Thereby, no convexity assumptions have to be met. The experimental results on synthetic data and image data show that the new method identifies interpretable patterns which explain the data almost always better than the competing algorithms.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 1090-1131,discrete mathematics;combinatorics;machine learning;mathematical optimization;statistics;mathematics;
Discrimination of Alzheimer’s Disease using longitudinal information,Helena Aidos (Instituto Superior Técnico);Ana L. N. Fred (Instituto Superior Técnico);,"2461135768,2297453548",-,2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 1006-1030,-
Robust unsupervised cluster matching for network data,Tomoharu Iwata (Nippon Telegraph and Telephone);Katsuhiko Ishiguro (Nippon Telegraph and Telephone);,"2108993706,2069134894","Unsupervised cluster matching is a task to find matching between clusters of objects in different domains. Examples include matching word clusters in different languages without dictionaries or parallel sentences and matching user communities across different friendship networks. Existing methods assume that every object is assigned into a cluster. However, in real-world applications, some objects would not form clusters. These irrelevant objects deteriorate the cluster matching performance since mistakenly estimated matching affect on estimation of matching of other objects. In this paper, we propose a probabilistic model for robust unsupervised cluster matching that discovers relevance of objects and matching of object clusters, simultaneously, given multiple networks. The proposed method finds correspondence only for relevant objects, and keeps irrelevant objects unmatched, which enables us to improve the matching performance since the adverse impact of irrelevant objects is eliminated. With the proposed method, relevant objects in different networks are clustered into a shared set of clusters by assuming that different networks are generated from a common network probabilistic model, which is an extension of stochastic block models. Objects assigned into the same clusters are considered as matched. Edges for irrelevant objects are assumed to be generated from a noise distribution irrespective of cluster assignments. We present an efficient Bayesian inference procedure of the proposed model based on collapsed Gibbs sampling. In our experiments, we demonstrate the effectiveness of the proposed method using synthetic and real-world data sets, including multilingual corpora and movie ratings.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 1132-1154,network model;unsupervised learning;data mining;pattern recognition;machine learning;computer science;
Enhancing social collaborative filtering through the application of non-negative matrix factorization and exponential random graph models,Georgios Alexandridis (National Technical University of Athens);Georgios Siolas (National Technical University of Athens);Andreas Stafylopatis (National Technical University of Athens);,"2426054988,2010588381,2336400308","Social collaborative filtering recommender systems extend the traditional user-to-item interaction with explicit user-to-user relationships, thereby allowing for a wider exploration of correlations among users and items, that potentially lead to better recommendations. A number of methods have been proposed in the direction of exploring the social network, either locally (i.e. the vicinity of each user) or globally. In this paper, we propose a novel methodology for collaborative filtering social recommendation that tries to combine the merits of both the aforementioned approaches, based on the soft-clustering of the Friend-of-a-Friend (FoaF) network of each user. This task is accomplished by the non-negative factorization of the adjacency matrix of the FoaF graph, while the edge-centric logic of the factorization algorithm is ameliorated by incorporating more general structural properties of the graph, such as the number of edges and stars, through the introduction of the exponential random graph models. The preliminary results obtained reveal the potential of this idea.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 1031-1059,exponential random graph models;non negative matrix factorization;collaborative filtering;recommender system;theoretical computer science;combinatorics;data mining;machine learning;computer science;mathematics;
Retrieving geometric information from images: the case of hand-drawn diagrams,Dan Song (Beihang University);Dongming Wang (Beihang University);Xiaoyu Chen (Beihang University);,"2294964784,2229217467,2233797701","This paper addresses the problem of retrieving meaningful geometric information implied in image data. We outline a general algorithmic scheme to solve the problem in any geometric domain. The scheme, which depends on the domain, may lead to concrete algorithms when the domain is properly and formally specified. Taking plane Euclidean geometry \({\mathbb {E}}\) as an example of the domain, we show how to formally specify \({\mathbb {E}}\) and how to concretize the scheme to yield algorithms for the retrieval of meaningful geometric information in \({\mathbb {E}}\). For images of hand-drawn diagrams in \({\mathbb {E}}\), we present concrete algorithms to retrieve typical geometric objects and geometric relations, as well as their labels, and demonstrate the feasibility of our algorithms with experiments. An example is presented to illustrate how nontrivial geometric theorems can be generated from retrieved geometric objects and relations and thus how implied geometric knowledge may be discovered automatically from images.",2017,Data Mining and Knowledge Discovery volume 31 issue 4 pp 934-971,geometric transformation;formal specification;pattern matching;knowledge extraction;discrete mathematics;combinatorics;geometry;computer science;mathematics;
Identifying Consistent Statements about Numerical Data with Dispersion-Corrected Subgroup Discovery,Mario Boley (Max Planck Society);Bryan R. Goldsmith;Luca M. Ghiringhelli (Max Planck Society);Jilles Vreeken (Max Planck Society);,"2581150136,2705878701,1777702824,1971070670","Existing algorithms for subgroup discovery with numerical targets do not optimize the error or target variable dispersion of the groups they find. This often leads to unreliable or inconsistent statements about the data, rendering practical applications, especially in scientific domains, futile. Therefore, we here extend the optimistic estimator framework for optimal subgroup discovery to a new class of objective functions: we show how tight estimators can be computed efficiently for all functions that are determined by subgroup size (non-decreasing dependence), the subgroup median value, and a dispersion measure around the median (non-increasing dependence). In the important special case when dispersion is measured using the average absolute deviation from the median, this novel approach yields a linear time algorithm. Empirical evaluation on a wide range of datasets shows that, when used within branch-and-bound search, this approach is highly efficient and indeed discovers subgroups with much smaller errors.",2017,Data Mining and Knowledge Discovery,data mining;machine learning;statistics;algorithm;computer science;mathematics;
The best privacy defense is a good privacy offense: obfuscating a search engine user’s profile,Jörg Wicker (Technische Universität München);Stefan Kramer (Technische Universität München);,"2166053766,2283720790","User privacy on the internet is an important and unsolved problem. So far, no sufficient and comprehensive solution has been proposed that helps a user to protect his or her privacy while using the internet. Data are collected and assembled by numerous service providers. Solutions so far focused on the side of the service providers to store encrypted or transformed data that can be still used for analysis. This has a major flaw, as it relies on the service providers to do this. The user has no chance of actively protecting his or her privacy. In this work, we suggest a new approach, empowering the user to take advantage of the same tool the other side has, namely data mining to produce data which obfuscates the user’s profile. We apply this approach to search engine queries and use feedback of the search engines in terms of personalized advertisements in an algorithm similar to reinforcement learning to generate new queries potentially confusing the search engine. We evaluated the approach using a real-world data set. While evaluation is hard, we achieve results that indicate that it is possible to influence the user’s profile that the search engine generates. This shows that it is feasible to defend a user’s privacy from a new and more practical perspective.",2017,Data Mining and Knowledge Discovery pp 1-25,privacy software;privacy;web mining;reinforcement learning;internet privacy;world wide web;data mining;computer science;
BSig: evaluating the statistical significance of biclustering solutions,Rui Henriques (INESC-ID);Sara C. Madeira (INESC-ID);,"2139129317,2047722776",-,2017,Data Mining and Knowledge Discovery,-
"Time series joins, motifs, discords and shapelets: a unifying view that exploits the matrix profile","Chin-Chia Michael Yeh (Center for Information Technology);Yan Zhu (Shanghai Jiao Tong University);Liudmila Ulanova (University of California, Riverside);Nurjahan Begum (University of California, Riverside);Yifei Ding (University of California, Riverside);Hoang Anh Dau (University of California, Riverside);Zachary Zimmerman (Azusa Pacific University);Diego Furtado Silva (Spanish National Research Council);Abdullah Mueen (University of New Mexico);Eamonn Keogh (University of California, Riverside);","2107817180,2678804180,2089139422,2157373250,2342796293,2712909183,2316597706,2138204294,2083987245,2170070822",-,2017,Data Mining and Knowledge Discovery,bioinformatics;data mining;database;
Imbalanced classification in sparse and large behaviour datasets,Jellis Vanhoeyveld;David Martens (University of Antwerp);,"2477735961,2605386389",-,2017,Data Mining and Knowledge Discovery,pattern recognition;
Comparing dynamics of fluency and inter-limb coordination in climbing activities using multi-scale Jensen–Shannon embedding and clustering,Romain Herault (Intelligence and National Security Alliance);Dominic Orth (University of Rouen);Ludovic Seifert (University of Rouen);Jeremie Boulanger (University of Rouen);John Aldo Lee;,"1995790827,2148659472,2121213514,2131908913,2626270373",-,2017,Data Mining and Knowledge Discovery,artificial intelligence;machine learning;simulation;computer science;
Discovering recurring activity in temporal networks,Orestis Kostakis (Aalto University);Nikolaj Tatti (Aalto University);Aristides Gionis (Aalto University);,"1500961275,1367500519,737311942",-,2017,Data Mining and Knowledge Discovery,-
Noise-tolerance matrix completion for location recommendation,Bin Xia (Nanjing University of Science and Technology);Tao Li (Florida International University);Qianmu Li (Nanjing University of Science and Technology);Hong Zhang (Nanjing University of Science and Technology);,"2307189372,2472069284,2150722659,2441182045","Due to the sharply increasing number of users and venues in Location-Based Social Networks, it becomes a big challenge to provide recommendations which match users’ preferences. Furthermore, the sparse data and skew distribution (i.e., structural noise) also worsen the coverage and accuracy of recommendations. This problem is prevalent in traditional recommender methods since they assume that the collected data truly reflect users’ preferences. To overcome the limitation of current recommenders, it is imperative to explore an effective strategy, which can accurately provide recommendations while tolerating the structural noise. However, few study concentrates on the process of noisy data in the recommender system, even recent matrix-completion algorithms. In this paper, we cast the location recommendation as a mathematical matrix-completion problem and propose a robust algorithm named Linearized Bregman Iteration for Matrix Completion (LBIMC), which can effectively recover the user-location matrix considering structural noise and provide recommendations based solely on check-in records. Our experiments are conducted by an amount of check-in data from Foursquare, and the results demonstrate the effectiveness of LBIMC.",2017,Data Mining and Knowledge Discovery pp 1-24,recommender system;world wide web;data mining;machine learning;statistics;computer science;
Archetypoid analysis for sports analytics,G. Vinué (University of Valencia);I. Epifanio (RIU Hotels);,"2651830774,2650889268","We intend to understand the growing amount of sports performance data by finding extreme data points, which makes human interpretation easier. In archetypoid analysis each datum is expressed as a mixture of actual observations (archetypoids). Therefore, it allows us to identify not only extreme athletes and teams, but also the composition of other athletes (or teams) according to the archetypoid athletes, and to establish a ranking. The utility of archetypoids in sports is illustrated with basketball and soccer data in three scenarios. Firstly, with multivariate data, where they are compared with other alternatives, showing their best results. Secondly, despite the fact that functional data are common in sports (time series or trajectories), functional data analysis has not been exploited until now, due to the sparseness of functions. In the second scenario, we extend archetypoid analysis for sparse functional data, furthermore showing the potential of functional data analysis in sports analytics. Finally, in the third scenario, features are not available, so we use proximities. We extend archetypoid analysis when asymmetric relations are present in data. This study provides information that will provide valuable knowledge about player/team/league performance so that we can analyze athlete’s careers.",2017,Data Mining and Knowledge Discovery pp 1-35,functional data analysis;extreme point;multidimensional scaling;data science;data mining;simulation;statistics;
Regimes in baseball players’ career data,Marcus Bendtsen (Linköping University);,2048626060,"In this paper we investigate how we can use gated Bayesian networks, a type of probabilistic graphical model, to represent regimes in baseball players’ career data. We find that baseball players do indeed go through different regimes throughout their career, where each regime can be associated with a certain level of performance. We show that some of the transitions between regimes happen in conjunction with major events in the players’ career, such as being traded or injured, but that some transitions cannot be explained by such events. The resulting model is a tool for managers and coaches that can be used to identify where transitions have occurred, as well as an online monitoring tool to detect which regime the player currently is in.",2017,Data Mining and Knowledge Discovery pp 1-42,simulation;
Visual analysis of pressure in football,Gennady Andrienko (Fraunhofer Society);Natalia Andrienko (Fraunhofer Society);Guido Budziak (Eindhoven University of Technology);Jason Dykes (City University London);Georg Fuchs (Fraunhofer Society);Tatiana von Landesberger (Technische Universität Darmstadt);Hendrik Weber;,"237265413,1983982202,2559683684,2144192189,2306943979,110159255,2559088388","Modern movement tracking technologies enable acquisition of high quality data about movements of the players and the ball in the course of a football match. However, there is a big difference between the raw data and the insights into team behaviors that analysts would like to gain. To enable such insights, it is necessary first to establish relationships between the concepts characterizing behaviors and what can be extracted from data. This task is challenging since the concepts are not strictly defined. We propose a computational approach to detecting and quantifying the relationships of pressure emerging during a game. Pressure is exerted by defending players upon the ball and the opponents. Pressing behavior of a team consists of multiple instances of pressure exerted by the team members. The extracted pressure relationships can be analyzed in detailed and summarized forms with the use of static and dynamic visualizations and interactive query tools. To support examination of team tactics in different situations, we have designed and implemented a novel interactive visual tool “time mask”. It enables selection of multiple disjoint time intervals in which given conditions are fulfilled. Thus, it is possible to select game situations according to ball possession, ball distance to the goal, time that has passed since the last ball possession change or remaining time before the next change, density of players’ positions, or various other conditions. In response to a query, the analyst receives visual and statistical summaries of the set of selected situations and can thus perform joint analysis of these situations. We give examples of applying the proposed combination of computational, visual, and interactive techniques to real data from games in the German Bundesliga, where the teams actively used pressing in their defense tactics.",2017,Data Mining and Knowledge Discovery pp 1-47,visual analytics;multimedia;data mining;artificial intelligence;machine learning;simulation;computer science;
Sports analytics for professional speed skating,Arno Knobbe (Leiden University);Jac Orie;Nico Hofman;Benjamin van der Burgh (Leiden University);Ricardo Cachucho (Leiden University);,"1229146049,2332694046,2568804328,2397756397,274548734","In elite sports, training schedules are becoming increasingly complex, and a large number of parameters of such schedules need to be tuned to the specific physique of a given athlete. In this paper, we describe how extensive analysis of historical data can help optimise these parameters, and how possible pitfalls of under- and overtraining in the past can be avoided in future schedules. We treat the series of exercises an athlete undergoes as a discrete sequence of attributed events, that can be aggregated in various ways, to capture the many ways in which an athlete can prepare for an important test event. We report on a cooperation with the elite speed skating team LottoNL-Jumbo, who have recorded detailed training data over the last 15 years. The aim of the project was to analyse this potential source of knowledge, and extract actionable and interpretable patterns that can provide input to future improvements in training. We present two alternative techniques to aggregate sequences of exercises into a combined, long-term training effect, one of which based on a sliding window, and one based on a physiological model of how the body responds to exercise. Next, we use both linear modelling and Subgroup Discovery to extract meaningful models of the data.",2017,Data Mining and Knowledge Discovery pp 1-31,sequential pattern mining;operations research;data mining;simulation;computer science;
Classification and legality analysis of bowling action in the game of cricket,Muhammad Salman (NUST School of Electrical Engineering and Computer Science);Saad Qaisar (NUST School of Electrical Engineering and Computer Science);Ali Mustafa Qamar (NUST School of Electrical Engineering and Computer Science);,"2618010391,2091938465,2618756863","One of the hot topics in modern era of cricket is to decide whether the bowling action of a bowler is legal or not. Because of the complex bio-mechanical movement of the bowling arm, it is not possible for the on-field umpire to declare a bowling action as legal or illegal. Inertial sensors are currently being used for activity recognition in cricket for the coaching of bowlers and detecting the legality of their moves, since a well trained and legal bowling action is highly significant for the career of a cricket player. After extensive analysis and research, we present a system to detect the legality of the bowling action based on real time multidimensional physiological data obtained from the inertial sensors mounted on the bowlers arm. We propose a method to examine the movement of the bowling arm in the correct rotation order with a precise angle. The system evaluates the bowling action using various action profiles. The action profiles are used so as to simplify the complex bio-mechanical movement of the bowling arm along with minimizing the size of the data provided to the classifier. The events of interest are identified and tagged. Algorithms such as support vector machines, k-nearest neighbor, Naive Bayes, random forest, and artificial neural network are trained over statistical features extracted from the tagged data. To accomplish the reliability of outcome measures, the technical error of measurement was adopted. The proposed method achieves very high accuracy in the correct classification of bowling action.",2017,Data Mining and Knowledge Discovery pp 1-29,inertial measurement unit;feature extraction;biological classification;activity recognition;speech recognition;artificial intelligence;machine learning;simulation;computer science;
Reducing uncertainty of dynamic heterogeneous information networks: a fusing reconstructing approach,Ning Yang (Sichuan University);Lifang He (Vision Institute);Zheng Li (Sichuan University);Philip S. Yu (University of Illinois at Chicago);,"2283784084,2690427399,2710202894,2125104194","In real world, a heterogeneous information network (HIN) is often dynamic due to the time varying features of the nodes, and uncertain due to missing values and noise. In this paper, we investigate the problem of reducing the uncertainty of a dynamic HIN, which is an important task for HIN analysis. The challenges are three-fold, the heterogeneity of features, the heterogeneity of constraints, and the dynamic uncertainty. We propose a novel approach, called fusing reconstruction (FRec), which reconstructs the uncertain snapshots of a dynamic HIN in a homogeneous feature space combining two fusions, the fusion of heterogeneous features and the fusion of heterogeneous constraints. To address the challenge of the heterogeneity of features, we propose an invertible fusing transformation (IFT) as the first part of FRec. IFT is a bidirectional transformation, which is able to learn unified latent homogeneous feature representations for heterogeneous nodes and transform them back to the raw heterogeneous feature space by its invertibility. To address the challenge of the heterogeneity of constraints and the challenge of dynamic uncertainty, we propose a heterogeneous constraints fusion based tensor reconstruction model (HCF-TRM) as the second part of FRec. HCF-TRM is able to denoise the uncertain snapshots of a dynamic HIN and recovers the missing values by fusing the spatial smoothness constraint and the temporal smoothness constraint into the tensor reconstruction. At last, the extensive experiments conducted on real datasets and synthetic datasets verify the effectiveness and scalability of FRec.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 879-906,graph embedding;data mining;machine learning;mathematical optimization;mathematics;
The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances,"Anthony Bagnall (University of East Anglia);Jason Lines (University of East Anglia);Aaron Bostrom (University of East Anglia);James Large (University of East Anglia);Eamonn J. Keogh (University of California, Riverside);","2171856547,1984663852,2136857950,2554190571,2170070822","In the last 5 years there have been a large number of new time series classification algorithms proposed in the literature. These algorithms have been evaluated on subsets of the 47 data sets in the University of California, Riverside time series classification archive. The archive has recently been expanded to 85 data sets, over half of which have been donated by researchers at the University of East Anglia. Aspects of previous evaluations have made comparisons between algorithms difficult. For example, several different programming languages have been used, experiments involved a single train/test split and some used normalised data whilst others did not. The relaunch of the archive provides a timely opportunity to thoroughly evaluate algorithms on a larger number of datasets. We have implemented 18 recently proposed algorithms in a common Java framework and compared them against two standard benchmark classifiers (and each other) by performing 100 resampling experiments on each of the 85 datasets. We use these results to test several hypotheses relating to whether the algorithms are significantly more accurate than the benchmarks and each other. Our results indicate that only nine of these algorithms are significantly more accurate than both benchmarks and that one classifier, the collective of transformation ensembles, is significantly more accurate than all of the others. All of our experiments and results are reproducible: we release all of our code, results and experimental details and we hope these experiments form the basis for more robust testing of new algorithms in the future.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 606-660,data science;data mining;machine learning;statistics;computer science;mathematics;
On classifier behavior in the presence of mislabeling noise,Katsiaryna Mirylenka (IBM);George Giannakopoulos (University of Trento);Le Minh Do (University of Trento);Themis Palpanas (Paris Descartes University);,"250322829,2106620877,2559815951,2010554420","Machine learning algorithms perform differently in settings with varying levels of training set mislabeling noise. Therefore, the choice of the right algorithm for a particular learning problem is crucial. The contribution of this paper is towards two, dual problems: first, comparing algorithm behavior; and second, choosing learning algorithms for noisy settings. We present the “sigmoid rule” framework, which can be used to choose the most appropriate learning algorithm depending on the properties of noise in a classification problem. The framework uses an existing model of the expected performance of learning algorithms as a sigmoid function of the signal-to-noise ratio in the training instances. We study the characteristics of the sigmoid function using five representative non-sequential classifiers, namely, Naive Bayes, kNN, SVM, a decision tree classifier, and a rule-based classifier, and three widely used sequential classifiers based on hidden Markov models, conditional random fields and recursive neural networks. Based on the sigmoid parameters we define a set of intuitive criteria that are useful for comparing the behavior of learning algorithms in the presence of noise. Furthermore, we show that there is a connection between these parameters and the characteristics of the underlying dataset, showing that we can estimate an expected performance over a dataset regardless of the underlying algorithm. The framework is applicable to concept drift scenarios, including modeling user behavior over time, and mining of noisy time series of evolving nature.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 661-701,concept drift;biological classification;learning classifier system;data mining;pattern recognition;machine learning;statistics;computer science;
On searching and indexing sequences of temporal intervals,Orestis Kostakis (Aalto University);Panagiotis Papapetrou (Stockholm University);,"1500961275,2000108749","In several application domains, including sign language, sensor networks, and medicine, events are not necessarily instantaneous but they may have a time duration. Such events build sequences of temporal intervals, which may convey useful domain knowledge; thus, searching and indexing these sequences is crucial. We formulate the problem of comparing sequences of labeled temporal intervals and present a distance measure that can be computed in polynomial time. We prove that the distance measure is metric and satisfies the triangle inequality. For speeding up search in large databases of sequences of temporal intervals, we propose an approximate indexing method that is based on embeddings. The proposed indexing framework is shown to be contractive and can guarantee no false dismissal. The distance measure is tested and benchmarked through rigorous experimentation on real data taken from several application domains, including: American Sign Language annotated video recordings, robot sensor data, and Hepatitis patient data. In addition, the indexing scheme is tested on a large synthetic dataset. Our experiments show that speedups of over an order of magnitude can be achieved while maintaining high levels of accuracy. As a result of our work, it becomes possible to implement recommender systems, search engines and assistive applications for the fields that employ sequences of temporal intervals.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 809-850,pattern;time series;theoretical computer science;discrete mathematics;data mining;machine learning;statistics;mathematics;
Explaining clusterings of process instances,Pieter De Koninck (Katholieke Universiteit Leuven);Jochen De Weerdt (Katholieke Universiteit Leuven);Seppe K. L. M. vanden Broucke (Katholieke Universiteit Leuven);,"2412366220,2044761747,783869731","This paper presents a technique that aims to increase human understanding of trace clustering solutions. The clustering techniques under scrutiny stem from the process mining domain, where the clustering of process instances is deemed a useful technique to analyse process data with a large variety of behaviour. Until now, the most often used method to inspect clustering solutions in this domain is visual inspection of the clustering results. This paper proposes a more thorough approach based on the post hoc application of supervised learning with support vector machines on cluster results. Our approach learns concise rules to describe why a specific instance is included in a certain cluster based on specific control-flow based feature variables. An extensive experimental evaluation is presented showing that our technique outperforms alternatives. Likewise, we are able to identify features that lead to shorter and more accurate explanations.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 774-808,constrained clustering;business process discovery;fuzzy clustering;clustering high dimensional data;support vector machine;cluster analysis;consensus clustering;conceptual clustering;data mining;pattern recognition;machine learning;computer science;
Improving time series similarity measures by integrating preprocessing steps,Frank Höppner;,2306305617,"While many application papers involving time series data report about the beneficial application of filters, filtering (and preprocessing in general) plays at best a minor role in the proposals of similarity measures for time series or the studies that compare them. We investigate the performance of basic Euclidean distance with an integrated preprocessing (filtering with automatically derived filters (supervised or unsupervised) and rescaling) and demonstrate that such measures can better respond to typical problems in time series similarity. By accounting for differences in both domains (time and value) we overcome some limitations of elastic measures that focus on time only. Using the proposed measure on real datasets we can achieve performance gains comparable to those of switching from a lock-step measure (Euclidean) to an elastic measure (DTW).",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 851-878,temporal database;preprocessor;adaptive filter;data mining;pattern recognition;machine learning;computer science;mathematics;
Detecting cooperative and organized spammer groups in micro-blogging community,Qi Dang (Xi'an Jiaotong University);Yadong Zhou (Xi'an Jiaotong University);Feng Gao (Xi'an Jiaotong University);Qindong Sun;,"2487134350,2166287960,2627880293,2691826786","In recent years, social spammers become rampant and evolve a number of variations in most social networks. In micro-blogging community, there are a typical type of anomalous groups consisting of cooperative and organized spammers, and they are hired by public relation companies and paid for posting tweets with certain content. They intentionally evolve their content and behavior patterns to prevent them from being detected, and cooperatively hijack the trending topics with a deliberate point of view which would affect people’s judgments and decisions seriously. Due to the evolving nature and hidden behavior of this type of spammers, we have to deal with two important issues to solve the problem of detecting this type of spammer groups. One is to detect the anomalous topics hijacked by spammer groups from numerous trending topics. Another is to detect the members of spammer group from the users joining anomalous topics. In this paper, we propose a two-stage topology-based method to detect spammer groups partially distributed in multiple trending topics. In the first stage, we detect the anomalous topics from plenty of trending topics according to a new similarity measure based on subgraph ranking. A topic is identified as anomalous if the topology characteristics of retweeting networks between adjacent periods change dramatically. In the second stage, we obtain several anomalous topic sequences through a few initial labeled spammers by employing the basic idea of label propagation, and cluster the users who join each topic sequence into group spammers and normal users by their total authorities. The total authority of user is his/her weighted cumulative authorities in anomalous topics of each topic sequence, and authority in each topic is defined based on the out-degree of user in the retweeting network. The experimental results based on real-world data collected from Sina micro-blogging site demonstrate that our similarity measure keeps a leading performance in all evaluation metrics, and our method can effectively detect the group spammers compared with other methods.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 573-605,spamming;internet privacy;world wide web;data mining;computer science;
Tiers for peers: a practical algorithm for discovering hierarchy in weighted networks,Nikolaj Tatti (Helsinki Institute for Information Technology);,1367500519,"Interactions in many real-world phenomena can be explained by a strong hierarchical structure. Typically, this structure or ranking is not known; instead we only have observed outcomes of the interactions, and the goal is to infer the hierarchy from these observations. Discovering a hierarchy in the context of directed networks can be formulated as follows: given a graph, partition vertices into levels such that, ideally, there are only edges from upper levels to lower levels. The ideal case can only happen if the graph is acyclic. Consequently, in practice we have to introduce a penalty function that penalizes edges violating the hierarchy. A practical variant for such penalty is agony, where each violating edge is penalized based on the severity of the violation. Hierarchy minimizing agony can be discovered in Open image in new window time, and much faster in practice. In this paper we introduce several extensions to agony. We extend the definition for weighted graphs and allow a cardinality constraint that limits the number of levels. While, these are conceptually trivial extensions, current algorithms cannot handle them, nor they can be easily extended. We solve the problem by showing the connection to the capacitated circulation problem, and we demonstrate that we can compute the exact solution fast in practice for large datasets. We also introduce a provably fast heuristic algorithm that produces rankings with competitive scores. In addition, we show that we can compute agony in polynomial time for any convex penalty, and, to complete the picture, we show that minimizing hierarchy with any concave penalty is an NP-hard problem.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 702-738,discrete mathematics;combinatorics;data mining;machine learning;mathematical optimization;statistics;mathematics;
Visualizing the behavior and some symmetry properties of Bayesian confirmation measures,Emilio Celotto;,2717988768,"Bayesian confirmation measures, a special class of interestingness measures, are functions usually adopted in ranking inductive rules generated by data mining methods such as association rule mining, decision trees, rough sets. Till now a plethora of measures have been defined in many different ways. Identifying and effectively distinguishing among them is a difficult task. In this paper we propose a unified visual approach aimed at comparing and classifying a large subset of Bayesian confirmation measures (those satisfying the initial and final probability dependence condition). We first reduce the set of variables in their analytical expression to only two, thus allowing to draw their contour lines on the plane. We observe that two dimensional contour lines plots represent a sort of fingerprints of the confirmation measures and, therefore, this geometric visualization can be used as an effective tool in order to investigate properties and behavior of the measures. We highlight the potential of this approach not only to study known measures but also in order to invent new measures satisfying given required characteristics. We finally define, following the geometry of the plots, a new set of symmetry properties of confirmation measures and describe geometrically four classical symmetries.",2017,Data Mining and Knowledge Discovery volume 31 issue 3 pp 739-773,data mining;machine learning;statistics;mathematics;
On temporal-constrained sub-trajectory cluster analysis,Nikos Pelekis (University of Piraeus);Panagiotis Tampakis (University of Piraeus);Marios Vodas (University of Piraeus);Christos Doulkeridis (University of Piraeus);Yannis Theodoridis (University of Piraeus);,"2020175353,1998197826,221267374,167530315,31261168","Cluster analysis over Moving Object Databases (MODs) is a challenging research topic that has attracted the attention of the mobility data mining community. In this paper, we study the temporal-constrained sub-trajectory cluster analysis problem, where the aim is to discover clusters of sub-trajectories given an ad-hoc, user-specified temporal constraint within the dataset’s lifetime. The problem is challenging because: (a) the time window is not known in advance, instead it is specified at query time, and (b) the MOD is continuously updated with new trajectories. Existing solutions first filter the trajectory database according to the temporal constraint, and then apply a clustering algorithm from scratch on the filtered data. However, this approach is extremely inefficient, when considering explorative data analysis where multiple clustering tasks need to be performed over different temporal subsets of the database, while the database is updated with new trajectories. To address this problem, we propose an incremental and scalable solution to the problem, which is built upon a novel indexing structure, called Representative Trajectory Tree (ReTraTree). ReTraTree acts as an effective spatio-temporal partitioning technique; partitions in ReTraTree correspond to groupings of sub-trajectories, which are incrementally maintained and assigned to representative (sub-)trajectories. Due to the proposed organization of sub-trajectories, the problem under study can be efficiently solved as simply as executing a query operator on ReTraTree, while insertion of new trajectories is supported. Our extensive experimental study performed on real and synthetic datasets shows that our approach outperforms a state-of-the-art in-DBMS solution supported by PostgreSQL by orders of magnitude.",2017,Data Mining and Knowledge Discovery pp 1-37,search engine indexing;cluster analysis;data mining;database;machine learning;computer science;
Lagrangian relaxations for multiple network alignment,Eric Malmi (Aalto University);Sanjay Chawla (Qatar Computing Research Institute);Aristides Gionis (Aalto University);,"2289295535,2201421368,737311942","We propose a principled approach for the problem of aligning multiple partially overlapping networks. The objective is to map multiple graphs into a single graph while preserving vertex and edge similarities. The problem is inspired by the task of integrating partial views of a family tree (genealogical network) into one unified network, but it also has applications, for example, in social and biological networks. Our approach, called Flan, introduces the idea of generalizing the facility location problem by adding a non-linear term to capture edge similarities and to infer the underlying entity network. The problem is solved using an alternating optimization procedure with a Lagrangian relaxation. Flan has the advantage of being able to leverage prior information on the number of entities, so that when this information is available, Flan is shown to work robustly without the need to use any ground truth data for fine-tuning method parameters. Additionally, we present three multiple-network extensions to an existing state-of-the-art pairwise alignment method called Natalie. Extensive experiments on synthetic, as well as real-world datasets on social networks and genealogical networks, attest to the effectiveness of the proposed approaches which clearly outperform a popular multiple network alignment method called IsoRankN.",2017,Data Mining and Knowledge Discovery pp 1-28,lagrangian relaxation;facility location problem;social network;combinatorics;data mining;machine learning;mathematical optimization;computer science;mathematics;
Flexible constrained sampling with guarantees for pattern mining,Vladimir Dzyuba (Katholieke Universiteit Leuven);Matthijs van Leeuwen (Leiden University);Luc De Raedt (Katholieke Universiteit Leuven);,"2032827832,2658292108,189137728","Pattern sampling has been proposed as a potential solution to the infamous pattern explosion. Instead of enumerating all patterns that satisfy the constraints, individual patterns are sampled proportional to a given quality measure. Several sampling algorithms have been proposed, but each of them has its limitations when it comes to (1) flexibility in terms of quality measures and constraints that can be used, and/or (2) guarantees with respect to sampling accuracy. We therefore present Flexics, the first flexible pattern sampler that supports a broad class of quality measures and constraints, while providing strong guarantees regarding sampling accuracy. To achieve this, we leverage the perspective on pattern mining as a constraint satisfaction problem and build upon the latest advances in sampling solutions in SAT as well as existing pattern mining algorithms. Furthermore, the proposed algorithm is applicable to a variety of pattern languages, which allows us to introduce and tackle the novel task of sampling sets of patterns. We introduce and empirically evaluate two variants of Flexics: (1) a generic variant that addresses the well-known itemset sampling task and the novel pattern set sampling task as well as a wide range of expressive constraints within these tasks, and (2) a specialized variant that exploits existing frequent itemset techniques to achieve substantial speed-ups. Experiments show that Flexics is both accurate and efficient, making it a useful tool for pattern-based data exploration.",2017,Data Mining and Knowledge Discovery pp 1-28,theoretical computer science;data mining;real time computing;computer science;
"A Markov Game model for valuing actions, locations, and team performance in ice hockey",Oliver Schulte (Simon Fraser University);Mahmoud Khademi (Simon Fraser University);Sajjad Gholami (Simon Fraser University);Zeyu Zhao (Simon Fraser University);Mehrsan Javan (Simon Fraser University);Philippe Desaulniers (Simon Fraser University);,"1896956012,2607459866,2553952903,2605747519,2601122903,2666006630","We apply the Markov Game formalism to develop a context-aware approach to valuing player actions, locations, and team performance in ice hockey. The Markov Game formalism uses machine learning and AI techniques to incorporate context and look-ahead. Dynamic programming is applied to learn value functions that quantify the impact of actions on goal scoring. Learning is based on a massive new dataset, from SportLogiq, that contains over 1.3M events in the National Hockey League. The SportLogiq data include the location of an action, which has previously been unavailable in hockey analytics. We give examples showing how the model assigns context and location aware values to a large set of 13 action types. Team performance can be assessed as the aggregate value of actions performed by the team’s players, or the aggregate value of states reached by the team. Model validation shows that the total team action and state value both provide a strong indicator predictor of team success, as measured by the team’s average goal ratio.",2017,Data Mining and Knowledge Discovery pp 1-23,q learning;artificial intelligence;machine learning;simulation;computer science;
Social regularized von Mises–Fisher mixture model for item recommendation,Aghiles Salah (Paris Descartes University);Mohamed Nadif (Paris Descartes University);,"2607326409,21121672","Collaborative filtering (CF) is a widely used technique to guide the users of web applications towards items that might interest them. CF approaches are severely challenged by the characteristics of user-item preference matrices, which are often high dimensional and extremely sparse. Recently, several works have shown that incorporating information from social networks—such as friendship and trust relationships—into traditional CF alleviates the sparsity related issues and yields a better recommendation quality, in most cases. More interestingly, even with comparable performances, social-based CF is more beneficial than traditional CF; the former makes it possible to provide recommendations for cold start users. In this paper, we propose a novel model that leverages information from social networks to improve recommendations. While existing social CF models are based on popular modelling assumptions such as Gaussian or Multinomial, our model builds on the von Mises–Fisher assumption which turns out to be more adequate, than the aforementioned assumptions, for high dimensional sparse data. Setting the estimate of the model parameters under the maximum likelihood approach, we derive a scalable learning algorithm for analyzing data with our model. Empirical results on several real-world datasets provide strong support for the advantages of the proposed model.",2017,Data Mining and Knowledge Discovery pp 1-24,collaborative filtering;mixture model;recommender system;data science;data mining;machine learning;statistics;computer science;
Classification of high-dimensional evolving data streams via a resource-efficient online ensemble,"Tingting Zhai (Nanjing University);Yang Gao (Nanjing University);Hao Wang (Nanjing University);Longbing Cao (University of Technology, Sydney);","2477398676,2410080050,2599526299,2115085568","A novel online ensemble strategy, ensemble BPegasos (EBPegasos), is proposed to solve the problems simultaneously caused by concept drifting and the curse of dimensionality in classifying high-dimensional evolving data streams, which has not been addressed in the literature. First, EBPegasos uses BPegasos, an online kernelized SVM-based algorithm, as the component classifier to address the scalability and sparsity of high-dimensional data. Second, EBPegasos takes full advantage of the characteristics of BPegasos to cope with various types of concept drifts. Specifically, EBPegasos constructs diverse component classifiers by controlling the budget size of BPegasos; it also equips each component with a drift detector to monitor and evaluate its performance, and modifies the ensemble structure only when large performance degradation occurs. Such conditional structural modification strategy makes EBPegasos strike a good balance between exploiting and forgetting old knowledge. Lastly, we first prove experimentally that EBPegasos is more effective and resource-efficient than the tree ensembles on high-dimensional data. Then comprehensive experiments on synthetic and real-life datasets also show that EBPegasos can cope with various types of concept drifts significantly better than the state-of-the-art ensemble frameworks when all ensembles use BPegasos as the base learner.",2017,Data Mining and Knowledge Discovery pp 1-24,concept drift;ensemble learning;data mining;pattern recognition;machine learning;computer science;
Survey on using constraints in data mining,Valerio Grossi (University of Pisa);Andrea Romei (University of Pisa);Franco Turini (University of Pisa);,"2144534063,1240669206,2241902680","This paper provides an overview of the current state-of-the-art on using constraints in knowledge discovery and data mining. The use of constraints in a data mining task requires specific definition and satisfaction tools during knowledge extraction. This survey proposes three groups of studies based on classification, clustering and pattern mining, whether the constraints are on the data, the models or the measures, respectively. We consider the distinctions between hard and soft constraint satisfaction, and between the knowledge extraction phases where constraints are considered. In addition to discussing how constraints can be used in data mining, we show how constraint-based languages can be used throughout the data mining process.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 424-464,constrained clustering;concept mining;data stream mining;knowledge extraction;data science;data mining;database;computer science;
Graph summarization with quality guarantees,Matteo Riondato (Brown University);David García-Soriano (Yahoo!);Francesco Bonchi (Institute for Scientific Interchange);,"1555209364,45643653,2176652147","We study the problem of graph summarization. Given a large graph we aim at producing a concise lossy representation (a summary) that can be stored in main memory and used to approximately answer queries about the original graph much faster than by using the exact representation. In this work we study a very natural type of summary: the original set of vertices is partitioned into a small number of supernodes connected by superedges to form a complete weighted graph. The superedge weights are the edge densities between vertices in the corresponding supernodes. To quantify the dissimilarity between the original graph and a summary, we adopt the reconstruction error and the cut-norm error. By exposing a connection between graph summarization and geometric clustering problems (i.e., k-means and k-median), we develop the first polynomial-time approximation algorithms to compute the best possible summary of a certain size under both measures. We discuss how to use our summaries to store a (lossy or lossless) compressed graph representation and to approximately answer a large class of queries about the original graph, including adjacency, degree, eigenvector centrality, and triangle and subgraph counting. Using the summary to answer queries is very efficient as the running time to compute the answer depends on the number of supernodes in the summary, rather than the number of nodes in the original graph.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 314-349,factor critical graph;distance hereditary graph;simplex graph;strength of a graph;quartic graph;voltage graph;complement graph;graph bandwidth;coxeter graph;graph power;graph factorization;butterfly graph;null graph;graph labeling;power graph analysis;cubic graph;distance regular graph;line graph;regular graph;degree;directed graph;automatic summarization;approximation algorithm;theoretical computer science;discrete mathematics;combinatorics;data mining;machine learning;computer science;mathematics;
Active learning: an empirical study of common baselines,Maria Eugenia Ramirez-Loaiza (Illinois Institute of Technology);Manali Sharma (Illinois Institute of Technology);Geet Kumar (Illinois Institute of Technology);Mustafa Bilgic 0001 (Illinois Institute of Technology);,"2006774049,2107515560,2278730215,2010936866","Most of the empirical evaluations of active learning approaches in the literature have focused on a single classifier and a single performance measure. We present an extensive empirical evaluation of common active learning baselines using two probabilistic classifiers and several performance measures on a number of large datasets. In addition to providing important practical advice, our findings highlight the importance of overlooked choices in active learning experiments in the literature. For example, one of our findings shows that model selection is as important as devising an active learning approach, and choosing one classifier and one performance measure can often lead to unexpected and unwarranted conclusions. Active learning should generally improve the model's capability to distinguish between instances of different classes, but our findings show that the improvements provided by active learning for one performance measure often came at the expense of another measure. We present several such results, raise questions, guide users and researchers to better alternatives, caution against unforeseen side effects of active learning, and suggest future research directions.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 287-313,active learning;management science;data mining;machine learning;
Multiple Bayesian discriminant functions for high-dimensional massive data classification,Jianfei Zhang (Université de Sherbrooke);Shengrui Wang (Université de Sherbrooke);Lifei Chen (Fujian Normal University);Patrick Gallinari (Pierre-and-Marie-Curie University);,"2311674678,2106818440,2699319152,2235456028","The presence of complex distributions of samples concealed in high-dimensional, massive sample-size data challenges all of the current classification methods for data mining. Samples within a class usually do not uniformly fill a certain (sub)space but are individually concentrated in certain regions of diverse feature subspaces, revealing the class dispersion. Current classifiers applied to such complex data inherently suffer from either high complexity or weak classification ability, due to the imbalance between flexibility and generalization ability of the discriminant functions used by these classifiers. To address this concern, we propose a novel representation of discriminant functions in Bayesian inference, which allows multiple Bayesian decision boundaries per class, each in its individual subspace. For this purpose, we design a learning algorithm that incorporates the naive Bayes and feature weighting approaches into structural risk minimization to learn multiple Bayesian discriminant functions for each class, thus combining the simplicity and effectiveness of naive Bayes and the benefits of feature weighting in handling high-dimensional data. The proposed learning scheme affords a recursive algorithm for exploring class density distribution for Bayesian estimation, and an automated approach for selecting powerful discriminant functions while keeping the complexity of the classifier low. Experimental results on real-world data characterized by millions of samples and features demonstrate the promising performance of our approach.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 465-501,naive bayes classifier;supervised learning;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Comparison of local outlier detection techniques in spatial multivariate data,Marie Ernst (University of Liège);Gentiane Haesbroeck (University of Liège);,"2099323089,209366699","Outlier detection techniques in spatial data should allow to identify two types of outliers: global and local ones. Local outliers typically have non-spatial attributes that strongly differ from those observed on their neighbors. Detecting local outliers requires to be able to work locally, on neighborhoods, in order to take into account the spatial dependence between the statistical units under consideration, even though the outlyingness is usually measured on the non-spatial variables. Many procedures have been outlined in the literature, but their number reduces when one wants to deal with multivariate non-spatial attributes. In this paper, focus is on the multivariate context. A review of existing procedures is done. A new approach, based on a two-step improvement of an existing one, is also designed and compared with the benchmarked methods by means of examples and simulations.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 371-399,spatial analysis;econometrics;data mining;statistics;mathematics;
Modeling user interests from web browsing activities,Fabio Gasparetti (Roma Tre University);,1998809194,"Browsing sessions are rich in elements useful to build profiles of user interests, but at the same time HTML pages include noisy data such as advertisements, navigation menus and privacy notes. Moreover, some pages cover several different topics making it difficult to identify the most relevant to the user. For these reasons, they are often ignored by personalized search and recommender systems. We propose a novel approach for recognizing valuable text descriptions of current user information needs--namely cues--based on the data mined from browsing interactions over the web. The approach combines page clustering techniques based on Document Object Model-based representations for acquiring evidence about relevant correlations between text contents. This evidence is exploited for better filtering out irrelevant information and facilitating the construction of interest profiles. A comparative framework proves the accuracy of the extracted cues in the personalize search task, where results are re-ranked according to the last browsed resources.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 502-547,user modeling;information needs;cluster analysis;multimedia;world wide web;information retrieval;data mining;machine learning;computer science;
Outlier detection using binary decision diagrams,Takuro Kutsuna (Toyota);Akihiro Yamamoto (Kyoto University);,"2062587687,2144601133","We propose a novel method for outlier detection using binary decision diagrams. Leave-one-out density is proposed as a new measure for detecting outliers, which is defined as a ratio of the number of data elements inside a region to the volume of the region after a focused datum is removed. We show that leave-one-out density can be evaluated very efficiently on a set of regions around each datum in a given dataset by using binary decision diagrams. The time complexity of the proposed method is nearly linear with respect to the size of the dataset, while the outlier detection accuracy is still comparable to that of other methods. Experimental results show the effectiveness of the proposed method.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 548-572,local outlier factor;binary decision diagram;anomaly detection;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Unsupervised group matching with application to cross-lingual topic matching without alignment information,Tomoharu Iwata (Nippon Telegraph and Telephone);Motonobu Kanagawa (Institute of Statistical Mathematics);Tsutomu Hirao (Nippon Telegraph and Telephone);Kenji Fukumizu (Institute of Statistical Mathematics);,"2108993706,1983772152,2144768804,167589996","We propose a method for unsupervised group matching, which is the task of finding correspondence between groups across different domains without cross-domain similarity measurements or paired data. For example, the proposed method can find matching of topic categories in different languages without alignment information. The proposed method interprets a group as a probability distribution, which enables us to handle uncertainty in a limited amount of data, and to incorporate the high order information on groups. Groups are matched by maximizing the dependence between distributions, in which we use the Hilbert Schmidt independence criterion for measuring the dependence. By using kernel embedding which maps distributions into a reproducing kernel Hilbert space, we can calculate the dependence between distributions without density estimation. In the experiments, we demonstrate the effectiveness of the proposed method using synthetic and real data sets including an application to cross-lingual topic matching.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 350-370,kernel embedding of distributions;theoretical computer science;pattern recognition;machine learning;mathematics;
Discovering rare categories from graph streams,Dawei Zhou (Arizona State University);Arun Karthikeyan (Arizona State University);Kangyang Wang (Arizona State University);Nan Cao (New York University Shanghai);Jingrui He (Arizona State University);,"2303436841,2704454788,2246428827,2101761023,2693123770","Nowadays, massive graph streams are produced from various real-world applications, such as financial fraud detection, sensor networks, wireless networks. In contrast to the high volume of data, it is usually the case that only a small percentage of nodes within the time-evolving graphs might be of interest to people. Rare category detection (RCD) is an important topic in data mining, focusing on identifying the initial examples from the rare classes in imbalanced data sets. However, most existing techniques for RCD are designed for static data sets, thus not suitable for time-evolving data. In this paper, we introduce a novel setting of RCD on time-evolving graphs. To address this problem, we propose two incremental algorithms, SIRD and BIRD, which are constructed upon existing density-based techniques for RCD. These algorithms exploit the time-evolving nature of the data by dynamically updating the detection models enabling a ""time-flexible"" RCD. Moreover, to deal with the cases where the exact priors of the minority classes are not available, we further propose a modified version named BIRD-LI based on BIRD. Besides, we also identify a critical task in RCD named query distribution, which targets to allocate the limited budget among multiple time steps, such that the initial examples from the rare classes are detected as early as possible with the minimum labeling cost. The proposed incremental RCD algorithms and various query distribution strategies are evaluated empirically on both synthetic and real data sets.",2017,Data Mining and Knowledge Discovery volume 31 issue 2 pp 400-423,data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Adjusting for Scorekeeper Bias in NBA Box Scores,Matthew van Bommel (Simon Fraser University);Luke Bornn (Simon Fraser University);,"2338891821,1253847257","Box score statistics in the National Basketball Association are used to measure and evaluate player performance. Some of these statistics are subjective in nature and since box score statistics are recorded by scorekeepers hired by the home team for each game, there exists potential for inconsistency and bias. These inconsistencies can have far reaching consequences, particularly with the rise in popularity of daily fantasy sports. Using box score data, we estimate models able to quantify both the bias and the generosity of each scorekeeper for two of the most subjective statistics: assists and blocks. We then use optical player tracking data for the 2015–2016 season to improve the assist model by including other contextual spatio-temporal variables such as time of possession, player locations, and distance traveled. From this model, we present results measuring the impact of the scorekeeper and of the other contextual variables on the probability of a pass being recorded as an assist. Results for adjusting season assist totals to remove scorekeeper influence are also presented.",2017,Data Mining and Knowledge Discovery pp 1-21,basketball;simulation;statistics;
Activity recognition in beach volleyball using a Deep Convolutional Neural Network,Thomas Kautz (University of Erlangen-Nuremberg);Benjamin H. Groh (University of Erlangen-Nuremberg);Julius Hannink (University of Erlangen-Nuremberg);Ulf Jensen (University of Erlangen-Nuremberg);Holger Strubberg (Leipzig University);Bjoern M. Eskofier (University of Erlangen-Nuremberg);,"2330351955,1984853066,2474985025,2147140904,2589152975,1265058821","Many injuries in sports are caused by overuse. These injuries are a major cause for reduced performance of professional and non-professional beach volleyball players. Monitoring of player actions could help identifying and understanding risk factors and prevent such injuries. Currently, time-consuming video examination is the only option for detailed player monitoring in beach volleyball. The lack of a reliable automatic monitoring system impedes investigations about the risk factors of overuse injuries. In this work, we present an unobtrusive automatic monitoring system for beach volleyball based on wearable sensors. We investigate the possibilities of Deep Learning in this context by designing a Deep Convolutional Neural Network for sensor-based activity classification. The performance of this new approach is compared to five common classification algorithms. With our Deep Convolutional Neural Network, we achieve a classification accuracy of 83.2%, thereby outperforming the other classification algorithms by 16.0%. Our results show that detailed player monitoring in beach volleyball using wearable sensors is feasible. The substantial performance margin between established methods and our Deep Neural Network indicates that Deep Learning has the potential to extend the boundaries of sensor-based activity recognition.",2017,Data Mining and Knowledge Discovery pp 1-28,sportscenter;deep learning;convolutional neural network;computer security;artificial intelligence;machine learning;simulation;computer science;
Micro-review synthesis for multi-entity summarization,Thanh-Son Nguyen (Singapore Management University);Hady W. Lauw (Singapore Management University);Panayiotis Tsaparas (University of Ioannina);,"2227568756,2024254804,2234654910","Location-based social networks (LBSNs), exemplified by Foursquare, are fast gaining popularity. One important feature of LBSNs is micro-review. Upon check-in at a particular venue, a user may leave a short review (up to 200 characters long), also known as a tip. These tips are an important source of information for others to know more about various aspects of an entity (e.g., restaurant), such as food, waiting time, or service. However, a user is often interested not in one particular entity, but rather in several entities collectively, for instance within a neighborhood or a category. In this paper, we address the problem of summarizing the tips of multiple entities in a collection, by way of synthesizing new micro-reviews that pertain to the collection, rather than to the individual entities per se. We formulate this problem in terms of first finding a representation of the collection, by identifying a number of “aspects” that link common threads across two or more entities within the collection. We express these aspects as dense subgraphs in a graph of sentences derived from the multi-entity corpora. This leads to a formulation of maximal multi-entity quasi-cliques, as well as a heuristic algorithm to find K such quasi-cliques maximizing the coverage over the multi-entity corpora. To synthesize a summary tip for each aspect, we select a small number of sentences from the corresponding quasi-clique, balancing conciseness and representativeness in terms of a facility location problem. Our approach performs well on collections of Foursquare entities based on localities and categories, producing more representative and diverse summaries than the baselines.",2017,Data Mining and Knowledge Discovery pp 1-29,world wide web;information retrieval;data mining;machine learning;computer science;
Generalizing DTW to the multi-dimensional case requires an adaptive approach,"Mohammad Shokoohi-Yekta (Apple Inc.);Bing Hu 0001 (Facebook);Hongxia Jin (Samsung);Jun Wang (University of Texas at Dallas);Eamonn J. Keogh (University of California, Riverside);","2585925331,2584271387,2636824514,2608497112,2170070822","In recent years Dynamic Time Warping (DTW) has emerged as the distance measure of choice for virtually all time series data mining applications. For example, virtually all applications that process data from wearable devices use DTW as a core sub-routine. This is the result of significant progress in improving DTW's efficiency, together with multiple empirical studies showing that DTW-based classifiers at least equal (and generally surpass) the accuracy of all their rivals across dozens of datasets. Thus far, most of the research has considered only the one-dimensional case, with practitioners generalizing to the multi-dimensional case in one of two ways, dependent or independent warping. In general, it appears the community believes either that the two ways are equivalent, or that the choice is irrelevant. In this work, we show that this is not the case. The two most commonly used multi-dimensional DTW methods can produce different classifications, and neither one dominates over the other. This seems to suggest that one should learn the best method for a particular application. However, we will show that this is not necessary; a simple, principled rule can be used on a case-by-case basis to predict which of the two methods we should trust at the time of classification. Our method allows us to ensure that classification results are at least as accurate as the better of the two rival methods, and, in many cases, our method is significantly more accurate. We demonstrate our ideas with the most extensive set of multi-dimensional time series classification experiments ever attempted.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 1-31,dynamic time warping;biological classification;gesture recognition;data mining;pattern recognition;machine learning;computer science;
Evidence-based uncertainty sampling for active learning,Manali Sharma (Illinois Institute of Technology);Mustafa Bilgic (Illinois Institute of Technology);,"2107515560,2010936866","Active learning methods select informative instances to effectively learn a suitable classifier. Uncertainty sampling, a frequently utilized active learning strategy, selects instances about which the model is uncertain but it does not consider the reasons for why the model is uncertain. In this article, we present an evidence-based framework that can uncover the reasons for why a model is uncertain on a given instance. Using the evidence-based framework, we discuss two reasons for uncertainty of a model: a model can be uncertain about an instance because it has strong, but conflicting evidence for both classes or it can be uncertain because it does not have enough evidence for either class. Our empirical evaluations on several real-world datasets show that distinguishing between these two types of uncertainties has a drastic impact on the learning efficiency. We further provide empirical and analytical justifications as to why distinguishing between the two uncertainties matters.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 164-202,active learning;biological classification;econometrics;data mining;machine learning;mathematics;
Reliable early classification of time series based on discriminating the classes over time,"Usue Mori (University of the Basque Country);Alexander Mendiburu (University of the Basque Country);Eamonn J. Keogh (University of California, Riverside);José Antonio Lozano (University of the Basque Country);","2143741250,2114536351,2170070822,2223079850","The goal of early classification of time series is to predict the class value of a sequence early in time, when its full length is not yet available. This problem arises naturally in many contexts where the data is collected over time and the label predictions have to be made as soon as possible. In this work, a method based on probabilistic classifiers is proposed for the problem of early classification of time series. An important feature of this method is that, in its learning stage, it discovers the timestamps in which the prediction accuracy for each class begins to surpass a pre-defined threshold. This threshold is defined as a percentage of the accuracy that would be obtained if the full series were available, and it is defined by the user. The class predictions for new time series will only be made in these timestamps or later. Furthermore, when applying the model to a new time series, a class label will only be provided if the difference between the two largest predicted class probabilities is higher than or equal to a certain threshold, which is calculated in the training step. The proposal is validated on 45 benchmark time series databases and compared with several state-of-the-art methods, and obtains superior results in both earliness and accuracy. In addition, we show the practical applicability of our method for a real-world problem: the detection and identification of bird calls in a biodiversity survey scenario.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 233-263,gaussian process;data mining;pattern recognition;machine learning;statistics;computer science;
Tensor decompositions and data fusion in epileptic EEG and fMRI data,Borbála Hunyadi (Katholieke Universiteit Leuven);Patrick Dupont (Katholieke Universiteit Leuven);Wim Van Paesschen (Katholieke Universiteit Leuven);Sabine Van Huffel (Katholieke Universiteit Leuven);,"2139725152,2149947959,316104977,1347151784",-,2017,Data Mining and Knowledge Discovery volume 7 issue 1 pp 1-15,computer science;
SimUSF: an efficient and effective similarity measure that is invariant to violations of the interval scale assumption,Thilak L. Fernando (Monash University);Geoffrey I. Webb (Monash University);,"2508090384,2126304162","Similarity measures are central to many machine learning algorithms. There are many different similarity measures, each catering for different applications and data requirements. Most similarity measures used with numerical data assume that the attributes are interval scale. In the interval scale, it is assumed that a unit difference has the same meaning irrespective of the magnitudes of the values separated. When this assumption is violated, accuracy may be reduced. Our experiments show that removing the interval scale assumption by transforming data to ranks can improve the accuracy of distance-based similarity measures on some tasks. However the rank transform has high time and storage overheads. In this paper, we introduce an efficient similarity measure which does not consider the magnitudes of inter-instance distances. We compare the new similarity measure with popular similarity measures in two applications: DBScan clustering and content based multimedia information retrieval with real world datasets and different transform functions. The results show that the proposed similarity measure provides good performance on a range of tasks and is invariant to violations of the interval scale assumption.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 264-286,cluster analysis;discrete mathematics;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Outlying property detection with numerical attributes,Fabrizio Angiulli (University of Calabria);Fabio Fassetti (University of Calabria);Giuseppe Manco (Indian Council of Agricultural Research);Luigi Palopoli (University of Calabria);,"3821842,184075056,2093732677,2294106506","The outlying property detection problem (OPDP) is the problem of discovering the properties distinguishing a given object, known in advance to be an outlier in a database, from the other database objects. This problem has been recently analyzed focusing on categorical attributes only. However, numerical attributes are very relevant and widely used in databases. Therefore, in this paper, we analyze the OPDP within a context where also numerical attributes are taken into account, which represents a relevant case left open in the literature. As major contributions, we present an efficient parameter-free algorithm to compute the measure of object exceptionality we introduce, and propose a unified framework for mining exceptional properties in the presence of both categorical and numerical attributes.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 134-163,kernel density estimation;cluster analysis;anomaly detection;data mining;pattern recognition;machine learning;computer science;mathematics;
Hierarchical evolving Dirichlet processes for modeling nonlinear evolutionary traces in temporal data,"Peng Wang (Alibaba Group);Peng Zhang (University of Technology, Sydney);Chuan Zhou (Chinese Academy of Sciences);Zhao Li (Alibaba Group);Hong Yang (MathWorks);","2717480781,2120503182,2224226654,2337134791,2615632406","Clustering analysis aims to group a set of similar data objects into the same cluster. Topic models, which belong to the soft clustering methods, are powerful tools to discover latent clusters/topics behind large data sets. Due to the dynamic nature of temporal data, clusters often exhibit complicated patterns such as birth, branch and death. However, most existing temporal clustering models assume that clusters evolve as a linear chain, and they cannot model and detect branching of clusters. In this paper, we present evolving Dirichlet processes (EDP for short) to model nonlinear evolutionary traces behind temporal data, especially for temporal text collections. In the setting of EDP, temporal collections are divided into epochs. In order to model cluster branching over time, EDP allows each cluster in an epoch to form Dirichlet processes (DP) and uses a combination of the cluster-specific DPs as the prior for cluster distributions in the next epoch. To model hierarchical temporal data, such as online document collections, we propose a new class of evolving hierarchical Dirichlet processes (EHDP for short) which extends the hierarchical Dirichlet processes (HDP) to model evolving temporal data. We design an online learning framework based on Gibbs sampling to infer the evolutionary traces of clusters over time. In experiments, we validate that EDP and EHDP can capture nonlinear evolutionary traces of clusters on both synthetic and real-world text collections and achieve better results than its peers.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 32-64,hierarchical dirichlet process;latent dirichlet allocation;data science;data mining;machine learning;statistics;computer science;
Efficient histogram dictionary learning for text/image modeling and classification,Minyoung Kim (Seoul National University of Science and Technology);,2305839646,"In dealing with text or image data, it is quite effective to represent them as histograms. In modeling histograms, although recent Bayesian topic models such as latent Dirichlet allocation and its variants are shown to be successful, they often suffer from computational overhead for inference of a large number of hidden variables. In this paper we consider a different modeling strategy of forming a dictionary of base histograms whose convex combination yields a histogram of observable text/image document. The dictionary entries are learned from data, which establishes direct/indirect association between specific topics/keywords and the base histograms. From a learned dictionary, the coding of an observed histogram can provide succinct and salient information useful for classification. One of our main contributions is that we propose a very efficient dictionary learning algorithm based on the recent Nesterov's smooth optimization technique in conjunction with analytic solution methods for quadratic minimization sub-problems. Not alone the faster theoretical convergence rate, also in real time, our algorithm is 20---30 times faster than general-purpose optimizers such as interior-point methods. In classification/annotation tasks on several text/image datasets, our approach exhibits comparable or often superior performance to existing Bayesian models, while significantly faster than their variational inference.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 203-232,data mining;pattern recognition;machine learning;computer science;
Adversarial classification using signaling games with an application to phishing detection,Nicolas Figueroa (Pontifical Catholic University of Chile);Gastón L'huillier (University of Chile);Richard Weber (University of Chile);,"2170700863,1767313800,2110790975","In adversarial classification, the interaction between classifiers and adversaries can be modeled as a game between two players. It is natural to model this interaction as a dynamic game of incomplete information, since the classifier does not know the exact intentions of the different types of adversaries (senders). For these games, equilibrium strategies can be approximated and used as input for classification models. In this paper we show how to model such interactions between players, as well as give directions on how to approximate their mixed strategies. We propose perceptron-like machine learning approximations as well as novel Adversary-Aware Online Support Vector Machines. Results in a real-world adversarial environment show that our approach is competitive with benchmark online learning algorithms, and provides important insights into the complex relations among players.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 92-133,bayesian game;support vector machine;data mining;machine learning;simulation;computer science;
"TBM, a transformation based method for microaggregation of large volume mixed data",Mostafa Salari (Tarbiat Modares University);Saeed Jalili (Tarbiat Modares University);Reza Mortazavi (Damghan University);,"2595350107,2137409053,2308374409","Due to recent advances in data collection and processing, data publishing has emerged by some organizations for scientific and commercial purposes. Published data should be anonymized such that staying useful while the privacy of data respondents is preserved. Microaggregation is a popular mechanism for data anonymization, but naturally operates on numerical datasets. However, the type of data in the real world is usually mixed i.e., there are both numeric and categorical attributes together. In this paper, we propose a novel transformation based method for microaggregation of mixed data called TBM. The method uses multidimensional scaling to generate a numeric equivalent from mixed dataset. The partitioning step of microaggregation is performed on the equivalent dataset but the aggregation step on the original data. TBM can microaggregate large mixed datasets in a short time with low information loss. Experimental results show that the proposed method attains better trade-off between data utility and privacy in a shorter time in comparison with the traditional methods.",2017,Data Mining and Knowledge Discovery volume 31 issue 1 pp 65-91,multidimensional scaling;internet privacy;data mining;database;machine learning;computer science;
Exemplar learning for extremely efficient anomaly detection in real-valued time series,Michael Jones (Massachusetts Institute of Technology);Daniel Nikovski (Mitsubishi Electric Research Laboratories);Makoto Imamura (Mitsubishi Electric);Takahisa Hirata (Mitsubishi Electric);,"2140427449,2077981624,1967323550,2136742466","We investigate algorithms for efficiently detecting anomalies in real-valued one-dimensional time series. Past work has shown that a simple brute force algorithm that uses as an anomaly score the Euclidean distance between nearest neighbors of subsequences from a testing time series and a training time series is one of the most effective anomaly detectors. We investigate a very efficient implementation of this method and show that it is still too slow for most real world applications. Next, we present a new method based on summarizing the training time series with a small set of exemplars. The exemplars we use are feature vectors that capture both the high frequency and low frequency information in sets of similar subsequences of the time series. We show that this exemplar-based method is both much faster than the efficient brute force method as well as a prediction-based method and also handles a wider range of anomalies. We compare our algorithm across a large variety of publicly available time series and encourage others to do the same. Our exemplar-based algorithm is able to process time series in minutes that would take other methods days to process.",2016,Data Mining and Knowledge Discovery volume 30 issue 6 pp 1427-1454,time series;anomaly detection;data mining;pattern recognition;machine learning;statistics;computer science;
Discovering outlying aspects in large datasets,Nguyen Xuan Vinh (University of Melbourne);Jeffrey Chan (University of Melbourne);Simone Romano (University of Melbourne);James Bailey (University of Melbourne);Christopher Leckie (University of Melbourne);Kotagiri Ramamohanarao (University of Melbourne);Jian Pei (Simon Fraser University);,"1982975784,2408228308,2165099692,2131557737,2111831791,123309386,2126330539","We address the problem of outlying aspects mining: given a query object and a reference multidimensional data set, how can we discover what aspects (i.e., subsets of features or subspaces) make the query object most outlying? Outlying aspects mining can be used to explain any data point of interest, which itself might be an inlier or outlier. In this paper, we investigate several open challenges faced by existing outlying aspects mining techniques and propose novel solutions, including (a) how to design effective scoring functions that are unbiased with respect to dimensionality and yet being computationally efficient, and (b) how to efficiently search through the exponentially large search space of all possible subspaces. We formalize the concept of dimensionality unbiasedness, a desirable property of outlyingness measures. We then characterize existing scoring measures as well as our novel proposed ones in terms of efficiency, dimensionality unbiasedness and interpretability. Finally, we evaluate the effectiveness of different methods for outlying aspects discovery and demonstrate the utility of our proposed approach on both large real and synthetic data sets.",2016,Data Mining and Knowledge Discovery volume 30 issue 6 pp 1520-1555,econometrics;data mining;statistics;mathematics;
Generalized Gini Correlation and its Application in Data-Mining,Yi Gao (Northwestern University);Wenxin Jiang (Northwestern University);Martin A. Tanner (Northwestern University);,"2704904261,2111799824,2185567839","An asymmetric correlation measure commonly used in social economics, called the Gini correlation, is defined between a numerical response and a rank. We generalize the definition of this correlation so that it can be applied to data mining. The new definition, called the generalized Gini correlation, is found to include special cases that are equivalent to common evaluation measures used in data mining, for example, the LIFT measures for a binary response and the expected profit measure for a monetary response. We consider estimation and inference regarding this generalized Gini correlation. The asymptotic distribution of the estimated correlation is derived with the help of some empirical process theory. We consider several ways of constructing confidence intervals and demonstrate their performance numerically. Our paper is interdisciplinary and makes contributions to both the Gini literature and the literature of statistical inference of performance measures in data mining.",2016,Data Mining and Knowledge Discovery volume 30 issue 6 pp 1455-1479,empirical process;asymptotic distribution;confidence interval;econometrics;mathematical optimization;statistics;mathematics;
Online route prediction based on clustering of meaningful velocity-change areas,Fernando Terroso-Saenz (University of Murcia);Mercedes Valdes-Vela (University of Murcia);Antonio F. Skarmeta-Gomez (University of Murcia);,"1758413390,1757886482,2090995024","Personal route prediction has emerged as an important topic within the mobility mining domain. In this context, many proposals apply an off-line learning process before being able to run the on-line prediction algorithm. The present work introduces a novel framework that integrates the route learning and the prediction algorithm in an on-line manner. By means of a thin-client and server architecture, it also puts forward a new concept for route abstraction based on the detection of spatial regions where certain velocity features of routes frequently change. The proposal is evaluated by real-world and synthetic datasets and compared with a well-established mechanism by exhibiting quite promising results.",2016,Data Mining and Knowledge Discovery volume 30 issue 6 pp 1480-1519,data mining;artificial intelligence;machine learning;computer science;
Tour recommendation for groups,Aris Anagnostopoulos (Sapienza University of Rome);Reem Atassi (Sapienza University of Rome);Luca Becchetti (Sapienza University of Rome);Adriano Fazzone (Sapienza University of Rome);Fabrizio Silvestri (Istituto di Scienza e Tecnologie dell'Informazione);,"2136686850,2549599010,2095497563,2019988564,2134079936","Consider a group of people who are visiting a major touristic city, such as NY, Paris, or Rome. It is reasonable to assume that each member of the group has his or her own interests or preferences about places to visit, which in general may differ from those of other members. Still, people almost always want to hang out together and so the following question naturally arises: What is the best tour that the group could perform together in the city? This problem underpins several challenges, ranging from understanding people’s expected attitudes towards potential points of interest, to modeling and providing good and viable solutions. Formulating this problem is challenging because of multiple competing objectives. For example, making the entire group as happy as possible in general conflicts with the objective that no member becomes disappointed. In this paper, we address the algorithmic implications of the above problem, by providing various formulations that take into account the overall group as well as the individual satisfaction and the length of the tour. We then study the computational complexity of these formulations, we provide effective and efficient practical algorithms, and, finally, we evaluate them on datasets constructed from real city data.",2016,Data Mining and Knowledge Discovery pp 1-32,operations research;data mining;simulation;
Locating the contagion source in networks with partial timestamps,Kai Zhu (Arizona State University);Zhen Chen (Arizona State University);Lei Ying (Arizona State University);,"2239189061,2305487824,2716770006","This paper studies the problem of identifying a single contagion source when partial timestamps of a contagion process are available. We formulate the source localization problem as a ranking problem on graphs, where infected nodes are ranked according to their likelihood of being the source. Two ranking algorithms, cost-based ranking and tree-based ranking, are proposed in this paper. Experimental evaluations with synthetic and real-world data show that our algorithms significantly improve the ranking accuracy compared with four existing algorithms.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1217-1248,world wide web;data mining;machine learning;computer science;
A distributed approach for graph mining in massive networks,Nilothpal Talukder (Rensselaer Polytechnic Institute);Mohammed J. Zaki (Rensselaer Polytechnic Institute);,"2658968731,2165917828","We propose a novel distributed algorithm for mining frequent subgraphs from a single, very large, labeled network. Our approach is the first distributed method to mine a massive input graph that is too large to fit in the memory of any individual compute node. The input graph thus has to be partitioned among the nodes, which can lead to potential false negatives. Furthermore, for scalable performance it is crucial to minimize the communication among the compute nodes. Our algorithm, DistGraph, ensures that there are no false negatives, and uses a set of optimizations and efficient collective communication operations to minimize information exchange. To our knowledge DistGraph is the first approach demonstrated to scale to graphs with over a billion vertices and edges. Scalability results on up to 2048 IBM Blue Gene/Q compute nodes, with 16 cores each, show very good speedup.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1024-1052,distance hereditary graph;strength of a graph;complement graph;graph bandwidth;graph power;graph database;random geometric graph;graph;supercomputer;theoretical computer science;distributed computing;machine learning;computer science;
An efficient exact algorithm for triangle listing in large graphs,Sofiane Lagraa (Centre national de la recherche scientifique);Hamida Seba (University of Lyon);,"1988744000,1979875134","This paper presents a new efficient exact algorithm for listing triangles in a large graph. While the problem of listing triangles in a graph has been considered before, dealing with large graphs continues to be a challenge. Although previous research has attempted to tackle the challenge, this is the first contribution that addresses this problem on a compressed copy of the input graph. In fact, the proposed solution lists the triangles without decompressing the graph. This yields interesting improvements in both storage requirement of the graphs and their time processing.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1350-1369,partial k tree;distance hereditary graph;voltage graph;indifference graph;forbidden graph characterization;coxeter graph;pancyclic graph;1 planar graph;graph operations;comparability graph;universal graph;block graph;graph product;split graph;clique width;outerplanar graph;symmetric graph;modular decomposition;pathwidth;line graph;discrete mathematics;combinatorics;mathematical optimization;mathematics;
Irrevocable-choice algorithms for sampling from a stream,"Yan Zhu 0014 (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2678804180,2170070822","The problem of sampling from data streams has attracted significant interest in the last decade. Whichever sampling criteria is considered (uniform sample, maximally diverse sample, etc.), the challenges stem from the relatively small amount of memory available in the face of unbounded streams. In this work we consider an interesting extension of this problem, the framework of which is stimulated by recent improvements in sensing technologies and robotics. In some situations it is not only possible to digitally sense some aspects of the world, but to physically capture a tangible aspect of that world. Currently deployed examples include devices that can capture water/air samples, and devices that capture individual insects or fish. Such devices create an interesting twist on the stream sampling problem, because in most cases, the decision to take a physical sample is irrevocable. In this work we show how to generalize diversification sampling strategies to the irrevocable-choice setting, demonstrating our ideas on several real world domains.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 998-1023,diversification;sampling;data mining;simulation;statistics;computer science;
Mining rooted ordered trees under subtree homeomorphism,Mostafa Haghir Chehreghani (Katholieke Universiteit Leuven);Maurice Bruynooghe (Katholieke Universiteit Leuven);,"2277421228,1275083776","Mining frequent tree patterns has many applications in different areas such as XML data, bioinformatics and World Wide Web. The crucial step in frequent pattern mining is frequency counting, which involves a matching operator to find occurrences (instances) of a tree pattern in a given collection of trees. A widely used matching operator for tree-structured data is subtree homeomorphism, where an edge in the tree pattern is mapped onto an ancestor-descendant relationship in the given tree. Tree patterns that are frequent under subtree homeomorphism are usually called embedded patterns. In this paper, we present an efficient algorithm for subtree homeomorphism with application to frequent pattern mining. We propose a compact data-structure, called occ, which stores only information about the rightmost paths of occurrences and hence can encode and represent several occurrences of a tree pattern. We then define efficient join operations on the occ data-structure, which help us count occurrences of tree patterns according to occurrences of their proper subtrees. Based on the proposed subtree homeomorphism method, we develop an effective pattern mining algorithm, called TPMiner. We evaluate the efficiency of TPMiner on several real-world and synthetic datasets. Our extensive experiments confirm that TPMiner always outperforms well-known existing algorithms, and in several cases the improvement with respect to existing algorithms is significant.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1249-1272,k ary tree;t tree;search tree;discrete mathematics;combinatorics;data mining;mathematics;
Skopus: Mining top-k sequential patterns under leverage,"Francois Petitjean (Faculty of Information Technology, University Džemal Bijedić of Mostar);Tao Li (Nanjing University of Information Science and Technology);Nikolaj Tatti (Aalto University);Geoffrey I. Webb (Faculty of Information Technology, University Džemal Bijedić of Mostar);","1966389669,2686419165,1367500519,2126304162","This paper presents a framework for exact discovery of the top-k sequential patterns under Leverage. It combines (1) a novel definition of the expected support for a sequential pattern--a concept on which most interestingness measures directly rely--with (2) Skopus: a new branch-and-bound algorithm for the exact discovery of top-k sequential patterns under a given measure of interest. Our interestingness measure employs the partition approach. A pattern is interesting to the extent that it is more frequent than can be explained by assuming independence between any of the pairs of patterns from which it can be composed. The larger the support compared to the expectation under independence, the more interesting is the pattern. We build on these two elements to exactly extract the k sequential patterns with highest leverage, consistent with our definition of expected support. We conduct experiments on both synthetic data with known patterns and real-world datasets; both experiments confirm the consistency and relevance of our approach with regard to the state of the art.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1086-1111,data science;data mining;pattern recognition;computer science;mathematics;
Exact and efficient top-K inference for multi-target prediction by querying separable linear relational models,Michiel Stock (Ghent University);Krzysztof Dembczynski (Poznań University of Technology);Bernard De Baets (Ghent University);Willem Waegeman (Ghent University);,"2099854306,1886095867,145057113,18839523","Many complex multi-target prediction problems that concern large target spaces are characterised by a need for efficient prediction strategies that avoid the computation of predictions for all targets explicitly. Examples of such problems emerge in several subfields of machine learning, such as collaborative filtering, multi-label classification, dyadic prediction and biological network inference. In this article we analyse efficient and exact algorithms for computing the top-K predictions in the above problem settings, using a general class of models that we refer to as separable linear relational models. We show how to use those inference algorithms, which are modifications of well-known information retrieval methods, in a variety of machine learning settings. Furthermore, we study the possibility of scoring items incompletely, while still retaining an exact top-K retrieval. Experimental results in several application domains reveal that the so-called threshold algorithm is very scalable, performing often many orders of magnitude more efficiently than the naive approach.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1370-1394,software framework;kernel method;system;matrix;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Top-k overlapping densest subgraphs,Esther Galbrun (French Institute for Research in Computer Science and Automation);Aristides Gionis (Helsinki Institute for Information Technology);Nikolaj Tatti (Helsinki Institute for Information Technology);,"2276244909,737311942,1367500519","Finding dense subgraphs is an important problem in graph mining and has many practical applications. At the same time, while large real-world networks are known to have many communities that are not well-separated, the majority of the existing work focuses on the problem of finding a single densest subgraph. Hence, it is natural to consider the question of finding the top-kdensest subgraphs. One major challenge in addressing this question is how to handle overlaps: eliminating overlaps completely is one option, but this may lead to extracting subgraphs not as dense as it would be possible by allowing a limited amount of overlap. Furthermore, overlaps are desirable as in most real-world graphs there are vertices that belong to more than one community, and thus, to more than one densest subgraph. In this paper we study the problem of finding top-koverlapping densest subgraphs, and we present a new approach that improves over the existing techniques, both in theory and practice. First, we reformulate the problem definition in a way that we are able to obtain an algorithm with constant-factor approximation guarantee. Our approach relies on using techniques for solving the max-sum diversification problem, which however, we need to extend in order to make them applicable to our setting. Second, we evaluate our algorithm on a collection of benchmark datasets and show that it convincingly outperforms the previous methods, both in terms of quality and efficiency.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1134-1165,social network analysis;approximation algorithm;theoretical computer science;discrete mathematics;combinatorics;mathematics;
Generalized random shapelet forests,Isak Karlsson (Stockholm University);Panagiotis Papapetrou (Stockholm University);Henrik Boström (Stockholm University);,"2123576956,2000108749,2082592554","Shapelets are discriminative subsequences of time series, usually embedded in shapelet-based decision trees. The enumeration of time series shapelets is, however, computationally costly, which in addition to the inherent difficulty of the decision tree learning algorithm to effectively handle high-dimensional data, severely limits the applicability of shapelet-based decision tree learning from large (multivariate) time series databases. This paper introduces a novel tree-based ensemble method for univariate and multivariate time series classification using shapelets, called the generalized random shapelet forest algorithm. The algorithm generates a set of shapelet-based decision trees, where both the choice of instances used for building a tree and the choice of shapelets are randomized. For univariate time series, it is demonstrated through an extensive empirical investigation that the proposed algorithm yields predictive performance comparable to the current state-of-the-art and significantly outperforms several alternative algorithms, while being at least an order of magnitude faster. Similarly for multivariate time series, it is shown that the algorithm is significantly less computationally costly and more accurate than the current state-of-the-art.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1053-1085,decision tree;ensemble learning;econometrics;data mining;machine learning;statistics;computer science;mathematics;
Scalable time series classification,Patrick Schäfer (Zuse Institute Berlin);,2308409892,"Time series classification tries to mimic the human understanding of similarity. When it comes to long or larger time series datasets, state-of-the-art classifiers reach their limits because of unreasonably high training or testing times. One representative example is the 1-nearest-neighbor dynamic time warping classifier (1-NN DTW) that is commonly used as the benchmark to compare to. It has several shortcomings: it has a quadratic time complexity in the time series length and its accuracy degenerates in the presence of noise. To reduce the computational complexity, early abandoning techniques, cascading lower bounds, or recently, a nearest centroid classifier have been introduced. Still, classification times on datasets of a few thousand time series are in the order of hours. We present our Bag-Of-SFA-Symbols in Vector Space classifier that is accurate, fast and robust to noise. We show that it is significantly more accurate than 1-NN DTW while being multiple orders of magnitude faster. Its low computational complexity combined with its good classification accuracy makes it relevant for use cases like long or large amounts of time series or real-time analytics.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1273-1298,dynamic time warping;time series;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;
Ensembles of label noise filters: a ranking approach,Luís Paulo F. Garcia (Spanish National Research Council);Ana Carolina Lorena (Federal University of São Paulo);Stan Matwin (Dalhousie University);André Carlos Ponce de Leon Ferreira de Carvalho (Spanish National Research Council);,"2147975215,2568941498,2631100416,2250248997","Label noise can be a major problem in classification tasks, since most machine learning algorithms rely on data labels in their inductive process. Thereupon, various techniques for label noise identification have been investigated in the literature. The bias of each technique defines how suitable it is for each dataset. Besides, while some techniques identify a large number of examples as noisy and have a high false positive rate, others are very restrictive and therefore not able to identify all noisy examples. This paper investigates how label noise detection can be improved by using an ensemble of noise filtering techniques. These filters, individual and ensembles, are experimentally compared. Another concern in this paper is the computational cost of ensembles, once, for a particular dataset, an individual technique can have the same predictive performance as an ensemble. In this case the individual technique should be preferred. To deal with this situation, this study also proposes the use of meta-learning to recommend, for a new dataset, the best filter. An extensive experimental evaluation of the use of individual filters, ensemble filters and meta-learning was performed using public datasets with imputed label noise. The results show that ensembles of noise filters can improve noise filtering performance and that a recommendation system based on meta-learning can successfully recommend the best filtering technique for new datasets. A case study using a real dataset from the ecological niche modeling domain is also presented and evaluated, with the results validated by an expert.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1192-1216,noise measurement;recommender system;data mining;pattern recognition;machine learning;computer science;
C-BiLDA extracting cross-lingual topics from non-parallel texts by distinguishing shared from unshared content,Geert Heyman (Katholieke Universiteit Leuven);Ivan Vulić (Katholieke Universiteit Leuven);Marie-Francine Moens (Katholieke Universiteit Leuven);,"2502903857,2028299656,1931663571","We study the problem of extracting cross-lingual topics from non-parallel multilingual text datasets with partially overlapping thematic content (e.g., aligned Wikipedia articles in two different languages). To this end, we develop a new bilingual probabilistic topic model called comparable bilingual latent Dirichlet allocation (C-BiLDA), which is able to deal with such comparable data, and, unlike the standard bilingual LDA model (BiLDA), does not assume the availability of document pairs with identical topic distributions. We present a full overview of C-BiLDA, and show its utility in the task of cross-lingual knowledge transfer for multi-class document classification on two benchmarking datasets for three language pairs. The proposed model outperforms the baseline LDA model, as well as the standard BiLDA model and two standard low-rank approximation methods (CL-LSI and CL-KCCA) used in previous work on this task.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1299-1323,feature learning;natural language processing;information retrieval;data mining;machine learning;computer science;
Bayesian Wishart matrix factorization,Cheng Luo (University of New South Wales);Xiongcai Cai (University of New South Wales);,"2709760643,2149099612",User tastes are constantly drifting over time as users are exposed to different types of products. The ability to model the tendency of both user preferences and product attractiveness is vital to the success of recommender systems (RSs). We propose a Bayesian Wishart matrix factorization method to model the temporal dynamics of variations among user preferences and item attractiveness in a novel algorithmic perspective. The proposed method is able to well model and properly control diverse rating behaviors across time frames and related temporal effects within time frames in the tendency of user preferences and item attractiveness. We evaluate the proposed method on two synthetic and three real-world benchmark datasets for RSs. Experimental results demonstrate that our proposed method significantly outperforms a variety of state-of-the-art methods in RSs.,2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1166-1191,matrix decomposition;recommender system;data mining;machine learning;simulation;computer science;mathematics;
Optimizing network robustness by edge rewiring: a general framework,Hau Chan (Stony Brook University);Leman Akoglu (Stony Brook University);,"2683434709,2288278917","Spectral measures have long been used to quantify the robustness of real-world graphs. For example, spectral radius (or the principal eigenvalue) is related to the effective spreading rates of dynamic processes (e.g., rumor, disease, information propagation) on graphs. Algebraic connectivity (or the Fiedler value), which is a lower bound on the node and edge connectivity of a graph, captures the ""partitionability"" of a graph into disjoint components. In this work we address the problem of modifying a given graph's structure under a given budget so as to maximally improve its robustness, as quantified by spectral measures. We focus on modifications based on degree-preserving edge rewiring, such that the expected load (e.g., airport flight capacity) or physical/hardware requirement (e.g., count of ISP router traffic switches) of nodes remain unchanged. Different from a vast literature of measure-independent heuristic approaches, we propose an algorithm, called EdgeRewire, which optimizes a specific measure of interest directly. Notably, EdgeRewire is general to accommodate six different spectral measures. Experiments on real-world datasets from three different domains (Internet AS-level, P2P, and airport flights graphs) show the effectiveness of our approach, where EdgeRewire produces graphs with both (i) higher robustness, and (ii) higher attack-tolerance over several state-of-the-art methods.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1395-1425,voltage graph;modular decomposition;algebraic connectivity;discrete mathematics;combinatorics;machine learning;mathematical optimization;mathematics;
Guest editors' introduction to the EcmlPkdd 2016 journal track special issue of Machine Learning,Thomas Gärtner (University of Nottingham);Mirco Nanni (Istituto di Scienza e Tecnologie dell'Informazione);Andrea Passerini (University of Trento);Céline Robardet (Institut national des sciences Appliquées de Lyon);,"2565430060,2110486381,2035962062,1976373341",-,2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 995-997,-
Using regression makes extraction of shared variation in multiple datasets easy,Jussi Korpela;Andreas Henelius;Lauri Ahonen;Arto Klami (Helsinki Institute for Information Technology);Kai Puolamäki (Aalto University);,"2690002173,134249432,2609271698,144686356,96415260","In many data analysis tasks it is important to understand the relationships between different datasets. Several methods exist for this task but many of them are limited to two datasets and linear relationships. In this paper, we propose a new efficient algorithm, termed cocoreg, for the extraction of variation common to all datasets in a given collection of arbitrary size. cocoreg extends redundancy analysis to more than two datasets, utilizing chains of regression functions to extract the shared variation in the original data space. The algorithm can be used with any linear or non-linear regression function, which makes it robust, straightforward, fast, and easy to implement and use. We empirically demonstrate the efficacy of shared variation extraction using the cocoreg algorithm on five artificial and three real datasets.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1112-1133,linear regression;data mining;machine learning;statistics;computer science;
ClusPath: a temporal-driven clustering to infer typical evolution paths,Marian-Andrei Rizoiu (NICTA);Julien Velcin (Ericsson);Stéphane Bonnevay (Ericsson);Stéphane Lallich (Ericsson);,"297821025,81361876,114919337,248929170","We propose ClusPath, a novel algorithm for detecting general evolution tendencies in a population of entities. We show how abstract notions, such as the Swedish socio-economical model (in a political dataset) or the companies fiscal optimization (in an economical dataset) can be inferred from low-level descriptive features. Such high-level regularities in the evolution of entities are detected by combining spatial and temporal features into a spatio-temporal dissimilarity measure and using semi-supervised clustering techniques. The relations between the evolution phases are modeled using a graph structure, inferred simultaneously with the partition, by using a ""slow changing world"" assumption. The idea is to ensure a smooth passage for entities along their evolution paths, which catches the long-term trends in the dataset. Additionally, we also provide a method, based on an evolutionary algorithm, to tune the parameters of ClusPath to new, unseen datasets. This method assesses the fitness of a solution using four opposed quality measures and proposes a balanced compromise.",2016,Data Mining and Knowledge Discovery volume 30 issue 5 pp 1324-1349,correlation clustering;fuzzy clustering;cluster analysis;data science;data mining;machine learning;statistics;
Visual Semantic Based 3D Video Retrieval System Using HDFS.,Kumar Cr;Suguna S;,"2580779870,2581690144",-,2016,Data Mining and Knowledge Discovery volume 10 issue 8 pp 3806,visual word;
"On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study",Guilherme O. Campos (University of São Paulo);Arthur Zimek (Ludwig Maximilian University of Munich);Jörg Sander (University of Alberta);Ricardo J. G. B. Campello (University of São Paulo);Barbora Micenková (Aarhus University);Erich Schubert (Ludwig Maximilian University of Munich);Ira Assent (Aarhus University);Michael E. Houle (National Institute of Informatics);,"2632658677,242745652,2118842476,2043417111,20146914,2011689237,145164693,2088104168","The evaluation of unsupervised outlier detection algorithms is a constant challenge in data mining research. Little is known regarding the strengths and weaknesses of different standard outlier detection models, and the impact of parameter choices for these algorithms. The scarcity of appropriate benchmark datasets with ground truth annotation is a significant impediment to the evaluation of outlier methods. Even when labeled datasets are available, their suitability for the outlier detection task is typically unknown. Furthermore, the biases of commonly-used evaluation measures are not fully understood. It is thus difficult to ascertain the extent to which newly-proposed outlier detection methods improve over established methods. In this paper, we perform an extensive experimental study on the performance of a representative set of standard k nearest neighborhood-based methods for unsupervised outlier detection, across a wide variety of datasets prepared for this purpose. Based on the overall performance of the outlier detection methods, we provide a characterization of the datasets themselves, and discuss their suitability as outlier detection benchmark sets. We also examine the most commonly-used measures for comparing the performance of different methods, and suggest adaptations that are more suitable for the evaluation of outlier detection results.",2016,Data Mining and Knowledge Discovery volume 30 issue 4 pp 891-927,measure;evaluation;data mining;pattern recognition;statistics;
Characterizing concept drift,"Geoffrey I. Webb (Faculty of Information Technology, University Džemal Bijedić of Mostar);Roy Hyde (Faculty of Information Technology, University Džemal Bijedić of Mostar);Hong Cao (Agency for Science, Technology and Research);Hai Long Nguyen;Francois Petitjean (Faculty of Information Technology, University Džemal Bijedić of Mostar);","2126304162,2550258009,2619776246,2649740057,2709762332","Most machine learning models are static, but the world is dynamic, and increasing online deployment of learned models gives increasing urgency to the development of efficient and effective mechanisms to address learning in the context of non-stationary distributions, or as it is commonly called concept drift. However, the key issue of characterizing the different types of drift that can occur has not previously been subjected to rigorous definition and analysis. In particular, while some qualitative drift categorizations have been proposed, few have been formally defined, and the quantitative descriptions required for precise and objective understanding of learner performance have not existed. We present the first comprehensive framework for quantitative analysis of drift. This supports the development of the first comprehensive set of formal definitions of types of concept drift. The formal definitions clarify ambiguities and identify gaps in previous definitions, giving rise to a new comprehensive taxonomy of concept drift types and a solid foundation for research into mechanisms to detect and address concept drift.",2016,Data Mining and Knowledge Discovery volume 30 issue 4 pp 964-994,concept drift;data mining;artificial intelligence;machine learning;computer science;
Clustering categorical data in projected spaces,Mohamed Bouguessa (Université du Québec à Montréal);,1172064443,"The problem of clustering categorical data has been widely investigated and appropriate approaches have been proposed. However, the majority of the existing methods suffer from one or more of the following limitations: (1) difficulty detecting clusters of very low dimensionality embedded in high-dimensional spaces, (2) lack of an automatic mechanism for identifying relevant dimensions for each cluster, (3) lack of an outlier detection mechanism and (4) dependence on a set of parameters that need to be properly tuned. Most of the existing approaches are inadequate for dealing with these four issues in a unified framework. This motivates our effort to propose a fully automatic projected clustering algorithm for high-dimensional categorical data which is capable of facing the four aforementioned issues in a single framework. Our algorithm comprises two phases: (1) outlier handling and (2) clustering in projected spaces. The first phase of the algorithm is based on a probabilistic approach that exploits the beta mixture model to identify and eliminate outlier objects from a data set in a systematic way. In the second phase, the clustering process is based on a novel quality function that allows the identification of projected clusters of low dimensionality embedded in a high-dimensional space without any parameter setting by the user. The suitability of our proposal is demonstrated through empirical studies using synthetic and real data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 3-38,k medians clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;
Generalization-based privacy preservation and discrimination prevention in data publishing and mining,Sara Hajian;Josep Domingo-Ferrer (Rovira i Virgili University);Oriol Farràs (Polytechnic University of Catalonia);,"2088002537,275327080,1757798271","Living in the information society facilitates the automatic collection of huge amounts of data on individuals, organizations, etc. Publishing such data for secondary analysis (e.g. learning models and finding patterns) may be extremely useful to policy makers, planners, marketing analysts, researchers and others. Yet, data publishing and mining do not come without dangers, namely privacy invasion and also potential discrimination of the individuals whose data are published. Discrimination may ensue from training data mining models (e.g. classifiers) on data which are biased against certain protected groups (ethnicity, gender, political preferences, etc.). The objective of this paper is to describe how to obtain data sets for publication that are: (i) privacy-preserving; (ii) unbiased regarding discrimination; and (iii) as useful as possible for learning models and finding patterns. We present the first generalization-based approach to simultaneously offer privacy preservation and discrimination prevention. We formally define the problem, give an optimal algorithm to tackle it and evaluate the algorithm in terms of both general and specific data analysis metrics (i.e. various types of classifiers and rule induction algorithms). It turns out that the impact of our transformation on the quality of data is the same or only slightly higher than the impact of achieving just privacy preservation. In addition, we show how to extend our approach to different privacy models and anti-discrimination legal concepts.",2014,Data Mining and Knowledge Discovery volume 28 pp 1158-1188,generalization;privacy;data science;data mining;machine learning;
A peek into the black box: exploring classifiers by randomization,Andreas Henelius;Kai Puolamäki (Aalto University);Henrik Boström (Stockholm University);Lars Asker (Stockholm University);Panagiotis Papapetrou (Stockholm University);,"134249432,96415260,2082592554,2089372118,2000108749","Classifiers are often opaque and cannot easily be inspected to gain understanding of which factors are of importance. We propose an efficient iterative algorithm to find the attributes and dependencies used by any classifier when making predictions. The performance and utility of the algorithm is demonstrated on two synthetic and 26 real-world datasets, using 15 commonly used learning algorithms to generate the classifiers. The empirical investigation shows that the novel algorithm is indeed able to find groupings of interacting attributes exploited by the different classifiers. These groupings allow for finding similarities among classifiers for a single dataset as well as for determining the extent to which different classifiers exploit such interactions in general.",2014,Data Mining and Knowledge Discovery volume 28 pp 1503-1529,cascading classifiers;random subspace method;randomization;data mining;pattern recognition;
Ontology of core data mining entities,Panče Panov;Larisa Soldatova (Brunel University London);Sašo Džeroski (University of Freiburg);,"1880876268,2037117905,1419022840","In this article, we present OntoDM-core, an ontology of core data mining entities. OntoDM-core defines the most essential data mining entities in a three-layered ontological structure comprising of a specification, an implementation and an application layer. It provides a representational framework for the description of mining structured data, and in addition provides taxonomies of datasets, data mining tasks, generalizations, data mining algorithms and constraints, based on the type of data. OntoDM-core is designed to support a wide range of applications/use cases, such as semantic annotation of data mining algorithms, datasets and results; annotation of QSAR studies in the context of drug discovery investigations; and disambiguation of terms in text mining. The ontology has been thoroughly assessed following the practices in ontology engineering, is fully interoperable with many domain resources and is easy to extend. OntoDM-core is available at http://www.ontodm.com .",2014,Data Mining and Knowledge Discovery volume 28 pp 1222-1265,molecule mining;ontology based data integration;upper ontology;ontology;biological activity;
Overlapping community detection in labeled graphs,Esther Galbrun (Boston University);Aristides Gionis (Helsinki Institute for Information Technology);Nikolaj Tatti (Helsinki Institute for Information Technology);,"2276244909,737311942,1367500519","We present a new approach for the problem of finding overlapping communities in graphs and social networks. Our approach consists of a novel problem definition and three accompanying algorithms. We are particularly interested in graphs that have labels on their vertices, although our methods are also applicable to graphs with no labels. Our goal is to find k communities so that the total edge density over all k communities is maximized. In the case of labeled graphs, we require that each community is succinctly described by a set of labels. This requirement provides a better understanding for the discovered communities. The proposed problem formulation leads to the discovery of vertex-overlapping and dense communities that cover as many graph edges as possible. We capture these properties with a simple objective function, which we solve by adapting efficient approximation algorithms for the generalized maximum-coverage problem and the densest-subgraph problem. Our proposed algorithm is a generic greedy scheme. We experiment with three variants of the scheme, obtained by varying the greedy step of finding a dense subgraph. We validate our algorithms by comparing with other state-of-the-art community-detection methods on a variety of performance measures. Our experiments confirm that our algorithms achieve results of high quality in terms of the reported measures, and are practical in terms of performance.",2014,Data Mining and Knowledge Discovery volume 28 issue 5 pp 1586-1610,indifference graph;maximal independent set;longest path problem;independent set;graph partition;
Unsupervised interaction-preserving discretization of multivariate data,Hoang Vu Nguyen (Karlsruhe Institute of Technology);Emmanuel Müller (Karlsruhe Institute of Technology);Jilles Vreeken (Max Planck Society);Klemens Böhm (Karlsruhe Institute of Technology);,"2150437310,2112493600,1971070670,2245547659","Discretization is the transformation of continuous data into discrete bins. It is an important and general pre-processing technique, and a critical element of many data mining and data management tasks. The general goal is to obtain data that retains as much information in the continuous original as possible. In general, but in particular for exploratory tasks, a key open question is how to discretize multivariate data such that significant associations and patterns are preserved. That is exactly the problem we study in this paper. We propose IPD, an information-theoretic method for unsupervised discretization that focuses on preserving multivariate interactions. To this end, when discretizing a dimension, we consider the distribution of the data over all other dimensions. In particular, our method examines consecutive multivariate regions and combines them if (a) their multivariate data distributions are statistically similar, and (b) this merge reduces the MDL encoding cost. To assess the similarities, we propose $$ ID $$ I D , a novel interaction distance that does not require assuming a distribution and permits computation in closed form. We give an efficient algorithm for finding the optimal bin merge, as well as a fast well-performing heuristic. Empirical evaluation through pattern-based compression, outlier mining, and classification shows that by preserving interactions we consistently outperform the state of the art in both quality and speed.",2014,Data Mining and Knowledge Discovery volume 28 pp 1366-1397,discretization;biological classification;data mining;pattern recognition;machine learning;
Approximating the crowd,Şeyda Ertekin (Massachusetts Institute of Technology);Cynthia Rudin (Massachusetts Institute of Technology);Haym Hirsh (Cornell University);,"2155137863,2141705163,2151078108","The problem of ""approximating the crowd"" is that of estimating the crowd's majority opinion by querying only a subset of it. Algorithms that approximate the crowd can intelligently stretch a limited budget for a crowdsourcing task. We present an algorithm, ""CrowdSense,"" that works in an online fashion where items come one at a time. CrowdSense dynamically samples subsets of the crowd based on an exploration/exploitation criterion. The algorithm produces a weighted combination of the subset's votes that approximates the crowd's opinion. We then introduce two variations of CrowdSense that make various distributional approximations to handle distinct crowd characteristics. In particular, the first algorithm makes a statistical independence approximation of the labelers for large crowds, whereas the second algorithm finds a lower bound on how often the current subcrowd agrees with the crowd's majority vote. Our experiments on CrowdSense and several baselines demonstrate that we can reliably approximate the entire crowd's vote by collecting opinions from a representative subset of the crowd.",2014,Data Mining and Knowledge Discovery volume 28 pp 1189-1221,crowdsourcing;internet privacy;data mining;machine learning;simulation;
Self-organizing maps by difference of convex functions optimization,Hoai An Le Thi (University of Lorraine);Manh Cuong Nguyen (University of Lorraine);,"2214160777,2160958807","We offer an efficient approach based on difference of convex functions (DC) optimization for self-organizing maps (SOM). We consider SOM as an optimization problem with a nonsmooth, nonconvex energy function and investigated DC programming and DC algorithm (DCA), an innovative approach in nonconvex optimization framework to effectively solve this problem. Furthermore an appropriate training version of this algorithm is proposed. The numerical results on many real-world datasets show the efficiency of the proposed DCA based algorithms on both quality of solutions and topographic maps.",2014,Data Mining and Knowledge Discovery volume 28 issue 28 pp 1336-1365,self organizing map;artificial intelligence;machine learning;mathematical optimization;computer science;
Active exploration for large graphs,Meng Fang (Information Technology University);Jie Yin (Commonwealth Scientific and Industrial Research Organisation);Xingquan Zhu (Florida Atlantic University);,"2152013896,2150861151,2618356905","Modern information networks, such as social networks, communication networks, and citation networks, are often characterized by very large sizes and dynamically changing structures. Common solutions to graph mining tasks (e.g., node classification) usually employ an unrestricted sampling-then-mining paradigm to reduce a large network to a manageable size, followed by subsequent mining tasks. However, real-world networks may be unaccessible at once and must be crawled progressively. This can be due to the fact that the size of the network is too large, or some privacy/legal concerns. In this paper, we propose an Active Exploration framework for large graphs, where the goal is to simultaneously carry out network sampling and node labeling in order to build a sampled network from which the trained classifier can have the maximum node classification accuracy. To achieve this goal, we consider a network as a Markov chain and compute the stationary distribution of the nodes by deriving supervised random walks. The stationary distribution helps identify specific nodes to be sampled in the next step, and the labeling process labels the most informative node which in turn strengthens the sampling of the network. To improve the scalability of active exploration for large graphs, we also propose a more efficient multi-seed algorithm that simultaneously runs multiple, parallel exploration processes, and makes joint decisions to determine which nodes are to be sampled and labeled next. The simultaneous, mutually enhanced sampling and labeling processes ensure that the final sampled network contains a maximum number of nodes directly related to the underlying mining tasks. Experiments on both synthetic and real-world networks demonstrate that our active exploration algorithms have much better chance to include target nodes in the sampled networks than baseline methods.",2016,Data Mining and Knowledge Discovery volume 30 issue 3 pp 511-549,evolving networks;active learning;random walk;distributed computing;data mining;machine learning;statistics;computer science;
MINAS: multiclass learning algorithm for novelty detection in data streams,Elaine Ribeiro de Faria (University of São Paulo);André Carlos Ponce de Leon Ferreira de Carvalho (Institute of Mathematics);João Gama (University of Porto);,"2144338799,2250248997,2113857198","Data stream mining is an emergent research area that aims at extracting knowledge from large amounts of continuously generated data. Novelty detection (ND) is a classification task that assesses if one or a set of examples differ significantly from the previously seen examples. This is an important task for data stream, as new concepts may appear, disappear or evolve over time. Most of the works found in the ND literature presents it as a binary classification task. In several data stream real life problems, ND must be treated as a multiclass task, in which, the known concept is composed by one or more classes and different new classes may appear. This work proposes MINAS, an algorithm for ND in data streams. MINAS deals with ND as a multiclass task. In the initial training phase, MINAS builds a decision model based on a labeled data set. In the online phase, new examples are classified using this model, or marked as unknown. Groups of unknown examples can be used later to create valid novelty patterns (NP), which are added to the current model. The decision model is updated as new data come over the stream in order to reflect changes in the known classes and allow the addition of NP. This work also presents a set of experiments carried out comparing MINAS and the main novelty detection algorithms found in the literature, using artificial and real data sets. The experimental results show the potential of the proposed algorithm.",2016,Data Mining and Knowledge Discovery volume 30 issue 3 pp 640-680,multiclass classification;data stream mining;data mining;pattern recognition;machine learning;computer science;
Parameter learning in hybrid Bayesian networks using prior knowledge,Inmaculada Pérez-Bernabé (University of Almería);Antonio Fernández (University of Almería);Rafael Rumí (University of Almería);Antonio Salmerón (University of Almería);,"111539308,2143909263,1625462692,2112611937","Mixtures of truncated basis functions have been recently proposed as a generalisation of mixtures of truncated exponentials and mixtures of polynomials for modelling univariate and conditional distributions in hybrid Bayesian networks. In this paper we analyse the problem of learning the parameters of marginal and conditional MoTBF densities when both prior knowledge and data are available. Incorporating prior knowledge provide a valuable tool for obtaining useful models, especially in domains of applications where data are costly or scarce, and prior knowledge is available from practitioners. We explore scenarios where the prior knowledge can be expressed as an MoTBF density that is afterwards combined with another MoTBF density estimated from the available data. The resulting model remains within the MoTBF class which is a convenient property from the point of view of inference in hybrid Bayesian networks. The performance of the proposed method is tested in a series of experiments carried out over synthetic and real data.",2016,Data Mining and Knowledge Discovery volume 30 issue 3 pp 576-604,econometrics;data mining;machine learning;statistics;mathematics;
Enhancing aggregation phase of microaggregation methods for interval disclosure risk minimization,Reza Mortazavi (Damghan University);Saeed Jalili (Tarbiat Modares University);,"2308374409,2137409053","Microaggregation is a masking mechanism to protect confidential data in a public release. This technique can produce a k-anonymous dataset where data records are partitioned into groups of at least k members. In each group, a representative centroid is computed by aggregating the group members and is published instead of the original records. In a conventional microaggregation algorithm, the centroids are computed based on simple arithmetic mean of group members. This naive formulation does not consider the proximity of the published values to the original ones, so an intruder may be able to guess the original values. This paper proposes a disclosure-aware aggregation model, where published values are computed in a given distance from the original ones to attain a more protected and useful published dataset. Empirical results show the superiority of the proposed method in achieving a better trade-off point between disclosure risk and information loss in comparison with other similar anonymization techniques.",2016,Data Mining and Knowledge Discovery volume 30 issue 3 pp 605-639,anonymity;information privacy;internet privacy;computer security;data mining;computer science;
General factorization framework for context-aware recommendations,Balázs Hidasi (Budapest University of Technology and Economics);Domonkos Tikk (Óbuda University);,"1950878799,165729861","Context-aware recommendation algorithms focus on refining recommendations by considering additional information, available to the system. This topic has gained a lot of attention recently. Among others, several factorization methods were proposed to solve the problem, although most of them assume explicit feedback which strongly limits their real-world applicability. While these algorithms apply various loss functions and optimization strategies, the preference modeling under context is less explored due to the lack of tools allowing for easy experimentation with various models. As context dimensions are introduced beyond users and items, the space of possible preference models and the importance of proper modeling largely increases. In this paper we propose a general factorization framework (GFF), a single flexible algorithm that takes the preference model as an input and computes latent feature matrices for the input dimensions. GFF allows us to easily experiment with various linear models on any context-aware recommendation task, be it explicit or implicit feedback based. The scaling properties makes it usable under real life circumstances as well. We demonstrate the framework's potential by exploring various preference models on a 4-dimensional context-aware problem with contexts that are available for almost any real life datasets. We show in our experiments--performed on five real life, implicit feedback datasets--that proper preference modelling significantly increases recommendation accuracy, and previously unused models outperform the traditional ones. Novel models in GFF also outperform state-of-the-art factorization algorithms. We also extend the method to be fully compliant to the Multidimensional Dataspace Model, one of the most extensive data models of context-enriched data. Extended GFF allows the seamless incorporation of information into the factorization framework beyond context, like item metadata, social networks, session information, etc. Preliminary experiments show great potential of this capability.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 342-371,collaborative filtering;factorization;recommender system;theoretical computer science;data mining;machine learning;computer science;
Efficient temporal mining of micro-blog texts and its application to event discovery,Giovanni Stilo (Sapienza University of Rome);Paola Velardi (Sapienza University of Rome);,"2053318314,299152467","In this paper we present a novel method for clustering words in micro-blogs, based on the similarity of the related temporal series. Our technique, named SAX*, uses the Symbolic Aggregate ApproXimation algorithm to discretize the temporal series of terms into a small set of levels, leading to a string for each. We then define a subset of ""interesting"" strings, i.e. those representing patterns of collective attention. Sliding temporal windows are used to detect co-occurring clusters of tokens with the same or similar string. To assess the performance of the method we first tune the model parameters on a 2-month 1 % Twitter stream, during which a number of world-wide events of differing type and duration (sports, politics, disasters, health, and celebrities) occurred. Then, we evaluate the quality of all discovered events in a 1-year stream, ""googling"" with the most frequent cluster n-grams and manually assessing how many clusters correspond to published news in the same temporal slot. Finally, we perform a complexity evaluation and we compare SAX* with three alternative methods for event discovery. Our evaluation shows that SAX* is at least one order of magnitude less complex than other temporal and non-temporal approaches to micro-blog clustering.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 372-402,data science;world wide web;data mining;machine learning;computer science;
Fast approximation of betweenness centrality through sampling,Matteo Riondato (Brown University);Evgenios M. Kornaropoulos (Brown University);,"1555209364,1644594112","Betweenness centrality is a fundamental measure in social network analysis, expressing the importance or influence of individual vertices (or edges) in a network in terms of the fraction of shortest paths that pass through them. Since exact computation in large networks is prohibitively expensive, we present two efficient randomized algorithms for betweenness estimation. The algorithms are based on random sampling of shortest paths and offer probabilistic guarantees on the quality of the approximation. The first algorithm estimates the betweenness of all vertices (or edges): all approximate values are within an additive factor $$\varepsilon \in (0,1)$$??(0,1) from the real values, with probability at least $$1-\delta $$1-?. The second algorithm focuses on the top-K vertices (or edges) with highest betweenness and estimate their betweenness value to within a multiplicative factor $$\varepsilon $$?, with probability at least $$1-\delta $$1-?. This is the first algorithm that can compute such approximation for the top-K vertices (or edges). By proving upper and lower bounds to the VC-dimension of a range set associated with the problem at hand, we can bound the sample size needed to achieve the desired approximations. We obtain sample sizes that are independent from the number of vertices in the network and only depend on a characteristic quantity that we call the vertex-diameter, that is the maximum number of vertices in a shortest path. In some cases, the sample size is completely independent from any quantitative property of the graph. An extensive experimental evaluation on real and artificial networks shows that our algorithms are significantly faster and much more scalable as the number of vertices grows than other algorithms with similar approximation guarantees.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 438-475,distance;betweenness centrality;social network analysis;vc dimension;sampling;approximation algorithm;discrete mathematics;combinatorics;machine learning;mathematical optimization;statistics;computer science;mathematics;
Using dynamic time warping distances as features for improved time series classification,Rohit J. Kate (University of Wisconsin–Milwaukee);,2102852419,"Dynamic time warping (DTW) has proven itself to be an exceptionally strong distance measure for time series. DTW in combination with one-nearest neighbor, one of the simplest machine learning methods, has been difficult to convincingly outperform on the time series classification task. In this paper, we present a simple technique for time series classification that exploits DTW's strength on this task. But instead of directly using DTW as a distance measure to find nearest neighbors, the technique uses DTW to create new features which are then given to a standard machine learning method. We experimentally show that our technique improves over one-nearest neighbor DTW on 31 out of 47 UCR time series benchmark datasets. In addition, this method can be easily extended to be used in combination with other methods. In particular, we show that when combined with the symbolic aggregate approximation (SAX) method, it improves over it on 37 out of 47 UCR datasets. Thus the proposed method also provides a mechanism to combine distance-based methods like DTW with feature-based methods like SAX. We also show that combining the proposed classifiers through ensembles further improves the performance on time series classification.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 283-312,dynamic time warping;speech recognition;pattern recognition;machine learning;computer science;
Time series representation and similarity based on local autopatterns,Mustafa Gokce Baydogan (Boğaziçi University);George C. Runger (Arizona State University);,"2071505279,2005957266","Time series data mining has received much greater interest along with the increase in temporal data sets from different domains such as medicine, finance, multimedia, etc. Representations are important to reduce dimensionality and generate useful similarity measures. High-level representations such as Fourier transforms, wavelets, piecewise polynomial models, etc., were considered previously. Recently, autoregressive kernels were introduced to reflect the similarity of the time series. We introduce a novel approach to model the dependency structure in time series that generalizes the concept of autoregression to local autopatterns. Our approach generates a pattern-based representation along with a similarity measure called learned pattern similarity (LPS). A tree-based ensemble-learning strategy that is fast and insensitive to parameter settings is the basis for the approach. Then, a robust similarity measure based on the learned patterns is presented. This unsupervised approach to represent and measure the similarity between time series generally applies to a number of data mining tasks (e.g., clustering, anomaly detection, classification). Furthermore, an embedded learning of the representation avoids pre-defined features and an extraction step which is common in some feature-based approaches. The method generalizes in a straightforward manner to multivariate time series. The effectiveness of LPS is evaluated on time series classification problems from various domains. We compare LPS to eleven well-known similarity measures. Our experimental results show that LPS provides fast and competitive results on benchmark datasets from several domains. Furthermore, LPS provides a research direction and template approach that breaks from the linear dependency models to potentially foster other promising nonlinear approaches.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 476-509,similarity;autoregressive model;decision tree;time series;data mining;pattern recognition;machine learning;statistics;mathematics;
Instance-level accuracy versus bag-level accuracy in multi-instance learning,Gitte Vanwinckelen (Katholieke Universiteit Leuven);Vinicius Tragante do O;Daan Fierens (Katholieke Universiteit Leuven);Hendrik Blockeel (Katholieke Universiteit Leuven);,"2273700918,2689093362,256756514,2049189351","In multi-instance learning, instances are organized into bags, and a bag is labeled positive if it contains at least one positive instance, and negative otherwise; the labels of the individual instances are not given. The task is to learn a classifier from this limited information. While the original task description involved learning an instance classifier, in the literature the task is often interpreted as learning a bag classifier. Depending on which of these two interpretations is used, it is more natural to evaluate classifiers according to how well they predict, respectively, instance labels or bag labels. In the literature, however, the two interpretations are often mixed, or the intended interpretation is left implicit. In this paper, we investigate the difference between bag-level and instance-level accuracy, both analytically and empirically. We show that there is a substantial difference between these two, and better performance on one does not necessarily imply better performance on the other. It is therefore useful to clearly distinguish the two settings, and always use the evaluation criterion most relevant for the task at hand. We show experimentally that the same conclusions hold for area under the ROC curve.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 313-341,stability;accuracy and precision;evaluation;biological classification;instance based learning;data mining;pattern recognition;machine learning;statistics;computer science;
Classification of streaming time series under more realistic assumptions,"Bing Hu 0001 (University of California, Riverside);Yanping Chen 0005 (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2105942667,2472401419,2170070822","Much of the vast literature on time series classification makes several assumptions about data and the algorithm's eventual deployment that are almost certainly unwarranted. For example, many research efforts assume that the beginning and ending points of the pattern of interest can be correctly identified, during both the training phase and later deployment. Another example is the common assumption that queries will be made at a constant rate that is known ahead of time, thus computational resources can be exactly budgeted. In this work, we argue that these assumptions are unjustified, and this has in many cases led to unwarranted optimism about the performance of the proposed algorithms. As we shall show, the task of correctly extracting individual gait cycles, heartbeats, gestures, behaviors, etc., is generally much more difficult than the task of actually classifying those patterns. Likewise, gesture classification systems deployed on a device such as Google Glass may issue queries at frequencies that range over an order of magnitude, making it difficult to plan computational resources. We propose to mitigate these problems by introducing an alignment-free time series classification framework. The framework requires only very weakly annotated data, such as ""in this ten minutes of data, we see mostly normal heartbeats$$\ldots $$?,"" and by generalizing the classic machine learning idea of data editing to streaming/continuous data, allows us to build robust, fast and accurate anytime classifiers. We demonstrate on several diverse real-world problems that beyond removing unwarranted assumptions and requiring essentially no human intervention, our framework is both extremely fast and significantly more accurate than current state-of-the-art approaches.",2016,Data Mining and Knowledge Discovery volume 30 issue 2 pp 403-437,data dictionary;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Exceptional Model Mining,Wouter Duivesteijn (Leiden University);Adrianus Feelders (Utrecht University);Arno Knobbe (Leiden University);,"134040164,2240805150,1229146049","Finding subsets of a dataset that somehow deviate from the norm, i.e. where something interesting is going on, is a classical Data Mining task. In traditional local pattern mining methods, such deviations are measured in terms of a relatively high occurrence (frequent itemset mining), or an unusual distribution for one designated target attribute (common use of subgroup discovery). These, however, do not encompass all forms of ""interesting"". To capture a more general notion of interestingness in subsets of a dataset, we develop Exceptional Model Mining (EMM). This is a supervised local pattern mining framework, where several target attributes are selected, and a model over these targets is chosen to be the target concept. Then, we strive to find subgroups: subsets of the dataset that can be described by a few conditions on single attributes. Such subgroups are deemed interesting when the model over the targets on the subgroup is substantially different from the model on the whole dataset. For instance, we can find subgroups where two target attributes have an unusual correlation, a classifier has a deviating predictive performance, or a Bayesian network fitted on several target attributes has an exceptional structure. We give an algorithmic solution for the EMM framework, and analyze its computational complexity. We also discuss some illustrative applications of EMM instances, including using the Bayesian network model to identify meteorological conditions under which food chains are displaced, and using a regression model to find the subset of households in the Chinese province of Hunan that do not follow the general economic law of demand.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 47-98,regression;knowledge;data science;data mining;machine learning;computer science;
In Press) Discovering outlying aspects in large datasets,N Vinh (University of Melbourne);J Chan (RMIT University);S Romano (University of Melbourne);J Bailey (University of Melbourne);C Leckie (University of Melbourne);R Kotagiri;J Pei (Simon Fraser University);,"1982975784,2408228308,2165099692,2131557737,2111831791,2664403833,2126330539","We address the problem of outlying aspects mining: given a query object and a reference multidimensional data set, how can we discover what aspects (i.e., subsets of features or subspaces) make the query object most outlying? Outlying aspects mining can be used to explain any data point of interest, which itself might be an inlier or outlier. In this paper, we investigate several open challenges faced by existing outlying aspects mining techniques and propose novel solutions, including (a) how to design effective scoring functions that are unbiased with respect to dimensionality and yet being computationally efficient, and (b) how to efficiently search through the exponentially large search space of all possible subspaces. We formalize the concept of dimensionality unbiasedness, a desirable property of outlyingness measures. We then characterize existing scoring measures as well as our novel proposed ones in terms of efficiency, dimensionality unbiasedness and interpretability. Finally, we evaluate the effectiveness of different methods for outlying aspects discovery and demonstrate the utility of our proposed approach on both large real and synthetic data sets.",2016,Data Mining and Knowledge Discovery pp 1-36,econometrics;data mining;machine learning;statistics;mathematics;
A computational approach inspired by simulated annealing to study the stability of protein interaction networks in cancer and neurological disorders,Kristina Ibáñez (Complutense University of Madrid);María Guijarro (Complutense University of Madrid);Gonzalo Pajares (Complutense University of Madrid);Alfonso Valencia (City National Bank);,"2549355154,2120669322,2097298626,2524334304","Molecular networks provide a powerful tool for the study of biomedical systems, in particular several studies have detected alterations of the network structure associated to disease states. Here we propose that diseases cannot only alter the structure of the network but also its stability. To evaluate network stability we have developed a new methodological framework. Our approach is an adaptation of the classical Deterministic Simulated Annealing algorithm to work with discrete states. Adjusted energy values are used to compare the network stability in disease and control states. The results show that cancer networks are less stable than the Alzheimer's disease (AD) ones. These results can be interpreted in terms of our previous observations on cancer and AD inverse comorbidity, i.e. AD patients have lower than expected risk to suffer cancer.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 226-242,cancer;simulated annealing;gene expression;systems biology;bioinformatics;artificial intelligence;simulation;computer science;
Link prediction using time series of neighborhood-based node similarity scores,İsmail Güneş (Istanbul Technical University);Şule Gündüz-Öğüdücü (Istanbul Technical University);Zehra Çataltepe (Istanbul Technical University);,"2409802969,1568753271,2072118064","We propose a link prediction method for evolving networks. Our method first computes a number of different node similarity scores (e.g. Common Neighbor, Preferential Attachment, Adamic---Adar, Jaccard) and their weighted versions, for different past time periods. In order to predict the future node similarity scores, a powerful time series forecasting model, ARIMA, based on these past node similarity scores is used. This time series forecasting based approach enables link prediction based on modeling of the change of past node similarities and also external factors. The proposed link prediction method can be used for evolving networks and prediction of new or recurring links. We evaluate the link prediction performances of our proposed method and the previously proposed time series and similarity based link prediction methods under different circumstances by means of different AUC measures. We show that, the link prediction method proposed in this article results in a better performance than the previous methods.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 147-180,evolving networks;social network;time series;data mining;artificial intelligence;machine learning;statistics;mathematics;
Sampling frequent and minimal boolean patterns: theory and application in classification,Geng Li (Rensselaer Polytechnic Institute);Mohammed J. Zaki (Rensselaer Polytechnic Institute);,"2123276876,2165917828","We tackle the challenging problem of mining the simplest Boolean patterns from categorical datasets. Instead of complete enumeration, which is typically infeasible for this class of patterns, we develop effective sampling methods to extract a representative subset of the minimal Boolean patterns in disjunctive normal form (DNF). We propose a novel theoretical characterization of the minimal DNF expressions, which allows us to prune the pattern search space effectively. Our approach can provide a near-uniform sample of the minimal DNF patterns. We perform an extensive set of experiments to demonstrate the effectiveness of our sampling method. We also show that minimal DNF patterns make effective features for classification.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 181-225,markov chain monte carlo;biological classification;discrete mathematics;combinatorics;statistics;algorithm;mathematics;
Accelerating the discovery of unsupervised-shapelets,"Jesin Zakaria (University of California, Riverside);Abdullah Mueen (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);Neal E. Young (University of California, Riverside);","2129110089,2083987245,2170070822,1964247219","Over the past decade, time series clustering has become an increasingly important research topic in data mining community. Most existing methods for time series clustering rely on distances calculated from the entire raw data using the Euclidean distance or Dynamic Time Warping distance as the distance measure. However, the presence of significant noise, dropouts, or extraneous data can greatly limit the accuracy of clustering in this domain. Moreover, for most real world problems, we cannot expect objects from the same class to be equal in length. As a consequence, most work on time series clustering only considers the clustering of individual time series ""behaviors,"" e.g., individual heart beats or individual gait cycles, and contrives the time series in some way to make them all equal in length. However, automatically formatting the data in such a way is often a harder problem than the clustering itself. In this work, we show that by using only some local patterns and deliberately ignoring the rest of the data, we can mitigate the above problems and cluster time series of different lengths, e.g., cluster one heartbeat with multiple heartbeats. To achieve this, we exploit and extend a recently introduced concept in time series data mining called shapelets. Unlike existing work, our work demonstrates the unintuitive fact that shapelets can be learned from unlabeled time series. We show, with extensive empirical evaluation in diverse domains, that our method is more accurate than existing methods. Moreover, in addition to accurate clustering results, we show that our work also has the potential to give insight into the domains to which it is applied. While a brute-force algorithm to discover shapelets in an unsupervised way could be untenably slow, we introduce two novel optimization procedures to significantly speed up the unsupervised-shapelet discovery process and allow it to be cast as an anytime algorithm.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 243-281,canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;cluster analysis;time series;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Decomposition-by-normalization (DBN): leveraging approximate functional dependencies for efficient CP and tucker decompositions,Mijung Kim (Arizona State University);K. Selçuk Candan (Arizona State University);,"2129489018,674992784","For many multi-dimensional data applications, tensor operations as well as relational operations both need to be supported throughout the data lifecycle. Tensor based representations (including two widely used tensor decompositions, CP and Tucker decompositions) are proven to be effective in multi-aspect data analysis and tensor decomposition is an important tool for capturing high-order structures in multi-dimensional data. Although tensor decomposition is shown to be effective for multi-dimensional data analysis, the cost of tensor decomposition is often very high. Since the number of modes of the tensor data is one of the main factors contributing to the costs of the tensor operations, in this paper, we focus on reducing the modality of the input tensors to tackle the computational cost of the tensor decomposition process. We propose a novel decomposition-by-normalization scheme that first normalizes the given relation into smaller tensors based on the functional dependencies of the relation, decomposes these smaller tensors, and then recombines the sub-results to obtain the overall decomposition. The decomposition and recombination steps of the decomposition-by-normalization scheme fit naturally in settings with multiple cores. This leads to a highly efficient, effective, and parallelized decomposition-by-normalization algorithm for both dense and sparse tensors for CP and Tucker decompositions. Experimental results confirm the efficiency and effectiveness of the proposed decomposition-by-normalization scheme compared to the conventional nonnegative CP decomposition and Tucker decomposition approaches.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 1-46,multilinear subspace learning;tucker decomposition;discrete mathematics;combinatorics;mathematical optimization;statistics;mathematics;
On detecting maximal quasi antagonistic communities in signed graphs,Ming Gao (East China Normal University);Ee-Peng Lim (Singapore Management University);David Lo (Singapore Management University);Philips Kokoh Prasetyo (Singapore Management University);,"2233450724,2130308643,2132927693,2106800246","Many networks can be modeled as signed graphs. These include social networks, and relationships/interactions networks. Detecting sub-structures in such networks helps us understand user behavior, predict links, and recommend products. In this paper, we detect dense sub-structures from a signed graph, called quasi antagonistic communities (QACs). An antagonistic community consists of two groups of users expressing positive relationships within each group but negative relationships across groups. Instead of requiring complete set of negative links across its groups, a QAC allows a small number of inter-group negative links to be missing. We propose an algorithm, Mascot, to find all maximal quasi antagonistic communities (MQACs). Mascot consists of two stages: pruning and enumeration stages. Based on the properties of QAC, we propose four pruning rules to reduce the size of candidate graphs in the pruning stage. We use an enumeration tree to enumerate all strongly connected subgraphs in a top---down fashion in the second stage before they are used to construct MQACs. We have conducted extensive experiments using synthetic signed graphs and two real networks to demonstrate the efficiency and accuracy of the Mascot algorithm. We have also found that detecting MQACs helps us to predict the signs of links.",2016,Data Mining and Knowledge Discovery volume 30 issue 1 pp 99-146,pareto distribution;discrete mathematics;combinatorics;machine learning;statistics;mathematics;
Discrimination- and privacy-aware patterns,Sara Hajian;Josep Domingo-Ferrer (Rovira i Virgili University);Anna Monreale (University of Pisa);Dino Pedreschi (University of Pisa);Fosca Giannotti (Istituto di Scienza e Tecnologie dell'Informazione);,"2088002537,275327080,22253233,7769909,1205765909","Data mining is gaining societal momentum due to the ever increasing availability of large amounts of human data, easily collected by a variety of sensing technologies. We are therefore faced with unprecedented opportunities and risks: a deeper understanding of human behavior and how our society works is darkened by a greater chance of privacy intrusion and unfair discrimination based on the extracted patterns and profiles. Consider the case when a set of patterns extracted from the personal data of a population of individual persons is released for a subsequent use into a decision making process, such as, e.g., granting or denying credit. First, the set of patterns may reveal sensitive information about individual persons in the training population and, second, decision rules based on such patterns may lead to unfair discrimination, depending on what is represented in the training cases. Although methods independently addressing privacy or discrimination in data mining have been proposed in the literature, in this context we argue that privacy and discrimination risks should be tackled together, and we present a methodology for doing so while publishing frequent pattern mining results. We describe a set of pattern sanitization methods, one for each discrimination measure used in the legal literature, to achieve a fair publishing of frequent patterns in combination with two possible privacy transformations: one based on $$k$$k-anonymity and one based on differential privacy. Our proposed pattern sanitization methods based on $$k$$k-anonymity yield both privacy- and discrimination-protected patterns, while introducing reasonable (controlled) pattern distortion. Moreover, they obtain a better trade-off between protection and data quality than the sanitization methods based on differential privacy. Finally, the effectiveness of our proposals is assessed by extensive experiments.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1733-1782,privacy;internet privacy;computer security;data mining;computer science;
The BOSS is concerned with time series classification in the presence of noise,Patrick Schäfer (Zuse Institute Berlin);,2308409892,"Similarity search is one of the most important and probably best studied methods for data mining. In the context of time series analysis it reaches its limits when it comes to mining raw datasets. The raw time series data may be recorded at variable lengths, be noisy, or are composed of repetitive substructures. These build a foundation for state of the art search algorithms. However, noise has been paid surprisingly little attention to and is assumed to be filtered as part of a preprocessing step carried out by a human. Our Bag-of-SFA-Symbols (BOSS) model combines the extraction of substructures with the tolerance to extraneous and erroneous data using a noise reducing representation of the time series. We show that our BOSS ensemble classifier improves the best published classification accuracies in diverse application areas and on the official UCR classification benchmark datasets by a large margin.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1505-1530,similarity;noise;time series;fourier transform;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;
Learning sequential classifiers from long and noisy discrete-event sequences efficiently,Gessé Dafé (Universidade Federal de Minas Gerais);Adriano Veloso (Universidade Federal de Minas Gerais);Mohammed J. Zaki (Rensselaer Polytechnic Institute);Wagner Meira (Universidade Federal de Minas Gerais);,"2485923365,2158169143,2165917828,2165931068","A variety of applications, such as information extraction, intrusion detection and protein fold recognition, can be expressed as sequences of discrete events or elements (rather than unordered sets of features), that is, there is an order dependence among the elements composing each data instance. These applications may be modeled as classification problems, and in this case the classifier should exploit sequential interactions among the elements, so that the ordering relationship among them is properly captured. Dominant approaches to this problem include: (i) learning Hidden Markov Models, (ii) exploiting frequent sequences extracted from the data and (iii) computing string kernels. Such approaches, however, are computationally hard and vulnerable to noise, especially if the data shows long range dependencies (i.e., long subsequences are necessary in order to model the data). In this paper we provide simple algorithms that build highly effective sequential classifiers. Our algorithms are based on enumerating approximately contiguous subsequences from the training set on a demand-driven basis, exploiting a lightweight and flexible subsequence matching function and an innovative subsequence enumeration strategy called pattern silhouettes, making our learning algorithms fast and the corresponding classifiers robust to noisy data. Our empirical results on a variety of datasets indicate that the best trade-off between accuracy and learning time is usually obtained by limiting the length of the subsequences by a factor of $$\log {n}$$logn, which leads to a $$O(n\log {n})$$O(nlogn) learning cost (where $$n$$n is the length of the sequence being classified). Finally, we show that, in most of the cases, our classifiers are faster than existing solutions (sometimes, by orders of magnitude), also providing significant accuracy improvements in most of the evaluated cases.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1685-1708,data mining;pattern recognition;machine learning;mathematics;
Weakly supervised nonnegative matrix factorization for user-driven clustering,Jaegul Choo (Georgia Institute of Technology);Changhyun Lee (Google);Chandan K. Reddy (Wayne State University);Haesun Park (Georgia Institute of Technology);,"2148380128,2597514406,2100435683,2123241397","Clustering high-dimensional data and making sense out of its result is a challenging problem. In this paper, we present a weakly supervised nonnegative matrix factorization (NMF) and its symmetric version that take into account various prior information via regularization in clustering applications. Unlike many other existing methods, the proposed weakly supervised NMF methods provide interpretable and flexible outputs by directly incorporating various forms of prior information. Furthermore, the proposed methods maintain a comparable computational complexity to the standard NMF under an alternating nonnegativity-constrained least squares framework. By using real-world data, we conduct quantitative analyses to compare our methods against other semi-supervised clustering methods. We also present the use cases where the proposed methods lead to semantically meaningful and accurate clustering results by properly utilizing user-driven prior information.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1598-1621,canopy clustering algorithm;correlation clustering;constrained clustering;cure data clustering algorithm;fuzzy clustering;non negative matrix factorization;regularization;cluster analysis;pattern recognition;machine learning;mathematical optimization;computer science;mathematics;
Ensemble methods for uplift modeling,Michał Sołtys (Polish Academy of Sciences);Szymon Jaroszewicz (Polish Academy of Sciences);Piotr Rzepakowski;,"2412752768,115085028,1907515892","Uplift modeling is a branch of machine learning which aims at predicting the causal effect of an action such as a marketing campaign or a medical treatment on a given individual by taking into account responses in a treatment group, containing individuals subject to the action, and a control group serving as a background. The resulting model can then be used to select individuals for whom the action will be most profitable. This paper analyzes the use of ensemble methods: bagging and random forests in uplift modeling. We perform an extensive experimental evaluation to demonstrate that the application of those methods often results in spectacular gains in model performance, turning almost useless single models into highly capable uplift ensembles. The gains are much larger than those achieved in case of standard classification. We show that those gains are a result of high ensemble diversity, which in turn is a result of the differences between class probabilities in the treatment and control groups being harder to model than the class probabilities themselves. The feature of uplift modeling which makes it difficult thus also makes it amenable to the application of ensemble methods. As a result, bagging and random forests emerge from our evaluation as key tools in the uplift modeling toolbox.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1531-1559,random forest;bootstrap aggregating;ensemble learning;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
A general framework for predictive tensor modeling with domain knowledge,Yada Zhu (IBM);Jingrui He (Arizona State University);Richard D. Lawrence (IBM);,"2712115745,2693123770,1965188977","In many real applications such as virtual metrology in semiconductor manufacturing, face recognition, and gait recognition in computer vision, the input data is naturally expressed as tensors or multi-dimensional arrays. Furthermore, in addition to the known label information, domain knowledge can often be obtained from various sources, e.g., multiple domain experts. To address such problems, in this paper, we propose a general optimization framework for dealing with tensor inputs while taking into consideration domain knowledge. To be specific, our framework is based on a linear model, and we obtain the weight tensor in a hierarchical way--first approximate it by a low-rank tensor, and then estimate the low-rank approximation using the domain knowledge from various sources. This is motivated by wafer quality prediction in semiconductor manufacturing. We also propose an effective algorithm named H-MOTE for solving this framework, which is guaranteed to converge. For each iteration, the time complexity of H-MOTE is linear with respect to the number of examples as well as the size of the weight tensor. Therefore, H-MOTE is scalable to large-scale problems. Experimental results show that H-MOTE outperforms state-of-the-art techniques on both synthetic and real data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1709-1732,semiconductor device fabrication;tensor;theoretical computer science;data mining;machine learning;computer science;
Multi-relational pattern mining over data streams,Andreia Silva (Instituto Superior Técnico);Cláudia Antunes (Instituto Superior Técnico);,"2165533671,2081435542","The data storage paradigm has changed in the last decade, from operational databases to data repositories that make easier to analyze data and mining information. Among those, the primary multidimensional model represents data through star schemas, where each relation denotes an event involving a set of dimensions or business perspectives. Mining data modeled as a star schema presents two major challenges, namely: mining extremely large amounts of data and dealing with several data tables at the same time. In this paper, we describe an algorithm--Star FP Stream, in detail. This algorithm aims for finding the set of frequent patterns in a large star schema, mining directly the data, in their original structure, and exploring the most efficient techniques for mining data streams. Experiments were conducted over two star schemas, in the healthcare and sales domains.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1783-1814,star schema;concept mining;data stream mining;data warehouse;data science;data mining;database;machine learning;computer science;
A general framework for never-ending learning from time series streams,"Yanping Chen 0005 (University of California, Riverside);Yuan Hao (University of California, Riverside);Thanawin Rakthanmanon (Kasetsart University);Jesin Zakaria (University of California, Riverside);Bing Hu 0001 (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2472401419,2169241512,141314290,2129110089,2105942667,2170070822","Time series classification has been an active area of research in the data mining community for over a decade, and significant progress has been made in the tractability and accuracy of learning. However, virtually all work assumes a one-time training session in which labeled examples of all the concepts to be learned are provided. This assumption may be valid in a handful of situations, but it does not hold in most medical and scientific applications where we initially may have only the vaguest understanding of what concepts can be learned. Based on this observation, we propose a never-ending learning framework for time series in which an agent examines an unbounded stream of data and occasionally asks a teacher (which may be a human or an algorithm) for a label. We demonstrate the utility of our ideas with experiments that consider real-world problems in domains as diverse as medicine, entomology, wildlife monitoring, and human behavior analyses.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1622-1664,time series;biological classification;data stream mining;data science;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Size matters: choosing the most informative set of window lengths for mining patterns in event sequences,Jefrey Lijffijt (University of Bristol);Panagiotis Papapetrou (Stockholm University);Kai Puolamäki (Aalto University);,"115479936,2000108749,96415260","In order to find patterns in data, it is often necessary to aggregate or summarise data at a higher level of granularity. Selecting the appropriate granularity is a challenging task and often no principled solutions exist. This problem is particularly relevant in analysis of data with sequential structure. We consider this problem for a specific type of data, namely event sequences. We introduce the problem of finding the best set of window lengths for analysis of event sequences for algorithms with real-valued output. We present suitable criteria for choosing one or multiple window lengths and show that these naturally translate into a computational optimisation problem. We show that the problem is NP-hard in general, but that it can be approximated efficiently and even analytically in certain cases. We give examples of tasks that demonstrate the applicability of the problem and present extensive experiments on both synthetic data and real data from several domains. We find that the method works well in practice, and that the optimal sets of window lengths themselves can provide new insight into the data.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1838-1864,exploratory data analysis;streams;association;information system;dna;theoretical computer science;bioinformatics;data mining;machine learning;statistics;computer science;
Quadratic regularization projected Barzilai---Borwein method for nonnegative matrix factorization,Yakui Huang (Xidian University);Hongwei Liu (Xidian University);Shuisheng Zhou (Xidian University);,"2631681507,2155495874,2723105359","In this paper, based on the alternating nonnegative least squares framework, we present a new efficient method for nonnegative matrix factorization that uses a quadratic regularization projected Barzilai---Borwein (QRPBB) method to solve the subproblems. At each iteration, the QRPBB method first generates a point by solving a strongly convex quadratic minimization problem, which has a simple closed-form solution that is inexpensive to calculate, and then applies a projected Barzilai---Borwein method to update the solution of NMF. Global convergence result is established under mild conditions. Numerical comparisons of methods on both synthetic and real-world datasets show that the proposed method is efficient.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1665-1684,nonnegative matrix;non negative matrix factorization;combinatorics;mathematical analysis;machine learning;mathematical optimization;computer science;mathematics;
Cluster validity functions for categorical data: a solution-space perspective,Liang Bai (Shanxi University);Jiye Liang (Shanxi University);,"2688274907,2716335768","For categorical data, there are three widely-used internal validity functions: the $$k$$k-modes objective function, the category utility function and the information entropy function, which are defined based on within-cluster information only. Many clustering algorithms have been developed to use them as objective functions and find their optimal solutions. In this paper, we study the generalization, effectiveness and normalization of the three validity functions from a solution-space perspective. First, we present a generalized validity function for categorical data. Based on it, we analyze the generality and difference of the three validity functions in the solution space. Furthermore, we address the problem whether the between-cluster information is ignored when these validity functions are used to evaluate clustering results. To the end, we analyze the upper and lower bounds of the three validity functions for a given data set, which can help us estimate the clustering difficulty on a data set and compare the performance of a clustering algorithm on different data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1560-1597,convergent validity;normalization;generalization;cluster analysis;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Properties of the sample estimators used for statistical normalization of feature vectors,Mikhail Y. Prostov (Moscow State University);Maria M. Suarez-Alvarez (Cardiff University);Yuriy I. Prostov;,"1639900683,2083711132,1990737125","Normalization of feature vectors is often used as a step of data preprocessing for clustering. A unified statistical approach to feature vector normalization has been proposed recently by the authors. After the proposed normalization, the contributions of both numerical and categorical attributes to a specified objective function are statistically the same. In spite of the importance for estimators to be consistent, the consistency of the sample estimators used for normalization, has never been considered. A mathematical justification of the statistical normalization procedure is given here. The sample estimators proposed for normalization of attributes of feature vectors are proven to have desirable properties, namely they are consistent and unbiased. Some other mathematical questions related to clustering have got here a rigorous treatment. In particular, the statistical normalization procedure is discussed in detail in the cases of the objective functions being based on the Chebyshev, attribute mismatch categorical and Minkowski mixed p-metrics. As an application of the normalization procedure, clustering of several benchmark datasets is performed with non-normalized and introduced normalized mixed metrics using either the $$k$$k-prototypes (for $$p=2$$p=2) or another algorithm (for $$p\not = 2$$p?2).",2015,Data Mining and Knowledge Discovery volume 29 issue 6 pp 1815-1837,normalization;estimator;econometrics;data mining;statistics;mathematics;
Multiscale event detection in social media,Xiaowen Dong (Massachusetts Institute of Technology);Dimitrios Mavroeidis (Philips);Francesco Calabrese (IBM);Pascal Frossard (École Polytechnique Fédérale de Lausanne);,"2129161834,2485292246,2016269244,2063844727","Event detection has been one of the most important research topics in social media analysis. Most of the traditional approaches detect events based on fixed temporal and spatial resolutions, while in reality events of different scales usually occur simultaneously, namely, they span different intervals in time and space. In this paper, we propose a novel approach towards multiscale event detection using social media data, which takes into account different temporal and spatial scales of events in the data. Specifically, we explore the properties of the wavelet transform, which is a well-developed multiscale transform in signal processing, to enable automatic handling of the interaction between temporal and spatial scales. We then propose a novel algorithm to compute a data similarity graph at appropriate scales and detect events of different scales simultaneously by a single graph-based clustering process. Furthermore, we present spatiotemporal statistical analysis of the noisy information present in the data stream, which allows us to define a novel term-filtering procedure for the proposed event detection algorithm and helps us study its behavior using simulated noisy data. Experimental results on both synthetically generated data and real world data collected from Twitter demonstrate the meaningfulness and effectiveness of the proposed approach. Our framework further extends to numerous application domains that involve multiscale and multiresolution data analysis.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1374-1405,data science;theoretical computer science;data mining;statistics;computer science;
Mining outlying aspects on numeric data,Lei Duan (Sichuan University);Guanting Tang (Simon Fraser University);Jian Pei (Simon Fraser University);James Bailey (University of Melbourne);Akiko Campbell;Changjie Tang (Sichuan University);,"2618270272,2136282317,2126330539,2131557737,2152383629,2099022773","When we are investigating an object in a data set, which itself may or may not be an outlier, can we identify unusual (i.e., outlying) aspects of the object? In this paper, we identify the novel problem of mining outlying aspects on numeric data. Given a query object $$o$$o in a multidimensional numeric data set $$O$$O, in which subspace is $$o$$o most outlying? Technically, we use the rank of the probability density of an object in a subspace to measure the outlyingness of the object in the subspace. A minimal subspace where the query object is ranked the best is an outlying aspect. Computing the outlying aspects of a query object is far from trivial. A naive method has to calculate the probability densities of all objects and rank them in every subspace, which is very costly when the dimensionality is high. We systematically develop a heuristic method that is capable of searching data sets with tens of dimensions efficiently. Our empirical study using both real data and synthetic data demonstrates that our method is effective and efficient.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1116-1151,kernel density estimation;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
MassExodus: modeling evolving networks in harsh environments,Saket Navlakha (Salk Institute for Biological Studies);Christos Faloutsos (Carnegie Mellon University);Ziv Bar-Joseph (Center for Computational Biology);,"2059206925,2198983026,96358963","Consider networks in harsh environments, where nodes may be lost due to failure, attack, or infection--how is the topology affected by such events? Can we mimic and measure the effect? We propose a new generative model of network evolution in dynamic and harsh environments. Our model can reproduce the range of topologies observed across known robust and fragile biological networks, as well as several additional transport, communication, and social networks. We also develop a new optimization measure to evaluate robustness based on preserving high connectivity following random or adversarial bursty node loss. Using this measure, we evaluate the robustness of several real-world networks and propose a new distributed algorithm to construct secure networks operating within malicious environments.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1211-1232,distributed computing;computer security;machine learning;
Assessing the impact of a health intervention via user-generated Internet content,Vasileios Lampos (University College London);Elad Yom-Tov (Microsoft);Richard Pebody (Public Health England);Ingemar J. Cox (University College London);,"100906785,205587521,1214858697,2707492096","Assessing the effect of a health-oriented intervention by traditional epidemiological methods is commonly based only on population segments that use healthcare services. Here we introduce a complementary framework for evaluating the impact of a targeted intervention, such as a vaccination campaign against an infectious disease, through a statistical analysis of user-generated content submitted on web platforms. Using supervised learning, we derive a nonlinear regression model for estimating the prevalence of a health event in a population from Internet data. This model is applied to identify control location groups that correlate historically with the areas, where a specific intervention campaign has taken place. We then determine the impact of the intervention by inferring a projection of the disease rates that could have emerged in the absence of a campaign. Our case study focuses on the influenza vaccination program that was launched in England during the 2013/14 season, and our observations consist of millions of geo-located search queries to the Bing search engine and posts on Twitter. The impact estimates derived from the application of the proposed statistical framework support conventional assessments of the campaign.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1434-1457,social media;user generated content;intervention;gaussian process;supervised learning;data science;world wide web;data mining;machine learning;computer science;
Dynamic inference of social roles in information cascades,Sarvenaz Choobdar (University of Porto);Pedro Manuel Pinto Ribeiro (University of Porto);Srinivasan Parthasarathy (Ohio State University);Fernando M. A. Silva (University of Porto);,"429229401,2145123184,2106796124,2115144937","Nodes in complex networks inherently represent different kinds of functional or organizational roles. In the dynamic process of an information cascade, users play different roles in spreading the information: some act as seeds to initiate the process, some limit the propagation and others are in-between. Understanding the roles of users is crucial in modeling the cascades. Previous research mainly focuses on modeling users behavior based upon the dynamic exchange of information with neighbors. We argue however that the structural patterns in the neighborhood of nodes may already contain enough information to infer users' roles, independently from the information flow in itself. To approach this possibility, we examine how network characteristics of users affect their actions in the cascade. We also advocate that temporal information is very important. With this in mind, we propose an unsupervised methodology based on ensemble clustering to classify users into their social roles in a network, using not only their current topological positions, but also considering their history over time. Our experiments on two social networks, Flickr and Digg, show that topological metrics indeed possess discriminatory power and that different structural patterns correspond to different parts in the process. We observe that user commitment in the neighborhood affects considerably the influence score of users. In addition, we discover that the cohesion of neighborhood is important in the blocking behavior of users. With this we can construct topological fingerprints that can help us in identifying social roles, based solely on structural social ties, and independently from nodes activity and how information flows.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1152-1177,information cascade;complex network;role;data mining;machine learning;
Clustering Boolean tensors,Saskia Metzler (Max Planck Society);Pauli Miettinen (Max Planck Society);,"2156792870,2015634213","Graphs--such as friendship networks--that evolve over time are an example of data that are naturally represented as binary tensors. Similarly to analysing the adjacency matrix of a graph using a matrix factorization, we can analyse the tensor by factorizing it. Unfortunately, tensor factorizations are computationally hard problems, and in particular, are often significantly harder than their matrix counterparts. In case of Boolean tensor factorizations--where the input tensor and all the factors are required to be binary and we use Boolean algebra--much of that hardness comes from the possibility of overlapping components. Yet, in many applications we are perfectly happy to partition at least one of the modes. For instance, in the aforementioned time-evolving friendship networks, groups of friends might be overlapping, but the time points at which the network was captured are always distinct. In this paper we investigate what consequences this partitioning has on the computational complexity of the Boolean tensor factorizations and present a new algorithm for the resulting clustering problem. This algorithm can alternatively be seen as a particularly regularized clustering algorithm that can handle extremely high-dimensional observations. We analyse our algorithm with the goal of maximizing the similarity and argue that this is more meaningful than minimizing the dissimilarity. As a by-product we obtain a PTAS and an efficient 0.828-approximation algorithm for rank-1 binary factorizations. Our algorithm for Boolean tensor clustering achieves high scalability, high similarity, and good generalization to unseen data with both synthetic and real-world data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1343-1373,boolean network;tensor;boolean algebra;approximation;decomposition;cluster analysis;numerical analysis;data structure;theoretical computer science;discrete mathematics;combinatorics;data mining;machine learning;statistics;computer science;mathematics;
Knowledge base completion by learning pairwise-interaction differentiated embeddings,Yu Zhao (Beijing University of Posts and Telecommunications);Sheng Gao (Beijing University of Posts and Telecommunications);Patrick Gallinari (Pierre-and-Marie-Curie University);Jun Guo (Beijing University of Posts and Telecommunications);,"2421222894,2716280362,2235456028,2101091369","A knowledge base of triples like (subject entity, predicate relation,object entity) is a very important resource for knowledge management. It is very useful for human-like reasoning, query expansion, question answering (Siri) and other related AI tasks. However, such a knowledge base often suffers from incompleteness due to a large volume of increasing knowledge in the real world and a lack of reasoning capability. In this paper, we propose a Pairwise-interaction Differentiated Embeddings model to embed entities and relations in the knowledge base to low dimensional vector representations and then predict the possible truth of additional facts to extend the knowledge base. In addition, we present a probability-based objective function to improve the model optimization. Finally, we evaluate the model by considering the problem of computing how likely the additional triple is true for the task of knowledge base completion. Experiments on WordNet and Freebase show the excellent performance of our model and algorithm.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1486-1504,open knowledge base connectivity;procedural knowledge;body of knowledge;knowledge extraction;knowledge base;knowledge based systems;knowledge management;data mining;artificial intelligence;machine learning;computer science;mathematics;
Efficient and effective community search,Nicola Barbieri (Yahoo!);Francesco Bonchi (Yahoo!);Edoardo Galimberti (Instituto Politécnico Nacional);Francesco Gullo (Yahoo!);,"2155070167,2176652147,2545190585,1979201319","Community search is the problem of finding a good community for a given set of query vertices. One of the most studied formulations of community search asks for a connected subgraph that contains all query vertices and maximizes the minimum degree. All existing approaches to min-degree-based community search suffer from limitations concerning efficiency, as they need to visit (large part of) the whole input graph, as well as accuracy, as they output communities quite large and not really cohesive. Moreover, some existing methods lack generality: they handle only single-vertex queries, find communities that are not optimal in terms of minimum degree, and/or require input parameters. In this work we advance the state of the art on community search by proposing a novel method that overcomes all these limitations: it is in general more efficient and effective--one/two orders of magnitude on average, it can handle multiple query vertices, it yields optimal communities, and it is parameter-free. These properties are confirmed by an extensive experimental analysis performed on various real-world graphs.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1406-1433,combinatorics;data mining;machine learning;mathematics;
Generalization of clustering agreements and distances for overlapping clusters and network communities,Reihaneh Rabbany (University of Alberta);Osmar R. Zaïane (University of Alberta);,"1904584114,2308328903","A measure of distance between two clusterings has important applications, including clustering validation and ensemble clustering. Generally, such distance measure provides navigation through the space of possible clusterings. Mostly used in cluster validation, a normalized clustering distance, a.k.a. agreement measure, compares a given clustering result against the ground-truth clustering. The two widely-used clustering agreement measures are adjusted rand index and normalized mutual information. In this paper, we present a generalized clustering distance from which these two measures can be derived. We then use this generalization to construct new measures specific for comparing (dis)agreement of clusterings in networks, a.k.a. communities. Further, we discuss the difficulty of extending the current, contingency based, formulations to overlapping cases, and present an alternative algebraic formulation for these (dis)agreement measures. Unlike the original measures, the new co-membership based formulation is easily extendable for different cases, including overlapping clusters and clusters of inter-related data. These two extensions are, in particular, important in the context of finding communities in complex networks.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1458-1485,flame clustering;k medians clustering;brown clustering;canopy clustering algorithm;complete linkage clustering;correlation clustering;constrained clustering;cure data clustering algorithm;single linkage clustering;dendrogram;fuzzy clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;data mining;pattern recognition;machine learning;mathematics;
Finding the longest common sub-pattern in sequences of temporal intervals,Orestis Kostakis (Aalto University);Panagiotis Papapetrou (Stockholm University);,"1500961275,2000108749","We study the problem of finding the longest common sub-pattern (LCSP) shared by two sequences of temporal intervals. In particular we are interested in finding the LCSP of the corresponding arrangements. Arrangements of temporal intervals are a powerful way to encode multiple concurrent labeled events that have a time duration. Discovering commonalities among such arrangements is useful for a wide range of scientific fields and applications, as it can be seen by the number and diversity of the datasets we use in our experiments. In this paper, we define the problem of LCSP and prove that it is NP-complete by demonstrating a connection between graphs and arrangements of temporal intervals. This connection leads to a series of interesting open problems. In addition, we provide an exact algorithm to solve the LCSP problem, and also propose and experiment with three polynomial time and space under-approximation techniques. Finally, we introduce two upper bounds for LCSP and study their suitability for speeding up 1-NN search. Experiments are performed on seven datasets taken from a wide range of real application domains, plus two synthetic datasets. Lastly, we describe several application cases that demonstrate the need and suitability of LCSP.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1178-1210,information and computer science;discrete mathematics;combinatorics;data mining;algorithm;mathematics;
Beyond rankings: comparing directed acyclic graphs,Eric Malmi (Aalto University);Nikolaj Tatti (Aalto University);Aristides Gionis (Aalto University);,"2289295535,1367500519,737311942","Defining appropriate distance measures among rankings is a classic area of study which has led to many useful applications. In this paper, we propose a more general abstraction of preference data, namely directed acyclic graphs (DAGs), and introduce a measure for comparing DAGs, given that a vertex correspondence between the DAGs is known. We study the properties of this measure and use it to aggregate and cluster a set of DAGs. We show that these problems are $$\mathbf {NP}$$NP-hard and present efficient methods to obtain solutions with approximation guarantees. In addition to preference data, these methods turn out to have other interesting applications, such as the analysis of a collection of information cascades in a network. We test the methods on synthetic and real-world datasets, showing that the methods can be used to, e.g., find a set of influential individuals related to a set of topics in a network or to discover meaningful and occasionally surprising clustering structure.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1233-1257,information cascade;directed acyclic graph;cluster analysis;discrete mathematics;combinatorics;machine learning;computer science;mathematics;
Tractome: a visual data mining tool for brain connectivity analysis,Diana Porro-Muñoz (Kessler Foundation);Emanuele Olivetti (Kessler Foundation);Nusrat Sharmin (Kessler Foundation);Thien Bao Nguyen (Kessler Foundation);Eleftherios Garyfallidis (Université de Sherbrooke);Paolo Avesani (Kessler Foundation);,"2286586841,2129977254,2278205434,2119443905,342412512,2122337053","Diffusion magnetic resonance imaging data allows reconstructing the neural pathways of the white matter of the brain as a set of 3D polylines. This kind of data sets provides a means of study of the anatomical structures within the white matter, in order to detect neurologic diseases and understand the anatomical connectivity of the brain. To the best of our knowledge, there is still not an effective or satisfactory method for automatic processing of these data. Therefore, a manually guided visual exploration of experts is crucial for the purpose. However, because of the large size of these data sets, visual exploration and analysis has also become intractable. In order to make use of the advantages of both manual and automatic analysis, we have developed a new visual data mining tool for the analysis of human brain anatomical connectivity. With such tool, humans and automatic algorithms capabilities are integrated in an interactive data exploration and analysis process. A very important aspect to take into account when designing this tool, was to provide the user with comfortable interaction. For this purpose, we tackle the scalability issue in the different stages of the system, including the automatic algorithm and the visualization and interaction techniques that are used.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1258-1279,scalability;cluster analysis;computer vision;data mining;machine learning;computer science;
Ranking episodes using a partition model,Nikolaj Tatti (Aalto University);,1367500519,"One of the biggest setbacks in traditional frequent pattern mining is that overwhelmingly many of the discovered patterns are redundant. A prototypical example of such redundancy is a freerider pattern where the pattern contains a true pattern and some additional noise events. A technique for filtering freerider patterns that has proved to be efficient in ranking itemsets is to use a partition model where a pattern is divided into two subpatterns and the observed support is compared to the expected support under the assumption that these two subpatterns occur independently. In this paper we develop a partition model for episodes, patterns discovered from sequential data. An episode is essentially a set of events, with possible restrictions on the order of events. Unlike with itemset mining, computing the expected support of an episode requires surprisingly sophisticated methods. In order to construct the model, we partition the episode into two subepisodes. We then model how likely the events in each subepisode occur close to each other. If this probability is high--which is often the case if the subepisode has a high support--then we can expect that when one event from a subepisode occurs, then the remaining events occur also close by. This approach increases the expected support of the episode, and if this increase explains the observed support, then we can deem the episode uninteresting. We demonstrate in our experiments that using the partition model can effectively and efficiently reduce the redundancy in episodes.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1312-1342,data mining;artificial intelligence;machine learning;mathematics;
DRESS: dimensionality reduction for efficient sequence search,Alexios Kotsifakos (University of Texas at Arlington);Alexandra Stefan (University of Texas at Arlington);Vassilis Athitsos (University of Texas at Arlington);Gautam Das (University of Texas at Arlington);Panagiotis Papapetrou (Stockholm University);,"1923472341,1991224120,139967712,2112689123,2000108749","Similarity search in large sequence databases is a problem ubiquitous in a wide range of application domains, including searching biological sequences. In this paper we focus on protein and DNA data, and we propose a novel approximate method method for speeding up range queries under the edit distance. Our method works in a filter-and-refine manner, and its key novelty is a query-sensitive mapping that transforms the original string space to a new string space of reduced dimensionality. Specifically, it first identifies the $$t$$t most frequent codewords in the query, and then uses these codewords to convert both the query and the database to a more compact representation. This is achieved by replacing every occurrence of each codeword with a new letter and by removing the remaining parts of the strings. Using this new representation, our method identifies a set of candidate matches that are likely to satisfy the range query, and finally refines these candidates in the original space. The main advantage of our method, compared to alternative methods for whole sequence matching under the edit distance, is that it does not require any training to create the mapping, and it can handle large query lengths with negligible losses in accuracy. Our experimental evaluation demonstrates that, for higher range values and large query sizes, our method produces significantly lower costs and runtimes compared to two state-of-the-art competitor methods.",2015,Data Mining and Knowledge Discovery volume 29 issue 5 pp 1280-1311,nearest neighbor search;information and computer science;theoretical computer science;data mining;machine learning;computer science;mathematics;
Mining strong relevance between heterogeneous entities from unstructured biomedical data,Ming Ji (University of Illinois at Urbana–Champaign);Qi He (LinkedIn);Jiawei Han 0001 (University of Illinois at Urbana–Champaign);W. Scott Spangler (IBM);,"2717351498,2676736523,2121939561,2106251501","Huge volumes of biomedical text data discussing about different biomedical entities are being generated every day. Hidden in those unstructured data are the strong relevance relationships between those entities, which are critical for many interesting applications including building knowledge bases for the biomedical domain and semantic search among biomedical entities. In this paper, we study the problem of discovering strong relevance between heterogeneous typed biomedical entities from massive biomedical text data. We first build an entity correlation graph from data, in which the collection of paths linking two heterogeneous entities offer rich semantic contexts for their relationships, especially those paths following the patterns of top-$$k$$k selected meta paths inferred from data. Guided by such meta paths, we design a novel relevance measure to compute the strong relevance between two heterogeneous entities, named $${\mathsf {EntityRel}}$$EntityRel. Our intuition is, two entities of heterogeneous types are strongly relevant if they have strong direct links or they are linked closely to other strongly relevant heterogeneous entities along paths following the selected patterns. We provide experimental results on mining strong relevance between drugs and diseases. More than 20 millions of MEDLINE abstracts and 5 types of biological entities (Drug, Disease, Compound, Target, MeSH) are used to construct the entity correlation graph. A prototype of drug search engine for disease queries is implemented. Extensive comparisons are made against multiple state-of-the-arts in the examples of Drug---Disease relevance discovery.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 976-998,relevance;data science;information retrieval;data mining;computer science;
Classification-driven temporal discretization of multivariate time series,Robert Moskovitch (Ben-Gurion University of the Negev);Yuval Shahar (Ben-Gurion University of the Negev);,"319285823,700636827","Biomedical data, in particular electronic medical records data, include a large number of variables sampled in irregular fashion, often including both time point and time intervals, thus providing several challenges for analysis and data mining. Classification of multivariate time series data is a challenging task, but is often necessary for medical care or research. Increasingly, temporal abstraction, in which a series of raw-data time points is abstracted into a set of symbolic time intervals, is being used for classification of multivariate time series. In this paper, we introduce a novel supervised discretization method, geared towards enhancement of classification accuracy, which determines the cutoffs that will best discriminate among classes through the distribution of their states. We present a framework for classification of multivariate time series analysis, which implements three phases: (1) application of a temporal-abstraction process that transforms a series of raw time-stamped data points into a series of symbolic time intervals (based on either unsupervised or supervised temporal abstraction); (2) mining these time intervals to discover frequent temporal-interval relation patterns (TIRPs), using versions of Allen's 13 temporal relations; (3) using the patterns as features to induce a classifier. We evaluated the framework, focusing on the comparison of three versions of the new, supervised, temporal discretization for classification (TD4C) method, each relying on a different symbolic-state distribution-distance measure among outcome classes, to several commonly used unsupervised methods, on real datasets in the domains of diabetes, intensive care, and infectious hepatitis. Using only three abstract temporal relations resulted in a better classification performance than using Allen's seven relations, especially when using three symbolic states per variable. Similarly when using the horizontal support and mean duration as the TIRPs feature representation, rather than a binary (existence) representation. The classification performance when using the three versions of TD4C was superior to the performance when using the unsupervised (EWD, SAX, and KB) discretization methods.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 871-913,discretization;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;
Data mining for censored time-to-event data: a Bayesian network model for predicting cardiovascular risk from electronic health record data,Sunayan Bandyopadhyay (University of Minnesota);Julian Wolfson (University of Minnesota);David M. Vock (University of Minnesota);Gabriela Vazquez-Benitez (HealthPartners);Gediminas Adomavicius (Carlson School of Management);Mohamed Elidrisi (University of Minnesota);Paul E. Johnson (Carlson School of Management);Patrick J. O'Connor (HealthPartners);,"2200631451,2048816096,2051623346,1946449039,1988164005,1920454987,2436913298,2108379158","Models for predicting the risk of cardiovascular (CV) events based on individual patient characteristics are important tools for managing patient care. Most current and commonly used risk prediction models have been built from carefully selected epidemiological cohorts. However, the homogeneity and limited size of such cohorts restrict the predictive power and generalizability of these risk models to other populations. Electronic health data (EHD) from large health care systems provide access to data on large, heterogeneous, and contemporaneous patient populations. The unique features and challenges of EHD, including missing risk factor information, non-linear relationships between risk factors and CV event outcomes, and differing effects from different patient subgroups, demand novel machine learning approaches to risk model development. In this paper, we present a machine learning approach based on Bayesian networks trained on EHD to predict the probability of having a CV event within 5 years. In such data, event status may be unknown for some individuals, as the event time is right-censored due to disenrollment and incomplete follow-up. Since many traditional data mining methods are not well-suited for such data, we describe how to modify both modeling and assessment techniques to account for censored observation times. We show that our approach can lead to better predictive performance than the Cox proportional hazards model (i.e., a regression-based approach commonly used for censored, time-to-event data) or a Bayesian network with ad hoc approaches to right-censoring. Our techniques are motivated by and illustrated on data from a large US Midwestern health care system.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 1033-1069,bayesian network;survival analysis;econometrics;data mining;machine learning;statistics;computer science;
A relative similarity based method for interactive patient risk prediction,Buyue Qian (IBM);Xiang Wang (IBM);Nan Cao (IBM);Hongfei Li (IBM);Yu-Gang Jiang (Fudan University);,"2306481588,2099725100,2101761023,2134372436,2143115300","This paper investigates the patient risk prediction problem in the context of active learning with relative similarities. Active learning has been extensively studied and successfully applied to solve real problems. The typical setting of active learning methods is to query absolute questions. In a medical application where the goal is to predict the risk of patients on certain disease using Electronic Health Records (EHR), the absolute questions take the form of ""Will this patient suffer from Alzheimer's later in his/her life?"", or ""Are these two patients similar or not?"". Due to the excessive requirements of domain knowledge, such absolute questions are usually difficult to answer, even for experienced medical experts. In addition, the performance of absolute question focused active learning methods is less stable, since incorrect answers often occur which can be detrimental to the risk prediction model. In this paper, alternatively, we focus on designing relative questions that can be easily answered by domain experts. The proposed relative queries take the form of ""Is patient A or patient B more similar to patient C?"", which can be answered by medical experts with more confidence. These questions poll relative information as opposed to absolute information, and even can be answered by non-experts in some cases. In this paper we propose an interactive patient risk prediction method, which actively queries medical experts with the relative similarity of patients. We explore our method on both benchmark and real clinic datasets, and make several interesting discoveries including that querying relative similarities is effective in patient risk prediction, and sometimes can even yield better prediction accuracy than asking for absolute questions.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 1070-1093,active learning;data science;information retrieval;data mining;computer science;
On mining latent treatment patterns from electronic medical records,Zhengxing Huang (Zhejiang University);Wei Dong;Peter Bath (Information school);Lei Ji;Huilong Duan (Zhejiang University);,"2147222904,2209702621,2131389459,2438291895,2124432645","Clinical pathway (CP) analysis plays an important role in health-care management in ensuring specialized, standardized, normalized and sophisticated therapy procedures for individual patients. Recently, with the rapid development of hospital information systems, a large volume of electronic medical records (EMRs) has been produced, which provides a comprehensive source for CP analysis. In this paper, we are concerned with the problem of utilizing the heterogeneous EMRs to assist CP analysis and improvement. More specifically, we develop a probabilistic topic model to link patient features and treatment behaviors together to mine treatment patterns hidden in EMRs. Discovered treatment patterns, as actionable knowledge representing the best practice for most patients in most time of their treatment processes, form the backbone of CPs, and can be exploited to help physicians better understand their specialty and learn from previous experiences for CP analysis and improvement. Experimental results on a real collection of 985 EMRs collected from a Chinese hospital show that the proposed approach can effectively identify meaningful treatment patterns from EMRs.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 914-949,latent dirichlet allocation;data science;bioinformatics;data mining;machine learning;computer science;
Probabilistic change detection and visualization methods for the assessment of temporal stability in biomedical data quality,Carlos Sáez (Grupo México);Pedro Pereira Rodrigues (University of Porto);João Gama (University of Porto);Montserrat Robles (Grupo México);Juan Miguel García-Gómez (Grupo México);,"2570483970,2115274281,2113857198,2273561250,2083058207","Knowledge discovery on biomedical data can be based on on-line, data-stream analyses, or using retrospective, timestamped, off-line datasets. In both cases, changes in the processes that generate data or in their quality features through time may hinder either the knowledge discovery process or the generalization of past knowledge. These problems can be seen as a lack of data temporal stability. This work establishes the temporal stability as a data quality dimension and proposes new methods for its assessment based on a probabilistic framework. Concretely, methods are proposed for (1) monitoring changes, and (2) characterizing changes, trends and detecting temporal subgroups. First, a probabilistic change detection algorithm is proposed based on the Statistical Process Control of the posterior Beta distribution of the Jensen---Shannon distance, with a memoryless forgetting mechanism. This algorithm (PDF-SPC) classifies the degree of current change in three states: In-Control, Warning, and Out-of-Control. Second, a novel method is proposed to visualize and characterize the temporal changes of data based on the projection of a non-parametric information-geometric statistical manifold of time windows. This projection facilitates the exploration of temporal trends using the proposed IGT-plot and, by means of unsupervised learning methods, discovering conceptually-related temporal subgroups. Methods are evaluated using real and simulated data based on the National Hospital Discharge Survey (NHDS) dataset.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 950-975,information geometry;change detection;data quality;visual analytics;information theory;data science;data mining;machine learning;statistics;computer science;
Guest editorial: Special issue on data mining for medicine and healthcare,"Fei Wang (University of Connecticut);Gregor Stiglic (Birmingham City University Faculty of Health);Zoran Obradovic (Temple University);Ian Davidson (University of California, Davis);","2465953593,73310800,2029694244,2560595684",-,2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 867-870,-
Constrained elastic net based knowledge transfer for healthcare information exchange,Yan Li (Wayne State University);Bhanukiran Vinzamuri (Wayne State University);Chandan K. Reddy (Wayne State University);,"2607418379,23137369,2100435683","Transfer learning methods have been successfully applied in solving a wide range of real-world problems. However, there is almost no attempt of effectively using these methods in healthcare applications. In the healthcare domain, it becomes extremely critical to solve the ""when to transfer"" issue of transfer learning. In highly divergent source and target domains, transfer learning can lead to negative transfer. Most of the existing works in transfer learning are primarily focused on selecting useful information from the source to improve the performance of the target task, but whether the transfer learning can help and when the transfer learning should be applied in the target task are still some of the impending challenges. In this paper, we address this issue of ""when to transfer"" by proposing a sparse feature selection model based on the constrained elastic net penalty. As a case study of the proposed model, we demonstrate the performance using the diabetes electronic health records (EHRs) which contain patient records from all fifty states in the United States. Our approach can choose relevant features to transfer knowledge from the source to the target tasks. The proposed model can measure the differences between multivariate data distributions conditional on the predicted model, and based on this measurement we can avoid unsuccessful transfer. We successfully transfer the knowledge across different states to improve the diagnosis of diabetes in a certain state with insufficient records to build an individualized predictive model with the aid of information from other states.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 1094-1112,inductive transfer;multi task learning;transfer of learning;regularization;data mining;machine learning;simulation;computer science;
Generative modeling of repositories of health records for predictive tasks,Rui Henriques (INESC-ID);Cláudia Antunes (INESC-ID);Sara C. Madeira (INESC-ID);,"2139129317,2081435542,2047722776","Repositories of health records are collections of events with varying number and sparsity of occurrences within and among patients. Although a large number of predictive models have been proposed in the last decade, they are not yet able to simultaneously capture cross-attribute and temporal dependencies associated with these repositories. Two major streams of predictive models can be found. On one hand, deterministic models rely on compact subsets of discriminative events to anticipate medical conditions. On the other hand, generative models offer a more complete and noise-tolerant view based on the likelihood of the testing arrangements of events to discriminate a particular outcome. However, despite the relevance of generative predictive models, they are not easily extensible to deal with complex grids of events. In this work, we rely on the Markov assumption to propose new predictive models able to deal with cross-attribute and temporal dependencies. Experimental results hold evidence for the utility and superior accuracy of generative models to anticipate health conditions, such as the need for surgeries. Additionally, we show that the proposed generative models are able to decode temporal patterns of interest (from the learned lattices) with acceptable completeness and precision levels, and with superior efficiency for voluminous repositories.",2015,Data Mining and Knowledge Discovery volume 29 issue 4 pp 999-1032,predictive modelling;hidden markov model;data science;data mining;machine learning;statistics;computer science;
Graph based anomaly detection and description: a survey,Leman Akoglu (Stony Brook University);Hanghang Tong (IBM);Danai Koutra (Carnegie Mellon University);,"2288278917,2224718883,1524801041","Detecting anomalies in data is a vital task, with numerous high-impact applications in areas such as security, finance, health care, and law enforcement. While numerous techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured graph data have been of focus recently. As objects in graphs have long-range correlations, a suite of novel technology has been developed for anomaly detection in graph data. This survey aims to provide a general, comprehensive, and structured overview of the state-of-the-art methods for anomaly detection in data represented as graphs. As a key contribution, we give a general framework for the algorithms categorized under various settings: unsupervised versus (semi-)supervised approaches, for static versus dynamic graphs, for attributed versus plain graphs. We highlight the effectiveness, scalability, generality, and robustness aspects of the methods. What is more, we stress the importance of anomaly attribution and highlight the major techniques that facilitate digging out the root cause, or the `why', of the detected anomalies for further analysis and sense-making. Finally, we present several real-world applications of graph-based anomaly detection in diverse domains, including financial, auction, computer traffic, and social networks. We conclude our survey with a discussion on open theoretical and practical challenges in the field.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 626-688,change detection;visual analytics;anomaly detection;data science;data mining;machine learning;statistics;computer science;
Time series classification with ensembles of elastic distance measures,Jason Lines (University of East Anglia);Anthony Bagnall (University of East Anglia);,"1984663852,2171856547","Several alternative distance measures for comparing time series have recently been proposed and evaluated on time series classification (TSC) problems. These include variants of dynamic time warping (DTW), such as weighted and derivative DTW, and edit distance-based measures, including longest common subsequence, edit distance with real penalty, time warp with edit, and move---split---merge. These measures have the common characteristic that they operate in the time domain and compensate for potential localised misalignment through some elastic adjustment. Our aim is to experimentally test two hypotheses related to these distance measures. Firstly, we test whether there is any significant difference in accuracy for TSC problems between nearest neighbour classifiers using these distance measures. Secondly, we test whether combining these elastic distance measures through simple ensemble schemes gives significantly better accuracy. We test these hypotheses by carrying out one of the largest experimental studies ever conducted into time series classification. Our first key finding is that there is no significant difference between the elastic distance measures in terms of classification accuracy on our data sets. Our second finding, and the major contribution of this work, is to define an ensemble classifier that significantly outperforms the individual classifiers. We also demonstrate that the ensemble is more accurate than approaches not based in the time domain. Nearly all TSC papers in the data mining literature cite DTW (with warping window set through cross validation) as the benchmark for comparison. We believe that our ensemble is the first ever classifier to significantly outperform DTW and as such raises the bar for future work in this area.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 565-592,data mining;pattern recognition;machine learning;statistics;mathematics;
Evaluation measures for hierarchical classification: a unified view and novel approaches,"Aris Kosmopoulos (Athens University of Economics and Business);Ioannis Partalas (Joseph Fourier University);Eric Gaussier (Joseph Fourier University);Georgios Paliouras (National Centre of Scientific Research ""Demokritos"");Ion Androutsopoulos (Athens University of Economics and Business);","2115643045,127847919,2667237248,2086391101,1808727851","Hierarchical classification addresses the problem of classifying items into a hierarchy of classes. An important issue in hierarchical classification is the evaluation of different classification algorithms, an issue which is complicated by the hierarchical relations among the classes. Several evaluation measures have been proposed for hierarchical classification using the hierarchy in different ways without however providing a unified view of the problem. This paper studies the problem of evaluation in hierarchical classification by analysing and abstracting the key components of the existing performance measures. It also proposes two alternative generic views of hierarchical evaluation and introduces two corresponding novel measures. The proposed measures, along with the state-of-the-art ones, are empirically tested on three large datasets from the domain of text classification. The empirical results illustrate the undesirable behaviour of existing approaches and how the proposed methods overcome most of these problems across a range of cases.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 820-865,evaluation;data mining;pattern recognition;machine learning;mathematics;
On measuring similarity for sequences of itemsets,Elias Egho (Centre national de la recherche scientifique);Chedy C. Raïssi (French Institute for Research in Computer Science and Automation);Toon Calders (Université libre de Bruxelles);Nicolas Jay (Centre national de la recherche scientifique);Amedeo Napoli (Centre national de la recherche scientifique);,"2310452071,2065278996,2064105222,2249387274,2141826860","Computing the similarity between sequences is a very important challenge for many different data mining tasks. There is a plethora of similarity measures for sequences in the literature, most of them being designed for sequences of items. In this work, we study the problem of measuring the similarity between sequences of itemsets. We focus on the notion of common subsequences as a way to measure similarity between a pair of sequences composed of a list of itemsets. We present new combinatorial results for efficiently counting distinct and common subsequences. These theoretical results are the cornerstone of an effective dynamic programming approach to deal with this problem. In addition, we propose an approximate method to speed up the computation process for long sequences. We have applied our method to various data sets: healthcare trajectories, online handwritten characters and synthetic data. Our results confirm that our measure of similarity produces competitive scores and indicate that our method is relevant for large scale sequential data analysis.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 732-764,sequential pattern mining;cluster analysis;bioinformatics;data mining;pattern recognition;machine learning;computer science;mathematics;
"Evolutionary soft co-clustering: formulations, algorithms, and applications",Wenlu Zhang (Old Dominion University);Rongjian Li (Old Dominion University);Daming Feng (Old Dominion University);Andrey N. Chernikov (Old Dominion University);Nikos Chrisochoides (Old Dominion University);Christopher Osgood (Old Dominion University);Shuiwang Ji (Old Dominion University);,"2303814361,2130205980,2102683354,2025483061,180555034,2082470855,2149659377","We consider the co-clustering of time-varying data using evolutionary co-clustering methods. Existing approaches are based on the spectral learning framework, thus lacking a probabilistic interpretation. We overcome this limitation by developing a probabilistic model in this paper. The proposed model assumes that the observed data are generated via a two-step process that depends on the historic co-clusters. This allows us to capture the temporal smoothness in a probabilistically principled manner. To perform maximum likelihood parameter estimation, we present an EM-based algorithm. We also establish the convergence of the proposed EM algorithm. An appealing feature of the proposed model is that it leads to soft co-clustering assignments naturally. We evaluate the proposed method on both synthetic and real-world data sets. Experimental results show that our method consistently outperforms prior approaches based on spectral method. To fully exploit the real-world impact of our methods, we further perform a systematic application study on the analysis of Drosophila gene expression pattern images. We encode the spatial gene expression information at a particular developmental time point into a data matrix using a mesh-generation pipeline. We then co-cluster the embryonic domains and the genes simultaneously for multiple time points using our evolutionary co-clustering method. Results show that the co-clusters of gene and embryonic domains reflect the underlying biology.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 765-791,expectation maximization algorithm;bioinformatics;data mining;machine learning;statistics;computer science;
CenKNN: a scalable and effective text classifier,Guansong Pang (Monash University);Huidong Jin (Commonwealth Scientific and Industrial Research Organisation);Shengyi Jiang (Guangdong University of Foreign Studies);,"2533915033,2651666466,2653019742","A big challenge in text classification is to perform classification on a large-scale and high-dimensional text corpus in the presence of imbalanced class distributions and a large number of irrelevant or noisy term features. A number of techniques have been proposed to handle this challenge with varying degrees of success. In this paper, by combining the strengths of two widely used text classification techniques, K-Nearest-Neighbor (KNN) and centroid based (Centroid) classifiers, we propose a scalable and effective flat classifier, called CenKNN, to cope with this challenge. CenKNN projects high-dimensional (often hundreds of thousands) documents into a low-dimensional (normally a few dozen) space spanned by class centroids, and then uses the $$k$$ k -d tree structure to find $$K$$ K nearest neighbors efficiently. Due to the strong representation power of class centroids, CenKNN overcomes two issues related to existing KNN text classifiers, i.e., sensitivity to imbalanced class distributions and irrelevant or noisy term features. By working on projected low-dimensional data, CenKNN substantially reduces the expensive computation time in KNN. CenKNN also works better than Centroid since it uses all the class centroids to define similarity and works well on complex data, i.e., non-linearly separable data and data with local patterns within each class. A series of experiments on both English and Chinese, benchmark and synthetic corpora demonstrates that although CenKNN works on a significantly lower-dimensional space, it performs substantially better than KNN and its five variants, and existing scalable classifiers, including Centroid and Rocchio. CenKNN is also empirically preferable to another well-known classifier, support vector machines, on highly imbalanced corpora with a small number of classes.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 593-625,centroid;dimensionality reduction;k nearest neighbors algorithm;data mining;pattern recognition;machine learning;computer science;mathematics;
Detecting anomaly collections using extreme feature ranks,Hanbo Dai (Hubei University);Feida Zhu (Singapore Management University);Ee Peng Lim (Singapore Management University);Hwee Hwa Pang (Singapore Management University);,"2147320963,2160602068,2130308643,2095771566","Detecting anomaly collections is an important task with many applications, including spam and fraud detection. In an anomaly collection, entities often operate in collusion and hold different agendas to normal entities. As a result, they usually manifest collective extreme traits, i.e., members of an anomaly collection are consistently clustered toward the top or bottom ranks on certain features. We therefore propose to detect these anomaly collections by extreme feature ranks. We introduce a novel anomaly definition called Extreme Rank Anomalous Collection or ERAC. We propose a new measure of anomalousness capturing collective extreme traits based on a statistical model. As there can be a large number of ERACs of various sizes, for simplicity, we first investigate the ERAC detection problem of finding top- $$K$$ K ERACs of a predefined size limit. We then tackle the follow-up ERAC expansion problem of uncovering the supersets of the detected ERACs that are more anomalous without any size constraint. Algorithms are proposed for both ERAC detection and expansion problems, followed by studies of their performance in four datasets. Specifically, in synthetic datasets, both ERAC detection and expansion algorithms demonstrate high precisions and recalls. In a web spam dataset, both ERAC detection and expansion algorithms discover web spammers with higher precisions than existing approaches. In an IMDB dataset, both ERAC detection and expansion algorithms identify unusual actor collections that are not easily identified by clustering-based methods. In a Chinese online forum dataset, our ERAC detection algorithm identifies suspicious ""water army"" spammer collections agreed by human evaluators. ERAC expansion algorithm successfully reveals two larger spammer collections with different spamming behaviors.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 689-731,world wide web;data mining;machine learning;mathematics;
Multi-period classification: learning sequent classes from temporal domains,Rui Henriques (INESC-ID);Sara C. Madeira (INESC-ID);Cláudia Antunes (INESC-ID);,"2139129317,2047722776,2081435542","As the majority of real-world decisions change over time, extending traditional classifiers to deal with the problem of classifying an attribute of interest across different time periods becomes increasingly important. Tackling this problem, referred to as multi-period classification, is critical to answer real-world tasks, such as the prediction of upcoming healthcare needs or administrative planning tasks. In this context, although existing research provides principles for learning single labels from complex data domains, less attention has been given to the problem of learning sequences of classes (symbolic time series). This work motivates the need for multi-period classifiers, and proposes a method, cluster-based multi-period classification (CMPC), that preserves local dependencies across the periods under classification. Evaluation against real-world datasets provides evidence of the relevance of multi-period classifiers, and shows the superior performance of the CMPC method against peer methods adapted from long-term prediction for multi-period tasks with a high number of periods.",2015,Data Mining and Knowledge Discovery volume 29 issue 3 pp 792-819,data mining;pattern recognition;machine learning;mathematics;
Addressing the cold-start problem in location recommendation using geo-social correlations,Huiji Gao (Arizona State University);Jiliang Tang (Arizona State University);Huan Liu (Arizona State University);,"2166899337,2147392410,2122391114","Location-based social networks (LBSNs) have attracted an increasing number of users in recent years, resulting in large amounts of geographical and social data. Such LBSN data provide an unprecedented opportunity to study the human movement from their socio-spatial behavior, in order to improve location-based applications like location recommendation. As users can check-in at new places, traditional work on location prediction that relies on mining a user's historical moving trajectories fails as it is not designed for the cold-start problem of recommending new check-ins. While previous work on LBSNs attempting to utilize a user's social connections for location recommendation observed limited help from social network information. In this work, we propose to address the cold-start location recommendation problem by capturing the correlations between social networks and geographical distance on LBSNs with a geo-social correlation model. The experimental results on a real-world LBSN dataset demonstrate that our approach properly models the geo-social correlations of a user's cold-start check-ins and significantly improves the location recommendation performance.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 299-323,cold start;world wide web;data mining;machine learning;simulation;computer science;
Survey on distance metric learning and dimensionality reduction in data mining,Fei Wang (IBM);Jimeng Sun (Georgia Institute of Technology);,"2465953593,2110385854","Distance metric learning is a fundamental problem in data mining and knowledge discovery. Many representative data mining algorithms, such as $$k$$ k -nearest neighbor classifier, hierarchical clustering and spectral clustering, heavily rely on the underlying distance metric for correctly measuring relations among input data. In recent years, many studies have demonstrated, either theoretically or empirically, that learning a good distance metric can greatly improve the performance of classification, clustering and retrieval tasks. In this survey, we overview existing distance metric learning approaches according to a common framework. Specifically, depending on the available supervision information during the distance metric learning process, we categorize each distance metric learning algorithm as supervised, unsupervised or semi-supervised. We compare those different types of metric learning methods, point out their strength and limitations. Finally, we summarize open challenges in distance metric learning and propose future directions for distance metric learning.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 534-564,neighbourhood components analysis;k medians clustering;variation of information;string metric;hierarchical clustering;dimensionality reduction;semi supervised learning;data mining;pattern recognition;machine learning;computer science;mathematics;
Learning a symbolic representation for multivariate time series classification,Mustafa Gokce Baydogan (Boğaziçi University);George C. Runger (Arizona State University);,"2071505279,2005957266","Multivariate time series (MTS) classification has gained importance with the increase in the number of temporal datasets in different domains (such as medicine, finance, multimedia, etc.). Similarity-based approaches, such as nearest-neighbor classifiers, are often used for univariate time series, but MTS are characterized not only by individual attributes, but also by their relationships. Here we provide a classifier based on a new symbolic representation for MTS (denoted as SMTS) with several important elements. SMTS considers all attributes of MTS simultaneously, rather than separately, to extract information contained in the relationships. Symbols are learned from a supervised algorithm that does not require pre-defined intervals, nor features. An elementary representation is used that consists of the time index, and the values (and first differences for numerical attributes) of the individual time series as columns. That is, there is essentially no feature extraction (aside from first differences) and the local series values are fused to time position through the time index. The initial representation of raw data is quite simple conceptually and operationally. Still, a tree-based ensemble can detect interactions in the space of the time index and time values and this is exploited to generate a high-dimensional codebook from the terminal nodes of the trees. Because the time index is included as an attribute, each MTS is learned to be segmented by time, or by the value of one of its attributes. The codebook is processed with a second ensemble where now implicit feature selection is exploited to handle the high-dimensional input. The constituent properties produce a distinctly different algorithm. Moreover, MTS with nominal and missing values are handled efficiently with tree learners. Experiments demonstrate the effectiveness of the proposed approach in terms of accuracy and computation times in a large collection multivariate (and univariate) datasets.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 400-422,codebook;decision tree;supervised learning;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Labeled directed acyclic graphs: a generalization of context-specific independence in directed graphical models,Johan Pensar (Åbo Akademi University);Henrik J. Nyman (Åbo Akademi University);Timo Koski (Royal Institute of Technology);Jukka Corander (Åbo Akademi University);,"2013394117,2071704220,2078390131,2045095944","We introduce a novel class of labeled directed acyclic graph (LDAG) models for finite sets of discrete variables. LDAGs generalize earlier proposals for allowing local structures in the conditional probability distribution of a node, such that unrestricted label sets determine which edges can be deleted from the underlying directed acyclic graph (DAG) for a given context. Several properties of these models are derived, including a generalization of the concept of Markov equivalence classes. Efficient Bayesian learning of LDAGs is enabled by introducing an LDAG-based factorization of the Dirichlet prior for the model parameters, such that the marginal likelihood can be calculated analytically. In addition, we develop a novel prior distribution for the model structures that can appropriately penalize a model for its labeling complexity. A non-reversible Markov chain Monte Carlo algorithm combined with a greedy hill climbing approach is used for illustrating the useful properties of LDAG models for both real and synthetic data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 503-533,acyclic dependencies principle;moral graph;directed acyclic word graph;bayesian network;markov chain monte carlo;graphical model;directed acyclic graph;discrete mathematics;combinatorics;machine learning;statistics;computer science;mathematics;
Inhibiting diffusion of complex contagions in social networks: theoretical and experimental results,"Chris J. Kuhlman (Virginia Bioinformatics Institute);V. S. Anil Kumar (Virginia Bioinformatics Institute);Madhav V. Marathe (Virginia Bioinformatics Institute);S. S. Ravi (University at Albany, SUNY);Daniel J. Rosenkrantz (University at Albany, SUNY);","1966158927,2137890755,2242145496,2150130480,250841333","We consider the problem of inhibiting undesirable contagions (e.g. rumors, spread of mob behavior) in social networks. Much of the work in this context has been carried out under the 1-threshold model, where diffusion occurs when a node has just one neighbor with the contagion. We study the problem of inhibiting more complex contagions in social networks where nodes may have thresholds larger than 1. The goal is to minimize the propagation of the contagion by removing a small number of nodes (called critical nodes) from the network. We study several versions of this problem and prove that, in general, they cannot even be efficiently approximated to within any factor $$\rho \ge 1$$ ? ? 1 , unless P = NP. We develop efficient and practical heuristics for these problems and carry out an experimental study of their performance on three well known social networks, namely epinions, wikipedia and slashdot. Our results show that these heuristics perform significantly better than five other known methods. We also establish an efficiently computable upper bound on the number of nodes to which a contagion can spread and evaluate this bound on many real and synthetic networks.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 423-465,blocking;social network;artificial intelligence;machine learning;statistics;
Using the minimum description length to discover the intrinsic cardinality and dimensionality of time series,"Bing Hu 0001 (University of California, Riverside);Thanawin Rakthanmanon (University of California, Riverside);Yuan Hao (University of California, Riverside);Scott Evans (GE Global Research);Stefano Lonardi (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2105942667,141314290,2169241512,2297125128,301234865,2170070822","Many algorithms for data mining or indexing time series data do not operate directly on the raw data, but instead they use alternative representations that include transforms, quantization, approximation, and multi-resolution abstractions. Choosing the best representation and abstraction level for a given task/dataset is arguably the most critical step in time series data mining. In this work, we investigate the problem of discovering the natural intrinsic representation model, dimensionality and alphabet cardinality of a time series. The ability to automatically discover these intrinsic features has implications beyond selecting the best parameters for particular algorithms, as characterizing data in such a manner is useful in its own right and an important sub-routine in algorithms for classification, clustering and outlier discovery. We will frame the discovery of these intrinsic features in the Minimal Description Length framework. Extensive empirical tests show that our method is simpler, more general and more accurate than previous methods, and has the important advantage of being essentially parameter-free.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 358-399,dimensionality reduction;time series;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
A framework for dissimilarity-based partitioning clustering of categorical time series,Manuel García-Magariños (University of A Coruña);José Antonio Vilar (University of A Coruña);,"2253515657,2506970049","A new framework for clustering categorical time series is proposed. In our approach, a dissimilarity-based partitioning method is considered. We suggest measuring the dissimilarity between two categorical time series by assessing both closeness of raw categorical values and proximity between dynamic behaviours. For the latter, a particular index computing the temporal correlation for categorical-valued sequences is introduced. The dissimilarity measure is then used to perform clustering by considering a modified version of the $$k$$ k -modes algorithm specifically designed to provide with a better characterization of the clusters. Furthermore, the problem of determining the number of clusters in this framework is analyzed by comparing a range of procedures, including a prediction-based resampling method properly adjusted to deal with our dissimilarity. Several graphical devices to interpret and visualize the temporal pattern of each cluster are also provided. Performance of this clustering methodology is studied on different simulated scenarios and its effectiveness is concluded by comparison with alternative approaches. Real data use is illustrated by analyzing navigation patterns of users visiting a specific news web site.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 466-502,correlation clustering;k means clustering;data visualization;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Exemplar-based low-rank matrix decomposition for data clustering,Lijun Wang (Wayne State University);Ming Dong (Wayne State University);,"2310094485,2618285502","Today, digital data is accumulated at a faster than ever speed in science, engineering, biomedicine, and real-world sensing. The ubiquitous phenomenon of massive data and sparse information imposes considerable challenges in data mining research. In this paper, we propose a theoretical framework, Exemplar-based low-rank sparse matrix decomposition (EMD), to cluster large-scale datasets. Capitalizing on recent advances in matrix approximation and decomposition, EMD can partition datasets with large dimensions and scalable sizes efficiently. Specifically, given a data matrix, EMD first computes a representative data subspace and a near-optimal low-rank approximation. Then, the cluster centroids and indicators are obtained through matrix decomposition, in which we require that the cluster centroids lie within the representative data subspace. By selecting the representative exemplars, we obtain a compact ""sketch""of the data. This makes the clustering highly efficient and robust to noise. In addition, the clustering results are sparse and easy for interpretation. From a theoretical perspective, we prove the correctness and convergence of the EMD algorithm, and provide detailed analysis on its efficiency, including running time and spatial requirements. Through extensive experiments performed on both synthetic and real datasets, we demonstrate the performance of EMD for clustering large-scale data.",2015,Data Mining and Knowledge Discovery volume 29 issue 2 pp 324-357,linear subspace;low rank approximation;matrix decomposition;cluster analysis;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Link prediction in heterogeneous data via generalized coupled tensor factorization,Beyza Ermiş (Boğaziçi University);Evrim Acar (University of Copenhagen);A. Taylan Cemgil (Boğaziçi University);,"1926755740,2250409171,1539996673","This study deals with missing link prediction, the problem of predicting the existence of missing connections between entities of interest. We approach the problem as filling in missing entries in a relational dataset represented by several matrices and multiway arrays, that will be simply called tensors. Consequently, we address the link prediction problem by data fusion formulated as simultaneous factorization of several observation tensors where latent factors are shared among each observation. Previous studies on joint factorization of such heterogeneous datasets have focused on a single loss function (mainly squared Euclidean distance or Kullback---Leibler-divergence) and specific tensor factorization models (CANDECOMP/PARAFAC and/or Tucker). However, in this paper, we study various alternative tensor models as well as loss functions including the ones already studied in the literature using the generalized coupled tensor factorization framework. Through extensive experiments on two real-world datasets, we demonstrate that (i) joint analysis of data from multiple sources via coupled factorization significantly improves the link prediction performance, (ii) selection of a suitable loss function and a tensor factorization model is crucial for accurate missing link prediction and loss functions that have not been studied for link prediction before may outperform the commonly-used loss functions, (iii) joint factorization of datasets can handle difficult cases, such as the cold start problem that arises when a new entity enters the dataset, and (iv) our approach is scalable to large-scale data.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 203-236,sensor fusion;missing data;machine learning;mathematical optimization;statistics;computer science;mathematics;
Summarizing numeric spatial data streams by trend cluster discovery,Annalisa Appice (University of Bari);Anna Ciampi (University of Bari);Donato Malerba (University of Bari);,"135896968,2209686676,2360612151","Advances in pervasive computing and sensor technologies have paved the way for the explosive living ubiquity of geo-physical data streams. The management of the massive and unbounded streams of sensor data produced poses several challenges, including the real-time application of summarization techniques, which should allow the storage and query of this amount of georeferenced and timestamped data in a server with limited memory. In order to face this issue, we have designed a summarization technique, called SUMATRA, which segments the stream into windows, computes summaries window-by-window and stores these summaries in a database. Trend clusters are discovered as summaries of each window. They are clusters of georeferenced data which vary according to a similar trend along the window time horizon. Several compression techniques are also investigated to derive a compact, but accurate representation of these trends for storage in the database. A learning strategy to automatically choose the best trend compression technique is designed. Finally, an in-network modality for tree-based trend cluster discovery is investigated in order to achieve an efficacious aggregation schema which drastically reduces the number of bytes transmitted across the network and maintains a longer network lifespan. This schema is mapped onto the routing structure of a tree-based WSN topology. Experiments performed with several data streams of real sensor networks assess the summarization capability, the accuracy and the efficiency of the proposed summarization schema.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 84-136,cluster analysis;automatic summarization;world wide web;data mining;database;machine learning;computer science;
Visualizing multi-dimensional decision boundaries in 2D,M. A. Migut (University of Amsterdam);Marcel Worring (University of Amsterdam);Cor J. Veenman (University of Amsterdam);,"677200669,286406747,696275742","In many applications experts need to make decisions based on the analysis of multi-dimensional data. Various classification models can support the decision making process. To obtain an intuitive understanding of the classification model, interactive visualizations are essential. We argue that this is best done by a series of interactive 2D scatterplots. In this paper, we define a set of characteristics of the multi-dimensional classification model that have to be visually represented in those scatterplots. Our proposed method presents those characteristics in a uniform manner for both linear and non-linear classification methods. We combine a visualization of a Voronoi based representation of multi-dimensional decision boundaries with visualization of the distances of the data elements to these boundaries. To allow the developer of the model to refine the threshold of the classification model and instantly observe the results, we use interactive decision point selection on a performance curve. Finally, we show how the combination of those techniques allows exploration of multi-dimensional decision boundaries in 2D.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 273-295,biological classification;decision engineering;visual analytics;knowledge extraction;data science;data mining;machine learning;computer science;
To tune or not to tune: rule evaluation for metaheuristic-based sequential covering algorithms,Bart Minnaert (Ghent University);David Martens (University of Antwerp);Manu De Backer (Ghent University);Bart Baesens (Katholieke Universiteit Leuven);,"1949701817,2605386389,2600097042,2061851337","While many papers propose innovative methods for constructing individual rules in separate-and-conquer rule learning algorithms, comparatively few study the heuristic rule evaluation functions used in these algorithms to ensure that the selected rules combine into a good rule set. Underestimating the impact of this component has led to suboptimal design choices in many algorithms. The main goal of this paper is to demonstrate the importance of heuristic rule evaluation functions by improving existing rule induction techniques and to provide guidelines for algorithm designers. We first select optimal heuristic rule learning functions for several metaheuristic-based algorithms and empirically compare the resulting heuristics across algorithms. This results in large and significant improvements of the predictive accuracy for two techniques. We find that despite the absence of a global optimal choice for all algorithms, good default choices can be shared across algorithms with similar search biases. A near-optimal selection can thus be found for new algorithms with minor experimental tuning. Lastly, a major contribution is made towards balancing a model's predictive accuracy with its comprehensibility. We construct a Pareto front of optimal solutions for this trade-off and show that gains in comprehensibility and/or accuracy are possible for the techniques studied. The parametrized heuristics enable users to select the desired balance as they offer a high flexibility when it comes to selecting the desired accuracy and comprehensibility in rule miners.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 237-272,evaluation function;heuristics;algorithm design;biological classification;global optimization;data mining;artificial intelligence;machine learning;computer science;
Very fast decision rules for classification in data streams,Petr Kosina (Masaryk University);João Gama (University of Porto);,"2067500809,2113857198","Data stream mining is the process of extracting knowledge structures from continuous, rapid data records. Many decision tasks can be formulated as stream mining problems and therefore many new algorithms for data streams are being proposed. Decision rules are one of the most interpretable and flexible models for predictive data mining. Nevertheless, few algorithms have been proposed in the literature to learn rule models for time-changing and high-speed flows of data. In this paper we present the very fast decision rules (VFDR) algorithm and discuss interesting extensions to the base version. All the proposed versions are one-pass and any-time algorithms. They work on-line and learn ordered or unordered rule sets. Algorithms designed to work with data streams should be able to detect changes and quickly adapt the decision model. In order to manage these situations we also present the adaptive extension (AVFDR) to detect changes in the process generating data and adapt the decision model. Detecting local drifts takes advantage of the modularity of the rule sets. In AVFDR, each individual rule monitors the evolution of performance metrics to detect concept drift. AVFDR prunes rules whenever a drift is signaled. This explicit change detection mechanism provides useful information about the dynamics of the process generating data, faster adaptation to changes and generates more compact rule sets. The experimental evaluation demonstrates that algorithms achieve competitive results in comparison to alternative methods and the adaptive methods are able to learn fast and compact rule sets from evolving streams.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 168-202,concept drift;biological classification;data stream mining;data mining;pattern recognition;machine learning;computer science;
Spatial Data Mining,Shashi Shekhar (University of Minnesota);Pusheng Zhang (Rutgers Business School – Newark and New Brunswick);Yan Huang (University of North Texas);,"2134885186,2161710027,2130510374",-,2015,Data Mining and Knowledge Discovery pp 837-854,spatial descriptive statistics;spatial relation;spatial analysis;categorical variable;anomaly detection;data mining;pattern recognition;machine learning;computer science;
Clustering categorical data in projected spaces,Mohamed Bouguessa (Université du Québec à Montréal);,1172064443,"The problem of clustering categorical data has been widely investigated and appropriate approaches have been proposed. However, the majority of the existing methods suffer from one or more of the following limitations: (1) difficulty detecting clusters of very low dimensionality embedded in high-dimensional spaces, (2) lack of an automatic mechanism for identifying relevant dimensions for each cluster, (3) lack of an outlier detection mechanism and (4) dependence on a set of parameters that need to be properly tuned. Most of the existing approaches are inadequate for dealing with these four issues in a unified framework. This motivates our effort to propose a fully automatic projected clustering algorithm for high-dimensional categorical data which is capable of facing the four aforementioned issues in a single framework. Our algorithm comprises two phases: (1) outlier handling and (2) clustering in projected spaces. The first phase of the algorithm is based on a probabilistic approach that exploits the beta mixture model to identify and eliminate outlier objects from a data set in a systematic way. In the second phase, the clustering process is based on a novel quality function that allows the identification of projected clusters of low dimensionality embedded in a high-dimensional space without any parameter setting by the user. The suitability of our proposal is demonstrated through empirical studies using synthetic and real data sets.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 3-38,k medians clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;mixture model;categorical variable;cluster analysis;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Sequential network change detection with its applications to ad impact relation analysis,Yu Hayashi (University of Tokyo);Kenji Yamanishi (University of Tokyo);,"2170494835,2302798453","We are concerned with the issue of tracking changes of variable dependencies from multivariate time series. Conventionally, this issue has been addressed in the batch scenario where the whole data set is given at once, and the change detection must be done in a retrospective way. This paper addresses this issue in a sequential scenario where multivariate data are sequentially input and the detection must be done in a sequential fashion. We propose a new method for sequential tracking of variable dependencies. In it we employ a Bayesian network as a representation of variable dependencies. The key ideas of our method are: (1) we extend the theory of dynamic model selection, which has been developed in the batch-learning scenario, into the sequential setting, and apply it to our issue, (2) we conduct the change detection sequentially using dynamic programming per a window where we employ the Hoeffding's bound to automatically determine the window size. We empirically demonstrate that our proposed method is able to perform change detection more efficiently than a conventional batch method. Further, we give a new framework of an application of variable dependency change detection, which we call Ad Impact Relation analysis (AIR). In it, we detect the time point when a commercial message advertisement has given an impact on the market and effectively visualize the impact through network changes. We employ real data sets to demonstrate the validity of AIR.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 137-167,bayesian network;information theory;data mining;real time computing;machine learning;statistics;computer science;
Ensemble anomaly detection from multi-resolution trajectory features,Shin Ando (Gunma University);Theerasak Thanomphongphan (Panasonic);Yoichi Seki (Gunma University);Einoshin Suzuki (Kyushu University);,"2607818638,2411340414,2141219499,2228069075","The numerical, sequential observation of behaviors, such as trajectories, have become an important subject for data mining and knowledge discovery research. Processing the raw observation into representative features of the behaviors involves an implicit choice of time-scale and resolution, which critically affect the final output of the mining techniques. The choice is associated with the parameters of data-processing, e.g., smoothing and segmentation, which unintuitively yet strongly influence the intrinsic structure of the numerical data. Data mining techniques generally require users to provide an appropriately processed input, but selecting a resolution is an arduous task that may require an expensive, manual examination of outputs between different settings. In this paper, we propose a novel ensemble framework for aggregating outcomes in different settings of scale and resolution parameters for an anomaly detection task. Such a task is difficult for existing ensemble approaches based on weighted combination because: (a) evaluating and weighing an output requires training samples of anomalies which are generally unavailable, (b) the detectability of anomalies can depend on the resolution, i.e., the distinction from normal instances may only be apparent within a small, selective range of parameters. In the proposed framework, predictions based on different resolutions are aggregated to construct meta-feature representations of the behavior instances. The meta-features provide the discriminative information for conducting a clustering-based anomaly detection. In the proposed framework, two interrelated tasks of the behavior analysis: processing the numerical data and discovering anomalous patterns, are addressed jointly, providing an intuitive alternative for a knowledge-intensive parameter selection. We also design an efficient clustering-based anomaly detection algorithm which reduces the computational burden of mining at multiple resolutions. We conduct an empirical study of the proposed framework using real-world trajectory data. It shows that the proposed framework achieves a significant improvement over the conventional ensemble approach.",2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 39-83,data mining;pattern recognition;machine learning;statistics;computer science;
Erratum to: Unsupervised interaction-preserving discretization of multivariate data,Hoang Vu Nguyen (Karlsruhe Institute of Technology);Emmanuel Müller (Karlsruhe Institute of Technology);Jilles Vreeken (Max Planck Society);Klemens Böhm (Karlsruhe Institute of Technology);,"2150437310,2112493600,1971070670,2245547659",-,2015,Data Mining and Knowledge Discovery volume 29 issue 1 pp 296-297,pattern recognition;machine learning;statistics;
Generalization-based privacy preservation and discrimination prevention in data publishing and mining,Sara Hajian;Josep Domingo-Ferrer (Rovira i Virgili University);Oriol Farràs (Polytechnic University of Catalonia);,"2088002537,275327080,1757798271","Living in the information society facilitates the automatic collection of huge amounts of data on individuals, organizations, etc. Publishing such data for secondary analysis (e.g. learning models and finding patterns) may be extremely useful to policy makers, planners, marketing analysts, researchers and others. Yet, data publishing and mining do not come without dangers, namely privacy invasion and also potential discrimination of the individuals whose data are published. Discrimination may ensue from training data mining models (e.g. classifiers) on data which are biased against certain protected groups (ethnicity, gender, political preferences, etc.). The objective of this paper is to describe how to obtain data sets for publication that are: (i) privacy-preserving; (ii) unbiased regarding discrimination; and (iii) as useful as possible for learning models and finding patterns. We present the first generalization-based approach to simultaneously offer privacy preservation and discrimination prevention. We formally define the problem, give an optimal algorithm to tackle it and evaluate the algorithm in terms of both general and specific data analysis metrics (i.e. various types of classifiers and rule induction algorithms). It turns out that the impact of our transformation on the quality of data is the same or only slightly higher than the impact of achieving just privacy preservation. In addition, we show how to extend our approach to different privacy models and anti-discrimination legal concepts.",2014,Data Mining and Knowledge Discovery volume 28 pp 1158-1188,generalization;privacy;data science;data mining;machine learning;statistics;computer science;
A peek into the black box: exploring classifiers by randomization,Andreas Henelius;Kai Puolamäki (Aalto University);Henrik Boström (Stockholm University);Lars Asker (Stockholm University);Panagiotis Papapetrou (Stockholm University);,"134249432,96415260,2082592554,2089372118,2000108749","Classifiers are often opaque and cannot easily be inspected to gain understanding of which factors are of importance. We propose an efficient iterative algorithm to find the attributes and dependencies used by any classifier when making predictions. The performance and utility of the algorithm is demonstrated on two synthetic and 26 real-world datasets, using 15 commonly used learning algorithms to generate the classifiers. The empirical investigation shows that the novel algorithm is indeed able to find groupings of interacting attributes exploited by the different classifiers. These groupings allow for finding similarities among classifiers for a single dataset as well as for determining the extent to which different classifiers exploit such interactions in general.",2014,Data Mining and Knowledge Discovery volume 28 pp 1503-1529,cascading classifiers;random subspace method;randomization;data mining;pattern recognition;machine learning;statistics;computer science;
Ontology of core data mining entities,Panče Panov;Larisa Soldatova (Brunel University London);Sašo Džeroski (University of Freiburg);,"1880876268,2037117905,1419022840","In this article, we present OntoDM-core, an ontology of core data mining entities. OntoDM-core defines the most essential data mining entities in a three-layered ontological structure comprising of a specification, an implementation and an application layer. It provides a representational framework for the description of mining structured data, and in addition provides taxonomies of datasets, data mining tasks, generalizations, data mining algorithms and constraints, based on the type of data. OntoDM-core is designed to support a wide range of applications/use cases, such as semantic annotation of data mining algorithms, datasets and results; annotation of QSAR studies in the context of drug discovery investigations; and disambiguation of terms in text mining. The ontology has been thoroughly assessed following the practices in ontology engineering, is fully interoperable with many domain resources and is easy to extend. OntoDM-core is available at http://www.ontodm.com .",2014,Data Mining and Knowledge Discovery volume 28 pp 1222-1265,molecule mining;ontology based data integration;upper ontology;ontology;biological activity;technology;concept mining;data stream mining;web mining;knowledge extraction;text mining;data science;information retrieval;data mining;machine learning;computer science;
Overlapping community detection in labeled graphs,Esther Galbrun (Boston University);Aristides Gionis (Helsinki Institute for Information Technology);Nikolaj Tatti (Helsinki Institute for Information Technology);,"2276244909,737311942,1367500519","We present a new approach for the problem of finding overlapping communities in graphs and social networks. Our approach consists of a novel problem definition and three accompanying algorithms. We are particularly interested in graphs that have labels on their vertices, although our methods are also applicable to graphs with no labels. Our goal is to find k communities so that the total edge density over all k communities is maximized. In the case of labeled graphs, we require that each community is succinctly described by a set of labels. This requirement provides a better understanding for the discovered communities. The proposed problem formulation leads to the discovery of vertex-overlapping and dense communities that cover as many graph edges as possible. We capture these properties with a simple objective function, which we solve by adapting efficient approximation algorithms for the generalized maximum-coverage problem and the densest-subgraph problem. Our proposed algorithm is a generic greedy scheme. We experiment with three variants of the scheme, obtained by varying the greedy step of finding a dense subgraph. We validate our algorithms by comparing with other state-of-the-art community-detection methods on a variety of performance measures. Our experiments confirm that our algorithms achieve results of high quality in terms of the reported measures, and are practical in terms of performance.",2014,Data Mining and Knowledge Discovery volume 28 issue 5 pp 1586-1610,indifference graph;maximal independent set;longest path problem;independent set;graph partition;social network;discrete mathematics;combinatorics;machine learning;mathematical optimization;mathematics;
Unsupervised interaction-preserving discretization of multivariate data,Hoang Vu Nguyen (Karlsruhe Institute of Technology);Emmanuel Müller (Karlsruhe Institute of Technology);Jilles Vreeken (Max Planck Society);Klemens Böhm (Karlsruhe Institute of Technology);,"2150437310,2112493600,1971070670,2245547659","Discretization is the transformation of continuous data into discrete bins. It is an important and general pre-processing technique, and a critical element of many data mining and data management tasks. The general goal is to obtain data that retains as much information in the continuous original as possible. In general, but in particular for exploratory tasks, a key open question is how to discretize multivariate data such that significant associations and patterns are preserved. That is exactly the problem we study in this paper. We propose IPD, an information-theoretic method for unsupervised discretization that focuses on preserving multivariate interactions. To this end, when discretizing a dimension, we consider the distribution of the data over all other dimensions. In particular, our method examines consecutive multivariate regions and combines them if (a) their multivariate data distributions are statistically similar, and (b) this merge reduces the MDL encoding cost. To assess the similarities, we propose $$ ID $$ I D , a novel interaction distance that does not require assuming a distribution and permits computation in closed form. We give an efficient algorithm for finding the optimal bin merge, as well as a fast well-performing heuristic. Empirical evaluation through pattern-based compression, outlier mining, and classification shows that by preserving interactions we consistently outperform the state of the art in both quality and speed.",2014,Data Mining and Knowledge Discovery volume 28 pp 1366-1397,discretization;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;
Approximating the crowd,Şeyda Ertekin (Massachusetts Institute of Technology);Cynthia Rudin (Massachusetts Institute of Technology);Haym Hirsh (Cornell University);,"2155137863,2141705163,2151078108","The problem of ""approximating the crowd"" is that of estimating the crowd's majority opinion by querying only a subset of it. Algorithms that approximate the crowd can intelligently stretch a limited budget for a crowdsourcing task. We present an algorithm, ""CrowdSense,"" that works in an online fashion where items come one at a time. CrowdSense dynamically samples subsets of the crowd based on an exploration/exploitation criterion. The algorithm produces a weighted combination of the subset's votes that approximates the crowd's opinion. We then introduce two variations of CrowdSense that make various distributional approximations to handle distinct crowd characteristics. In particular, the first algorithm makes a statistical independence approximation of the labelers for large crowds, whereas the second algorithm finds a lower bound on how often the current subcrowd agrees with the crowd's majority vote. Our experiments on CrowdSense and several baselines demonstrate that we can reliably approximate the entire crowd's vote by collecting opinions from a representative subset of the crowd.",2014,Data Mining and Knowledge Discovery volume 28 pp 1189-1221,crowdsourcing;internet privacy;data mining;machine learning;simulation;computer science;
Self-organizing maps by difference of convex functions optimization,Hoai An Le Thi (University of Lorraine);Manh Cuong Nguyen (University of Lorraine);,"2214160777,2160958807","We offer an efficient approach based on difference of convex functions (DC) optimization for self-organizing maps (SOM). We consider SOM as an optimization problem with a nonsmooth, nonconvex energy function and investigated DC programming and DC algorithm (DCA), an innovative approach in nonconvex optimization framework to effectively solve this problem. Furthermore an appropriate training version of this algorithm is proposed. The numerical results on many real-world datasets show the efficiency of the proposed DCA based algorithms on both quality of solutions and topographic maps.",2014,Data Mining and Knowledge Discovery volume 28 issue 28 pp 1336-1365,self organizing map;artificial intelligence;machine learning;mathematical optimization;computer science;mathematics;
Detecting localized homogeneous anomalies over spatio-temporal data,"Aditya Telang (IBM);P. Deepak (IBM);Salil Joshi (IBM);Prasad Deshpande (IBM);Ranjana Rajendran (University of California, Santa Cruz);","2310270527,2158000868,2106463510,2304487933,2223900279","The last decade has witnessed an unprecedented growth in availability of data having spatio-temporal characteristics. Given the scale and richness of such data, finding spatio-temporal patterns that demonstrate significantly different behavior from their neighbors could be of interest for various application scenarios such as--weather modeling, analyzing spread of disease outbreaks, monitoring traffic congestions, and so on. In this paper, we propose an automated approach of exploring and discovering such anomalous patterns irrespective of the underlying domain from which the data is recovered. Our approach differs significantly from traditional methods of spatial outlier detection, and employs two phases--(i) discovering homogeneous regions, and (ii) evaluating these regions as anomalies based on their statistical difference from a generalized neighborhood. We evaluate the quality of our approach and distinguish it from existing techniques via an extensive experimental evaluation.",2014,Data Mining and Knowledge Discovery volume 28 issue 5 pp 1480-1502,data science;data mining;statistics;
Classy: fast clustering streams of call-graphs,Orestis Kostakis (F-Secure);,2678330604,"An abstraction resilient to common malware obfuscation techniques is the call-graph. A call-graph is the representation of an executable file as a directed graph with labeled vertices, where the vertices correspond to functions and the edges to function calls. Unfortunately, most of the interesting graph comparison problems, including full-graph comparison and computing the largest common subgraph, belong to the $$NP$$ N P -hard class. This makes the study and use of graphs in large scale systems difficult. Existing work has focused only on offline clustering and has not addressed the issue of clustering streams of graphs. In this paper we present Classy, a scalable distributed system that clusters streams of large call-graphs for purposes including automated malware classification and facilitating malware analysts. Since algorithms aimed at clustering sets are not suitable for clustering streams of objects, we propose the use of a clustering algorithm that relies on the notion of candidate clusters and reference samples therein. We demonstrate via thorough experimentation that this approach yields results very close to the offline optimal. Graph similarity is determined by computing a graph edit distance (GED) of pairs of graphs using an adapted version of simulated annealing. Furthermore, we present a novel lower bound for the GED. We also study the problem of approximating statistics of clusters of graphs when the distances of only a fraction of all possible pairs have been computed. Finally, we present results and statistics from a real production-side system that has clustered and contains more than 0.8 million graphs.",2014,Data Mining and Knowledge Discovery volume 28 pp 1554-1585,indifference graph;graph operations;correlation clustering;graph product;malware;modular decomposition;fuzzy clustering;streams;cluster analysis;theoretical computer science;data mining;machine learning;computer science;
Leveraging the power of local spatial autocorrelation in geophysical interpolative clustering,Annalisa Appice (University of Bari);Donato Malerba (University of Bari);,"135896968,2360612151","Nowadays ubiquitous sensor stations are deployed worldwide, in order to measure several geophysical variables (e.g. temperature, humidity, light) for a growing number of ecological and industrial processes. Although these variables are, in general, measured over large zones and long (potentially unbounded) periods of time, stations cannot cover any space location. On the other hand, due to their huge volume, data produced cannot be entirely recorded for future analysis. In this scenario, summarization, i.e. the computation of aggregates of data, can be used to reduce the amount of produced data stored on the disk, while interpolation, i.e. the estimation of unknown data in each location of interest, can be used to supplement station records. We illustrate a novel data mining solution, named interpolative clustering, that has the merit of addressing both these tasks in time-evolving, multivariate geophysical applications. It yields a time-evolving clustering model, in order to summarize geophysical data and computes a weighted linear combination of cluster prototypes, in order to predict data. Clustering is done by accounting for the local presence of the spatial autocorrelation property in the geophysical data. Weights of the linear combination are defined, in order to reflect the inverse distance of the unseen data to each cluster geometry. The cluster geometry is represented through shape-dependent sampling of geographic coordinates of clustered stations. Experiments performed with several data collections investigate the trade-off between the summarization capability and predictive accuracy of the presented interpolative clustering algorithm.",2014,Data Mining and Knowledge Discovery volume 28 pp 1266-1313,k medians clustering;inverse distance weighting;data stream clustering;fuzzy clustering;clustering high dimensional data;spatial analysis;cluster analysis;data mining;machine learning;statistics;computer science;mathematics;
Learning about meetings,Been Kim (Massachusetts Institute of Technology);Cynthia Rudin (Massachusetts Institute of Technology);,"2634960625,2141705163","Most people participate in meetings almost every day, multiple times a day. The study of meetings is important, but also challenging, as it requires an understanding of social signals and complex interpersonal dynamics. Our aim in this work is to use a data-driven approach to the science of meetings. We provide tentative evidence that: (i) it is possible to automatically detect when during the meeting a key decision is taking place, from analyzing only the local dialogue acts, (ii) there are common patterns in the way social dialogue acts are interspersed throughout a meeting, (iii) at the time key decisions are made, the amount of time left in the meeting can be predicted from the amount of time that has passed, (iv) it is often possible to predict whether a proposal during a meeting will be accepted or rejected based entirely on the language (the set of persuasive words) used by the speaker.",2014,Data Mining and Knowledge Discovery volume 28 pp 1134-1157,artificial intelligence;
Invariant time-series factorization,Josif Grabocka (University of Hildesheim);Lars Schmidt-Thieme (University of Hildesheim);,"2064655889,78243962","Time-series analysis is an important domain of machine learning and a plethora of methods have been developed for the task. This paper proposes a new representation of time series, which in contrast to existing approaches, decomposes a time-series dataset into latent patterns and membership weights of local segments to those patterns. The process is formalized as a constrained objective function and a tailored stochastic coordinate descent optimization is applied. The time-series are projected to a new feature representation consisting of the sums of the membership weights, which captures frequencies of local patterns. Features from various sliding window sizes are concatenated in order to encapsulate the interaction of patterns from different sizes. The derived representation offers a set of features that boosts classification accuracy. Finally, a large-scale experimental comparison against 11 baselines over 43 real life datasets, indicates that the proposed method achieves state-of-the-art prediction accuracy results.",2014,Data Mining and Knowledge Discovery volume 28 pp 1455-1479,data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Uncovering the plot: detecting surprising coalitions of entities in multi-relational schemas,Hao Wu (Virginia Tech);Jilles Vreeken (Max Planck Society);Nikolaj Tatti (Aalto University);Naren Ramakrishnan (Virginia Tech);,"2305209292,1971070670,1367500519,2199255697","Many application domains such as intelligence analysis and cybersecurity require tools for the unsupervised identification of suspicious entities in multi-relational/network data. In particular, there is a need for automated semi-automated approaches to `uncover the plot', i.e., to detect non-obvious coalitions of entities bridging many types of relations. We cast the problem of detecting such suspicious coalitions and their connections as one of mining surprisingly dense and well-connected chains of biclusters over multi-relational data. With this as our goal, we model data by the Maximum Entropy principle, such that in a statistically well-founded way we can gauge the surprisingness of a discovered bicluster chain with respect to what we already know. We design an algorithm for approximating the most informative multi-relational patterns, and provide strategies to incrementally organize discovered patterns into the background model. We illustrate how our method is adept at discovering the hidden plot in multiple synthetic and real-world intelligence analysis datasets. Our approach naturally generalizes traditional attribute-based maximum entropy models for single relations, and further supports iterative, human-in-the-loop, knowledge discovery.",2014,Data Mining and Knowledge Discovery volume 28 pp 1398-1428,data science;data mining;machine learning;mathematics;
Preserving worker privacy in crowdsourcing,Hiroshi Kajino (University of Tokyo);Hiromi Arai;Hisashi Kashima (Kyoto University);,"2154833284,2706940766,2126337623","This paper proposes a crowdsourcing quality control method with worker-privacy preservation. Crowdsourcing allows us to outsource tasks to a number of workers. The results of tasks obtained in crowdsourcing are often low-quality due to the difference in the degree of skill. Therefore, we need quality control methods to estimate reliable results from low-quality results. In this paper, we point out privacy problems of workers in crowdsourcing. Personal information of workers can be inferred from the results provided by each worker. To formulate and to address the privacy problems, we define a worker-private quality control problem, a variation of the quality control problem that preserves privacy of workers. We propose a worker-private latent class protocol where a requester can estimate the true results with worker privacy preserved. The key ideas are decentralization of computation and introduction of secure computation. We theoretically guarantee the security of the proposed protocol and experimentally examine the computational efficiency and accuracy.",2014,Data Mining and Knowledge Discovery volume 28 pp 1314-1335,crowdsourcing;quality control;expectation maximization algorithm;internet privacy;computer security;data mining;machine learning;computer science;
Confidence bands for time series data,Jussi Korpela;Kai Puolamäki (Aalto University);Aristides Gionis (Helsinki Institute for Information Technology);,"2690002173,96415260,737311942","Simultaneous confidence intervals, or confidence bands, provide an intuitive description of the variability of a time series. Given a set of $$N$$ N time series of length $$M$$ M , we consider the problem of finding a confidence band that contains a $$(1-\alpha )$$ ( 1 - ? ) -fraction of the observations. We construct such confidence bands by finding the set of $$N\!\!-\!\!K$$ N - K time series whose envelope is minimized. We refer to this problem as the minimum width envelope problem. We show that the minimum width envelope problem is $$\mathbf {NP}$$ NP -hard, and we develop a greedy heuristic algorithm, which we compare to quantile- and distance-based confidence band methods. We also describe a method to find an effective confidence level $$\alpha _{\mathrm {eff}}$$ ? eff and an effective number of observations to remove $$K_{\mathrm {eff}}$$ K eff , such that the resulting confidence bands will keep the family-wise error rate below $$\alpha $$ ? . We evaluate our methods on synthetic and real datasets. We demonstrate that our method can be used to construct confidence bands with guaranteed family-wise error rate control, also when there is too little data for the quantile-based methods to work.",2014,Data Mining and Knowledge Discovery volume 28 pp 1530-1553,confidence and prediction bands;familywise error rate;time series;econometrics;mathematical optimization;statistics;mathematics;
Guest editors' introduction: special issue of the ECML/PKDD 2014 journal track,Toon Calders (Université libre de Bruxelles);Floriana Esposito (University of Bari);Eyke E. Hüllermeier (University of Paderborn);Rosa Meo (University of Turin);,"2064105222,2122401555,323026139,2117349166",-,2014,Data Mining and Knowledge Discovery volume 28 pp 1129-1133,-
Discovering bands from graphs,Nikolaj Tatti (Aalto University);,1367500519,"Discovering the underlying structure of a given graph is one of the fundamental goals in graph mining. Given a graph, we can often order vertices in a way that neighboring vertices have a higher probability of being connected to each other. This implies that the edges form a band around the diagonal in the adjacency matrix. Such structure may rise for example if the graph was created over time: each vertex had an active time interval during which the vertex was connected with other active vertices. The goal of this paper is to model this phenomenon. To this end, we formulate an optimization problem: given a graph and an integer $$K$$ K , we want to order graph vertices and partition the ordered adjacency matrix into $$K$$ K bands such that bands closer to the diagonal are more dense. We measure the goodness of a segmentation using the log-likelihood of a log-linear model, a flexible family of distributions containing many standard distributions. We divide the problem into two subproblems: finding the order and finding the bands. We show that discovering bands can be done in polynomial time with isotonic regression, and we also introduce a heuristic iterative approach. For discovering the order we use Fiedler order accompanied with a simple combinatorial refinement. We demonstrate empirically that our heuristic works well in practice.",2014,Data Mining and Knowledge Discovery volume 28 pp 1429-1454,neighbourhood;strength of a graph;complement graph;graph bandwidth;path graph;graph power;hypercube graph;wheel graph;graph energy;level structure;cycle graph;isotonic regression;distance regular graph;vertex;regular graph;adjacency matrix;degree;log linear model;connected component;independent set;graph partition;directed graph;discrete mathematics;combinatorics;machine learning;mathematical optimization;statistics;computer science;mathematics;
Classification of time series by shapelet transformation,Jon Hills (University of East Anglia);Jason Lines (University of East Anglia);Edgaras Baranauskas (University of East Anglia);James Mapp (University of East Anglia);Anthony Bagnall (University of East Anglia);,"2163379274,1984663852,2288538814,2112794204,2171856547","Time-series classification (TSC) problems present a specific challenge for classification algorithms: how to measure similarity between series. A shapelet is a time-series subsequence that allows for TSC based on local, phase-independent similarity in shape. Shapelet-based classification uses the similarity between a shapelet and a series as a discriminatory feature. One benefit of the shapelet approach is that shapelets are comprehensible, and can offer insight into the problem domain. The original shapelet-based classifier embeds the shapelet-discovery algorithm in a decision tree, and uses information gain to assess the quality of candidates, finding a new shapelet at each node of the tree through an enumerative search. Subsequent research has focused mainly on techniques to speed up the search. We examine how best to use the shapelet primitive to construct classifiers. We propose a single-scan shapelet algorithm that finds the best $$k$$ k shapelets, which are used to produce a transformed dataset, where each of the $$k$$ k features represent the distance between a time series and a shapelet. The primary advantages over the embedded approach are that the transformed data can be used in conjunction with any classifier, and that there is no recursive search for shapelets. We demonstrate that the transformed data, in conjunction with more complex classifiers, gives greater accuracy than the embedded shapelet tree. We also evaluate three similarity measures that produce equivalent results to information gain in less time. Finally, we show that by conducting post-transform clustering of shapelets, we can enhance the interpretability of the transformed data. We conduct our experiments on 29 datasets: 17 from the UCR repository, and 12 we provide ourselves.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 851-881,data mining;pattern recognition;machine learning;statistics;mathematics;
Behavior-based clustering and analysis of interestingness measures for association rule mining,Caroline V. Tew (Brigham Young University);Christophe G. Giraud-Carrier (Brigham Young University);Kesler W. Tanner (Brigham Young University);Scott H. Burton (Brigham Young University);,"2110479981,2181238288,2490434495,2154409865","A number of studies, theoretical, empirical, or both, have been conducted to provide insight into the properties and behavior of interestingness measures for association rule mining. While each has value in its own right, most are either limited in scope or, more importantly, ignore the purpose for which interestingness measures are intended, namely the ultimate ranking of discovered association rules. This paper, therefore, focuses on an analysis of the rule-ranking behavior of 61 well-known interestingness measures tested on the rules generated from 110 different datasets. By clustering based on ranking behavior, we highlight, and formally prove, previously unreported equivalences among interestingness measures. We also show that there appear to be distinct clusters of interestingness measures, but that there remain differences among clusters, confirming that domain knowledge is essential to the selection of an appropriate interestingness measure for a particular task and business objective.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 1004-1045,association rule learning;cluster analysis;data science;data mining;pattern recognition;machine learning;computer science;mathematics;
Feature selection for k-means clustering stability: theoretical analysis and an algorithm,Dimitrios Mavroeidis (IBM);Elena Marchiori (Radboud University Nijmegen);,"2715883754,1974086637","Stability of a learning algorithm with respect to small input perturbations is an important property, as it implies that the derived models are robust with respect to the presence of noisy features and/or data sample fluctuations. The qualitative nature of the stability property enhardens the development of practical, stability optimizing, data mining algorithms as several issues naturally arise, such as: how ""much"" stability is enough, or how can stability be effectively associated with intrinsic data properties. In the context of this work we take into account these issues and explore the effect of stability maximization in the continuous (PCA-based) k-means clustering problem. Our analysis is based on both mathematical optimization and statistical arguments that complement each other and allow for the solid interpretation of the algorithm's stability properties. Interestingly, we derive that stability maximization naturally introduces a tradeoff between cluster separation and variance, leading to the selection of features that have a high cluster separation index that is not artificially inflated by the features variance. The proposed algorithmic setup is based on a Sparse PCA approach, that selects the features that maximize stability in a greedy fashion. In our study, we also analyze several properties of Sparse PCA relevant to stability that promote Sparse PCA as a viable feature selection mechanism for clustering. The practical relevance of the proposed method is demonstrated in the context of cancer research, where we consider the problem of detecting potential tumor biomarkers using microarray gene expression data. The application of our method to a leukemia dataset shows that the tradeoff between cluster separation and variance leads to the selection of features corresponding to important biomarker genes. Some of them have relative low variance and are not detected without the direct optimization of stability in Sparse PCA based k-means. Apart from the qualitative evaluation, we have also verified our approach as a feature selection method for $$k$$ k -means clustering using four cancer research datasets. The quantitative empirical results illustrate the practical utility of our framework as a feature selection mechanism for clustering.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 918-960,sparse pca;cluster analysis;stability;feature selection;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Discovering episodes with compact minimal windows,Nikolaj Tatti (University of Antwerp);,1367500519,"Discovering the most interesting patterns is the key problem in the field of pattern mining. While ranking or selecting patterns is well-studied for itemsets it is surprisingly under-researched for other, more complex, pattern types. In this paper we propose a new quality measure for episodes. An episode is essentially a set of events with possible restrictions on the order of events. We say that an episode is significant if its occurrence is abnormally compact, that is, only few gap events occur between the actual episode events, when compared to the expected length according to the independence model. We can apply this measure as a post-pruning step by first discovering frequent episodes and then rank them according to this measure. In order to compute the score we will need to compute the mean and the variance according to the independence model. As a main technical contribution we introduce a technique that allows us to compute these values. Such a task is surprisingly complex and in order to solve it we develop intricate finite state machines that allow us to compute the needed statistics. We also show that asymptotically our score can be interpreted as a $$P$$ P value. In our experiments we demonstrate that despite its intricacy our ranking is fast: we can rank tens of thousands episodes in seconds. Our experiments with text data demonstrate that our measure ranks interpretable episodes high.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 1046-1077,statistical hypothesis testing;data mining;machine learning;statistics;mathematics;
Assessing the quality of multilevel graph clustering,François Queyroi (Centre national de la recherche scientifique);Maylis Delest (Centre national de la recherche scientifique);Jean-Marc Fédou (University of Nice Sophia Antipolis);Guy Melançon (Centre national de la recherche scientifique);,"2535913967,2040327210,2275399036,2238570106","""Lifting up"" a non-hierarchical approach to handle hierarchical clustering by iteratively applying the approach to hierarchically cluster a graph is a popular strategy. However, these lifted iterative strategies cannot reasonably guide the overall nesting process precisely because they fail to evaluate the very hierarchical character of the clustering they produce. In this study, we develop a criterion that can evaluate the quality of the subgraph hierarchy. The multilevel criterion we present and discuss in this paper generalizes a measure designed for a one-level (flat) graph clustering to take nesting of the clusters into account. We borrow ideas from standard techniques in algebraic combinatorics and exploit a variable $$q$$ q to keep track of the depth of clusters at which edges occur. Our multilevel measure relies on a recursive definition involving variable $$q$$ q outputting a one-variable polynomial. This paper examines archetypal examples as proofs-of-concept; these simple cases are useful in understanding how the multilevel measure actually works. We also apply this multilevel modularity to real world networks to demonstrate how it can be used to compare hierarchical clusterings of graphs.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 1107-1128,hierarchical clustering of networks;correlation clustering;clustering coefficient;fuzzy clustering;hierarchical clustering;discrete mathematics;combinatorics;data mining;machine learning;statistics;computer science;mathematics;
Multiple instance learning via Gaussian processes,Minyoung Kim (Seoul National University of Science and Technology);Fernando De la Torre (Robotics Institute);,"2305839646,2101970311","Multiple instance learning (MIL) is a binary classification problem with loosely supervised data where a class label is assigned only to a bag of instances indicating presence/absence of positive instances. In this paper we introduce a novel MIL algorithm using Gaussian processes (GP). The bag labeling protocol of the MIL can be effectively modeled by the sigmoid likelihood through the max function over GP latent variables. As the non-continuous max function makes exact GP inference and learning infeasible, we propose two approximations: the soft-max approximation and the introduction of witness indicator variables. Compared to the state-of-the-art MIL approaches, especially those based on the Support Vector Machine, our model enjoys two most crucial benefits: (i) the kernel parameters can be learned in a principled manner, thus avoiding grid search and being able to exploit a variety of kernel families with complex forms, and (ii) the efficient gradient search for kernel parameter learning effectively leads to feature selection to extract most relevant features while discarding noise. We demonstrate that our approaches attain superior or comparable performance to existing methods on several real-world MIL datasets including large-scale content-based image retrieval problems.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 1078-1106,gaussian process;instance based learning;data mining;pattern recognition;machine learning;statistics;mathematics;
Mining trajectories of moving dynamic spatio-temporal regions in sensor datasets,"Michael P. McGuire (Towson University);Vandana Pursnani Janeja (University of Maryland, Baltimore County);Aryya Gangopadhyay (University of Maryland, Baltimore County);","2311972679,2290556930,2132136220","When mining large spatio-temporal datasets, interesting patterns typically emerge where the dataset is most dynamic. These dynamic regions can be characterized by a location or set of locations that exhibit different behaviors from their neighbors and the time periods where these differences are most pronounced. Examples include locally intense areas of precipitation, anomalous sea surface temperature (SST) readings, and locally high levels of water pollution, to name a few. The focus of this paper is to find and analyze the pattern of moving dynamic spatio-temporal regions in large sensor datasets. The approach presented in this paper uses a measure of local spatial autocorrelation over time to determine how pronounced the difference in measurements taken at a spatial location is with those taken at neighboring locations. Dynamic regions are analyzed both globally, in the form of spatial locations and time periods that have the largest difference in local spatial autocorrelation, and locally, in the form of dynamic spatial locations for a particular time period or dynamic time periods for a particular spatial node. Then, moving dynamic regions are identified by determining the spatio-temporal connectivity, extent, and trajectory for groups of locally dynamic spatial locations whose position has shifted from one time period to the next. The efficacy of the approach is demonstrated on two real-world spatio-temporal datasets (a) NEXRAD precipitation and (b) SST. Promising results were found in discovering highly dynamic regions in these datasets depicting several real environmental phenomenon which are validated as actual events of interest.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 961-1003,trajectory;spatial dependence;data mining;
Semi-supervised projected model-based clustering,Luis Guerra (Technical University of Madrid);Concha Bielza (Technical University of Madrid);Víctor Robles (Technical University of Madrid);Pedro Larrañaga (Technical University of Madrid);,"2516459764,281976954,2175995654,2305155066","We present an adaptation of model-based clustering for partially labeled data, that is capable of finding hidden cluster labels. All the originally known and discoverable clusters are represented using localized feature subset selections (subspaces), obtaining clusters unable to be discovered by global feature subset selection. The semi-supervised projected model-based clustering algorithm (SeSProC) also includes a novel model selection approach, using a greedy forward search to estimate the final number of clusters. The quality of SeSProC is assessed using synthetic data, demonstrating its effectiveness, under different data conditions, not only at classifying instances with known labels, but also at discovering completely hidden clusters in different subspaces. Besides, SeSProC also outperforms three related baseline algorithms in most scenarios using synthetic and real data sets.",2014,Data Mining and Knowledge Discovery volume 28 issue 4 pp 882-917,determining the number of clusters in a data set;correlation clustering;constrained clustering;linear subspace;single linkage clustering;fuzzy clustering;clustering high dimensional data;cluster analysis;data mining;pattern recognition;machine learning;computer science;mathematics;
CID: an efficient complexity-invariant distance for time series,"Gustavo E. A. P. A. Batista (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);Oben Moses Tataw (University of California, Riverside);Vinícius M. A. de Souza (Spanish National Research Council);","2165222361,2170070822,1206031314,2158208077","The ubiquity of time series data across almost all human endeavors has produced a great interest in time series data mining in the last decade. While dozens of classification algorithms have been applied to time series, recent empirical evidence strongly suggests that simple nearest neighbor classification is exceptionally difficult to beat. The choice of distance measure used by the nearest neighbor algorithm is important, and depends on the invariances required by the domain. For example, motion capture data typically requires invariance to warping, and cardiology data requires invariance to the baseline (the mean value). Similarly, recent work suggests that for time series clustering, the choice of clustering algorithm is much less important than the choice of distance measure used.In this work we make a somewhat surprising claim. There is an invariance that the community seems to have missed, complexity invariance. Intuitively, the problem is that in many domains the different classes may have different complexities, and pairs of complex objects, even those which subjectively may seem very similar to the human eye, tend to be further apart under current distance measures than pairs of simple objects. This fact introduces errors in nearest neighbor classification, where some complex objects may be incorrectly assigned to a simpler class. Similarly, for clustering this effect can introduce errors by ""suggesting"" to the clustering algorithm that subjectively similar, but complex objects belong in a sparser and larger diameter cluster than is truly warranted.We introduce the first complexity-invariant distance measure for time series, and show that it generally produces significant improvements in classification and clustering accuracy. We further show that this improvement does not compromise efficiency, since we can lower bound the measure and use a modification of triangular inequality, thus making use of most existing indexing and data mining algorithms. We evaluate our ideas with the largest and most comprehensive set of time series mining experiments ever attempted in a single work, and show that complexity-invariant distance measures can produce improvements in classification and clustering in the vast majority of cases.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 634-669,fuzzy clustering;complexity;cluster analysis;time series;biological classification;consensus clustering;data mining;machine learning;statistics;computer science;mathematics;
Interesting pattern mining in multi-relational data,Eirini Spyropoulou (University of Bristol);Tijl De Bie (University of Bristol);Mario Boley (Fraunhofer Society);,"1981173521,2080198120,2074964178","Mining patterns from multi-relational data is a problem attracting increasing interest within the data mining community. Traditional data mining approaches are typically developed for single-table databases, and are not directly applicable to multi-relational data. Nevertheless, multi-relational data is a more truthful and therefore often also a more powerful representation of reality. Mining patterns of a suitably expressive syntax directly from this representation, is thus a research problem of great importance. In this paper we introduce a novel approach to mining patterns in multi-relational data. We propose a new syntax for multi-relational patterns as complete connected subsets of database entities. We show how this pattern syntax is generally applicable to multi-relational data, while it reduces to well-known tiles "" Geerts et al. (Proceedings of Discovery Science, pp 278---289, 2004)"" when the data is a simple binary or attribute-value table. We propose RMiner, a simple yet practically efficient divide and conquer algorithm to mine such patterns which is an instantiation of an algorithmic framework for efficiently enumerating all fixed points of a suitable closure operator ""Boley et al. (Theor Comput Sci 411(3):691---700, 2010)"". We show how the interestingness of patterns of the proposed syntax can conveniently be quantified using a general framework for quantifying subjective interestingness of patterns ""De Bie (Data Min Knowl Discov 23(3):407---446, 2011b)"". Finally, we illustrate the usefulness and the general applicability of our approach by discussing results on real-world and synthetic databases.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 808-849,data pre processing;data stream mining;data science;data mining;machine learning;algorithm;computer science;mathematics;
A time-efficient breadth-first level-wise lattice-traversal algorithm to discover rare itemsets,Luigi Troiano (University of Sannio);Giacomo Scibelli (University of Sannio);,"1922097447,2557454765","In this paper we face the problem of searching for rare itemsets. A main issue regards the strategy to adopt in exploring the power set lattice. Assuming a power set lattice with full set at the top and empty set at the bottom, the most of the algorithms adopt a bottom-up exploration, i.e. moving from smaller to larger sets. Although this approach is advantageous in the case of frequent itemsets, it might not be worth being used for rare itemsets, as they occur on the top of the lattice. We propose Rarity, a top-down breadth-first level-wise algorithm. Experimental results and comparisons are illustrated in order to provide a quantitative characterization of algorithm performances and complexity. Application to some UCI benchmark and real world datasets is provided. An algorithm parallelization is outlined. Experiments showed that this approach takes advantage of finding all rare non-zero itemsets in less time than other solutions, at expenses of higher memory demand.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 773-807,data science;data mining;algorithm;computer science;mathematics;
Subspace clustering of high-dimensional data: a predictive approach,Brian McWilliams (ETH Zurich);Giovanni Montana (Imperial College London);,"2171258051,2103014545","In several application domains, high-dimensional observations are collected and then analysed in search for naturally occurring data clusters which might provide further insights about the nature of the problem. In this paper we describe a new approach for partitioning such high-dimensional data. Our assumption is that, within each cluster, the data can be approximated well by a linear subspace estimated by means of a principal component analysis (PCA). The proposed algorithm, Predictive Subspace Clustering (PSC) partitions the data into clusters while simultaneously estimating cluster-wise PCA parameters. The algorithm minimises an objective function that depends upon a new measure of influence for PCA models. A penalised version of the algorithm is also described for carrying our simultaneous subspace clustering and variable selection. The convergence of PSC is discussed in detail, and extensive simulation results and comparisons to competing methods are presented. The comparative performance of PSC has been assessed on six real gene expression data sets for which PSC often provides state-of-art results.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 736-772,model selection;dna microarray;principal component analysis;cluster analysis;feature selection;data mining;pattern recognition;machine learning;statistics;computer science;
Para Miner: a generic pattern mining algorithm for multi-core architectures,Benjamin Negrevergne (University of Grenoble);Alexandre Termier (University of Grenoble);Marie-Christine Rousset (University of Grenoble);Jean-François Méhaut (University of Grenoble);,"2601608077,99113242,2048382749,2119380111","In this paper, we present Para Miner which is a generic and parallel algorithm for closed pattern mining. Para Miner is built on the principles of pattern enumeration in strongly accessible set systems. Its efficiency is due to a novel dataset reduction technique (that we call EL-reduction), combined with novel technique for performing dataset reduction in a parallel execution on a multi-core architecture. We illustrate Para Miner's genericity by using this algorithm to solve three different pattern mining problems: the frequent itemset mining problem, the mining frequent connected relational graphs problem and the mining gradual itemsets problem. In this paper, we prove the soundness and the completeness of Para Miner. Furthermore, our experiments show that despite being a generic algorithm, Para Miner can compete with specialized state of the art algorithms designed for the pattern mining problems mentioned above. Besides, for the particular problem of gradual itemset mining, Para Miner outperforms the state of the art algorithm by two orders of magnitude.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 593-633,data science;data mining;machine learning;computer science;
A reference based analysis framework for understanding anomaly detection techniques for symbolic sequences,Varun Chandola (Oak Ridge National Laboratory);Varun Mithal (University of Minnesota);Vipin Kumar (University of Minnesota);,"2096898130,184559979,2161062602","Anomaly detection for symbolic sequence data is a highly important area of research and is relevant in many application domains. While several techniques have been proposed within different domains, understanding of their relative strengths and weaknesses is limited. The key factor for this is that the nature of sequence data varies significantly across domains, and hence while a technique might perform well in its original domain, its performance is not guaranteed in a different domain. In this paper, we aim at establishing this understanding for a wide variety of anomaly detection techniques for symbolic sequences. We present a comparative evaluation of a large number of anomaly detection techniques on a variety of publicly available as well as artificially generated data sets. Many of these are existing techniques while some are slight variants and/or adaptations of traditional anomaly detection techniques to sequence data. The analysis presented in this paper allows relative comparison of the different anomaly detection techniques and highlights their strengths and weaknesses. We extend the reference based analysis (RBA) framework, which was originally proposed to analyze multivariate categorical data, to analyze symbolic sequence data sets. We visualize the symbolic sequences using the characteristics provided by the RBA framework and use the visualization to understand various aspects of the sequence data. We then use the characterization done by RBA to understand the performance of the different techniques. Using the RBA framework, we propose two anomaly detection techniques for symbolic sequences, which show consistently superior performance over the existing techniques across the different data sets.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 702-735,sequence;anomaly detection;bioinformatics;data mining;algorithm;computer science;
Generating multiple alternative clusterings via globally optimal subspaces,Xuan Hong Dang (Aarhus University);James Bailey (University of Melbourne);,"1964285635,2131557737","Clustering analysis is important for exploring complex datasets. Alternative clustering analysis is an emerging subfield involving techniques for the generation of multiple different clusterings, allowing the data to be viewed from different perspectives. We present two new algorithms for alternative clustering generation. A distinctive feature of our algorithms is their principled formulation of an objective function, facilitating the discovery of a subspace satisfying natural quality and orthogonality criteria. The first algorithm is a regularization of the Principal Components analysis method, whereas the second is a regularization of graph-based dimension reduction. In both cases, we demonstrate a globally optimum subspace solution can be computed. Experimental evaluation shows our techniques are able to equal or outperform a range of existing methods.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 569-592,cluster analysis;unsupervised learning;data mining;pattern recognition;machine learning;computer science;mathematics;
GA-TVRC-Het: genetic algorithm enhanced time varying relational classifier for evolving heterogeneous networks,İsmail Güneş (Istanbul Technical University);Zehra Çataltepe (Istanbul Technical University);Şule Gündüz-Öğüdücü (Istanbul Technical University);,"2409802969,2072118064,1568753271","Evolving heterogeneous networks, which contain different types of nodes and links that change over time, appear in many domains including protein–protein interactions, scientific collaborations, telecommunications. In this paper, we aim to discover temporal information from a heterogenous evolving network in order to improve node classification. We propose a framework, Genetic Algorithm enhanced Time Varying Relational Classifier for evolving Heterogeneous Networks (GA-TVRC-Het), to extract the effects of different relationship types in different time periods in the past. These effects are discovered adaptively by utilizing genetic algorithms. A relational classifier is extended as the classification method in order to be able to work with different types of nodes. The proposed framework is tested on two real world data sets. It is shown that using the optimal time effect improves the classification performance to a large extent. It is observed that the optimal time effect does not necessarily follow a certain functional trend, for example linear or exponential decay in time. Another observation is that the optimal time effect may be different for each type of interaction. Both observations reveal the reason why GA-TVRC-Het outperforms methods that rely on a predefined form of time effect or the same time effect for each link type.",2014,Data Mining and Knowledge Discovery volume 28 issue 3 pp 670-701,evolving networks;heterogeneous network;social network;genetic algorithm;data mining;artificial intelligence;machine learning;computer science;
Repeated labeling using multiple noisy labelers,Panagiotis G. Ipeirotis (New York University Stern School of Business);Foster J. Provost (New York University Stern School of Business);Victor S. Sheng (University of Central Arkansas);Jing Wang (New York University Stern School of Business);,"94049422,2158932634,2010535889,2710605715","This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling, and focus especially on the improvement of training labels for supervised induction of predictive models. With the outsourcing of small tasks becoming easier, for example via Amazon's Mechanical Turk, it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling, preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity, and show several main results. (i) Repeated-labeling can improve label quality and model quality, but not always. (ii) When labels are noisy, repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap. (iii) As soon as the cost of processing the unlabeled data is not free, even the simple strategy of labeling everything multiple times can give considerable advantage. (iv) Repeatedly labeling a carefully chosen set of points is generally preferable, and we present a set of robust techniques that combine different notions of uncertainty to select data points for which quality should be improved. The bottom line: the results show clearly that when labeling is not perfect, selective acquisition of multiple labels is a strategy that data miners should have in their repertoire; for certain label-quality/cost regimes, the benefit is substantial.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 402-441,sequence labeling;crowdsourcing;active learning;data pre processing;data quality;biological classification;data mining;artificial intelligence;machine learning;computer science;
Adaptive evolutionary clustering,Kevin S. Xu (University of Michigan);Mark Kliger (Omek Interactive);Alfred O. Hero (University of Michigan);,"2162920558,2308636426,2139712442","In many practical applications of clustering, the objects to be clustered evolve over time, and a clustering result is desired at each time step. In such applications, evolutionary clustering typically outperforms traditional static clustering by producing clustering results that reflect long-term trends while being robust to short-term variations. Several evolutionary clustering algorithms have recently been proposed, often by adding a temporal smoothness penalty to the cost function of a static clustering method. In this paper, we introduce a different approach to evolutionary clustering by accurately tracking the time-varying proximities between objects followed by static clustering. We present an evolutionary clustering framework that adaptively estimates the optimal smoothing parameter using shrinkage estimation, a statistical approach that improves a naive estimate using additional information. The proposed framework can be used to extend a variety of static clustering algorithms, including hierarchical, k-means, and spectral clustering, into evolutionary clustering algorithms. Experiments on synthetic and real data sets indicate that the proposed framework outperforms static clustering and existing evolutionary clustering algorithms in many scenarios.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 304-336,k medians clustering;flame clustering;hierarchical clustering of networks;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;spectral clustering;fuzzy clustering;k means clustering;clustering high dimensional data;hierarchical clustering;tracking;smoothing;adaptive filter;cluster analysis;consensus clustering;biclustering;conceptual clustering;data mining;pattern recognition;machine learning;computer science;mathematics;
Ensemble-based noise detection: noise ranking and visual performance evaluation,Borut Sluban;Dragan Gamberger;Nada Lavrač (University of Nova Gorica);,"2699865172,235901219,44897255","Noise filtering is most frequently used in data preprocessing to improve the accuracy of induced classifiers. The focus of this work is different: we aim at detecting noisy instances for improved data understanding, data cleaning and outlier identification. The paper is composed of three parts. The first part presents an ensemble-based noise ranking methodology for explicit noise and outlier identification, named Noise- Rank, which was successfully applied to a real-life medical problem as proven in domain expert evaluation. The second part is concerned with quantitative performance evaluation of noise detection algorithms on data with randomly injected noise. A methodology for visual performance evaluation of noise detection algorithms in the precision-recall space, named Viper, is presented and compared to standard evaluation practice. The third part presents the implementation of the NoiseRank and Viper methodologies in a web-based platform for composition and execution of data mining workflows. This implementation allows public accessibility of the developed approaches, repeatability and sharing of the presented experiments as well as the inclusion of web services enabling to incorporate new noise detection algorithms into the proposed noise detection and performance evaluation workflows.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 265-303,noise measurement;data science;data mining;machine learning;statistics;computer science;
G-Tries: a data structure for storing and finding subgraphs,Pedro Manuel Pinto Ribeiro (University of Porto);Fernando M. A. Silva (University of Porto);,"2145123184,2115144937","The ability to find and count subgraphs of a given network is an important non trivial task with multidisciplinary applicability. Discovering network motifs or computing graphlet signatures are two examples of methodologies that at their core rely precisely on the subgraph counting problem. Here we present the g-trie, a data-structure specifically designed for discovering subgraph frequencies. We produce a tree that encapsulates the structure of the entire graph set, taking advantage of common topologies in the same way a prefix tree takes advantage of common prefixes. This avoids redundancy in the representation of the graphs, thus allowing for both memory and computation time savings. We introduce a specialized canonical labeling designed to highlight common substructures and annotate the g-trie with a set of conditional rules that break symmetries, avoiding repetitions in the computation. We introduce a novel algorithm that takes as input a set of small graphs and is able to efficiently find and count them as induced subgraphs of a larger network. We perform an extensive empirical evaluation of our algorithms, focusing on efficiency and scalability on a set of diversified complex networks. Results show that g-tries are able to clearly outperform previously existing algorithms by at least one order of magnitude.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 337-377,complex network;data structure;theoretical computer science;discrete mathematics;combinatorics;data mining;machine learning;computer science;mathematics;
Exploiting domain knowledge to detect outliers,Fabrizio Angiulli (University of Calabria);Fabio Fassetti (University of Calabria);,"3821842,184075056","We present a novel definition of outlier whose aim is to embed an available domain knowledge in the process of discovering outliers. Specifically, given a background knowledge, encoded by means of a set of first-order rules, and a set of positive and negative examples, our approach aims at singling out the examples showing abnormal behavior. The technique here proposed is unsupervised, since there are no examples of normal or abnormal behavior, even if it has connections with supervised learning, since it is based on induction from examples. We provide a notion of compliance of a set of facts with respect to a background knowledge and a set of examples, which is exploited to detect the examples that prevent to improve generalization of the induced hypothesis. By testing compliance with respect to both the direct and the dual concept, we are able to distinguish among three kinds of abnormalities, that are irregular, anomalous, and outlier observations. This allows us to provide a finer characterization of the anomaly at hand and to single out subtle forms of anomalies. Moreover, we are also able to provide explanations for the abnormality of an observation which make intelligible the motivation underlying its exceptionality. We present both exact and approximate algorithms for mining abnormalities. The approximate algorithms improve execution time while guaranteeing good accuracy. Moreover, we discuss peculiarities of the novel approach, present examples of knowledge mined, analyze the scalability of the algorithms, and provide comparison with noise handling mechanisms and some alternative approaches.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 519-568,anomaly detection;concept learning;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Aggregative quantification for regression,Antonio Bella (Polytechnic University of Valencia);Cèsar Ferri (Polytechnic University of Valencia);José Hernández-Orallo (Polytechnic University of Valencia);María José Ramírez-Quintana (Polytechnic University of Valencia);,"2281550010,2170579254,309815489,678223772","The problem of estimating the class distribution (or prevalence) for a new unlabelled dataset (from a possibly different distribution) is a very common problem which has been addressed in one way or another in the past decades. This problem has been recently reconsidered as a new task in data mining, renamed quantification when the estimation is performed as an aggregation (and possible adjustment) of a single-instance supervised model (e.g., a classifier). However, the study of quantification has been limited to classification, while it is clear that this problem also appears, perhaps even more frequently, with other predictive problems, such as regression. In this case, the goal is to determine a distribution or an aggregated indicator of the output variable for a new unlabelled dataset. In this paper, we introduce a comprehensive new taxonomy of quantification tasks, distinguishing between the estimation of the whole distribution and the estimation of some indicators (summary statistics), for both classification and regression. This distinction is especially useful for regression, since predictions are numerical values that can be aggregated in many different ways, as in multi-dimensional hierarchical data warehouses. We focus on aggregative quantification for regression and see that the approaches borrowed from classification do not work. We present several techniques based on segmentation which are able to produce accurate estimations of the expected value and the distribution of the output variable. We show experimentally that these methods especially excel for the relevant scenarios where training and test distributions dramatically differ.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 475-518,segmentation;distribution;econometrics;data mining;statistics;mathematics;
Affinity-driven blog cascade analysis and prediction,Hui Li (Xidian University);Sourav S Bhowmick (Nanyang Technological University);Aixin Sun (Nanyang Technological University);Jiangtao Cui (Xidian University);,"2617926336,2168903744,2124989948,2119745525","Information propagation within the blogosphere is of much importance in implementing policies, marketing research, launching new products, and other applications. In this paper, we take a microscopic view of the information propagation pattern in blogosphere by investigating blog cascade affinity. A blog cascade is a group of posts linked together discussing about the same topic, and cascade affinity refers to the phenomenon of a blog's inclination to join a specific cascade. We identify and analyze an array of macroscopic and microscopic content-oblivious features that may affect a blogger's cascade joining behavior and utilize these features to predict cascade affinity of blogs. Based on these features, we present two non-probabilistic and probabilistic strategies, namely support vector machine (SVM) classification-based approach and Bipartite Markov Random Field-based (BiMRF) approach, respectively, to predict the probability of blogs' affinity to a cascade and rank them accordingly. Evaluated on a real dataset consisting of 873,496 posts, our experimental results demonstrate that our prediction strategy can generate high quality results ( $$F1$$ -measure of 72.5 % for SVM and 71.1 % for BiMRF) comparing with the approaches using traditional or singular features only such as elapsed time, number of participants which is around 11.2 and 8.9 %, respectively. Our experiments also showed that among all features identified, the number of quasi-friends is the most important factor affecting bloggers' inclination to join cascades.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 442-474,information flow;social network;marketing research;data science;data mining;artificial intelligence;machine learning;
Conditional ordinal random fields for structured ordinal-valued label prediction,Minyoung Kim (Seoul National University of Science and Technology);,2305839646,"Predicting labels of structured data such as sequences or images is a very important problem in statistical machine learning and data mining. The conditional random field (CRF) is perhaps one of the most successful approaches for structured label prediction via conditional probabilistic modeling. In such models, it is traditionally assumed that each label is a random variable from a nominal category set (e.g., class categories) where all categories are symmetric and unrelated from one another. In this paper we consider a different situation of ordinal-valued labels where each label category bears a particular meaning of preference or order. This setup fits many interesting problems/datasets for which one is interested in predicting labels that represent certain degrees of intensity or relevance. We propose a fairly intuitive and principled CRF-like model that can effectively deal with the ordinal-scale labels within an underlying correlation structure. Unlike standard log-linear CRFs, learning the proposed model incurs non-convex optimization. However, the new model can be learned accurately using efficient gradient search. We demonstrate the improved prediction performance achieved by the proposed model on several intriguing sequence/image label prediction tasks.",2014,Data Mining and Knowledge Discovery volume 28 issue 2 pp 378-401,structured prediction;ordinal regression;conditional random field;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
"Local outlier detection reconsidered: a generalized view on locality with applications to spatial, video, and network outlier detection",Erich Schubert (Ludwig Maximilian University of Munich);Arthur Zimek (University of Alberta);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);,"2011689237,242745652,1919135125","Outlier detection research has been seeing many new algorithms every year that often appear to be only slightly different from existing methods along with some experiments that show them to ""clearly outperform"" the others. However, few approaches come along with a clear analysis of existing methods and a solid theoretical differentiation. Here, we provide a formalized method of analysis to allow for a theoretical comparison and generalization of many existing methods. Our unified view improves understanding of the shared properties and of the differences of outlier detection models. By abstracting the notion of locality from the classic distance-based notion, our framework facilitates the construction of abstract methods for many special data types that are usually handled with specialized algorithms. In particular, spatial neighborhood can be seen as a special case of locality. Here we therefore compare and generalize approaches to spatial outlier detection in a detailed manner. We also discuss temporal data like video streams, or graph data such as community networks. Since we reproduce results of specialized approaches with our general framework, and even improve upon them, our framework provides reasonable baselines to evaluate the true merits of specialized approaches. At the same time, seeing spatial outlier detection as a special case of local outlier detection, opens up new potentials for analysis and advancement of methods.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 190-237,data mining;machine learning;statistics;computer science;
On constrained spectral clustering and its applications,"Xiang Wang (University of California, Davis);Buyue Qian (University of California, Davis);Ian Davidson (University of California, Davis);","2099725100,2306481588,2560595684","Constrained clustering has been well-studied for algorithms such as K-means and hierarchical clustering. However, how to satisfy many constraints in these algorithmic settings has been shown to be intractable. One alternative to encode many constraints is to use spectral clustering, which remains a developing area. In this paper, we propose a flexible framework for constrained spectral clustering. In contrast to some previous efforts that implicitly encode Must-Link (ML) and Cannot-Link (CL) constraints by modifying the graph Laplacian or constraining the underlying eigenspace, we present a more natural and principled formulation, which explicitly encodes the constraints as part of a constrained optimization problem. Our method offers several practical advantages: it can encode the degree of belief in ML and CL constraints; it guarantees to lower-bound how well the given constraints are satisfied using a user-specified threshold; it can be solved deterministically in polynomial time through generalized eigendecomposition. Furthermore, by inheriting the objective function from spectral clustering and encoding the constraints explicitly, much of the existing analysis of unconstrained spectral clustering techniques remains valid for our formulation. We validate the effectiveness of our approach by empirical results on both artificial and real datasets. We also demonstrate an innovative use of encoding large number of constraints: transfer learning via constraints.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 1-30,brown clustering;canopy clustering algorithm;correlation clustering;constrained clustering;cure data clustering algorithm;transfer of learning;spectral clustering;fuzzy clustering;graph partition;clustering high dimensional data;cluster analysis;combinatorics;data mining;machine learning;mathematical optimization;computer science;mathematics;
Training and assessing classification rules with imbalanced data,Giovanna Menardi (University of Padua);Nicola Torelli (University of Trieste);,"2044485101,2085381725","The problem of modeling binary responses by using cross-sectional data has been addressed with a number of satisfying solutions that draw on both parametric and nonparametric methods. However, there exist many real situations where one of the two responses (usually the most interesting for the analysis) is rare. It has been largely reported that this class imbalance heavily compromises the process of learning, because the model tends to focus on the prevalent class and to ignore the rare events. However, not only the estimation of the classification model is affected by a skewed distribution of the classes, but also the evaluation of its accuracy is jeopardized, because the scarcity of data leads to poor estimates of the model's accuracy. In this work, the effects of class imbalance on model training and model assessing are discussed. Moreover, a unified and systematic framework for dealing with the problem of imbalanced classification is proposed, based on a smoothed bootstrap re-sampling technique. The proposed technique is founded on a sound theoretical basis and an extensive empirical study shows that it outperforms the main other remedies to face imbalanced learning problems.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 92-122,kernel density estimation;data mining;pattern recognition;machine learning;statistics;mathematics;
Anomaly detection in large-scale data stream networks,Duc-Son Pham (Curtin University);Svetha Venkatesh (Deakin University);Mihai Lazarescu (Curtin University);Saha Budhaditya (Deakin University);,"2131203824,2146461601,1974154379,2043280991","This paper addresses the anomaly detection problem in large-scale data mining applications using residual subspace analysis. We are specifically concerned with situations where the full data cannot be practically obtained due to physical limitations such as low bandwidth, limited memory, storage, or computing power. Motivated by the recent compressed sensing (CS) theory, we suggest a framework wherein random projection can be used to obtained compressed data, addressing the scalability challenge. Our theoretical contribution shows that the spectral property of the CS data is approximately preserved under a such a projection and thus the performance of spectral-based methods for anomaly detection is almost equivalent to the case in which the raw data is completely available. Our second contribution is the construction of the framework to use this result and detect anomalies in the compressed data directly, thus circumventing the problems of data acquisition in large sensor networks. We have conducted extensive experiments to detect anomalies in network and surveillance applications on large datasets, including the benchmark PETS 2007 and 83 GB of real footage from three public train stations. Our results show that our proposed method is scalable, and importantly, its performance is comparable to conventional methods for anomaly detection when the complete data is available.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 145-189,compressed sensing;spectral method;anomaly detection;data science;data mining;machine learning;computer science;
A statistical significance testing approach to mining the most informative set of patterns,Jefrey Lijffijt (Aalto University);Panagiotis Papapetrou (Aalto University);Kai Puolamäki (Aalto University);,"115479936,2000108749,96415260","Hypothesis testing using constrained null models can be used to compute the significance of data mining results given what is already known about the data. We study the novel problem of finding the smallest set of patterns that explains most about the data in terms of a global p value. The resulting set of patterns, such as frequent patterns or clusterings, is the smallest set that statistically explains the data. We show that the newly formulated problem is, in its general form, NP-hard and there exists no efficient algorithm with finite approximation ratio. However, we show that in a special case a solution can be computed efficiently with a provable approximation ratio. We find that a greedy algorithm gives good results on real data and that, using our approach, we can formulate and solve many known data-mining tasks. We demonstrate our method on several data mining tasks. We conclude that our framework is able to identify in various settings a small set of patterns that statistically explains the data and to formulate data mining problems in the terms of statistical significance.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 238-263,information system;time series;data science;data mining;machine learning;statistics;computer science;
Hierarchical co-clustering: off-line and incremental approaches,Ruggero G. Pensa (University of Turin);Dino Ienco (Centre national de la recherche scientifique);Rosa Meo (University of Turin);,"108207645,2288551980,2117349166","Clustering data is challenging especially for two reasons. The dimensionality of the data is often very high which makes the cluster interpretation hard. Moreover, with high-dimensional data the classic metrics fail in identifying the real similarities between objects. The second challenge is the evolving nature of the observed phenomena which makes the datasets accumulating over time. In this paper we show how we propose to solve these problems. To tackle the high-dimensionality problem, we propose to apply a co-clustering approach on the dataset that stores the occurrence of features in the observed objects. Co-clustering computes a partition of objects and a partition of features simultaneously. The novelty of our co-clustering solution is that it arranges the clusters in a hierarchical fashion, and it consists of two hierarchies: one on the objects and one on the features. The two hierarchies are coupled because the clusters at a certain level in one hierarchy are coupled with the clusters at the same level of the other hierarchy and form the co-clusters. Each cluster of one of the two hierarchies thus provides insights on the clusters of the other hierarchy. Another novelty of the proposed solution is that the number of clusters is possibly unlimited. Nevertheless, the produced hierarchies are still compact and therefore more readable because our method allows multiple splits of a cluster at the lower level. As regards the second challenge, the accumulating nature of the data makes the datasets intractably huge over time. In this case, an incremental solution relieves the issue because it partitions the problem. In this paper we introduce an incremental version of our algorithm of hierarchical co-clustering. It starts from an intermediate solution computed on the previous version of the data and it updates the co-clustering results considering only the added block of data. This solution has the merit of speeding up the computation with respect to the original approach that would recompute the result on the overall dataset. In addition, the incremental algorithm guarantees approximately the same answer than the original version, but it saves much computational load. We validate the incremental approach on several high-dimensional datasets and perform an accurate comparison with both the original version of our algorithm and with the state of the art competitors as well. The obtained results open the way to a novel usage of the co-clustering algorithms in which it is advantageous to partition the data into several blocks and process them incrementally thus ""incorporating"" data gradually into an on-going co-clustering solution.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 31-64,hierarchical clustering;biclustering;data mining;machine learning;algorithm;computer science;
The effect of homogeneity on the computational complexity of combinatorial data anonymization,Robert Bredereck (Technical University of Berlin);André Nichterlein (Technical University of Berlin);Rolf Niedermeier (Technical University of Berlin);Geevarghese Philip (Max Planck Society);,"2081061368,1976620569,1992934687,2134470666","A matrix M is said to be k-anonymous if for each row r in M there are at least k ? 1 other rows in M which are identical to r. The NP-hard k-Anonymity problem asks, given an n × m-matrix M over a fixed alphabet and an integer s > 0, whether M can be made k-anonymous by suppressing (blanking out) at most s entries. Complementing previous work, we introduce two new ""data-driven"" parameterizations for k-Anonymity--the number t in of different input rows and the number t out of different output rows--both modeling aspects of data homogeneity. We show that k-Anonymity is fixed-parameter tractable for the parameter t in , and that it is NP-hard even for t out = 2 and alphabet size four. Notably, our fixed-parameter tractability result implies that k-Anonymity can be solved in linear time when t in is a constant. Our computational hardness results also extend to the related privacy problems p-Sensitivity and l-Diversity, while our fixed-parameter tractability results extend to p-Sensitivity and the usage of domain generalization hierarchies, where the entries are replaced by more general data instead of being completely suppressed.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 65-91,discrete mathematics;combinatorics;machine learning;statistics;algorithm;mathematics;
Generalized Dirichlet priors for Naïve Bayesian classifiers with multinomial models in document classification,Tzu-Tsung Wong (National Cheng Kung University);,2710126452,"The generalized Dirichlet distribution has been shown to be a more appropriate prior than the Dirichlet distribution for naive Bayesian classifiers. When the dimension of a generalized Dirichlet random vector is large, the computational effort for calculating the expected value of a random variable can be high. In document classification, the number of distinct words that is the dimension of a prior for naive Bayesian classifiers is generally more than ten thousand. Generalized Dirichlet priors can therefore be inapplicable for document classification from the viewpoint of computational efficiency. In this paper, some properties of the generalized Dirichlet distribution are established to accelerate the calculation of the expected values of random variables. Those properties are then used to construct noninformative generalized Dirichlet priors for naive Bayesian classifiers with multinomial models. Our experimental results on two document sets show that generalized Dirichlet priors can achieve a significantly higher prediction accuracy and that the computational efficiency of naive Bayesian classifiers is preserved.",2014,Data Mining and Knowledge Discovery volume 28 issue 1 pp 123-144,categorical distribution;dirichlet multinomial distribution;generalized dirichlet distribution;hierarchical dirichlet process;dirichlet distribution;latent dirichlet allocation;pattern recognition;machine learning;statistics;mathematics;
Discovery of extreme events-related communities in contrasting groups of physical system networks,Zhengzhang Chen (North Carolina State University);William Hendrix (North Carolina State University);Hang Guan (Zhejiang University);Isaac K. Tetteh (North Carolina State University);Alok N. Choudhary (Northwestern University);Fredrick H. M. Semazzi (North Carolina State University);Nagiza F. Samatova (North Carolina State University);,"2132666618,2634477385,2109358033,2000101239,2147783234,1774763090,1984246357","The latent behavior of a physical system that can exhibit extreme events such as hurricanes or rainfalls, is complex. Recently, a very promising means for studying complex systems has emerged through the concept of complex networks. Networks representing relationships between individual objects usually exhibit community dynamics. Conventional community detection methods mainly focus on either mining frequent subgraphs in a network or detecting stable communities in time-varying networks. In this paper, we formulate a novel problem--detection of predictive and phase-biased communities in contrasting groups of networks, and propose an efficient and effective machine learning solution for finding such anomalous communities. We build different groups of networks corresponding to different system's phases, such as higher or low hurricane activity, discover phase-related system components as seeds to help bound the search space of community generation in each network, and use the proposed contrast-based technique to identify the changing communities across different groups. The detected anomalous communities are hypothesized (1) to play an important role in defining the target system's state(s) and (2) to improve the predictive skill of the system's states when used collectively in the ensemble of predictive models. When tested on the two important extreme event problems--identification of tropical cyclone-related and of African Sahel rainfall-related climate indices--our algorithm demonstrated the superior performance in terms of various skill and robustness metrics, including 8---16 % accuracy increase, as well as physical interpretability of detected communities. The experimental results also show the efficiency of our algorithm on synthetic datasets.",2013,Data Mining and Knowledge Discovery volume 27 issue 2 pp 225-258,qualitative comparative analysis;data science;data mining;machine learning;
Cluster ensemble selection based on relative validity indexes,Murilo Coelho Naldi (University of the Fraser Valley);André C. P. L. F. Carvalho (University of São Paulo);Ricardo J. G. B. Campello (University of São Paulo);,"2345606854,2250248997,2043417111","Cluster ensemble aims at producing high quality data partitions by combining a set of different partitions produced from the same data. Diversity and quality are claimed to be critical for the selection of the partitions to be combined. To enhance these characteristics, methods can be applied to evaluate and select a subset of the partitions that provide ensemble results similar or better than those based on the full set of partitions. Previous studies have shown that this selection can significantly improve the quality of the final partitions. For such, an appropriate evaluation of the candidate partitions to be combined must be performed. In this work, several methods to evaluate and select partitions are investigated, most of them based on relative clustering validity indexes. These indexes select the partitions with the highest quality to participate in the ensemble. However, each relative index can be more suitable for particular data conformations. Thus, distinct relative indexes are combined to create a final evaluation that tends to be robust to changes in the application scenario, as the majority of the combined indexes may compensate the poor performance of some individual indexes. We also investigate the impact of the diversity among partitions used for the ensemble. A comparative evaluation of results obtained from an extensive collection of experiments involving state-of-the-art methods and statistical tests is presented. Based on the obtained results, a practical design approach is proposed to support cluster ensemble selection. This approach was successfully applied to real public domain data sets.",2013,Data Mining and Knowledge Discovery volume 27 issue 2 pp 259-289,combination;evaluation;data mining;machine learning;statistics;mathematics;
How to alternatize a clustering algorithm,"M. Shahriar Hossain (Virginia State University);Naren Ramakrishnan (Virginia Tech);Ian Davidson (University of California, Davis);Layne T. Watson (Virginia Tech);","2120864034,2199255697,2560595684,2147592994","Given a clustering algorithm, how can we adapt it to find multiple, nonredundant, high-quality clusterings? We focus on algorithms based on vector quantization and describe a framework for automatic `alternatization' of such algorithms. Our framework works in both simultaneous and sequential learning formulations and can mine an arbitrary number of alternative clusterings. We demonstrate its applicability to various clustering algorithms--k-means, spectral clustering, constrained clustering, and co-clustering--and effectiveness in mining a variety of datasets.",2013,Data Mining and Knowledge Discovery volume 27 issue 2 pp 193-224,flame clustering;hierarchical clustering of networks;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;fuzzy clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;biclustering;conceptual clustering;data mining;pattern recognition;machine learning;computer science;mathematics;
Using coarse information for real valued prediction,Amit Dhurandhar (IBM);,2061123877,"In domains such as consumer products and manufacturing amongst others, we have problems that warrant the prediction of a continuous target. Besides the usual set of explanatory attributes, we may also have exact (or approximate) estimates of aggregated targets, which are the sums of disjoint sets of individual targets that we are trying to predict. The question now becomes can we use these aggregated targets, which are a coarser piece of information, to improve the quality of predictions of the individual targets? In this paper, we provide a simple yet provable way of accomplishing this. In particular, given predictions from any regression model of the target on the test data, we elucidate a provable method for improving these predictions in terms of mean squared error, given exact (or accurate enough) information of the aggregated targets. These estimates of the aggregated targets may be readily available or obtained--through multilevel regression--at different levels of granularity. Based on the proof of our method we suggest a criterion for choosing the appropriate level. Moreover, in addition to estimates of the aggregated targets, if we have exact (or approximate) estimates of the mean and variance of the target distribution, then based on our general strategy we provide an optimal way of incorporating this information so as to further improve the quality of predictions of the individual targets. We then validate the results and our claims by conducting experiments on synthetic and real industrial data obtained from diverse domains.",2013,Data Mining and Knowledge Discovery volume 27 issue 2 pp 167-192,hierarchy;regression;econometrics;data mining;statistics;mathematics;
A visual analytics framework for spatio-temporal analysis and modelling,Natalia V. Andrienko (Fraunhofer Society);Gennady L. Andrienko (Fraunhofer Society);,"1983982202,237265413","To support analysis and modelling of large amounts of spatio-temporal data having the form of spatially referenced time series (TS) of numeric values, we combine interactive visual techniques with computational methods from machine learning and statistics. Clustering methods and interactive techniques are used to group TS by similarity. Statistical methods for TS modelling are then applied to representative TS derived from the groups of similar TS. The framework includes interactive visual interfaces to a library of modelling methods supporting the selection of a suitable method, adjustment of model parameters, and evaluation of the models obtained. The models can be externally stored, communicated, and used for prediction and in further computational analyses. From the visual analytics perspective, the framework suggests a way to externalize spatio-temporal patterns emerging in the mind of the analyst as a result of interactive visual analysis: the patterns are represented in the form of computer-processable and reusable models. From the statistical analysis perspective, the framework demonstrates how TS analysis and modelling can be supported by interactive visual interfaces, particularly, in a case of numerous TS that are hard to analyse individually. From the application perspective, the framework suggests a way to analyse large numbers of spatial TS with the use of well-established statistical methods for TS analysis.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 55-83,interactive visual analysis;cluster analysis;time series;visual analytics;data science;data mining;machine learning;statistics;computer science;
A regularized graph layout framework for dynamic network visualization,Kevin S. Xu (University of Michigan);Mark Kliger (Omek Interactive);Alfred O. Hero (University of Michigan);,"2162920558,2308636426,2139712442","Many real-world networks, including social and information networks, are dynamic structures that evolve over time. Such dynamic networks are typically visualized using a sequence of static graph layouts. In addition to providing a visual representation of the network structure at each time step, the sequence should preserve the mental map between layouts of consecutive time steps to allow a human to interpret the temporal evolution of the network. In this paper, we propose a framework for dynamic network visualization in the on-line setting where only present and past graph snapshots are available to create the present layout. The proposed framework creates regularized graph layouts by augmenting the cost function of a static graph layout algorithm with a grouping penalty, which discourages nodes from deviating too far from other nodes belonging to the same group, and a temporal penalty, which discourages large node movements between consecutive time steps. The penalties increase the stability of the layout sequence, thus preserving the mental map. We introduce two dynamic layout algorithms within the proposed framework, namely dynamic multidimensional scaling and dynamic graph Laplacian layout. We apply these algorithms on several data sets to illustrate the importance of both grouping and temporal regularization for producing interpretable visualizations of dynamic networks.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 84-116,graph bandwidth;mental mapping;random geometric graph;dynamic network analysis;graph;laplacian matrix;regularization;multidimensional scaling;visualization;theoretical computer science;data mining;machine learning;mathematical optimization;computer science;
Preface: Intelligent interactive data visualization,Barbara Hammer (Citec);Daniel A. Keim (University of Konstanz);Neil D. Lawrence (University of Sheffield);Guy Lebanon (Georgia Institute of Technology);,"2134858009,2147343253,1979713447,2312000221",-,2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 1-3,information retrieval;computer science;
Cartogram visualization for nonlinear manifold learning models,Alfredo Vellido (Polytechnic University of Catalonia);David L. García (Polytechnic University of Catalonia);Àngela Nebot (Polytechnic University of Catalonia);,"170241628,2252901791,2161728171","Real-world applications of multivariate data analysis often stumble upon the barrier of interpretability. Simple data analysis methods are usually easy to interpret, but they risk providing poor data models. More involved methods may instead yield faithful data models, but limited interpretability. This is the case of linear and nonlinear methods for multivariate data visualization through dimensionality reduction. Even though the latter have provided some of the most exciting visualization developments, their practicality is hindered by the difficulty of explaining them in an intuitive manner. The interpretability, and therefore the practical applicability, of data visualization through nonlinear dimensionality reduction (NLDR) methods would improve if, first, we could accurately calculate the distortion introduced by these methods in the visual representation and, second, if we could faithfully reintroduce this distortion into such representation. In this paper, we describe a technique for the reintroduction of the distortion into the visualization space of NLDR models. It is based on the concept of density-equalizing maps, or cartograms, recently developed for the representation of geographic information. We illustrate it using Generative Topographic Mapping (GTM), a nonlinear manifold learning method that can provide both multivariate data visualization and a measure of the local distortion that the model generates. Although illustrated here with GTM, it could easily be extended to other NLDR visualization methods, provided a local distortion measure could be calculated. It could also serve as a guiding tool for interactive data visualization.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 22-54,cartogram;nonlinear dimensionality reduction;data visualization;computer vision;data mining;machine learning;statistics;computer science;mathematics;
Visualizing dimensionality reduction of systems biology data,Andreas Lehrmann (University of Tübingen);Michael Huber 0002 (University of Tübingen);Aydin Can Polatkan (University of Tübingen);Albert Pritzkau (Leipzig University);Kay Nieselt (University of Tübingen);,"2279052662,2161411168,1234250567,2287881356,96854432","One of the challenges in analyzing high-dimensional expression data is the detection of important biological signals. A common approach is to apply a dimension reduction method, such as principal component analysis. Typically, after application of such a method the data is projected and visualized in the new coordinate system, using scatter plots or profile plots. These methods provide good results if the data have certain properties which become visible in the new coordinate system but which were hard to detect in the original coordinate system. Often however, the application of only one method does not suffice to capture all important signals. Therefore several methods addressing different aspects of the data need to be applied. We have developed a framework for linear and non-linear dimension reduction methods within our visual analytics pipeline SpRay. This includes measures that assist the interpretation of the factorization result. Different visualizations of these measures can be combined with functional annotations that support the interpretation of the results. We show an application to high-resolution time series microarray data in the antibiotic-producing organism Streptomyces coelicolor as well as to microarray data measuring expression of cells with normal karyotype and cells with trisomies of human chromosomes 13 and 21.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 146-165,independent component analysis;dimensionality reduction;principal component analysis;systems biology;bioinformatics;data mining;machine learning;statistics;computer science;mathematics;
Generic visual analysis for multi- and hyperspectral image data,Björn Labitzke (University of Siegen);Serkan Bayraktar (University of Siegen);Andreas Kolb (University of Siegen);,"1964778783,2627048183,1968586732","Multi- and hyperspectral imaging and data analysis has been investigated in the last decades in the context of various fields of application like remote sensing or microscopic spectroscopy. However, recent developments in sensor technology and a growing number of application areas require a more generic view on data analysis, that clearly expands the current, domain-specific approaches. In this context, we address the problem of interactive exploration of multi- and hyperspectral data, consisting of (semi-)automatic data analysis and scientific visualization in a comprehensive fashion. In this paper, we propose an approach that enables a generic interactive exploration and easy segmentation of multi- and hyperspectral data, based on characterizing spectra of an individual dataset, the so-called endmembers. Using the concepts of existing endmember extraction algorithms, we derive a visual analysis system, where the characteristic spectra initially identified serve as input to interactively tailor a problem-specific visual analysis by means of visual exploration. An optional outlier detection improves the robustness of the endmember detection and analysis. An adequate system feedback of the costly unmixing procedure for the spectral data with respect to the current set of endmembers is ensured by a novel technique for progressive unmixing and view update which is applied at user modification. The progressive unmixing is based on an efficient prediction scheme applied to previous unmixing results. We present a detailed evaluation of our system in terms of confocal Raman microscopy, common multispectral imaging and remote sensing.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 117-145,interactive visual analysis;feature extraction;computer vision;data mining;machine learning;computer science;
On studying a 3D user interface for OLAP,Sébastien Lafon;Fatma Bouali (Isfahan University of Technology);Christiane Guinot (François Rabelais University);Gilles Venturini (François Rabelais University);,"1976878245,2481475765,2036860373,2068916923","In this paper, a new visual and interactive user interface for OLAP is presented, and its strengths and weaknesses examined. A survey on 3D interfaces for OLAP is detailed, which shows that only one interface that uses Virtual Reality has been proposed. Then we present our approach: it consists of a 3D representation of OLAP cubes where many OLAP operators have been integrated and where several measures can be visualized. A 3D stereoscopic screen can be used in conjunction with a 3D mouse. Finally a user study is reported that compares standard dynamic cross-tables with our interface on different tasks. We conclude that 3D with stereoscopy is not as promising as expected even with recent 3D devices.",2013,Data Mining and Knowledge Discovery volume 27 issue 1 pp 4-21,online analytical processing;virtual reality;world wide web;data mining;database;computer science;
Closed and noise-tolerant patterns in n-ary relations,Loïc Cerf (Universidade Federal de Minas Gerais);Jérémy Besson (Institut national des sciences Appliquées de Lyon);Kim-Ngan T. Nguyen (University of Lyon);Jean-François Boulicaut (University of Lyon);,"2153172063,2262066572,2132356875,1971530415","Binary relation mining has been extensively studied. Nevertheless, many interesting 0/1 data naturally appear as n-ary relations with n ? 3. A timely challenge is to extend local pattern extraction, eg, closed pattern mining, to such contexts. When considering higher arities, faint noise affects more and more the quality of the extracted patterns. We study a declarative specification of error-tolerant patterns by means of new primitive constraints and the design of an efficient algorithm to extract every solution pattern. It exploits the enumeration principles of the state-of-the-art Data-Peeler algorithm for n-ary relation mining. Efficiently enforcing error-tolerance crucially depends on innovative strategies to incrementally compute partial information on the data. Our prototype is tested on both synthetic and real datasets. It returns relevant collections of patterns even in the case of noisy ternary or 4-ary relations, eg, in the context of pattern discovery from dynamic networks.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 574-619,fault tolerance;theoretical computer science;data mining;machine learning;computer science;mathematics;
"Dependence maps, a dimensionality reduction with dependence distance for high-dimensional data",Kichun Lee (Hanyang University);Alexander G. Gray (Georgia Institute of Technology);Heeyoung Kim (Georgia Institute of Technology);,"2111406077,2112810595,2395460658","We introduce the dependence distance, a new notion of the intrinsic distance between points, derived as a pointwise extension of statistical dependence measures between variables. We then introduce a dimension reduction procedure for preserving this distance, which we call the dependence map. We explore its theoretical justification, connection to other methods, and empirical behavior on real data sets.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 512-532,dependence relation;diffusion map;dimensionality reduction;markov chain;discrete mathematics;combinatorics;machine learning;statistics;computer science;mathematics;
Topic model for analyzing purchase data with price information,Tomoharu Iwata (Nippon Telegraph and Telephone);Hiroshi Sawada (Nippon Telegraph and Telephone);,"2108993706,2099875912","We propose a new topic model for analyzing purchase data with price information. Price is an important factor in consumer purchase behavior. The proposed model assumes that a topic has its own price distributions for each item as well as an item distribution. The topic proportions, which represent a user's purchase tendency, are influenced by the user's purchased items and their prices. By estimating the mean and the variance of the price for each topic, the proposed model can cluster related items taking their price ranges into consideration. We present its efficient inference procedure based on collapsed Gibbs sampling. Experiments on real purchase data demonstrate the effectiveness of the proposed model.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 559-573,gibbs sampling;cluster analysis;data mining;machine learning;computer science;
Projective clustering ensembles,Francesco Gullo (Yahoo!);Carlotta Domeniconi (George Mason University);Andrea Tagarelli (University of Calabria);,"1979201319,45678088,273425128","A considerable amount of work has been done in data clustering research during the last four decades, and a myriad of methods has been proposed focusing on different data types, proximity functions, cluster representation models, and cluster presentation. However, clustering remains a challenging problem due to its ill-posed nature: it is well known that off-the-shelf clustering methods may discover different patterns in a given set of data, mainly because every clustering algorithm has its own bias resulting from the optimization of different criteria. This bias becomes even more important as in almost all real-world applications, data is inherently high-dimensional and multiple clustering solutions might be available for the same data collection. In this respect, the problems of projective clustering and clustering ensembles have been recently defined to deal with the high dimensionality and multiple clusterings issues, respectively. Nevertheless, despite such two issues can often be encountered together, existing approaches to the two problems have been developed independently of each other. In our earlier work Gullo et al. (Proceedings of the international conference on data mining (ICDM), 2009a) we introduced a novel clustering problem, called projective clustering ensembles (PCE): given a set (ensemble) of projective clustering solutions, the goal is to derive a projective consensus clustering, i.e., a projective clustering that complies with the information on object-to-cluster and the feature-to-cluster assignments given in the ensemble. In this paper, we enhance our previous study and provide theoretical and experimental insights into the PCE problem. PCE is formalized as an optimization problem and is designed to satisfy desirable requirements on independence from the specific clustering ensemble algorithm, ability to handle hard as well as soft data clustering, and different feature weightings. Two PCE formulations are defined: a two-objective optimization problem, in which the two objective functions respectively account for the object- and feature-based representations of the solutions in the ensemble, and a single-objective optimization problem, in which the object- and feature-based representations are embedded into a single function to measure the distance error between the projective consensus clustering and the projective ensemble. The significance of the proposed methods for solving the PCE problem has been shown through an extensive experimental evaluation based on several datasets and comparatively with projective clustering and clustering ensemble baselines.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 452-511,flame clustering;brown clustering;canopy clustering algorithm;determining the number of clusters in a data set;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;fuzzy clustering;clustering high dimensional data;multi objective optimization;hierarchical clustering;cluster analysis;consensus clustering;biclustering;conceptual clustering;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
Representations for multi-document event clustering,Wim De Smet (Katholieke Universiteit Leuven);Marie-Francine Moens (Katholieke Universiteit Leuven);,"2152917141,1931663571","We study several techniques for representing, fusing and comparing content representations of news documents. As underlying models we consider the vector space model (both in a term setting and in a latent semantic analysis setting) and probabilistic topic models based on latent Dirichlet allocation. Content terms can be classified as topical terms or named entities, yielding several models for content fusion and comparison. All used methods are completely unsupervised. We find that simple methods can still outperform the current state-of-the-art techniques.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 533-558,probabilistic latent semantic analysis;cluster analysis;text mining;data mining;pattern recognition;machine learning;computer science;
Solving non-negative matrix factorization by alternating least squares with a modified strategy,Hongwei Liu (Xidian University);Xiangli Li (Xidian University);Xiuyun Zheng (Xidian University);,"2155495874,2701908902,2721839046","Non-negative matrix factorization (NMF) is a method to obtain a representation of data using non-negativity constraints. A popular approach is alternating non-negative least squares (ANLS). As is well known, if the sequence generated by ANLS has at least one limit point, then the limit point is a stationary point of NMF. However, no evdience has shown that the sequence generated by ANLS has at least one limit point. In order to overcome this shortcoming, we propose a modified strategy for ANLS in this paper. The modified strategy can ensure the sequence generated by ANLS has at least one limit point, and this limit point is a stationary point of NMF. The results of numerical experiments are reported to show the effectiveness of the proposed algorithm.",2013,Data Mining and Knowledge Discovery volume 26 issue 3 pp 435-451,non negative matrix factorization;combinatorics;calculus;machine learning;mathematical optimization;computer science;mathematics;
Experimental comparison of representation methods and distance measures for time series data,"Xiaoyue Wang (University of California, Riverside);Abdullah Mueen (University of California, Riverside);Hui Ding (Northwestern University);Goce Trajcevski (Northwestern University);Peter Scheuermann (Northwestern University);Eamonn J. Keogh (University of California, Riverside);","2170860754,2083987245,2310874565,98612900,797615088,2170070822","The previous decade has brought a remarkable increase of the interest in applications that deal with querying and mining of time series data. Many of the research efforts in this context have focused on introducing new representation methods for dimensionality reduction or novel similarity measures for the underlying data. In the vast majority of cases, each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive experimental study re-implementing eight different time series representations and nine similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this article, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. In addition to providing a unified validation of some of the existing achievements, our experiments also indicate that, in some cases, certain claims in the literature may be unduly optimistic.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 275-309,time series;econometrics;data mining;machine learning;statistics;computer science;mathematics;
A survey on enhanced subspace clustering,"Kelvin Sim (Agency for Science, Technology and Research);Vivekanand Gopalkrishnan (IBM);Arthur Zimek (Ludwig Maximilian University of Munich);Gao Cong (Nanyang Technological University);","2272606362,1206024763,242745652,2295915604","Subspace clustering finds sets of objects that are homogeneous in subspaces of high-dimensional datasets, and has been successfully applied in many domains. In recent years, a new breed of subspace clustering algorithms, which we denote as enhanced subspace clustering algorithms, have been proposed to (1) handle the increasing abundance and complexity of data and to (2) improve the clustering results. In this survey, we present these enhanced approaches to subspace clustering by discussing the problems they are solving, their cluster definitions and algorithms. Besides enhanced subspace clustering, we also present the basic subspace clustering and the related works in high-dimensional clustering.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 332-397,k medians clustering;flame clustering;subclu;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;fuzzy clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;biclustering;conceptual clustering;data science;data mining;machine learning;computer science;
Parameter-less co-clustering for star-structured heterogeneous data,Dino Ienco (University of Turin);Céline Robardet (University of Lyon);Ruggero G. Pensa (University of Turin);Rosa Meo (University of Turin);,"2288551980,1976373341,108207645,2117349166","The availability of data represented with multiple features coming from heterogeneous domains is getting more and more common in real world applications. Such data represent objects of a certain type, connected to other types of data, the features, so that the overall data schema forms a star structure of inter-relationships. Co-clustering these data involves the specification of many parameters, such as the number of clusters for the object dimension and for all the features domains. In this paper we present a novel co-clustering algorithm for heterogeneous star-structured data that is parameter-less. This means that it does not require either the number of row clusters or the number of column clusters for the given feature spaces. Our approach optimizes the Goodman---Kruskal's ?, a measure for cross-association in contingency tables that evaluates the strength of the relationship between two categorical variables. We extend ? to evaluate co-clustering solutions and in particular we apply it in a higher dimensional setting. We propose the algorithm CoStar which optimizes ? by a local search approach. We assess the performance of CoStar on publicly available datasets from the textual and image domains using objective external criteria. The results show that our approach outperforms state-of-the-art methods for the co-clustering of heterogeneous data, while it remains computationally efficient.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 217-254,cluster analysis;biclustering;data mining;database;machine learning;algorithm;computer science;
Using derivatives in time series classification,Tomasz Górecki (Adam Mickiewicz University in Poznań);Maciej Łuczak (Koszalin University of Technology);,"1981763333,2126127772","Over recent years the popularity of time series has soared. Given the widespread use of modern information technology, a large number of time series may be collected during business, medical or biological operations, for example. As a consequence there has been a dramatic increase in the amount of interest in querying and mining such data, which in turn has resulted in a large number of works introducing new methodologies for indexing, classification, clustering and approximation of time series. In particular, many new distance measures between time series have been introduced. In this paper, we propose a new distance function based on a derivative. In contrast to well-known measures from the literature, our approach considers the general shape of a time series rather than point-to-point function comparison. The new distance is used in classification with the nearest neighbor rule. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on 20 time series datasets from a wide variety of application domains. Our experiments show that our method provides a higher quality of classification on most of the examined datasets.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 310-331,dynamic time warping;time series;data science;data mining;machine learning;statistics;computer science;
Active hashing and its application to image and text retrieval,Yi Zhen (Hong Kong University of Science and Technology);Dit Yan Yeung (Hong Kong University of Science and Technology);,"2122755168,2109477161","In recent years, hashing-based methods for large-scale similarity search have sparked considerable research interests in the data mining and machine learning communities. While unsupervised hashing-based methods have achieved promising successes for metric similarity, they cannot handle semantic similarity which is usually given in the form of labeled point pairs. To overcome this limitation, some attempts have recently been made on semi-supervised hashing which aims at learning hash functions from both metric and semantic similarity simultaneously. Existing semi-supervised hashing methods can be regarded as passive hashing since they assume that the labeled pairs are provided in advance. In this paper, we propose a novel framework, called active hashing, which can actively select the most informative labeled pairs for hash function learning. Specifically, it identifies the most informative points to label and constructs labeled pairs accordingly. Under this framework, we use data uncertainty as a measure of informativeness and develop a batch mode algorithm to speed up active selection. We empirically compare our method with a state-of-the-art passive hashing method on two benchmark data sets, showing that the proposed method can reduce labeling cost as well as overcome the limitations of passive hashing.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 255-274,k independent hashing;hopscotch hashing;2 choice hashing;feature hashing;locality preserving hashing;double hashing;dynamic perfect hashing;open addressing;universal hashing;extendible hashing;locality sensitive hashing;hash function;hash table;information retrieval;data mining;pattern recognition;computer science;
Enhanced spatiotemporal relational probability trees and forests,Amy McGovern (University of Oklahoma);Nathaniel Troutman (University of Oklahoma);Rodger A. Brown (National Oceanic and Atmospheric Administration);John K. Williams (National Center for Atmospheric Research);Jennifer Abernethy (National Center for Atmospheric Research);,"2110730349,1991259956,2143422341,2205062974,2099161170","Many real world domains are inherently spatiotemporal in nature. In this work, we introduce significant enhancements to two spatiotemporal relational learning methods, the spatiotemporal relational probability tree and the spatiotemporal relational random forest, that increase their ability to learn using spatiotemporal data. We enabled the models to formulate questions on both objects and the scalar and vector fields within and around objects, allowing the models to differentiate based on the gradient, divergence, and curl and to recognize the shape of point clouds defined by fields. This enables the model to ask questions about the change of a shape over time or about its orientation. These additions are validated on several real-world hazardous weather datasets. We demonstrate that these additions enable the models to learn robust classifiers that outperform the versions without these new additions. In addition, analysis of the learned models shows that the findings are consistent with current meteorological theories.",2013,Data Mining and Knowledge Discovery volume 26 issue 2 pp 398-433,statistical relational learning;data mining;artificial intelligence;machine learning;computer science;mathematics;
ABACUS: frequent pAttern mining-BAsed Community discovery in mUltidimensional networkS,Michele Berlingerio (IBM);Fabio Pinelli (IBM);Francesco Calabrese (IBM);,"264481733,1873045008,2016269244","Community discovery in complex networks is the problem of detecting, for each node of the network, its membership to one of more groups of nodes, the communities, that are densely connected, or highly interactive, or, more in general, similar, according to a similarity function. So far, the problem has been widely studied in monodimensional networks, i.e. networks where only one connection between two entities may exist. However, real networks are often multidimensional, i.e., multiple connections between any two nodes may exist, either reflecting different kinds of relationships, or representing different values of the same type of tie. In this context, the problem of community discovery has to be redefined, taking into account multidimensional structure of the graph. We define a new concept of community that groups together nodes sharing memberships to the same monodimensional communities in the different single dimensions. As we show, such communities are meaningful and able to group nodes even if they might not be connected in any of the monodimensional networks. We devise frequent pAttern mining-BAsed Community discoverer in mUltidimensional networkS (ABACUS), an algorithm that is able to extract multidimensional communities based on the extraction of frequent closed itemsets from monodimensional community memberships. Experiments on two different real multidimensional networks confirm the meaningfulness of the introduced concepts, and open the way for a new class of algorithms for community discovery that do not rely on the dense connections among nodes.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 294-320,community structure;social network analysis;data mining;artificial intelligence;machine learning;mathematics;
Nearly exact mining of frequent trees in large networks,Ashraf M. Kibriya (Katholieke Universiteit Leuven);Jan Ramon (Katholieke Universiteit Leuven);,"1986642368,2168801554","Mining frequent patterns in a single network (graph) poses a number of challenges. Already only to match one path pattern to a network under subgraph isomorphism is NP-complete. Classical matching algorithms become intractable even for reasonably small patterns, on networks which are large or have a high average degree. Based on recent advances in parameterized complexity theory, we propose a novel miner for rooted trees in networks. The miner, for a fixed parameter \(k\) (maximal pattern size), can mine all rooted trees with delay linear in the size of the network and only mildly exponential in the fixed parameter \(k\). This allows us to mine tractably, rooted trees, in large networks such as the WWW or social networks. We establish the practical applicability of our miner, by presenting an experimental evaluation on both synthetic and real-world data.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 478-504,combinatorics;data mining;machine learning;mathematics;
An efficiently computable subgraph pattern support measure: counting independent observations,Yuyi Wang (Katholieke Universiteit Leuven);Jan Ramon (Katholieke Universiteit Leuven);Thomas Fannes (Katholieke Universiteit Leuven);,"2270893978,2168801554,304978995","Graph support measures are functions measuring how frequently a given subgraph pattern occurs in a given database graph. An important class of support measures relies on overlap graphs. A major advantage of overlap-graph based approaches is that they combine anti-monotonicity with counting the occurrences of a subgraph pattern which are independent according to certain criteria. However, existing overlap-graph based support measures are expensive to compute. In this paper, we propose a new support measure which is based on a new notion of independence. We show that our measure is the solution to a sparse linear program, which can be computed efficiently using interior point methods. We study the anti-monotonicity and other properties of this new measure, and relate it to the statistical power of a sample of embeddings in a network. We show experimentally that, in contrast to earlier overlap-graph based proposals, our support measure makes it feasible to mine subgraph patterns in large networks.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 444-477,degeneracy;distance hereditary graph;induced subgraph isomorphism problem;forbidden graph characterization;subgraph isomorphism problem;linear programming;discrete mathematics;combinatorics;data mining;pattern recognition;machine learning;statistics;mathematics;
Growing a list,Benjamin Letham (Massachusetts Institute of Technology);Cynthia Rudin (Massachusetts Institute of Technology);Katherine A. Heller (Duke University);,"1983818389,2141705163,2158760032","It is easy to find expert knowledge on the Internet on almost any topic, but obtaining a complete overview of a given topic is not always easy: information can be scattered across many sources and must be aggregated to be useful. We introduce a method for intelligently growing a list of relevant items, starting from a small seed of examples. Our algorithm takes advantage of the wisdom of the crowd, in the sense that there are many experts who post lists of things on the Internet. We use a collection of simple machine learning components to find these experts and aggregate their lists to produce a single complete and meaningful list. We use experiments with gold standards and open-ended experiments without gold standards to show that our method significantly outperforms the state of the art. Our method uses the ranking algorithm Bayesian Sets even when its underlying independence assumption is violated, and we provide a theoretical generalization bound to motivate its use.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 372-395,ranking;collective intelligence;data science;information retrieval;data mining;machine learning;statistics;computer science;
What distinguish one from its peers in social networks,Yi-Chen Lo (National Taiwan University);Jhao-Yin Li (Academia Sinica);Mi-Yen Yeh (Academia Sinica);Shou-De Lin (National Taiwan University);Jian Pei (Simon Fraser University);,"2629502844,2153344407,2120443347,2114357324,2126330539","Being able to discover the uniqueness of an individual is a meaningful task in social network analysis. This paper proposes two novel problems in social network analysis: how to identify the uniqueness of a given query vertex, and how to identify a group of vertices that can mutually identify each other. We further propose intuitive yet effective methods to identify the uniqueness identification sets and the mutual identification groups of different properties. We further conduct an extensive experiment on both real and synthetic datasets to demonstrate the effectiveness of our model.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 396-420,social network;data mining;mathematics;
A framework for semi-supervised and unsupervised optimal extraction of clusters from hierarchies,Ricardo J. G. B. Campello (University of São Paulo);Davoud Moulavi (University of Alberta);Arthur Zimek (University of Alberta);Jörg Sander (University of Alberta);,"2043417111,1994079834,242745652,2118842476","We introduce a framework for the optimal extraction of flat clusterings from local cuts through cluster hierarchies. The extraction of a flat clustering from a cluster tree is formulated as an optimization problem and a linear complexity algorithm is presented that provides the globally optimal solution to this problem in semi-supervised as well as in unsupervised scenarios. A collection of experiments is presented involving clustering hierarchies of different natures, a variety of real data sets, and comparisons with specialized methods from the literature.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 344-371,constrained clustering;single linkage clustering;hierarchical clustering;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Activity preserving graph simplification,Francesco Bonchi (Yahoo!);Gianmarco De Francisci Morales (Yahoo!);Aristides Gionis (Aalto University);Antti Ukkonen (Helsinki Institute for Information Technology);,"2176652147,2153118160,737311942,1957862955","We study the problem of simplifying a given directed graph by keeping a small subset of its arcs. Our goal is to maintain the connectivity required to explain a set of observed traces of information propagation across the graph. Unlike previous work, we do not make any assumption about an underlying model of information propagation. Instead, we approach the task as a combinatorial problem. We prove that the resulting optimization problem is \(\mathbf{NP}\)-hard. We show that a standard greedy algorithm performs very well in practice, even though it does not have theoretical guarantees. Additionally, if the activity traces have a tree structure, we show that the objective function is supermodular, and experimentally verify that the approach for size-constrained submodular minimization recently proposed by Nagano et al. (28th International Conference on Machine Learning, 2011) produces very good results. Moreover, when applied to the task of reconstructing an unobserved graph, our methods perform comparably to a state-of-the-art algorithm devised specifically for this task.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 321-343,distance hereditary graph;strength of a graph;complement graph;graph bandwidth;moral graph;closure problem;null graph;graph property;combinatorics;data mining;machine learning;mathematical optimization;mathematics;
Guest editor’s introduction: special issue of the ECML PKDD 2013 journal track,Hendrik Blockeel (Katholieke Universiteit Leuven);Kristian Kersting (University of Bonn);Siegfried Nijssen (Katholieke Universiteit Leuven);Filip Železný (Czech Technical University in Prague);,"2049189351,2252032993,2102450877,671487464",-,2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 291-293,knowledge extraction;data science;data mining;computer science;
Guest editors’ introduction: special section of selected papers from ECML-PKDD 2012,Tijl De Bie (University of Bristol);Peter A. Flach (University of Bristol);,"2080198120,1814273096",-,2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 442-443,-
Fast sequence segmentation using log-linear models,Nikolaj Tatti (University of Antwerp);,1367500519,"Sequence segmentation is a well-studied problem, where given a sequence of elements, an integer K, and some measure of homogeneity, the task is to split the sequence into K contiguous segments that are maximally homogeneous. A classic approach to find the optimal solution is by using a dynamic program. Unfortunately, the execution time of this program is quadratic with respect to the length of the input sequence. This makes the algorithm slow for a sequence of non-trivial length. In this paper we study segmentations whose measure of goodness is based on log-linear models, a rich family that contains many of the standard distributions. We present a theoretical result allowing us to prune many suboptimal segmentations. Using this result, we modify the standard dynamic program for 1D log-linear models, and by doing so reduce the computational time. We demonstrate empirically, that this approach can significantly reduce the computational burden of finding the optimal segmentation.",2013,Data Mining and Knowledge Discovery volume 27 issue 3 pp 421-441,scale space segmentation;pruning;change detection;segmentation;machine learning;mathematical optimization;algorithm;mathematics;
A single pass algorithm for clustering evolving data streams based on swarm intelligence,Agostino Forestiero (National Research Council);Clara Pizzuti (National Research Council);Giandomenico Spezzano (National Research Council);,"2307709873,54675057,98373048","Existing density-based data stream clustering algorithms use a two-phase scheme approach consisting of an online phase, in which raw data is processed to gather summary statistics, and an offline phase that generates the clusters by using the summary data. In this article we propose a data stream clustering method based on a multi-agent system that uses a decentralized bottom-up self-organizing strategy to group similar data points. Data points are associated with agents and deployed onto a 2D space, to work simultaneously by applying a heuristic strategy based on a bio-inspired model, known as flocking model. Agents move onto the space for a fixed time and, when they encounter other agents into a predefined visibility range, they can decide to form a flock if they are similar. Flocks can join to form swarms of similar groups. This strategy allows to merge the two phases of density-based approaches and thus to avoid the computing demanding offline cluster computation, since a swarm represents a cluster. Experimental results show that the bio-inspired approach can obtain very good results on real and synthetic data sets.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 1-26,correlation clustering;data stream clustering;cluster analysis;data stream mining;distributed computing;data mining;machine learning;computer science;
Regularized nonnegative shared subspace learning,Sunil Kumar Gupta 0001 (Curtin University);Dinh Q. Phung (Curtin University);Brett Adams (Curtin University);Svetha Venkatesh (Curtin University);,"2119406083,2441989510,2163867018,2146461601","Joint modeling of related data sources has the potential to improve various data mining tasks such as transfer learning, multitask clustering, information retrieval etc. However, diversity among various data sources might outweigh the advantages of the joint modeling, and thus may result in performance degradations. To this end, we propose a regularized shared subspace learning framework, which can exploit the mutual strengths of related data sources while being immune to the effects of the variabilities of each source. This is achieved by further imposing a mutual orthogonality constraint on the constituent subspaces which segregates the common patterns from the source specific patterns, and thus, avoids performance degradations. Our approach is rooted in nonnegative matrix factorization and extends it further to enable joint analysis of related data sources. Experiments performed using three real world data sets for both retrieval and clustering applications demonstrate the benefits of regularization and validate the effectiveness of the model. Our proposed solution provides a formal framework appropriate for jointly analyzing related data sources and therefore, it is applicable to a wider context in data mining.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 57-97,transfer of learning;data mining;pattern recognition;machine learning;statistics;computer science;
Summarizing categorical data by clustering attributes,Michael Mampaey (University of Antwerp);Jilles Vreeken (University of Antwerp);,"2027051129,1971070670","For a book, its title and abstract provide a good first impression of what to expect from it. For a database, obtaining a good first impression is typically not so straightforward. While low-order statistics only provide very limited insight, downright mining the data rapidly provides too much detail for such a quick glance. In this paper we propose a middle ground, and introduce a parameter-free method for constructing high-quality descriptive summaries of binary and categorical data. Our approach builds a summary by clustering attributes that strongly correlate, and uses the Minimum Description Length principle to identify the best clustering--without requiring a distance measure between attributes. Besides providing a practical overview of which attributes interact most strongly, these summaries can also be used as surrogates for the data, and can easily be queried. Extensive experimentation shows that our method discovers high-quality results: correlated attributes are correctly grouped, which is verified both objectively and subjectively. Our models can also be employed as surrogates for the data; as an example of this we show that we can quickly and accurately query the estimated supports of frequent generalized itemsets.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 130-173,categorical variable;automatic summarization;data science;data mining;database;machine learning;statistics;computer science;
Exploiting unlabeled data to enhance ensemble diversity,Min-Ling Zhang (Southeast University);Zhi-Hua Zhou (Nanjing University);,"2310402581,2286237009","Ensemble learning learns from the training data by generating an ensemble of multiple base learners. It is well-known that to construct a good ensemble with strong generalization ability, the base learners are deemed to be accurate as well as diverse. In this paper, unlabeled data is exploited to facilitate ensemble learning by helping augment the diversity among the base learners. Specifically, a semi-supervised ensemble method named udeed, i.e. Unlabeled Data to Enhance Ensemble Diversity, is proposed. In contrast to existing semi-supervised ensemble methods which utilize unlabeled data by estimating error-prone pseudo-labels on them to enlarge the labeled data to improve base learners' accuracies, udeed works by maximizing accuracies of base learners on labeled data while maximizing diversity among them on unlabeled data. Extensive experiments on 20 regular-scale and five large-scale data sets are conducted under the setting of either few or abundant labeled data. Experimental results show that udeed can effectively utilize unlabeled data for ensemble learning via diversity augmentation, and is highly competitive to well-established semi-supervised ensemble methods.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 98-129,semi supervised learning;ensemble learning;data mining;pattern recognition;machine learning;computer science;
A preconditioned conjugate gradient algorithm for GeneRank with application to microarray data mining,Gang Wu (Jiangsu Normal University);Wei Xu (Tongji University);Ying Zhang (Xuzhou Medical College);Yimin Wei (Fudan University);,"2709204363,2639050594,2418217002,2116477201","The problem of identifying key genes is of fundamental importance in biology and medicine. The GeneRank model explores connectivity data to produce a prioritization of the genes in a microarray experiment that is less susceptible to variation caused by experimental noise than the one based on expression levels alone. The GeneRank algorithm amounts to solving an unsymmetric linear system. However, when the matrix in question is very large, the GeneRank algorithm is inefficient and even can be infeasible. On the other hand, the adjacency matrix is symmetric in the GeneRank model, while the original GeneRank algorithm fails to exploit the symmetric structure of the problem in question. In this paper, we discover that the GeneRank problem can be rewritten as a symmetric positive definite linear system, and propose a preconditioned conjugate gradient algorithm to solve it. Numerical experiments support our theoretical results, and show superiority of the novel algorithm.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 27-56,gene regulatory network;microarray;theoretical computer science;mathematical optimization;algorithm;mathematics;
Privacy-preserving record linkage,Vassilios Verykios (Hellenic Open University);Peter Christen (Australian National University);,"77221159,2023765750",-,2013,Data Mining and Knowledge Discovery,personally identifiable information;record linkage;group method of data handling;information privacy;internet privacy;world wide web;data mining;computer science;
Score-based methods for learning Markov boundaries by searching in constrained spaces,Silvia Acid (University of Granada);Luis M. de Campos (University of Granada);Moisés Fernández (University of Granada);,"2126395522,2156828743,2675865464","Within probabilistic classification problems, learning the Markov boundary of the class variable consists in the optimal approach for feature subset selection. In this paper we propose two algorithms that learn the Markov boundary of a selected variable. These algorithms are based on the score+search paradigm for learning Bayesian networks. Both algorithms use standard scoring functions but they perform the search in constrained spaces of class-focused directed acyclic graphs, going through the space by means of operators adapted for the problem. The algorithms have been validated experimentally by using a wide spectrum of databases, and their results show a performance competitive with the state-of-the-art.",2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 174-212,variable order bayesian network;markov algorithm;variable order markov model;markov blanket;bayesian network;markov model;pattern recognition;machine learning;mathematical optimization;computer science;mathematics;
Erratum to: Mining local and tail dependence structures based on pointwise mutual information,Teruko Takada (Osaka City University);,2112769489,-,2013,Data Mining and Knowledge Discovery volume 26 issue 1 pp 213-215,combinatorics;data mining;statistics;mathematics;
Simultaneous classification and community detection on heterogeneous network data,Prakash Mandayam Comar (Michigan State University);Pang Ning Tan (Michigan State University);Anil K. Jain (Michigan State University);,"1993778338,2113230973,2162010601","Previous studies on network mining have focused primarily on learning a single task (such as classification or community detection) on a given network. This paper considers the problem of multi-task learning on heterogeneous network data. Specifically, we present a novel framework that enables one to perform classification on one network and community detection in another related network. Multi-task learning is accomplished by introducing a joint objective function that must be optimized to ensure the classes in one network are consistent with the link structure, nodal attributes, as well as the communities detected in another network. We provide both theoretical and empirical analysis of the framework. We also show that the framework can be extended to incorporate prior information about the correspondences between the clusters and classes in different networks. Experiments performed on both real-world and synthetic data sets demonstrate the effectiveness of the joint framework compared to applying classification and community detection algorithms on each network separately.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 420-449,organizational network analysis;multi task learning;dynamic network analysis;one class classification;network simulation;biological classification;data science;data mining;machine learning;computer science;
Diverse subgroup set discovery,Matthijs van Leeuwen (Katholieke Universiteit Leuven);Arno J. Knobbe (Leiden University);,"2143928993,1229146049","Large data is challenging for most existing discovery algorithms, for several reasons. First of all, such data leads to enormous hypothesis spaces, making exhaustive search infeasible. Second, many variants of essentially the same pattern exist, due to (numeric) attributes of high cardinality, correlated attributes, and so on. This causes top-k mining algorithms to return highly redundant result sets, while ignoring many potentially interesting results. These problems are particularly apparent with subgroup discovery (SD) and its generalisation, exceptional model mining. To address this, we introduce subgroup set discovery: one should not consider individual subgroups, but sets of subgroups. We consider three degrees of redundancy, and propose corresponding heuristic selection strategies in order to eliminate redundancy. By incorporating these (generic) subgroup selection methods in a beam search, the aim is to improve the balance between exploration and exploitation. The proposed algorithm, dubbed DSSD for diverse subgroup set discovery, is experimentally evaluated and compared to existing approaches. For this, a variety of target types with corresponding datasets and quality measures is used. The subgroup sets that are discovered by the competing methods are evaluated primarily on the following three criteria: (1) diversity in the subgroup covers (exploration), (2) the maximum quality found (exploitation), and (3) runtime. The results show that DSSD outperforms each traditional SD method on all or a (non-empty) subset of these criteria, depending on the specific setting. The more complex the task, the larger the benefit of using our diverse heuristic search turns out to be.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 208-242,brute force search;heuristic;combinatorics;bioinformatics;data mining;computer science;mathematics;
Tensor factorization using auxiliary information,Atsuhiro Narita (University of Tokyo);Kohei Hayashi (University of Tokyo);Ryota Tomioka (University of Tokyo);Hisashi Kashima (University of Tokyo);,"2108074803,2260348883,2443967568,2428201863","Most of the existing analysis methods for tensors (or multi-way arrays) only assume that tensors to be completed are of low rank. However, for example, when they are applied to tensor completion problems, their prediction accuracy tends to be significantly worse when only a limited number of entries are observed. In this paper, we propose to use relationships among data as auxiliary information in addition to the low-rank assumption to improve the quality of tensor decomposition. We introduce two regularization approaches using graph Laplacians induced from the relationships, one for moderately sparse cases and the other for extremely sparse cases. We also give present two kinds of iterative algorithms for approximate solutions: one based on an EM-like algorithms which is stable but not so scalable, and the other based on gradient-based optimization which is applicable to large scale datasets. Numerical experiments on tensor completion using synthetic and benchmark datasets show that the use of auxiliary information improves completion accuracy over the existing methods based only on the low-rank assumption, especially when observations are sparse.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 298-324,tucker decomposition;tensor;discrete mathematics;combinatorics;mathematical optimization;statistics;mathematics;
Network regression with predictive clustering trees,Daniela Stojanova;Michelangelo Ceci (University of Bari);Annalisa Appice (University of Bari);Sašo Džeroski (University of Freiburg);,"2037620856,2114873949,135896968,1419022840","Network data describe entities represented by nodes, which may be connected with (related to) each other by edges. Many network datasets are characterized by a form of autocorrelation, where the value of a variable at a given node depends on the values of variables at the nodes it is connected with. This phenomenon is a direct violation of the assumption that data are independently and identically distributed. At the same time, it offers an unique opportunity to improve the performance of predictive models on network data, as inferences about one entity can be used to improve inferences about related entities. Regression inference in network data is a challenging task. While many approaches for network classification exist, there are very few approaches for network regression. In this paper, we propose a data mining algorithm, called NCLUS, that explicitly considers autocorrelation when building regression models from network data. The algorithm is based on the concept of predictive clustering trees (PCTs) that can be used for clustering, prediction and multi-target prediction, including multi-target regression and multi-target classification. We evaluate our approach on several real world problems of network regression, coming from the areas of social and spatial networks. Empirical results show that our algorithm performs better than PCTs learned by completely disregarding network information, as well as PCTs that are tailored for spatial data, but do not take autocorrelation into account, and a variety of other existing approaches.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 378-413,autocorrelation;data mining;machine learning;statistics;computer science;
Actively learning to infer social ties,Honglei Zhuang (Tsinghua University);Jie Tang (Tsinghua University);Wenbin Tang (Tsinghua University);Tiancheng Lou (Tsinghua University);Alvin Chin;Xia Wang;,"2128637305,2158012360,2171289332,2162145093,2680220575,2630483673","We study the extent to which social ties between people can be inferred in large social network, in particular via active user interactions. In most online social networks, relationships are lack of meaning labels (e.g., ""colleague"" and ""intimate friends"") due to various reasons. Understanding the formation of different types of social relationships can provide us insights into the micro-level dynamics of the social network. In this work, we precisely define the problem of inferring social ties and propose a Partially-Labeled Pairwise Factor Graph Model (PLP-FGM) for learning to infer the type of social relationships. The model formalizes the problem of inferring social ties into a flexible semi-supervised framework. We test the model on three different genres of data sets and demonstrate its effectiveness. We further study how to leverage user interactions to help improve the inferring accuracy. Two active learning algorithms are proposed to actively select relationships to query users for their labels. Experimental results show that with only a few user corrections, the accuracy of inferring social ties can be significantly improved. Finally, to scale the model to handle real large networks, a distributed learning algorithm has been developed.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 270-297,active learning;interpersonal ties;data mining;machine learning;
Finding density-based subspace clusters in graphs with feature vectors,Stephan Günnemann (RWTH Aachen University);Brigitte Boden (RWTH Aachen University);Thomas Seidl (RWTH Aachen University);,"316694267,2117690819,2140301036","Data sources representing attribute information in combination with network information are widely available in today's applications. To realize the full potential for knowledge extraction, mining techniques like clustering should consider both information types simultaneously. Recent clustering approaches combine subspace clustering with dense subgraph mining to identify groups of objects that are similar in subsets of their attributes as well as densely connected within the network. While those approaches successfully circumvent the problem of full-space clustering, their limited cluster definitions are restricted to clusters of certain shapes. In this work we introduce a density-based cluster definition, which takes into account the attribute similarity in subspaces as well as a local graph density and enables us to detect clusters of arbitrary shape and size. Furthermore, we avoid redundancy in the result by selecting only the most interesting non-redundant clusters. Based on this model, we introduce the clustering algorithm DB-CSC, which uses a fixed point iteration method to efficiently determine the clustering solution. We prove the correctness and complexity of this fixed point iteration analytically. In thorough experiments we demonstrate the strength of DB-CSC in comparison to related approaches.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 243-269,k medians clustering;flame clustering;brown clustering;canopy clustering algorithm;determining the number of clusters in a data set;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;clustering coefficient;fuzzy clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;discrete mathematics;combinatorics;data mining;machine learning;computer science;mathematics;
Comparing apples and oranges: measuring differences between exploratory data mining results,Nikolaj Tatti (University of Antwerp);Jilles Vreeken (University of Antwerp);,"1367500519,1971070670","Deciding whether the results of two different mining algorithms provide significantly different information is an important, yet understudied, open problem in exploratory data mining. Whether the goal is to select the most informative result for analysis, or to decide which mining approach will most likely provide the most novel insight, it is essential that we can tell how different the information is that different results by possibly different methods provide. In this paper we take a first step towards comparing exploratory data mining results on binary data. We propose to meaningfully convert results into sets of noisy tiles, and compare between these sets by maximum entropy modelling and Kullback---Leibler divergence, well-founded notions from Information Theory. We so construct a measure that is highly flexible, and allows us to naturally include background knowledge, such that differences in results can be measured from the perspective of what a user already knows. Furthermore, adding to its interpretability, it coincides with Jaccard dissimilarity when we only consider exact tiles. Our approach provides a means to study and tell differences between results of different exploratory data mining methods. As an application, we show that our measure can also be used to identify which parts of results best redescribe other results. Furthermore, we study its use for iterative data mining, where one iteratively wants to find that result that will provide maximal novel information. Experimental evaluation shows our measure gives meaningful results, correctly identifies methods that are similar in nature, automatically provides sound redescriptions of results, and is highly applicable for iterative data mining.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 173-207,distance;principle of maximum entropy;concept mining;data science;data mining;machine learning;statistics;mathematics;
Fast projections onto mixed-norm balls with applications,Suvrit Sra (Max Planck Society);,2469620852,"Joint sparsity offers powerful structural cues for feature selection, especially for variables that are expected to demonstrate a ""grouped"" behavior. Such behavior is commonly modeled via group-lasso, multitask lasso, and related methods where feature selection is effected via mixed-norms. Several mixed-norm based sparse models have received substantial attention, and for some cases efficient algorithms are also available. Surprisingly, several constrained sparse models seem to be lacking scalable algorithms. We address this deficiency by presenting batch and online (stochastic-gradient) optimization methods, both of which rely on efficient projections onto mixed-norm balls. We illustrate our methods by applying them to the multitask lasso. We conclude by mentioning some open problems.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 358-377,multi task learning;matrix norm;pattern recognition;machine learning;mathematical optimization;computer science;mathematics;
Fast support vector machines for convolution tree kernels,Aliaksei Severyn (University of Trento);Alessandro Moschitti (University of Trento);,"1267219816,48142092","Feature engineering is one of the most complex aspects of system design in machine learning. Fortunately, kernel methods provide the designer with formidable tools to tackle such complexity. Among others, tree kernels (TKs) have been successfully applied for representing structured data in diverse domains, ranging from bioinformatics and data mining to natural language processing. One drawback of such methods is that learning with them typically requires a large number of kernel computations (quadratic in the number of training examples) between training examples. However, in practice substructures often repeat in the data which makes it possible to avoid a large number of redundant kernel evaluations. In this paper, we propose the use of Directed Acyclic Graphs (DAGs) to compactly represent trees in the training algorithm of Support Vector Machines. In particular, we use DAGs for each iteration of the cutting plane algorithm (CPA) to encode the model composed by a set of trees. This enables DAG kernels to efficiently evaluate TKs between the current model and a given training tree. Consequently, the amount of total computation is reduced by avoiding redundant evaluations over shared substructures. We provide theory and algorithms to formally characterize the above idea, which we tested on several datasets. The empirical results confirm the benefits of the approach in terms of significant speedups over previous state-of-the-art methods. In addition, we propose an alternative sampling strategy within the CPA to address the class-imbalance problem, which coupled with fast learning methods provides a viable TK learning framework for a large class of real-world applications.",2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 325-357,tree kernel;kernel method;theoretical computer science;data mining;machine learning;algorithm;computer science;mathematics;
Guest Editors' Introduction: special issue of selected papers from ECML PKDD 2011,Dimitrios Gunopulos (National and Kapodistrian University of Athens);Donato Malerba (University of Bari);Michalis Vazirgiannis (Athens University of Economics and Business);,"2712250546,2360612151,1914497179",-,2012,Data Mining and Knowledge Discovery volume 25 issue 2 pp 169-172,-
Community detection via heterogeneous interaction analysis,Lei Tang (Yahoo!);Xufei Wang (Arizona State University);Huan Liu (Arizona State University);,"2141813676,2121550591,2122391114","The pervasiveness of Web 2.0 and social networking sites has enabled people to interact with each other easily through various social media. For instance, popular sites like Del.icio.us, Flickr, and YouTube allow users to comment on shared content (bookmarks, photos, videos), and users can tag their favorite content. Users can also connect with one another, and subscribe to or become a fan or a follower of others. These diverse activities result in a multi-dimensional network among actors, forming group structures with group members sharing similar interests or affiliations. This work systematically addresses two challenges. First, it is challenging to effectively integrate interactions over multiple dimensions to discover hidden community structures shared by heterogeneous interactions. We show that representative community detection methods for single-dimensional networks can be presented in a unified view. Based on this unified view, we present and analyze four possible integration strategies to extend community detection from single-dimensional to multi-dimensional networks. In particular, we propose a novel integration scheme based on structural features. Another challenge is the evaluation of different methods without ground truth information about community membership. We employ a novel cross-dimension network validation (CDNV) procedure to compare the performance of different methods. We use synthetic data to deepen our understanding, and real-world data to compare integration strategies as well as baseline methods in a large scale. We study further the computational time of different methods, normalization effect during integration, sensitivity to related parameters, and alternative community detection methods for integration.",2012,Data Mining and Knowledge Discovery volume 25 issue 1 pp 1-33,social media;internet privacy;world wide web;data mining;machine learning;computer science;
FRaC: a feature-modeling approach for semi-supervised and unsupervised anomaly detection,Keith Noto (Tufts University);Carla E. Brodley (Tufts University);Donna K. Slonim (Tufts University);,"1964319870,1994240001,2201429319","Anomaly detection involves identifying rare data instances (anomalies) that come from a different class or distribution than the majority (which are simply called ""normal"" instances). Given a training set of only normal data, the semi-supervised anomaly detection task is to identify anomalies in the future. Good solutions to this task have applications in fraud and intrusion detection. The unsupervised anomaly detection task is different: Given unlabeled, mostly-normal data, identify the anomalies among them. Many real-world machine learning tasks, including many fraud and intrusion detection tasks, are unsupervised because it is impractical (or impossible) to verify all of the training data. We recently presented FRaC, a new approach for semi-supervised anomaly detection. FRaC is based on using normal instances to build an ensemble of feature models, and then identifying instances that disagree with those models as anomalous. In this paper, we investigate the behavior of FRaC experimentally and explain why FRaC is so successful. We also show that FRaC is a superior approach for the unsupervised as well as the semi-supervised anomaly detection task, compared to well-known state-of-the-art anomaly detection methods, LOF and one-class support vector machines, and to an existing feature-modeling approach.",2012,Data Mining and Knowledge Discovery volume 25 issue 1 pp 109-133,medical research;anomaly detection;unsupervised learning;data science;data mining;machine learning;computer science;
Mining closed strict episodes,Nikolaj Tatti (University of Antwerp);Boris Cule (University of Antwerp);,"1367500519,2158578835","Discovering patterns in a sequence is an important aspect of data mining. One popular choice of such patterns are episodes, patterns in sequential data describing events that often occur in the vicinity of each other. Episodes also enforce in which order the events are allowed to occur. In this work we introduce a technique for discovering closed episodes. Adopting existing approaches for discovering traditional patterns, such as closed itemsets, to episodes is not straightforward. First of all, we cannot define a unique closure based on frequency because an episode may have several closed superepisodes. Moreover, to define a closedness concept for episodes we need a subset relationship between episodes, which is not trivial to define. We approach these problems by introducing strict episodes. We argue that this class is general enough, and at the same time we are able to define a natural subset relationship within it and use it efficiently. In order to mine closed episodes we define an auxiliary closure operator. We show that this closure satisfies the needed properties so that we can use the existing framework for mining closed patterns. Discovering the true closed episodes can be done as a post-processing step. We combine these observations into an efficient mining algorithm and demonstrate empirically its performance in practice.",2012,Data Mining and Knowledge Discovery volume 25 issue 1 pp 34-66,data mining;machine learning;algorithm;mathematics;
A practical approximation algorithm for optimal k-anonymity,Batya Kenig (Open University);Tamir Tassa (Open University);,"2504852242,71704941","k-Anonymity is a privacy preserving method for limiting disclosure of private information in data mining. The process of anonymizing a database table typically involves generalizing table entries and, consequently, it incurs loss of relevant information. This motivates the search for anonymization algorithms that achieve the required level of anonymization while incurring a minimal loss of information. The problem of k-anonymization with minimal loss of information is NP-hard. We present a practical approximation algorithm that enables solving the k-anonymization problem with an approximation guarantee of O(ln k). That algorithm improves an algorithm due to Aggarwal et al. (Proceedings of the international conference on database theory (ICDT), 2005) that offers an approximation guarantee of O(k), and generalizes that of Park and Shim (SIGMOD ’07: proceedings of the 2007 ACM SIGMOD international conference on management of data, 2007) that was limited to the case of generalization by suppression. Our algorithm uses techniques that we introduce herein for mining closed frequent generalized records. Our experiments show that the significance of our algorithm is not limited only to the theory of k-anonymization. The proposed algorithm achieves lower information losses than the leading approximation algorithm, as well as the leading heuristic algorithms. A modified version of our algorithm that issues l-diverse k-anonymizations also achieves lower information losses than the corresponding modified versions of the leading algorithms.",2012,Data Mining and Knowledge Discovery volume 25 issue 1 pp 134-168,approximation algorithm;theoretical computer science;data mining;database;machine learning;computer science;
Discovering injective episodes with general partial orders,Avinash Achar (Indian Institute of Science);Srivatsan Laxman (Microsoft);Raajay Viswanathan (Microsoft);P. S. Sastry (Indian Institute of Science);,"343987496,2044569235,2514813052,2520038081","Frequent episode discovery is a popular framework for temporal pattern discovery in event streams. An episode is a partially ordered set of nodes with each node associated with an event type. Currently algorithms exist for episode discovery only when the associated partial order is total order (serial episode) or trivial (parallel episode). In this paper, we propose efficient algorithms for discovering frequent episodes with unrestricted partial orders when the associated event-types are unique. These algorithms can be easily specialized to discover only serial or parallel episodes. Also, the algorithms are flexible enough to be specialized for mining in the space of certain interesting subclasses of partial orders. We point out that frequency alone is not a sufficient measure of interestingness in the context of partial order mining. We propose a new interestingness measure for episodes with unrestricted partial orders which, when used along with frequency, results in an efficient scheme of data mining. Simulations are presented to demonstrate the effectiveness of our algorithms.",2012,Data Mining and Knowledge Discovery volume 25 issue 1 pp 67-108,partially ordered set;data mining;machine learning;algorithm;mathematics;
Survey on mining subjective data on the web,Mikalai Tsytsarau (University of Trento);Themis Palpanas (University of Trento);,"18896700,2010554420","In the past years we have witnessed Sentiment Analysis and Opinion Mining becoming increasingly popular topics in Information Retrieval and Web data analysis. With the rapid growth of the user-generated content represented in blogs, wikis and Web forums, such an analysis became a useful tool for mining the Web, since it allowed us to capture sentiments and opinions at a large scale. Opinion retrieval has established itself as an important part of search engines. Ratings, opinion trends and representative opinions enrich the search experience of users when combined with traditional document retrieval, by revealing more insights about a subject. Opinion aggregation over product reviews can be very useful for product marketing and positioning, exposing the customers' attitude towards a product and its features along different dimensions, such as time, geographical location, and experience. Tracking how opinions or discussions evolve over time can help us identify interesting trends and patterns and better understand the ways that information is propagated in the Internet. In this study, we review the development of Sentiment Analysis and Opinion Mining during the last years, and also discuss the evolution of a relatively new research direction, namely, Contradiction Analysis. We give an overview of the proposed methods and recent advances in these areas, and we try to layout the future research directions in the field.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 478-514,sentiment analysis;data science;world wide web;data mining;computer science;
Community detection in Social Media,Symeon Papadopoulos (Aristotle University of Thessaloniki);Yiannis Kompatsiaris (ITT Technical Institute);Athena Vakali (Aristotle University of Thessaloniki);Ploutarchos Spyridonos (Aristotle University of Thessaloniki);,"2143661694,109359389,2045559396,2111433044","The proposed survey discusses the topic of community detection in the context of Social Media. Community detection constitutes a significant tool for the analysis of complex networks by enabling the study of mesoscopic structures that are often associated with organizational and functional characteristics of the underlying networks. Community detection has proven to be valuable in a series of domains, e.g. biology, social sciences, bibliometrics. However, despite the unprecedented scale, complexity and the dynamic nature of the networks derived from Social Media data, there has only been limited discussion of community detection in this context. More specifically, there is hardly any discussion on the performance characteristics of community detection methods as well as the exploitation of their results in the context of real-world web mining and information retrieval scenarios. To this end, this survey first frames the concept of community and the problem of community detection in the context of Social Media, and provides a compact classification of existing algorithms based on their methodological principles. The survey places special emphasis on the performance of existing methods in terms of computational complexity and memory requirements. It presents both a theoretical and an experimental comparative discussion of several popular methods. In addition, it discusses the possibility for incremental application of the methods and proposes five strategies for scaling community detection to real-world networks of huge scales. Finally, the survey deals with the interpretation and exploitation of community detection results in the context of intelligent web applications and services.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 515-554,social media;complex network;computational complexity theory;web mining;data science;world wide web;data mining;machine learning;computer science;
"Web log analysis: a review of a decade of studies about information acquisition, inspection and interpretation of user interaction",Maristella Agosti (University of Padua);Franco Crivellari (University of Padua);Giorgio Maria Di Nunzio (University of Padua);,"2003927988,1264551732,2150234485","In the last decade, the importance of analyzing information management systems logs has grown, because log data constitute a relevant aspect in evaluating the quality of such systems. A review of 10 years of research on log analysis is presented in this paper. About 50 papers and posters from five major conferences and about 30 related journal papers have been selected to trace the history of the state-of-the-art in this field. The paper presents an overview of two main themes: Web search engine log analysis and Digital Library System log analysis. The problem of the analysis of different sources of log data and the distribution of data are investigated.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 663-696,web log analysis software;data science;world wide web;data mining;computer science;
Mining the Semantic Web,Achim Rettinger (Karlsruhe Institute of Technology);Uta Lösch (Karlsruhe Institute of Technology);Volker Tresp (Siemens);Claudia D'Amato (University of Bari);Nicola Fanizzi (University of Bari);,"2050175453,2059695658,175204660,2104431764,2090764765","In the Semantic Web vision of the World Wide Web, content will not only be accessible to humans but will also be available in machine interpretable form as ontological knowledge bases. Ontological knowledge bases enable formal querying and reasoning and, consequently, a main research focus has been the investigation of how deductive reasoning can be utilized in ontological representations to enable more advanced applications. However, purely logic methods have not yet proven to be very effective for several reasons: First, there still is the unsolved problem of scalability of reasoning to Web scale. Second, logical reasoning has problems with uncertain information, which is abundant on Semantic Web data due to its distributed and heterogeneous nature. Third, the construction of ontological knowledge bases suitable for advanced reasoning techniques is complex, which ultimately results in a lack of such expressive real-world data sets with large amounts of instance data. From another perspective, the more expressive structured representations open up new opportunities for data mining, knowledge extraction and machine learning techniques. If moving towards the idea that part of the knowledge already lies in the data, inductive methods appear promising, in particular since inductive methods can inherently handle noisy, inconsistent, uncertain and missing data. While there has been broad coverage of inducing concept structures from less structured sources (text, Web pages), like in ontology learning, given the problems mentioned above, we focus on new methods for dealing with Semantic Web knowledge bases, relying on statistical inference on their standard representations. We argue that machine learning research has to offer a wide variety of methods applicable to different expressivity levels of Semantic Web knowledge bases: ranging from weakly expressive but widely available knowledge bases in RDF to highly expressive first-order knowledge bases, this paper surveys statistical approaches to mining the Semantic Web. We specifically cover similarity and distance-based methods, kernel machines, multivariate prediction models, relational graphical models and first-order probabilistic learning approaches and discuss their applicability to Semantic Web representations. Finally we present selected experiments which were conducted on Semantic Web mining tasks for some of the algorithms presented before. This is intended to show the breadth and general potential of this exiting new research and application area for data mining.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 613-662,web modeling;semantic computing;social semantic web;semantic analytics;semantic grid;semantic web rule language;rdf;description logic;linked data;semantic similarity;semantic web;web intelligence;semantic search;ontology;knowledge representation and reasoning;natural language processing;information retrieval;data mining;machine learning;computer science;
A generalized taxonomy of explanations styles for traditional and social recommender systems,"Alexis Papadimitriou (Aristotle University of Thessaloniki);Panagiotis Symeonidis (Aristotle University of Thessaloniki);Yannis Manolopoulos (University of Maryland, College Park);","2159184480,2401499786,276012958","Recommender systems usually provide explanations of their recommendations to better help users to choose products, activities or even friends. Up until now, the type of an explanation style was considered in accordance to the recommender system that employed it. This relation was one-to-one, meaning that for each different recommender systems category, there was a different explanation style category. However, this kind of one-to-one correspondence can be considered as over-simplistic and non generalizable. In contrast, we consider three fundamental resources that can be used in an explanation: users, items and features and any combination of them. In this survey, we define (i) the Human style of explanation, which provides explanations based on similar users, (ii) the Item style of explanation, which is based on choices made by a user on similar items and (iii) the Feature style of explanation, which explains the recommendation based on item features rated by the user beforehand. By using any combination of the aforementioned styles we can also define the Hybrid style of explanation. We demonstrate how these styles are put into practice, by presenting recommender systems that employ them. Moreover, since there is inadequate research in the impact of social web in contemporary recommender systems and their explanation styles, we study new emerged social recommender systems i.e. Facebook Connect explanations (HuffPo, Netflix, etc.) and geo-social explanations that combine geographical with social data (Gowalla, Facebook Places, etc.). Finally, we summarize the results of three different user studies, to support that Hybrid is the most effective explanation style, since it incorporates all other styles.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 555-583,recommender system;artificial intelligence;machine learning;computer science;
Customer relationship management and Web mining: the next frontier,Alexander Tuzhilin (New York University Stern School of Business);,2057138063,"After a decade of successful development of new Web mining technologies, it is a good time to examine novel promising areas that will advance Web mining over the next decade. This paper argues that CRM is such an area that can benefit from and contribute to further advancements of the Web mining research. This is the case because CRM is an underexplored field that has many open and interesting problems important to the industry and academia. This paper reviews some of the key aspects of CRM, describes certain problems and promising research directions in the field, and discusses how Web mining can contribute to solving these problems.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 584-612,personalization;web intelligence;web mining;world wide web;data mining;computer science;
More than modelling and hiding: towards a comprehensive view of Web mining and privacy,Bettina Berendt (Katholieke Universiteit Leuven);,36886011,"Over the last decade, privacy has been widely recognised as one of the major problems of data collections in general and the Web in particular. This concerns specifically data arising from Web usage (such as querying or transacting) and social networking (characterised by rich self-profiling including relational information) and the inferences drawn from them. The data mining community has been very conscious of these issues and has addressed in particular the inference problems through various methods for ""privacy-preserving data mining"" and ""privacy-preserving data publishing"". However, it appears that these approaches by themselves cannot effectively solve the privacy problems posed by mining. We argue that this is due to the underlying notions of privacy and of data mining, both of which are too narrow. Drawing on notions of privacy not only as hiding, but as control and negotiation, as well as on data mining not only as modelling, but as the whole cycle of knowledge discovery, we offer an alternative view. This is intended to be a comprehensive view of the privacy challenges as well as solution approaches along all phases of the knowledge discovery cycle. The paper thus combines a survey with an outline of an agenda for a comprehensive, interdisciplinary view of Web mining and privacy.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 697-737,privacy software;privacy by design;social network analysis;privacy;web mining;data science;world wide web;data mining;computer science;
Guest editorial: special issue on a decade of mining the Web,Myra Spiliopoulou (Otto-von-Guericke University Magdeburg);Bamshad Mobasher (DePaul University);Olfa Nasraoui (University of Louisville);Osmar R. Zaïane (University of Alberta);,"192509020,1892801027,260981774,2308328903","As editors of the Special Issue on a Decade of Mining the Web, we provide a brief overview of how Web mining evolved from the first Web mining workshop (WEBKDD'99) till today. We then introduce the papers of the special issue. Each of them is in a domain of Web mining research; it contains a survey of the past and a vision for the future.",2012,Data Mining and Knowledge Discovery volume 24 issue 3 pp 473-477,web 2 0;social semantic web;web analytics;data web;web standards;web application security;web development;semantic web;web intelligence;web mining;data science;world wide web;data mining;computer science;
Mining periodic behaviors of object movements for animal and biological sustainability studies,Zhenhui Li (University of Illinois at Urbana–Champaign);Jiawei Han (University of Illinois at Urbana–Champaign);Bolin Ding (University of Illinois at Urbana–Champaign);Roland Kays (North Carolina Museum of Natural Sciences);,"2098136913,2121939561,2642048689,2127760509","Periodicity is one of the most frequently occurring phenomena for moving objects. Animals usually have periodic movement behaviors, such as daily foraging behaviors or yearly migration behaviors. Such periodic behaviors are the keys to understand animal movement and they also reflect the seasonal, climate, or environmental changes of the ecosystem. However, periodic behaviors could be complicated, involving multiple interleaving periods, partial time span, and spatiotemporal noises and outliers. In this paper, we address the problem of mining periodic behaviors for moving objects. It involves two sub-problems: how to detect the periods in complex movements, and how to mine periodic behaviors. A period is usually a single value, such as 24 h. And a periodic behavior is a statistical description of the periodic movement for one specific period. For example, we could describe an animal's daily behavior in the way that ""From 6 pm to 6 am, it has 90% probability staying at location A and from 7 am to 5 pm, it has 70% probability staying at location B and 30% probability staying at location C"". So our tasks is to first detect the periods and then describe each periodic behavior according to different periods. Our main assumption is that the observed movement is generated from multiple interleaved periodic behaviors associated with certain reference locations. Based on this assumption, we propose a two-stage algorithm, Periodica, to solve the problem. At the first stage, the notion of reference spot is proposed to capture the reference locations. Through reference spots, multiple periods in the movement can be retrieved using a method that combines Fourier transform and autocorrelation. At the second stage, a probabilistic model is proposed to characterize the periodic behaviors. For a specific period, periodic behaviors are statistically generalized from partial movement sequences through hierarchical clustering. Finally, we show two extensions to the Periodica algorithm: (1) missing data interpolation, and (2) future movement prediction. Empirical studies on both synthetic and real data sets demonstrate the effectiveness of the proposed method.",2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 355-386,data mining;artificial intelligence;simulation;computer science;
Descriptive matrix factorization for sustainability Adopting the principle of opposites,Christian Thurau (Fraunhofer Society);Kristian Kersting (Fraunhofer Society);Mirwaes Wahabzada (Fraunhofer Society);Christian Bauckhage (Fraunhofer Society);,"2012185565,2252032993,336206225,2034409955","Climate change, the global energy footprint, and strategies for sustainable development have become topics of considerable political and public interest. The public debate is informed by an exponentially growing amount of data and there are diverse partisan interest when it comes to interpretation. We therefore believe that data analysis methods are called for that provide results which are intuitively understandable even to non-experts. Moreover, such methods should be efficient so that non-experts users can perform their own analysis at low expense in order to understand the effects of different parameters and influential factors. In this paper, we discuss a new technique for factorizing data matrices that meets both these requirements. The basic idea is to represent a set of data by means of convex combinations of extreme data points. This often accommodates human cognition. In contrast to established factorization methods, the approach presented in this paper can also determine over-complete bases. At the same time, convex combinations allow for highly efficient matrix factorization. Based on techniques adopted from the field of distance geometry, we derive a linear time algorithm to determine suitable basis vectors for factorization. By means of the example of several environmental and developmental data sets we discuss the performance and characteristics of the proposed approach and validate that significant efficiency gains are obtainable without performance decreases compared to existing convexity constrained approaches.",2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 325-354,distance geometry;matrix decomposition;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
Greener aviation with virtual sensors: a case study,Ashok N. Srivastava (Ames Research Center);,2143728639,"The environmental impact of aviation is enormous given the fact that in the US alone there are nearly 6 million flights per year of commercial aircraft. This situation has driven numerous policy and procedural measures to help develop environmentally friendly technologies which are safe and affordable and reduce the environmental impact of aviation. However, many of these technologies require significant initial investment in newer aircraft fleets and modifications to existing regulations which are both long and costly enterprises. We propose to use an anomaly detection method based on Virtual Sensors to help detect overconsumption of fuel in aircraft which relies only on the data recorded during flight of most existing commercial aircraft, thus significantly reducing the cost and complexity of implementing this method. The Virtual Sensors developed here are ensemble-learning regression models for detecting the overconsumption of fuel based on instantaneous measurements of the aircraft state. This approach requires no additional information about standard operating procedures or other encoded domain knowledge. We present experimental results on three data sets and compare five different Virtual Sensors algorithms. The first two data sets are publicly available and consist of a simulated data set from a flight simulator and a real-world turbine disk. We show the ability to detect anomalies with high accuracy on these data sets. These sets contain seeded faults, meaning that they have been deliberately injected into the system. The second data set is from real-world fleet of 84 jet aircraft where we show the ability to detect fuel overconsumption which can have a significant environmental and economic impact. To the best of our knowledge, this is the first study of its kind in the aviation domain.",2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 443-471,aviation;gaussian process;ensemble learning;anomaly detection;data mining;machine learning;simulation;computer science;
Introduction to data mining for sustainability,"Katharina Morik (Technical University of Dortmund);Kanishka Bhaduri (Ames Research Center);Hillol Kargupta (University of Maryland, Baltimore County);","2070565061,78114061,539587773",-,2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 311-324,data science;data mining;
Tracing Evolving Subspace Clusters in Temporal Climate Data,Stephan Günnemann (RWTH Aachen University);Hardy Kremer (RWTH Aachen University);Charlotte Laufkötter (ETH Zurich);Thomas Seidl (RWTH Aachen University);,"316694267,2130568417,2306460733,2140301036","Analysis of temporal climate data is an active research area. Advanced data mining methods designed especially for these temporal data support the domain expert's pursuit to understand phenomena as the climate change, which is crucial for a sustainable world. Important solutions for mining temporal data are cluster tracing approaches, which are used to mine temporal evolutions of clusters. Generally, clusters represent groups of objects with similar values. In a temporal context like tracing, similar values correspond to similar behavior in one snapshot in time. Each cluster can be interpreted as a behavior type and cluster tracing corresponds to tracking similar behaviors over time. Existing tracing approaches are for datasets satisfying two specific conditions: The clusters appear in all attributes, i.e., fullspace clusters, and the data objects have unique identifiers. These identifiers are used for tracking clusters by measuring the number of objects two clusters have in common, i.e. clusters are traced based on similar object sets. These conditions, however, are strict: First, in complex data, clusters are often hidden in individual subsets of the dimensions. Second, mapping clusters based on similar objects sets does not reflect the idea of tracing similar behavior types over time, because similar behavior can even be represented by clusters having no objects in common. A tracing method based on similar object values is needed. In this paper, we introduce a novel approach that traces subspace clusters based on object value similarity. Neither subspace tracing nor tracing by object value similarity has been done before.",2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 387-410,theoretical computer science;data mining;machine learning;computer science;
Estimating the risk of fire outbreaks in the natural environment,Daniela Stojanova;Andrej Kobler;Peter Ogrinc;Bernard Ženko;Sašo Džeroski (University of Freiburg);,"2037620856,2020869069,303558565,218991779,1419022840","A constant and controlled level of emission of carbon and other gases into the atmosphere is a pre-condition for preventing global warming and an essential issue for a sustainable world. Fires in the natural environment are phenomena that extensively increase the level of greenhouse emissions and disturb the normal functioning of natural ecosystems. Therefore, estimating the risk of fire outbreaks and fire prevention are the first steps in reducing the damage caused by fire. In this study, we build predictive models to estimate the risk of fire outbreaks in Slovenia, using data from a GIS, Remote Sensing imagery and the weather prediction model ALADIN. The study is carried out on three datasets, from three regions: one for the Kras region, one for the coastal region and one for continental Slovenia. On these datasets, we apply both classical statistical approaches and state-of-the-art data mining algorithms, such as ensembles of decision trees, in order to obtain predictive models of fire outbreaks. In addition, we explore the influence of fire fuel information on the performance of the models, measured in terms of accuracy, Kappa statistic, precision and recall. Best results in terms of predictive accuracy are obtained by ensembles of decision trees.",2012,Data Mining and Knowledge Discovery volume 24 issue 2 pp 411-442,biological classification;simulation;
Scalable influence maximization for independent cascade model in large-scale social networks,Chi Wang (University of Illinois at Urbana–Champaign);Wei Chen (Microsoft);Yajun Wang (Microsoft);,"2461963590,2527738285,2567737653","Influence maximization, defined by Kempe et al. (SIGKDD 2003), is the problem of finding a small set of seed nodes in a social network that maximizes the spread of influence under certain influence cascade models. The scalability of influence maximization is a key factor for enabling prevalent viral marketing in large-scale online social networks. Prior solutions, such as the greedy algorithm of Kempe et al. (SIGKDD 2003) and its improvements are slow and not scalable, while other heuristic algorithms do not provide consistently good performance on influence spreads. In this article, we design a new heuristic algorithm that is easily scalable to millions of nodes and edges in our experiments. Our algorithm has a simple tunable parameter for users to control the balance between the running time and the influence spread of the algorithm. Our results from extensive simulations on several real-world and synthetic networks demonstrate that our algorithm is currently the best scalable solution to the influence maximization problem: (a) our algorithm scales beyond million-sized graphs where the greedy algorithm becomes infeasible, and (b) in all size ranges, our algorithm performs consistently well in influence spread—it is always among the best algorithms, and in most cases it significantly outperforms all other scalable heuristics to as much as 100–260% increase in influence spread.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 545-576,viral marketing;social network;theoretical computer science;machine learning;mathematical optimization;computer science;
Clustering daily patterns of human activities in the city,Shan Jiang (Massachusetts Institute of Technology);Joseph Ferreira (Massachusetts Institute of Technology);Marta C. González (Massachusetts Institute of Technology);,"2674653191,2147702459,2277322729","Data mining and statistical learning techniques are powerful analysis tools yet to be incorporated in the domain of urban studies and transportation research. In this work, we analyze an activity-based travel survey conducted in the Chicago metropolitan area over a demographic representative sample of its population. Detailed data on activities by time of day were collected from more than 30,000 individuals (and 10,552 households) who participated in a 1-day or 2-day survey implemented from January 2007 to February 2008. We examine this large-scale data in order to explore three critical issues: (1) the inherent daily activity structure of individuals in a metropolitan area, (2) the variation of individual daily activities—how they grow and fade over time, and (3) clusters of individual behaviors and the revelation of their related socio-demographic information. We find that the population can be clustered into 8 and 7 representative groups according to their activities during weekdays and weekends, respectively. Our results enrich the traditional divisions consisting of only three groups (workers, students and non-workers) and provide clusters based on activities of different time of day. The generated clusters combined with social demographic information provide a new perspective for urban and transportation planning as well as for emergency response and spreading dynamics, by addressing when, where, and how individuals interact with places in metropolitan areas.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 478-510,metropolitan area;eigendecomposition of a matrix;simulation;
Learning influence from heterogeneous social networks,Lu Liu (Capital Medical University);Jie Tang (Tsinghua University);Jiawei Han (University of Illinois at Urbana–Champaign);Shiqiang Yang (Tsinghua University);,"2536075520,2158012360,2121939561,2127183023","Influence is a complex and subtle force that governs social dynamics and user behaviors. Understanding how users influence each other can benefit various applications, e.g., viral marketing, recommendation, information retrieval and etc. While prior work has mainly focused on qualitative aspect, in this article, we present our research in quantitatively learning influence between users in heterogeneous networks. We propose a generative graphical model which leverages both heterogeneous link information and textual content associated with each user in the network to mine topic-level influence strength. Based on the learned direct influence, we further study the influence propagation and aggregation mechanisms: conservative and non-conservative propagations to derive the indirect influence. We apply the discovered influence to user behavior prediction in four different genres of social networks: Twitter, Digg, Renren, and Citation. Qualitatively, our approach can discover some interesting influence patterns from these heterogeneous networks. Quantitatively, the learned influence strength greatly improves the accuracy of user behavior prediction.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 511-544,topic model;social network analysis;multimedia;world wide web;data mining;machine learning;computer science;
Guest editorial: Special issue on data mining technologies for computational social science,Fei Wang 0001 (IBM);Hanghang Tong (IBM);Philip S. Yu (University of Illinois at Chicago);Charu C. Aggarwal (IBM);,"2465953593,2224718883,2125104194,2146335907",-,2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 415-419,-
Clustering large attributed information networks: an efficient incremental computing approach,Hong Cheng (The Chinese University of Hong Kong);Yang Zhou (Georgia Institute of Technology);Xin Huang (The Chinese University of Hong Kong);Jeffrey Xu Yu (The Chinese University of Hong Kong);,"2161754280,2625264668,2150026201,2119358208","In recent years, many information networks have become available for analysis, including social networks, road networks, sensor networks, biological networks, etc. Graph clustering has shown its effectiveness in analyzing and visualizing large networks. The goal of graph clustering is to partition vertices in a large graph into clusters based on various criteria such as vertex connectivity or neighborhood similarity. Many existing graph clustering methods mainly focus on the topological structures, but largely ignore the vertex properties which are often heterogeneous. Recently, a new graph clustering algorithm, SA-cluster, has been proposed which combines structural and attribute similarities through a unified distance measure. SA-Cluster performs matrix multiplication to calculate the random walk distances between graph vertices. As part of the clustering refinement, the graph edge weights are iteratively adjusted to balance the relative importance between structural and attribute similarities. As a consequence, matrix multiplication is repeated in each iteration of the clustering process to recalculate the random walk distances which are affected by the edge weight update. In order to improve the efficiency and scalability of SA-cluster, in this paper, we propose an efficient algorithm In-Cluster to incrementally update the random walk distances given the edge weight increments. Complexity analysis is provided to estimate how much runtime cost Inc-Cluster can save. We further design parallel matrix computation techniques on a multicore architecture. Experimental results demonstrate that Inc-Cluster achieves significant speedup over SA-Cluster on large graphs, while achieving exactly the same clustering quality in terms of intra-cluster structural cohesiveness and attribute value homogeneity.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 450-477,canopy clustering algorithm;strength of a graph;graph bandwidth;level structure;correlation clustering;constrained clustering;power graph analysis;data stream clustering;spatial network;cure data clustering algorithm;random geometric graph;clustering coefficient;fuzzy clustering;graph partition;complex network;cluster analysis;discrete mathematics;combinatorics;data mining;machine learning;statistics;computer science;mathematics;
Behavioral event data and their analysis,"Ian N. Davidson (University of California, Davis);Sean Gilpin (University of California, Davis);Peter B. Walker (Naval Medical Research Center);","2560595684,2021798691,2136497257","Social science is broadly defined as the analysis of human behavior whether it be at an individual or a group level. In this work, we explore the analysis of human behavior encoded as a trail of their events over time and space, which we refer to as behavioral event data. We show that such data offers challenges to data mining algorithm designers as the data to analyze is naturally multi-way, involves complex patterns that form/reform over time, and has complex interactions between groups in the population. Though the data naturally lends itself to be represented as graphs and tensors we show how existing techniques are limited in their usefulness and outline our own algorithms to overcome these challenges. In this paper, using the adversarial event behavior of blue and red forces, we show three core problems and solutions in event behavior analysis: (1) Decomposing behavior to identify areas of intense activity, (2) Predicting what groups of events are likely to occur, and (3) Analysis to identify interacting behavior given a known template.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 635-653,data science;data mining;computer science;
Mining blackhole and volcano patterns in directed graphs: a general approach,Zhongmou Li (Rutgers–Newark);Hui Xiong (Rutgers–Newark);Yanchi Liu (University of Science and Technology Beijing);,"2158697087,2153710278,2159798580","Given a directed graph, the problem of blackhole mining is to identify groups of nodes, called blackhole patterns, in a way such that the average in-weight of this group is significantly larger than the average out-weight of the same group. The problem of finding volcano patterns is a dual problem of mining blackhole patterns. Therefore, we focus on discovering the blackhole patterns. Indeed, in this article, we develop a generalized blackhole mining framework. Specifically, we first design two pruning schemes for reducing the computational cost by reducing both the number of candidate patterns and the average computation cost for each candidate pattern. The first pruning scheme is to exploit the concept of combination dominance to reduce the exponential growth search space. Based on this pruning approach, we develop the gBlackhole algorithm. Instead, the second pruning scheme is an approximate approach, named approxBlackhole, which can strike a balance between the efficiency and the completeness of blackhole mining. Finally, experimental results on real-world data show that the performance of approxBlackhole can be several orders of magnitude faster than gBlackhole, and both of them have huge computational advantages over the brute-force approach. Also, we show that the blackhole mining algorithm can be used to capture some suspicious financial fraud patterns.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 577-602,computer security;data mining;machine learning;
Using EmotiBlog to annotate and analyse subjectivity in the new textual genres,Ester Boldrini (University of Alicante);Alexandra Balahur (University of Alicante);Patricio Martínez-Barco (University of Alicante);Andrés Montoyo (University of Alicante);,"2052205103,125440414,150475307,1209450393","Thanks to the increasing amount of subjective data on the Web 2.0, tools to manage and exploit such data become essential. Our research is focused on the creation of EmotiBlog, a fine-grained annotation scheme for labelling subjectivity in non-traditional textual genres. We also present the EmotiBlog corpus; a collection of blog posts composed by 270,000 tokens about 3 topics and in 3 languages: Spanish, English and Italian. Additionally, we carry out a series of experiments focused on checking the robustness of the model and its applicability to Natural Language Processing tasks with regards to the 3 languages. The experiments for the inter-annotator agreement, as well as for feature selection, provided satisfactory results, which have given an impetus to continue working with the model and extend the annotated corpus. In order to check its applicability, we tested different Machine Learning models created using the annotation in EmotiBlog on other corpora in order to see if the obtained annotation is domain and genre independent, obtaining positive results. Finally, we also applied EmotiBlog to Opinion Mining, proving that our resource allows an improvement the performance of systems built for this task.",2012,Data Mining and Knowledge Discovery volume 25 issue 3 pp 603-634,resource;sentiment analysis;natural language processing;information retrieval;data mining;machine learning;computer science;
Hellinger distance decision trees are robust and skew-insensitive,David A. Cieslak (University of Notre Dame);T. Ryan Hoens (University of Notre Dame);Nitesh V. Chawla (University of Notre Dame);W. Philip Kegelmeyer (University of Notre Dame);,"2004286868,679846916,1979796846,389943480","Learning from imbalanced data is an important and common problem. Decision trees, supplemented with sampling techniques, have proven to be an effective way to address the imbalanced data problem. Despite their effectiveness, however, sampling methods add complexity and the need for parameter selection. To bypass these difficulties we propose a new decision tree technique called Hellinger Distance Decision Trees (HDDT) which uses Hellinger distance as the splitting criterion. We analytically and empirically demonstrate the strong skew insensitivity of Hellinger distance and its advantages over popular alternatives such as entropy (gain ratio). We apply a comprehensive empirical evaluation framework testing against commonly used sampling and ensemble methods, considering performance across 58 varied datasets. We demonstrate the superiority (using robust tests of statistical significance) of HDDT on imbalanced data, as well as its competitive performance on balanced datasets. We thereby arrive at the particularly practical conclusion that for imbalanced data it is sufficient to use Hellinger trees with bagging (BG) without any sampling methods. We provide all the datasets and software for this paper online ( http://www.nd.edu/~dial/hddt ).",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 136-158,hellinger distance;decision tree;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
DHCC: Divisive hierarchical clustering of categorical data,Tengke Xiong (Université de Sherbrooke);Shengrui Wang (Université de Sherbrooke);André Mayers (Université de Sherbrooke);Ernest Monga (Université de Sherbrooke);,"2164669555,2106818440,1939414168,2007490044","Clustering categorical data poses two challenges defining an inherently meaningful similarity measure, and effectively dealing with clusters which are often embedded in different subspaces. In this paper, we propose a novel divisive hierarchical clustering algorithm for categorical data, named DHCC. We view the task of clustering categorical data from an optimization perspective, and propose effective procedures to initialize and refine the splitting of clusters. The initialization of the splitting is based on multiple correspondence analysis (MCA). We also devise a strategy for deciding when to terminate the splitting process. The proposed algorithm has five merits. First, due to its hierarchical nature, our algorithm yields a dendrogram representing nested groupings of patterns and similarity levels at different granularities. Second, it is parameter-free, fully automatic and, in particular, requires no assumption regarding the number of clusters. Third, it is independent of the order in which the data is processed. Fourth, it is scalable to large data sets. And finally, our algorithm is capable of seamlessly discovering clusters embedded in subspaces, thanks to its use of a novel data representation and Chi-square dissimilarity measures. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 103-135,k medians clustering;hierarchical clustering of networks;brown clustering;canopy clustering algorithm;determining the number of clusters in a data set;correlation clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;dendrogram;fuzzy clustering;clustering high dimensional data;hierarchical clustering;categorical variable;cluster analysis;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
An inductive database system based on virtual mining views,Hendrik Blockeel (Katholieke Universiteit Leuven);Toon Calders (Eindhoven University of Technology);Élisa Fromont (Centre national de la recherche scientifique);Bart Goethals (University of Antwerp);Adriana Prado (Centre national de la recherche scientifique);Céline Robardet (University of Lyon);,"2049189351,2064105222,2142341142,1992071743,2140192241,1976373341","Inductive databases integrate database querying with database mining. In this article, we present an inductive database system that does not rely on a new data mining query language, but on plain SQL. We propose an intuitive and elegant framework based on virtual mining views, which are relational tables that virtually contain the complete output of data mining algorithms executed over a given data table. We show that several types of patterns and models that are implicitly present in the data, such as itemsets, association rules, and decision trees, can be represented and queried with SQL using a unifying framework. As a proof of concept, we illustrate a complete data mining scenario with SQL queries over the mining views, which is executed in our system.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 247-287,null;database model;data definition language;view;query by example;temporal database;query optimization;database design;query language;concept mining;intelligent database;data stream mining;information retrieval;data mining;database;computer science;
Projection approaches to process mining using region-based techniques,Josep Carmona (Polytechnic University of Catalonia);,2146037330,"Traces are everywhere from information systems that store their continuous executions, to any type of health care applications that record each patient's history. The transformation of a set of traces into a mathematical model that can be used for a formal reasoning is therefore of great value. The discovery of process models out of traces is an interesting problem that has received significant attention in the last years. This is a central problem in Process Mining, a novel area which tries to close the cycle between system design and validation, by resorting on methods for the automated discovery, analysis and extension of process models. In this work, algorithms for the derivation of a Petri net from a set of traces are presented. The methods are grounded on the theory of regions, which maps a model in the state-based domain (e.g., an automata) into a model in the event-based domain (e.g., a Petri net). When dealing with large examples, a direct application of the theory of regions will suffer from two problems: one is the state-explosion problem, i.e., the resources required by algorithms that work at the state-level are sometimes prohibitive. This paper introduces decomposition and projection techniques to alleviate the complexity of the region-based algorithms for Petri net discovery, thus extending its applicability to handle large inputs. A second problem is known as the overfitting problem for region-based approaches, which informally means that, in order to represent with high accuracy the trace set, the models obtained are often spaghetti-like. By focusing on special type of processes called conservative and for which an elegant theory and efficient algorithms can be devised, the techniques presented in this paper alleviate the overfitting problem and moreover incorporate structure into the models generated.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 218-246,process mining;petri net;data mining;machine learning;statistics;algorithm;computer science;mathematics;
Mining spatial colocation patterns: a different framework,Jin Soung Yoo (Indiana University – Purdue University Fort Wayne);Mark Bow (Indiana University – Purdue University Fort Wayne);,"2038679102,1833652979","Recently, there has been considerable interest in mining spatial colocation patterns from large spatial datasets. Spatial colocation patterns represent the subsets of spatial events whose instances are often located in close geographic proximity. Most studies of spatial colocation mining require the specification of two parameter constraints to find interesting colocation patterns. One is a minimum prevalent threshold of colocations, and the other is a distance threshold to define spatial neighborhood. However, it is difficult for users to decide appropriate threshold values without prior knowledge of their task-specific spatial data. In this paper, we propose a different framework for spatial colocation pattern mining. To remove the first constraint, we propose the problem of finding N-most prevalent colocated event sets, where N is the desired number of colocated event sets with the highest interest measure values per each pattern size. We developed two alternative algorithms for mining the N-most patterns. They reduce candidate events effectively and use a filter-and-refine strategy for efficiently finding colocation instances from a spatial dataset. We prove the algorithms are correct and complete in finding the N-most prevalent colocation patterns. For the second constraint, a distance threshold for spatial neighborhood determination, we present various methods to estimate appropriate distance bounds from user input data. The result can help an user to set a distance for a conceptualization of spatial neighborhood. Our experimental results with real and synthetic datasets show that our algorithmic design is computationally effective in finding the N-most prevalent colocation patterns. The discovered patterns were different depending on the distance threshold, which shows that it is important to select appropriate neighbor distances.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 159-194,data science;data mining;machine learning;
Using trees to mine multirelational databases,Aída Jiménez (University of Granada);Fernando Berzal (University of Granada);Juan-Carlos Cubero (University of Granada);,"2129692324,1562381855,2131691236","This paper proposes a new approach to mine multirelational databases. Our approach is based on the representation of multirelational databases as sets of trees, for which we propose two alternative representation schemes. Tree mining techniques can thus be applied as the basis for multirelational data mining techniques, such as multirelational classification or multirelational clustering. We analyze the differences between identifying induced and embedded tree patterns in the proposed tree-based representation schemes and we study the relationships among the sets of tree patterns that can be discovered in each case. This paper also describes how these frequent tree patterns can be used, for instance, to mine association rules in multirelational databases.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 1-39,association rule learning;data mining;pattern recognition;machine learning;computer science;mathematics;
Data mining from a patient safety database: the lessons learned,James Bentham (King's College London);David J. Hand (Imperial College London);,"2663590556,2175518357","The issue of patient safety is an extremely important one; each year in the UK, hundreds of thousands of people suffer due to some sort of incident that occurs whilst they are in National Health Service care. The National Patient Safety Agency (NPSA) works to try to reduce the scale of the problem. One of its major projects is to collect a very large dataset, the Reporting and Learning System (RLS), which describes several million of these incidents. The RLS is used as the basis for research by the NPSA. However, the NPSA has identified a gap in their work between high-level quantitative analysis and detailed, manual analysis of small samples. This paper describes the lessons learned from a knowledge discovery process that attempted to fill this gap. The RLS contains a free text description of each incident. A high dimensional model of the text is calculated, using the vector space model with term weighting applied. Dimensionality reduction techniques are used to produce the final models of the text. These models are examined using an anomaly detection tool to find groups of incidents that should be coherent in meaning, and that might be of interest to the NPSA. A three stage process is developed for assessing the results. The first stage uses a quantitative measure based on the use of planted groups of known interest, the second stage involves manual filtering by a non-expert, and the third stage is assessment by clinical experts.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 195-217,knowledge extraction;information extraction;data science;data mining;machine learning;simulation;statistics;computer science;
Efficient prediction algorithms for binary decomposition techniques,Sang-Hyeun Park (Technische Universität Darmstadt);Johannes Fürnkranz (Technische Universität Darmstadt);,"2170901016,52482323","Binary decomposition methods transform multiclass learning problems into a series of two-class learning problems that can be solved with simpler learning algorithms. As the number of such binary learning problems often grows super-linearly with the number of classes, we need efficient methods for computing the predictions. In this article, we discuss an efficient algorithm that queries only a dynamically determined subset of the trained classifiers, but still predicts the same classes that would have been predicted if all classifiers had been queried. The algorithm is first derived for the simple case of pairwise classification, and then generalized to arbitrary pairwise decompositions of the learning problem in the form of ternary error-correcting output codes under a variety of different code designs and decoding strategies.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 40-77,multiclass classification;data mining;pattern recognition;machine learning;computer science;mathematics;
Entropy on covers,Zhimin Wang (Harvard University);,2511699430,"As a generalization of partitions, covers allow overlaps between their members. In this paper, we will propose a family of entropy-like measures over covers, which are anti monotonic with regard to the partial order defined by refinement relations of covers. In parallel to the entropy theory, we also develop their conditional forms, which in turn lead to a family of semi-metrics on covers. These make it possible to apply entropy-based techniques in data mining or machine learning to problems naturally modelled by covers.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 288-309,cover;entropy;feature selection;discrete mathematics;combinatorics;machine learning;computer science;mathematics;
Mining local and tail dependence structures based on pointwise mutual information,Teruko Takada (Osaka City University);,2112769489,"The behavior of events that occur infrequently but have a large impact tends to differ from that of the central tendency, and identifying the tail dependence structure among key factors is critical for controlling risks. However, due to technical difficulties, conventional analyses of dependence have focused on the global average dependence. This article proposes a novel approach for analyzing the entire structure of nonlinear dependence between two data sets on the basis of accurate pointwise mutual information estimation. The emphasis is on fat-tailed distributions that tend to appear in events involving sudden large changes. The proposed pointwise mutual information estimator is sufficiently robust and efficient for exploring tail dependence, and its good performance was confirmed in an experimental study. The significance of the identified dependence structure was assessed using the proposed bootstrap procedure. New facts were discovered from its application to daily returns and volume on the New York stock Exchange (NYSE) Composite Index.",2012,Data Mining and Knowledge Discovery volume 24 issue 1 pp 78-102,pointwise mutual information;volume;data visualization;econometrics;data mining;statistics;mathematics;
Maximum entropy models and subjective interestingness: an application to tiles in binary databases,Tijl De Bie (University of Bristol);,2080198120,"Recent research has highlighted the practical benefits of subjective interestingness measures, which quantify the novelty or unexpectedness of a pattern when contrasted with any prior information of the data miner (Silberschatz and Tuzhilin, Proceedings of the 1st ACM SIGKDD international conference on Knowledge discovery and data mining (KDD95), 1995; Geng and Hamilton, ACM Comput Surv 38(3):9, 2006). A key challenge here is the formalization of this prior information in a way that lends itself to the definition of a subjective interestingness measure that is both meaningful and practical. In this paper, we outline a general strategy of how this could be achieved, before working out the details for a use case that is important in its own right. Our general strategy is based on considering prior information as constraints on a probabilistic model representing the uncertainty about the data. More specifically, we represent the prior information by the maximum entropy (MaxEnt) distribution subject to these constraints. We briefly outline various measures that could subsequently be used to contrast patterns with this MaxEnt model, thus quantifying their subjective interestingness. We demonstrate this strategy for rectangular databases with knowledge of the row and column sums. This situation has been considered before using computation intensive approaches based on swap randomizations, allowing for the computation of empirical p-values as interestingness measures (Gionis et al., ACM Trans Knowl Discov Data 1(3):14, 2007). We show how the MaxEnt model can be computed remarkably efficiently in this situation, and how it can be used for the same purpose as swap randomizations but computationally more efficiently. More importantly, being an explicitly represented distribution, the MaxEnt model can additionally be used to define analytically computable interestingness measures, as we demonstrate for tiles (Geerts et al., Proceedings of the 7th international conference on Discovery science (DS04), 2004) in binary databases.",2011,Data Mining and Knowledge Discovery volume 23 issue 3 pp 407-446,principle of maximum entropy;data mining;artificial intelligence;machine learning;statistics;mathematics;
Leveraging social media networks for classification,Lei Tang (Yahoo!);Huan Liu (Arizona State University);,"2141813676,2122391114","Social media has reshaped the way in which people interact with each other. The rapid development of participatory web and social networking sites like YouTube, Twitter, and Facebook, also brings about many data mining opportunities and novel challenges. In particular, we focus on classification tasks with user interaction information in a social network. Networks in social media are heterogeneous, consisting of various relations. Since the relation-type information may not be available in social media, most existing approaches treat these inhomogeneous connections homogeneously, leading to an unsatisfactory classification performance. In order to handle the network heterogeneity, we propose the concept of social dimension to represent actors' latent affiliations, and develop a classification framework based on that. The proposed framework, SocioDim, first extracts social dimensions based on the network structure to accurately capture prominent interaction patterns between actors, then learns a discriminative classifier to select relevant social dimensions. SocioDim, by differentiating different types of network connections, outperforms existing representative methods of classification in social media, and offers a simple yet effective approach to integrating two types of seemingly orthogonal information: the network of actors and their attributes.",2011,Data Mining and Knowledge Discovery volume 23 issue 3 pp 447-478,organizational network analysis;social heuristics;dynamic network analysis;social media;social network analysis;social network;social computing;statistical relational learning;data mining;machine learning;computer science;
Publishing anonymous survey rating data,Xiaoxun Sun (Australian Council for Educational Research);Hua Wang (University of Southern Queensland);Jiuyong Li (University of South Australia);Jian Pei (Simon Fraser University);,"2149439472,2306205450,2095948822,2126330539","We study the challenges of protecting privacy of individuals in the large public survey rating data in this paper. Recent study shows that personal information in supposedly anonymous movie rating records are de-identified. The survey rating data usually contains both ratings of sensitive and non-sensitive issues. The ratings of sensitive issues involve personal privacy. Even though the survey participants do not reveal any of their ratings, their survey records are potentially identifiable by using information from other public sources. None of the existing anonymisation principles (e.g., k-anonymity, l-diversity, etc.) can effectively prevent such breaches in large survey rating data sets. We tackle the problem by defining a principle called $${(k,\epsilon)}$$ -anonymity model to protect privacy. Intuitively, the principle requires that, for each transaction t in the given survey rating data T, at least (k ? 1) other transactions in T must have ratings similar to t, where the similarity is controlled by $${\epsilon}$$ . The $${(k,\epsilon)}$$ -anonymity model is formulated by its graphical representation and a specific graph-anonymisation problem is studied by adopting graph modification with graph theory. Various cases are analyzed and methods are developed to make the updated graph meet $${(k,\epsilon)}$$ requirements. The methods are applied to two real-life data sets to demonstrate their efficiency and practical utility.",2011,Data Mining and Knowledge Discovery volume 23 issue 3 pp 379-406,educational assessment;graph theory;internet privacy;world wide web;data mining;statistics;computer science;
All normalized anti-monotonic overlap graph measures are bounded,Toon Calders (Eindhoven University of Technology);Jan Ramon (Katholieke Universiteit Leuven);Dries Van Dyck (University of Hasselt);,"2064105222,2168801554,2055535156","In graph mining, a frequency measure for graphs is anti-monotonic if the frequency of a pattern never exceeds the frequency of a subpattern. The efficiency and correctness of most graph pattern miners relies critically on this property. We study the case where frequent subgraphs have to be found in one graph. Vanetik et al. (Data Min Knowl Disc 13(2):243---260, 2006) already gave sufficient and necessary conditions for anti-monotonicity of graph measures depending only on the edge-overlaps between the instances of the pattern in a labeled graph. We extend these results to homomorphisms, isomorphisms and homeomorphisms on both labeled and unlabeled, directed and undirected graphs, for vertex- and edge-overlap. We show a set of reductions between the different morphisms that preserve overlap. As a secondary contribution, we prove that the popular maximum independent set measure assigns the minimal possible normalized frequency and we introduce a new measure based on the minimum clique partition that assigns the maximum possible normalized frequency. In that way, we obtain that all normalized anti-monotonic overlap graph measures are bounded from above and below. We also introduce a new measure sandwiched between the former two based on the polynomial time computable Lovasz ?-function.",2011,Data Mining and Knowledge Discovery volume 23 issue 3 pp 503-548,windmill graph;simplex graph;strength of a graph;voltage graph;complement graph;forbidden graph characterization;coxeter graph;graph power;butterfly graph;string graph;comparability graph;null graph;circulant graph;circle graph;split graph;graph property;cubic graph;line graph;regular graph;degree;independent set;time complexity;discrete mathematics;combinatorics;topology;computer science;mathematics;
Measuring the component overlapping in the Gaussian mixture model,Haojun Sun (Shantou University);Shengrui Wang (Université de Sherbrooke);,"2723216079,2648810655","The ability of a clustering algorithm to deal with overlapping clusters is a major indicator of its efficiency. However, the phenomenon of cluster overlapping is still not mathematically well characterized, especially in multivariate cases. In this paper, we are interested in the overlap phenomenon between Gaussian clusters, since the Gaussian mixture is a fundamental data distribution model suitable for many clustering algorithms. We introduce the novel concept of the ridge curve and establish a theory on the degree of overlap between two components. Based on this theory, we develop an algorithm for calculating the overlap rate. As an example, we use this algorithm to calculate the overlap rates between the classes in the IRIS data set and clear up some of the confusion as to the true number of classes in the data set. We investigate factors that affect the value of the overlap rate, and show how the theory can be used to generate ""truthed data"" as well as to measure the overlap rate between a given pair of clusters or components in a mixture. Finally, we show an example of application of the theory to evaluate the well known clustering algorithms.",2011,Data Mining and Knowledge Discovery volume 23 issue 3 pp 479-502,determining the number of clusters in a data set;mixture model;cluster analysis;econometrics;machine learning;statistics;computer science;mathematics;
Summarizing transactional databases with overlapped hyperrectangles,Yang Xiang (Ohio State University);Ruoming Jin (Kent State University);David Fuhry (Ohio State University);Feodor F. Dragan (Kent State University);,"2572284403,2119237514,2398106800,664281783","Transactional data are ubiquitous. Several methods, including frequent itemset mining and co-clustering, have been proposed to analyze transactional databases. In this work, we propose a new research problem to succinctly summarize transactional databases. Solving this problem requires linking the high level structure of the database to a potentially huge number of frequent itemsets. We formulate this problem as a set covering problem using overlapped hyperrectangles (a concept generally regarded as tile according to some existing papers); we then prove that this problem and its several variations are NP-hard, and we further reveal its relationship with the compact representation of a directed bipartite graph. We develop an approximation algorithm Hyper which can achieve a logarithmic approximation ratio in polynomial time. We propose a pruning strategy that can significantly speed up the processing of our algorithm, and we also propose an efficient algorithm Hyper+ to further summarize the set of hyperrectangles by allowing false positive conditions. Additionally, we show that hyperrectangles generated by our algorithms can be properly visualized. A detailed study using both real and synthetic datasets shows the effectiveness and efficiency of our approaches in summarizing transactional databases.",2011,Data Mining and Knowledge Discovery volume 23 issue 2 pp 215-251,set cover problem;automatic summarization;theoretical computer science;data mining;database;computer science;mathematics;
Matching samples of multiple views,Abhishek Tripathi (Helsinki Institute for Information Technology);Arto Klami (Helsinki Institute for Information Technology);Matej Orešič (VTT Technical Research Centre of Finland);Samuel Kaski (Helsinki Institute for Information Technology);,"2131724366,144686356,2067118172,1221219011","Multi-view learning studies how several views, different feature representations, of the same objects could be best utilized in learning. In other words, multi-view learning is analysis of co-occurrence data, where the observations are co-occurrences of samples in the views. Standard multi-view learning such as joint density modeling cannot be done in the absence of co-occurrence, when the views are observed separately and the identities of objects are not known. As a practical example, joint analysis of mRNA and protein concentrations requires mapping between genes and proteins. We introduce a data-driven approach for learning the correspondence of the observations in the different views, in order to enable joint analysis also in the absence of known co-occurrence. The method finds a matching that maximizes statistical dependency between the views, which is particularly suitable for multi-view methods such as canonical correlation analysis which has the same objective. We apply the method to translational metabolomics, to identify differences and commonalities in metabolic processes in different species or tissues. The metabolite identities and roles in the different species are not generally known, and it is necessary to search for a matching. In this paper we show, using different metabolomics measurement batches as the views so that the ground truth is known, that the metabolite identities can be reliably matched by a consensus of several matching solutions.",2011,Data Mining and Knowledge Discovery volume 23 issue 2 pp 300-321,canonical correlation;bipartite graph;bioinformatics;data mining;machine learning;statistics;mathematics;
Fast density-weighted low-rank approximation spectral clustering,Fanhua Shang (Xidian University);Licheng Jiao (Xidian University);Jiarong Shi (Xidian University);Maoguo Gong (Xidian University);Ronghua Shang (Xidian University);,"1972696148,2166558591,2324806398,2139563917,1985245930","While spectral clustering can produce high-quality clusterings on small data sets, computational cost makes it infeasible for large data sets. Affinity Propagation (AP) has a limitation that it is hard to determine the value of parameter `preference' which can lead to an optimal clustering solution. These problems limit the scope of application of the two methods. In this paper, we develop a novel fast two-stage spectral clustering framework with local and global consistency. Under this framework, we propose a Fast density-Weighted low-rank Approximation Spectral Clustering (FWASC) algorithm to address the above issues. The proposed algorithm is a high-quality graph partitioning method, and simultaneously considers both the local and global structure information contained in the data sets. Specifically, we first present a new Fast Two-Stage AP (FTSAP) algorithm to coarsen the input sparse graph and produce a small number of final representative exemplars, which is a simple and efficient sampling scheme. Then we present a density-weighted low-rank approximation spectral clustering algorithm to operate those representative exemplars on the global underlying structure of data manifold. Experimental results show that our algorithm outperforms the state-of-the-art spectral clustering and original AP algorithms in terms of speed, memory usage, and quality.",2011,Data Mining and Knowledge Discovery volume 23 issue 2 pp 345-378,flame clustering;k medians clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;spectral clustering;fuzzy clustering;graph partition;clustering high dimensional data;cluster analysis;data mining;pattern recognition;machine learning;mathematical optimization;statistics;computer science;mathematics;
Mining frequent itemsets over distributed data streams by continuously maintaining a global synopsis,En Tzu Wang (Industrial Technology Research Institute);Arbee L. P. Chen (National Chengchi University);,"2431917719,2211440602","Mining frequent itemsets over data streams has attracted much research attention in recent years. In the past, we had developed a hash-based approach for mining frequent itemsets over a single data stream. In this paper, we extend that approach to mine global frequent itemsets from a collection of data streams distributed at distinct remote sites. To speed up the mining process, we make the first attempt to address a new problem on continuously maintaining a global synopsis for the union of all the distributed streams. The mining results therefore can be yielded on demand by directly processing the maintained global synopsis. Instead of collecting and processing all the data in a central server, which may waste the computation resources of remote sites, distributed computations over the data streams are performed. A distributed computation framework is proposed in this paper, including two communication strategies and one merging operation. These communication strategies are designed according to an accuracy guarantee of the mining results, determining when and what the remote sites should transmit to the central server (named coordinator). On the other hand, the merging operation is exploited to merge the information received from the remote sites into the global synopsis maintained at the coordinator. By the strategies and operation, the goal of continuously maintaining the global synopsis can be achieved. Rooted in the continuously maintained global synopsis, we propose a mining algorithm for finding global frequent itemsets. Moreover, the correctness guarantees of the communication strategies and merging operation, and the accuracy guarantee analysis of the mining algorithm are provided. Finally, a series of experiments on synthetic datasets and a real dataset are performed to show the effectiveness and efficiency of the distributed computation framework.",2011,Data Mining and Knowledge Discovery volume 23 issue 2 pp 252-299,data stream mining;distributed computing;data mining;database;computer science;
Sequence classification via large margin hidden Markov models,Minyoung Kim (Seoul National University of Science and Technology);Vladimir Pavlovic (Rutgers University);,"2305839646,1969768610","We address the sequence classification problem using a probabilistic model based on hidden Markov models (HMMs). In contrast to commonly-used likelihood-based learning methods such as the joint/conditional maximum likelihood estimator, we introduce a discriminative learning algorithm that focuses on class margin maximization. Our approach has two main advantages: (i) As an extension of support vector machines (SVMs) to sequential, non-Euclidean data, the approach inherits benefits of margin-based classifiers, such as the provable generalization error bounds. (ii) Unlike many algorithms based on non-parametric estimation of similarity measures that enforce weak constraints on the data domain, our approach utilizes the HMM's latent Markov structure to regularize the model in the high-dimensional sequence space. We demonstrate significant improvements in classification performance of the proposed method in an extensive set of evaluations on time-series sequence data that frequently appear in data mining and computer vision domains.",2011,Data Mining and Knowledge Discovery volume 23 issue 2 pp 322-344,variable order markov model;maximum entropy markov model;hidden semi markov model;sequence space;discrimination learning;generalization error;support vector machine;time series;statistical model;hidden markov model;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Krimp: mining itemsets that compress,Jilles Vreeken (Utrecht University);Matthijs van Leeuwen (Utrecht University);Arno Siebes (Utrecht University);,"1971070670,2143928993,1988376837","One of the major problems in pattern mining is the explosion of the number of results. Tight constraints reveal only common knowledge, while loose constraints lead to an explosion in the number of returned patterns. This is caused by large groups of patterns essentially describing the same set of transactions. In this paper we approach this problem using the MDL principle: the best set of patterns is that set that compresses the database best. For this task we introduce the Krimp algorithm. Experimental evaluation shows that typically only hundreds of itemsets are returned; a dramatic reduction, up to seven orders of magnitude, in the number of frequent item sets. These selections, called code tables, are of high quality. This is shown with compression ratios, swap-randomisation, and the accuracies of the code table-based Krimp classifier, all obtained on a wide range of datasets. Further, we extensively evaluate the heuristic choices made in the design of the algorithm.",2011,Data Mining and Knowledge Discovery volume 23 issue 1 pp 169-214,common knowledge;compression ratio;data mining;pattern recognition;algorithm;mathematics;
Learning model trees from evolving data streams,Elena Ikonomovska;João Gama (University of Porto);Sašo Džeroski (University of Freiburg);,"2255580020,2113857198,1419022840","The problem of real-time extraction of meaningful patterns from time-changing data streams is of increasing importance for the machine learning and data mining communities. Regression in time-changing data streams is a relatively unexplored topic, despite the apparent applications. This paper proposes an efficient and incremental stream mining algorithm which is able to learn regression and model trees from possibly unbounded, high-speed and time-changing data streams. The algorithm is evaluated extensively in a variety of settings involving artificial and real data. To the best of our knowledge there is no other general purpose algorithm for incremental learning regression/model trees able to perform explicit change detection and informed adaptation. The algorithm performs online and in real-time, observes each example only once at the speed of arrival, and maintains at any-time a ready-to-use model tree. The tree leaves contain linear models induced online from the examples assigned to them, a process with low complexity. The algorithm has mechanisms for drift detection and model adaptation, which enable it to maintain accurate and updated regression models at any time. The drift detection mechanism exploits the structure of the tree in the process of local change detection. As a response to local drift, the algorithm is able to update the tree structure only locally. This approach improves the any-time performance and greatly reduces the costs of adaptation.",2011,Data Mining and Knowledge Discovery volume 23 issue 1 pp 128-168,population based incremental learning;incremental decision tree;concept drift;daylight saving time;change detection;tree structure;linear model;regression analysis;data stream mining;data mining;pattern recognition;machine learning;statistics;computer science;
Mixed-membership naive Bayes models,Hanhuai Shan (University of Minnesota);Arindam Banerjee (University of Minnesota);,"2101454519,2037585042","In recent years, mixture models have found widespread usage in discovering latent cluster structure from data. A popular special case of finite mixture models is the family of naive Bayes (NB) models, where the probability of a feature vector factorizes over the features for any given component of the mixture. Despite their popularity, naive Bayes models do not allow data points to belong to different component clusters with varying degrees, i.e., mixed memberships, which puts a restriction on their modeling ability. In this paper, we propose mixed-membership naive Bayes (MMNB) models. On one hand, MMNB can be viewed as a generalization of NB by putting a Dirichlet prior on top to allow mixed memberships. On the other hand, MMNB can also be viewed as a generalization of latent Dirichlet allocation (LDA) with the ability to handle heterogeneous feature vectors with different types of features, e.g., real, categorical, etc.. We propose two variational inference algorithms to learn MMNB models. The first one is based on ideas originally used in LDA, and the second one uses substantially fewer variational parameters, leading to a significantly faster algorithm. Further, we extend MMNB/LDA to discriminative mixed-membership models for classification by suitably combining MMNB/LDA with multi-class logistic regression. The efficacy of the proposed mixed-membership models is demonstrated by extensive experiments on several datasets, including UCI benchmarks, recommendation systems, and text datasets.",2011,Data Mining and Knowledge Discovery volume 23 issue 1 pp 1-62,dynamic topic model;latent dirichlet allocation;mixture model;recommender system;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
An efficient and effective similarity measure to enable data mining of petroglyphs,"Qiang Zhu 0002 (University of California, Riverside);Xiaoyue Wang (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);Sang-Hee Lee (University of California, Riverside);","2312006013,2170860754,2170070822,2168330173","Rock art is an archaeological term for human-made markings on stone, including carved markings, known as petroglyphs, and painted markings, known as pictographs. It is believed that there are millions of petroglyphs in North America alone, and the study of this valued cultural resource has implications even beyond anthropology and history. Surprisingly, although image processing, information retrieval and data mining have had a large impact on many human endeavors, they have had essentially zero impact on the study of rock art. In this work we identify the reasons for this, and introduce a novel distance measure and algorithms which allow efficient and effective data mining of large collections of rock art.",2011,Data Mining and Knowledge Discovery volume 23 issue 1 pp 91-127,nearest neighbor search;image processing;data science;data mining;computer science;
Improving constrained pattern mining with first-fail-based heuristics,Christian Desrosiers (École de technologie supérieure);Philippe Galinier (École Polytechnique de Montréal);Alain Hertz (École Polytechnique de Montréal);Pierre Hansen (HEC Montréal);,"2139768026,281358777,2158636173,2099733369","In this paper, we present a general framework to mine patterns with antimonotone constraints. This framework uses a technique that structures the pattern space in a way that facilitates the integration of constraints within the mining process. Furthermore, we also introduce a powerful strategy that uses background information on the data to speed-up the mining process. We illustrate our approach on a popular structured data mining problem, the frequent subgraph mining problem, and show, through experiments on synthetic and real-life data, that this general approach has advantages over state-of-the-art pattern mining algorithms.",2011,Data Mining and Knowledge Discovery volume 23 issue 1 pp 63-90,k optimal pattern discovery;molecule mining;data model;concept mining;data stream mining;data science;data mining;machine learning;computer science;
Manifold elastic net: a unified framework for sparse dimension reduction,Tianyi Zhou (Nanyang Technological University);Dacheng Tao (Nanyang Technological University);Xindong Wu (University of Vermont);,"2153604853,2104129307,2123651450","It is difficult to find the optimal sparse solution of a manifold learning based dimensionality reduction algorithm. The lasso or the elastic net penalized manifold learning based dimensionality reduction is not directly a lasso penalized least square problem and thus the least angle regression (LARS) (Efron et al., Ann Stat 32(2):407---499, 2004), one of the most popular algorithms in sparse learning, cannot be applied. Therefore, most current approaches take indirect ways or have strict settings, which can be inconvenient for applications. In this paper, we proposed the manifold elastic net or MEN for short. MEN incorporates the merits of both the manifold learning based dimensionality reduction and the sparse learning based dimensionality reduction. By using a series of equivalent transformations, we show MEN is equivalent to the lasso penalized least square problem and thus LARS is adopted to obtain the optimal sparse solution of MEN. In particular, MEN has the following advantages for subsequent classification: (1) the local geometry of samples is well preserved for low dimensional data representation, (2) both the margin maximization and the classification error minimization are considered for sparse projection calculation, (3) the projection matrix of MEN improves the parsimony in computation, (4) the elastic net penalty reduces the over-fitting problem, and (5) the projection matrix of MEN can be interpreted psychologically and physiologically. Experimental evidence on face recognition over various popular datasets suggests that MEN is superior to top level dimensionality reduction algorithms.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 340-371,manifold alignment;dimensionality reduction;facial recognition system;pattern recognition;machine learning;mathematical optimization;statistics;computer science;mathematics;
Community discovery using nonnegative matrix factorization,Fei Wang 0001 (Florida International University);Tao Li (Florida International University);Xin Wang 0013 (Florida International University);Shenghuo Zhu (NEC);Chris H. Q. Ding (University of Texas at Arlington);,"2465953593,2472069284,2640972814,2096537073,2119616764","Complex networks exist in a wide range of real world systems, such as social networks, technological networks, and biological networks. During the last decades, many researchers have concentrated on exploring some common things contained in those large networks include the small-world property, power-law degree distributions, and network connectivity. In this paper, we will investigate another important issue, community discovery, in network analysis. We choose Nonnegative Matrix Factorization (NMF) as our tool to find the communities because of its powerful interpretability and close relationship between clustering methods. Targeting different types of networks (undirected, directed and compound), we propose three NMF techniques (Symmetric NMF, Asymmetric NMF and Joint NMF). The correctness and convergence properties of those algorithms are also studied. Finally the experiments on real world networks are presented to show the effectiveness of the proposed methods.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 493-521,evolving networks;network motif;non negative matrix factorization;biological network;degree distribution;complex network;network analysis;power law;social network;theoretical computer science;data mining;machine learning;computer science;mathematics;
"Nonnegative tensor factorization as an alternative Csiszar---Tusnady procedure: algorithms, convergence, probabilistic interpretations and novel probabilistic tensor latent variable analysis algorithms",Stefanos Zafeiriou (Imperial College London);Maria Petrou (Imperial College London);,"2293457281,2275174282","In this paper we study Nonnegative Tensor Factorization (NTF) based on the Kullback---Leibler (KL) divergence as an alternative Csiszar---Tusnady procedure. We propose new update rules for the aforementioned divergence that are based on multiplicative update rules. The proposed algorithms are built on solid theoretical foundations that guarantee that the limit point of the iterative algorithm corresponds to a stationary solution of the optimization procedure. Moreover, we study the convergence properties of the optimization procedure and we present generalized pythagorean rules. Furthermore, we provide clear probabilistic interpretations of these algorithms. Finally, we discuss the connections between generalized Probabilistic Tensor Latent Variable Models (PTLVM) and NTF, proposing in that way algorithms for PTLVM for arbitrary multivariate probabilistic mass functions.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 419-466,probabilistic latent semantic analysis;latent class model;probabilistic analysis of algorithms;kullback leibler divergence;pattern recognition;machine learning;mathematical optimization;statistics;computer science;mathematics;
Matrix-variate and higher-order probabilistic projections,Shipeng Yu (Siemens Healthcare);Jinbo Bi (University of Connecticut);Jieping Ye (Arizona State University);,"2162740804,2066975796,2305258894","Feature extraction from two-dimensional or higher-order data, such as face images and surveillance videos, have recently been an active research area. There have been several 2D or higher-order PCA-style dimensionality reduction algorithms, but they mostly lack probabilistic interpretations and are difficult to apply with, e.g., incomplete data. It is also hard to extend these algorithms for applications where a certain region of the data point needs special focus in the dimensionality reduction process (e.g., the facial region in a face image). In this paper we propose a probabilistic dimensionality reduction framework for 2D and higher-order data. It specifies a particular generative process for this type of data, and leads to better understanding of some 2D and higher-order PCA-style algorithms. In particular, we show it actually takes several existing algorithms as its (non-probabilistic) special cases. We develop efficient iterative learning algorithms within this framework and study the theoretical properties of the stationary points. The model can be easily extended to handle special regions in the high-order data. Empirical studies on several benchmark data and real-world cardiac ultrasound images demonstrate the strength of this framework.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 372-392,probabilistic analysis of algorithms;dimensionality reduction;empirical research;higher order logic;feature extraction;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
"Guest editorial: special issue on data mining with matrices, graphs and tensors",Tao Li (Florida International University);Chris H. Q. Ding (University of Texas at Arlington);Fei Wang 0001 (IBM);,"2472069284,2119616764,2465953593",-,2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 337-339,data science;data mining;machine learning;computer science;
Learning bidirectional asymmetric similarity for collaborative filtering via matrix factorization,Bin Cao (Hong Kong University of Science and Technology);Qiang Yang (Hong Kong University of Science and Technology);Jian-Tao Sun (Microsoft);Zheng Chen (Microsoft);,"2606635942,2109031554,2131116857,2425877144","Memory-based collaborative filtering (CF) aims at predicting the rating of a certain item for a particular user based on the previous ratings from similar users and/or similar items. Previous studies in finding similar users and items have several drawbacks. First, they are based on user-defined similarity measurements, such as Pearson Correlation Coefficient (PCC) or Vector Space Similarity (VSS), which are, for the most part, not adaptive and optimized for specific applications and data. Second, these similarity measures are restricted to symmetric ones such that the similarity between A and B is the same as that for B and A, although symmetry may not always hold in many real world applications. Third, they typically treat the similarity functions between users and functions between items separately. However, in reality, the similarities between users and between items are inter-related. In this paper, we propose a novel unified model for users and items, known as Similarity Learning based Collaborative Filtering (SLCF) , based on a novel adaptive bidirectional asymmetric similarity measurement. Our proposed model automatically learns asymmetric similarities between users and items at the same time through matrix factorization. Theoretical analysis shows that our model is a novel generalization of singular value decomposition (SVD). We show that, once the similarity relation is learned, it can be used flexibly in many ways for rating prediction. To take full advantage of the model, we propose several strategies to make the best use of the proposed similarity function for rating prediction. The similarity can be used either to improve the memory-based approaches or directly in a model based CF approaches. In addition, we also propose an online version of the rating prediction method to incorporate new users and new items. We evaluate SLCF using three benchmark datasets, including MovieLens, EachMovie and Netflix, through which we show that our methods can outperform many state-of-the-art baselines.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 393-418,similarity heuristic;semantic similarity;collaborative filtering;unified model;singular value decomposition;matrix decomposition;vector space;information retrieval;data mining;machine learning;statistics;mathematics;
Hierarchical visual event pattern mining and its applications,Peng Cui (Tsinghua University);Zhi-Qiang Liu;Li-Feng Sun (Tsinghua University);Shi-Qiang Yang (Tsinghua University);,"2113115369,2685703474,2134465402,2127183023","In this paper, we propose a hierarchical visual event pattern mining approach and utilize the patterns to address the key problems in video mining and understanding field. We classify events into primitive events (PEs) and compound events (CEs), where PEs are the units of CEs, and CEs serve as smooth priors and rules for PEs. We first propose a tensor-based video representation and Joint Matrix Factorization (JMF) for unsupervised primitive event categorization. Then we apply frequent pattern mining techniques to discover compound event pattern structures. After that, we utilize the two kinds of event patterns to address the applications of event recognition and anomaly detection. First we extend the Sequential Monte Carlo (SMC) method to recognition of live, sequential visual events. To accomplish this task we present a scheme that alternatively recognizes primitive and compound events in one framework. Then, we categorize the anomalies into abnormal events (never seen events) and abnormal contexts (rule breakers), and the two kinds of anomalies are detected simultaneously by embedding a deviation criterion into the SMC framework. Extensive experiments have been conducted which demonstrate that the proposed approach is effective as compared to other major approaches.",2011,Data Mining and Knowledge Discovery volume 22 issue 3 pp 467-492,particle filter;matrix decomposition;anomaly detection;data mining;pattern recognition;machine learning;computer science;
A survey of hierarchical classification across different application domains,Carlos Nascimento Silla (University of Kent);Alex Alves Freitas (University of Kent);,"2157703898,2131502281","In this survey we discuss the task of hierarchical classification. The literature about this field is scattered across very different application domains and for that reason research in one domain is often done unaware of methods developed in other domains. We define what is the task of hierarchical classification and discuss why some related tasks should not be considered hierarchical classification. We also present a new perspective about some existing hierarchical classification approaches, and based on that perspective we propose a new unifying framework to classify the existing approaches. We also present a review of empirical comparisons of the existing methods reported in the literature as well as a conceptual comparison of those methods at a high level of abstraction, discussing their advantages and disadvantages.",2011,Data Mining and Knowledge Discovery volume 22 issue 12 pp 31-72,tree structure;computer programming;data mining;machine learning;algorithm;computer science;
"Time series shapelets: a novel technique that allows accurate, interpretable and fast classification","Lexiang Ye (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2123231084,2170070822","Classification of time series has been attracting great interest over the past decade. While dozens of techniques have been introduced, recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems, especially for large-scale datasets. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a high time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data and to make the classification result more explainable, which global characteristics of the nearest neighbor cannot provide. In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations. Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. We can use the distance to the shapelet, rather than the distance to the nearest neighbor to classify objects. As we shall show with extensive empirical evaluations in diverse domains, classification algorithms based on the time series shapelet primitives can be interpretable, more accurate, and significantly faster than state-of-the-art classifiers.",2011,Data Mining and Knowledge Discovery volume 22 pp 149-182,best bin first;dspace;empirical evidence;decision tree;k nearest neighbors algorithm;time series;biological classification;data mining;pattern recognition;machine learning;computer science;mathematics;
Web robot detection techniques: overview and limitations,Derek Doran (University of Connecticut);Swapna S. Gokhale (University of Connecticut);,"2666509796,2172162018","Most modern Web robots that crawl the Internet to support value-added services and technologies possess sophisticated data collection and analysis capabilities. Some of these robots, however, may be ill-behaved or malicious, and hence, may impose a significant strain on a Web server. It is thus necessary to detect Web robots in order to block undesirable ones from accessing the server. Such detection is also essential to ensure that the robot traffic is considered appropriately in the performance and capacity planning of Web servers. Despite a variety of Web robot detection techniques, there is no consensus regarding a single technique, or even a specific ""type"" of technique, that performs well in practice. Therefore, to aid in the development of a practically applicable robot detection technique, this survey presents a critical analysis and comparison of the prevalent detection approaches. We propose a framework to classify the existing detection techniques into four categories based on their underlying detection philosophy. We compare the different classes to gain insights into those characteristics that make up an effective robot detection scheme. Finally, we discuss why the contemporary techniques fail to offer a general solution to the robot detection problem and propose a set of key ingredients necessary for strong Web robot detection.",2011,Data Mining and Knowledge Discovery volume 22 pp 183-210,web modeling;robots exclusion standard;web analytics;data web;web mapping;web application security;web development;web design;web crawler;web navigation;web server;web service;data collection;web intelligence;world wide web;data mining;simulation;computer science;
Learning Bayesian networks by hill climbing: efficient methods based on progressive restriction of the neighborhood,José A. Gámez (University of Castilla–La Mancha);Juan L. Mateo (University of Castilla–La Mancha);José Miguel Puerta (University of Castilla–La Mancha);,"2149808126,2141158417,2150251006","Learning Bayesian networks is known to be an NP-hard problem and that is the reason why the application of a heuristic search has proven advantageous in many domains. This learning approach is computationally efficient and, even though it does not guarantee an optimal result, many previous studies have shown that it obtains very good solutions. Hill climbing algorithms are particularly popular because of their good trade-off between computational demands and the quality of the models learned. In spite of this efficiency, when it comes to dealing with high-dimensional datasets, these algorithms can be improved upon, and this is the goal of this paper. Thus, we present an approach to improve hill climbing algorithms based on dynamically restricting the candidate solutions to be evaluated during the search process. This proposal, dynamic restriction, is new because other studies available in the literature about restricted search in the literature are based on two stages rather than only one as it is presented here. In addition to the aforementioned advantages of hill climbing algorithms, we show that under certain conditions the model they return is a minimal I-map of the joint probability distribution underlying the training data, which is a nice theoretical property with practical implications. In this paper we provided theoretical results that guarantee that, under these same conditions, the proposed algorithms also output a minimal I-map. Furthermore, we experimentally test the proposed algorithms over a set of different domains, some of them quite large (up to 800 variables), in order to study their behavior in practice.",2011,Data Mining and Knowledge Discovery volume 22 pp 106-148,np hard;hill climbing;bayesian network;probability distribution;heuristic;data mining;artificial intelligence;machine learning;mathematical optimization;statistics;computer science;mathematics;
Identifying predictive multi-dimensional time series motifs: an application to severe weather prediction,Amy McGovern (University of Oklahoma);Derek H. Rosendahl (University of Oklahoma);Rodger A. Brown (National Oceanic and Atmospheric Administration);Kelvin K. Droegemeier (University of Oklahoma);,"2110730349,2017665602,2143422341,2167491240","We introduce an efficient approach to mining multi-dimensional temporal streams of real-world data for ordered temporal motifs that can be used for prediction. Since many of the dimensions of the data are known or suspected to be irrelevant, our approach first identifies the salient dimensions of the data, then the key temporal motifs within each dimension, and finally the temporal ordering of the motifs necessary for prediction. For the prediction element, the data are assumed to be labeled. We tested the approach on two real-world data sets. To verify the generality of the approach, we validated the application on several subjects from the CMU Motion Capture database. Our main application uses several hundred numerically simulated supercell thunderstorms where the goal is to identify the most important features and feature interrelationships which herald the development of strong rotation in the lowest altitudes of a storm. We identified sets of precursors, in the form of meteorological quantities reaching extreme values in a particular temporal sequence, unique to storms producing strong low-altitude rotation. The eventual goal is to use this knowledge for future severe weather detection and prediction algorithms.",2011,Data Mining and Knowledge Discovery volume 22 pp 232-258,severe weather;motion capture;extreme value theory;time series;computer simulation;data science;data mining;machine learning;simulation;statistics;computer science;
Classifier evaluation and attribute selection against active adversaries,Murat Kantarcıoğlu (University of Texas at Dallas);Bowei Xi (Purdue University);Chris Clifton (Purdue University);,"332400322,2060668786,2158488542","Many data mining applications, such as spam filtering and intrusion detection, are faced with active adversaries. In all these applications, the future data sets and the training data set are no longer from the same population, due to the transformations employed by the adversaries. Hence a main assumption for the existing classification techniques no longer holds and initially successful classifiers degrade easily. This becomes a game between the adversary and the data miner: The adversary modifies its strategy to avoid being detected by the current classifier; the data miner then updates its classifier based on the new threats. In this paper, we investigate the possibility of an equilibrium in this seemingly never ending game, where neither party has an incentive to change. Modifying the classifier causes too many false positives with too little increase in true positives; changes by the adversary decrease the utility of the false negative items that are not detected. We develop a game theoretic framework where equilibrium behavior of adversarial classification applications can be analyzed, and provide solutions for finding an equilibrium point. A classifier's equilibrium performance indicates its eventual success or failure. The data miner could then select attributes based on their equilibrium performance, and construct an effective classifier. A case study on online lending data demonstrates how to apply the proposed game theoretic framework to a real application.",2011,Data Mining and Knowledge Discovery volume 22 pp 291-335,performance indicator;intrusion detection system;equilibrium point;type i and type ii errors;simulated annealing;game theory;computer security;data mining;machine learning;computer science;
A disk-aware algorithm for time series motif discovery,"Abdullah Mueen (University of California, Riverside);Eamonn Keogh (University of California, Riverside);Qiang Zhu (University of California, Riverside);Sydney S. Cash (Harvard University);M. Brandon Westover (Harvard University);Nima Bigdely-Shamlo (University of California, San Diego);","2083987245,2170070822,2312006013,2010431758,2037513643,330581843","Time series motifs are sets of very similar subsequences of a long time series. They are of interest in their own right, and are also used as inputs in several higher-level data mining algorithms including classification, clustering, rule-discovery and summarization. In spite of extensive research in recent years, finding time series motifs exactly in massive databases is an open problem. Previous efforts either found approximate motifs or considered relatively small datasets residing in main memory. In this work, we leverage off previous work on pivot-based indexing to introduce a disk-aware algorithm to find time series motifs exactly in multi-gigabyte databases which contain on the order of tens of millions of time series. We have evaluated our algorithm on datasets from diverse areas including medicine, anthropology, computer networking and image processing and show that we can find interesting and meaningful motifs in datasets that are many orders of magnitude larger than anything considered before.",2011,Data Mining and Knowledge Discovery volume 22 pp 73-105,pruning;time series;data science;data mining;machine learning;statistics;computer science;
Tree pattern expression for extracting information from syntactically parsed text corpora,Yong Suk Choi (Hanyang University);,2674537755,"With the public availability of a number of syntactically parsed text corpora, it has been increasingly important to efficiently extract desired information from such corpora. Many conventional works extract a desired text part by matching the parse tree of each sentence to a query that is represented as a structural form of relational predicates expressing a common structural pattern of desired text parts. However, although those works can be useful for limited types of simple queries, they are not very efficient in general because query formulations are sometimes very complicated for complex patterns of desired text parts and query matching tasks are likely to be exponentially time-consuming when considering a variety of complex sentential structures in a text corpus. In order to overcome such inadequacy, we present a novel tree pattern expression (TPE) that can represent various structural patterns intuitively and reduce pattern-matching complexity significantly. This paper first proposes TPE and its pattern-matching algorithm, and then theoretically analyzes the complexity of the proposed pattern-matching algorithm. It also illustrates a TPE-based information extraction system, which is applied to real text mining in a bio-text corpus. It finally shows some experimental results with some discussions in comparison with other systems.",2011,Data Mining and Knowledge Discovery volume 22 pp 211-231,pattern matching;information extraction;text mining;natural language processing;data mining;pattern recognition;machine learning;computer science;
Selective sampling techniques for feedback-based data retrieval,Hwanjo Yu (Pohang University of Science and Technology);,2663814781,"As many databases have been brought online, data retrieval--finding relevant data from large databases--has become a nontrivial task. A feedback-based data retrieval system was proposed to provide user with an intuitive way for expressing their preferences in queries. The system iteratively receives a partial ordering on a sample of data from the user, learns a ranking function, and returns highly ranked results according to the function. An important issue in such retrieval systems is minimizing the number of iterations or the amount of feedback to learn an accurate ranking function. This paper proposes selective sampling (or active learning) techniques for RankSVM that can be used in the retrieval systems. The proposed techniques minimizes the amount of user interaction to learn an accurate ranking function thus facilitates users formulating a preference query in the data retrieval system.",2011,Data Mining and Knowledge Discovery volume 22 pp 1-30,ranking;active learning;data retrieval;partially ordered set;information retrieval;data mining;machine learning;computer science;
Detecting and ordering salient regions,Larry Shoemaker (University of South Florida);Robert E. Banfield (University of South Florida);Lawrence O. Hall (University of South Florida);Kevin W. Bowyer (University of Notre Dame);W. Philip Kegelmeyer (Sandia National Laboratories);,"2108592759,2102169363,2159848645,2042301190,389943480","We describe an ensemble approach to learning salient regions from arbitrarily partitioned data. The partitioning comes from the distributed processing requirements of large-scale simulations. The volume of the data is such that classifiers can train only on data local to a given partition. Since the data partition reflects the needs of the simulation, the class statistics can vary from partition to partition. Some classes will likely be missing from some or even most partitions. We combine a fast ensemble learning algorithm with scaled probabilistic majority voting in order to learn an accurate classifier from such data. Since some simulations are difficult to model without a considerable number of false positive errors, and since we are essentially building a search engine for simulation data, we order predicted regions to increase the likelihood that most of the top-ranked predictions are correct (salient). Results from simulation runs of a canister being torn and from a casing being dropped show that regions of interest are successfully identified in spite of the class imbalance in the individual training sets. Lift curve analysis shows that the use of data driven ordering methods provides a statistically significant improvement over the use of the default, natural time step ordering. Significant time is saved for the end user by allowing an improved focus on areas of interest without the need to conventionally search all of the data.",2011,Data Mining and Knowledge Discovery volume 22 pp 259-290,lift;random forest;salience;type i and type ii errors;majority rule;region of interest;search engine;statistical significance;ensemble learning;data mining;pattern recognition;machine learning;statistics;computer science;
Nanosecond pulsed laser induced fluorescence : a powerful tool to probe atomic and molecular plasmas kinetics,Ead Emile Carbone (Eindhoven University of Technology);Jm Jose Palomares (Eindhoven University of Technology);S Simon Hübner (Eindhoven University of Technology);van der Jjam Joost Mullen (Eindhoven University of Technology);,"2563636999,2115957836,2107705907,1984048624",-,2011,Data Mining and Knowledge Discovery,laser induced fluorescence;kinetics;computer science;
Laser assisted electron gas heating: revision of the criterion for high pressure non-thermal plasmas,Ead Emile Carbone (Eindhoven University of Technology);Jm Jose Palomares (Eindhoven University of Technology);S Simon Hübner (Eindhoven University of Technology);van der Jjam Joost Mullen (Eindhoven University of Technology);,"2563636999,2115957836,2107705907,1984048624",-,2011,Data Mining and Knowledge Discovery,high pressure;computer science;
Laser scattering techniques applied to cold atmospheric plasmas : trends and pitfalls,Jm Jose Palomares (Eindhoven University of Technology);Ead Emile Carbone (Eindhoven University of Technology);S Simon Hübner (Eindhoven University of Technology);van Afh Bram Gessel (Eindhoven University of Technology);van der Jjam Joost Mullen (Eindhoven University of Technology);,"2115957836,2563636999,2107705907,2080079427,1984048624",-,2011,Data Mining and Knowledge Discovery,-
Re-examination of interestingness measures in pattern mining: a unified framework,Tianyi Wu (University of Illinois at Urbana–Champaign);Yuguo Chen (University of Illinois at Urbana–Champaign);Jiawei Han (University of Illinois at Urbana–Champaign);,"2164603845,2150631181,2121939561","Numerous interestingness measures have been proposed in statistics and data mining to assess object relationships. This is especially important in recent studies of association or correlation pattern mining. However, it is still not clear whether there is any intrinsic relationship among many proposed measures, and which one is truly effective at gauging object relationships in large data sets. Recent studies have identified a critical property, null-(transaction) invariance, for measuring associations among events in large data sets, but many measures do not have this property. In this study, we re-examine a set of null-invariant interestingness measures and find that they can be expressed as the generalized mathematical mean, leading to a total ordering of them. Such a unified framework provides insights into the underlying philosophy of the measures and helps us understand and select the proper measure for different applications. Moreover, we propose a new measure called Imbalance Ratio to gauge the degree of skewness of a data set. We also discuss the efficient computation of interesting patterns of different null-invariant interestingness measures by proposing an algorithm, GAMiner, which complements previous studies. Experimental evaluation verifies the effectiveness of the unified framework and shows that GAMiner speeds up the state-of-the-art algorithm by an order of magnitude.",2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 371-397,generalized mean;total order;association rule learning;data mining;pattern recognition;statistics;mathematics;
A clustering comparison measure using density profiles and its application to the discovery of alternate clusterings,Eric Bae (NICTA);James Bailey (NICTA);Guozhu Dong (Wright State University);,"2150440477,2131557737,2164298414","Data clustering is a fundamental and very popular method of data analysis. Its subjective nature, however, means that different clustering algorithms or different parameter settings can produce widely varying and sometimes conflicting results. This has led to the use of clustering comparison measures to quantify the degree of similarity between alternative clusterings. Existing measures, though, can be limited in their ability to assess similarity and sometimes generate unintuitive results. They also cannot be applied to compare clusterings which contain different data points, an activity which is important for scenarios such as data stream analysis. In this paper, we introduce a new clustering similarity measure, known as ADCO, which aims to address some limitations of existing measures, by allowing greater flexibility of comparison via the use of density profiles to characterize a clustering. In particular, it adopts a `data mining style' philosophy to clustering comparison, whereby two clusterings are considered to be more similar, if they are likely to give rise to similar types of prediction models. Furthermore, we show that this new measure can be applied as a highly effective objective function within a new algorithm, known as MAXIMUS, for generating alternate clusterings.",2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 427-471,correlation clustering;constrained clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;cluster analysis;data mining;pattern recognition;machine learning;computer science;
A weighted voting summarization of SOM ensembles,Bruno Baruque (University of Burgos);Emilio Corchado (University of Salamanca);,"88680535,155781915","Weighted Voting Superposition is a novel summarization algorithm for the results of an ensemble of Self-Organizing Maps. Its principal aim is to achieve the lowest topographic error in the map in order to obtain the best possible visualization of the internal structure of the data sets under study. This is done by means of a weighted voting process between the neurons of the ensemble maps in order to determine the characteristics of the neurons in the resulting map. The algorithm is applied in this case to the most widely known topology preserving mapping architecture: the Self- Organizing Map. A comparison is made between the novel fusion algorithm presented in this work and other previously devised fusion algorithms, along with a new variation of those algorithms, called Ordered Similarity. Although a practical example of the new algorithm was introduced in an earlier work, a rigorous description and analysis is presented here for the first time by comparing the performance of the aforementioned algorithms in relation to three well-known data sets (Iris, Wisconsin Breast Cancer and Wine) obtained from Internet repositories. The results show how this novel fusion algorithm outperforms the other fusion algorithms, yielding better visualization results for ensemble summarization of maps.",2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 398-426,breast cancer;self organizing map;ensemble learning;data visualization;data mining;artificial intelligence;machine learning;computer science;
Density-based semi-supervised clustering,Carlos Ruiz (Technical University of Madrid);Myra Spiliopoulou (Otto-von-Guericke University Magdeburg);Ernestina Menasalvas (Technical University of Madrid);,"2159696880,192509020,2219424376","Semi-supervised clustering methods guide the data partitioning and grouping process by exploiting background knowledge, among else in the form of constraints. In this study, we propose a semi-supervised density-based clustering method. Density-based algorithms are traditionally used in applications, where the anticipated groups are expected to assume non-spherical shapes and/or differ in cardinality or density. Many such applications, among else those on GIS, lend themselves to constraint-based clustering, because there is a priori knowledge on the group membership of some records. In fact, constraints might be the only way to prevent the formation of clusters that do not conform to the applications' semantics. For example, geographical objects, e.g. houses, separated by a borderline or a river may not be assigned to the same cluster, independently of their physical proximity. We first provide an overview of constraint-based clustering for different families of clustering algorithms. Then, we concentrate on the density-based algorithms' family and select the algorithm DBSCAN, which we enhance with Must-Link and Cannot-Link constraints. Our enhancement is seamless: we allow DBSCAN to build temporary clusters, which we then split or merge according to the constraints. Our experiments on synthetic and real datasets show that our approach improves the performance of the algorithm.",2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 345-370,k medians clustering;flame clustering;subclu;brown clustering;canopy clustering algorithm;optics algorithm;determining the number of clusters in a data set;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;fuzzy clustering;a priori and a posteriori;clustering high dimensional data;group dynamics;cluster analysis;consensus clustering;biclustering;data mining;pattern recognition;machine learning;mathematics;
Exact indexing for massive time series databases under time warping distance,Vit Niennattrakul (Chulalongkorn University);Pongsakorn Ruengronghirunya (Chulalongkorn University);Chotirat Ann Ratanamahatana (Chulalongkorn University);,"233889838,349267795,2091934636","Among many existing distance measures for time series data, Dynamic Time Warping (DTW) distance has been recognized as one of the most accurate and suitable distance measures due to its flexibility in sequence alignment. However, DTW distance calculation is computationally intensive. Especially in very large time series databases, sequential scan through the entire database is definitely impractical, even with random access that exploits some index structures since high dimensionality of time series data incurs extremely high I/O cost. More specifically, a sequential structure consumes high CPU but low I/O costs, while an index structure requires low CPU but high I/O costs. In this work, we therefore propose a novel indexed sequential structure called TWIST (Time Warping in Indexed Sequential sTructure) which benefits from both sequential access and index structure. When a query sequence is issued, TWIST calculates lower bounding distances between a group of candidate sequences and the query sequence, and then identifies the data access order in advance, hence reducing a great number of both sequential and random accesses. Impressively, our indexed sequential structure achieves significant speedup in a querying process. In addition, our method shows superiority over existing rival methods in terms of query processing time, number of page accesses, and storage requirement with no false dismissal guaranteed.",2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 509-541,time series;theoretical computer science;data mining;database;machine learning;statistics;computer science;
Erratum to: A link mining algorithm for earnings forecast and trading,Germán Creamer (Columbia University);Salvatore J. Stolfo (Columbia University);,"2257480447,2021877992",-,2010,Data Mining and Knowledge Discovery volume 21 issue 3 pp 542-542,actuarial science;
Three naive Bayes approaches for discrimination-free classification,Tgk Toon Calders (Eindhoven University of Technology);Se Sicco Verwer (Eindhoven University of Technology);,"2568367239,2062787554","In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artificial and real-life data.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 277-292,bayesian programming;bayes error rate;bayes classifier;naive bayes classifier;data mining;pattern recognition;machine learning;statistics;computer science;
A game-theoretic framework to identify overlapping communities in social networks,Wei Chen (Microsoft);Zhenming Liu (Harvard University);Xiaorui Sun (Shanghai Jiao Tong University);Yajun Wang (Microsoft);,"2527738285,2715813781,2640529002,2567737653","In this paper, we introduce a game-theoretic framework to address the community detection problem based on the structures of social networks. We formulate the dynamics of community formation as a strategic game called community formation game: Given an underlying social graph, we assume that each node is a selfish agent who selects communities to join or leave based on her own utility measurement. A community structure can be interpreted as an equilibrium of this game. We formulate the agents' utility by the combination of a gain function and a loss function. We allow each agent to select multiple communities, which naturally captures the concept of ""overlapping communities"". We propose a gain function based on the modularity concept introduced by Newman (Proc Natl Acad Sci 103(23):8577---8582, 2006), and a simple loss function that reflects the intrinsic costs incurred when people join the communities. We conduct extensive experiments under this framework, and our results show that our algorithm is effective in identifying overlapping communities, and are often better then other algorithms we evaluated especially when many people belong to multiple communities. To the best of our knowledge, this is the first time the community detection problem is addressed by a game-theoretic framework that considers community formation as the result of individual agents' rational behaviors.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 224-240,community structure;social network analysis;loss function;social network;data mining;machine learning;simulation;
Predicting labels for dyadic data,"Aditya Krishna Menon (University of California, San Diego);Charles Elkan (University of California, San Diego);","2107302653,705676171","In dyadic prediction, the input consists of a pair of items (a dyad), and the goal is to predict the value of an observation related to the dyad. Special cases of dyadic prediction include collaborative filtering, where the goal is to predict ratings associated with (user, movie) pairs, and link prediction, where the goal is to predict the presence or absence of an edge between two nodes in a graph. In this paper, we study the problem of predicting labels associated with dyad members. Special cases of this problem include predicting characteristics of users in a collaborative filtering scenario, and predicting the label of a node in a graph, which is a task sometimes called within-network classification or relational learning. This paper shows how to extend a recent dyadic prediction method to predict labels for nodes and labels for edges simultaneously. The new method learns latent features within a log-linear model in a supervised way, to maximize predictive accuracy for both dyad observations and item labels. We compare the new approach to existing methods for within-network classification, both experimentally and analytically. The experiments show, surprisingly, that learning latent features in an unsupervised way is superior for some applications to learning them in a supervised way.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 327-343,social network;statistical relational learning;data mining;artificial intelligence;machine learning;statistics;computer science;
Mining top-K frequent itemsets through progressive sampling,Andrea Pietracaprina (University of Padua);Matteo Riondato (Brown University);Eli Upfal (Brown University);Fabio Vandin (Brown University);,"1245144852,1555209364,265232414,269645400","We study the use of sampling for efficiently mining the top-K frequent itemsets of cardinality at most w. To this purpose, we define an approximation to the top-K frequent itemsets to be a family of itemsets which includes (resp., excludes) all very frequent (resp., very infrequent) itemsets, together with an estimate of these itemsets' frequencies with a bounded error. Our first result is an upper bound on the sample size which guarantees that the top-K frequent itemsets mined from a random sample of that size approximate the actual top-K frequent itemsets, with probability larger than a specified value. We show that the upper bound is asymptotically tight when w is constant. Our main algorithmic contribution is a progressive sampling approach, combined with suitable stopping conditions, which on appropriate inputs is able to extract approximate top-K frequent itemsets from samples whose sizes are smaller than the general upper bound. In order to test the stopping conditions, this approach maintains the frequency of all itemsets encountered, which is practical only for small w. However, we show how this problem can be mitigated by using a variation of Bloom filters. A number of experiments conducted on both synthetic and real benchmark datasets show that using samples substantially smaller than the original dataset (i.e., of size defined by the upper bound or reached through the progressive sampling approach) enable to approximate the actual top-K frequent itemsets with accuracy much higher than what analytically proved.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 310-326,bloom filter;sampling;data structure;data mining;database;pattern recognition;computer science;mathematics;
Maximal exceptions with minimal descriptions,Matthijs van Leeuwen (Utrecht University);,2143928993,"We introduce a new approach to Exceptional Model Mining. Our algorithm, called EMDM, is an iterative method that alternates between Exception Maximisation and Description Minimisation. As a result, it finds maximally exceptional models with minimal descriptions. Exceptional Model Mining was recently introduced by Leman et al. (Exceptional model mining 1---16, 2008) as a generalisation of Subgroup Discovery. Instead of considering a single target attribute, it allows for multiple `model' attributes on which models are fitted. If the model for a subgroup is substantially different from the model for the complete database, it is regarded as an exceptional model. To measure exceptionality, we propose two information-theoretic measures. One is based on the Kullback---Leibler divergence, the other on Krimp. We show how compression can be used for exception maximisation with these measures, and how classification can be used for description minimisation. Experiments show that our approach efficiently identifies subgroups that are both exceptional and interesting.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 259-276,kullback leibler divergence;iterative method;information theory;discrete mathematics;combinatorics;data mining;statistics;mathematics;
Using background knowledge to rank itemsets,Nikolaj Tatti (University of Antwerp);Michael Mampaey (University of Antwerp);,"1367500519,2027051129","Assessing the quality of discovered results is an important open problem in data mining. Such assessment is particularly vital when mining itemsets, since commonly many of the discovered patterns can be easily explained by background knowledge. The simplest approach to screen uninteresting patterns is to compare the observed frequency against the independence model. Since the parameters for the independence model are the column margins, we can view such screening as a way of using the column margins as background knowledge. In this paper we study techniques for more flexible approaches for infusing background knowledge. Namely, we show that we can efficiently use additional knowledge such as row margins, lazarus counts, and bounds of ones. We demonstrate that these statistics describe forms of data that occur in practice and have been studied in data mining. To infuse the information efficiently we use a maximum entropy approach. In its general setting, solving a maximum entropy model is infeasible, but we demonstrate that for our setting it can be solved in polynomial time. Experiments show that more sophisticated models fit the data better and that using more information improves the frequency prediction of itemsets.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 293-309,principle of maximum entropy;data mining;machine learning;statistics;computer science;mathematics;
Accelerating spectral clustering with partial supervision,Dimitrios Mavroeidis (Radboud University Nijmegen);,2715883754,"Spectral Clustering is a popular learning paradigm that employs the eigenvectors and eigenvalues of an appropriate input matrix for approximating the clustering objective. Albeit its empirical success in diverse application areas, spectral clustering has been criticized for its inefficiency when dealing with large-size datasets. This is mainly due to the fact that the complexity of most eigenvector algorithms is cubic with respect to the number of instances and even memory efficient iterative eigensolvers (such as the Power Method) may converge very slowly to the desired eigenvector solutions. In this paper, inspired from the relevant work on Pagerank we propose a semi-supervised framework for spectral clustering that provably improves the efficiency of the Power Method for computing the Spectral Clustering solution. The proposed method is extremely suitable for large and sparse matrices, where it is demonstrated to converge to the eigenvector solution with just a few Power Method iterations. The proposed framework reveals a novel perspective of semi-supervised spectral methods and demonstrates that the efficiency of spectral clustering can be enhanced not only by data compression but also by introducing the appropriate supervised bias to the input Laplacian matrix. Apart from the efficiency gains, the proposed framework is also demonstrated to improve the quality of the derived cluster models.",2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 241-258,canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;spectral clustering;fuzzy clustering;laplacian matrix;clustering high dimensional data;spectral method;power iteration;sparse matrix;cluster analysis;data compression;eigenvalues and eigenvectors;theoretical computer science;data mining;machine learning;mathematical optimization;statistics;mathematics;
Guest editors' introduction: special issue of selected papers from ECML PKDD 2010,José L. Balcázar (University of Cantabria);Francesco Bonchi (Yahoo!);Aristides Gionis (Yahoo!);Michèle Sebag (Centre national de la recherche scientifique);,"2115119778,2176652147,737311942,2127154967",-,2010,Data Mining and Knowledge Discovery volume 21 issue 2 pp 221-223,-
ENDER: a statistical framework for boosting decision rules,Krzysztof Dembczyński (Poznań University of Technology);Wojciech Kotłowski (Poznań University of Technology);Roman Słowiński (Poznań University of Technology);,"1886095867,1500202045,2134359788","Induction of decision rules plays an important role in machine learning. The main advantage of decision rules is their simplicity and human-interpretable form. Moreover, they are capable of modeling complex interactions between attributes. In this paper, we thoroughly analyze a learning algorithm, called ENDER, which constructs an ensemble of decision rules. This algorithm is tailored for regression and binary classification problems. It uses the boosting approach for learning, which can be treated as generalization of sequential covering. Each new rule is fitted by focusing on examples which were the hardest to classify correctly by the rules already present in the ensemble. We consider different loss functions and minimization techniques often encountered in the boosting framework. The minimization techniques are used to derive impurity measures which control construction of single decision rules. Properties of four different impurity measures are analyzed with respect to the trade-off between misclassification (discrimination) and coverage (completeness) of the rule. Moreover, we consider regularization consisting of shrinking and sampling. Finally, we compare the ENDER algorithm with other well-known decision rule learners such as SLIPPER, LRI and RuleFit.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 52-90,gradient boosting;decision rule;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Hierarchical document clustering using local patterns,Hassan H. Malik (Thomson Reuters);John R. Kender (Columbia University);Dmitriy Fradkin (Siemens);Fabian Moerchen (Siemens);,"2292051180,229175834,2028188512,1991190249","The global pattern mining step in existing pattern-based hierarchical clustering algorithms may result in an unpredictable number of patterns. In this paper, we propose IDHC, a pattern-based hierarchical clustering algorithm that builds a cluster hierarchy without mining for globally significant patterns. IDHC first discovers locally promising patterns by allowing each instance to ""vote"" for its representative size-2 patterns in a way that ensures an effective balance between local pattern frequency and pattern significance in the dataset. The cluster hierarchy (i.e., the global model) is then directly constructed using these locally promising patterns as features. Each pattern forms an initial (possibly overlapping) cluster, and the rest of the cluster hierarchy is obtained by following a unique iterative cluster refinement process. By effectively utilizing instance-to-cluster relationships, this process directly identifies clusters for each level in the hierarchy, and efficiently prunes duplicate clusters. Furthermore, IDHC produces cluster labels that are more descriptive (patterns are not artificially restricted), and adapts a soft clustering scheme that allows instances to exist in suitable nodes at various levels in the cluster hierarchy. We present results of experiments performed on 16 standard text datasets, and show that IDHC outperforms state-of-the-art hierarchical clustering algorithms in terms of average entropy and FScore measures.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 153-185,k medians clustering;hierarchical clustering of networks;complete linkage clustering;single linkage clustering;hierarchical clustering;dimensionality reduction;cluster analysis;consensus clustering;document clustering;data mining;pattern recognition;machine learning;computer science;mathematics;
Optimal constraint-based decision tree induction from itemset lattices,Siegfried Nijssen (Katholieke Universiteit Leuven);Elisa Fromont (Centre national de la recherche scientifique);,"2102450877,2142341142","In this article we show that there is a strong connection between decision tree learning and local pattern mining. This connection allows us to solve the computationally hard problem of finding optimal decision trees in a wide range of applications by post-processing a set of patterns: we use local patterns to construct a global model. We exploit the connection between constraints in pattern mining and constraints in decision tree induction to develop a framework for categorizing decision tree mining constraints. This framework allows us to determine which model constraints can be pushed deeply into the pattern mining process, and allows us to improve the state-of-the-art of optimal decision tree induction.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 9-51,incremental decision tree;decision stump;id3 algorithm;alternating decision tree;decision tree model;influence diagram;decision tree learning;decision tree;data mining;pattern recognition;machine learning;computer science;mathematics;
Guest Editorial: Global modeling using local patterns,Johannes Fürnkranz (Technische Universität Darmstadt);Arno J. Knobbe (Leiden University);,"52482323,1229146049","Overthelastdecade,localpatterndiscoveryhasbecomearapidlygrowingﬁeld(Moriketal.2005),andarangeoftechniquesisavailableforproducingextensivecollectionsofpatterns.Becauseoftheexhaustivenatureofmostsuchtechniques,thepatterncol-lections provide a fairly complete picture of the information content of the database.However,suchso-calledlocalpatternsrepresentfragmentedknowledge,anditisoftennot clear how the pieces of the puzzle can be combined into a global model, which isoften the desirable result of a data mining process. Thus, the question of how to turnlarge collections of patterns into global models deserves attention.This special issue of the Data Mining and Knowledge Discovery Journal featuresa number of papers that represent the state of the art in building global models fromlocal patterns. In our view, a common ground of all the local pattern mining tech-niquesisthattheycanbeconsidered tobefeatureconstructiontechniques thatfollowdifferent objectives (or constraints). We will see that the redundancy of these patternsandtheselectionofsuitablesubsetsofpatternsareaddressedinseparatesteps,sothateach resulting feature is highly informative in the context of the global data miningproblem.In earlier work (Knobbe et al. 2008), a framework was proposed that provides ageneral outline of the activities involved. The framework, called From Local Patterns",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 1-8,data science;data mining;artificial intelligence;computer science;
Using interesting sequences to interactively build Hidden Markov Models,Szymon Jaroszewicz (University of Massachusetts Amherst);,115085028,"The paper presents a method of interactive construction of global Hidden Markov Models (HMMs) based on local sequence patterns discovered in data. The method is based on finding interesting sequences whose frequency in the database differs from that predicted by the model. The patterns are then presented to the user who updates the model using their intelligence and their understanding of the modelled domain. It is demonstrated that such an approach leads to more understandable models than automated approaches. Two variants of the problem are considered: mining patterns occurring only at the beginning of sequences and mining patterns occurring at any position; both practically meaningful. For each variant, algorithms have been developed allowing for efficient discovery of all sequences with given minimum interestingness. Applications to modelling webpage visitors behavior and to modelling protein secondary structure are presented, validating the proposed approach.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 186-220,sequential pattern mining;protein secondary structure;hidden markov model;bioinformatics;data mining;machine learning;computer science;
Ensembles of jittered association rule classifiers,Paulo Jorge Azevedo (University of Minho);Alípio Mário Jorge (Delgado Community College);,"2156503788,2165617838","The ensembling of classifiers tends to improve predictive accuracy. To obtain an ensemble with N classifiers, one typically needs to run N learning processes. In this paper we introduce and explore Model Jittering Ensembling, where one single model is perturbed in order to obtain variants that can be used as an ensemble. We use as base classifiers sets of classification association rules. The two methods of jittering ensembling we propose are Iterative Reordering Ensembling (IRE) and Post Bagging (PB). Both methods start by learning one rule set over a single run, and then produce multiple rule sets without relearning. Empirical results on 36 data sets are positive and show that both strategies tend to reduce error with respect to the single model association rule classifier. A bias---variance analysis reveals that while both IRE and PB are able to reduce the variance component of the error, IRE is particularly effective in reducing the bias component. We show that Model Jittering Ensembling can represent a very good speed-up w.r.t. multiple model learning ensembling. We also compare Model Jittering with various state of the art classifiers in terms of predictive accuracy and computational efficiency.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 91-129,association rule learning;data mining;pattern recognition;machine learning;computer science;
Learning in parallel universes,Bernd Wiswedel (University of Konstanz);Frank Höppner;Michael R. Berthold (University of Konstanz);,"2040573880,2306305617,2117114528","We discuss Learning in parallel universes as a learning concept that encompasses the simultaneous analysis from multiple descriptor spaces. In contrast to existing approaches, this approach constructs a global model that is based on only partially applicable, local models in each descriptor space. We present some application scenarios and compare this learning strategy to other approaches on learning in multiple descriptor spaces. As a representative for learning in parallel universes we introduce different extensions to a family of unsupervised fuzzy clustering algorithms and evaluate their performance on an artificial data set and a benchmark of 3D objects.",2010,Data Mining and Knowledge Discovery volume 21 issue 1 pp 130-152,parallel universe;cluster analysis;discrete mathematics;machine learning;computer science;mathematics;
Temporal pattern discovery in longitudinal electronic patient records,G. Niklas Norén (Uppsala Monitoring Centre);Johan Hopstadius (Uppsala Monitoring Centre);Andrew Bate (Pfizer);Kristina Star (Uppsala Monitoring Centre);I. Ralph Edwards (Uppsala Monitoring Centre);,"2038259707,2066662884,1973485669,2160887348,2155523821","Large collections of electronic patient records provide a vast but still underutilised source of information on the real world use of medicines. They are maintained primarily for the purpose of patient administration, but contain a broad range of clinical information highly relevant for data analysis. While they are a standard resource for epidemiological confirmatory studies, their use in the context of exploratory data analysis is still limited. In this paper, we present a framework for open-ended pattern discovery in large patient records repositories. At the core is a graphical statistical approach to summarising and visualising the temporal association between the prescription of a drug and the occurrence of a medical event. The graphical overview contrasts the observed and expected number of occurrences of the medical event in different time periods both before and after the prescription of interest. In order to effectively screen for important temporal relationships, we introduce a new measure of temporal association, which contrasts the observed-to-expected ratio in a time period immediately after the prescription to the observed-to-expected ratio in a control period 2 years earlier. An important feature of both the observed-to-expected graph and the measure of temporal association is a statistical shrinkage towards the null hypothesis of no association, which provides protection against highlighting spurious associations. We demonstrate the usefulness of the proposed pattern discovery methodology by a set of examples from a collection of over two million patient records in the United Kingdom. The identified patterns include temporal relationships between drug prescriptions and medical events suggestive of persistent and transient risks of adverse events, possible beneficial effects of drugs, periodic co-occurrence, and systematic tendencies of patients to switch from one medication to another.",2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 361-387,exploratory data analysis;adverse effect;data analysis;data science;information retrieval;data mining;statistics;
Time to CARE: a collaborative engine for practical disease prediction,Darcy A. Davis (University of Notre Dame);Nitesh V. Chawla (University of Notre Dame);Nicholas A. Christakis (Harvard University);Albert-László Barabási (Northeastern University);,"2100885057,1979796846,720924201,2195478976","The monumental cost of health care, especially for chronic disease treatment, is quickly becoming unmanageable. This crisis has motivated the drive towards preventative medicine, where the primary concern is recognizing disease risk and taking action at the earliest signs. However, universal testing is neither time nor cost efficient. We propose CARE, a Collaborative Assessment and Recommendation Engine, which relies only on patient's medical history using ICD-9-CM codes in order to predict future disease risks. CARE uses collaborative filtering methods to predict each patient's greatest disease risks based on their own medical history and that of similar patients. We also describe an Iterative version, ICARE, which incorporates ensemble concepts for improved performance. Also, we apply time-sensitive modifications which make the CARE framework practical for realistic long-term use. These novel systems require no specialized information and provide predictions for medical conditions of all kinds in a single run. We present experimental results on a large Medicare dataset, demonstrating that CARE and ICARE perform well at capturing future disease risks.",2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 388-415,cost efficiency;collaborative filtering;medical history;health care;preventive healthcare;data mining;machine learning;simulation;computer science;
ECM-aware cell-graph mining for bone tissue modeling and classification,Cemal Cagatay Bilgin (Rensselaer Polytechnic Institute);Peter Bullough (Hospital for Special Surgery);George E. Plopper (Rensselaer Polytechnic Institute);Bülent Yener (Rensselaer Polytechnic Institute);,"2105214629,2125486713,11245715,2134569023","Pathological examination of a biopsy is the most reliable and widely used technique to diagnose bone cancer. However, it suffers from both inter- and intra- observer subjectivity. Techniques for automated tissue modeling and classification can reduce this subjectivity and increases the accuracy of bone cancer diagnosis. This paper presents a graph theoretical method, called extracellular matrix (ECM)-aware cell-graph mining, that combines the ECM formation with the distribution of cells in hematoxylin and eosin stained histopathological images of bone tissues samples. This method can identify different types of cells that coexist in the same tissue as a result of its functional state. Thus, it models the structure-function relationships more precisely and classifies bone tissue samples accurately for cancer diagnosis. The tissue images are segmented, using the eigenvalues of the Hessian matrix, to compute spatial coordinates of cell nuclei as the nodes of corresponding cell-graph. Upon segmentation a color code is assigned to each node based on the composition of its surrounding ECM. An edge is hypothesized (and established) between a pair of nodes if the corresponding cell membranes are in physical contact and if they share the same color. Hence, multiple colored-cell-graphs coexist in a tissue each modeling a different cell-type organization. Both topological and spectral features of ECM-aware cell-graphs are computed to quantify the structural properties of tissue samples and classify their different functional states as healthy, fractured, or cancerous using support vector machines. Classification accuracy comparison to related work shows that the ECM-aware cell-graph approach yields 90.0% whereas Delaunay triangulation and the simple cell-graph approach achieves 75.0 and 81.1% accuracy, respectively.",2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 416-438,h e stain;extracellular matrix;text mining;bioinformatics;data mining;machine learning;computer science;
Medical data mining: insights from winning two competitions,Saharon Rosset (Tel Aviv University);Claudia Perlich (IBM);Grzergorz Świrszcz (IBM);Prem Melville (IBM);Yan Liu (IBM);,"2129867074,164824025,2277410007,2073846700,2240541904","Two major data mining competitions in 2008 presented challenges in medical domains: KDD Cup 2008, which concerned cancer detection from mammography data; and Informs Data Mining Challenge 2008, dealing with diagnosis of pneumonia based on patient information from hospital files. Our team won both of these competitions, and in this paper we share our lessons learned and insights. We emphasize the aspects that pertain to the general practice and methodology of medical data mining, rather than to the specifics of each modeling competition. We concentrate on three topics: information leakage, its effect on competitions and proof-of-concept projects; consideration of real-life model performance measures in model construction and evaluation; and relational learning approaches to medical data mining tasks.",2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 439-468,proof of concept;leakage;statistical relational learning;data science;data mining;machine learning;simulation;computer science;
A real-time temporal Bayesian architecture for event surveillance and its application to patient-specific multiple disease outbreak detection,Xia Jiang (University of Pittsburgh);Gregory F. Cooper (University of Pittsburgh);,"2225977378,2137326150","Reliable and accurate detection of disease outbreaks remains an important research topic in disease outbreak surveillance. A temporal surveillance system bases its analysis on data not only from the most recent time period, but also on data from previous time periods. A non-temporal system only looks at data from the most recent time period. There are two difficulties with a non-temporal system when it is used to monitor real data which often contain noise. First, it is prone to produce false positive signals during non-outbreak time periods. Second, during an outbreak, it tends to release false negative signals early in the outbreak, which can adversely affect the decision making process of the user of the system. We conjecture that by converting a non-temporal system to a temporal one, we may attenuate these difficulties inherent in a non-temporal system. In this paper, we propose a Bayesian network architecture for a class of temporal event surveillance models called BayesNet-T. Using this Bayesian network architecture, we can convert certain non-temporal surveillance systems to temporal ones. We apply this architecture to a previously developed non-temporal multiple-disease outbreak detection system called PC and create a temporal system called PCT. PCT takes Emergency Department (ED) patient chief complaint data as its input. The PCT system was constructed using both data (non-outbreak diseases) and expert assessments (outbreak diseases). We compare PCT to PC using a real influenza outbreak. Furthermore, we compare PCT to both PC and the classic statistical methods CUSUM and EWMA using a total of 240 influenza and Cryptosporidium disease outbreaks created by injecting stochastically simulated outbreak cases into real ED admission data. Our results indicate that PCT has a smaller mean time to detection than PC at low false alarm rates, and that PCT is more stable than PC in that once an outbreak is detected, PCT is better at maintaining the detection signal on future days.",2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 328-360,outbreak;bayesian network;decision making;network architecture;operations research;data mining;machine learning;simulation;computer science;
Guest Editorial: Special Issue on impacting patient care by mining medical data,Rómer E. Rosales (Siemens Healthcare);R. Bharat Rao (Siemens Healthcare);,"2117656073,2122268670",-,2010,Data Mining and Knowledge Discovery volume 20 issue 3 pp 325-327,data science;computer science;
A fast outlier detection strategy for distributed high-dimensional data sets with mixed attributes,Anna Koufakou (University of Central Florida);Michael Georgiopoulos (University of Central Florida);,"239421741,673942444","Outlier detection has attracted substantial attention in many applications and research areas; some of the most prominent applications are network intrusion detection or credit card fraud detection. Many of the existing approaches are based on calculating distances among the points in the dataset. These approaches cannot easily adapt to current datasets that usually contain a mix of categorical and continuous attributes, and may be distributed among different geographical locations. In addition, current datasets usually have a large number of dimensions. These datasets tend to be sparse, and traditional concepts such as Euclidean distance or nearest neighbor become unsuitable. We propose a fast distributed outlier detection strategy intended for datasets containing mixed attributes. The proposed method takes into consideration the sparseness of the dataset, and is experimentally shown to be highly scalable with the number of points and the number of attributes in the dataset. Experimental results show that the proposed outlier detection method compares very favorably with other state-of-the art outlier detection strategies proposed in the literature and that the speedup achieved by its distributed version is very close to linear.",2010,Data Mining and Knowledge Discovery volume 20 issue 2 pp 259-289,clustering high dimensional data;euclidean distance;k nearest neighbors algorithm;anomaly detection;data mining;pattern recognition;machine learning;computer science;
Distance-based outlier queries in data streams: the novel task and algorithms,Fabrizio Angiulli (University of Calabria);Fabio Fassetti (University of Calabria);,"3821842,184075056","This work proposes a method for detecting distance-based outliers in data streams under the sliding window model. The novel notion of one-time outlier query is introduced in order to detect anomalies in the current window at arbitrary points-in-time. Three algorithms are presented. The first algorithm exactly answers to outlier queries, but has larger space requirements than the other two. The second algorithm is derived from the exact one, reduces memory requirements and returns an approximate answer based on estimations with a statistical guarantee. The third algorithm is a specialization of the approximate algorithm working with strictly fixed memory requirements. Accuracy properties and memory consumption of the algorithms have been theoretically assessed. Moreover experimental results have confirmed the effectiveness of the proposed approach and the good quality of the solutions.",2010,Data Mining and Knowledge Discovery volume 20 issue 2 pp 290-324,sliding window protocol;anomaly detection;data mining;database;machine learning;computer science;
COG: local decomposition for rare class analysis,Junjie Wu (Beihang University);Hui Xiong (Rutgers Business School – Newark and New Brunswick);Jian Chen (Tsinghua University);,"2149366604,2153710278,2586587700","Given its importance, the problem of predicting rare classes in large-scale multi-labeled data sets has attracted great attention in the literature. However, rare class analysis remains a critical challenge, because there is no natural way developed for handling imbalanced class distributions. This paper thus fills this crucial void by developing a method for classification using local clustering (COG). Specifically, for a data set with an imbalanced class distribution, we perform clustering within each large class and produce sub-classes with relatively balanced sizes. Then, we apply traditional supervised learning algorithms, such as support vector machines (SVMs), for classification. Along this line, we explore key properties of local clustering for a better understanding of the effect of COG on rare class analysis. Also, we provide a systematic analysis of time and space complexity of the COG method. Indeed, the experimental results on various real-world data sets show that COG produces significantly higher prediction accuracies on rare classes than state-of-the-art methods and the COG scheme can greatly improve the computational performance of SVMs. Furthermore, we show that COG can also improve the performances of traditional supervised learning algorithms on data sets with balanced class distributions. Finally, as two case studies, we have applied COG for two real-world applications: credit card fraud detection and network intrusion detection.",2010,Data Mining and Knowledge Discovery volume 20 issue 2 pp 191-220,dspace;k means clustering;support vector machine;supervised learning;data mining;pattern recognition;machine learning;computer science;
Spatial neighborhood based anomaly detection in sensor datasets,"Vandana Pursnani Janeja (University of Maryland, Baltimore County);Nabil R. Adam (Rutgers–Newark);Vijayalakshmi Atluri (Rutgers–Newark);Jaideep Vaidya (Rutgers–Newark);","2290556930,2300106300,2100792061,2164601541","Success of anomaly detection, similar to other spatial data mining techniques, relies on neighborhood definition. In this paper, we argue that the anomalous behavior of spatial objects in a neighborhood can be truly captured when both (a) spatial autocorrelation (similar behavior of nearby objects due to proximity) and (b) spatial heterogeneity (distinct behavior of nearby objects due to difference in the underlying processes in the region) are taken into consideration for the neighborhood definition. Our approach begins by generating micro neighborhoods around spatial objects encompassing all the information about a spatial object. We selectively merge these based on spatial relationships accounting for autocorrelation and inferential relationships accounting for heterogeneity, forming macro neighborhoods. In such neighborhoods, we then identify (i) spatio-temporal outliers, where individual sensor readings are anomalous, (ii) spatial outliers, where the entire sensor is an anomaly, and (iii) spatio-temporally coalesced outliers, where a group of spatio-temporal outliers in the macro neighborhood are separated by a small time lag indicating the traversal of the anomaly. We demonstrate the effectiveness of our approach in neighborhood formation and anomaly detection with experimental results in (i) water monitoring and (ii) highway traffic monitoring sensor datasets. We also compare the results of our approach with an existing approach for spatial anomaly detection.",2010,Data Mining and Knowledge Discovery volume 20 issue 2 pp 221-258,spatial heterogeneity;spatial relation;spatial analysis;sensor;anomaly detection;data mining;machine learning;statistics;computer science;
Outlier detection special issue,Sanjay Chawla (University of Sydney);David J. Hand (University of Sydney);Vasant Dhar (University of Sydney);,"2201421368,2175518357,2401262112",-,2010,Data Mining and Knowledge Discovery volume 20 issue 2 pp 189-190,anomaly detection;machine learning;computer science;
Extracting influential nodes on a social network for information diffusion,Masahiro Kimura (Ryukoku University);Kazumi Saito (University of Shizuoka);Ryohei Nakano (Chubu University);Hiroshi Motoda (Osaka University);,"1989850375,2171394160,2063725687,323689644","We address the combinatorial optimization problem of finding the most influential nodes on a large-scale social network for two widely-used fundamental stochastic diffusion models. The past study showed that a greedy strategy can give a good approximate solution to the problem. However, a conventional greedy method faces a computational problem. We propose a method of efficiently finding a good approximate solution to the problem under the greedy algorithm on the basis of bond percolation and graph theory, and compare the proposed method with the conventional method in terms of computational complexity in order to theoretically evaluate its effectiveness. The results show that the proposed method is expected to achieve a great reduction in computational cost. We further experimentally demonstrate that the proposed method is much more efficient than the conventional method using large-scale real-world networks including blog networks.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 70-97,computational problem;greedy randomized adaptive search procedure;social network analysis;diffusion;greedy algorithm;social network;computational complexity theory;graph theory;combinatorics;machine learning;mathematical optimization;computer science;mathematics;
Binary matrix factorization for analyzing gene expression data,Zhongyuan Zhang (Central University of Finance and Economics);Tao Li (Florida International University);Chris H. Q. Ding (University of Texas at Arlington);Xian-Wen Ren (Chinese Academy of Sciences);Xiang-Sun Zhang (Chinese Academy of Sciences);,"2131155200,2472069284,2119616764,2470087558,2171719997","The advent of microarray technology enables us to monitor an entire genome in a single chip using a systematic approach. Clustering, as a widely used data mining approach, has been used to discover phenotypes from the raw expression data. However traditional clustering algorithms have limitations since they can not identify the substructures of samples and features hidden behind the data. Different from clustering, biclustering is a new methodology for discovering genes that are highly related to a subset of samples. Several biclustering models/methods have been presented and used for tumor clinical diagnosis and pathological research. In this paper, we present a new biclustering model using Binary Matrix Factorization (BMF). BMF is a new variant rooted from non-negative matrix factorization (NMF). We begin by proving a new boundedness property of NMF. Two different algorithms to implement the model and their comparison are then presented. We show that the microarray data biclustering problem can be formulated as a BMF problem and can be solved effectively using our proposed algorithms. Unlike the greedy strategy-based algorithms, our proposed algorithms for BMF are more likely to find the global optima. Experimental results on synthetic and real datasets demonstrate the advantages of BMF over existing biclustering methods. Besides the attractive clustering performance, BMF can generate sparse results (i.e., the number of genes/features involved in each biclustering structure is very small related to the total number of genes/features) that are in accordance with the common practice in molecular biology.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 28-52,logical matrix;non negative matrix factorization;microarray analysis techniques;matrix decomposition;chip;biclustering;bioinformatics;data mining;machine learning;computer science;mathematics;
Progressive refinement for support vector machines,Kiri L. Wagstaff (Jet Propulsion Laboratory);Michael Kocurek (California Institute of Technology);Dominic Mazzoni (Jet Propulsion Laboratory);Benyang Tang (Jet Propulsion Laboratory);,"2110892363,2109673614,1924806610,2660386821","Support vector machines (SVMs) have good accuracy and generalization properties, but they tend to be slow to classify new examples. In contrast to previous work that aims to reduce the time required to fully classify all examples, we present a method that provides the best-possible classification given a specific amount of computational time. We construct two SVMs: a ""full"" SVM that is optimized for high accuracy, and an approximation SVM (via reduced-set or subset methods) that provides extremely fast, but less accurate, classifications. We apply the approximate SVM to the full data set, estimate the posterior probability that each classification is correct, and then use the full SVM to reclassify items in order of their likelihood of misclassification. Our experimental results show that this method rapidly achieves high accuracy, by selectively devoting resources (reclassification) only where needed. It also provides the first such progressive SVM solution that can be applied to multiclass problems.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 53-69,structured support vector machine;support vector machine;data mining;pattern recognition;machine learning;computer science;mathematics;
An incremental clustering scheme for data de-duplication,Gianni Costa (Indian Council of Agricultural Research);Giuseppe Manco (Indian Council of Agricultural Research);Riccardo Ortale (Indian Council of Agricultural Research);,"2157428172,2093732677,1974615881","We propose an incremental technique for discovering duplicates in large databases of textual sequences, i.e., syntactically different tuples, that refer to the same real-world entity. The problem is approached from a clustering perspective: given a set of tuples, the objective is to partition them into groups of duplicate tuples. Each newly arrived tuple is assigned to an appropriate cluster via nearest-neighbor classification. This is achieved by means of a suitable hash-based index, that maps any tuple to a set of indexing keys and assigns tuples with high syntactic similarity to the same buckets. Hence, the neighbors of a query tuple can be efficiently identified by simply retrieving those tuples that appear in the same buckets associated to the query tuple itself, without completely scanning the original database. Two alternative schemes for computing indexing keys are discussed and compared. An extensive experimental evaluation on both synthetic and real data shows the effectiveness of our approach.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 152-187,tuple;data deduplication;locality sensitive hashing;data mining;database;pattern recognition;machine learning;computer science;mathematics;
"Eigenvectors of directed graphs and importance scores: dominance, T-Rank, and sink remedies",Johannes Bjelland (Telenor);Mark Burgess (Oslo and Akershus University College of Applied Sciences);Geoffrey Canright (Telenor);Kenth Engø-Monsen (Telenor);,"2033616929,2255205611,2058912964,248458094","We study the properties of the principal eigenvector for the adjacency matrix (and related matrices) for a general directed graph. In particular--motivated by the use of the eigenvector for estimating the ""importance"" of the nodes in the graph--we focus on the distribution of positive weight in this eigenvector, and give a coherent picture which builds upon and unites earlier results. We also propose a simple method--""T-Rank""--for generating importance scores. T-Rank generates authority scores via a one-level, non-normalized matrix, and is thus distinct from known methods such as PageRank (normalized), HITS (two-level), and SALSA (two-level and normalized). We show, using our understanding of the principal eigenvector, that T-Rank has a much less severe ""sink problem"" than does PageRank. Also, we offer numerical results which quantify the ""tightly-knit community"" or TKC effect. We find that T-Rank has a stronger TKC effect than PageRank, and we offer a novel interpolation method which allows for continuous tuning of the strength of this TKC effect. Finally, we propose two new ""sink remedies"", i.e., methods for ensuring that the principal eigenvector is positive everywhere. One of our sink remedies (source pumping) is unique among sink remedies, in that it gives a positive eigenvector without rendering the graph strongly connected. We offer a preliminary evaluation of the effects and possible applications of these new sink remedies.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 98-151,normal matrix;adjacency matrix;link analysis;directed graph;eigenvalues and eigenvectors;theoretical computer science;combinatorics;data mining;machine learning;mathematical optimization;statistics;mathematics;
SCALE: a scalable framework for efficiently clustering transactional data,Hua Yan (University of Electronic Science and Technology of China);Keke Chen (Wright State University);Ling Liu (Georgia Institute of Technology College of Computing);Zhang Yi (Sichuan University);,"2130311184,2125330238,2125988131,2717603752","This paper presents SCALE, a fully automated transactional clustering framework. The SCALE design highlights three unique features. First, we introduce the concept of Weighted Coverage Density as a categorical similarity measure for efficient clustering of transactional datasets. The concept of weighted coverage density is intuitive and it allows the weight of each item in a cluster to be changed dynamically according to the occurrences of items. Second, we develop the weighted coverage density measure based clustering algorithm, a fast, memory-efficient, and scalable clustering algorithm for analyzing transactional data. Third, we introduce two clustering validation metrics and show that these domain specific clustering evaluation metrics are critical to capture the transactional semantics in clustering analysis. Our SCALE framework combines the weighted coverage density measure for clustering over a sample dataset with self-configuring methods. These self-configuring methods can automatically tune the two important parameters of our clustering algorithms: (1) the candidates of the best number K of clusters; and (2) the application of two domain-specific cluster validity measures to find the best result from the set of clustering results. We have conducted extensive experimental evaluation using both synthetic and real datasets and our results show that the weighted coverage density approach powered by the SCALE framework can efficiently generate high quality clustering results in a fully automated manner.",2010,Data Mining and Knowledge Discovery volume 20 issue 1 pp 1-27,k medians clustering;flame clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;transaction data;fuzzy clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;biclustering;conceptual clustering;data science;data mining;database;machine learning;computer science;
AmtB-mediated NH(3) transport in prokaryotes must be active and as a consequence regulation of transport by GlnK is mandatory to limit futile cycling of NH(4)(+)/NH(3),F. C. Boogerd (VU University Amsterdam);Hi-keung Tony Ma;Frank J. Bruggeman (VU University Amsterdam);Heeswijk van W. C;Reyes Garcia-Contreras;Douwe Molenaar (VU University Amsterdam);K. Krab (VU University Amsterdam);Hans V. Westerhoff (VU University Amsterdam);,"1798735499,2676428779,2100898815,2097415357,2706524896,2128267214,1279729646,89570192",-,2010,Data Mining and Knowledge Discovery,-
Systems biology from micro-organisms to human metabolic diseases: the role of detailed kinetic models,Bart Bakker;Eunen van K;J. A. Jeneson (Eindhoven University of Technology);Riel van N. A;Frank J. Bruggeman (VU University Amsterdam);Bas Teusink (VU University Amsterdam);,"2694342165,2569872966,1744895096,2570835471,2100898815,622208267",-,2010,Data Mining and Knowledge Discovery,systems biology;computational biology;computer science;
RTG: a recursive realistic graph generator using random typing,Leman Akoglu (Carnegie Mellon University);Christos Faloutsos (Carnegie Mellon University);,"2288278917,2198983026","We propose a new, recursive model to generate realistic graphs, evolving over time. Our model has the following properties: it is (a) flexible, capable of generating the cross product of weighted/unweighted, directed/undirected, uni/bipartite graphs; (b) realistic, giving graphs that obey eleven static and dynamic laws that real graphs follow (we formally prove that for several of the (power) laws and we estimate their exponents as a function of the model parameters); (c) parsimonious, requiring only four parameters. (d) fast, being linear on the number of edges; (e) simple, intuitively leading to the generation of macroscopic patterns. We empirically show that our model mimics two real-world graphs very well: Blognet (unipartite, undirected, unweighted) with 27 K nodes and 125 K edges; and Committee-to-Candidate campaign donations (bipartite, directed, weighted) with 23 K nodes and 880 K edges. We also show how to handle time so that edge/weight additions are bursty and self-similar.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 194-209,robertson seymour theorem;indifference graph;hopcroft karp algorithm;pancyclic graph;tree depth;1 planar graph;comparability graph;triangle free graph;graph product;dense graph;modular decomposition;pathwidth;line graph;chordal graph;regression model validation;bipartite graph;matching;power law;theoretical computer science;discrete mathematics;combinatorics;machine learning;statistics;mathematics;
A fast ensemble pruning algorithm based on pattern mining process,Qiang-Li Zhao (National University of Defense Technology);Yan-Huang Jiang (National University of Defense Technology);Ming Xu (National University of Defense Technology);,"2629585949,2690044403,2672337353","Ensemble pruning deals with the reduction of base classifiers prior to combination in order to improve generalization and prediction efficiency. Existing ensemble pruning algorithms require much pruning time. This paper presents a fast pruning approach: pattern mining based ensemble pruning (PMEP). In this algorithm, the prediction results of all base classifiers are organized as a transaction database, and FP-Tree structure is used to compact the prediction results. Then a greedy pattern mining method is explored to find the ensemble of size k. After obtaining the ensembles of all possible sizes, the one with the best accuracy is outputted. Compared with Bagging, GASEN, and Forward Selection, experimental results show that PMEP achieves the best prediction accuracy and keeps the size of the final ensemble small, more importantly, its pruning time is much less than other ensemble pruning algorithms.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 277-292,null move heuristic;killer heuristic;principal variation search;pruning;bootstrap aggregating;tree structure;data mining;pattern recognition;machine learning;computer science;
Taxonomy-driven lumping for sequence mining,Francesco Bonchi (Yahoo!);Carlos Castillo (Yahoo!);Debora Donato (Yahoo!);Aristides Gionis (Yahoo!);,"2176652147,2125169605,2168688135,737311942","Given a taxonomy of events and a dataset of sequences of these events, we study the problem of finding efficient and effective ways to produce a compact representation of the sequences. We model sequences with Markov models whose states correspond to nodes in the provided taxonomy, and each state represents the events in the subtree under the corresponding node. By lumping observed events to states that correspond to internal nodes in the taxonomy, we allow more compact models that are easier to understand and visualize, at the expense of a decrease in the data likelihood. We formally define and characterize our problem, and we propose a scalable search method for finding a good trade-off between two conflicting goals: maximizing the data likelihood, and minimizing the model complexity. We implement these ideas in Taxomo, a taxonomy-driven modeler, which we apply in two different domains, query-log mining and mining of moving-object trajectories. The empirical evaluation confirms the feasibility and usefulness of our approach.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 227-244,markov model;data science;data mining;machine learning;statistics;computer science;mathematics;
On subgroup discovery in numerical domains,Henrik Grosskreutz (Fraunhofer Society);Stefan Rüping (Fraunhofer Society);,"290692522,2289977704","Subgroup discovery is a Knowledge Discovery task that aims at finding subgroups of a population with high generality and distributional unusualness. While several subgroup discovery algorithms have been presented in the past, they focus on databases with nominal attributes or make use of discretization to get rid of the numerical attributes. In this paper, we illustrate why the replacement of numerical attributes by nominal attributes can result in suboptimal results. Thereafter, we present a new subgroup discovery algorithm that prunes large parts of the search space by exploiting bounds between related numerical subgroup descriptions. The same algorithm can also be applied to ordinal attributes. In an experimental section, we show that the use of our new pruning scheme results in a huge performance gain when more that just a few split-points are considered for the numerical attributes.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 210-226,pruning;performance;knowledge extraction;discrete mathematics;combinatorics;data mining;computer science;mathematics;
Two-way analysis of high-dimensional collinear data,Ilkka Huopaniemi (Helsinki University of Technology);Tommi Suvitaival (Helsinki University of Technology);Janne Nikkilä (Helsinki University of Technology);Matej Orešič (VTT Technical Research Centre of Finland);Samuel Kaski (Helsinki University of Technology);,"2308220517,2404999578,2038091895,2067118172,1221219011","We present a Bayesian model for two-way ANOVA-type analysis of high-dimensional, small sample-size datasets with highly correlated groups of variables. Modern cellular measurement methods are a main application area; typically the task is differential analysis between diseased and healthy samples, complicated by additional covariates requiring a multi-way analysis. The main complication is the combination of high dimensionality and low sample size, which renders classical multivariate techniques useless. We introduce a hierarchical model which does dimensionality reduction by assuming that the input variables come in similarly-behaving groups, and performs an ANOVA-type decomposition for the set of reduced-dimensional latent variables. We apply the methods to study lipidomic profiles of a recent large-cohort human diabetes study.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 261-276,latent variable model;hierarchical database model;latent variable;bayesian inference;factor analysis;sample size determination;analysis of variance;metabolomics;econometrics;data mining;statistics;computer science;mathematics;
Identifying the components,Matthijs van Leeuwen (Utrecht University);Jilles Vreeken (Utrecht University);Arno Siebes (Utrecht University);,"2143928993,1971070670,1988376837","Most, if not all, databases are mixtures of samples from different distributions. Transactional data is no exception. For the prototypical example, supermarket basket analysis, one also expects a mixture of different buying patterns. Households of retired people buy different collections of items than households with young children. Models that take such underlying distributions into account are in general superior to those that do not. In this paper we introduce two MDL-based algorithms that follow orthogonal approaches to identify the components in a transaction database. The first follows a model-based approach, while the second is data-driven. Both are parameter-free: the number of components and the components themselves are chosen such that the combined complexity of data and models is minimised. Further, neither prior knowledge on the distributions nor a distance metric on the data is required. Experiments with both methods show that highly characteristic components are identified.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 176-193,distributed transaction;metric;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Harnessing the strengths of anytime algorithms for constant data streams,Philipp Kranen (RWTH Aachen University);Thomas Seidl (RWTH Aachen University);,"2008431275,2140301036","Anytime algorithms have been proposed for many different applications, e.g., in data mining. Their strengths are the ability to first provide a result after a very short initialization and second to improve their result with additional time. Therefore, anytime algorithms have so far been used when the available processing time varies, e.g., on varying data streams. In this paper we propose to employ anytime algorithms on constant data streams, i.e., for tasks with constant time allowance. We introduce two approaches that harness the strengths of anytime algorithms on constant data streams and thereby improve the over all quality of the result with respect to the corresponding budget algorithm. We derive formulas for the expected performance gain and demonstrate the effectiveness of our novel approaches using existing anytime algorithms on benchmark data sets.",2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 245-260,data science;data mining;machine learning;computer science;
Guest editors' introduction: special issue of selected papers from ECML PKDD 2009,Aleksander Kolcz (Microsoft);Dunja Mladenic (Carnegie Mellon University);Wray L. Buntine (NICTA);Marko Grobelnik (Humboldt University of Berlin);John Shawe-Taylor (University College London);,"1846703145,2282522104,2282891647,345053453,2215287472",-,2009,Data Mining and Knowledge Discovery volume 19 issue 2 pp 173-175,-
"Flexible decision tree for data stream classification in the presence of concept change, noise and missing values",Sattar Hashemi (Shiraz University);Ying Yang (Australian Taxation Office);,"2198869282,2714038862","In recent years, classification learning for data streams has become an important and active research topic. A major challenge posed by data streams is that their underlying concepts can change over time, which requires current classifiers to be revised accordingly and timely. To detect concept change, a common methodology is to observe the online classification accuracy. If accuracy drops below some threshold value, a concept change is deemed to have taken place. An implicit assumption behind this methodology is that any drop in classification accuracy can be interpreted as a symptom of concept change. Unfortunately however, this assumption is often violated in the real world where data streams carry noise that can also introduce a significant reduction in classification accuracy. To compound this problem, traditional noise cleansing methods are incompetent for data streams. Those methods normally need to scan data multiple times whereas learning for data streams can only afford one-pass scan because of data's high speed and huge volume. Another open problem in data stream classification is how to deal with missing values. When new instances containing missing values arrive, how a learning model classifies them and how the learning model updates itself according to them is an issue whose solution is far from being explored. To solve these problems, this paper proposes a novel classification algorithm, flexible decision tree (FlexDT), which extends fuzzy logic to data stream classification. The advantages are three-fold. First, FlexDT offers a flexible structure to effectively and efficiently handle concept change. Second, FlexDT is robust to noise. Hence it can prevent noise from interfering with classification accuracy, and accuracy drop can be safely attributed to concept change. Third, it deals with missing values in an elegant way. Extensive evaluations are conducted to compare FlexDT with representative existing data stream classification algorithms using a large suite of data streams and various statistical tests. Experimental results suggest that FlexDT offers a significant benefit to data stream classification in real-world scenarios where concept change, noise and missing values coexist.",2009,Data Mining and Knowledge Discovery volume 19 issue 1 pp 95-131,one class classification;linear classifier;decision tree learning;fuzzy logic;decision tree;statistical hypothesis testing;data stream mining;data mining;pattern recognition;machine learning;statistics;computer science;
iSAX: disk-aware mining and indexing of massive time series datasets,"Jin Shieh (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2101109093,2170070822","Current research in indexing and mining time series data has produced many interesting algorithms and representations. However, the algorithms and the size of data considered have generally not been representative of the increasingly massive datasets encountered in science, engineering, and business domains. In this work, we introduce a novel multi-resolution symbolic representation which can be used to index datasets which are several orders of magnitude larger than anything else considered in the literature. To demonstrate the utility of this representation, we constructed a simple tree-based index structure which facilitates fast exact search and orders of magnitude faster, approximate search. For example, with a database of one-hundred million time series, the approximate search can retrieve high quality nearest neighbors in slightly over a second, whereas a sequential scan would take tens of minutes. Our experimental evaluation demonstrates that our representation allows index performance to scale well with increasing dataset sizes. Additionally, we provide analysis concerning parameter sensitivity, approximate search effectiveness, and lower bound comparisons between time series representations in a bit constrained environment. We further show how to exploit the combination of both exact and approximate search as sub-routines in data mining algorithms, allowing for the exact mining of truly massive real world datasets, containing tens of millions of time series.",2009,Data Mining and Knowledge Discovery volume 19 issue 1 pp 24-57,time series;data science;data mining;machine learning;statistics;computer science;
A novel hash-based approach for mining frequent itemsets over data streams requiring less memory space,En Tzu Wang (National Tsing Hua University);Arbee L. P. Chen (National Chengchi University);,"2431917719,2211440602","In recent times, data are generated as a form of continuous data streams in many applications. Since handling data streams is necessary and discovering knowledge behind data streams can often yield substantial benefits, mining over data streams has become one of the most important issues. Many approaches for mining frequent itemsets over data streams have been proposed. These approaches often consist of two procedures including continuously maintaining synopses for data streams and finding frequent itemsets from the synopses. However, most of the approaches assume that the synopses of data streams can be saved in memory and ignore the fact that the information of the non-frequent itemsets kept in the synopses may cause memory utilization to be significantly degraded. In this paper, we consider compressing the information of all the itemsets into a structure with a fixed size using a hash-based technique. This hash-based approach skillfully summarizes the information of the whole data stream by using a hash table, provides a novel technique to estimate the support counts of the non-frequent itemsets, and keeps only the frequent itemsets for speeding up the mining process. Therefore, the goal of optimizing memory space utilization can be achieved. The correctness guarantee, error analysis, and parameter setting of this approach are presented and a series of experiments is performed to show the effectiveness and the efficiency of this approach.",2009,Data Mining and Knowledge Discovery volume 19 issue 1 pp 132-172,hash function;hash table;type i and type ii errors;world wide web;data mining;database;computer science;
Global and componentwise extrapolations for accelerating training of Bayesian networks and conditional random fields,Han-Shen Huang (Academia Sinica);Bo-Hou Yang (Academia Sinica);Yu-Ming Chang (Academia Sinica);Chun-Nan Hsu (Academia Sinica);,"2615569815,2157275928,2691521100,2171329927","The triple jump extrapolation method is an effective approximation of Aitken's acceleration that can accelerate the convergence of many algorithms for data mining, including EM and generalized iterative scaling (GIS). It has two options--global and componentwise extrapolation. Empirical studies showed that neither can dominate the other and it is not known which one is better under what condition. In this paper, we investigate this problem and conclude that, when the Jacobian is (block) diagonal, componentwise extrapolation will be more effective. We derive two hints to determine the block diagonality. The first hint is that when we have a highly sparse data set, the Jacobian of the EM mapping for training a Bayesian network will be block diagonal. The second is that the block diagonality of the Jacobian of the GIS mapping for training CRF is negatively correlated with the strength of feature dependencies. We empirically verify these hints with controlled and real-world data sets and show that our hints can accurately predict which method will be superior. We also show that both global and componentwise extrapolation can provide substantial acceleration. In particular, when applied to train large-scale CRF models, the GIS variant accelerated by componentwise extrapolation not only outperforms its global extrapolation counterpart, as our hint predicts, but can also compete with limited-memory BFGS (L-BFGS), the de facto standard for CRF training, in terms of both computational efficiency and F-scores. Though none of the above methods are as fast as stochastic gradient descent (SGD), careful tuning is required for SGD and the results given in this paper provide a useful foundation for automatic tuning.",2009,Data Mining and Knowledge Discovery volume 19 issue 1 pp 58-94,conditional random field;bayesian network;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
Document analysis and visualization with zero-inflated poisson,Dora Alvarez (Ensenada Center for Scientific Research and Higher Education);Hugo Hidalgo (Ensenada Center for Scientific Research and Higher Education);,"2419730913,2430728078","Data visualization is aimed at obtaining a graphic representation of high dimensional information. A data projection over a lower dimensional space is pursued, looking for some structure on the projections. Among the several data projection based methods available, the Generative Topographic Mapping (GTM) has become an important probabilistic framework to model data. The application to document data requires a change in the original (Gaussian) model in order to consider binary or multinomial variables. There have been several modifications on GTM to consider this kind of data, but the resulting latent projections are all scattered on the visualization plane. A document visualization method is proposed in this paper, based on a generative probabilistic model consisting of a mixture of Zero-inflated Poisson distributions. The performance of the method is evaluated in terms of cluster forming for the latent projections with an index based on Fisher's classifier, and the topology preservation capability is measured with the Sammon's stress error. A comparison with the GTM implementation with Gaussian, multinomial and Poisson distributions and with a Latent Dirichlet model is presented, observing a greater performance for the proposed method. A graphic presentation of the projections is also provided, showing the advantage of the developed method in terms of visualization and class separation. A detailed analysis of some documents projected on the latent representation showed that most of the documents appearing away from the corresponding cluster could be identified as outliers.",2009,Data Mining and Knowledge Discovery volume 19 issue 1 pp 1-23,generative topographic map;zero inflated model;generative model;poisson distribution;statistical model;data visualization;data mining;pattern recognition;machine learning;statistics;computer science;
Harmony K-means algorithm for document clustering,Mehrdad Mahdavi (Sharif University of Technology);Hassan Abolhassani (Sharif University of Technology);,"2147539308,1968678165","Fast and high quality document clustering is a crucial task in organizing information, search engine results, enhancing web crawling, and information retrieval or filtering. Recent studies have shown that the most commonly used partition-based clustering algorithm, the K-means algorithm, is more suitable for large datasets. However, the K-means algorithm can generate a local optimal solution. In this paper we propose a novel Harmony K-means Algorithm (HKA) that deals with document clustering based on Harmony Search (HS) optimization method. It is proved by means of finite Markov chain theory that the HKA converges to the global optimum. To demonstrate the effectiveness and speed of HKA, we have applied HKA algorithms on some standard datasets. We also compare the HKA with other meta-heuristic and model-based document clustering approaches. Experimental results reveal that the HKA algorithm converges to the best known optimum faster than other methods and the quality of clusters are comparable.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 370-391,canopy clustering algorithm;harmony search;web crawler;k means clustering;markov chain;cluster analysis;document clustering;global optimization;information retrieval;data mining;machine learning;computer science;
DECODE: a new method for discovering clusters of different densities in spatial data,Tao Pei (Imperial College London);Ajay Jasra (Imperial College London);David J. Hand (Imperial College London);A.-Xing Zhu (University of Wisconsin-Madison);Chenghu Zhou (Chinese Academy of Sciences);,"2655472256,1977909497,2175518357,2550006152,2146969481","When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 337-369,point process;information management;data mining;machine learning;statistics;computer science;mathematics;
A divide-and-conquer recursive approach for scaling up instance selection algorithms,Aida de Haro-García (University of Córdoba);Nicolás García-Pedrajas (University of Córdoba);,"341608689,140902767","Instance selection is becoming more and more relevant due to the huge amount of data that is being constantly produced. However, although current algorithms are useful for fairly large datasets, scaling problems are found when the number of instances is of hundreds of thousands or millions. In the best case, these algorithms are of efficiency O(n 2), n being the number of instances. When we face huge problems, scalability is an issue, and most algorithms are not applicable. This paper presents a divide-and-conquer recursive approach to the problem of instance selection for instance based learning for very large problems. Our method divides the original training set into small subsets where the instance selection algorithm is applied. Then the selected instances are rejoined in a new training set and the same procedure, partitioning and application of an instance selection algorithm, is repeated. In this way, our approach is based on the philosophy of divide-and-conquer applied in a recursive manner. The proposed method is able to match, and even improve, for the case of storage reduction, the results of well-known standard algorithms with a very significant reduction of execution time. An extensive comparison in 30 datasets form the UCI Machine Learning Repository shows the usefulness of our method. Additionally, the method is applied to 5 huge datasets with from 300,000 to more than a million instances, with very good results and fast execution time.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 392-418,divide and conquer algorithms;scalability;instance based learning;data mining;pattern recognition;machine learning;computer science;
A link mining algorithm for earnings forecast and trading,Germán G. Creamer (Columbia University);Salvatore Stolfo (Columbia University);,"2257480447,2021877992","The objective of this paper is to present and discuss a link mining algorithm called CorpInterlock and its application to the financial domain. This algorithm selects the largest strongly connected component of a social network and ranks its vertices using several indicators of distance and centrality. These indicators are merged with other relevant indicators in order to forecast new variables using a boosting algorithm. We applied the algorithm CorpInterlock to integrate the metrics of an extended corporate interlock (social network of directors and financial analysts) with corporate fundamental variables and analysts' predictions (consensus). CorpInterlock used these metrics to forecast the trend of the cumulative abnormal return and earnings surprise of S&P 500 companies. The rationality behind this approach is that the corporate interlock has a direct effect on future earnings and returns because these variables affect directors and managers' compensation. The financial analysts engage in what the agency theory calls the ""earnings game"": Managers want to meet the financial forecasts of the analysts and analysts want to increase their compensation or business of the company that they follow. Following the CorpInterlock algorithm, we calculated a group of well-known social network metrics and integrated with economic variables using Logitboost. We used the results of the CorpInterlock algorithm to evaluate several trading strategies. We observed an improvement of the Sharpe ratio (risk-adjustment return) when we used ""long only"" trading strategies with the extended corporate interlock instead of the basic corporate interlock before the regulation Fair Disclosure (FD) was adopted (1998---2001). There was no major difference among the trading strategies after 2001. Additionally, the CorpInterlock algorithm implemented with Logitboost showed a significantly lower test error than when the CorpInterlock algorithm was implemented with logistic regression. We conclude that the CorpInterlock algorithm showed to be an effective forecasting algorithm and supported profitable trading strategies.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 419-445,trading strategy;computational finance;actuarial science;data mining;machine learning;computer science;
Ethological data mining: an automata-based approach to extract behavioral units and rules,Yasuki Kakishita (University of Electro-Communications);Kazutoshi Sasahara (Japan Society for the Promotion of Science);Tetsuro Nishino (University of Electro-Communications);Miki Takahasi (University of Tokyo);Kazuo Okanoya (University of Tokyo);,"2276560048,2168175351,2131791077,2111826158,26512328","We propose an efficient automata-based approach to extract behavioral units and rules from continuous sequential data of animal behavior. By introducing novel extensions, we integrate two elemental methods--the N-gram model and Angluin's machine learning algorithm into an ethological data mining framework. This allows us to obtain the minimized automaton-representation of behavioral rules that accept (or generate) the smallest set of possible behavioral patterns from sequential data of animal behavior. With this method, we demonstrate how the ethological data mining works using real birdsong data; we use the Bengalese finch song and perform experimental evaluations of this method using artificial birdsong data generated by a computer program. These results suggest that our ethological data mining works effectively even for noisy behavioral data by appropriately setting the parameters that we introduce. In addition, we demonstrate a case study using the Bengalese finch song, showing that our method successfully grasps the core structure of the singing behavior such as loops and branches.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 446-471,data mining;artificial intelligence;machine learning;computer science;
Incremental sequence-based frequent query pattern mining from XML queries,Guoliang Li (Tsinghua University);Jianhua Feng (Tsinghua University);Jianyong Wang (Tsinghua University);Lizhu Zhou (Tsinghua University);,"2171804313,1995232797,2105625159,2286125848","Existing algorithms of mining frequent XML query patterns (XQPs) employ a candidate generate-and-test strategy. They involve expensive candidate enumeration and costly tree-containment checking. Further, most of existing methods compute the frequencies of candidate query patterns from scratch periodically by checking the entire transaction database, which consists of XQPs transferred from user query logs. However, it is not straightforward to maintain such discovered frequent patterns in real XML databases as there may be frequent updates that may not only invalidate some existing frequent query patterns but also generate some new frequent query patterns. Therefore, a drawback of existing methods is that they are rather inefficient for the evolution of transaction databases. To address above-mentioned problems, this paper proposes an efficient algorithm ESPRIT to mine frequent XQPs without costly tree-containment checking. ESPRIT transforms XML queries into sequences using a one-to-one mapping technique and mines the frequent sequences to generate frequent XQPs. We propose two efficient incremental algorithms, ESPRIT-i and ESPRIT-i +, to incrementally mine frequent XQPs. We devise several novel optimization techniques of query rewriting, cache lookup, and cache replacement to improve the answerability and the hit rate of caching. We have implemented our algorithms and conducted a set of experimental studies on various datasets. The experimental results demonstrate that our algorithms achieve high efficiency and scalability and outperform state-of-the-art methods significantly.",2009,Data Mining and Knowledge Discovery volume 18 issue 3 pp 472-516,sargable;web search query;web query classification;xml database;query expansion;query optimization;sequential pattern mining;query language;information retrieval;data mining;database;computer science;
Sourcerer: mining and searching internet-scale software repositories,"Erik Linstead (University of California, Irvine);Sushil Krishna Bajracharya (University of California, Irvine);Trung Chi Ngo (University of California, Irvine);Paul Rigor (University of California, Irvine);Cristina Videira Lopes (University of California, Irvine);Pierre Baldi (University of California, Irvine);","1272400704,1977073778,2138440916,72922282,2132640881,2060797211","Large repositories of source code available over the Internet, or within large organizations, create new challenges and opportunities for data mining and statistical machine learning. Here we first develop Sourcerer, an infrastructure for the automated crawling, parsing, fingerprinting, and database storage of open source software on an Internet-scale. In one experiment, we gather 4,632 Java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data first reveal robust power-law behavior for package, method call, and lexical containment distributions. We then develop and apply unsupervised, probabilistic, topic and author-topic (AT) models to automatically discover the topics embedded in the code and extract topic-word, document-topic, and AT distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing source file similarity, developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering an software development staffing. Finally, by combining software textual content with structural information captured by our CodeRank approach, we are able to significantly improve software retrieval performance, increasing the area under the curve (AUC) retrieval metric to 0.92--- roughly 10---30% better than previous approaches based on text alone. A prototype of the system is available at: http://sourcerer.ics.uci.edu .",2009,Data Mining and Knowledge Discovery volume 18 issue 2 pp 300-336,software analysis pattern;source lines of code;area under the curve;software development;source code;power law;world wide web;data mining;database;machine learning;computer science;
Using instance-level constraints in agglomerative hierarchical clustering: theoretical and empirical results,"Ian Davidson (University of California, Davis);S. S. Ravi (University at Albany, SUNY);","2560595684,2695677490",Clustering with constraints is a powerful method that allows users to specify background knowledge and the expected cluster properties. Significant work has explored the incorporation of instance-level constraints into non-hierarchical clustering but not into hierarchical clustering algorithms. In this paper we present a formal complexity analysis of the problem and show that constraints can be used to not only improve the quality of the resultant dendrogram but also the efficiency of the algorithms. This is particularly important since many agglomerative style algorithms have running times that are quadratic (or faster growing) functions of the number of instances to be clustered. We present several bounds on the improvement in the running times of algorithms obtainable using constraints.,2009,Data Mining and Knowledge Discovery volume 18 issue 2 pp 257-282,k medians clustering;hierarchical clustering of networks;flame clustering;brown clustering;canopy clustering algorithm;hierarchical network model;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;dendrogram;fuzzy clustering;clustering high dimensional data;power iteration;hierarchical clustering;cluster analysis;consensus clustering;biclustering;semi supervised learning;conceptual clustering;data mining;pattern recognition;machine learning;computer science;mathematics;
Active learning for object classification: from exploration to exploitation,Nicolas Cebron (University of Konstanz);Michael R. Berthold (University of Konstanz);,"2078788081,2117114528","Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role, we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.",2009,Data Mining and Knowledge Discovery volume 18 issue 2 pp 283-299,active learning;exploration;interpersonal relationship;active learning;data science;data mining;machine learning;computer science;
Alternative prior assumptions for improving the performance of naïve Bayesian classifiers,Tzu-Tsung Wong (National Cheng Kung University);,2710126452,"The prior distribution of an attribute in a naive Bayesian classifier is typically assumed to be a Dirichlet distribution, and this is called the Dirichlet assumption. The variables in a Dirichlet random vector can never be positively correlated and must have the same confidence level as measured by normalized variance. Both the generalized Dirichlet and the Liouville distributions include the Dirichlet distribution as a special case. These two multivariate distributions, also defined on the unit simplex, are employed to investigate the impact of the Dirichlet assumption in naive Bayesian classifiers. We propose methods to construct appropriate generalized Dirichlet and Liouville priors for naive Bayesian classifiers. Our experimental results on 18 data sets reveal that the generalized Dirichlet distribution has the best performance among the three distribution families. Not only is the Dirichlet assumption inappropriate, but also forcing the variables in a prior to be all positively correlated can deteriorate the performance of the naive Bayesian classifier.",2009,Data Mining and Knowledge Discovery volume 18 issue 2 pp 183-213,categorical distribution;variational message passing;dirichlet multinomial distribution;concentration parameter;bayesian linear regression;generalized dirichlet distribution;conjugate;hierarchical dirichlet process;dirichlet distribution;naive bayes classifier;gibbs sampling;latent dirichlet allocation;prior probability;multivariate normal distribution;confidence interval;econometrics;pattern recognition;statistics;mathematics;
A global optimization method for semi-supervised clustering,Yu Xia (University of Birmingham);,2660577115,"In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.",2009,Data Mining and Knowledge Discovery volume 18 issue 2 pp 214-256,k medians clustering;flame clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;cutting plane method;clustering high dimensional data;cluster analysis;consensus clustering;biclustering;global optimization;pattern recognition;machine learning;mathematical optimization;mathematics;
Controlled experiments on the web: survey and practical guide,Ron Kohavi (Microsoft);Roger Longbotham (Microsoft);Dan Sommerfield (Microsoft);Randal M. Henne (Microsoft);,"73615348,2067073079,2058945821,2150097138","The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person's Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments.",2009,Data Mining and Knowledge Discovery volume 18 issue 1 pp 140-181,return on investment;randomized experiment;sample size determination;statistical power;e commerce;management science;data mining;simulation;statistics;computer science;
Transaction aggregation as a strategy for credit card fraud detection,Christopher Whitrow (Imperial College London);David J. Hand (Imperial College London);Piotr Juszczak (Imperial College London);David John Weston (Imperial College London);Niall M. Adams (Imperial College London);,"2461792258,2175518357,2075245609,2166424077,2145214992","The problem of preprocessing transaction data for supervised fraud classification is considered. It is impractical to present an entire series of transactions to a fraud detection system, partly because of the very high dimensionality of such data but also because of the heterogeneity of the transactions. Hence, a framework for transaction aggregation is considered and its effectiveness is evaluated against transaction-level detection, using a variety of classification methods and a realistic cost-based performance measure. These methods are applied in two case studies using real data. Transaction aggregation is found to be advantageous in many but not all circumstances. Also, the length of the aggregation period has a large impact upon performance. Aggregation seems particularly effective when a random forest is used for classification. Moreover, random forests were found to perform better than other classification methods, including SVMs, logistic regression and KNN. Aggregation also has the advantage of not requiring precisely labeled data and may be more robust to the effects of population drift.",2009,Data Mining and Knowledge Discovery volume 18 issue 1 pp 30-55,transaction data;random forest;preprocessor;logistic regression;data science;computer security;data mining;machine learning;computer science;
FRAPP: a framework for high-accuracy privacy-preserving mining,Shipra Agrawal (Indian Institute of Science);Jayant R. Haritsa (Indian Institute of Science);B. Aditya Prakash (Indian Institutes of Technology);,"2442316571,44170712,2124002246","To preserve client privacy in the data mining process, a variety of techniques based on random perturbation of individual data records have been proposed recently. In this paper, we present FRAPP, a generalized matrix-theoretic framework of random perturbation, which facilitates a systematic approach to the design of perturbation mechanisms for privacy-preserving mining. Specifically, FRAPP is used to demonstrate that (a) the prior techniques differ only in their choices for the perturbation matrix elements, and (b) a symmetric positive-definite perturbation matrix with minimal condition number can be identified, substantially enhancing the accuracy even under strict privacy requirements. We also propose a novel perturbation mechanism wherein the matrix elements are themselves characterized as random variables, and demonstrate that this feature provides significant improvements in privacy at only a marginal reduction in accuracy. The quantitative utility of FRAPP, which is a general-purpose random-perturbation-based privacy-preserving mining technique, is evaluated specifically with regard to association and classification rule mining on a variety of real datasets. Our experimental results indicate that, for a given privacy requirement, either substantially lower modeling errors are incurred as compared to the prior techniques, or the errors are comparable to those of direct mining on the true database.",2009,Data Mining and Knowledge Discovery volume 18 issue 1 pp 101-139,condition number;errors in variables models;privacy;random variable;data mining;machine learning;statistics;computer science;mathematics;
Scalable pattern mining with Bayesian networks as background knowledge,Szymon Jaroszewicz (University of Massachusetts Amherst);Tobias Scheffer (Max Planck Society);Dan A. Simovici (University of Massachusetts Amherst);,"115085028,2609429555,114567545","We study a discovery framework in which background knowledge on variables and their relations within a discourse area is available in the form of a graphical model. Starting from an initial, hand-crafted or possibly empty graphical model, the network evolves in an interactive process of discovery. We focus on the central step of this process: given a graphical model and a database, we address the problem of finding the most interesting attribute sets. We formalize the concept of interestingness of attribute sets as the divergence between their behavior as observed in the data, and the behavior that can be explained given the current model. We derive an exact algorithm that finds all attribute sets whose interestingness exceeds a given threshold. We then consider the case of a very large network that renders exact inference unfeasible, and a very large database or data stream. We devise an algorithm that efficiently finds the most interesting attribute sets with prescribed approximation bound and confidence probability, even for very large networks and infinite streams. We study the scalability of the methods in controlled experiments; a case-study sheds light on the practical usefulness of the approach.",2009,Data Mining and Knowledge Discovery volume 18 issue 1 pp 56-100,very large database;bayesian network;graphical model;association rule learning;data mining;pattern recognition;machine learning;statistics;computer science;
CONTOUR: an efficient algorithm for discovering discriminating subsequences,Jianyong Wang (Tsinghua University);Yuzhou Zhang (Tsinghua University);Lizhu Zhou (Tsinghua University);George Karypis (University of Minnesota);Charu C. Aggarwal (IBM);,"2105625159,2479340321,2286125848,219814910,2146335907","In recent years we have witnessed several applications of frequent sequence mining, such as feature selection for protein sequence classification and mining block correlations in storage systems. In typical applications such as clustering, it is not the complete set but only a subset of discriminating frequent subsequences which is of interest. One approach to discovering the subset of useful frequent subsequences is to apply any existing frequent sequence mining algorithm to find the complete set of frequent subsequences. Then, a subset of interesting subsequences can be further identified. Unfortunately, it is very time consuming to mine the complete set of frequent subsequences for large sequence databases. In this paper, we propose a new algorithm, CONTOUR, which efficiently mines a subset of high-quality subsequences directly in order to cluster the input sequences. We mainly focus on how to design some effective search space pruning methods to accelerate the mining process and discuss how to construct an accurate clustering algorithm based on the result of CONTOUR. We conducted an extensive performance study to evaluate the efficiency and scalability of CONTOUR, and the accuracy of the frequent subsequence-based clustering algorithm.",2009,Data Mining and Knowledge Discovery volume 18 issue 1 pp 1-29,sequential pattern mining;cluster analysis;protein sequencing;feature selection;bioinformatics;data mining;pattern recognition;machine learning;computer science;mathematics;
FURIA: an algorithm for unordered fuzzy rule induction,Jens Christian Hühn (University of Marburg);Eyke Hüllermeier (University of Paderborn);,"2331676183,323026139","This paper introduces a novel fuzzy rule-based classification method called FURIA, which is short for Fuzzy Unordered Rule Induction Algorithm. FURIA extends the well-known RIPPER algorithm, a state-of-the-art rule learner, while preserving its advantages, such as simple and comprehensible rule sets. In addition, it includes a number of modifications and extensions. In particular, FURIA learns fuzzy rules instead of conventional rules and unordered rule sets instead of rule lists. Moreover, to deal with uncovered examples, it makes use of an efficient rule stretching method. Experimental results show that FURIA significantly outperforms the original RIPPER, as well as other classifiers such as C4.5, in terms of classification accuracy.",2009,Data Mining and Knowledge Discovery volume 19 issue 3 pp 293-319,fuzzy classification;fuzzy logic;biological classification;data mining;pattern recognition;machine learning;computer science;mathematics;
Solving large p-median clustering problems by primal–dual variable neighborhood search,Pierre Hansen (HEC Montréal);Jack Brimberg (Royal Military College of Canada);Dragan Urošević (Serbian Academy of Sciences and Arts);Nenad Mladenović (Brunel University London);,"2099733369,22025931,2154884998,2305085776","Data clustering methods are used extensively in the data mining literature to detect important patterns in large datasets in the form of densely populated regions in a multi-dimensional Euclidean space. Due to the complexity of the problem and the size of the dataset, obtaining quality solutions within reasonable CPU time and memory requirements becomes the central challenge. In this paper, we solve the clustering problem as a large scale p-median model, using a new approach based on the variable neighborhood search (VNS) metaheuristic. Using a highly efficient data structure and local updating procedure taken from the OR literature, our VNS procedure is able to tackle large datasets directly without the need for data reduction or sampling as employed in certain popular methods. Computational results demonstrate that our VNS heuristic outperforms other local search based methods such as CLARA and CLARANS even after upgrading these procedures with the same efficient data structures and local search. We also obtain a bound on the quality of the solutions by solving heuristically a dual relaxation of the problem, thus introducing an important capability to the solution process.",2009,Data Mining and Knowledge Discovery volume 19 issue 3 pp 351-375,local search;euclidean space;data reduction;cluster analysis;data structure;data mining;machine learning;mathematical optimization;computer science;mathematics;
Fast incremental mining of web sequential patterns with PLWAP tree,Christie I. Ezeife (University of Windsor);Yi Liu (University of Windsor);,"2515904849,2310191499","Point and click at web pages generate continuous data sequences, which flow into the web log data, causing the need to update previously mined web sequential patterns. Algorithms for mining web sequential patterns from scratch include WAP, PLWAP and Apriori-based GSP. Reusing old patterns with only recent additional data sequences in an incremental fashion, when updating patterns, would achieve fast response time with reasonable memory space usage. This paper proposes two algorithms, RePL4UP (Revised PLWAP For UPdate), and PL4UP (PLWAP For UPdate), which use the PLWAP tree structure to incrementally update web sequential patterns efficiently without scanning the whole database even when previous small items become frequent. The RePL4UP concisely stores the position codes of small items in the database sequences in its metadata during tree construction. During mining, RePL4UP scans only the new additional database sequences, revises the old PLWAP tree to restore information on previous small items that have become frequent, while it deletes previous frequent items that have become small using the small item position codes. PL4UP initially builds a bigger PLWAP tree that includes all sequences in the database using a tolerance support, t, that is lower than the regular minimum support, s. The position code features of the PLWAP tree are used to efficiently mine these trees to extract current frequent patterns when the database is updated. These approaches more quickly update old frequent patterns without the need to re-scan the entire updated database.",2009,Data Mining and Knowledge Discovery volume 19 issue 3 pp 376-416,web page;scalability;tree structure;data stream mining;world wide web;data mining;database;computer science;
Subsea: an efficient heuristic algorithm for subgraph isomorphism,Vladimir Lipets (Ben-Gurion University of the Negev);Natalia Vanetik (Ben-Gurion University of the Negev);Ehud Gudes (Ben-Gurion University of the Negev);,"2313613984,2042215923,195553551",We present a novel approach to the problem of finding all subgraphs and induced subgraphs of a (target) graph which are isomorphic to another (pattern) graph. To attain efficiency we use a special representation of the pattern graph. We also combine our search algorithm with some known bisection algorithms. Experimental comparison with other algorithms was performed on several types of graphs. The comparison results suggest that the approach provided here is most effective when all instances of a subgraph need to be found.,2009,Data Mining and Knowledge Discovery volume 19 issue 3 pp 320-350,degeneracy;implicit graph;factor critical graph;distance hereditary graph;induced subgraph isomorphism problem;voltage graph;complement graph;forbidden graph characterization;graph bandwidth;graph power;graph factorization;butterfly graph;universal graph;claw free graph;graph homomorphism;graph property;bisection;color coding;subgraph isomorphism problem;line graph;graph isomorphism;heuristic;search algorithm;heuristic;discrete mathematics;combinatorics;mathematical optimization;computer science;mathematics;
Weka-A Machine Learning Workbench for Data Mining,Eibe Frank (University of Waikato);Mark A. Hall (University of Waikato);Geoffrey Holmes (University of Waikato);Richard Kirkby (University of Waikato);Bernhard Pfahringer (University of Waikato);Ian H. Witten (University of Waikato);Len Trigg;,"2165714491,2126237948,2189262995,2098111081,1991131908,2163446563,2704066262",-,2009,Data Mining and Knowledge Discovery pp 1269-1277,data pre processing;user interface;data processing;data science;theoretical computer science;data mining;machine learning;computer science;
Dimension Reduction and Feature Selection,Barak Chizi (Tel Aviv University);Oded Maimon (Tel Aviv University);,"2270247245,225598367",-,2009,Data Mining and Knowledge Discovery pp 83-100,fsa red algorithm;dimensionality reduction;feature selection;data mining;pattern recognition;machine learning;computer science;
Learning to hash: forgiving hash functions and applications,Shumeet Baluja (Google);Michele Covell (Google);,"1877528474,2217511182","The problem of efficiently finding similar items in a large corpus of high-dimensional data points arises in many real-world tasks, such as music, image, and video retrieval. Beyond the scaling difficulties that arise with lookups in large data sets, the complexity in these domains is exacerbated by an imprecise definition of similarity. In this paper, we describe a method to learn a similarity function from only weakly labeled positive examples. Once learned, this similarity function is used as the basis of a hash function to severely constrain the number of points considered for each lookup. Tested on a large real-world audio dataset, only a tiny fraction of the points (~0.27%) are ever considered for each lookup. To increase efficiency, no comparisons in the original high-dimensional space of points are required. The performance far surpasses, in terms of both efficiency and accuracy, a state-of-the-art Locality-Sensitive-Hashing-based (LSH) technique for the same problem and data set.",2008,Data Mining and Knowledge Discovery volume 17 issue 3 pp 402-430,k independent hashing;rolling hash;2 choice hashing;hash filter;primary clustering;feature hashing;suha;locality preserving hashing;double hashing;hash tree;dynamic perfect hashing;linear hashing;perfect hash function;universal hashing;locality sensitive hashing;hash function;consistent hashing;hash table;theoretical computer science;data mining;machine learning;computer science;mathematics;
Parallell interacting MCMC for learning of topologies of graphical models,Jukka Corander (Åbo Akademi University);Magnus Ekdahl (Linköping University);Timo Koski (Royal Institute of Technology);,"2045095944,2042989500,2078390131","Automated statistical learning of graphical models from data has attained a considerable degree of interest in the machine learning and related literature. Many authors have discussed and/or demonstrated the need for consistent stochastic search methods that would not be as prone to yield locally optimal model structures as simple greedy methods. However, at the same time most of the stochastic search methods are based on a standard Metropolis---Hastings theory that necessitates the use of relatively simple random proposals and prevents the utilization of intelligent and efficient search operators. Here we derive an algorithm for learning topologies of graphical models from samples of a finite set of discrete variables by utilizing and further enhancing a recently introduced theory for non-reversible parallel interacting Markov chain Monte Carlo-style computation. In particular, we illustrate how the non-reversible approach allows for novel type of creativity in the design of search operators. Also, the parallel aspect of our method illustrates well the advantages of the adaptive nature of search operators to avoid trapping states in the vicinity of locally optimal network topologies.",2008,Data Mining and Knowledge Discovery volume 17 issue 3 pp 431-456,markov chain monte carlo;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
"An integrated, generic approach to pattern mining: data mining template library",Vineet Chaoji (Rensselaer Polytechnic Institute);Mohammad Al Hasan (Rensselaer Polytechnic Institute);Saeed Salem (Rensselaer Polytechnic Institute);Mohammed Javeed Zaki (Rensselaer Polytechnic Institute);,"2344125319,2634411756,2164451553,2165917828","Frequent pattern mining (FPM) is an important data mining paradigm to extract informative patterns like itemsets, sequences, trees, and graphs. However, no practical framework for integrating the FPM tasks has been attempted. In this paper, we describe the design and implementation of the Data Mining Template Library (DMTL) for FPM. DMTL utilizes a generic data mining approach, where all aspects of mining are controlled via a set of properties. It uses a novel pattern property hierarchy to define and mine different pattern types. This property hierarchy can be thought of as a systematic characterization of the pattern space, i.e., a meta-pattern specification that allows the analyst to specify new pattern types, by extending this hierarchy. Furthermore, in DMTL all aspects of mining are controlled by a set of different mining properties. For example, the kind of mining approach to use, the kind of data types and formats to mine over, the kind of back-end storage manager to use, are all specified as a list of properties. This provides tremendous flexibility to customize the toolkit for various applications. Flexibility of the toolkit is exemplified by the ease with which support for a new pattern can be added. Experiments on synthetic and public dataset are conducted to demonstrate the scalability provided by the persistent back-end in the library. DMTL been publicly released as open-source software ( http://dmtl.sourceforge.net/ ), and has been downloaded by numerous researchers from all over the world.",2008,Data Mining and Knowledge Discovery volume 17 issue 3 pp 457-495,molecule mining;generic programming;sequential pattern mining;data type;concept mining;data stream mining;web mining;text mining;data science;data mining;database;computer science;
Efficiently finding unusual shapes in large image databases,"Li Wei (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);Xiaopeng Xi (University of California, Riverside);Melissa Yoder (University of California, Riverside);","2325104268,2170070822,2110982538,2102587638","Among the visual features of multimedia content, shape is of particular interest because humans can often recognize objects solely on the basis of shape. Over the past three decades, there has been a great deal of research on shape analysis, focusing mostly on shape indexing, clustering, and classification. In this work, we introduce the new problem of finding shape discords, the most unusual shapes in a collection. We motivate the problem by considering the utility of shape discords in diverse domains including zoology, microscopy, anthropology, and medicine. While the brute force search algorithm has quadratic time complexity, we avoid this untenable lethargy by using locality-sensitive hashing to estimate similarity between shapes which enables us to reorder the search more efficiently and thus extract the maximum benefit from an admissible pruning strategy we introduce. An extensive experimental evaluation demonstrates that our approach is empirically linear in time.",2008,Data Mining and Knowledge Discovery volume 17 issue 3 pp 343-376,locality sensitive hashing;active shape model;shape analysis;search algorithm;time complexity;shape;anomaly detection;theoretical computer science;computer vision;data mining;machine learning;computer science;mathematics;
Efficient algorithms for segmentation of item-set time series,"Parvathi Chundi (University of Nebraska Omaha);Daniel J. Rosenkrantz (University at Albany, SUNY);","2230771436,250841333","We propose a special type of time series, which we call an item-set time series, to facilitate the temporal analysis of software version histories, email logs, stock market data, etc. In an item-set time series, each observed data value is a set of discrete items. We formalize the concept of an item-set time series and present efficient algorithms for segmenting a given item-set time series. Segmentation of a time series partitions the time series into a sequence of segments where each segment is constructed by combining consecutive time points of the time series. Each segment is associated with an item set that is computed from the item sets of the time points in that segment, using a function which we call a measure function. We then define a concept called the segment difference, which measures the difference between the item set of a segment and the item sets of the time points in that segment. The segment difference values are required to construct an optimal segmentation of the time series. We describe novel and efficient algorithms to compute segment difference values for each of the measure functions described in the paper. We outline a dynamic programming based scheme to construct an optimal segmentation of the given item-set time series. We use the item-set time series segmentation techniques to analyze the temporal content of three different data sets---Enron email, stock market data, and a synthetic data set. The experimental results show that an optimal segmentation of item-set time series data captures much more temporal content than a segmentation constructed based on the number of time points in each segment, without examining the item set data at the time points, and can be used to analyze different types of temporal data.",2008,Data Mining and Knowledge Discovery volume 17 issue 3 pp 377-401,order of integration;time series;data mining;artificial intelligence;machine learning;statistics;computer science;
Automatically countering imbalance and its empirical relationship to cost,Nitesh V. Chawla (University of Notre Dame);David A. Cieslak (University of Notre Dame);Lawrence O. Hall (University of South Florida);Ajay Joshi (University of South Florida);,"1979796846,2004286868,2159848645,2098486845","Learning from imbalanced data sets presents a convoluted problem both from the modeling and cost standpoints. In particular, when a class is of great interest but occurs relatively rarely such as in cases of fraud, instances of disease, and regions of interest in large-scale simulations, there is a correspondingly high cost for the misclassification of rare events. Under such circumstances, the data set is often re-sampled to generate models with high minority class accuracy. However, the sampling methods face a common, but important, criticism: how to automatically discover the proper amount and type of sampling? To address this problem, we propose a wrapper paradigm that discovers the amount of re-sampling for a data set based on optimizing evaluation functions like the f-measure, Area Under the ROC Curve (AUROC), cost, cost-curves, and the cost dependent f-measure. Our analysis of the wrapper is twofold. First, we report the interaction between different evaluation and wrapper optimization functions. Second, we present a set of results in a cost- sensitive environment, including scenarios of unknown or changing cost matrices. We also compared the performance of the wrapper approach versus cost-sensitive learning methods--MetaCost and the Cost-Sensitive Classifiers--and found the wrapper to outperform the cost-sensitive classifiers in a cost-sensitive environment. Lastly, we obtained the lowest cost per test example compared to any result we are aware of for the KDD-99 Cup intrusion detection data set.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 225-252,evaluation function;intrusion detection system;receiver operating characteristic;region of interest;biological classification;sampling;data mining;artificial intelligence;machine learning;statistics;computer science;
Quantifying counts and costs via classification,George Forman (Hewlett-Packard);,2195069006,"Many business applications track changes over time, for example, measuring the monthly prevalence of influenza incidents. In situations where a classifier is needed to identify the relevant incidents, imperfect classification accuracy can cause substantial bias in estimating class prevalence. The paper defines two research challenges for machine learning. The `quantification' task is to accurately estimate the number of positive cases (or class distribution) in a test set, using a training set that may have a substantially different distribution. The `cost quantification' variant estimates the total cost associated with the positive class, where each case is tagged with a cost attribute, such as the expense to resolve the case. Quantification has a very different utility model from traditional classification research. For both forms of quantification, the paper describes a variety of methods and evaluates them with a suitable methodology, revealing which methods give reliable estimates when training data is scarce, the testing class distribution differs widely from training, and the positive class is rare, e.g., 1% positives. These strengths can make quantification practical for business use, even where classification accuracy is poor.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 164-206,one class classification;concept drift;biological classification;methodology;text mining;data mining;machine learning;statistics;computer science;
PRIE: a system for generating rulelists to maximize ROC performance,Tom Fawcett (Stanford University);,2590754628,"Rules are commonly used for classification because they are modular, intelligible and easy to learn. Existing work in classification rule learning assumes the goal is to produce categorical classifications to maximize classification accuracy. Recent work in machine learning has pointed out the limitations of classification accuracy: when class distributions are skewed, or error costs are unequal, an accuracy maximizing classifier can perform poorly. This paper presents a method for learning rules directly from ROC space when the goal is to maximize the area under the ROC curve (AUC). Basic principles from rule learning and computational geometry are used to focus the search for promising rule combinations. The result is a system that can learn intelligible rulelists with good ROC performance.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 207-224,receiver operating characteristic;computational geometry;data mining;pattern recognition;machine learning;statistics;computer science;
Pessimistic cost-sensitive active learning of decision trees for profit maximizing targeting campaigns,Lior Rokach (Ben-Gurion University of the Negev);Lihi Naamani (Deutsche Telekom);Armin Shmilovici (Ben-Gurion University of the Negev);,"1979308116,2397473140,2184642286","In business applications such as direct marketing, decision-makers are required to choose the action which best maximizes a utility function. Cost-sensitive learning methods can help them achieve this goal. In this paper, we introduce Pessimistic Active Learning (PAL). PAL employs a novel pessimistic measure, which relies on confidence intervals and is used to balance the exploration/exploitation trade-off. In order to acquire an initial sample of labeled data, PAL applies orthogonal arrays of fractional factorial design. PAL was tested on ten datasets using a decision tree inducer. A comparison of these results to those of other methods indicates PAL's superiority.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 283-316,decision tree;design of experiments;reinforcement learning;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
Maximizing classifier utility when there are data acquisition and modeling costs,Gary M. Weiss (Fordham University);Ye Tian (Fordham University);,"2112185085,2657485360","Classification is a well-studied problem in data mining. Classification performance was originally gauged almost exclusively using predictive accuracy, but as work in the field progressed, more sophisticated measures of classifier utility that better represented the value of the induced knowledge were introduced. Nonetheless, most work still ignored the cost of acquiring training examples, even though this cost impacts the total utility of the data mining process. In this article we analyze the relationship between the number of acquired training examples and the utility of the data mining process and, given the necessary cost information, we determine the number of training examples that yields the optimum overall performance. We then extend this analysis to include the cost of model induction--measured in terms of the CPU time required to generate the model. While our cost model does not take into account all possible costs, our analysis provides some useful insights and a template for future analyses using more sophisticated cost models. Because our analysis is based on experiments that acquire the full set of training examples, it cannot directly be used to find a classifier with optimal or near-optimal total utility. To address this issue we introduce two progressive sampling strategies that are empirically shown to produce classifiers with near-optimal total utility.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 253-282,decision tree;data science;data mining;machine learning;statistics;computer science;
Cost-sensitive learning with conditional Markov networks,"Prithviraj Sen (University of Maryland, College Park);Lise Getoor (University of Maryland, College Park);","2109537329,1984940772","There has been a recent, growing interest in classification and link prediction in structured domains. Methods such as conditional random fields and relational Markov networks support flexible mechanisms for modeling correlations due to the link structure. In addition, in many structured domains, there is an interesting structure in the risk or cost function associated with different misclassifications. There is a rich tradition of cost-sensitive learning applied to unstructured (IID) data. Here we propose a general framework which can capture correlations in the link structure and handle structured cost functions. We present two new cost-sensitive structured classifiers based on maximum entropy principles. The first determines the cost-sensitive classification by minimizing the expected cost of misclassification. The second directly determines the cost-sensitive classification without going through a probability estimation step. We contrast these approaches with an approach which employs a standard 0/1-loss structured classifier to estimate class conditional probabilities followed by minimization of the expected cost of misclassification and with a cost-sensitive IID classifier that does not utilize the correlations present in the link structure. We demonstrate the utility of our cost-sensitive structured classifiers with experiments on both synthetic and real-world data.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 136-163,structured support vector machine;maximum entropy markov model;structured prediction;conditional random field;principle of maximum entropy;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Guest editorial: special issue on utility-based data mining,Gary M. Weiss (Fordham University);Bianca Zadrozny (Federal Fluminense University);Maytal Saar-Tsechansky (McCombs School of Business);,"2112185085,54648453,131186531",-,2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 129-135,data science;operations research;data mining;computer science;
Classification trees and decision-analytic feedforward control: a case study from the video game industry,Michael Brydon (Simon Fraser University);Andrew Gemino (Simon Fraser University);,"2019241567,2173700457","The objective of this paper is to use a challenging real-world problem to illustrate how a probabilistic predictive model can provide the foundation for decision-analytic feedforward control. Commercial data mining software and sales data from a market research firm are used to create a predictive model of market success in the video game industry. A procedure is then described for transforming the classification trees into a decision-analytic model that can be solved to produce a value-maximizing game development policy. The video game example shows how the compact predictive models created by data mining algorithms can help to make decision-analytic feedforward control feasible, even for large, complex problems. However, the example also highlights the bounds placed on the practicality of the approach due to combinatorial explosions in the number of contingencies that have to be modeled. We show, for example, how the ""option value"" of sequels creates complexity that is effectively impossible to address using conventional decision analysis tools.",2008,Data Mining and Knowledge Discovery volume 17 issue 2 pp 317-342,video game development;decision tree;market research;decision analysis;data mining;artificial intelligence;machine learning;simulation;computer science;
Finding reliable subgraphs from large probabilistic graphs,Petteri Hintsanen (Helsinki Institute for Information Technology);Hannu Toivonen (Helsinki Institute for Information Technology);,"333024175,2250270171","Reliable subgraphs can be used, for example, to find and rank nontrivial links between given vertices, to concisely visualize large graphs, or to reduce the size of input for computationally demanding graph algorithms. We propose two new heuristics for solving the most reliable subgraph extraction problem on large, undirected probabilistic graphs. Such a problem is specified by a probabilistic graph G subject to random edge failures, a set of terminal vertices, and an integer K. The objective is to remove K edges from G such that the probability of connecting the terminals in the remaining subgraph is maximized. We provide some technical details and a rough analysis of the proposed algorithms. The practical performance of the methods is evaluated on real probabilistic graphs from the biological domain. The results indicate that the methods scale much better to large input graphs, both computationally and in terms of the quality of the result.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 3-23,implicit graph;distance hereditary graph;indifference graph;complement graph;forbidden graph characterization;pancyclic graph;graph power;comparability graph;universal graph;block graph;cograph;graph product;split graph;graph homomorphism;modular decomposition;pathwidth;line graph;chordal graph;graph drawing;independent set;search engine;reliability;graph theory;theoretical computer science;discrete mathematics;combinatorics;statistics;computer science;mathematics;
Adequate condensed representations of patterns,Arnaud Soulet (François Rabelais University);Bruno Crémilleux (Centre national de la recherche scientifique);,"2470748226,134342808","Patterns are at the core of the discovery of a lot of knowledge from data but their uses are limited due to their huge number and their mining cost. During the last decade, many works addressed the concept of condensed representation w.r.t. frequency queries. Such representations are several orders of magnitude smaller than the size of the whole collections of patterns, and also enable us to regenerate the frequency information of any pattern. In this paper, we propose a framework for condensed representations w.r.t. a large set of new and various queries named condensable functions based on interestingness measures (e.g., frequency, lift, minimum). Such condensed representations are achieved thanks to new closure operators automatically derived from each condensable function to get adequate condensed representations. We propose a generic algorithm Mic Mac to efficiently mine the adequate condensed representations. Experiments show both the conciseness of the adequate condensed representations and the efficiency of our algorithm.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 94-110,closure operator;genetic algorithm;theoretical computer science;data mining;machine learning;algorithm;computer science;mathematics;
The Boolean column and column-row matrix decompositions,Pauli Miettinen (Helsinki Institute for Information Technology);,2015634213,"Matrix decompositions are used for many data mining purposes. One of these purposes is to find a concise but interpretable representation of a given data matrix. Different decomposition formulations have been proposed for this task, many of which assume a certain property of the input data (e.g., nonnegativity) and aim at preserving that property in the decomposition. In this paper we propose new decomposition formulations for binary matrices, namely the Boolean CX and CUR decompositions. They are natural combinations of two previously presented decomposition formulations. We consider also two subproblems of these decompositions and present a rigorous theoretical study of the subproblems. We give algorithms for the decompositions and for the subproblems, and study their performance via extensive experimental evaluation. We show that even simple algorithms can give accurate and intuitive decompositions of real data, thus demonstrating the power and usefulness of the proposed decompositions.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 39-56,matrix decomposition;approximation;discrete mathematics;combinatorics;data mining;algorithm;mathematics;
SkyGraph: an algorithm for important subgraph discovery in relational graphs,"Apostolos N. Papadopoulos (Aristotle University of Thessaloniki);Apostolos Lyritsis;Yannis Manolopoulos (University of Maryland, College Park);","2118319580,1272657643,276012958","A significant number of applications require effective and efficient manipulation of relational graphs, towards discovering important patterns. Some example applications are: (i) analysis of microarray data in bioinformatics, (ii) pattern discovery in a large graph representing a social network, (iii) analysis of transportation networks, (iv) community discovery in Web data. The basic approach followed by existing methods is to apply mining techniques on graph data to discover important patterns, such as subgraphs that are likely to be useful. However, in some cases the number of mined patterns is large, posing difficulties in selecting the most important ones. For example, applying frequent subgraph mining on a set of graphs the system returns all connected subgraphs whose frequency is above a specified (usually user-defined) threshold. The number of discovered patterns may be large, and this number depends on the data characteristics and the frequency threshold specified. It would be more convenient for the user if ""goodness"" criteria could be set to evaluate the usefulness of these patterns, and if the user could provide preferences to the system regarding the characteristics of the discovered patterns. In this paper, we propose a methodology to support such preferences by applying subgraph discovery in relational graphs towards retrieving important connected subgraphs. The importance of a subgraph is determined by: (i) the order of the subgraph (the number of vertices) and (ii) the subgraph edge connectivity. The performance of the proposed technique is evaluated by using real-life as well as synthetically generated data sets.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 57-76,induced subgraph isomorphism problem;subgraph isomorphism problem;microarray analysis techniques;social network;data science;bioinformatics;data mining;machine learning;computer science;
Two heads better than one: pattern discovery in time-evolving multi-aspect data,Jimeng Sun (IBM);Charalampos E. Tsourakakis (Carnegie Mellon University);Evan Hoke (Apple Inc.);Christos Faloutsos (Carnegie Mellon University);Tina Eliassi-Rad (Lawrence Livermore National Laboratory);,"2110385854,750472553,2057065545,2198983026,218538652","Data stream values are often associated with multiple aspects. For example each value observed at a given time-stamp from environmental sensors may have an associated type (e.g., temperature, humidity, etc.) as well as location. Time-stamp, type and location are the three aspects, which can be modeled using a tensor (high-order array). However, the time aspect is special, with a natural ordering, and with successive time-ticks having usually correlated values. Standard multiway analysis ignores this structure. To capture it, we propose 2 Heads Tensor Analysis (2-heads), which provides a qualitatively different treatment on time. Unlike most existing approaches that use a PCA-like summarization scheme for all aspects, 2-heads treats the time aspect carefully. 2-heads combines the power of classic multilinear analysis with wavelets, leading to a powerful mining tool. Furthermore, 2-heads has several other advantages as well: (a) it can be computed incrementally in a streaming fashion, (b) it has a provable error guarantee and, (c) it achieves significant compression ratio against competitors. Finally, we show experiments on real datasets, and we illustrate how 2-heads reveals interesting trends in the data. This is an extended abstract of an article published in the Data Mining and Knowledge Discovery journal.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 111-128,compression ratio;tensor;wavelet;data stream mining;knowledge extraction;data science;data mining;artificial intelligence;machine learning;statistics;computer science;
A space efficient solution to the frequent string mining problem for many databases,Adrian Kügel (University of Ulm);Enno Ohlebusch (University of Ulm);,"2069706914,315454154","The frequent string mining problem is to find all substrings of a collection of string databases which satisfy database specific minimum and maximum frequency constraints. Our contribution improves the existing linear-time algorithm for this problem in such a way that the peak memory consumption is a constant factor of the size of the largest database of strings. We show how the results for each database can be stored implicitly in space proportional to the size of the database, making it possible to traverse the results in lexicographical order. Furthermore, we present a linear-time algorithm which calculates the intersection of the results of different databases. This algorithm is based on an algorithm to merge two suffix arrays, and our modification allows us to also calculate the LCP table of the resulting suffix array during the merging.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 24-38,commentz walter algorithm;generalized suffix tree;compressed suffix array;lexicographical order;string;string searching algorithm;satisfiability;theoretical computer science;data mining;machine learning;algorithm;mathematics;
Mining conjunctive sequential patterns,Chedy Raïssi (University of Montpellier);Toon Calders (Eindhoven University of Technology);Pascal Poncelet (Mines ParisTech);,"2065278996,2064105222,733374064","In this paper we aim at extending the non-derivable condensed representation in frequent itemset mining to sequential pattern mining. We start by showing a negative example: in the context of frequent sequences, the notion of non-derivability is meaningless. Therefore, we extend our focus to the mining of conjunctions of sequences. Besides of being of practical importance, this class of patterns has some nice theoretical properties. Based on a new unexploited theoretical definition of equivalence classes for sequential patterns, we are able to extend the notion of a non-derivable itemset to the sequence domain. We present a new depth-first approach to mine non-derivable conjunctive sequential patterns and show its use in mining association rules for sequences. This approach is based on a well known combinatorial theorem: the Mobius inversion. A performance study using both synthetic and real datasets illustrates the efficiency of our mining algorithm. These new introduced patterns have a high-potential for real-life applications, especially for network monitoring and biomedical fields with the ability to get sequential association rules with all the classical statistical metrics such as confidence, conviction, lift etc.",2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 77-93,network monitoring;sequential pattern mining;association rule learning;side effect;data mining;machine learning;algorithm;computer science;
Guest Editors' Introduction: Special issue of Selected Papers from ECML PKDD 2008,Walter Daelemans (University of Antwerp);Bart Goethals (University of Antwerp);Katharina Morik (Technical University of Dortmund);,"2234963844,1992071743,2070565061",-,2008,Data Mining and Knowledge Discovery volume 17 issue 1 pp 1-2,telecommunications;
Fast mining of distance-based outliers in high-dimensional datasets,Amol Ghoting (IBM);Srinivasan Parthasarathy (Ohio State University);Matthew Eric Otey (Google);,"2102101334,2106796124,291982408","Defining outliers by their distance to neighboring data points has been shown to be an effective non-parametric approach to outlier detection. In recent years, many research efforts have looked at developing fast distance-based outlier detection algorithms. Several of the existing distance-based outlier detection algorithms report log-linear time performance as a function of the number of data points on many real low-dimensional datasets. However, these algorithms are unable to deliver the same level of performance on high-dimensional datasets, since their scaling behavior is exponential in the number of dimensions. In this paper, we present RBRP, a fast algorithm for mining distance-based outliers, particularly targeted at high-dimensional datasets. RBRP scales log-linearly as a function of the number of data points and linearly as a function of the number of dimensions. Our empirical evaluation demonstrates that we outperform the state-of-the-art algorithm, often by an order of magnitude.",2008,Data Mining and Knowledge Discovery volume 16 issue 3 pp 349-364,local outlier factor;time complexity;cluster analysis;k nearest neighbors algorithm;anomaly detection;data mining;machine learning;statistics;computer science;
A framework for condensation-based anonymization of string data,Charu C. Aggarwal (IBM);Philip S. Yu (University of Illinois at Chicago);,"2146335907,2125104194","In recent years, privacy preserving data mining has become an important problem because of the large amount of personal data which is tracked by many business applications. An important method for privacy preserving data mining is the method of condensation. This method is often used in the case of multi-dimensional data in which pseudo-data is generated to mask the true values of the records. However, these methods are not easily applicable to the case of string data, since they require the use of multi-dimensional statistics in order to generate the pseudo-data. String data are especially important in the privacy preserving data-mining domain because most DNA and biological data are coded as strings. In this article, we will discuss a new method for privacy preserving mining of string data with the use of simple template-based models. The template-based model turns out to be effective in practice, and preserves important statistical characteristics of the strings such as intra-record distances. We will explore the behavior in the context of a classification application, and show that the accuracy of the application is not affected significantly by the anonymization process.",2008,Data Mining and Knowledge Discovery volume 16 issue 3 pp 251-275,biological data;condensation;privacy;internet privacy;world wide web;data mining;computer science;
Bipartite isoperimetric graph partitioning for data co-clustering,Manjeet Rege (Wayne State University);Ming Dong (Wayne State University);Farshad Fotouhi (Wayne State University);,"2492937077,2618285502,2039005146","Data co-clustering refers to the problem of simultaneous clustering of two data types. Typically, the data is stored in a contingency or co-occurrence matrix C where rows and columns of the matrix represent the data types to be co-clustered. An entry C ij of the matrix signifies the relation between the data type represented by row i and column j. Co-clustering is the problem of deriving sub-matrices from the larger data matrix by simultaneously clustering rows and columns of the data matrix. In this paper, we present a novel graph theoretic approach to data co-clustering. The two data types are modeled as the two sets of vertices of a weighted bipartite graph. We then propose Isoperimetric Co-clustering Algorithm (ICA)--a new method for partitioning the bipartite graph. ICA requires a simple solution to a sparse system of linear equations instead of the eigenvalue or SVD problem in the popular spectral co-clustering approach. Our theoretical analysis and extensive experiments performed on publicly available datasets demonstrate the advantages of ICA over other approaches in terms of the quality, efficiency and stability in partitioning the bipartite graph.",2008,Data Mining and Knowledge Discovery volume 16 issue 3 pp 276-312,simplex graph;biregular graph;foster graph;quartic graph;degree matrix;voltage graph;graph bandwidth;graph power;graph energy;edge transitive graph;blossom algorithm;incidence matrix;line graph;adjacency matrix;assignment problem;bipartite graph;graph partition;matching;directed graph;linear system;eigenvalues and eigenvectors;discrete mathematics;combinatorics;machine learning;mathematical optimization;statistics;computer science;mathematics;
Using association rules to mine for strong approximate dependencies,Daniel Sánchez (University of Granada);José María Serrano (University of Jaén);Ignacio Blanco (University of Granada);Maria Jose Martín-Bautista (University of Granada);María-Amparo Vila (University of Granada);,"2115680954,2628813894,2615525103,1972725735,2430050239","In this paper we deal with the problem of mining for approximate dependencies (AD) in relational databases. We introduce a definition of AD based on the concept of association rule, by means of suitable definitions of the concepts of item and transaction. This definition allow us to measure both the accuracy and support of an AD. We provide an interpretation of the new measures based on the complexity of the theory (set of rules) that describes the dependence, and we employ this interpretation to compare the new measures with existing ones. A methodology to adapt existing association rule mining algorithms to the task of discovering ADs is introduced. The adapted algorithms obtain the set of ADs that hold in a relation with accuracy and support greater than user-defined thresholds. The experiments we have performed show that our approach performs reasonably well over large databases with real-world data.",2008,Data Mining and Knowledge Discovery volume 16 issue 3 pp 313-348,association rule learning;relational database;data mining;database;machine learning;computer science;
Mining functional dependencies from data,Hong Yao (University of Regina);Howard J. Hamilton (University of Regina);,"2236543811,2196958594","In this paper, we propose an efficient rule discovery algorithm, called FD_Mine, for mining functional dependencies from data. By exploiting Armstrong's Axioms for functional dependencies, we identify equivalences among attributes, which can be used to reduce both the size of the dataset and the number of functional dependencies to be checked. We first describe four effective pruning rules that reduce the size of the search space. In particular, the number of functional dependencies to be checked is reduced by skipping the search for FDs that are logically implied by already discovered FDs. Then, we present the FD_Mine algorithm, which incorporates the four pruning rules into the mining process. We prove the correctness of FD_Mine, that is, we show that the pruning does not lead to the loss of useful information. We report the results of a series of experiments. These experiments show that the proposed algorithm is effective on 15 UCI datasets and synthetic data.",2008,Data Mining and Knowledge Discovery volume 16 issue 2 pp 197-219,dependency theory;relational database;functional dependency;knowledge extraction;data mining;database;machine learning;computer science;
Collusion set detection using graph clustering,Girish Keshav Palshikar (Tata Research Development and Design Centre);Manoj M. Apte (Tata Consultancy Services);,"145015526,2097461020","Many mal-practices in stock market trading--e.g., circular trading and price manipulation--use the modus operandi of collusion. Informally, a set of traders is a candidate collusion set when they have ""heavy trading"" among themselves, as compared to their trading with others. We formalize the problem of detection of collusion sets, if any, in the given trading database. We show that naive approaches are inefficient for real-life situations. We adapt and apply two well-known graph clustering algorithms for this problem. We also propose a new graph clustering algorithm, specifically tailored for detecting collusion sets. A novel feature of our approach is the use of Dempster---Schafer theory of evidence to combine the candidate collusion sets detected by individual algorithms. Treating individual experiments as evidence, this approach allows us to quantify the confidence (or belief) in the candidate collusion sets. We present detailed simulation experiments to demonstrate effectiveness of the proposed algorithms.",2008,Data Mining and Knowledge Discovery volume 16 issue 2 pp 135-164,clustering coefficient;cluster analysis;computer security;data mining;machine learning;computer science;
A recursive search algorithm for statistical disclosure assessment,"Anna M. Manning (School of Computer Science, University of Manchester);David J. Haglin (Minnesota State University, Mankato);John A. Keane (School of Computer Science, University of Manchester);","2403904754,689768299,2136990782","A new algorithm, SUDA2, is presented which finds minimally unique itemsets i.e., minimal itemsets of frequency one. These itemsets, referred to as Minimal Sample Uniques (MSUs), are important for statistical agencies who wish to estimate the risk of disclosure of their datasets. SUDA2 is a recursive algorithm which uses new observations about the properties of MSUs to prune and traverse the search space. Experimental comparisons with previous work demonstrate that SUDA2 is several orders of magnitude faster, enabling datasets of significantly more columns to be addressed. The ability of SUDA2 to identify the boundaries of the search space for MSUs is clearly demonstrated.",2008,Data Mining and Knowledge Discovery volume 16 issue 2 pp 165-196,disclosure;microdata;association rule learning;recursion;search algorithm;privacy;theoretical computer science;data mining;database;machine learning;statistics;computer science;mathematics;
Effective elimination of redundant association rules,James Cheng (Hong Kong University of Science and Technology);Yiping Ke (Hong Kong University of Science and Technology);Wilfred Ng (Hong Kong University of Science and Technology);,"2304873892,2164055299,2170178419","It is well-recognized that the main factor that hinders the applications of Association Rules (ARs) is the huge number of ARs returned by the mining process. In this paper, we propose an effective solution that presents concise mining results by eliminating the redundancy in the set of ARs. We adopt the concept of ? tolerance to define the set of ?-Tolerance ARs (?-TARs), which is a concise representation for the set of ARs. The notion of ?-tolerance is a relaxation on the closure defined on the support of frequent itemsets, thus allowing us to effectively prune the redundant ARs. We devise a set of inference rules, with which we prove that the set of ?-TARs is a non-redundant representation of ARs. In addition, we prove that the set of ARs that is derived from the ?-TARs by the inference rules is sound and complete. We also develop a compact tree structure called the ?-TAR tree, which facilitates the efficient generation of the ?-TARs and derivation of other ARs. Experimental results verify the efficiency of using the ?-TAR tree to generate the ?-TARs and to query the ARs. The set of ?-TARs is shown to be significantly smaller than the state-of-the-art concise representations of ARs. In addition, the approximation on the support and confidence of the ARs derived from the ?-TARs are highly accurate.",2008,Data Mining and Knowledge Discovery volume 16 issue 2 pp 221-249,association rule learning;data mining;artificial intelligence;machine learning;algorithm;computer science;mathematics;
Web usage mining: extracting unexpected periods from web logs,Florent Masseglia (French Institute for Research in Computer Science and Automation);Pascal Poncelet (European Medicines Agency);Maguelonne Teisseire (Centre national de la recherche scientifique);Alice Marascu (French Institute for Research in Computer Science and Automation);,"2440503352,733374064,2141863019,1948455341","Existing Web usage mining techniques are currently based on an arbitrary division of the data (e.g. ""one log per month"") or guided by presumed results (e.g. ""what is the customers' behaviour for the period of Christmas purchases?""). These approaches have two main drawbacks. First, they depend on the above-mentioned arbitrary organization of data. Second, they cannot automatically extract ""seasonal peaks"" from among the stored data. In this paper, we propose a specific data mining process (in particular, to extract frequent behaviour patterns) in order to reveal the densest periods automatically. From the whole set of possible combinations, our method extracts the frequent sequential patterns related to the extracted periods. A period is considered to be dense if it contains at least one frequent sequential pattern for the set of users connected to the website in that period. Our experiments show that the extracted periods are relevant and our approach is able to extract both frequent sequential patterns and the associated dense periods.",2008,Data Mining and Knowledge Discovery volume 16 issue 1 pp 39-65,seasonality;web mining;world wide web;data mining;real time computing;computer science;
Correlating burst events on streaming stock market data,Michail Vlachos (IBM);Kun Lung Wu (IBM);Shyh Kwei Chen (IBM);Philip S. Yu (IBM);,"2146138755,2095612124,2150933152,2125104194","We address the problem of monitoring and identification of correlated burst patterns in multi-stream time series databases. We follow a two-step methodology: first we identify the burst sections in our data and subsequently we store them for easy retrieval in an efficient in-memory index. The burst detection scheme imposes a variable threshold on the examined data and takes advantage of the skewed distribution that is typically encountered in many applications. The detected bursts are compacted into burst intervals and stored in an interval index. The index facilitates the identification of correlated bursts by performing very efficient overlap operations on the stored burst regions. We present the merits of the proposed indexing scheme through a thorough analysis of its complexity. We also manifest the real-time response of our burst indexing technique, and demonstrate the usefulness of the approach for correlating surprising volume trading events using historical stock data of the NY stock exchange. While the focus of this work is on financial data, the proposed methods and data-structures can find applications for anomaly or novelty detection in telecommunication, network traffic and medical data.",2008,Data Mining and Knowledge Discovery volume 16 issue 1 pp 109-133,stock exchange;skewness;search engine indexing;correlation;time series;data structure;computer security;data mining;real time computing;statistics;computer science;
Mining spatio-temporal patterns in object mobility databases,Florian Verhein (University of Sydney);Sanjay Chawla (University of Sydney);,"346847637,2201421368","With the increasing use of wireless communication devices and the ability to track people and objects cheaply and easily, the amount of spatio-temporal data is growing substantially. Many of these applications cannot easily locate the exact position of objects, but they can determine the region in which each object is contained. Furthermore, the regions are fixed and may vary greatly in size. Examples include mobile/cell phone networks, RFID tag readers and satellite tracking. This demands techniques to mine such data. These techniques must also correct for the bias produced by different sized regions. We provide a comprehensive definition of Spatio-Temporal Association Rules (STARs) that describe how objects move between regions over time. We also present other patterns that are useful for mobility data; stationary regions and high traffic regions. The latter consists of sources, sinks and thoroughfares. These patterns describe important temporal characteristics of regions and we show that they can be considered as special STARs. We define spatial support to effectively deal with the problem of different sized regions. We provide an efficient algorithm--STAR-Miner--to find these patterns by exploiting several pruning properties.",2008,Data Mining and Knowledge Discovery volume 16 issue 1 pp 5-38,mobile database;radio frequency identification;association rule learning;wireless;world wide web;computer security;data mining;computer science;
A dynamic bibliometric model for identifying online communities,Xin Wang (University of Birmingham);Ata Kabán (University of Birmingham);,"2422598324,2082255270","Predictive modelling of online dynamic user-interaction recordings and community identification from such data becomes more and more important with the widespread use of online communication technologies. Despite of the time-dependent nature of the problem, existing approaches of community identification are based on static or fully observed network connections. Here we present a new, dynamic generative model for the inference of communities from a sequence of temporal events produced through online computer- mediated interactions. The distinctive feature of our approach is that it tries to model the process in a more realistic manner, including an account for possible random temporal delays between the intended connections. The inference of these delays from the data then forms an integral part of our state-clustering methodology, so that the most likely communities are found on the basis of the likely intended connections rather than just the observed ones. We derive a maximum likelihood estimation algorithm for the identification of our model, which turns out to be computationally efficient for the analysis of historical data and it scales linearly with the number of non-zero observed (L + 1)-grams, where L is the Markov memory length. In addition, we also derive an incremental version of the algorithm, which could be used for real-time analysis. Results obtained on both synthetic and real-world data sets demonstrate the approach is flexible and able to reveal novel and insightful structural aspects of online interactions. In particular, the analysis of a full day worth synchronous Internet relay chat participation sequence, reveals the formation of an extremely clear community structure.",2008,Data Mining and Knowledge Discovery volume 16 issue 1 pp 67-107,latent variable model;community structure;markov chain;predictive modelling;cluster analysis;maximum likelihood;data mining;machine learning;simulation;statistics;computer science;
"Guest editorial: special issue on temporal data mining: theory, algorithms and applications",Tao Li (Florida International University);Chang-Shing Perng (IBM);Sheng Ma (IBM);,"2472069284,2127489856,2116699166","This special issue provides a leading forum for timely, in-depth presentation of recent advances in algorithms, theories and applications in temporal data mining. The selected papers underwent a rigorous refereeing and revision process.",2008,Data Mining and Knowledge Discovery volume 16 issue 1 pp 1-3,video denoising;data science;data mining;computer science;
CrossClus: user-guided multi-relational clustering,Xiaoxin Yin (University of Illinois at Urbana–Champaign);Jiawei Han (University of Illinois at Urbana–Champaign);Philip S. Yu (IBM);,"2304105079,2121939561,2125104194","Most structured data in real-life applications are stored in relational databases containing multiple semantically linked relations. Unlike clustering in a single table, when clustering objects in relational databases there are usually a large number of features conveying very different semantic information, and using all features indiscriminately is unlikely to generate meaningful results. Because the user knows her goal of clustering, we propose a new approach called CrossClus, which performs multi-relational clustering under user's guidance. Unlike semi-supervised clustering which requires the user to provide a training set, we minimize the user's effort by using a very simple form of user guidance. The user is only required to select one or a small set of features that are pertinent to the clustering goal, and CrossClus searches for other pertinent features in multiple relations. Each feature is evaluated by whether it clusters objects in a similar way with the user specified features. We design efficient and accurate approaches for both feature selection and object clustering. Our comprehensive experiments demonstrate the effectiveness and scalability of CrossClus.",2007,Data Mining and Knowledge Discovery volume 15 issue 3 pp 321-348,elasticity;flame clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;fuzzy clustering;clustering high dimensional data;relational database;data model;cluster analysis;consensus clustering;biclustering;conceptual clustering;feature selection;data mining;database;machine learning;computer science;
Tree-Traversing Ant Algorithm for term clustering based on featureless similarities,Wilson Wong (University of Western Australia);Wei Liu (University of Western Australia);Mohammed Bennamoun (University of Western Australia);,"2137126894,2527394672,431907532","Many conventional methods for concepts formation in ontology learning have relied on the use of predefined templates and rules, and static resources such as WordNet. Such approaches are not scalable, difficult to port between different domains and incapable of handling knowledge fluctuations. Their results are far from desirable, either. In this paper, we propose a new ant-based clustering algorithm, Tree-Traversing Ant (TTA), for concepts formation as part of an ontology learning system. With the help of Normalized Google Distance (NGD) and n° of Wikipedia (n°W) as measures for similarity and distance between terms, we attempt to achieve an adaptable clustering method that is highly scalable and portable across domains. Evaluations with an seven datasets show promising results with an average lexical overlap of 97% and ontological improvement of 48%. At the same time, the evaluations demonstrated several advantages that are not simultaneously present in standard ant-based and other conventional clustering methods.",2007,Data Mining and Knowledge Discovery volume 15 issue 3 pp 349-381,canopy clustering algorithm;correlation clustering;constrained clustering;single linkage clustering;fuzzy clustering;cluster analysis;text mining;data mining;artificial intelligence;machine learning;computer science;
Mining for trigger events with survival analysis,Edward C. Malthouse (Northwestern University);,2106689951,"This paper discusses a new application of data mining, quantifying the importance of responding to trigger events with reactive contacts. Trigger events happen during a customer's lifecycle and indicate some change in the relationship with the company. If detected early, the company can respond to the problem and retain the customer; otherwise the customer may switch to another company. It is usually easy to identify many potential trigger events. What is needed is a way of prioritizing which events demand interventions. We conceptualize the trigger event problem and show how survival analysis can be used to quantify the importance of addressing various trigger events. The method is illustrated on four real data sets from different industries and countries.",2007,Data Mining and Knowledge Discovery volume 15 issue 3 pp 383-402,customer lifetime value;market timing;survival analysis;personalized marketing;customer relationship management;data mining;
Classification of multi class dataset using wavelet power spectrum,"S. Prabakaran (Indian Institute of Information Technology and Management, Gwalior);Rajendra Sahu (Indian Institute of Information Technology and Management, Gwalior);Sekher Verma (Indian Institute of Information Technology and Management, Gwalior);","2235814220,2134646715,2171205509","Data mining techniques are widely used in many fields. One of the applications of data mining in the field of the Bioinformatics is classification of tissue samples. In the present work, a wavelet power spectrum based approach has been presented for feature selection and successful classification of the multi class dataset. The proposed method was applied on SRBCT and the breast cancer datasets which are multi class cancer datasets. The selected features are almost those selected in previous works. The method was able to produce almost 100% accurate classification results. The method is very simple and robust to noise. No extensive preprocessing is required. The classification was performed with comparatively very lesser number of features than those used in the original works. No information is lost due to the initial pruning of the data usually performed using a threshold in other methods. The method utilizes the inherent nature of the data in performing various tasks. So, the method can be used for a wide range of data.",2007,Data Mining and Knowledge Discovery volume 15 issue 3 pp 297-319,breast cancer;spectral density;feature selection;data science;data mining;machine learning;statistics;computer science;
Experiencing SAX: a novel symbolic representation of time series,"Jessica Lin 0001 (George Mason University);Eamonn J. Keogh (University of California, Riverside);Li Wei (University of California, Riverside);Stefano Lonardi (University of California, Riverside);","2100950507,2170070822,2325104268,301234865","Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 107-144,symbolic data analysis;discretization;time series;fourier transform;data structure;data mining;machine learning;statistics;algorithm;computer science;mathematics;
Mining process models with non-free-choice constructs,Lijie Wen (Tsinghua University);Wil M. P. van der Aalst (Eindhoven University of Technology);Jianmin Wang (Tsinghua University);Jiaguang Sun (Tsinghua University);,"2128324904,270949118,2707996989,2166023713","Process mining aims at extracting information from event logs to capture the business process as it is being executed. Process mining is particularly useful in situations where events are recorded but there is no system enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treatment activities are recorded in the hospital information system, but where health-care professionals determine the ""careflow."" Many process mining approaches have been proposed in recent years. However, in spite of many researchers' persistent efforts, there are still several challenging problems to be solved. In this paper, we focus on mining non-free-choice constructs, i.e., situations where there is a mixture of choice and synchronization. Although most real-life processes exhibit non-free-choice behavior, existing algorithms are unable to adequately deal with such constructs. Using a Petri-net-based representation, we will show that there are two kinds of causal dependencies between tasks, i.e., explicit and implicit ones. We propose an algorithm that is able to deal with both kinds of dependencies. The algorithm has been implemented in the ProM framework and experimental results shows that the algorithm indeed significantly improves existing process mining techniques.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 145-180,process mining;business process discovery;process modeling;data mining;artificial intelligence;machine learning;simulation;computer science;
Data mining with Temporal Abstractions: learning rules from time series,Lucia Sacchi (University of Pavia);Cristiana Larizza (University of Pavia);Carlo Combi (University of Verona);Riccardo Bellazzi (University of Pavia);,"1932616307,155890598,1975160284,2047440685","A large volume of research in temporal data mining is focusing on discovering temporal rules from time-stamped data. The majority of the methods proposed so far have been mainly devoted to the mining of temporal rules which describe relationships between data sequences or instantaneous events and do not consider the presence of complex temporal patterns into the dataset. Such complex patterns, such as trends or up and down behaviors, are often very interesting for the users. In this paper we propose a new kind of temporal association rule and the related extraction algorithm; the learned rules involve complex temporal patterns in both their antecedent and consequent. Within our proposed approach, the user defines a set of complex patterns of interest that constitute the basis for the construction of the temporal rule; such complex patterns are represented and retrieved in the data through the formalism of knowledge-based Temporal Abstractions. An Apriori-like algorithm looks then for meaningful temporal relationships (in particular, precedence temporal relationships) among the complex patterns of interest. The paper presents the results obtained by the rule extraction algorithm on a simulated dataset and on two different datasets related to biomedical applications: the first one concerns the analysis of time series coming from the monitoring of different clinical variables during hemodialysis sessions, while the other one deals with the biological problem of inferring relationships between genes from DNA microarray data.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 217-247,association rule learning;time series;knowledge base;data science;data mining;machine learning;computer science;
Efficient mining of understandable patterns from multivariate interval time series,Fabian Mörchen (Siemens);Alfred Ultsch (University of Marburg);,"1886239512,1959477005","We present a new method for the understandable description of local temporal relationships in multivariate data, called Time Series Knowledge Mining (TSKM). We define the Time Series Knowledge Representation (TSKR) as a new language for expressing temporal knowledge in time interval data. The patterns have a hierarchical structure, with levels corresponding to the temporal concepts duration, coincidence, and partial order. The patterns are very compact, but offer details for each element on demand. In comparison with related approaches, the TSKR is shown to have advantages in robustness, expressivity, and comprehensibility. The search for coincidence and partial order in interval data can be formulated as instances of the well known frequent itemset problem. Efficient algorithms for the discovery of the patterns are adapted accordingly. A novel form of search space pruning effectively reduces the size of the mining result to ease interpretation and speed up the algorithms. Human interaction is used during the mining to analyze and validate partial results as early as possible and guide further processing steps. The efficacy of the methods is demonstrated using two real life data sets. In an application to sports medicine the results were recognized as valid and useful by an expert of the field.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 181-215,multivariate statistics;partially ordered set;interpersonal relationship;time series;sports medicine;
Relational peculiarity-oriented mining,Muneaki Ohshima (Maebashi Institute of Technology);Ning Zhong (Maebashi Institute of Technology);Yiyu Yao (University of Regina);Chunnian Liu (Science College);,"2040129545,2157949701,2134033583,2255600810","Peculiarity rules are a new type of useful knowledge that can be discovered by searching the relevance among peculiar data. A main task in mining such knowledge is peculiarity identification. Previous methods for finding peculiar data focus on attribute values. By extending to record-level peculiarity, this paper investigates relational peculiarity-oriented mining. Peculiarity rules are mined, and more importantly explained, in a relational mining framework. Several experiments are carried out and the results show that relational peculiarity-oriented mining is effective.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 249-273,data science;data mining;database;
Detecting inconsistency in biological molecular databases using ontologies,"Qingfeng Chen (Deakin University);Yi Ping Phoebe Chen (Deakin University);Chengqi Zhang (Faculty of Information Technology, University Džemal Bijedić of Mostar);","2115956499,2578211231,2166080598","The rapid growth of life science databases demands the fusion of knowledge from heterogeneous databases to answer complex biological questions. The discrepancies in nomenclature, various schemas and incompatible formats of biological databases, however, result in a significant lack of interoperability among databases. Therefore, data preparation is a key prerequisite for biological database mining. Integrating diverse biological molecular databases is an essential action to cope with the heterogeneity of biological databases and guarantee efficient data mining. However, the inconsistency in biological databases is a key issue for data integration. This paper proposes a framework to detect the inconsistency in biological databases using ontologies. A numeric estimate is provided to measure the inconsistency and identify those biological databases that are appropriate for further mining applications. This aids in enhancing the quality of databases and guaranteeing accurate and efficient mining of biological databases.",2007,Data Mining and Knowledge Discovery volume 15 issue 2 pp 275-296,probabilistic database;biological database;database theory;data integrity;measure;
Frequent pattern mining: current status and future directions,Jiawei Han (University of Illinois at Urbana–Champaign);Hong Cheng (University of Illinois at Urbana–Champaign);Dong Xin (University of Illinois at Urbana–Champaign);Xifeng Yan (University of Illinois at Urbana–Champaign);,"2121939561,2161754280,1991372327,2116657824","Frequent pattern mining has been a focused theme in data mining research for over a decade. Abundant literature has been dedicated to this research and tremendous progress has been made, ranging from efficient and scalable algorithms for frequent itemset mining in transaction databases to numerous research frontiers, such as sequential pattern mining, structured pattern mining, correlation mining, associative classification, and frequent pattern-based clustering, as well as their broad applications. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions. We believe that frequent pattern mining research has substantially broadened the scope of data analysis and will have deep impact on data mining methodologies and applications in the long run. However, there are still some challenging research issues that need to be solved before frequent pattern mining can claim a cornerstone approach in data mining applications.",2007,Data Mining and Knowledge Discovery volume 15 issue 1 pp 55-86,k optimal pattern discovery;association rule learning;information technology;data science;bioinformatics;
Future trends in data mining,Hans-Peter Kriegel (Ludwig Maximilian University of Munich);Karsten M. Borgwardt (Max Planck Society);Peer Kröger (Ludwig Maximilian University of Munich);Alexey Pryakhin (Ludwig Maximilian University of Munich);Matthias Schubert (Ludwig Maximilian University of Munich);,"1919135125,2086114595,2100673337,1967213060,2139846034,242745652","Over recent years data mining has been establishing itself as one of the major disciplines in computer science with growing industrial impact. Undoubtedly, research in data mining will continue and even increase over coming decades. In this article, we sketch our vision of the future of data mining. Starting from the classic definition of ""data mining"", we elaborate on topics that -- in our opinion -- will set trends in data mining.",2007,Data Mining and Knowledge Discovery volume 15 issue 1 pp 87-97,knowledge extraction;data science;operations research;data mining;computer science;
Toward knowledge-rich data mining,Pedro M. Domingos (University of Washington);,2169012919,"This position paper proposes knowledge-rich data mining as a focus of research, and describes initial steps in pursuing it.",2007,Data Mining and Knowledge Discovery volume 15 issue 1 pp 21-28,markov model;first order logic;data science;data mining;machine learning;
Data mining and knowledge discovery 1996 to 2005: overcoming the hype and moving from university to business and analytics,Gregory Piatetsky-Shapiro;,234870102,I survey the transformation of the data mining and knowledge discovery field over the last 10 years from the unique vantage point of KDnuggets as a leading chronicler of the field. Analysis of the most frequent words in KDnuggets News leads to revealing observations.,2007,Data Mining and Knowledge Discovery volume 15 issue 1 pp 99-105,analytics;business analytics;knowledge extraction;business intelligence;data science;
"On data mining, compression, and Kolmogorov complexity",Christos Faloutsos (Carnegie Mellon University);Vasileios Megalooikonomou (Temple University);,"2198983026,2173849879","Will we ever have a theory of data mining analogous to the relational algebra in databases? Why do we have so many clearly different clustering algorithms? Could data mining be automated? We show that the answer to all these questions is negative, because data mining is closely related to compression and Kolmogorov complexity; and the latter is undecidable. Therefore, data mining will always be an art, where our goal will be to find better models (patterns) that fit our datasets as best as possible.",2007,Data Mining and Knowledge Discovery volume 15 issue 1 pp 3-20,outlier;compression;forecasting;cluster analysis;biological classification;
