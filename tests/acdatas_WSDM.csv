TwitterRank: finding topic-sensitive influential twitterers,Jianshu Weng (Singapore Management University)Ee-Peng Lim (Singapore Management University)Jing Jiang (Singapore Management University)Qi He (Pennsylvania State University),"2650380780,2136050841,2286546702,2309017108","This paper focuses on the problem of identifying influential users of micro-blogging services. Twitter, one of the most notable micro-blogging services, employs a social-networking model called ""following"", in which each user can choose who she wants to ""follow"" to receive tweets from without requiring the latter to give permission first. In a dataset prepared for this study, it is observed that (1) 72.4% of the users in Twitter follow more than 80% of their followers, and (2) 80.5% of the users have 80% of users they are following follow them back. Our study reveals that the presence of ""reciprocity"" can be explained by phenomenon of homophily. Based on this finding, TwitterRank, an extension of PageRank algorithm, is proposed to measure the influence of users in Twitter. TwitterRank measures the influence taking both the topical similarity between users and the link structure into account. Experimental results show that TwitterRank outperforms the one Twitter currently uses and other related algorithms, including the original PageRank and Topic-sensitive PageRank.",2010,Web Search and Data Mining,Fields of study: microbloggingreciprocitysocial networkinternet privacyworld wide web +2 others
Everyone's an influencer: quantifying influence on twitter,Eytan Bakshy (University of Michigan)Jake M. Hofman (Yahoo!)Winter A. Mason (Yahoo!)Duncan J. Watts (Yahoo!),"233957955,2311169505,2101475749,2138805444","In this paper we investigate the attributes and relative influence of 1.6M Twitter users by tracking 74 million diffusion events that took place on the Twitter follower graph over a two month interval in 2009. Unsurprisingly, we find that the largest cascades tend to be generated by users who have been influential in the past and who have a large number of followers. We also find that URLs that were rated more interesting and/or elicited more positive feelings by workers on Mechanical Turk were more likely to spread. In spite of these intuitive results, however, we find that predictions of which particular user or URL will generate large cascades are relatively unreliable. We conclude, therefore, that word-of-mouth diffusion can only be harnessed reliably by targeting large numbers of potential influencers, thereby capturing average effects. Finally, we consider a family of hypothetical marketing strategies, defined by the relative cost of identifying versus compensating potential ""influencers."" We find that although under some circumstances, the most influential users are also the most cost-effective, under a wide range of plausible assumptions the most cost-effective performance can be realized using ""ordinary influencers""---individuals who exert average or even less-than-average influence.",2011,Web Search and Data Mining,Fields of study: marketing strategyword of mouthcost effectiveness analysisdiffusionworld wide web +1 other
Finding high-quality content in social media,Eugene Agichtein (Emory University)Carlos Castillo (Yahoo!)Debora Donato (Yahoo!)Aristides Gionis (Yahoo!)Gilad Mishne (Yahoo!),"2283615530,2125169605,2168688135,737311942,2698345362","The quality of user-generated content varies drastically from excellent to abuse and spam. As the availability of such content increases, the task of identifying high-quality content sites based on user contributions --social media sites -- becomes increasingly important. Social media in general exhibit a rich variety of information sources: in addition to the content itself, there is a wide array of non-content information available, such as links between items and explicit quality ratings from members of the community. In this paper we investigate methods for exploiting such community feedback to automatically identify high quality content. As a test case, we focus on Yahoo! Answers, a large community question/answering portal that is particularly rich in the amount and types of content and social interactions available in it. We introduce a general classification framework for combining the evidence from different sources of information, that can be tuned automatically for a given social media type and quality definition. In particular, for the community question/answering domain, we show that our system is able to separate high-quality items from the rest with an accuracy close to that of humans",2008,Web Search and Data Mining,Fields of study: social mediauser generated contentmediaquestion answeringmultimedia +3 others
Diversifying search results,Rakesh Agrawal (Microsoft)Sreenivas Gollapudi (Microsoft)Alan Halverson (Microsoft)Samuel Ieong (Microsoft),"2537924216,2023254819,2040370899,2267310192","We study the problem of answering ambiguous web queries in a setting where there exists a taxonomy of information, and that both queries and documents may belong to more than one category according to this taxonomy. We present a systematic approach to diversifying results that aims to minimize the risk of dissatisfaction of the average user. We propose an algorithm that well approximates this objective in general, and is provably optimal for a natural special case. Furthermore, we generalize several classical IR metrics, including NDCG, MRR, and MAP, to explicitly account for the value of diversification. We demonstrate empirically that our algorithm scores higher in these generalized metrics compared to results produced by commercial search engines.",2009,Web Search and Data Mining,Fields of study: marginal utilityrelevancesearch engineworld wide webinformation retrieval +2 others
Patterns of temporal variation in online media,Jaewon Yang (Stanford University)Jure Leskovec (Stanford University),"2131921352,1878631932","Online content exhibits rich temporal dynamics, and diverse realtime user generated content further intensifies this process. However, temporal patterns by which online content grows and fades over time, and by which different pieces of content compete for attention remain largely unexplored. We study temporal patterns associated with online content and how the content's popularity grows and fades over time. The attention that content receives on the Web varies depending on many factors and occurs on very different time scales and at different resolutions. In order to uncover the temporal dynamics of online content we formulate a time series clustering problem using a similarity metric that is invariant to scaling and shifting. We develop the K-Spectral Centroid ( K-SC ) clustering algorithm that effectively finds cluster centroids with our similarity measure. By applying an adaptive wavelet-based incremental approach to clustering, we scale K-SC to large data sets. We demonstrate our approach on two massive datasets: a set of 580 million Tweets, and a set of 170 million blog posts and news media articles. We find that K-SC outperforms the K-means clustering algorithm in finding distinct shapes of time series. Our analysis shows that there are six main temporal shapes of attention of online content. We also present a simple model that reliably predicts the shape of attention by using information about only a small number of participants. Our analyses offer insight into common temporal patterns of the content on theWeb and broaden the understanding of the dynamics of human attention.",2011,Web Search and Data Mining,Fields of study: social mediauser generated contentnew mediak means clusteringtime series +4 others
A holistic lexicon-based approach to opinion mining,Xiaowen Ding (University of Illinois at Chicago)Bing Liu (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2691465777,2244698799,2125104194","One of the important types of information on the Web is the opinions expressed in the user generated content, e.g., customer reviews of products, forum posts, and blogs. In this paper, we focus on customer reviews of products. In particular, we study the problem of determining the semantic orientations (positive, negative or neutral) of opinions expressed on product features in reviews. This problem has many applications, e.g., opinion mining, summarization and search. Most existing techniques utilize a list of opinion (bearing) words (also called opinion lexicon) for the purpose. Opinion words are words that express desirable (e.g., great, amazing, etc.) or undesirable (e.g., bad, poor, etc) states. These approaches, however, all have some major shortcomings. In this paper, we propose a holistic lexicon-based approach to solving the problem by exploiting external evidences and linguistic conventions of natural language expressions. This approach allows the system to handle opinion words that are context dependent, which cause major difficulties for existing algorithms. It also deals with many special words, phrases and language constructs which have impacts on opinions based on their linguistic patterns. It also has an effective function for aggregating multiple conflicting opinion words in a sentence. A system, called Opinion Observer, based on the proposed technique has been implemented. Experimental results using a benchmark product review data set and some additional reviews show that the proposed technique is highly effective. It outperforms existing methods significantly",2008,Web Search and Data Mining,Fields of study: user generated contentcontext dependent memorynatural languagesentiment analysisnatural language processing +5 others
Learning influence probabilities in social networks,Amit Goyal (University of British Columbia)Francesco Bonchi (Yahoo!)Laks V.S. Lakshmanan (University of British Columbia),"2675938765,2176652147,2659892814","Recently, there has been tremendous interest in the phenomenon of influence propagation in social networks. The studies in this area assume they have as input to their problems a social graph with edges labeled with probabilities of influence between users. However, the question of where these probabilities come from or how they can be computed from real social network data has been largely ignored until now. Thus it is interesting to ask whether from a social graph and a log of actions by its users, one can build models of influence. This is the main problem attacked in this paper. In addition to proposing models and algorithms for learning the model parameters and for testing the learned models to make predictions, we also develop techniques for predicting the time by which a user may be expected to perform an action. We validate our ideas and techniques using the Flickr data set consisting of a social graph with 1.3M nodes, 40M edges, and an action log consisting of 35M tuples referring to 300K distinct actions. Beyond showing that there is genuine influence happening in a real social network, we show that our techniques have excellent prediction performance.",2010,Web Search and Data Mining,Fields of study: social networkworld wide websocial sciencedata miningartificial intelligence +3 others
Opinion spam and analysis,Nitin Jindal (University of Illinois at Chicago)Bing Liu (University of Illinois at Chicago),"2104817295,2244698799","Evaluative texts on the Web have become a valuable source of opinions on products, services, events, individuals, etc. Recently, many researchers have studied such opinion sources as product reviews, forum posts, and blogs. However, existing research has been focused on classification and summarization of opinions using natural language processing and data mining techniques. An important issue that has been neglected so far is opinion spam or trustworthiness of online opinions. In this paper, we study this issue in the context of product reviews, which are opinion rich and are widely used by consumers and product manufacturers. In the past two years, several startup companies also appeared which aggregate opinions from product reviews. It is thus high time to study spam in reviews. To the best of our knowledge, there is still no published study on this topic, although Web spam and email spam have been investigated extensively. We will see that opinion spam is quite different from Web spam and email spam, and thus requires different detection techniques. Based on the analysis of 5.8 million reviews and 2.14 million reviewers from amazon.com, we show that opinion spam in reviews is widespread. This paper analyzes such spam activities and presents some novel techniques to detect them",2008,Web Search and Data Mining,Fields of study: forum spamspambotsocial spamspammingspamdexing +5 others
Recommender systems with social regularization,Hao Ma (The Chinese University of Hong Kong)Dengyong Zhou (Microsoft)Chao Liu (Microsoft)Michael R. Lyu (The Chinese University of Hong Kong)Irwin King (AT&T Labs),"2656995071,2119648418,2095896511,2227744130,2121363826","Although Recommender Systems have been comprehensively analyzed in the past decade, the study of social-based recommender systems just started. In this paper, aiming at providing a general method for improving recommender systems by incorporating social network information, we propose a matrix factorization framework with social regularization. The contributions of this paper are four-fold: (1) We elaborate how social network information can benefit recommender systems; (2) We interpret the differences between social-based recommender systems and trust-aware recommender systems; (3) We coin the term Social Regularization to represent the social constraints on recommender systems, and we systematically illustrate how to design a matrix factorization objective function with social regularization; and (4) The proposed method is quite general, which can be easily extended to incorporate other contextual information, like social tags, etc. The empirical analysis on two large datasets demonstrates that our approaches outperform other state-of-the-art methods.",2011,Web Search and Data Mining,Fields of study: collaborative filteringmatrix decompositionsocial networkrecommender systeminformation retrievaldata miningmachine learningcomputer science
You are who you know: inferring user profiles in online social networks,Alan Mislove (Northeastern University)Bimal Viswanath (Max Planck Society)Krishna P. Gummadi (Max Planck Society)Peter Druschel (Max Planck Society),"2015972736,2151819869,1982116827,62967857","Online social networks are now a popular way for users to connect, express themselves, and share content. Users in today's online social networks often post a profile, consisting of attributes like geographic location, interests, and schools attended. Such profile information is used on the sites as a basis for grouping users, for sharing content, and for suggesting users who may benefit from interaction. However, in practice, not all users provide these attributes. In this paper, we ask the question: given attributes for some fraction of the users in an online social network, can we infer the attributes of the remaining users? In other words, can the attributes of users, in combination with the social network graph, be used to predict the attributes of another user in the network? To answer this question, we gather fine-grained data from two social networks and try to infer user profile attributes. We find that users with common attributes are more likely to be friends and often form dense communities, and we propose a method of inferring user attributes that is inspired by previous approaches to detecting communities in social networks. Our results show that certain user attributes can be inferred with high accuracy when given information on as little as 20% of the users.",2010,Web Search and Data Mining,Fields of study: social networkinternet privacyworld wide websocial sciencedata mining
Can social bookmarking improve web search,Paul Heymann (Stanford University)Georgia Koutrika (Stanford University)Hector Garcia-Molina (Stanford University),"2038619550,2246237345,237419955","Social bookmarking is a recent phenomenon which has the potential to give us a great deal of data about pages on the web. One major question is whether that data can be used to augment systems like web search. To answer this question, over the past year we have gathered what we believe to be the largest dataset from a social bookmarking site yet analyzed by academic researchers. Our dataset represents about forty million bookmarks from the social bookmarking site del.icio.us. We contribute a characterization of posts to del.icio. us: how many bookmarks exist (about 115 million), how fast is it growing, and how active are the URLs being posted about (quite active). We also contribute a characterization of tags used by bookmarkers. We found that certain tags tend to gravitate towards certain domains, and vice versa. We also found that tags occur in over 50 percent of the pages that they annotate, and in only 20 percent of cases do they not occur in the page text, backlink page text, or forward link page text of the pages they annotate. We conclude that social bookmarking can provide search data not currently provided by other sources, though it may currently lack the size and distribution of tags necessary to make a significant impact",2008,Web Search and Data Mining,Fields of study: social media optimizationdigital libraryworld wide webinformation retrievaldata miningcomputer science
Supervised random walks: predicting and recommending links in social networks,Lars Backstrom (Facebook)Jure Leskovec (Stanford University),"2096207090,1878631932","Predicting the occurrence of links is a fundamental problem in networks. In the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. Although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open. We develop an algorithm based on Supervised Random Walks that naturally combines the information from the network structure with node and edge level attributes. We achieve this by using these attributes to guide a random walk on the graph. We formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. We develop an efficient training algorithm to directly learn the edge strength estimation function. Our experiments on the Facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.",2011,Web Search and Data Mining,Fields of study: evolving networksdynamic network analysisnetwork sciencesocial networksupervised learningdata structureworld wide websocial sciencedata miningpattern recognitionmachine learningcomputer science
An experimental comparison of click position-bias models,Nick Craswell (Microsoft)Onno Zoeter (Microsoft)Michael J. Taylor (Microsoft)Bill Ramsey (Microsoft),"2009495402,2003940724,2145462364,2149133096","Search engine click logs provide an invaluable source of relevance information, but this information is biased. A key source of bias is presentation order: the probability of click is influenced by a document's position in the results page. This paper focuses on explaining that bias, modelling how probability of click depends on position. We propose four simple hypotheses about how position bias might arise. We carry out a large data-gathering effort, where we perturb the ranking of a major search engine, to see how clicks are affected. We then explore which of the four hypotheses best explains the real-world position effects, and compare these to a simple logistic regression model. The data are not well explained by simple position models, where some users click indiscriminately on rank 1 or there is a simple decay of attention over ranks. A â cascade' model, where users view results from top to bottom and leave as soon as they see a worthwhile document, is our best explanation for position bias in early ranks",2008,Web Search and Data Mining,Fields of study: click pathsearch enginelogistic regressionworld wide webdata miningmachine learningstatisticscomputer science
#TwitterSearch: a comparison of microblog search and web search,Jaime Teevan (Microsoft)Daniel Ramage (Stanford University)Merredith Ringel Morris (Microsoft),"1982462162,2087112254,2232196576","Social networking Web sites are not just places to maintain relationships; they can also be valuable information sources. However, little is known about how and why people search socially-generated content. In this paper we explore search behavior on the popular microblogging/social networking site Twitter. Using analysis of large-scale query logs and supplemental qualitative data, we observe that people search Twitter to find temporally relevant information (e.g., breaking news, real-time content, and popular trends) and information related to people (e.g., content directed at the searcher, information about people of interest, and general sentiment and opinion). Twitter queries are shorter, more popular, and less likely to evolve as part of a session than Web queries. It appears people repeat Twitter queries to monitor the associated search results, while changing and developing Web queries to learn about a topic. The results returned from the different corpora support these different uses, with Twitter results including more social chatter and social events, and Web results containing more basic facts and navigational content. We discuss the implications of these findings for the design of next-generation Web search tools that incorporate social media.",2011,Web Search and Data Mining,Fields of study: social semantic webonline presence managementsocial webweb query classificationsocial media optimizationmicrobloggingsocial mediaqualitative propertysocial networksemantic searchinternet privacymultimediaworld wide webinformation retrievaldata miningcomputer science
Boilerplate detection using shallow text features,Christian Kohlschütter (Leibniz University of Hanover)Peter Fankhauser (Leibniz University of Hanover)Wolfgang Nejdl (Leibniz University of Hanover),"75181450,149446523,2228144965","In addition to the actual content Web pages consist of navigational elements, templates, and advertisements. This boilerplate text typically is not related to the main content, may deteriorate search precision and thus needs to be detected properly. In this paper, we analyze a small set of shallow text features for classifying the individual text elements in a Web page. We compare the approach to complex, state-of-the-art techniques and show that competitive accuracy can be achieved, at almost no cost. Moreover, we derive a simple and plausible stochastic model for describing the boilerplate creation process. With the help of our model, we also quantify the impact of boilerplate removal to retrieval performance and show significant improvements over the baseline. Finally, we extend the principled approach by straight-forward heuristics, achieving a remarkable detection accuracy.",2010,Web Search and Data Mining,Fields of study: web pagestochastic modellingworld wide webinformation retrievaldata miningmachine learningcomputer science
Identifying the influential bloggers in a community,Nitin Agarwal (Arizona State University)Huan Liu (Arizona State University)Lei Tang (Arizona State University)Philip S. Yu (University of Illinois at Chicago),"2153957209,2122391114,2141813676,2125104194","Blogging becomes a popular way for a Web user to publish information on the Web. Bloggers write blog posts, share their likes and dislikes, voice their opinions, provide suggestions, report news, and form groups in Blogosphere. Bloggers form their virtual communities of similar interests. Activities happened in Blogosphere affect the external world. One way to understand the development on Blogosphere is to find influential blog sites. There are many non-influential blog sites which form the ""the long tail"". Regardless of a blog site being influential or not, there are influential bloggers. Inspired by the high impact of the influentials in a physical community, we study a novel problem of identifying influential bloggers at a blog site. Active bloggers are not necessarily influential. Influential bloggers can impact fellow bloggers in various ways. In this paper, we discuss the challenges of identifying influential bloggers, investigate what constitutes influential bloggers, present a preliminary model attempting to quantify an influential blogger, and pave the way for building a robust model that allows for finding various types of the influentials. To illustrate these issues, we conduct experiments with data from a real-world blog site, evaluate multi-facets of the problem of identifying influential bloggers, and discuss unique challenges. We conclude with interesting findings and future work",2008,Web Search and Data Mining,Fields of study: social networkinternet privacyworld wide websocial science
Aspect and sentiment unification model for online review analysis,Yohan Jo (KAIST)Alice H. Oh (KAIST),"2139737370,2695422228","User-generated reviews on the Web contain sentiments about detailed aspects of products and services. However, most of the reviews are plain text and thus require much effort to obtain information about relevant details. In this paper, we tackle the problem of automatically discovering what aspects are evaluated in reviews and how sentiments for different aspects are expressed. We first propose Sentence-LDA (SLDA), a probabilistic generative model that assumes all words in a single sentence are generated from one aspect. We then extend SLDA to Aspect and Sentiment Unification Model (ASUM), which incorporates aspect and sentiment together to model sentiments toward different aspects. ASUM discovers pairs of {aspect, sentiment} which we call senti-aspects. We applied SLDA and ASUM to reviews of electronic devices and restaurants. The results show that the aspects discovered by SLDA match evaluative details of the reviews, and the senti-aspects found by ASUM capture important aspects that are closely coupled with a sentiment. The results of sentiment classification show that ASUM outperforms other generative models and comes close to supervised classification methods. One important advantage of ASUM is that it does not require any sentiment labels of the reviews, which are often expensive to obtain.",2011,Web Search and Data Mining,Fields of study: topic modelsentiment analysisnatural language processingworld wide webdata miningmachine learningcomputer science
Pairwise interaction tensor factorization for personalized tag recommendation,Steffen Rendle (Osaka University)Lars Schmidt-Thieme (University of Hildesheim),"1585981875,78243962","Tagging plays an important role in many recent websites. Recommender systems can help to suggest a user the tags he might want to use for tagging a specific item. Factorization models based on the Tucker Decomposition (TD) model have been shown to provide high quality tag recommendations outperforming other approaches like PageRank, FolkRank, collaborative filtering, etc. The problem with TD models is the cubic core tensor resulting in a cubic runtime in the factorization dimension for prediction and learning. In this paper, we present the factorization model PITF (Pairwise Interaction Tensor Factorization) which is a special case of the TD model with linear runtime both for learning and prediction. PITF explicitly models the pairwise interactions between users, items and tags. The model is learned with an adaption of the Bayesian personalized ranking (BPR) criterion which originally has been introduced for item recommendation. Empirically, we show on real world datasets that this model outperforms TD largely in runtime and even can achieve better prediction quality. Besides our lab experiments, PITF has also won the ECML/PKDD Discovery Challenge 2009 for graph-based tag recommendation.",2010,Web Search and Data Mining,Fields of study: personalizationcollaborative filteringfactor analysisperformancemeasurementrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning similarity metrics for event identification in social media,Hila Becker (Columbia University)Mor Naaman (Rutgers University)Luis Gravano (Columbia University),"2096763843,1220470961,2251396636","Social media sites (e.g., Flickr, YouTube, and Facebook) are a popular distribution outlet for users looking to share their experiences and interests on the Web. These sites host substantial amounts of user-contributed materials (e.g., photographs, videos, and textual content) for a wide variety of real-world events of different type and scale. By automatically identifying these events and their associated user-contributed social media documents, which is the focus of this paper, we can enable event browsing and search in state-of-the-art search engines. To address this problem, we exploit the rich ""context"" associated with social media content, including user-provided annotations (e.g., title, tags) and automatically generated information (e.g., content creation time). Using this rich context, which includes both textual and non-textual features, we can define appropriate document similarity metrics to enable online clustering of media to events. As a key contribution of this paper, we explore a variety of techniques for learning multi-feature similarity metrics for social media documents in a principled manner. We evaluate our techniques on large-scale, real-world datasets of event images from Flickr. Our evaluation results suggest that our approach identifies events, and their associated social media documents, more effectively than the state-of-the-art strategies on which we build.",2010,Web Search and Data Mining,Fields of study: social mediasearch engineworld wide webinformation retrievaldata miningcomputer science
Finding your friends and following them to where you are,Adam Sadilek (University of Rochester)Henry A. Kautz (University of Rochester)Jeffrey P. Bigham (University of Rochester),"2005357825,1966271946,2112106364","Location plays an essential role in our lives, bridging our online and offline worlds. This paper explores the interplay between people's location, interactions, and their social ties within a large real-world dataset. We present and evaluate Flap, a system that solves two intimately related tasks: link and location prediction in online social networks. For link prediction, Flap infers social ties by considering patterns in friendship formation, the content of people's messages, and user location. We show that while each component is a weak predictor of friendship alone, combining them results in a strong model, accurately identifying the majority of friendships. For location prediction, Flap implements a scalable probabilistic model of human mobility, where we treat users with known GPS positions as noisy sensors of the location of their friends. We explore supervised and unsupervised learning scenarios, and focus on the efficiency of both learning and inference. We evaluate Flap on a large sample of highly active users from two distinct geographical areas and show that it (1) reconstructs the entire friendship graph with high accuracy even when no edges are given; and (2) infers people's fine-grained location, even when they keep their data private and we can only access the location of their friends. Our models significantly outperform current comparable approaches to either task.",2012,Web Search and Data Mining,Fields of study: graphical modelsocial networksupervised learningworld wide webdata miningartificial intelligencemachine learningcomputer science
Coupled semi-supervised learning for information extraction,Andrew Carlson (Carnegie Mellon University)Justin Betteridge (Carnegie Mellon University)Richard C. Wang (Carnegie Mellon University)Estevam R. Hruschka (Federal University of São Carlos)Tom M. Mitchell (Carnegie Mellon University),"2154786016,2143543388,2505522689,2137503162,2151014374","We consider the problem of semi-supervised learning to extract categories (e.g., academic fields, athletes) and relations (e.g., PlaysSport(athlete, sport)) from web pages, starting with a handful of labeled training examples of each category or relation, plus hundreds of millions of unlabeled web documents. Semi-supervised training using only a few labeled examples is typically unreliable because the learning task is underconstrained. This paper pursues the thesis that much greater accuracy can be achieved by further constraining the learning task, by coupling the semi-supervised training of many extractors for different categories and relations. We characterize several ways in which the training of category and relation extractors can be coupled, and present experimental results demonstrating significantly improved accuracy as a result.",2010,Web Search and Data Mining,Fields of study: stabilitysemi supervised learningweb mininginformation extractionunsupervised learningworld wide webinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Adding semantics to microblog posts,Edgar Meij (University of Amsterdam)Wouter Weerkamp (University of Amsterdam)Maarten de Rijke (University of Amsterdam),"2709215799,197647246,401833296","Microblogs have become an important source of information for the purpose of marketing, intelligence, and reputation management. Streams of microblogs are of great value because of their direct and real-time nature. Determining what an individual microblog post is about, however, can be non-trivial because of creative language usage, the highly contextualized and informal nature of microblog posts, and the limited length of this form of communication. We propose a solution to the problem of determining what a microblog post is about through semantic linking: we add semantics to posts by automatically identifying concepts that are semantically related to it and generating links to the corresponding Wikipedia articles. The identified concepts can subsequently be used for, e.g., social media mining, thereby reducing the need for manual inspection and selection. Using a purpose-built test collection of tweets, we show that recently proposed approaches for semantic linking do not perform well, mainly due to the idiosyncratic nature of microblog posts. We propose a novel method based on machine learning with a set of innovative features and show that it is able to achieve significant improvements over all other methods, especially in terms of precision.",2012,Web Search and Data Mining,Fields of study: microbloggingbrandsocial mediainternet privacyworld wide webinformation retrievaldata miningcomputer science
Identifying topical authorities in microblogs,Aditya Pal (University of Minnesota)Scott Counts (Microsoft),"2111306931,2147297385","Content in microblogging systems such as Twitter is produced by tens to hundreds of millions of users. This diversity is a notable strength, but also presents the challenge of finding the most interesting and authoritative authors for any given topic. To address this, we first propose a set of features for characterizing social media authors, including both nodal and topical metrics. We then show how probabilistic clustering over this feature space, followed by a within-cluster ranking procedure, can yield a final list of top authors for a given topic. We present results across several topics, along with results from a user study confirming that our method finds authors who are significantly more interesting and authoritative than those resulting from several baseline conditions. Additionally our algorithm is computationally feasible in near real-time scenarios making it an attractive alternative for capturing the rapidly changing dynamics of microblogs.",2011,Web Search and Data Mining,Fields of study: microbloggingauthoritysocial mediarankingfeature vectorcluster analysisinternet privacyworld wide webinformation retrievaldata miningcomputer science
What's in a hashtag?: content based prediction of the spread of ideas in microblogging communities,Oren Tsur (Hebrew University of Jerusalem)Ari Rappoport (Hebrew University of Jerusalem),"766307452,2037811987","Current social media research mainly focuses on temporal trends of the information flow and on the topology of the social graph that facilitates the propagation of information. In this paper we study the effect of the content of the idea on the information propagation. We present an efficient hybrid approach based on a linear regression for predicting the spread of an idea in a given time frame. We show that a combination of content features with temporal and topological features minimizes prediction error. Our algorithm is evaluated on Twitter hashtags extracted from a dataset of more than 400 million tweets. We analyze the contribution and the limitations of the various feature types to the spread of information, demonstrating that content aspects can be used as strong predictors thus should not be disregarded. We also study the dependencies between global features such as graph topology and content features.",2012,Web Search and Data Mining,Fields of study: microbloggingsocial mediainformation flowmean squared prediction errorlinear regressiondata scienceworld wide webdata miningmachine learningcomputer science
Overlapping community detection at scale: a nonnegative matrix factorization approach,Jaewon Yang (Stanford University)Jure Leskovec (Stanford University),"2131921352,1878631932","Network communities represent basic structures for understanding the organization of real-world networks. A community (also referred to as a module or a cluster) is typically thought of as a group of nodes with more connections amongst its members than between its members and the remainder of the network. Communities in networks also overlap as nodes belong to multiple clusters at once. Due to the difficulties in evaluating the detected communities and the lack of scalable algorithms, the task of overlapping community detection in large networks largely remains an open problem. In this paper we present BIGCLAM (Cluster Affiliation Model for Big Networks), an overlapping community detection method that scales to large networks of millions of nodes and edges. We build on a novel observation that overlaps between communities are densely connected. This is in sharp contrast with present community detection methods which implicitly assume that overlaps between communities are sparsely connected and thus cannot properly extract overlapping communities in networks. In this paper, we develop a model-based community detection algorithm that can detect densely overlapping, hierarchically nested as well as non-overlapping communities in massive networks. We evaluate our algorithm on 6 large social, collaboration and information networks with ground-truth community information. Experiments show state of the art performance both in terms of the quality of detected communities as well as in speed and scalability of our algorithm.",2013,Web Search and Data Mining,Fields of study: clique percolation methodcommunity structurematrix decompositionworld wide webdistributed computingdata miningcomputer science
Corroborating information from disagreeing views,Alban Galland (French Institute for Research in Computer Science and Automation)Serge Abiteboul (French Institute for Research in Computer Science and Automation)Amélie Marian (Rutgers University)Pierre Senellart (Télécom ParisTech),"2161122370,172400696,2653530345,2039937633","We consider a set of views stating possibly conflicting facts. Negative facts in the views may come, e.g., from functional dependencies in the underlying database schema. We want to predict the truth values of the facts. Beyond simple methods such as voting (typically rather accurate), we explore techniques based on ""corroboration"", i.e., taking into account trust in the views. We introduce three fixpoint algorithms corresponding to different levels of complexity of an underlying probabilistic model. They all estimate both truth values of facts and trust in the views. We present experimental studies on synthetic and real-world data. This analysis illustrates how and in which context these methods improve corroboration results over baseline methods. We believe that corroboration can serve in a wide range of applications such as source selection in the semantic Web, data quality assessment or semantic annotation cleaning in social networks. This work sets the bases for a wide range of techniques for solving these more complex problems.",2010,Web Search and Data Mining,Fields of study: viewsemantic webconfidencedata qualitysocial networkfunctional dependencystatistical modelinformation retrievaldata miningdatabasemachine learningcomputer science
Clustering the tagged web,Daniel Ramage (Stanford University)Paul Heymann (Stanford University)Christopher D. Manning (Stanford University)Hector Garcia-Molina (Stanford University),"2087112254,2038619550,2149153931,237419955","Automatically clustering web pages into semantic groups promises improved search and browsing on the web. In this paper, we demonstrate how user-generated tags from large-scale social bookmarking websites such as del.icio.us can be used as a complementary data source to page text and anchor text for improving automatic clustering of web pages. This paper explores the use of tags in 1) K-means clustering in an extended vector space model that includes tags as well as page text and 2) a novel generative clustering algorithm based on latent Dirichlet allocation that jointly models text and tags. We evaluate the models by comparing their output to an established web directory. We find that the naive inclusion of tagging data improves cluster quality versus page text alone, but a more principled inclusion can substantially improve the quality of all models with a statistically significant absolute F-score increase of 4%. The generative model outperforms K-means with another 8% F-score increase.",2009,Web Search and Data Mining,Fields of study: correlation clusteringfuzzy clusteringk means clusteringcluster analysisworld wide webinformation retrievaldata miningmachine learningcomputer science
Exploiting social relations for sentiment analysis in microblogging,Xia Hu (Arizona State University)Lei Tang (Walmart Labs)Jiliang Tang (Arizona State University)Huan Liu (Arizona State University),"2161448330,2141813676,2147392410,2122391114","Microblogging, like Twitter and Sina Weibo, has become a popular platform of human expressions, through which users can easily produce content on breaking news, public events, or products. The massive amount of microblogging data is a useful and timely source that carries mass sentiment and opinions on various topics. Existing sentiment analysis approaches often assume that texts are independent and identically distributed (i.i.d.), usually focusing on building a sophisticated feature space to handle noisy and short texts, without taking advantage of the fact that the microblogs are networked data. Inspired by the social sciences findings that sentiment consistency and emotional contagion are observed in social networks, we investigate whether social relations can help sentiment analysis by proposing a Sociological Approach to handling Noisy and short Texts (SANT) for sentiment classification. In particular, we present a mathematical optimization formulation that incorporates the sentiment consistency and emotional contagion theories into the supervised learning process; and utilize sparse learning to tackle noisy texts in microblogging. An empirical study of two real-world Twitter datasets shows the superior performance of our framework in handling noisy and short tweets.",2013,Web Search and Data Mining,Fields of study: microbloggingsocial environmentsentiment analysisinternet privacyworld wide webdata miningcomputer science
The tube over time: characterizing popularity growth of youtube videos,Flavio Figueiredo (Universidade Federal de Minas Gerais)Fabrício Benevenuto (Universidade Federal de Minas Gerais)Jussara M. Almeida (Universidade Federal de Minas Gerais),"2034386535,1976666824,2130973600","Understanding content popularity growth is of great importance to Internet service providers, content creators and online marketers. In this work, we characterize the growth patterns of video popularity on the currently most popular video sharing application, namely YouTube. Using newly provided data by the application, we analyze how the popularity of individual videos evolves since the video's upload time. Moreover, addressing a key aspect that has been mostly overlooked by previous work, we characterize the types of the referrers that most often attracted users to each video, aiming at shedding some light into the mechanisms (e.g., searching or external linking) that often drive users towards a video, and thus contribute to popularity growth. Our analyses are performed separately for three video datasets, namely, videos that appear in the YouTube top lists, videos removed from the system due to copyright violation, and videos selected according to random queries submitted to YouTube's search engine. Our results show that popularity growth patterns depend on the video dataset. In particular, copyright protected videos tend to get most of their views much earlier in their lifetimes, often exhibiting a popularity growth characterized by a viral epidemic-like propagation process. In contrast, videos in the top lists tend to experience sudden significant bursts of popularity. We also show that not only search but also other YouTube internal mechanisms play important roles to attract users to videos in all three datasets.",2011,Web Search and Data Mining,Fields of study: search engineinternet privacymultimediaworld wide webcomputer science
Using early view patterns to predict the popularity of youtube videos,Henrique Pinto (Universidade Federal de Minas Gerais)Jussara M. Almeida (Universidade Federal de Minas Gerais)Marcos André Gonçalves (Universidade Federal de Minas Gerais),"2137546890,2130973600,2115586749","Predicting Web content popularity is an important task for supporting the design and evaluation of a wide range of systems, from targeted advertising to effective search and recommendation services. We here present two simple models for predicting the future popularity of Web content based on historical information given by early popularity measures. Our approach is validated on datasets consisting of videos from the widely used YouTube video-sharing portal. Our experimental results show that, compared to a state-of-the-art baseline model, our proposed models lead to significant decreases in relative squared errors, reaching up to 20% reduction on average, and larger reductions (of up to 71%) for videos that experience a high peak in popularity in their early days followed by a sharp decrease in popularity.",2013,Web Search and Data Mining,Fields of study: regression analysisinternet privacymultimediaworld wide webmachine learningstatisticscomputer science
Scalable inference in latent variable models,Amr Ahmed (Yahoo!)Mohamed Aly (Yahoo!)Joseph Gonzalez (Carnegie Mellon University)Shravan M. Narayanamurthy (Yahoo!)Alexander J. Smola (Yahoo!),"2259645355,2234169967,2252171364,1967865087,1972291593","Latent variable techniques are pivotal in tasks ranging from predicting user click patterns and targeting ads to organizing the news and managing user generated content. Latent variable techniques like topic modeling, clustering, and subspace estimation provide substantial insight into the latent structure of complex data with little or no external guidance making them ideal for reasoning about large-scale, rapidly evolving datasets. Unfortunately, due to the data dependencies and global state introduced by latent variables and the iterative nature of latent variable inference, latent-variable techniques are often prohibitively expensive to apply to large-scale, streaming datasets. In this paper we present a scalable parallel framework for efficient inference in latent variable models over streaming web-scale data. Our framework addresses three key challenges: 1) synchronizing the global state which includes global latent variables (e.g., cluster centers and dictionaries); 2) efficiently storing and retrieving the large local state which includes the data-points and their corresponding latent variables (e.g., cluster membership); and 3) sequentially incorporating streaming data (e.g., the news). We address these challenges by introducing: 1) a novel delta-based aggregation system with a bandwidth-efficient communication protocol; 2) schedule-aware out-of-core storage; and 3) approximate forward sampling to rapidly incorporate new data. We demonstrate state-of-the-art performance of our framework by easily tackling datasets two orders of magnitude larger than those addressed by the current state-of-the-art. Furthermore, we provide an optimized and easily customizable open-source implementation of the framework 1 .",2012,Web Search and Data Mining,Fields of study: probabilistic latent semantic analysisgraphical modeldata scienceworld wide webdata miningmachine learningstatisticscomputer science
fLDA: matrix factorization through latent dirichlet allocation,Deepak Agarwal (Yahoo!)Bee-Chung Chen (Yahoo!),"2591515730,2152441490","We propose fLDA, a novel matrix factorization method to predict ratings in recommender system applications where a ""bag-of-words"" representation for item meta-data is natural. Such scenarios are commonplace in web applications like content recommendation, ad targeting and web search where items are articles, ads and web pages respectively. Because of data sparseness, regularization is key to good predictive accuracy. Our method works by regularizing both user and item factors simultaneously through user features and the bag of words associated with each item. Specifically, each word in an item is associated with a discrete latent factor often referred to as the topic of the word; item topics are obtained by averaging topics across all words in an item. Then, user rating on an item is modeled as user's affinity to the item's topics where user affinity to topics (user factors) and topic assignments to words in items (item factors) are learned jointly in a supervised fashion. To avoid overfitting, user and item factors are regularized through Gaussian linear regression and Latent Dirichlet Allocation (LDA) priors respectively. We show our model is accurate, interpretable and handles both cold-start and warm-start scenarios seamlessly through a single model. The efficacy of our method is illustrated on benchmark datasets and a new dataset from Yahoo! Buzz where fLDA provides superior predictive accuracy in cold-start scenarios and is comparable to state-of-the-art methods in warm-start scenarios. As a by-product, fLDA also identifies interesting topics that explains user-item interactions. Our method also generalizes a recently proposed technique called supervised LDA (sLDA) to collaborative filtering applications. While sLDA estimates item topic vectors in a supervised fashion for a single regression, fLDA incorporates multiple regressions (one for each user) in estimating the item factors.",2010,Web Search and Data Mining,Fields of study: bag of words modelbayesian hierarchical modelingcollaborative filteringlatent dirichlet allocationgraphical modelweb pagematrix decompositionlinear regressionrecommender systemworld wide webinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
Correlating financial time series with micro-blogging activity,"Eduardo J. Ruiz (University of California, Riverside)Vagelis Hristidis (University of California, Riverside)Carlos Castillo (Yahoo!)Aristides Gionis (Yahoo!)Alejandro Jaimes (Yahoo!)","2095858230,238786035,2125169605,737311942,2193615068","We study the problem of correlating micro-blogging activity with stock-market events, defined as changes in the price and traded volume of stocks. Specifically, we collect messages related to a number of companies, and we search for correlations between stock-market events for those companies and features extracted from the micro-blogging messages. The features we extract can be categorized in two groups. Features in the first group measure the overall activity in the micro-blogging platform, such as number of posts, number of re-posts, and so on. Features in the second group measure properties of an induced interaction graph , for instance, the number of connected components, statistics on the degree distribution, and other graph-based properties. We present detailed experimental results measuring the correlation of the stock market events with these features, using Twitter as a data source. Our results show that the most correlated features are the number of connected components and the number of nodes of the interaction graph. The correlation is stronger with the traded volume than with the price of the stock. However, by using a simulator we show that even relatively small correlations between price and micro-blogging features can be exploited to drive a stock trading strategy that outperforms other baseline strategies.",2012,Web Search and Data Mining,Fields of study: social networksocial sciencedata miningcomputer science
Understanding temporal query dynamics,Anagha Kulkarni (Carnegie Mellon University)Jaime Teevan (Microsoft)Krysta Marie Svore (Microsoft)Susan T. Dumais (Microsoft),"2187942432,1982462162,1996400553,676500258","Web search is strongly influenced by time. The queries people issue change over time, with some queries occasionally spiking in popularity (e.g., earthquake ) and others remaining relatively constant (e.g., youtube ). The documents indexed by the search engine also change, with some documents always being about a particular query (e.g., the Wikipedia page on earthquakes is about the query earthquake ) and others being about the query only at a particular point in time (e.g., the New York Times is only about earthquakes following a major seismic activity). The relationship between documents and queries can also change as people's intent changes (e.g., people sought different content for the query earthquake before the Haitian earthquake than they did after). In this paper, we explore how queries, their associated documents, and the query intent change over the course of 10 weeks by analyzing query log data, a daily Web crawl, and periodic human relevance judgments. We identify several interesting features by which changes to query popularity can be classified, and show that presence of these features, when accompanied by changes in result content, can be a good indicator of change in query intent.",2011,Web Search and Data Mining,Fields of study: range querysargablerankingonline aggregationweb search queryweb query classificationspatial queryquery by exampleweb crawlerquery expansionquery optimizationquery languagesearch engineworld wide webinformation retrievaldata miningcomputer science
Inferring social ties across heterogenous networks,Jie Tang (Tsinghua University)Tiancheng Lou (Tsinghua University)Jon M. Kleinberg (Cornell University),"2158012360,2162145093,2261367123","It is well known that different types of social ties have essentially different influence on people. However, users in online social networks rarely categorize their contacts into ""family"", ""colleagues"", or ""classmates"". While a bulk of research has focused on inferring particular types of relationships in a specific social network, few publications systematically study the generalization of the problem of inferring social ties over multiple heterogeneous networks. In this work, we develop a framework for classifying the type of social relationships by learning across heterogeneous networks. The framework incorporates social theories into a factor graph model, which effectively improves the accuracy of inferring the type of social relationships in a target network by borrowing knowledge from a different source network. Our empirical study on five different genres of networks validates the effectiveness of the proposed framework. For example, by leveraging information from a coauthor network with labeled advisor-advisee relationships, the proposed framework is able to obtain an F1-score of 90% (8-28% improvements over alternative methods) for inferring manager-subordinate relationships in an enterprise email network.",2012,Web Search and Data Mining,Fields of study: dynamic network analysisnetwork sciencesocial network analysispredictive modellingsocial networksocial sciencedata miningmachine learningcomputer science
Characterizing the influence of domain expertise on web search behavior,Ryen W. White (Microsoft)Susan T. Dumais (Microsoft)Jaime Teevan (Microsoft),"2096583854,676500258,1982462162","Domain experts search differently than people with little or no domain knowledge. Previous research suggests that domain experts employ different search strategies and are more successful in finding what they are looking for than non-experts. In this paper we present a large-scale, longitudinal, log-based analysis of the effect of domain expertise on web search behavior in four different domains (medicine, finance, law, and computer science). We characterize the nature of the queries, search sessions, web sites visited, and search success for users identified as experts and non-experts within these domains. Large-scale analysis of real-world interactions allows us to understand how expertise relates to vocabulary, resource use, and search task under more realistic search conditions than has been possible in previous small-scale studies. Building upon our analysis we develop a model to predict expertise based on search behavior, and describe how knowledge about domain expertise can be used to present better results and query suggestions to users and to help non-experts gain expertise.",2009,Web Search and Data Mining,Fields of study: search analyticsproblem domainsubject matter expertdomain knowledgesemantic searchdata scienceknowledge managementworld wide webdata miningcomputer science
Challenges in building large-scale information retrieval systems: invited talk,Jeffrey Dean (Google),2429370538,"Building and operating large-scale information retrieval systems used by hundreds of millions of people around the world provides a number of interesting challenges. Designing such systems requires making complex design tradeoffs in a number of dimensions, including (a) the number of user queries that must be handled per second and the response latency to these requests, (b) the number and size of various corpora that are searched, (c) the latency and frequency with which documents are updated or added to the corpora, and (d) the quality and cost of the ranking algorithms that are used for retrieval. In this talk I will discuss the evolution of Google's hardware infrastructure and information retrieval systems and some of the design challenges that arise from ever-increasing demands in all of these dimensions. I will also describe how we use various pieces of distributed systems infrastructure when building these retrieval systems. Finally, I will describe some future challenges and open research problems in this area.",2009,Web Search and Data Mining,Fields of study: cognitive models of information retrievalhuman computer information retrievalsearch enginetheoretical computer scienceworld wide webinformation retrievaldata miningcomputer science
Efficient multiple-click models in web search,Fan Guo (Carnegie Mellon University)Chao Liu (Microsoft)Yi Min Wang (Microsoft),"2278294079,2095896511,2137802269","Many tasks that leverage web search users' implicit feedback rely on a proper and unbiased interpretation of user clicks. Previous eye-tracking experiments and studies on explaining position-bias of user clicks provide a spectrum of hypotheses and models on how an average user examines and possibly clicks web documents returned by a search engine with respect to the submitted query. In this paper, we attempt to close the gap between previous work, which studied how to model a single click, and the reality that multiple clicks on web documents in a single result page are not uncommon. Specifically, we present two multiple-click models: the independent click model (ICM) which is reformulated from previous work, and the dependent click model (DCM) which takes into consideration dependencies between multiple clicks. Both models can be efficiently learned with linear time and space complexities. More importantly, they can be incrementally updated as new click logs flow in. These are well-demanded properties in reality. We systematically evaluate the two models on click logs obtained in July 2008 from a major commercial search engine. The data set, after preprocessing, contains over 110 thousand distinct queries and 8.8 million query sessions. Extensive experimental studies demonstrate the gain of modeling multiple clicks and their dependencies. Finally, we note that since our experimental setup does not rely on tweaking search result rankings, it can be easily adopted by future studies.",2009,Web Search and Data Mining,Fields of study: three click rulestatistical modelworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms,Lihong Li (Yahoo!)Wei Chu (Yahoo!)John Langford (Yahoo!)Xuanhui Wang (Yahoo!),"2125714999,2467733054,2232397101,2102775025","Contextual bandit algorithms have become popular for online recommendation systems such as Digg, Yahoo! Buzz, and news recommendation in general. Offline evaluation of the effectiveness of new algorithms in these applications is critical for protecting online user experiences but very challenging due to their ""partial-label"" nature. Common practice is to create a simulator which simulates the online environment for the problem at hand and then run an algorithm against this simulator. However, creating simulator itself is often difficult and modeling bias is usually unavoidably introduced. In this paper, we introduce a replay methodology for contextual bandit algorithm evaluation. Different from simulator-based approaches, our method is completely data-driven and very easy to adapt to different applications. More importantly, our method can provide provably unbiased evaluations. Our empirical results on a large-scale news article recommendation dataset collected from Yahoo! Front Page conform well with our theoretical results. Furthermore, comparisons between our offline replay and online bucket evaluation of several contextual bandit algorithms show accuracy and effectiveness of our offline evaluation method.",2011,Web Search and Data Mining,Fields of study: multi armed banditrecommender systemworld wide webdata miningmachine learningcomputer science
When will it happen?: relationship prediction in heterogeneous information networks,Yizhou Sun (University of Illinois at Urbana–Champaign)Jiawei Han (University of Illinois at Urbana–Champaign)Charu C. Aggarwal (IBM)Nitesh V. Chawla (University of Notre Dame),"2131539564,2121939561,2146335907,1979796846","Link prediction, i.e., predicting links or interactions between objects in a network, is an important task in network analysis. Although the problem has attracted much attention recently, there are several challenges that have not been addressed so far. First, most existing studies focus only on link prediction in homogeneous networks, where all objects and links belong to the same type. However, in the real world, heterogeneous networks that consist of multi-typed objects and relationships are ubiquitous. Second, most current studies only concern the problem of whether a link will appear in the future but seldom pay attention to the problem of when it will happen. In this paper, we address both issues and study the problem of predicting when a certain relationship will happen in the scenario of heterogeneous networks . First, we extend the link prediction problem to the relationship prediction problem, by systematically defining both the target relation and the topological features, using a meta path-based approach. Then, we directly model the distribution of relationship building time with the use of the extracted topological features. The experiments on citation relationship prediction between authors on the DBLP network demonstrate the effectiveness of our methodology.",2012,Web Search and Data Mining,Fields of study: heterogeneous networknetwork analysisdata miningartificial intelligencemachine learningcomputer science
Beyond DCG: user behavior as a predictor of a successful search,Ahmed Hassan (University of Michigan)Rosie Jones (Yahoo!)Kristina Lisa Klinkner (Carnegie Mellon University),"2266125312,2128530851,231613701","Web search engines are traditionally evaluated in terms of the relevance of web pages to individual queries. However, relevance of web pages does not tell the complete picture, since an individual query may represent only a piece of the user's information need and users may have different information needs underlying the same queries. In this work, we address the problem of predicting user search goal success by modeling user behavior. We show empirically that user behavior alone can give an accurate picture of the success of the user's web search goals, without considering the relevance of the documents displayed. In fact, our experiments show that models using user behavior are more predictive of goal success than those using document relevance. We build novel sequence models incorporating time distributions for this task and our experiments show that the sequence and time distribution models are more accurate than static models based on user behavior, or predictions based on document relevance.",2010,Web Search and Data Mining,Fields of study: search analyticscomputer user satisfactionorganic searchweb search queryweb query classificationweb designuser requirements documentuser modelinginformation needsweb pagesearch engineweb search engineworld wide webinformation retrievaldata miningcomputer science
Structure and dynamics of information pathways in online media,Manuel Gomez Rodriguez (Max Planck Society)Jure Leskovec (Stanford University)Bernhard Schölkopf (Max Planck Society),"2421855118,1878631932,297432538","Diffusion of information, spread of rumors and infectious diseases are all instances of stochastic processes that occur over the edges of an underlying network. Many times networks over which contagions spread are unobserved, and such networks are often dynamic and change over time. In this paper, we investigate the problem of inferring dynamic networks based on information diffusion data. We assume there is an unobserved dynamic network that changes over time, while we observe the results of a dynamic process spreading over the edges of the network. The task then is to infer the edges and the dynamics of the underlying network. We develop an on-line algorithm that relies on stochastic convex optimization to efficiently solve the dynamic network inference problem. We apply our algorithm to information diffusion among 3.3 million mainstream media and blog sites and experiment with more than 179 million different pieces of information spreading over the network in a one year period. We study the evolution of information pathways in the online media space and find interesting insights. Information pathways for general recurrent topics are more stable across time than for on-going news events. Clusters of news media sites and blogs often emerge and vanish in matter of days for on-going news events. Major social movements and events involving civil population, such as the Libyan'{}s civil war or Syria'{}s uprise, lead to an increased amount of information pathways among blogs as well as in the overall increase in the network centrality of blogs and social media sites.",2013,Web Search and Data Mining,Fields of study: news mediainformation cascadesocial networkworld wide websocial scienceartificial intelligencemachine learningsimulationcomputer science
SoftRank: optimizing non-smooth rank metrics,Michael J. Taylor (Microsoft)John Guiver (Microsoft)Stephen Robertson (Microsoft)Tom Minka (Microsoft),"2145462364,2039323299,2129454193,172536002","We address the problem of learning large complex ranking functions. Most IR applications use evaluation metrics that depend only upon the ranks of documents. However, most ranking functions generate document scores, which are sorted to produce a ranking. Hence IR metrics are innately non-smooth with respect to the scores, due to the sort. Unfortunately, many machine learning algorithms require the gradient of a training objective in order to perform the optimization of the model parameters,and because IR metrics are non-smooth,we need to find a smooth proxy objective that can be used for training. We present a new family of training objectives that are derived from the rank distributions of documents, induced by smoothed scores. We call this approach SoftRank. We focus on a smoothed approximation to Normalized Discounted Cumulative Gain (NDCG), called SoftNDCG and we compare it with three other training objectives in the recent literature. We present two main results. First, SoftRank yields a very good way of optimizing NDCG. Second, we show that it is possible to achieve state of the art test set NDCG results by optimizing a soft NDCG objective on the training set with a different discount function",2008,Web Search and Data Mining,Fields of study: ranking svmrankingmetricscumulantgradient descentdata miningmachine learningmathematical optimizationstatisticscomputer science
FENNEL: streaming graph partitioning for massive scale graphs,Charalampos E. Tsourakakis (Aalto University)Christos Gkantsidis (Microsoft)Bozidar Radunovic (Microsoft)Milan Vojnovic (Microsoft),"750472553,117801055,837942740,1992645465","Balanced graph partitioning in the streaming setting is a key problem to enable scalable and efficient computations on massive graph data such as web graphs, knowledge graphs, and graphs arising in the context of online social networks. Two families of heuristics for graph partitioning in the streaming setting are in wide use: place the newly arrived vertex in the cluster with the largest number of neighbors or in the cluster with the least number of non-neighbors. In this work, we introduce a framework which unifies the two seemingly orthogonal heuristics and allows us to quantify the interpolation between them. More generally, the framework enables a well principled design of scalable, streaming graph partitioning algorithms that are amenable to distributed implementations. We derive a novel one-pass, streaming graph partitioning algorithm and show that it yields significant performance improvements over previous approaches using an extensive set of real-world and synthetic graphs. Surprisingly, despite the fact that our algorithm is a one-pass streaming algorithm, we found its performance to be in many cases comparable to the de-facto standard offline software METIS and in some cases even superiror. For instance, for the Twitter graph with more than 1.4 billion of edges, our method partitions the graph in about 40 minutes achieving a balanced partition that cuts as few as 6.8% of edges, whereas it took more than 81/2 hours by METIS to produce a balanced partition that cuts 11.98% of edges. We also demonstrate the performance gains by using our graph partitioner while solving standard PageRank computation in a graph processing platform with respect to the communication cost and runtime.",2014,Web Search and Data Mining,Fields of study: distance hereditary graphstrength of a graphvoltage graphcomplement graphgraph bandwidthcomparability graphgraph productclique widthpathwidthgraphgraph partitiontheoretical computer scienceworld wide webdistributed computingdata miningmachine learningcomputer science
Folks in Folksonomies: social link prediction from shared metadata,Rossano Schifanella (University of Turin)Alain Barrat (Centre national de la recherche scientifique)Ciro Cattuto (Institute for Scientific Interchange)Benjamin Markines (Indiana University Bloomington)Filippo Menczer (Indiana University Bloomington),"2200389328,1157737953,288858733,1012478477,2248192384","Web 2.0 applications have attracted a considerable amount of attention because their open-ended nature allows users to create lightweight semantic scaffolding to organize and share content. To date, the interplay of the social and semantic components of social media has been only partially explored. Here we focus on Flickr and Last.fm, two social media systems in which we can relate the tagging activity of the users with an explicit representation of their social network. We show that a substantial level of local lexical and topical alignment is observable among users who lie close to each other in the social network. We introduce a null model that preserves user activity while removing local correlations, allowing us to disentangle the actual local alignment between users from statistical effects due to the assortative mixing of user activity and centrality in the social network. This analysis suggests that users with similar topical interests are more likely to be friends, and therefore semantic similarity measures among users based solely on their annotation metadata should be predictive of social links. We test this hypothesis on the Last.fm data set, confirming that the social network constructed from semantic similarity captures actual friendship more accurately than Last.fm's suggestions based on listening patterns.",2010,Web Search and Data Mining,Fields of study: web 2 0social semantic websocial medianull modelsmith waterman algorithmsemantic similaritysocial networkworld wide webdata miningcomputer science
Auralist: introducing serendipity into music recommendation,Yuan Cao Zhang (University of Cambridge)Diarmuid Ó Séaghdha (University of Cambridge)Daniele Quercia (University of Cambridge)Tamas Jambor (University of Cambridge),"2236195309,274659761,2714967879,2568246021","Recommendation systems exist to help users discover content in a large body of items. An ideal recommendation system should mimic the actions of a trusted friend or expert, producing a personalised collection of recommendations that balance between the desired goals of accuracy, diversity, novelty and serendipity. We introduce the Auralist recommendation framework, a system that - in contrast to previous work - attempts to balance and improve all four factors simultaneously. Using a collection of novel algorithms inspired by principles of ""serendipitous discovery"", we demonstrate a method of successfully injecting serendipity, novelty and diversity into recommendations whilst limiting the impact on accuracy. We evaluate Auralist quantitatively over a broad set of metrics and, with a user study on music recommendation, show that Auralist's emphasis on serendipity indeed improves user satisfaction.",2012,Web Search and Data Mining,Fields of study: diversificationcollaborative filteringmetricsaccuracy and precisionrecommender systemknowledge managementmultimediaworld wide webdata miningmachine learningcomputer science
Scalable knowledge harvesting with high precision and high recall,Ndapandula Nakashole (Max Planck Society)Martin Theobald (Max Planck Society)Gerhard Weikum (Max Planck Society),"2022819398,2159374572,514836396","Harvesting relational facts from Web sources has received great attention for automatically constructing large knowledge bases. Stateof-the-art approaches combine pattern-based gathering of fact candidates with constraint-based reasoning. However, they still face major challenges regarding the trade-offs between precision, recall, and scalability. Techniques that scale well are susceptible to noisy patterns that degrade precision, while techniques that employ deep reasoning for high precision cannot cope with Web-scale data. This paper presents a scalable system, called PROSPERA, for high-quality knowledge harvesting. We propose a new notion of ngram-itemsets for richer patterns, and use MaxSat-based constraint reasoning on both the quality of patterns and the validity of fact candidates.We compute pattern-occurrence statistics for two benefits: they serve to prune the hypotheses space and to derive informative weights of clauses for the reasoner. The paper shows how to incorporate these building blocks into a scalable architecture that can parallelize all phases on a Hadoop-based distributed platform. Our experiments with the ClueWeb09 corpus include comparisons to the recent ReadTheWeb experiment. We substantially outperform these prior results in terms of recall, with the same precision, while having low run-times.",2011,Web Search and Data Mining,Fields of study: scalabilityinformation extractionknowledge basetheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Personalizing web search using long term browsing history,Nicolaas Matthijs (University of Cambridge)Filip Radlinski (Microsoft),"2230977152,2072292845","Personalizing web search results has long been recognized as an avenue to greatly improve the search experience. We present a personalization approach that builds a user interest profile using users' complete browsing behavior, then uses this model to rerank web results. We show that using a combination of content and previously visited websites provides effective personalization. We extend previous work by proposing a number of techniques for filtering previously viewed content that greatly improve the user model used for personalization. Our approaches are compared to previous work in offline experiments and are evaluated against unpersonalized web search in large scale online tests. Large improvements are found in both cases.",2011,Web Search and Data Mining,Fields of study: web search queryweb designinterleavingrankinguser modelingevaluationmultimediaworld wide webinformation retrievalcomputer science
Towards recency ranking in web search,Anlei Dong (Yahoo!)Yi Chang (Yahoo!)Zhaohui Zheng (Yahoo!)Gilad Mishne (Yahoo!)Jing Bai (Yahoo!)Ruiqiang Zhang (Yahoo!)Karolina Buchner (Yahoo!)Ciya Liao (Yahoo!)Fernando Diaz (Yahoo!),"2102564942,2168000538,2089011938,2698345362,2303745997,2121528607,2142665806,2146812112,2159093489","In web search, recency ranking refers to ranking documents by relevance which takes freshness into account. In this paper, we propose a retrieval system which automatically detects and responds to recency sensitive queries. The system detects recency sensitive queries using a high precision classifier. The system responds to recency sensitive queries by using a machine learned ranking model trained for such queries. We use multiple recency features to provide temporal evidence which effectively represents document recency. Furthermore, we propose several training methodologies important for training recency sensitive rankers. Finally, we develop new evaluation metrics for recency sensitive queries. Our experiments demonstrate the efficacy of the proposed approaches.",2010,Web Search and Data Mining,Fields of study: web query classificationinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Clustering product features for opinion mining,Zhongwu Zhai (Tsinghua University)Bing Liu (University of Illinois at Chicago)Hua Xu (Tsinghua University)Peifa Jia (Tsinghua University),"2127954048,2244698799,2293087018,2145471327","In sentiment analysis of product reviews, one important problem is to produce a summary of opinions based on product features/attributes (also called aspects). However, for the same feature, people can express it with many different words or phrases. To produce a useful summary, these words and phrases, which are domain synonyms, need to be grouped under the same feature group. Although several methods have been proposed to extract product features from reviews, limited work has been done on clustering or grouping of synonym features. This paper focuses on this task. Classic methods for solving this problem are based on unsupervised learning using some forms of distributional similarity. However, we found that these methods do not do well. We then model it as a semi-supervised learning problem. Lexical characteristics of the problem are exploited to automatically identify some labeled examples. Empirical evaluation shows that the proposed method outperforms existing state-of-the-art methods by a large margin.",2011,Web Search and Data Mining,Fields of study: sentiment analysisinformation retrievaldata miningpattern recognitionmachine learningcomputer science
A model to estimate intrinsic document relevance from the clickthrough logs of a web search engine,Georges Dupret (Yahoo!)Ciya Liao (Yahoo!),"2080443884,2146812112","We propose a new model to interpret the clickthrough logs of a web search engine. This model is based on explicit assumptions on the user behavior. In particular, we draw conclusions on a document relevance by observing the user behavior after he examined the document and not based on whether a user clicks or not a document url. This results in a model based on intrinsic relevance, as opposed to perceived relevance. We use the model to predict document relevance and then use this as feature for a ""Learning to Rank"" machine learning algorithm. Comparing the ranking functions obtained by training the algorithm with and without the new feature we observe surprisingly good results. This is particularly notable given that the baseline we use is the heavily optimized ranking function of a leading commercial search engine. A deeper analysis shows that the new feature is particularly helpful for non navigational queries and queries with a large abandonment rate or a large average number of queries per session. This is important because these types of query is considered to be the most difficult to solve.",2010,Web Search and Data Mining,Fields of study: search enginelearning to rankweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Improving ad relevance in sponsored search,Dustin Hillard (Yahoo!)Stefan Schroedl (Yahoo!)Eren Manavoglu (Yahoo!)Hema Raghavan (Yahoo!)Chirs Leggetter (Yahoo!),"2016371632,1810148087,26108554,2010246433,2229994523","We describe a machine learning approach for predicting sponsored search ad relevance. Our baseline model incorporates basic features of text overlap and we then extend the model to learn from past user clicks on advertisements. We present a novel approach using translation models to learn user click propensity from sparse click logs. Our relevance predictions are then applied to multiple sponsored search applications in both offline editorial evaluations and live online user tests. The predicted relevance score is used to improve the quality of the search page in three areas: filtering low quality ads, more accurate ranking for ads, and optimized page placement of ads to reduce prominent placement of low relevance ads. We show significant gains across all three tasks.",2010,Web Search and Data Mining,Fields of study: translationworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning concept importance using a weighted dependence model,Michael Bendersky (University of Massachusetts Amherst)Donald Metzler (Yahoo!)W. Bruce Croft (University of Massachusetts Amherst),"2112702096,2151486164,2127889770","Modeling query concepts through term dependencies has been shown to have a significant positive effect on retrieval performance, especially for tasks such as web search, where relevance at high ranks is particularly critical. Most previous work, however, treats all concepts as equally important, an assumption that often does not hold, especially for longer, more complex queries. In this paper, we show that one of the most effective existing term dependence models can be naturally extended by assigning weights to concepts. We demonstrate that the weighted dependence model can be trained using existing learning-to-rank techniques, even with a relatively small number of training queries. Our study compares the effectiveness of both endogenous (collection-based) and exogenous (based on external sources) features for determining concept importance. To test the weighted dependence model, we perform experiments on both publicly available TREC corpora and a proprietary web corpus. Our experimental results indicate that our model consistently and significantly outperforms both the standard bag-of-words model and the unweighted term dependence model, and that combining endogenous and exogenous features generally results in the best retrieval effectiveness.",2010,Web Search and Data Mining,Fields of study: bag of words modellearning to rankinformation retrievaldata miningmachine learningcomputer science
Influence diffusion dynamics and influence maximization in social networks with friend and foe relationships,Yanhua Li (University of Minnesota)Wei Chen (Microsoft)Yajun Wang (Microsoft)Zhi Li Zhang (University of Minnesota),"2160296268,2527738285,2670586468,2164420873","Influence diffusion and influence maximization in large-scale online social networks (OSNs) have been extensively studied because of their impacts on enabling effective online viral marketing. Existing studies focus on social networks with only friendship relations, whereas the foe or enemy relations that commonly exist in many OSNs, e.g., Epinions and Slashdot, are completely ignored. In this paper, we make the first attempt to investigate the influence diffusion and influence maximization in OSNs with both friend and foe relations, which are modeled using positive and negative edges on signed networks. In particular, we extend the classic voter model to signed networks and analyze the dynamics of influence diffusion of two opposite opinions. We first provide systematic characterization of both short-term and long-term dynamics of influence diffusion in this model, and illustrate that the steady state behaviors of the dynamics depend on three types of graph structures, which we refer to as balanced graphs, anti-balanced graphs, and strictly unbalanced graphs. We then apply our results to solve the influence maximization problem and develop efficient algorithms to select initial seeds of one opinion that maximize either its short-term influence coverage or long-term steady state influence coverage. Extensive simulation results on both synthetic and real-world networks, such as Epinions and Slashdot, confirm our theoretical analysis on influence diffusion dynamics, and demonstrate that our influence maximization algorithms perform consistently better than other heuristic algorithms.",2013,Web Search and Data Mining,Fields of study: combinatoricssocial psychologyartificial intelligencemachine learningcomputer science
Integration of news content into web results,Fernando Diaz (Yahoo!),2159093489,"Aggregated search refers to the integration of content from specialized corpora or verticals into web search results. Aggregation improves search when the user has vertical intent but may not be aware of or desire vertical search. In this paper, we address the issue of integrating search results from a news vertical into web search results. News is particularly challenging because, given a query, the appropriate decision---to integrate news content or not---changes with time. Our system adapts to news intent in two ways. First, by inspecting the dynamics of the news collection and query volume, we can track development of and interest in topics. Second, by using click feedback, we can quickly recover from system errors. We define several click-based metrics which allow a system to be monitored and tuned without annotator effort.",2009,Web Search and Data Mining,Fields of study: organic searchweb search queryweb query classificationquery expansionposterior predictive distributionsearch enginesemantic searchmultimediaworld wide webinformation retrievaldata miningcomputer science
Adaptive bootstrapping of recommender systems using decision trees,Nadav Golbandi (Yahoo!)Yehuda Koren (Yahoo!)Ronny Lempel (Yahoo!),"2642611369,1966367906,2249016471","Recommender systems perform much better on users for which they have more information. This gives rise to a problem of satisfying users new to a system. The problem is even more acute considering that some of these hard to profile new users judge the unfamiliar system by its ability to immediately provide them with satisfying recommendations, and may quickly abandon the system when disappointed. Rapid profiling of new users by a recommender system is often achieved through a bootstrapping process - a kind of an initial interview - that elicits users to provide their opinions on certain carefully chosen items or categories. The elicitation process becomes particularly effective when adapted to users' responses, making best use of users' time by dynamically modifying the questions to improve the evolving profile. In particular, we advocate a specialized version of decision trees as the most appropriate tool for this task. We detail an efficient tree learning algorithm, specifically tailored to the unique properties of the problem. Several extensions to the tree construction are also introduced, which enhance the efficiency and utility of the method. We implemented our methods within a movie recommendation service. The experimental study delivered encouraging results, with the tree-based bootstrapping process significantly outperforming previous approaches.",2011,Web Search and Data Mining,Fields of study: collaborative filteringdecision treesatisfiabilityrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Discovering and using groups to improve personalized search,Jaime Teevan (Microsoft)Meredith Ringel Morris (Microsoft)Steve Bush (Microsoft),"1982462162,2123314761,2224904056","Personalized Web search takes advantage of information about an individual to identify the most relevant results for that person. A challenge for personalization lies in collecting user profiles that are rich enough to do this successfully. One way an individual's profile can be augmented is by using data from other people. To better understand whether groups of people can be used to benefit personalized search, we explore the similarity of query selection, desktop information, and explicit relevance judgments across people grouped in different ways. The groupings we explore fall along two dimensions: the longevity of the group members' relationship, and how explicitly the group is formed. We find that some groupings provide valuable insight into what members consider relevant to queries related to the group focus, but that it can be difficult to identify valuable groups implicitly. Building on these findings, we explore an algorithm to ""groupize"" (versus ""personalize"" ) Web search results that leads to a significant improvement in result ranking on group-relevant queries.",2009,Web Search and Data Mining,Fields of study: personalizationcollaborative filteringtwo dimensional spaceworld wide webinformation retrievaldata miningmachine learningcomputer science
Maximizing product adoption in social networks,Smriti Bhagat (University of British Columbia)Amit Goyal (University of British Columbia)Laks V.S. Lakshmanan (University of British Columbia),"2499581372,2675938765,2659892814","One of the key objectives of viral marketing is to identify a small set of users in a social network, who when convinced to adopt a product will influence others in the network leading to a large number of adoptions in an expected sense. The seminal work of Kempe et al. [13] approaches this as the problem of influence maximization. This and other previous papers tacitly assume that a user who is influenced (or, informed) about a product necessarily adopts the product and encourages her friends to adopt it. However, an influenced user may not adopt the product herself, and yet form an opinion based on the experiences of her friends, and share this opinion with others. Furthermore, a user who adopts the product may not like the product and hence not encourage her friends to adopt it to the same extent as another user who adopted and liked the product. This is independent of the extent to which those friends are influenced by her. Previous works do not account for these phenomena. We argue that it is important to distinguish product adoption from influence. We propose a model that factors in a user's experience (or projected experience) with a product. We adapt the classical Linear Threshold (LT) propagation model by defining an objective function that explicitly captures product adoption, as opposed to influence. We show that under our model, adoption maximization is NP-hard and the objective function is monotone and submodular, thus admitting an approximation algorithm. We perform experiments on three real popular social networks and show that our model is able to distinguish between influence and adoption, and predict product adoption much more accurately than approaches based on the classical LT model.",2012,Web Search and Data Mining,Fields of study: viral marketingsocial networkworld wide websocial sciencedata miningmachine learningsimulation
Exploiting homophily effect for trust prediction,Jiliang Tang (Arizona State University)Huiji Gao (Arizona State University)Xia Hu (Arizona State University)Huan Liu (Arizona State University),"2147392410,2166899337,2161448330,2122391114",-,2013,Web Search and Data Mining,-
App recommendation: a contest between satisfaction and temptation,Peifeng Yin (Pennsylvania State University)Ping Luo (Hewlett-Packard)Wang-Chien Lee (Pennsylvania State University)Min Wang (Hewlett-Packard),"2113084173,2291210646,2143778659,2467205710","Due to the huge and still rapidly growing number of mobile applications (apps), it becomes necessary to provide users an app recommendation service. Different from conventional item recommendation where the user interest is the primary factor, app recommendation also needs to consider factors that invoke a user to replace an old app (if she already has one) with a new app. In this work we propose an Actual- Tempting model that captures such factors in the decision process of mobile app adoption. The model assumes that each owned app has an actual satisfactory value and a new app under consideration has a tempting value. The former stands for the real satisfactory value the owned app brings to the user while the latter represents the estimated value the new app may seemingly have. We argue that the process of app adoption therefore is a contest between the owned apps' actual values and the candidate app's tempting value. Via the extensive experiments we show that the AT model performs significantly better than the conventional recommendation techniques such as collaborative filtering and content-based recommendation. Furthermore, the best recommendation performance is achieved when the AT model is combined with them.",2013,Web Search and Data Mining,Fields of study: world wide web
Identifying content for planned events across social media sites,Hila Becker (Columbia University)Dan Iter (Columbia University)Mor Naaman (Rutgers University)Luis Gravano (Columbia University),"2096763843,2624784513,1220470961,2251396636","User-contributed Web data contains rich and diverse information about a variety of events in the physical world, such as shows, festivals, conferences and more. This information ranges from known event features (e.g., title, time, location) posted on event aggregation platforms (e.g., Last.fm events, EventBrite, Facebook events) to discussions and reactions related to events shared on different social media sites (e.g., Twitter, YouTube, Flickr). In this paper, we focus on the challenge of automatically identifying user-contributed content for events that are planned and, therefore, known in advance, across different social media sites. We mine event aggregation platforms to extract event features, which are often noisy or missing. We use these features to develop query formulation strategies for retrieving content associated with an event on different social media sites. Further, we explore ways in which event content identified on one social media site can be used to retrieve additional relevant event content on other social media sites. We apply our strategies to a large set of user-contributed events, and analyze their effectiveness in retrieving relevant event content from Twitter, YouTube, and Flickr.",2012,Web Search and Data Mining,Fields of study: social media optimizationsocial mediadocument retrievalinternet privacyworld wide webinformation retrievalcomputer science
Beyond basic faceted search,Ori Ben-Yitzhak (IBM)Nadav Golbandi (IBM)Nadav Har'El (IBM)Ronny Lempel (Yahoo!)Andreas Neumann 0001 (IBM)Shila Ofek-Koifman (IBM)Dafna Sheinwald (IBM)Eugene J. Shekita (IBM)Benjamin Sznajder (IBM)Sivan Yogev (IBM),"336983331,2076209129,2161112051,2249016471,2238956578,952679772,97365951,2309335715,2293368318,2154470788","This paper extends traditional faceted search to support richer information discovery tasks over more complex data models. Our first extension adds exible, dynamic business intelligence aggregations to the faceted application, enabling users to gain insight into their data that is far richer than just knowing the quantities of documents belonging to each facet. We see this capability as a step toward bringing OLAP capabilities, traditionally supported by databases over relational data, to the domain of free-text queries over metadata-rich content. Our second extension shows how one can efficiently extend a faceted search engine to support correlated facets - a more complex information model in which the values associated with a document across multiple facets are not independent. We show that by reducing the problem to a recently solved tree-indexing scenario, data with correlated facets can be efficiently indexed and retrieved",2008,Web Search and Data Mining,Fields of study: information modelcomplex data typerelational databasebusiness intelligenceworld wide webinformation retrievaldata miningdatabasecomputer science
GeoFolk: latent spatial semantics in web 2.0 social media,Sergej Sizov (University of Düsseldorf),2619768059,"We describe an approach for multi-modal characterization of social media by combining text features (e.g. tags as a prominent example of short, unstructured text labels) with spatial knowledge (e.g. geotags and coordinates of images and videos). Our model-based framework GeoFolk combines these two aspects in order to construct better algorithms for content management, retrieval, and sharing. The approach is based on multi-modal Bayesian models which allow us to integrate spatial semantics of social media in a well-formed, probabilistic manner. We systematically evaluate the solution on a subset of Flickr data, in characteristic scenarios of tag recommendation, content classification, and clustering. Experimental results show that our method outperforms baseline techniques that are based on one of the aspects alone. The approach described in this contribution can also be used in other domains such as Geoweb retrieval.",2010,Web Search and Data Mining,Fields of study: bayesian inferenceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Balanced label propagation for partitioning massive graphs,Johan Ugander (Cornell University)Lars Backstrom (Facebook),"1992714166,2096207090","Partitioning graphs at scale is a key challenge for any application that involves distributing a graph across disks, machines, or data centers. Graph partitioning is a very well studied problem with a rich literature, but existing algorithms typically can not scale to billions of edges, or can not provide guarantees about partition sizes. In this work we introduce an efficient algorithm, balanced label propagation, for precisely partitioning massive graphs while greedily maximizing edge locality, the number of edges that are assigned to the same shard of a partition. By combining the computational efficiency of label propagation --- where nodes are iteratively relabeled to the same 'label' as the plurality of their graph neighbors --- with the guarantees of constrained optimization --- guiding the propagation by a linear program constraining the partition sizes --- our algorithm makes it practically possible to partition graphs with billions of edges. Our algorithm is motivated by the challenge of performing graph predictions in a distributed system. Because this requires assigning each node in a graph to a physical machine with memory limitations, it is critically necessary to ensure the resulting partition shards do not overload any single machine. We evaluate our algorithm for its partitioning performance on the Facebook social graph, and also study its performance when partitioning Facebook's 'People You May Know' service (PYMK), the distributed system responsible for the feature extraction and ranking of the friends-of-friends of all active Facebook users. In a live deployment, we observed average query times and average network traffic levels that were 50.5% and 37.1% (respectively) when compared to the previous naive random sharding.",2013,Web Search and Data Mining,Fields of study: distance hereditary graphstrength of a graphvoltage graphcomplement graphgraph bandwidththeta graphmultiple edgesmoral graphgraph operationscomparability graphlevel structurenull graphclique widthmodular decompositionmultigraphclustering coefficientindependent setgraph partitionsocial networktheoretical computer sciencedistributed computingmachine learningcomputer science
Personalized entity recommendation: a heterogeneous information network approach,Xiao Yu (University of Illinois at Urbana–Champaign)Xiang Ren (University of Illinois at Urbana–Champaign)Yizhou Sun (Northeastern University)Quanquan Gu (University of Illinois at Urbana–Champaign)Bradley Sturt (University of Illinois at Urbana–Champaign)Urvashi Khandelwal (University of Illinois at Urbana–Champaign)Brandon Norick (University of Illinois at Urbana–Champaign)Jiawei Han (University of Illinois at Urbana–Champaign),"2160715520,2129405715,2131539564,2167348148,2712564201,2223860396,2222819066,2121939561","Among different hybrid recommendation techniques, network-based entity recommendation methods, which utilize user or item relationship information, are beginning to attract increasing attention recently. Most of the previous studies in this category only consider a single relationship type, such as friendships in a social network. In many scenarios, the entity recommendation problem exists in a heterogeneous information network environment. Different types of relationships can be potentially used to improve the recommendation quality. In this paper, we study the entity recommendation problem in heterogeneous information networks. Specifically, we propose to combine heterogeneous relationship information for each user differently and aim to provide high-quality personalized recommendation results using user implicit feedback data and personalized recommendation models. In order to take full advantage of the relationship heterogeneity in information networks, we first introduce meta-path-based latent features to represent the connectivity between users and items along different types of paths. We then define recommendation models at both global and personalized levels and use Bayesian ranking optimization techniques to estimate the proposed models. Empirical studies show that our approaches outperform several widely employed or the state-of-the-art entity recommendation techniques.",2014,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
The life and death of online groups: predicting group growth and longevity,Sanjay Ram Kairam (Stanford University)Dan J. Wang (Stanford University)Jure Leskovec (Stanford University),"2212067359,2426567143,1878631932","We pose a fundamental question in understanding how to identify and design successful communities: What factors predict whether a community will grow and survive in the long term? Social scientists have addressed this question extensively by analyzing offline groups which endeavor to attract new members, such as social movements, finding that new individuals are influenced strongly by their ties to members of the group. As a result, prior work on the growth of communities has treated growth primarily as a diffusion processes, leading to findings about group evolution which can be difficult to explain. The proliferation of online social networks and communities, however, has created new opportunities to study, at a large scale and with very fine resolution, the mechanisms which lead to the formation, growth, and demise of online groups. In this paper, we analyze data from several thousand online social networks built on the Ning platform with the goal of understanding the factors contributing to the growth and longevity of groups within these networks. Specifically, we investigate the role that two types of growth (growth through diffusion and growth by other means) play during a group's formative stages from the perspectives of both the individual member and the group. Applying these insights to a population of groups of different ages and sizes, we build a model to classify groups which will grow rapidly over the short-term and long-term. Our model achieves over 79% accuracy in predicting group growth over the following two months and over 78% accuracy in predictions over the following two years. We utilize a similar approach to predict which groups will die within a year. The results of our combined analysis provide insight into how both early non-diffusion growth and a complex set of network constraints appear to contribute to the initial and continued growth and success of groups within social networks. Finally we discuss implications of this work for the design, maintenance, and analysis of online communities.",2012,Web Search and Data Mining,Fields of study: social networkworld wide websocial sciencesimulation
A comparative analysis of cascade measures for novelty and diversity,Charles L.A. Clarke (University of Waterloo)Nick Craswell (Microsoft)Ian Soboroff (National Institute of Standards and Technology)Azin Ashkan (University of Waterloo),"2098618034,2009495402,2031005049,2075598693","Traditional editorial effectiveness measures, such as nDCG, remain standard for Web search evaluation. Unfortunately, these traditional measures can inappropriately reward redundant information and can fail to reflect the broad range of user needs that can underlie a Web query. To address these deficiencies, several researchers have recently proposed effectiveness measures for novelty and diversity. Many of these measures are based on simple cascade models of user behavior, which operate by considering the relationship between successive elements of a result list. The properties of these measures are still poorly understood, and it is not clear from prior research that they work as intended. In this paper we examine the properties and performance of cascade measures with the goal of validating them as tools for measuring effectiveness. We explore their commonalities and differences, placing them in a unified framework; we discuss their theoretical difficulties and limitations, and compare the measures experimentally, contrasting them against traditional measures and against other approaches to measuring novelty. Data collected by the TREC 2009 Web Track is used as the basis for our experimental comparison. Our results indicate that these measures reward systems that achieve an balance between novelty and overall precision in their result lists, as intended. Nonetheless, other measures provide insights not captured by the cascade measures, and we suggest that future evaluation efforts continue to report a variety of measures.",2011,Web Search and Data Mining,Fields of study: qualitative comparative analysisdata collectionworld wide webdata miningmachine learningsimulationstatistics
Information arbitrage across multi-lingual Wikipedia,Eytan Adar (University of Washington)Michael Skinner (Google)Daniel S. Weld (University of Washington),"2305277957,2306918764,560881892","The rapid globalization of Wikipedia is generating a parallel, multi-lingual corpus of unprecedented scale. Pages for the same topic in many different languages emerge both as a result of manual translation and independent development. Unfortunately, these pages may appear at different times, vary in size, scope, and quality. Furthermore, differential growth rates cause the conceptual mapping between articles in different languages to be both complex and dynamic. These disparities provide the opportunity for a powerful form of information arbitrage --leveraging articles in one or more languages to improve the content in another. Analyzing four large language domains (English, Spanish, French, and German), we present Ziggurat , an automated system for aligning Wikipedia infoboxes, creating new infoboxes as necessary, filling in missing information, and detecting discrepancies between parallel pages. Our method uses self-supervised learning and our experiments demonstrate the method's feasibility, even in the absence of dictionaries.",2009,Web Search and Data Mining,Fields of study: brandtranslationsupervised learningdata sciencenatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
We feel fine and searching the emotional web,Sepandar D. Kamvar (Stanford University)Jonathan Harris (Burlington Coat Factory),"117399983,2711479060","We present We Feel Fine , an emotional search engine and web-based artwork whose mission is to collect the world's emotions to help people better understand themselves and others. We Feel Fine continuously crawls blogs, microblogs, and social networking sites, extracting sentences that include the words ""I feel"" or ""I am feeling"", as well as the gender, age, and location of the people authoring those sentences. The We Feel Fine search interface allows users to search or browse over the resulting sentence-level index, asking questions such as ""How did young people in Ohio feel when Obama was elected?"" While most research in sentiment analysis focuses on algorithms for extraction and classification of sentiment about given topics, we focus instead on building an interface that provides an engaging means of qualitative exploration of emotional data, and a flexible data collection and serving architecture that enables an ecosystem of data analysis applications. We use our observations on the usage of We Feel Fine to suggest a class of visualizations called Experiential Data Visualization, which focus on immersive item-level interaction with data. We also discuss the implications of such visualizations for crowdsourcing qualitative research in the social sciences.",2011,Web Search and Data Mining,Fields of study: social mediasearch enginequalitative researchdata collectiondata analysissentiment analysisdata visualizationinternet privacymultimediaworld wide webinformation retrievaldata miningstatisticscomputer science
A scalable pattern mining approach to web graph compression with communities,Gregory Buehrer (Ohio State University)Kumar Chellapilla (Microsoft),"2224310768,2010097212","A link server is a system designed to support efficient implementations of graph computations on the web graph. In this work, we present a compression scheme for the web graph specifically designed to accommodate community queries and other random access algorithms on link servers. We use a frequent pattern mining approach to extract meaningful connectivity formations. Our Virtual Node Miner achieves graph compression without sacrificing random access by generating virtual nodes from frequent itemsets in vertex adjacency lists. The mining phase guarantees scalability by bounding the pattern mining complexity to O ( E log E ). We facilitate global mining, relaxing the requirement for the graph to be sorted by URL, enabling discovery for both inter-domain as well as intra-domain patterns. As a consequence, the approach allows incremental graph updates. Further, it not only facilitates but can also expedite graph computations such as PageRank and local random walks by implementing them directly on the compressed graph. We demonstrate the effectiveness of the proposed approach on several publicly available large web graph data sets. Experimental results indicate that the proposed algorithm achieves a 10- to 15-fold compression on most real word web graph data sets",2008,Web Search and Data Mining,Fields of study: graph databaserandom geometric graphgraphlink analysisrandom accessrandom walksystems designtheoretical computer scienceworld wide webdata miningdatabasestatisticscomputer science
mTrust: discerning multi-faceted trust in a connected world,Jiliang Tang (Arizona State University)Huiji Gao (Arizona State University)Huan Liu (Arizona State University),"2147392410,2166899337,2122391114","Traditionally, research about trust assumes a single type of trust between users. However, trust, as a social concept, inherently has many facets indicating multiple and heterogeneous trust relationships between users. Due to the presence of a large trust network for an online user, it is necessary to discern multi-faceted trust as there are naturally experts of different types. Our study in product review sites reveals that people place trust differently to different people. Since the widely used adjacency matrix cannot capture multi-faceted trust relationships between users, we propose a novel approach by incorporating these relationships into traditional rating prediction algorithms to reliably estimate their strengths. Our work results in interesting findings such as heterogeneous pairs of reciprocal links. Experimental results on real-world data from Epinions and Ciao show that our work of discerning multi-faceted trust can be applied to improve the performance of tasks such as rating prediction, facet-sensitive ranking, and status theory.",2012,Web Search and Data Mining,Fields of study: computational trustadjacency matrixdata miningartificial intelligence
Topical semantics of twitter links,"Michael J. Welch (Yahoo!)Uri Schonfeld (University of California, Los Angeles)Dan He (University of California, Los Angeles)Junghoo Cho (University of California, Los Angeles)","2139437446,2249234390,2146540756,2167033418","Twitter, a micro-blogging platform with an estimated 20 million unique monthly visitors and over 100 million registered users, offers an abundance of rich, structured data at a rate exceeding 600 tweets per second. Recent efforts to leverage this social data to rank users by quality and topical relevance have largely focused on the ""follow"" relationship. Twitter's data offers additional implicit relationships between users, however, such as ""retweets"" and ""mentions"". In this paper we investigate the semantics of the follow and retweet relationships. Specifically, we show that the transitivity of topical relevance is better preserved over retweet links, and that retweeting a user is a significantly stronger indicator of topical interest than following him. We demonstrate these properties by ranking users with two variants of the PageRank algorithm; one based on the follows sub-graph and one based on the implicit retweet sub-graph. We perform a user study to assess the topical relevance of the resulting top-ranked users.",2011,Web Search and Data Mining,Fields of study: semantic data modelrankingdata modelsystems modelingworld wide webinformation retrievaldata miningcomputer science
A large-scale sentiment analysis for Yahoo! answers,Onur Kucuktunc (Ohio State University)Berkant Barla Cambazoglu (Yahoo!)Ingmar Weber (Yahoo!)Hakan Ferhatosmanoglu (Bilkent University),"301495216,2044137649,2074066684,217414012","Sentiment extraction from online web documents has recently been an active research topic due to its potential use in commercial applications. By sentiment analysis, we refer to the problem of assigning a quantitative positive/negative mood to a short bit of text. Most studies in this area are limited to the identification of sentiments and do not investigate the interplay between sentiments and other factors. In this work, we use a sentiment extraction tool to investigate the influence of factors such as gender, age, education level, the topic at hand, or even the time of the day on sentiments in the context of a large online question answering site. We start our analysis by looking at direct correlations, e.g., we observe more positive sentiments on weekends, very neutral ones in the Science & Mathematics topic, a trend for younger people to express stronger sentiments, or people in military bases to ask the most neutral questions. We then extend this basic analysis by investigating how properties of the (asker, answerer) pair affect the sentiment present in the answer. Among other things, we observe a dependence on the pairing of some inferred attributes estimated by a user's ZIP code. We also show that the best answers differ in their sentiments from other answers, e.g., in the Business & Finance topic, best answers tend to have a more neutral sentiment than other answers. Finally, we report results for the task of predicting the attitude that a question will provoke in answers. We believe that understanding factors influencing the mood of users is not only interesting from a sociological point of view, but also has applications in advertising, recommendation, and search.",2012,Web Search and Data Mining,Fields of study: attitudepredictionsentiment analysisquestion answeringnatural language processingworld wide webinformation retrievaldata miningcomputer science
The web changes everything: understanding the dynamics of web content,Eytan Adar (University of Washington)Jaime Teevan (Microsoft)Susan T. Dumais (Microsoft)Jonathan L. Elsas (Carnegie Mellon University),"2305277957,1982462162,676500258,2132217740","The Web is a dynamic, ever changing collection of information. This paper explores changes in Web content by analyzing a crawl of 55,000 Web pages, selected to represent different user visitation patterns. Although change over long intervals has been explored on random (and potentially unvisited) samples of Web pages, little is known about the nature of finer grained changes to pages that are actively consumed by users, such as those in our sample. We describe algorithms, analyses, and models for characterizing changes in Web content, focusing on both time (by using hourly and sub-hourly crawls) and structure (by looking at page-, DOM-, and term-level changes). Change rates are higher in our behavior-based sample than found in previous work on randomly sampled pages, with a large portion of pages changing more than hourly. Detailed content and structure analyses identify stable and dynamic content within each page. The understanding of Web change we develop in this paper has implications for tools designed to help people interact with dynamic Web content, such as search engines, advertising, and Web browsers.",2009,Web Search and Data Mining,Fields of study: web 2 0website parse templateweb analyticsstatic web pagesite mapweb mappingmashupweb designdynamic web pageweb navigationweb serviceweb pagesearch engineweb mininghuman factors and ergonomicsmultimediaworld wide webinformation retrievaldata miningcomputer science
Pairwise ranking aggregation in a crowdsourced setting,Xi Chen (Carnegie Mellon University)Paul N. Bennett (Microsoft)Kevyn Collins-Thompson (Microsoft)Eric Horvitz (Microsoft),"2585528910,2137013502,2088682983,1970391018","Inferring rankings over elements of a set of objects, such as documents or images, is a key learning problem for such important applications as Web search and recommender systems. Crowdsourcing services provide an inexpensive and efficient means to acquire preferences over objects via labeling by sets of annotators. We propose a new model to predict a gold-standard ranking that hinges on combining pairwise comparisons via crowdsourcing. In contrast to traditional ranking aggregation methods, the approach learns about and folds into consideration the quality of contributions of each annotator. In addition, we minimize the cost of assessment by introducing a generalization of the traditional active learning scenario to jointly select the annotator and pair to assess while taking into account the annotator quality, the uncertainty over ordering of the pair, and the current model uncertainty. We formalize this as an active learning strategy that incorporates an exploration-exploitation tradeoff and implement it using an efficient online Bayesian updating scheme. Using simulated and real-world data, we demonstrate that the active learning strategy achieves significant reductions in labeling cost while maintaining accuracy.",2013,Web Search and Data Mining,Fields of study: crowdsourcingrankingdata scienceworld wide webdata miningmachine learningstatisticscomputer science
From chatter to headlines: harnessing the real-time web for personalized news recommendation,Gianmarco De Francisci Morales (IMT Institute for Advanced Studies Lucca)Aristides Gionis (Yahoo!)Claudio Lucchese (Istituto di Scienza e Tecnologie dell'Informazione),"2153118160,737311942,1989507918","We propose a new methodology for recommending interesting news to users by exploiting the information in their twitter persona. We model relevance between users and news articles using a mix of signals drawn from the news stream and from twitter: the profile of the social neighborhood of the users, the content of their own tweet stream, and topic popularity in the news and in the whole twitter-land. We validate our approach on a real-world dataset of approximately 40k articles coming from Yahoo! News and one month of crawled twitter data. We train our model using a learning-to-rank approach and support-vector machines. The train and test set are drawn from Yahoo! toolbar log data. We heuristically identify 3214 users of twitter in the log and use their clicks on news articles to train our system. Our methodology is able to predict with good accuracy the news articles clicked by the users and rank them higher than other news articles. The results show that the combination of various signals from real-time Web and micro-blogging platforms can be a useful resource to understand user behavior.",2012,Web Search and Data Mining,Fields of study: news aggregatorpersonalizationsupport vector machinerecommender systeminternet privacymultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
On ranking controversies in wikipedia: models and evaluation,Ba-Quy Vuong (Nanyang Technological University)Ee-Peng Lim (Nanyang Technological University)Aixin Sun (Nanyang Technological University)Minh-Tam Le (Nanyang Technological University)Hady Wirawan Lauw (Nanyang Technological University)Kuiyu Chang (Nanyang Technological University),"2157586039,2136050841,2124989948,2163062760,2024254804,2147346151","Wikipedia 1 is a very large and successful Web 2.0 example. As the number of Wikipedia articles and contributors grows at a very fast pace, there are also increasing disputes occurring among the contributors. Disputes often happen in articles with controversial content. They also occur frequently among contributors who are ""aggressive"" or controversial in their personalities. In this paper, we aim to identify controversial articles in Wikipedia. We propose three models, namely the Basic model and two Controversy Rank ( CR ) models. These models draw clues from collaboration and edit history instead of interpreting the actual articles or edited content. While the Basic model only considers the amount of disputes within an article, the two Controversy Rank models extend the former by considering the relationships between articles and contributors. We also derived enhanced versions of these models by considering the age of articles. Our experiments on a collection of 19,456 Wikipedia articles shows that the Controversy Rank models can more effectively determine controversial articles compared to the Basic and other baseline models",2008,Web Search and Data Mining,Fields of study: branddata scienceworld wide webinformation retrievalsocial sciencedata miningcomputer science
Query reformulation using anchor text,Van Dang (University of Massachusetts Amherst)Bruce W. Croft (University of Massachusetts Amherst),"2160214997,2134251575","Query reformulation techniques based on query logs have been studied as a method of capturing user intent and improving retrieval effectiveness. The evaluation of these techniques has primarily, however, focused on proprietary query logs and selected samples of queries. In this paper, we suggest that anchor text, which is readily available, can be an effective substitute for a query log and study the effectiveness of a range of query reformulation techniques (including log-based stemming, substitution, and expansion) using standard TREC collections. Our results show that log-based query reformulation techniques are indeed effective with standard collections, but expansion is a much safer form of query modification than word substitution. We also show that using anchor text as a simulated query log is as least as effective as a real log for these techniques.",2010,Web Search and Data Mining,Fields of study: sargablerankingrdf query languageboolean conjunctive queryonline aggregationweb search queryweb query classificationspatial queryanchor textquery by examplequery expansionquery optimizationquery languageworld wide webinformation retrievaldatabasecomputer science
Identifying task-based sessions in search engine query logs,Claudio Lucchese (Istituto di Scienza e Tecnologie dell'Informazione)Salvatore Orlando (Ca' Foscari University of Venice)Raffaele Perego (Istituto di Scienza e Tecnologie dell'Informazione)Fabrizio Silvestri (Istituto di Scienza e Tecnologie dell'Informazione)Gabriele Tolomei (Istituto di Scienza e Tecnologie dell'Informazione),"1989507918,2109622093,1650486011,2134079936,2103603267","The research challenge addressed in this paper is to devise effective techniques for identifying task-based sessions , i.e. sets of possibly non contiguous queries issued by the user of a Web Search Engine for carrying out a given task . In order to evaluate and compare different approaches, we built, by means of a manual labeling process, a ground-truth where the queries of a given query log have been grouped in tasks. Our analysis of this ground-truth shows that users tend to perform more than one task at the same time, since about 75% of the submitted queries involve a multi-tasking activity. We formally define the Task-based Session Discovery Problem (TSDP) as the problem of best approximating the manually annotated tasks, and we propose several variants of well known clustering algorithms, as well as a novel efficient heuristic algorithm, specifically tuned for solving the TSDP. These algorithms also exploit the collaborative knowledge collected by Wiktionary and Wikipedia for detecting query pairs that are not similar from a lexical content point of view, but actually semantically related. The proposed algorithms have been evaluated on the above ground-truth, and are shown to perform better than state-of-the-art approaches, because they effectively take into account the multi-tasking behavior of users.",2011,Web Search and Data Mining,Fields of study: sargableweb search queryweb query classificationquery expansionquery optimizationground truthquery languageheuristicsearch engineweb search engineworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Anatomy of the long tail: ordinary people with extraordinary tastes,Sharad Goel (Yahoo!)Andrei Z. Broder (Yahoo!)Evgeniy Gabrilovich (Yahoo!)Bo Pang (Yahoo!),"2148409872,2637163715,1804802447,2129095822","The success of ""infinite-inventory"" retailers such as Amazon.com and Netflix has been ascribed to a ""long tail"" phenomenon. To wit, while the majority of their inventory is not in high demand, in aggregate these ""worst sellers,"" unavailable at limited-inventory competitors, generate a significant fraction of total revenue. The long tail phenomenon, however, is in principle consistent with two fundamentally different theories. The first, and more popular hypothesis, is that a majority of consumers consistently follow the crowds and only a minority have any interest in niche content; the second hypothesis is that everyone is a bit eccentric, consuming both popular and specialty products. Based on examining extensive data on user preferences for movies, music, Web search, and Web browsing, we find overwhelming support for the latter theory. However, the observed eccentricity is much less than what is predicted by a fully random model whereby every consumer makes his product choices independently and proportional to product popularity; so consumers do indeed exhibit at least some a priori propensity toward either the popular or the exotic. Our findings thus suggest an additional factor in the success of infinite-inventory retailers, namely, that tail availability may boost head sales by offering consumers the convenience of ""one-stop shopping"" for both their mainstream and niche interests. This hypothesis is further supported by our theoretical analysis that presents a simple model in which shared inventory stores, such as Amazon Marketplace, gain a clear advantage by satisfying tail demand, helping to explain the emergence and increasing popularity of such retail arrangements. Hence, we believe that the return-on-investment (ROI) of niche products goes beyond direct revenue, extending to second-order gains associated with increased consumer satisfaction and repeat patronage. More generally, our findings call into question the conventional wisdom that specialty products only appeal to a minority of consumers.",2010,Web Search and Data Mining,Fields of study: return on investmentlong tailsecond order logicsatisfiabilityworld wide webdata miningcomputer science
Query by document,Yin Yang (Hong Kong University of Science and Technology)Nilesh Bansal (University of Toronto)Wisam Dakka (Google)Panagiotis G. Ipeirotis (New York University)Nick Koudas (University of Toronto)Dimitris Papadias (Hong Kong University of Science and Technology),"2280962535,2117826507,293694482,94049422,335443309,2243308922","We are experiencing an unprecedented increase of content contributed by users in forums such as blogs, social networking sites and microblogging services. Such abundance of content complements content on web sites and traditional media forums such as news papers, news and financial streams, and so on. Given such plethora of information there is a pressing need to cross reference information across textual services. For example, commonly we read a news item and we wonder if there are any blogs reporting related content or vice versa. In this paper, we present techniques to automate the process of cross referencing online information content. We introduce methodologies to extract phrases from a given "" query document "" to be used as queries to search interfaces with the goal to retrieve content related to the query document. In particular, we consider two techniques to extract and score key phrases. We also consider techniques to complement extracted phrases with information present in external sources such as Wikipedia and introduce an algorithm called RelevanceRank for this purpose. We discuss both these techniques in detail and provide an experimental study utilizing a large number of human judges from Amazons's Mechanical Turk service. Detailed experiments demonstrate the effectiveness and efficiency of the proposed techniques for the task of automating retrieval of documents related to a query document.",2009,Web Search and Data Mining,Fields of study: web 2 0web query classificationbrandself informationmultimediaworld wide webinformation retrievaldata miningstatisticscomputer science
Classifying tags using open content resources,Simon E. Overell (Imperial College London)Börkur Sigurbjörnsson (Yahoo!)Roelof van Zwol (Yahoo!),"222333427,2142176234,281648438","Tagging has emerged as a popular means to annotate on-line objects such as bookmarks, photos and videos. Tags vary in semantic meaning and can describe different aspects of a media object. Tags describe the content of the media as well as locations, dates, people and other associated meta-data. Being able to automatically classify tags into semantic categories allows us to understand better the way users annotate media objects and to build tools for viewing and browsing the media objects. In this paper we present a generic method for classifying tags using third party open content resources, such as Wikipedia and the Open Directory. Our method uses structural patterns that can be extracted from resource meta-data. We describe the implementation of our method on Wikipedia using WordNet categories as our classification schema and ground truth. Two structural patterns found in Wikipedia are used for training and classification: categories and templates. We apply our system to classifying Flickr tags. Compared to a WordNet baseline our method increases the coverage of the Flickr vocabulary by 115%. We can classify many important entities that are not covered by WordNet, such as, London Eye, Big Island, Ronaldinho, geocaching and wii .",2009,Web Search and Data Mining,Fields of study: open contentbranduser generated contentground truthcategorizationworld wide webinformation retrievaldata miningcomputer science
"Daily deals: prediction, social diffusion, and reputational ramifications",John W. Byers (Boston University)Michael Mitzenmacher (Harvard University)Georgios Zervas (Yale University),"2101152111,1988080645,2080016373","Daily deal sites have become the latest Internet sensation, providing discounted offers to customers for restaurants, ticketed events, services, and other items. We begin by undertaking a study of the economics of daily deals on the web, based on a dataset we compiled by monitoring Groupon and LivingSocial sales in 20 large cities over several months. We use this dataset to characterize deal purchases; glean insights about operational strategies of these firms; and evaluate customers' sensitivity to factors such as price, deal scheduling, and limited inventory. We then marry our daily deals dataset with additional datasets we compiled from Facebook and Yelp users to study the interplay between social networks and daily deal sites. First, by studying user activity on Facebook while a deal is running, we provide evidence that daily deal sites benefit from significant word-of-mouth effects during sales events, consistent with results predicted by cascade models. Second, we consider the effects of daily deals on the longer-term reputation of merchants, based on their Yelp reviews before and after they run a daily deal. Our analysis shows that while the number of reviews increases significantly due to daily deals, average rating scores from reviewers who mention daily deals are 10% lower than scores of their peers on average.",2012,Web Search and Data Mining,Fields of study: reputationword of mouthsocial networkworld wide websocial science
Quantifying Controversy in Social Media,Kiran Garimella (Aalto University)Gianmarco De Francisci Morales (Aalto University)Aristides Gionis (Aalto University)Michael Mathioudakis (University of Toronto),"1979823234,2153118160,737311942,2085699011","Which topics spark the most heated debates in social media? Identifying these topics is a first step towards creating systems which pierce echo chambers. In this paper, we perform a systematic methodological study of controversy detection using social media network structure and content. Unlike previous work, rather than identifying controversy in a single hand-picked topic and use domain-specific knowledge, we focus on comparing topics in any domain. Our approach to quantifying controversy is a graph-based three-stage pipeline, which involves (i) building a conversation graph about a topic, which represents alignment of opinion among users; (ii) partitioning the conversation graph to identify potential sides of the controversy; and (iii)measuring the amount of controversy from characteristics of the~graph. We perform an extensive comparison of controversy measures, as well as graph building approaches and data sources. We use both controversial and non-controversial topics on Twitter, as well as other external datasets. We find that our new random-walk-based measure outperforms existing ones in capturing the intuitive notion of controversy, and show that content features are vastly less helpful in this task.",2016,Web Search and Data Mining,Fields of study: social mediarandom walksocial psychologyworld wide webdata miningartificial intelligencestatisticscomputer sciencemathematics
Advertising keyword suggestion based on concept hierarchy,Yifan Chen (Shanghai Jiao Tong University)Gui-Rong Xue (Shanghai Jiao Tong University)Yong Yu (Shanghai Jiao Tong University),"2677025521,2167947354,2119244895","The increasing growth of the World Wide Web constantly enlarges the revenue generated by search engine advertising. Advertisers bid on keywords associated with their products to display their ads on the search result pages. Keyword suggestion methods are proposed to fill the gap between the keywords chosen by advertisers and the popular queries, through finding new relevant keywords according to some statistical information (for example, the keyword co-occurrence). However, there is little effort taking semantic information, such as concept hierarchy, into account. In this paper, we propose a novel keyword suggestion method that fully exploits the semantic knowledge among concept hierarchy. Given a keyword, we first match it with some relevant concepts. Then the relevant concepts are used with their hierarchy to fertilize the meanings of the keywords. Finally new keywords are suggested according to the concept information rather than the statistical co-occurrence of the keyword itself. Experimental results show that our proposed method can successfully provide suggestion that meets the accuracy and coverage requirements",2008,Web Search and Data Mining,Fields of study: keyword densitykeyword advertisingsearch engineworld wide webinformation retrievaldata miningcomputer science
Mining the web to predict future events,Kira Radinsky (Technion – Israel Institute of Technology)Eric Horvitz (Microsoft),"1780829609,1970391018","We describe and evaluate methods for learning to forecast forthcoming events of interest from a corpus containing 22 years of news stories. We consider the examples of identifying significant increases in the likelihood of disease outbreaks, deaths, and riots in advance of the occurrence of these events in the world. We provide details of methods and studies, including the automated extraction and generalization of sequences of events from news corpora and multiple web resources. We evaluate the predictive power of the approach on real-world events withheld from the system.",2013,Web Search and Data Mining,Fields of study: data scienceworld wide webdata mining
Correcting for missing data in information cascades,Eldar Sadikov (Stanford University)Montserrat Medina (Stanford University)Jure Leskovec (Stanford University)Hector Garcia-Molina (Stanford University),"1993458034,2222609063,1878631932,237419955","Transmission of infectious diseases, propagation of information, and spread of ideas and influence through social networks are all examples of diffusion. In such cases we say that a contagion spreads through the network, a process that can be modeled by a cascade graph. Studying cascades and network diffusion is challenging due to missing data. Even a single missing observation in a sequence of propagation events can significantly alter our inferences about the diffusion process. We address the problem of missing data in information cascades. Specifically, given only a fraction C' of the complete cascade C, our goal is to estimate the properties of the complete cascade C, such as its size or depth. To estimate the properties of C, we first formulate k-tree model of cascades and analytically study its properties in the face of missing data. We then propose a numerical method that given a cascade model and observed cascade C' can estimate properties of the complete cascade C. We evaluate our methodology using information propagation cascades in the Twitter network (70 million nodes and 2 billion edges), as well as information cascades arising in the blogosphere. Our experiments show that the k-tree model is an effective tool to study the effects of missing data in cascades. Most importantly, we show that our method (and the k-tree model) can accurately estimate properties of the complete cascade C even when 90% of the data is missing.",2011,Web Search and Data Mining,Fields of study: social networknumerical analysisinfectious diseasedata miningstatisticscomputer science
Large scale query log analysis of re-finding,"Sarah K. Tyler (University of California, Santa Cruz)Jaime Teevan (Microsoft)","2153562969,1982462162","Although Web search engines are targeted towards helping people find new information, people regularly use them to re-find Web pages they have seen before. Researchers have noted the existence of this phenomenon, but relatively little is understood about how re-finding behavior differs from the finding of new information. This paper dives deeply into the differences via analysis of three large-scale data sources: 1) query logs (queries, clicks, result impressions), 2) Web browsing logs (URL visits), and 3) a daily Web crawl (page content). It appears that people learn valuable information about the pages they find that helps them re-find what they are looking for later; compared to the initial finding query, re-finding queries are typically shorter, and rank the re-found URL higher. While many instances of re-finding probably serve as a type of bookmark for a known URL, others seem to represent the resumption of a previous task; results clicked at the end of a session are more likely than those at the beginning to be re-found during a later session, while re-finding is more likely to happen at the beginning of a session than at the end. Additionally, we observe differences in cross-session and intra-session re-finding that may indicate different types of re-finding tasks. Our findings suggest there is a rich opportunity for search engines to take advantage of re-finding behavior as a means to improve the search experience.",2010,Web Search and Data Mining,Fields of study: semantic urlweb analyticssite mapweb search queryweb query classificationweb crawlerquery expansionweb pagesearch engineweb search engineworld wide webinformation retrievaldata miningdatabasecomputer science
Effects of user similarity in social media,Ashton Anderson (Stanford University)Daniel P. Huttenlocher (Cornell University)Jon M. Kleinberg (Cornell University)Jure Leskovec (Stanford University),"2155788867,677134955,2261367123,1878631932","There are many settings in which users of a social media application provide evaluations of one another. In a variety of domains, mechanisms for evaluation allow one user to say whether he or she trusts another user, or likes the content they produced, or wants to confer special levels of authority or responsibility on them. Earlier work has studied how the relative status between two users - that is, their comparative levels of status in the group - affects the types of evaluations that one user gives to another. Here we study how similarity in the characteristics of two users can affect the evaluation one user provides of another. We analyze this issue under a range of natural similarity measures, showing how the interaction of similarity and status can produce strong effects. Among other consequences, we find that evaluations are less status-driven when users are more similar to each other; and we use effects based on similarity to provide a plausible mechanism for a complex phenomenon observed in studies of user evaluation, that evaluations are particularly low among users of roughly equal status. Our work has natural applications to the prediction of evaluation outcomes based on user characteristics, and the use of similarity information makes possible a novel application that we introduce here - to estimate the chance of a favorable overall evaluation from a group knowing only the attributes of the group's members, but not their expressed opinions.",2012,Web Search and Data Mining,Fields of study: computer user satisfactionsocial mediauser modelinginternet privacyworld wide webcomputer science
Learning evolving and emerging topics in social media: a dynamic nmf approach with temporal regularization,Ankan Saha (University of Chicago)Vikas Sindhwani (IBM),"2121457248,281476361","As massive repositories of real-time human commentary, social media platforms have arguably evolved far beyond passive facilitation of online social interactions. Rapid analysis of information content in online social media streams (news articles, blogs,tweets etc.) is the need of the hour as it allows business and government bodies to understand public opinion about products and policies. In most of these settings, data points appear as a stream of high dimensional feature vectors. Guided by real-world industrial deployment scenarios, we revisit the problem of online learning of topics from streaming social media content. On one hand, the topics need to be dynamically adapted to the statistics of incoming datapoints, and on the other hand, early detection of rising new trends is important in many applications. We propose an online nonnegative matrix factorizations framework to capture the evolution and emergence of themes in unstructured text under a novel temporal regularization framework. We develop scalable optimization algorithms for our framework, propose a new set of evaluation metrics, and report promising empirical results on traditional TDT tasks as well as streaming Twitter data. Our system is able to rapidly capture emerging themes, track existing topics over time while maintaining temporal consistency and continuity in user views, and can be explicitly configured to bound the amount of information being presented to the user.",2012,Web Search and Data Mining,Fields of study: non negative matrix factorizationsocial relationdata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Linking online news and social media,Manos Tsagkias (University of Amsterdam)Maarten de Rijke (University of Amsterdam)Wouter Weerkamp (University of Amsterdam),"207528511,401833296,197647246","Much of what is discussed in social media is inspired by events in the news and, vice versa, social media provide us with a handle on the impact of news events. We address the following linking task: given a news article, find social media utterances that implicitly reference it. We follow a three-step approach: we derive multiple query models from a given source news article, which are then used to retrieve utterances from a target social media index, resulting in multiple ranked lists that we then merge using data fusion techniques. Query models are created by exploiting the structure of the source article and by using explicitly linked social media utterances that discuss the source article. To combat query drift resulting from the large volume of text, either in the source news article itself or in social media utterances explicitly linked to it, we introduce a graph-based method for selecting discriminative terms. For our experimental evaluation, we use data from Twitter, Digg, Delicious, the New York Times Community, Wikipedia, and the blogosphere to generate query models. We show that different query models, based on different data sources, provide complementary information and manage to retrieve different social media utterances from our target index. As a consequence, data fusion methods manage to significantly boost retrieval performance over individual approaches. Our graph-based term selection method is shown to help improve both effectiveness and efficiency.",2011,Web Search and Data Mining,Fields of study: social mediauser generated contentworld wide webinformation retrievaldata miningmachine learningcomputer science
"Characterizing and curating conversation threads: expansion, focus, volume, re-entry",Lars Backstrom (Facebook)Jon M. Kleinberg (Cornell University)Lillian Lee (Cornell University)Cristian Danescu-Niculescu-Mizil (Stanford University),"2096207090,2261367123,2124867291,160157097","Discussion threads form a central part of the experience on many Web sites, including social networking sites such as Facebook and Google Plus and knowledge creation sites such as Wikipedia. To help users manage the challenge of allocating their attention among the discussions that are relevant to them, there has been a growing need for the algorithmic curation of on-line conversations --- the development of automated methods to select a subset of discussions to present to a user. Here we consider two key sub-problems inherent in conversational curation: length prediction --- predicting the number of comments a discussion thread will receive --- and the novel task of re-entry prediction --- predicting whether a user who has participated in a thread will later contribute another comment to it. The first of these sub-problems arises in estimating how interesting a thread is, in the sense of generating a lot of conversation; the second can help determine whether users should be kept notified of the progress of a thread to which they have already contributed. We develop and evaluate a range of approaches for these tasks, based on an analysis of the network structure and arrival pattern among the participants, as well as a novel dichotomy in the structure of long threads. We find that for both tasks, learning-based approaches using these sources of information.",2013,Web Search and Data Mining,Fields of study: branduser generated contentsocial networkmultimediaworld wide websocial sciencedata miningmachine learningcomputer science
Early exit optimizations for additive machine learned ranking systems,Berkant Barla Cambazoglu (Yahoo!)Hugo Zaragoza (Yahoo!)Olivier Chapelle (Yahoo!)Jiang Chen (Yahoo!)Ciya Liao (Yahoo!)Zhaohui Zheng (Yahoo!)Jon Degenhardt (Yahoo!),"2044137649,2123875642,2049499784,2682956572,2146812112,2089011938,2224498565","Some commercial web search engines rely on sophisticated machine learning systems for ranking web documents. Due to very large collection sizes and tight constraints on query response times, online efficiency of these learning systems forms a bottleneck. An important problem in such systems is to speedup the ranking process without sacrificing much from the quality of results. In this paper, we propose optimization strategies that allow short-circuiting score computations in additive learning systems. The strategies are evaluated over a state-of-the-art machine learning system and a large, real-life query log, obtained from Yahoo!. By the proposed strategies, we are able to speedup the score computations by more than four times with almost no loss in result quality.",2010,Web Search and Data Mining,Fields of study: rankingranking svmweb search queryweb query classificationactive learningweb search engineworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Co-factorization machines: modeling user interests and predicting individual decisions in Twitter,Liangjie Hong (Lehigh University)Aziz S. Doumith (Lehigh University)Brian D. Davison (Lehigh University),"2152948077,2222499424,2203702053","Users of popular services like Twitter and Facebook are often simultaneously overwhelmed with the amount of information delivered via their social connections and miss out on much content that they might have liked to see, even though it was distributed outside of their social circle. Both issues serve as difficulties to the users and drawbacks to the services. Social media service providers can benefit from understanding user interests and how they interact with the service, potentially predicting their behaviors in the future. In this paper, we address the problem of simultaneously predicting user decisions and modeling users' interests in social media by analyzing rich information gathered from Twitter. The task differs from conventional recommender systems as the cold-start problem is ubiquitous, and rich features, including textual content, need to be considered. We build predictive models for user decisions in Twitter by proposing Co-Factorization Machines (CoFM), an extension of a state-of-the-art recommendation model, to handle multiple aspects of the dataset at the same time. Additionally, we discuss and compare ranking-based loss functions in the context of recommender systems, providing the first view of how they vary from each other and perform in real tasks. We explore an extensive set of features and conduct experiments on a real-world dataset, concluding that CoFM with ranking-based loss functions is superior to state-of-the-art methods and yields interpretable latent factors.",2013,Web Search and Data Mining,Fields of study: collaborative filteringrecommender systeminternet privacyworld wide webinformation retrievaldata miningmachine learningcomputer science
Multi-dimensional search result diversification,Zhicheng Dou (Microsoft)Sha Hu (Renmin University of China)Kun Chen (Xi'an Jiaotong University)Ruihua Song (Microsoft)Ji-Rong Wen (Microsoft),"2330149811,2158724505,2722323375,2163477531,2066159008","Most existing search result diversification algorithms diversify search results in terms of a specific dimension. In this paper, we argue that search results should be diversified in a multi-dimensional way, as queries are usually ambiguous at different levels and dimensions. We first explore mining subtopics from four types of data sources, including anchor texts, query logs, search result clusters, and web sites. Then we propose a general framework that explicitly diversifies search results based on multiple dimensions of subtopics. It balances the relevance of documents with respect to the query and the novelty of documents by measuring the coverage of subtopics. Experimental results on the TREC 2009 Web track dataset indicate that combining multiple types of subtopics do help better understand user intents. By incorporating multiple types of subtopics, our models improve the diversity of search results over the sole use of one of them, and outperform two state-of-the-art models.",2011,Web Search and Data Mining,Fields of study: web search queryanchor textworld wide webinformation retrievaldata miningcomputer science
A peek into the future: predicting the evolution of popularity in user generated content,Mohamed Ahmed (NEC)Stella Spagna (University of Pisa)Felipe Huici (NEC)Saverio Niccolini (NEC),"2099801935,2020990846,2169722657,255116046","Content popularity prediction finds application in many areas, including media advertising, content caching, movie revenue estimation, traffic management and macro-economic trends forecasting, to name a few. However, predicting this popularity is difficult due to, among others, the effects of external phenomena, the influence of context such as locality and relevance to users,and the difficulty of forecasting information cascades. In this paper we identify patterns of temporal evolution that are generalisable to distinct types of data, and show that we can (1) accurately classify content based on the evolution of its popularity over time and (2) predict the value of the content's future popularity. We verify the generality of our method by testing it on YouTube, Digg and Vimeo data sets and find our results to outperform the K-Means baseline when classifying the behaviour of content and the linear regression baseline when predicting its popularity.",2013,Web Search and Data Mining,Fields of study: social mediainternet privacyworld wide webdata miningcomputer science
Geo topic model: joint modeling of user's activity area and interests for location recommendation,Takeshi Kurashima (Nippon Telegraph and Telephone)Tomoharu Iwata (Nippon Telegraph and Telephone)Takahide Hoshide (Nippon Telegraph and Telephone)Noriko Takaya (Nippon Telegraph and Telephone)Ko Fujimura (Nippon Telegraph and Telephone),"2090365413,2108993706,2055638161,2584052289,2164460727","This paper proposes a method that analyzes the location log data of multiple users to recommend locations to be visited. The method uses our new topic model, called Geo Topic Model, that can jointly estimate both the user's interests and activity area hosting the user's home, office and other personal places. By explicitly modeling geographical features of locations and users, the user's interests in other features of locations, which we call latent topics, can be inferred effectively. The topic interests estimated by our model 1) lead to high accuracy in predicting visit behavior as driven by personal interests, 2) make possible the generation of recommendations when the user is in an unfamiliar area (e.g. sightseeing), and 3) enable the recommender system to suggest an interpretable representation of the user profile that can be customized by the user. Experiments are conducted using real location logs of landmark and restaurant visits to evaluate the recommendation performance of the proposed method in terms of the accuracy of predicting visit selections. We also show that our model can estimate latent features of locations such as art, nature and atmosphere as latent topics, and describe each user's preference based on them.",2013,Web Search and Data Mining,Fields of study: topic modelworld wide webinformation retrievaldata miningmachine learningcomputer science
Topical clustering of search results,Ugo Scaiella (University of Pisa)Paolo Ferragina (University of Pisa)Andrea Marino (University of Florence)Massimiliano Ciaramita (Google),"326820196,531878810,2124718556,2226821684","Search results clustering (SRC) is a challenging algorithmic problem that requires grouping together the results returned by one or more search engines in topically coherent clusters, and labeling the clusters with meaningful phrases describing the topics of the results included in them. In this paper we propose to solve SRC via an innovative approach that consists of modeling the problem as the labeled clustering of the nodes of a newly introduced graph of topics . The topics are Wikipedia-pages identified by means of recently proposed topic annotators [9, 11, 16, 20] applied to the search results, and the edges denote the relatedness among these topics computed by taking into account the linkage of the Wikipedia-graph. We tackle this problem by designing a novel algorithm that exploits the spectral properties and the labels of that graph of topics. We show the superiority of our approach with respect to academic state-of-the-art work [6] and well-known commercial systems (CLUSTY and LINGO3G) by performing an extensive set of experiments on standard datasets and user studies via Amazon Mechanical Turk. We test several standard measures for evaluating the performance of all systems and show a relative improvement of up to 20%.",2012,Web Search and Data Mining,Fields of study: correlation clusteringspectral clusteringfuzzy clusteringsearch engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Probabilistic models for personalizing web search,David Sontag (New York University)Kevyn Collins-Thompson (Microsoft)Paul N. Bennett (Microsoft)Ryen W. White (Microsoft)Susan T. Dumais (Microsoft)Bodo Billerbeck (Microsoft),"2138531792,2088682983,2137013502,2096583854,676500258,2076708895","We present a new approach for personalizing Web search results to a specific user. Ranking functions for Web search engines are typically trained by machine learning algorithms using either direct human relevance judgments or indirect judgments obtained from click-through data from millions of users. The rankings are thus optimized to this generic population of users, not to any specific user. We propose a generative model of relevance which can be used to infer the relevance of a document to a specific user for a search query. The user-specific parameters of this generative model constitute a compact user profile. We show how to learn these profiles from a user's long-term search history. Our algorithm for computing the personalized ranking is simple and has little computational overhead. We evaluate our personalization approach using historical search data from thousands of users of a major Web search engine. Our findings demonstrate gains in retrieval performance for queries with high ambiguity, with particularly large improvements for acronym queries.",2012,Web Search and Data Mining,Fields of study: rankingsearch analyticsokapi bm25web search querypersonalizationsearch enginestatistical modelsemantic searchmetasearch engineweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Multi-relational matrix factorization using bayesian personalized ranking for social network data,Artus Krohn-Grimberghe (University of Hildesheim)Lucas Drumond (University of Hildesheim)Christoph Freudenthaler (University of Hildesheim)Lars Schmidt-Thieme (University of Hildesheim),"188349725,2103850662,2043953584,78243962","A key element of the social networks on the internet such as Facebook and Flickr is that they encourage users to create connections between themselves, other users and objects. One important task that has been approached in the literature that deals with such data is to use social graphs to predict user behavior (e.g. joining a group of interest). More specifically, we study the cold-start problem, where users only participate in some relations, which we will call social relations, but not in the relation on which the predictions are made, which we will refer to as target relations. We propose a formalization of the problem and a principled approach to it based on multi-relational factorization techniques. Furthermore, we derive a principled feature extraction scheme from the social data to extract predictors for a classifier on the target relation. Experiments conducted on real world datasets show that our approach outperforms current methods.",2012,Web Search and Data Mining,Fields of study: cold startrankingmatrix decompositionsocial networkfeature extractionrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Improving the sensitivity of online controlled experiments by utilizing pre-experiment data,Alex Deng (Microsoft)Ya Xu (Microsoft)Ron Kohavi (Microsoft)Toby Walker (Microsoft),"2172042952,2310280520,73615348,2623983410","Online controlled experiments are at the heart of making data-driven decisions at a diverse set of companies, including Amazon, eBay, Facebook, Google, Microsoft, Yahoo, and Zynga. Small differences in key metrics, on the order of fractions of a percent, may have very significant business implications. At Bing it is not uncommon to see experiments that impact annual revenue by millions of dollars, even tens of millions of dollars, either positively or negatively. With thousands of experiments being run annually, improving the sensitivity of experiments allows for more precise assessment of value, or equivalently running the experiments on smaller populations (supporting more experiments) or for shorter durations (improving the feedback cycle and agility). We propose an approach (CUPED) that utilizes data from the pre-experiment period to reduce metric variability and hence achieve better sensitivity. This technique is applicable to a wide variety of key business metrics, and it is practical and easy to implement. The results on Bing's experimentation system are very successful: we can reduce variance by about 50%, effectively achieving the same statistical power with only half of the users, or half the duration.",2013,Web Search and Data Mining,Fields of study: variancesensitivitypowerworld wide webdata miningsimulationstatistics
Preferential behavior in online groups,Lars Backstrom (Cornell University)Ravi Kumar (Yahoo!)Cameron Marlow (Yahoo!)Jasmine Novak (Yahoo!)Andrew Tomkins (Yahoo!),"2096207090,2232709231,2106254705,2130548382,2130754085","Online communities in the form of message boards, listservs, and newsgroups continue to represent a considerable amount of the social activity on the Internet. Every year thousands of groups ourish while others decline into relative obscurity; likewise, millions of members join a new community every year, some of whom will come to manage or moderate the conversation while others simply sit by the sidelines and observe. These processes of group formation, growth, and dissolution are central in social science, and in an online venue they have ramifications for the design and development of community software In this paper we explore a large corpus of thriving online communities. These groups vary widely in size, moderation and privacy, and cover an equally diverse set of subject matter. We present a broad range of descriptive statistics of these groups. Using metadata from groups, members, and individual messages, we identify users who post and are replied-to frequently by multiple group members; we classify these high-engagement users based on the longevity of their engagements. We show that users who will go on to become long-lived, highly-engaged users experience significantly better treatment than other users from the moment they join the group, well before there is an opportunity for them to develop a long-standing relationship with members of the group We present a simple model explaining long-term heavy engagement as a combination of user-dependent and group-dependent factors. Using this model as an analytical tool, we show that properties of the user alone are sufficient to explain 95% of all memberships, but introducing a small amount of per-group information dramatically improves our ability to model users belonging to multiple groups.",2008,Web Search and Data Mining,Fields of study: social networkuser experience designworld wide websocial sciencedata mining
Quality-aware collaborative question answering: methods and evaluation,Maggy Anastasia Suryanto (Nanyang Technological University)Ee Peng Lim (Singapore Management University)Aixin Sun (Nanyang Technological University)Roger Hsiang-Li Chiang (University of Cincinnati),"2056475916,2136050841,2124989948,2157678369","Community Question Answering (QA) portals contain questions and answers contributed by hundreds of millions of users. These databases of questions and answers are of great value if they can be used directly to answer questions from any user. In this research, we address this collaborative QA task by drawing knowledge from the crowds in community QA portals such as Yahoo! Answers. Despite their popularity, it is well known that answers in community QA portals have unequal quality. We therefore propose a quality-aware framework to design methods that select answers from a community QA portal considering answer quality in addition to answer relevance. Besides using answer features for determining answer quality, we introduce several other quality-aware QA methods using answer quality derived from the expertise of answerers. Such expertise can be question independent or question dependent. We evaluate our proposed methods using a database of 95K questions and 537K answers obtained from Yahoo! Answers. Our experiments have shown that answer quality can improve QA performance significantly. Furthermore, question dependent expertise based methods are shown to outperform methods using answer features only. It is also found that there are also good answers not among the best answers identified by Yahoo! Answers users.",2009,Web Search and Data Mining,Fields of study: design methodsquestion answeringworld wide webinformation retrievaldata miningcomputer science
On composition of a federated web search result page: using online users to provide pairwise preference for heterogeneous verticals,Ashok Kumar Ponnuswami (Microsoft)Kumaresh Pattabiraman (Microsoft)Qiang Wu (Microsoft)Ran Gilad-Bachrach (Microsoft)Tapas Kanungo (Microsoft),"718203011,2026776090,2677547231,274891381,2500033247","Modern web search engines are federated --- a user query is sent to the numerous specialized search engines called verticals like web (text documents), News, Image, Video, etc. and the results returned by these engines are then aggregated and composed into a search result page (SERP) and presented to the user. For a specific query, multiple verticals could be relevant, which makes the placement of these vertical results within blocks of textual web results challenging: how do we represent, assess, and compare the relevance of these heterogeneous entities? In this paper we present a machine-learning framework for SERP composition in the presence of multiple relevant verticals. First, instead of using the traditional label generation method of human judgment guidelines and trained judges, we use a randomized online auditioning system that allows us to evaluate triples of the form query, web block, vertical>. We use a pairwise click preference to evaluate whether the web block or the vertical block had a better users' engagement. Next, we use a hinged feature vector that contains features from the web block to create a common reference frame and augment it with features representing the specific vertical judged by the user. A gradient boosted decision tree is then learned from the training data. For the final composition of the SERP, we place a vertical result at a slot if the score is higher than a computed threshold. The thresholds are algorithmically determined to guarantee specific coverage for verticals at each slot. We use correlation of clicks as our offline metric and show that click-preference target has a better correlation than human judgments based models. Furthermore, on online tests for News and Image verticals we show higher user engagement for both head and tail queries.",2011,Web Search and Data Mining,Fields of study: web search queryreference framesearch enginedecision treefeature vectorweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
A sketch-based distance oracle for web-scale graphs,Atish Das Sarma (Georgia Institute of Technology)Sreenivas Gollapudi (Microsoft)Marc Najork (Microsoft)Rina Panigrahy (Microsoft),"2266878914,2023254819,2027155665,1923488504","We study the fundamental problem of computing distances between nodes in large graphs such as the web graph and social networks. Our objective is to be able to answer distance queries between pairs of nodes in real time. Since the standard shortest path algorithms are expensive, our approach moves the time-consuming shortest-path computation offline, and at query time only looks up precomputed values and performs simple and fast computations on these precomputed values. More specifically, during the offline phase we compute and store a small ""sketch"" for each node in the graph, and at query-time we look up the sketches of the source and destination nodes and perform a simple computation using these two sketches to estimate the distance.",2010,Web Search and Data Mining,Fields of study: k shortest path routingdistancelongest path problemdijkstra s algorithmembeddingshortest path problemsocial networktheoretical computer sciencemachine learningcomputer science
Leveraging temporal dynamics of document content in relevance ranking,Jonathan L. Elsas (Carnegie Mellon University)Susan T. Dumais (Microsoft),"2132217740,676500258","Many web documents are dynamic, with content changing in varying amounts at varying frequencies. However, current document search algorithms have a static view of the document content, with only a single version of the document in the index at any point in time. In this paper, we present the first published analysis of using the temporal dynamics of document content to improve relevance ranking. We show that there is a strong relationship between the amount and frequency of content change and relevance. We develop a novel probabilistic document ranking algorithm that allows differential weighting of terms based on their temporal characteristics. By leveraging such content dynamics we show significant performance improvements for navigational queries.",2010,Web Search and Data Mining,Fields of study: rankingsearch algorithmworld wide webinformation retrievaldata miningcomputer science
Who uses web search for what: and how,Ingmar Weber (Yahoo!)Alejandro Jaimes (Yahoo!),"2074066684,2193615068","We analyze a large query log of 2.3 million anonymous registered users from a web-scale U.S. search engine in order to jointly analyze their on-line behavior in terms of who they might be (demographics), what they search for (query topics), and how they search (session analysis). We examine basic demographics from registration information provided by the users, augmented with U.S. census data, analyze basic session statistics, classify queries into types (navigational, informational, transactional) based on click entropy, classify queries into topic categories, and cluster users based on the queries they issued. We then examine the resulting clusters in terms of demographics and search behavior. Our analysis of the data suggests that there are important differences in search behavior across different demographic groups in terms of the topics they search for, and how they search (e.g., white conservatives are those likely to have voted republican, mostly white males, who search for business, home, and gardening related topics; Baby Boomers tend to be primarily interested in Finance and a large fraction of their sessions consist of simple navigational queries related to online banking, etc.). Finally, we examine regional search differences, which seem to correlate with differences in local industries (e.g., gambling related queries are highest in Las Vegas and lowest in Salt Lake City; searches related to actors are about three times higher in L.A. than in any other region).",2011,Web Search and Data Mining,Fields of study: search analyticsweb query classificationsearch enginesemantic searchdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
What's in a name?: an unsupervised approach to link users across communities,Jing Liu (Harbin Institute of Technology)Fan Zhang (Nankai University)Xinying Song (Microsoft)Young-In Song (Naver Corporation)Chin-Yew Lin (Microsoft)Hsiao-Wuen Hon (Microsoft),"2701242056,2701850571,2596438211,2104757924,2159460278,2299524537","In this paper, we consider the problem of linking users across multiple online communities. Specifically, we focus on the alias-disambiguation step of this user linking task, which is meant to differentiate users with the same usernames. We start quantitatively analyzing the importance of the alias-disambiguation step by conducting a survey on 153 volunteers and an experimental analysis on a large dataset of About.me (75,472 users). The analysis shows that the alias-disambiguation solution can address a major part of the user linking problem in terms of the coverage of true pairwise decisions (46.8%). To the best of our knowledge, this is the first study on human behaviors with regards to the usages of online usernames. We then cast the alias-disambiguation step as a pairwise classification problem and propose a novel unsupervised approach. The key idea of our approach is to automatically label training instances based on two observations: (a) rare usernames are likely owned by a single natural person, e.g. pennystar88 as a positive instance; (b) common usernames are likely owned by different natural persons, e.g. tank as a negative instance. We propose using the n-gram probabilities of usernames to estimate the rareness or commonness of usernames. Moreover, these two observations are verified by using the dataset of Yahoo! Answers. The empirical evaluations on 53 forums verify: (a) the effectiveness of the classifiers with the automatically generated training data and (b) that the rareness and commonness of usernames can help user linking. We also analyze the cases where the classifiers fail.",2013,Web Search and Data Mining,Fields of study: social networkdata scienceworld wide webdata miningmachine learningcomputer science
Quality-biased ranking of web documents,Michael Bendersky (University of Massachusetts Amherst)W. Bruce Croft (University of Massachusetts Amherst)Yanlei Diao (University of Massachusetts Amherst),"2112702096,2127889770,2245676595","Many existing retrieval approaches do not take into account the content quality of the retrieved documents, although link-based measures such as PageRank are commonly used as a form of document prior. In this paper, we present the quality-biased ranking method that promotes documents containing high-quality content, and penalizes low-quality documents. The quality of the document content can be determined by its readability, layout and ease-of-navigation, among other factors. Accordingly, instead of using a single estimate for document quality, we consider multiple content-based features that are directly integrated into a state-of- the-art retrieval method. These content-based features are easy to compute, store and retrieve, even for large web collections. We use several query sets and web collections to empirically evaluate the performance of our quality-biased retrieval method. In each case, our method consistently improves by a large margin the retrieval performance of text-based and link-based retrieval methods that do not take into account the quality of the document content.",2011,Web Search and Data Mining,Fields of study: rankingdocument clusteringworld wide webinformation retrievaldata miningcomputer science
Entropy of search logs: how hard is search? with personalization? with backoff?,Qiaozhu Mei (University of Illinois at Urbana–Champaign)Kenneth Ward Church (Microsoft),"2166036605,2172397963","How many pages are there on the Web? 5B? 20B? More? Less? Big bets on clusters in the clouds could be wiped out if a small cache of a few million urls could capture much of the value. Language modeling techniques are applied to MSN's search logs to estimate entropy. The perplexity is surprisingly small: millions, not billions. Entropy is a powerful tool for sizing challenges and opportunities. How hard is search? How hard are query suggestion mechanisms like auto-complete? How much does personalization help? All these difficult questions can be answered by estimation of entropy from search logs. What is the potential opportunity for personalization? In this paper, we propose a new way to personalize search, personalization with backoff. If we have relevant data for a particular user, we should use it. But if we don't, back off to larger and larger classes of similar users. As a proof of concept, we use the first few bytes of the IP address to define classes. The coefficients of each backoff class are estimated with an EM algorithm. Ideally, classes would be defined by market segments, demographics and surrogate variables such as time and geography",2008,Web Search and Data Mining,Fields of study: market segmentationproof of conceptentropyexpectation maximization algorithmlanguage modeldata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Improving pairwise learning for item recommendation from implicit feedback,Steffen Rendle (University of Konstanz)Christoph Freudenthaler (University of Konstanz),"1585981875,2559669528","Pairwise algorithms are popular for learning recommender systems from implicit feedback. For each user, or more generally context, they try to discriminate between a small set of selected items and the large set of remaining (irrelevant) items. Learning is typically based on stochastic gradient descent (SGD) with uniformly drawn pairs. In this work, we show that convergence of such SGD learning algorithms slows down considerably if the item popularity has a tailed distribution. We propose a non-uniform item sampler to overcome this problem. The proposed sampler is context-dependent and oversamples informative pairs to speed up convergence. An efficient implementation with constant amortized runtime costs is developed. Furthermore, it is shown how the proposed learning algorithm can be applied to a large class of recommender models. The properties of the new learning algorithm are studied empirically on two real-world recommender system problems. The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime.",2014,Web Search and Data Mining,Fields of study: matrix decompositionrecommender systemtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Mining contrastive opinions on political texts using cross-perspective topic model,Yi Fang (Purdue University)Luo Si (Purdue University)Naveen Somasundaram (Purdue University)Zhengtao Yu (Kunming University of Science and Technology),"2158128598,2127260490,2229185297,2667198709","This paper presents a novel opinion mining research problem, which is called Contrastive Opinion Modeling (COM). Given any query topic and a set of text collections from multiple perspectives, the task of COM is to present the opinions of the individual perspectives on the topic, and furthermore to quantify their difference. This general problem subsumes many interesting applications, including opinion summarization and forecasting, government intelligence and cross-cultural studies. We propose a novel unsupervised topic model for contrastive opinion modeling. It simulates the generative process of how opinion words occur in the documents of different collections. The ad hoc opinion search process can be efficiently accomplished based on the learned parameters in the model. The difference of perspectives can be quantified in a principled way by the Jensen-Shannon divergence among the individual topic-opinion distributions. An extensive set of experiments have been conducted to evaluate the proposed model on two datasets in the political domain: 1) statement records of U.S. senators; 2) world news reports from three representative media in U.S., China and India, respectively. The experimental results with both qualitative and quantitative analysis have shown the effectiveness of the proposed model.",2012,Web Search and Data Mining,Fields of study: jensen shannon divergencetopic modelcultural studiesdata sciencenatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Collaborative ranking,Suhrid Balakrishnan (AT&T Labs)Sumit Chopra (AT&T Labs),"2191719801,2277168470","Typical recommender systems use the root mean squared error (RMSE) between the predicted and actual ratings as the evaluation metric. We argue that RMSE is not an optimal choice for this task, especially when we will only recommend a few (top) items to any user. Instead, we propose using a ranking metric, namely normalized discounted cumulative gain (NDCG), as a better evaluation metric for this task. Borrowing ideas from the learning to rank community for web search, we propose novel models which approximately optimize NDCG for the recommendation task. Our models are essentially variations on matrix factorization models where we also additionally learn the features associated with the users and the items for the ranking task. Experimental results on a number of standard collaborative filtering data sets validate our claims. The results also show the accuracy and efficiency of our models and the benefits of learning features for ranking.",2012,Web Search and Data Mining,Fields of study: ranking svmmean squared errorlearning to rankworld wide webinformation retrievaldata miningmachine learningcomputer science
"How to win friends and influence people, truthfully: influence maximization mechanisms for social networks","Yaron Singer (University of California, Berkeley)",2155009540,"Throughout the past decade there has been extensive research on algorithmic and data mining techniques for solving the problem of influence maximization in social networks: if one can incentivize a subset of individuals to become early adopters of a new technology, which subset should be selected so that the word-of-mouth effect in the social network is maximized? Despite the progress in modeling and techniques, the incomplete information aspect of the problem has been largely overlooked. While data can often provide the network structure and influence patterns may be observable, the inherent cost individuals have to become early adopters is difficult to extract. In this paper we introduce mechanisms that elicit individuals' costs while providing desirable approximation guarantees in some of the most well-studied models of social network influence. We follow the mechanism design framework which advocates for allocation and payment schemes that incentivize individuals to report their true information. We also performed experiments using the Mechanical Turk platform and social network data to provide evidence of the framework's effectiveness in practice.",2012,Web Search and Data Mining,Fields of study: social networkmanagement scienceworld wide websocial sciencedata miningmachine learningcomputer science
Ranking mechanisms in twitter-like forums,Anish Das Sarma (Yahoo!)Atish Das Sarma (Georgia Institute of Technology)Sreenivas Gollapudi (Microsoft)Rina Panigrahy (Microsoft),"2103056292,2266878914,2023254819,1923488504","We study the problem of designing a mechanism to rank items in forums by making use of the user reviews such as thumb and star ratings. We compare mechanisms where forum users rate individual posts and also mechanisms where the user is asked to perform a pairwise comparison and state which one is better. The main metric used to evaluate a mechanism is the ranking accuracy vs the cost of reviews, where the cost is measured as the average number of reviews used per post. We show that for many reasonable probability models, there is no thumb (or star) based ranking mechanism that can produce approximately accurate rankings with bounded number of reviews per item. On the other hand we provide a review mechanism based on pairwise comparisons which achieves approximate rankings with bounded cost. We have implemented a system, shoutvelocity, which is a twitter-like forum but items (i.e., tweets in Twitter) are rated by using comparisons. For each new item the user who posts the item is required to compare two previous entries. This ensures that over a sequence of n posts, we get at least n comparisons requiring one review per item on average. Our mechanism uses this sequence of comparisons to obtain a ranking estimate. It ensures that every item is reviewed at least once and winning entries are reviewed more often to obtain better estimates of top items.",2010,Web Search and Data Mining,Fields of study: world wide webdata miningmachine learningstatisticscomputer science
"Tips, dones and todos: uncovering user profiles in foursquare",Marisa A. Vasconcelos (Universidade Federal de Minas Gerais)Saulo M. R. Ricci (Universidade Federal de Minas Gerais)Jussara M. Almeida (Universidade Federal de Minas Gerais)Fabrício Benevenuto (Universidade Federal de Ouro Preto)Virgílio A. F. Almeida (Universidade Federal de Minas Gerais),"2096241788,2163281082,2130973600,1976666824,2100108167","Online Location Based Social Networks (LBSNs), which combine social network features with geographic information sharing, are becoming increasingly popular. One such application is Foursquare, which doubled its user population in less than six months. Among other features, Foursquare allows users to leave tips (i.e., reviews or recommendations) at specific venues as well as to give feedback on previously posted tips by adding them to their to-do lists or marking them as done. In this paper, we analyze how Foursquare users exploit these three features - tips, dones and to-dos - uncovering different behavior profiles. Our study reveals the existence of very active and influential users, some of which are famous businesses and brands, that seem engaged in posting tips at a large variety of venues while also receiving a great amount of user feedback on them. We also provide evidence of spamming, showing the existence of users that post tips whose contents are unrelated to the nature or domain of the venue where the tips were left.",2012,Web Search and Data Mining,Fields of study: spammingsocial networkinternet privacymultimediaworld wide websocial sciencedata miningcomputer science
"Trend analysis model: trend consists of temporal words, topics, and timestamps",Noriaki Kawamae (Tokyo Denki University),279243410,"This paper presents a topic model that identifies interpretable low dimensional components in time-stamped data for capturing the evolution of trends. Unlike other models for time-stamped data, our proposal, the trend analysis model (TAM), focuses on the difference between temporal words and other words in each document to detect topic evolution over time. TAM introduces a latent trend class variable into each document and a latent switch variable into each token for handling these differences. The trend class has a probability distribution over temporal words, topics, and a continuous distribution over time, where each topic is responsible for generating words. The latter class uses a document specific probabilistic distribution to judge which variable each word comes from for generating words in each token. Accordingly, TAM can explain which topic co-occurrence pattern will appear at any given time, and represents documents of similar content and timestamp as sharing the same trend class. Therefore, TAM projects them on a latent space of trend dimensionality and allows us to predict the temporal evolution of words and topics in document collections. Experiments on various data sets show that the proposed model can capture interpretable low dimensionality sets of topics and timestamps, take advantage of previous models, and is useful as a generative model in the analysis of the evolution of trends.",2011,Web Search and Data Mining,Fields of study: latent variable modellatent class modellatent dirichlet allocationgraphical modelworld wide webdata miningpattern recognitionmachine learningstatisticscomputer science
Modeling dwell time to predict click-level satisfaction,Youngho Kim (University of Massachusetts Amherst)Ahmed Hassan (Microsoft)Ryen W. White (Microsoft)Imed Zitouni (Microsoft),"2311461839,2266125312,2096583854,2507515815","Clicks on search results are the most widely used behavioral signals for predicting search satisfaction. Even though clicks are correlated with satisfaction, they can also be noisy. Previous work has shown that clicks are affected by position bias, caption bias, and other factors. A popular heuristic for reducing this noise is to only consider clicks with long dwell time, usually equaling or exceeding 30 seconds. The rationale is that the more time a searcher spends on a page, the more likely they are to be satisfied with its contents. However, having a single threshold value assumes that users need a fixed amount of time to be satisfied with any result click, irrespective of the page chosen. In reality, clicked pages can differ significantly. Pages have different topics, readability levels, content lengths, etc. All of these factors may affect the amount of time spent by the user on the page. In this paper, we study the effect of different page characteristics on the time needed to achieve search satisfaction. We show that the topic of the page, its length and its readability level are critical in determining the amount of dwell time needed to predict whether any click is associated with satisfaction. We propose a method to model and provide a better understanding of click dwell time. We estimate click dwell time distributions for SAT (satisfied) or DSAT (dissatisfied) clicks for different click segments and use them to derive features to train a click-level satisfaction model. We compare the proposed model to baseline methods that use dwell time and other search performance predictors as features, and demonstrate that the proposed model achieves significant improvements.",2014,Web Search and Data Mining,Fields of study: world wide websimulation
Unsupervised graph-based topic labelling using dbpedia,Ioana Hulpus (Digital Enterprise Research Institute)Conor Hayes (Digital Enterprise Research Institute)Marcel Karnstedt (Digital Enterprise Research Institute)Derek Greene (University College Dublin),"76757058,2099954206,694770543,2131371111","Automated topic labelling brings benefits for users aiming at analysing and understanding document collections, as well as for search engines targetting at the linkage between groups of words and their inherent topics. Current approaches to achieve this suffer in quality, but we argue their performances might be improved by setting the focus on the structure in the data. Building upon research for concept disambiguation and linking to DBpedia, we are taking a novel approach to topic labelling by making use of structured data exposed by DBpedia. We start from the hypothesis that words co-occuring in text likely refer to concepts that belong closely together in the DBpedia graph. Using graph centrality measures, we show that we are able to identify the concepts that best represent the topics. We comparatively evaluate our graph-based approach and the standard text-based approach, on topics extracted from three corpora, based on results gathered in a crowd-sourcing experiment. Our research shows that graph-based analysis of DBpedia can achieve better results for topic labelling in terms of both precision and topic coverage.",2013,Web Search and Data Mining,Fields of study: latent dirichlet allocationnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Cascade-based community detection,Nicola Barbieri (Yahoo!)Francesco Bonchi (Yahoo!)Giuseppe Manco (Indian Council of Agricultural Research),"2155070167,2176652147,2093732677","Given a directed social graph and a set of past informa- tion cascades observed over the graph, we study the novel problem of detecting modules of the graph (communities of nodes), that also explain the cascades. Our key observation is that both information propagation and social ties forma- tion in a social network can be explained according to the same latent factor, which ultimately guide a user behavior within the network. Based on this observation, we propose the Community-Cascade Network (CCN) model, a stochas- tic mixture membership generative model that can fit, at the same time, the social graph and the observed set of cas- cades. Our model produces overlapping communities and for each node, its level of authority and passive interest in each community it belongs. For learning the parameters of the CCN model, we devise a Generalized Expectation Maximization procedure. We then apply our model to real-world social networks and in- formation cascades: the results witness the validity of the proposed CCN model, providing useful insights on its signif- icance for analyzing social behavior.",2013,Web Search and Data Mining,Fields of study: information cascadesocial networkworld wide webdata miningartificial intelligencemachine learningstatistics
On the selection of tags for tag clouds,Petros Venetis (Stanford University)Georgia Koutrika (IBM)Hector Garcia-Molina (Stanford University),"1989096520,2246237345,237419955","We examine the creation of a tag cloud for exploring and understanding a set of objects (e.g., web pages, documents). In the first part of our work, we present a formal system model for reasoning about tag clouds. We then present metrics that capture the structural properties of a tag cloud, and we briefly present a set of tag selection algorithms that are used in current sites (e.g., del.icio.us, Flickr, Technorati) or that have been described in recent work. In order to evaluate the results of these algorithms, we devise a novel synthetic user model. This user model is specifically tailored for tag cloud evaluation and assumes an ""ideal"" user. We evaluate the algorithms under this user model, as well as the model itself, using two datasets: CourseRank (a Stanford social tool containing information about courses) and del.icio.us (a social bookmarking site). The results yield insights as to when and why certain selection schemes work best.",2011,Web Search and Data Mining,Fields of study: tag clouduser modelingweb pagesystems modelingworld wide webinformation retrievaldata miningcomputer science
WebSets: extracting sets of entities from the web using unsupervised information extraction,Bhavana Bharat Dalvi (Carnegie Mellon University)William W. Cohen (Carnegie Mellon University)Jamie Callan (Carnegie Mellon University),"2081006310,2115385359,2148123616","We describe a open-domain information extraction method for extracting concept-instance pairs from an HTML corpus. Most earlier approaches to this problem rely on combining clusters of distributionally similar terms and concept-instance pairs obtained with Hearst patterns. In contrast, our method relies on a novel approach for clustering terms found in HTML tables, and then assigning concept names to these clusters using Hearst patterns. The method can be efficiently applied to a large corpus, and experimental results on several datasets show that our method can accurately extract large numbers of concept-instance pairs.",2012,Web Search and Data Mining,Fields of study: cluster analysisweb mininginformation extractioninformation retrievaldata miningdatabasecomputer science
"I tag, you tag: translating tags for advanced user models",Robert Wetzker (Technical University of Berlin)Carsten Zimmermann (University of San Diego)Christian Bauckhage (Fraunhofer Society)Sahin Albayrak (Technical University of Berlin),"2064728310,2171114049,2034409955,1919884716","Collaborative tagging services (folksonomies) have been among the stars of the Web 2.0 era. They allow their users to label diverse resources with freely chosen keywords (tags). Our studies of two real-world folksonomies unveil that individual users develop highly personalized vocabularies of tags. While these meet individual needs and preferences, the considerable differences between personal tag vocabularies (personomies) impede services such as social search or customized tag recommendation. In this paper, we introduce a novel user-centric tag model that allows us to derive mappings between personal tag vocabularies and the corresponding folksonomies. Using these mappings, we can infer the meaning of user-assigned tags and can predict choices of tags a user may want to assign to new items. Furthermore, our translational approach helps in reducing common problems related to tag ambiguity, synonymous tags, or multilingualism. We evaluate the applicability of our method in tag recommendation and tag-based social search. Extensive experiments show that our translational model improves the prediction accuracy in both scenarios.",2010,Web Search and Data Mining,Fields of study: noindexuser modelingworld wide webinformation retrievaldata miningmachine learningcomputer science
Large-scale analysis of individual and task differences in search result page examination strategies,Georg Buscher (Microsoft)Ryen W. White (Microsoft)Susan T. Dumais (Microsoft)Jeff Huang (University of Washington),"2192651416,2096583854,676500258,2115870741","Understanding the impact of individual and task differences on search result page examination strategies is important in developing improved search engines. Characterizing these effects using query and click data alone is common but insufficient since they provide an incomplete picture of result examination behavior. Cursor- or gaze-tracking studies reveal richer interaction patterns but are often done in small-scale laboratory settings. In this paper we leverage large-scale rich behavioral log data in a naturalistic setting. We examine queries, clicks, cursor movements, scrolling, and text highlighting for millions of queries on the Bing commercial search engine to better understand the impact of user, task, and user-task interactions on user behavior on search result pages (SERPs). By clustering users based on cursor features, we identify individual, task, and user-task differences in how users examine results which are similar to those observed in small-scale studies. Our findings have implications for developing search support for behaviorally-similar searcher cohorts, modeling search behavior, and designing search systems that leverage implicit feedback.",2012,Web Search and Data Mining,Fields of study: search analyticssearch enginedifferential psychologyworld wide webinformation retrievalsimulationcomputer science
CoBayes: bayesian knowledge corroboration with assessors of unknown areas of expertise,Gjergji Kasneci (Microsoft)Jurgen Van Gael (Microsoft)David H. Stern (Microsoft)Thore Graepel (Microsoft),"42507994,74155146,2465980647,2032008572","Our work aims at building probabilistic tools for constructing and maintaining large-scale knowledge bases containing entity-relationship-entity triples (statements) extracted from the Web. In order to mitigate the uncertainty inherent in information extraction and integration we propose leveraging the ""wisdom of the crowds"" by aggregating truth assessments that users provide about statements. The suggested method, CoBayes, operates on a collection of statements, a set of deduction rules (e.g. transitivity), a set of users, and a set of truth assessments of users about statements. We propose a joint probabilistic model of the truth values of statements and the expertise of users for assessing statements. The truth values of statements are interconnected through derivations based on the deduction rules. The correctness of a user's assessment for a given statement is modeled by linear mappings from user descriptions and statement descriptions into a common latent knowledge space where the inner product between user and statement vectors determines the probability that the user assessment for that statement will be correct. Bayesian inference in this complex graphical model is performed using mixed variational and expectation propagation message passing. We demonstrate the viability of CoBayes in comparison to other approaches, on realworld datasets and user feedback collected from Amazon Mechanical Turk.",2011,Web Search and Data Mining,Fields of study: usergraphical modelbayesian inferencemessage passingfeedbackknowledgeinformation extractionknowledge basedata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Automatic generation of bid phrases for online advertising,Sujith Ravi (Google)Andrei Z. Broder (Yahoo!)Evgeniy Gabrilovich (Yahoo!)Vanja Josifovski (Yahoo!)Sandeep Pandey (Yahoo!)Bo Pang (Yahoo!),"2590734359,2637163715,1804802447,344688379,2137133237,2129095822","One of the most prevalent online advertising methods is textual advertising. To produce a textual ad, an advertiser must craft a short creative (the text of the ad) linking to a landing page, which describes the product or service being promoted. Furthermore, the advertiser must associate the creative to a set of manually chosen bid phrases representing those Web search queries that should trigger the ad. For efficiency, given a landing page, the bid phrases are often chosen first, and then for each bid phrase the creative is produced using a template. Nevertheless, an ad campaign (e.g., for a large retailer) might involve thousands of landing pages and tens or hundreds of thousands of bid phrases, hence the entire process is very laborious. Our study aims towards the automatic construction of online ad campaigns: given a landing page, we propose several algorithmic methods to generate bid phrases suitable for the given input. Such phrases must be both relevant (that is, reflect the content of the page) and well-formed (that is, likely to be used as queries to a Web search engine). To this end, we use a two phase approach. First, candidate bid phrases are generated by a number of methods, including a (mono-lingual) translation model capable of generating phrases contained within the text of the input as well as previously ""unseen"" phrases. Second, the candidates are ranked in a probabilistic framework using both the translation model, which favors relevant phrases, as well as a bid phrase language model, which favors well-formed phrases. Empirical evaluation based on a real-life corpus of advertiser-created landing pages and associated bid phrases confirms the value of our approach, which successfully re-generates many of the human-crafted bid phrases and performs significantly better than a pure text extraction method.",2010,Web Search and Data Mining,Fields of study: online advertisingweb search engineworld wide webinformation retrievaldata miningcomputer science
An empirical analysis of sponsored search performance in search engine advertising,Anindya Ghose (New York University)Sha Yang (New York University),"2095776928,2636215455","The phenomenon of sponsored search advertising â where advertisers pay a fee to Internet search engines to be displayed alongside organic (non-sponsored) web search results â is gaining ground as the largest source of revenues for search engines. Despite the growth of search advertising, we have little understanding of how consumers respond to contextual and sponsored search advertising on the Internet. Using a unique panel dataset of several hundred keywords collected from a large nationwide retailer that advertises on Google, we empirically model the relationship between different metrics such as click-through rates, conversion rates, bid prices and keyword ranks. Our paper proposes a novel framework and data to better understand what drives these differences. We use a Hierarchical Bayesian modeling framework and estimate the model using Markov Chain Monte Carlo (MCMC) methods. We empirically estimate the impact of keyword attributes on consumer search and purchase behavior as well as on firms' decision-making behavior on bid prices and ranks. We find that the presence of retailer-specific information in the keyword increases click-through rates, and the presence of brand-specific information in the keyword increases conversion rates. We also demonstrate that as suggested by anecdotal evidence, search engines like Google factor in both the auction bid price as well as prior click-through rates before allotting a final rank to an advertisement. To the best of our knowledge, this is the first study that uses real world data from an advertiser and jointly estimates the effect of sponsored search advertising at a keyword level on consumer search, click and purchase behavior in electronic markets",2008,Web Search and Data Mining,Fields of study: search analyticsorganic searchkeyword advertisingsearch engineonline advertisingworld wide webdata miningcomputer science
A hybrid approach to item recommendation in folksonomies,Robert Wetzker (Technical University of Berlin)Winfried Umbrath (Technical University of Berlin)Alan Said (Technical University of Berlin),"2064728310,1163961881,2104679579","In this paper we consider the problem of item recommendation in collaborative tagging communities, so called folksonomies, where users annotate interesting items with tags. Rather than following a collaborative filtering or annotation-based approach to recommendation, we extend the probabilistic latent semantic analysis (PLSA) approach and present a unified recommendation model which evolves from item user and item tag co-occurrences in parallel. The inclusion of tags reduces known collaborative filtering problems related to overfitting and allows for higher quality recommendations. Experimental results on a large snapshot of the delicious bookmarking service show the scalability of our approach and an improved recommendation quality compared to two-mode collaborative or annotation based methods.",2009,Web Search and Data Mining,Fields of study: probabilistic latent semantic analysiscollaborative filteringrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Personalized click prediction in sponsored search,Haibin Cheng (Yahoo!)Erick Cantú-Paz (Yahoo!),"2656686463,2646539044","Sponsored search is a multi-billion dollar business that generates most of the revenue for search engines. Predicting the probability that users click on ads is crucial to sponsored search because the prediction is used to influence ranking, filtering, placement, and pricing of ads. Ad ranking, filtering and placement have a direct impact on the user experience, as users expect the most useful ads to rank high and be placed in a prominent position on the page. Pricing impacts the advertisers' return on their investment and revenue for the search engine. The objective of this paper is to present a framework for the personalization of click models in sponsored search. We develop user-specific and demographic-based features that reflect the click behavior of individuals and groups. The features are based on observations of search and click behaviors of a large number of users of a commercial search engine. We add these features to a baseline non-personalized click model and perform experiments on offline test sets derived from user logs as well as on live traffic. Our results demonstrate that the personalized models significantly improve the accuracy of click prediction.",2010,Web Search and Data Mining,Fields of study: click pathorganic searchpersonalizationsearch engineprinciple of maximum entropyuser experience designmultimediaworld wide webdata miningstatisticscomputer science
Modeling dynamic behavior in large evolving graphs,Ryan A. Rossi (Purdue University)Brian Gallagher (Lawrence Livermore National Laboratory)Jennifer Neville (Purdue University)Keith Henderson (Lawrence Livermore National Laboratory),"2060818872,2188853992,2124572662,2196117844","Given a large time-evolving graph, how can we model and characterize the temporal behaviors of individual nodes (and network states)? How can we model the behavioral transition patterns of nodes? We propose a temporal behavior model that captures the ""roles"" of nodes in the graph and how they evolve over time. The proposed dynamic behavioral mixed-membership model (DBMM) is scalable, fully automatic (no user-defined parameters), non-parametric/data-driven (no specific functional form or parameterization), interpretable (identifies explainable patterns), and flexible (applicable to dynamic and streaming networks). Moreover, the interpretable behavioral roles are generalizable and computationally efficient. We applied our model for (a) identifying patterns and trends of nodes and network states based on the temporal behavior, (b) predicting future structural changes, and (c) detecting unusual temporal behavior transitions. The experiments demonstrate the scalability, flexibility, and effectiveness of our model for identifying interesting patterns, detecting unusual structural transitions, and predicting the future structural changes of the network and individual nodes.",2013,Web Search and Data Mining,Fields of study: dynamic network analysiscomputingdata miningmachine learningsimulationcomputer science
Knowledge-based graph document modeling,Michael Schuhmacher (University of Mannheim)Simone Paolo Ponzetto (University of Mannheim),"2165387107,2252270924","We propose a graph-based semantic model for representing document content. Our method relies on the use of a semantic network, namely the DBpedia knowledge base, for acquiring fine-grained information about entities and their semantic relations, thus resulting in a knowledge-rich document model. We demonstrate the benefits of these semantic representations in two tasks: entity ranking and computing document semantic similarity. To this end, we couple DBpedia's structure with an information-theoretic measure of concept association, based on its explicit semantic relations, and compute semantic similarity using a Graph Edit Distance based measure, which finds the optimal matching between the documents' entities using the Hungarian method. Experimental results show that our general model outperforms baselines built on top of traditional methods, and achieves a performance close to that of highly specialized methods that have been tuned to these specific tasks.",2014,Web Search and Data Mining,Fields of study: semantic web stacksemantic compressionsemantic computingsemantic equivalencesemantic gridsemantic technologyexplicit semantic analysissemantic integrationsemantic data modelsemantic similaritynatural language processinginformation retrievaldata miningcomputer science
SBotMiner: large scale search bot detection,Fang Yu (Microsoft)Yinglian Xie (Microsoft)Qifa Ke (Microsoft),"2536300858,2122250353,2146637363","In this paper, we study search bot traffic from search engine query logs at a large scale. Although bots that generate search traffic aggressively can be easily detected, a large number of distributed, low rate search bots are difficult to identify and are often associated with malicious attacks. We present SBotMiner, a system for automatically identifying stealthy, low-rate search bot traffic from query logs. Instead of detecting individual bots, our approach captures groups of distributed, coordinated search bots. Using sampled data from two different months, SBotMiner identifies over 123 million bot-related pageviews, accounting for 3.8% of total traffic. Our in-depth analysis shows that a large fraction of the identified bot traffic may be associated with various malicious activities such as phishing attacks or vulnerability exploits. This finding suggests that detecting search bot traffic holds great promise to detect and stop attacks early on.",2010,Web Search and Data Mining,Fields of study: bot herderclick fraudsearch engineinternet privacyworld wide webcomputer securitycomputer science
"Characterizing web content, user interests, and search behavior by reading level and topic",Jin Young Kim (University of Massachusetts Amherst)Kevyn Collins-Thompson (Microsoft)Paul N. Bennett (Microsoft)Susan T. Dumais (Microsoft),"2152189701,2088682983,2137013502,676500258","A user's expertise or ability to understand a document on a given topic is an important aspect of that document's relevance. However, this aspect has not been well-explored in information retrieval systems, especially those at Web scale where the great diversity of content, users, and tasks presents an especially challenging search problem. To help improve our modeling and understanding of this diversity, we apply automatic text classifiers, based on reading difficulty and topic prediction, to estimate a novel type of profile for important entities in Web search -- users, websites, and queries. These profiles capture topic and reading level distributions, which we then use in conjunction with search log data to characterize and compare different entities. We find that reading level and topic distributions provide an important new representation of Web content and user interests, and that using both together is more effective than using either one separately. In particular we find that: 1) the reading level of Web content and the diversity of visitors to a website can vary greatly by topic; 2) the degree to which a user's profile matches with a site's profile is closely correlated with the user's preference of the website in search results, and 3) site or URL profiles can be used to predict 'expertness' whether a given site or URL is oriented toward expert vs. non-expert users. Our findings provide strong evidence in favor of jointly incorporating reading level and topic distribution metadata into a variety of critical tasks in Web information systems.",2012,Web Search and Data Mining,Fields of study: web modelingsubject matter expertworld wide webinformation retrievaldata miningcomputer science
Predicting the readability of short web summaries,Tapas Kanungo (Yahoo!)David Orr (Yahoo!),"2496441443,2151846816","Readability is a crucial presentation attribute that web summarization algorithms consider while generating a querybaised web summary. Readability quality also forms an important component in real-time monitoring of commercial search-engine results since readability of web summaries impacts clickthrough behavior, as shown in recent studies, and thus impacts user satisfaction and advertising revenue. The standard approach to computing the readability is to first collect a corpus of random queries and their corresponding search result summaries, and then each summary is then judged by a human for its readabilty quality. An average readability score is then reported. This process is time consuming and expensive. Besides, the manual evaluation process can not be used in the real-time summary generation process. In this paper we propose a machine learning approach to the problem. We use the corpus as described above and extract summary features that we think may characterize readability. We then estimate a model (gradient boosted decision tree) that predicts human judgments given the features. This model can then be used in real time to estimate the readability of new (unseen) web search summaries and also be used in the summary generation process. We present results on approximately 5000 editorial judgments collected over the course of a year and show examples where the model predicts the quality well and where it disagrees with human judgments. We compare the results of the model to previous models of readability, most notably Collins-Thompson-Callan, Fog and Flesch-Kincaid, and see that our model shows substantially better correlation with editorial judgments as measured by Pearson's correlation coefficient. The learning algorithm also provides us with the relative importance of the features used.",2009,Web Search and Data Mining,Fields of study: search enginedecision treeautomatic summarizationworld wide webinformation retrievaldata miningmachine learningcomputer science
Using graded-relevance metrics for evaluating community QA answer selection,Tetsuya Sakai (Microsoft)Daisuke Ishikawa (NII Holdings)Noriko Kando (NII Holdings)Yohei Seki (University of Tsukuba)Kazuko Kuriyama (National Institute of Informatics)Chin-Yew Lin (Microsoft),"2233707155,2441682934,343307178,2134453497,2041253834,2159460278","Community Question Answering (CQA) sites such as Yahoo! Answers have emerged as rich knowledge resources for information seekers. However, answers posted to CQA sites can be irrelevant, incomplete, redundant, incorrect, biased, ill-formed or even abusive. Hence, automatic selection of ""good"" answers for a given posted question is a practical research problem that will help us manage the quality of accumulated knowledge. One way to evaluate answer selection systems for CQA would be to use the Best Answers (BAs) that are readily available from the CQA sites. However, BAs may be biased, and even if they are not, there may be other good answers besides BAs. To remedy these two problems, we propose system evaluation methods that involve multiple answer assessors and graded-relevance information retrieval metrics. Our main findings from experiments using the NTCIR-8 CQA task data are that, using our evaluation methods, (a) we can detect many substantial differences between systems that would have been overlooked by BA-based evaluation; and (b) we can better identify hard questions (i.e. those that are handled poorly by many systems and therefore require focussed investigation) compared to BAbased evaluation. We therefore argue that our approach is useful for building effective CQA answer selection systems despite the cost of manual answer assessments.",2011,Web Search and Data Mining,Fields of study: evaluationquestion answeringnatural language processingworld wide webinformation retrievaldata miningdatabasecomputer science
Finding text reuse on the web,Michael Bendersky (University of Massachusetts Amherst)W. Bruce Croft (University of Massachusetts Amherst),"2112702096,2127889770","With the overwhelming number of reports on similar events originating from different sources on the web, it is often hard, using existing web search paradigms, to find the original source of ""facts"", statements, rumors, and opinions, and to track their development. Several techniques have been previously proposed for detecting such text reuse between different sources, however these techniques have been tested against relatively small and homogeneous TREC collections. In this work, we test the feasibility of text reuse detection techniques in the setting of web search. In addition to text reuse detection, we develop a novel technique that addresses the unique challenges of finding original sources on the web, such as defining a timeline. We also explore the use of link analysis for identifying reliable and relevant reports. Our experimental results show that the proposed techniques can operate on the scale of the web, are significantly more accurate than standard web search for finding text reuse, and provide a richer representation for tracking the information flow.",2009,Web Search and Data Mining,Fields of study: web modelingweb standardsweb designlink analysisinformation flowworld wide webinformation retrievaldata miningstatisticscomputer science
A novel click model and its applications to online advertising,Zeyuan Allen Zhu (Tsinghua University)Weizhu Chen (Microsoft)Tom Minka (Microsoft)Chenguang Zhu (Tsinghua University)Zheng Chen (Microsoft),"2630683778,2108390110,172536002,2113736906,2425877144","Recent advances in click model have positioned it as an attractive method for representing user preferences in web search and online advertising. Yet, most of the existing works focus on training the click model for individual queries, and cannot accurately model the tail queries due to the lack of training data. Simultaneously, most of the existing works consider the query, url and position, neglecting some other important attributes in click log data, such as the local time. Obviously, the click through rate is different between daytime and midnight. In this paper, we propose a novel click model based on Bayesian network, which is capable of modeling the tail queries because it builds the click model on attribute values, with those values being shared across queries. We called our work General Click Model (GCM) as we found that most of the existing works can be special cases of GCM by assigning different parameters. Experimental results on a large-scale commercial advertisement dataset show that GCM can significantly and consistently lead to better results as compared to the state-of-the-art works.",2010,Web Search and Data Mining,Fields of study: click pathclick through rategaussianlocal timebayesian networksearch enginebayesian probabilityonline advertisingmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Coupled temporal scoping of relational facts,Partha Pratim Talukdar (Carnegie Mellon University)Derry Tanti Wijaya (Carnegie Mellon University)Tom M. Mitchell (Carnegie Mellon University),"2407474466,2238690600,2151014374","Recent research has made significant advances in automatically constructing knowledge bases by extracting relational facts (e.g., Bill Clinton-presidentOf-US) from large text corpora. Temporally scoping such relational facts in the knowledge base (i.e., determining that Bill Clinton-presidentOf-US is true only during the period 1993 - 2001) is an important, but relatively unexplored problem. In this paper, we propose a joint inference framework for this task, which leverages fact-specific temporal constraints, and weak supervision in the form of a few labeled examples. Our proposed framework, CoTS (Coupled Temporal Scoping), exploits temporal containment, alignment, succession, and mutual exclusion constraints among facts from within and across relations. Our contribution is multi-fold. Firstly, while most previous research has focused on micro-reading approaches for temporal scoping, we pose it in a macro-reading fashion, as a change detection in a time series of facts' features computed from a large number of documents. Secondly, to the best of our knowledge, there is no other work that has used joint inference for temporal scoping. We show that joint inference is effective compared to doing temporal scoping of individual facts independently. We conduct our experiments on large scale open-domain publicly available time-stamped datasets, such as English Gigaword Corpus and Google Books Ngrams, demonstrating CoTS's effectiveness.",2012,Web Search and Data Mining,Fields of study: change detectionmutual exclusiontime seriesknowledge baseworld wide webdata miningdatabaseartificial intelligencemachine learningstatisticscomputer science
An optimization framework for query recommendation,Aris Anagnostopoulos (Sapienza University of Rome)Luca Becchetti (Sapienza University of Rome)Carlos Castillo (Yahoo!)Aristides Gionis (Yahoo!),"2136686850,2095497563,2125169605,737311942","Query recommendation is an integral part of modern search engines. The goal of query recommendation is to facilitate users while searching for information. Query recommendation also allows users to explore concepts related to their information needs. In this paper, we present a formal treatment of the problem of query recommendation. In our framework we model the querying behavior of users by a probabilistic reformula- tion graph, or query-flow graph [Boldi et al. CIKM 2008]. A sequence of queries submitted by a user can be seen as a path on this graph. Assigning score values to queries allows us to define suitable utility functions and to consider the expected utility achieved by a reformulation path on the query-flow graph. Providing recommendations can be seen as adding shortcuts in the query-flow graph that ""nudge"" the reformulation paths of users, in such a way that users are more likely to follow paths with larger expected utility. We discuss in detail the most important questions that arise in the proposed framework. In particular, we provide examples of meaningful utility functions to optimize, we discuss how to estimate the effect of recommendations on the reformulation probabilities, we address the complexity of the optimization problems that we consider, we suggest efficient algorithmic solutions, and we validate our models and algorithms with extensive experimentation. Our techniques can be applied to other scenarios where user behavior can be modeled as a Markov process.",2010,Web Search and Data Mining,Fields of study: sargableweb search queryweb query classificationquery expansionquery optimizationinformation needsquery languageexpected utility hypothesissearch enginemarkov processoptimization problemtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Collaboration over time: characterizing and modeling network evolution,Jian Huang (Pennsylvania State University)Ziming Zhuang (Pennsylvania State University)Jia Li (Pennsylvania State University)C. Lee Giles (Pennsylvania State University),"2422960783,2165823887,2242053196,2124749556","A formal type of scientific and academic collaboration is coauthorship which can be represented by a coauthorship network. Coauthorship networks are among some of the largest social networks and offer us the opportunity to study the mechanisms underlying large-scale real world networks. We construct such a network for the Computer Science field covering research collaborations from 1980 to 2005, based on a large dataset of 451,305 papers authored by 283,174 distinct researchers. By mining this network, we first present a comprehensive study of the network statistical properties for a longitudinal network at the overall network level as well as for the intermediate community level. Major observations are that the database community is the best connected while the AI community is the most assortative, and that the Computer Science field as a whole shows a collaboration pattern more similar to Mathematics than to Biology. Moreover, the small world phenomenon and the scale-free degree distribution accompany the growth of the network. To study the individual collaborations, we propose a novel stochastic model, Stochastic Poisson model with Optimization Tree (S pot )to efficiently predict any increment of collaboration based on the local neighborhood structure. S pot models the non-stationary Poisson process by maximizing the log-likelihood with a tree structure. Empirical results show that S pot outperforms Support Vector Regression by better fitting collaboration records and predicting the rate of collaboration",2008,Web Search and Data Mining,Fields of study: network formationpoisson regressiondegree distributionpoisson processsocial network analysisscale free networksupport vector machinetree structurenetwork modelstochastic modellingsocial networkdata scienceworld wide websocial sciencedata miningmachine learningstatisticscomputer science
Fast and Space-Efficient Entity Linking for Queries,Roi Blanco (Yahoo!)Giuseppe Ottaviano (Istituto di Scienza e Tecnologie dell'Informazione)Edgar Meij (Yahoo!),"2128286424,2153528897,2160283388","Entity linking deals with identifying entities from a knowledge base in a given piece of text and has become a fundamental building block for web search engines, enabling numerous downstream improvements from better document ranking to enhanced search results pages. A key problem in the context of web search queries is that this process needs to run under severe time constraints as it has to be performed before any actual retrieval takes place, typically within milliseconds. In this paper we propose a probabilistic model that leverages user-generated information on the web to link queries to entities in a knowledge base. There are three key ingredients that make the algorithm fast and space-efficient. First, the linking process ignores any dependencies between the different entity candidates, which allows for a O(k 2 ) implementation in the number of query terms. Second, we leverage hashing and compression techniques to reduce the memory footprint. Finally, to equip the algorithm with contextual knowledge without sacrificing speed, we factor the distance between distributional semantics of the query words and entities into the model. We show that our solution significantly outperforms several state-of-the-art baselines by more than 14% while being able to process queries in sub-millisecond times---at least two orders of magnitude faster than existing systems.",2015,Web Search and Data Mining,Fields of study: web search queryweb query classificationbrandentity linkingworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning to rank for spatiotemporal search,Blake ShawJon SheaSiddhartha SinhaAndrew Hogue,"2629128866,2132797033,2422777650,2231687839","In this article we consider the problem of mapping a noisy estimate of a user's current location to a semantically meaningful point of interest, such as a home, restaurant, or store. Despite the poor accuracy of GPS on current mobile devices and the relatively high density of places in urban areas, it is possible to predict a user's location with considerable precision by explicitly modeling both places and users and by combining a variety of signals about a user's current context. Places are often simply modeled as a single latitude and longitude when in fact they are complex entities existing in both space and time and shaped by the millions of people that interact with them. Similarly, models of users reveal complex but predictable patterns of mobility that can be exploited for this task. We propose a novel spatial search algorithm that infers a user's location by combining aggregate signals mined from billions of foursquare check-ins with real-time contextual information. We evaluate a variety of techniques and demonstrate that machine learning algorithms for ranking and spatiotemporal models of places and users offer significant improvement over common methods for location search based on distance and popularity.",2013,Web Search and Data Mining,Fields of study: mobile devicegeocodingdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Predicting The Next App That You Are Going To Use,Ricardo A. Baeza-Yates (Yahoo!)Di Jiang (Hong Kong University of Science and Technology)Fabrizio Silvestri (Yahoo!)Beverly Harrison (Yahoo!),"528588921,2647585963,2134079936,2279540177","Given the large number of installed apps and the limited screen size of mobile devices, it is often tedious for users to search for the app they want to use. Although some mobile OSs provide categorization schemes that enhance the visibility of useful apps among those installed, the emerging category of homescreen apps aims to take one step further by automatically organizing the installed apps in a more intelligent and personalized way. In this paper, we study how to improve homescreen apps' usage experience through a prediction mechanism that allows to show to users which app she is going to use in the immediate future. The prediction technique is based on a set of features representing the real-time spatiotemporal contexts sensed by the homescreen app. We model the prediction of the next app as a classification problem and propose an effective personalized method to solve it that takes full advantage of human-engineered features and automatically derived features. Furthermore, we study how to solve the two naturally associated cold-start problems: app cold-start and user cold-start. We conduct large-scale experiments on log data obtained from Yahoo Aviate, showing that our approach can accurately predict the next app that a person is going to use.",2015,Web Search and Data Mining,Fields of study: mobile deep linkingpredictioninternet privacyworld wide webdata miningmachine learningstatisticscomputer science
Fast approximation of betweenness centrality through sampling,Matteo Riondato (Brown University)Evgenios M. Kornaropoulos (Brown University),"1555209364,1644594112","Betweenness centrality is a fundamental measure in social network analysis, expressing the importance or influence of individual vertices in a network in terms of the fraction of shortest paths that pass through them. Exact computation in large networks is prohibitively expensive and fast approximation algorithms are required in these cases. We present two efficient randomized algorithms for betweenness estimation. The algorithms are based on random sampling of shortest paths and offer probabilistic guarantees on the quality of the approximation. The first algorithm estimates the betweenness of all vertices: all approximated values are within an additive factor ɛ from the real values, with probability at least 1-δ. The second algorithm focuses on the top-K vertices with highest betweenness and approximate their betweenness within a multiplicative factor ɛ, with probability at least $1-δ. This is the first algorithm that can compute such approximation for the top-K vertices. We use results from the VC-dimension theory to develop bounds to the sample size needed to achieve the desired approximations. By proving upper and lower bounds to the VC-dimension of a range set associated with the problem at hand, we obtain a sample size that is independent from the number of vertices in the network and only depends on a characteristic quantity that we call the vertex-diameter, that is the maximum number of vertices in a shortest path. In some cases, the sample size is completely independent from any property of the graph. The extensive experimental evaluation that we performed using real and artificial networks shows that our algorithms are significantly faster and much more scalable as the number of vertices in the network grows than previously presented algorithms with similar approximation guarantees.",2014,Web Search and Data Mining,Fields of study: graph centerdistancecentralitybetweenness centralitysocial network analysisvc dimensionsamplingapproximation algorithmsocial sciencemachine learningmathematical optimizationstatisticscomputer science
Dynamic relationship and event discovery,Anish Das Sarma (Yahoo!)Alpa Jain (Yahoo!)Cong Yu (Google),"2103056292,2099613708,2687370976","This paper studies the problem of dynamic relationship and event discovery . A large body of previous work on relation extraction focuses on discovering predefined and static relationships between entities. In contrast, we aim to identify temporally defined (e.g., co-bursting) relationships that are not predefined by an existing schema, and we identify the underlying time constrained events that lead to these relationships. The key challenges in identifying such events include discovering and verifying dynamic connections among entities, and consolidating binary dynamic connections into events consisting of a set of entities that are connected at a given time period. We formalize this problem and introduce an efficient end-to-end pipeline as a solution. In particular, we introduce two formal notions, global temporal constraint cluster and local temporal constraint cluster , for detecting dynamic events. We further design efficient algorithms for discovering such events from a large graph of dynamic relationships. Finally, detailed experiments on real data show the effectiveness of our proposed solution.",2011,Web Search and Data Mining,Fields of study: entity relationship modelrelationship extractionnatural language processingdata miningdatabasemachine learningcomputer science
Beyond co-occurrence: discovering and visualizing tag relationships from geo-spatial and temporal similarities,Haipeng Zhang (Indiana University Bloomington)Mohammed Korayem (Indiana University Bloomington)Erkang You (Indiana University Bloomington)David J. Crandall (Indiana University Bloomington),"2475063278,2106216639,2336030567,2125508545","Studying relationships between keyword tags on social sharing websites has become a popular topic of research, both to improve tag suggestion systems and to discover connections between the concepts that the tags represent. Existing approaches have largely relied on tag co-occurrences. In this paper, we show how to find connections between tags by comparing their distributions over time and space, discovering tags with similar geographic and temporal patterns of use. Geo-spatial, temporal and geo-temporal distributions of tags are extracted and represented as vectors which can then be compared and clustered. Using a dataset of tens of millions of geo-tagged Flickr photos, we show that we can cluster Flickr photo tags based on their geographic and temporal patterns, and we evaluate the results both qualitatively and quantitatively using a panel of human judges. We also develop visualizations of temporal and geographic tag distributions, and show that they help humans recognize semantic relationships between tags. This approach to finding and visualizing similar tags is potentially useful for exploring any data having geographic and temporal annotations.",2012,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata mining
Ranking web sites with real user traffic,Mark R. Meiss (Indiana University Bloomington)Filippo Menczer (Indiana University Bloomington)Santo Fortunato (Institute for Scientific Interchange)Alessandro Flammini (Indiana University Bloomington)Alessandro Vespignani (Indiana University Bloomington),"2023477126,2248192384,2122189410,2012879311,1090210213","We analyze the traffic-weighted Web host graph obtained from a large sample of real Web users over about seven months. A number of interesting structural properties are revealed by this complex dynamic network, some in line with the well-studied boolean link host graph and others pointing to important differences. We find that while search is directly involved in a surprisingly small fraction of user clicks, it leads to a much larger fraction of all sites visited. The temporal traffic patterns display strong regularities, with a large portion of future requests being statistically predictable by past ones. Given the importance of topological measures such as PageRank in modeling user navigation, as well as their role in ranking sites for Web search, we use the traffic data to validate the PageRank random surfing model. The ranking obtained by the actual frequency with which a site is visited by users differs significantly from that approximated by the uniform surfing/teleportation behavior modeled by PageRank, especially for the most important sites. To interpret this finding, we consider each of the fundamental assumptions underlying PageRank and show how each is violated by actual user behavior",2008,Web Search and Data Mining,Fields of study: teleportationrankingcomplex dynamicsnavigationtheoretical computer scienceworld wide webinformation retrievaldata miningcomputer science
Is Wikipedia link structure different,Jaap Kamps (University of Amsterdam)Marijn Koolen (University of Amsterdam),"2088944921,2165198141","In this paper, we investigate the difference between Wikipedia and Web link structure with respect to their value as indicators of the relevance of a page for a given topic of request. Our experimental evidence is from two IR test-collections: the .GOV collection used at the TREC Web tracks and the Wikipedia XML Corpus used at INEX. We first perform a comparative analysis of Wikipedia and .GOV link structure and then investigate the value of link evidence for improving search on Wikipedia and on the .GOV domain. Our main findings are: First, Wikipedia link structure is similar to the Web, but more densely linked. Second, Wikipedia's outlinks behave similar to inlinks and both are good indicators of relevance, whereas on the Web the inlinks are more important. Third, when incorporating link evidence in the retrieval model, for Wikipedia the global link evidence fails and we have to take the local context into account.",2009,Web Search and Data Mining,Fields of study: brandworld wide webinformation retrievaldata miningcomputer science
Mining user web search activity with layered bayesian networks or how to capture a click in its context,Benjamin Piwowarski (University of Glasgow)Georges Dupret (Yahoo!)Rosie Jones (Yahoo!),"210095896,2080443884,2128530851","Mining user web search activity potentially has a broad range of applications including web result pre-fetching, automatic search query reformulation, click spam detection, estimation of document relevance and prediction of user satisfaction. This analysis is difficult because the data recorded by search engines while users interact with them, although abundant, is very noisy. In this work, we explore the utility of mining search behavior of users, represented by observed variables including the time the user spends on the page, and whether the user reformulated his or her query. As a case study, we examine the contribution this data makes to predicting the relevance of a document in the absence of document content models. To this end, we first propose a method for grouping the interactions of a particular user according to the different tasks he or she undertakes. With each task corresponding to a distinct information need, we then propose a Bayesian Network to holistically model these interactions. The aim is to identify distinct patterns of search behaviors. Finally, we join these patterns to a list of custom features and we use gradient boosted decision trees to predict the relevance of a set of query document pairs for which we have relevance assessments. The experimental results confirm the potential of our model, with significant improvements in precision for predicting the relevance of documents based on a model of the user's search and click behavior, over a baseline model using only click and query features, with no Bayesian Network input.",2009,Web Search and Data Mining,Fields of study: rankingweb search queryweb query classificationquery expansionbayesian networksearch enginedecision treeworld wide webinformation retrievaldata miningmachine learningcomputer science
Transferring heterogeneous links across location-based social networks,Jiawei Zhang (University of Illinois at Chicago)Xiangnan Kong (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2305185572,2204127537,2125104194","ocation-based social networks (LBSNs) are one kind of online social networks offering geographic services and have been attracting much attention in recent years. LBSNs usually have complex structures, involving heterogeneous nodes and links. Many recommendation services in LBSNs (e.g., friend and location recommendation) can be cast as link prediction problems (e.g., social link and location link prediction). Traditional link prediction researches on LBSNs mostly focus on predicting either social links or location links, assuming the prediction tasks of different types of links to be independent. However, in many real-world LBSNs, the prediction tasks for social links and location links are strongly correlated and mutually influential. Another key challenge in link prediction on LBSNs is the data sparsity problem (i.e., ""new network"" problem), which can be encountered when LBSNs branch into new geographic areas or social groups. Actually, nowadays, many users are involved in multiple networks simultaneously and users who just join one LBSN may have been using other LBSNs for a long time. In this paper, we study the problem of predicting multiple types of links simultaneously for a new LBSN across partially aligned LBSNs and propose a novel method TRAIL (TRAnsfer heterogeneous lInks across LBSNs). TRAIL can accumulate information for locations from online posts and extract heterogeneous features for both social links and location links. TRAIL can predict multiple types of links simultaneously. In addition, TRAIL can transfer information from other aligned networks to the new network to solve the problem of lacking information. Extensive experiments conducted on two real-world aligned LBSNs show that TRAIL can achieve very good performance and substantially outperform the baseline methods.",2014,Web Search and Data Mining,Fields of study: transfer of learningdata miningartificial intelligencemachine learningcomputer science
Learning query and document similarities from click-through bipartite graph with metadata,Wei Wu (Microsoft)Hang Li (Huawei)Jun Xu (Huawei),"2590381716,2128739099,2598177019","We consider learning query and document similarities from a click-through bipartite graph with metadata on the nodes. The metadata contains multiple types of features of queries and documents. We aim to leverage both the click-through bipartite graph and the features to learn query-document, document-document, and query-query similarities. The challenges include how to model and learn the similarity functions based on the graph data. We propose solving the problems in a principled way. Specifically, we use two different linear mappings to project the queries and documents in two different feature spaces into the same latent space, and take the dot product in the latent space as their similarity. Query-query and document-document similarities can also be naturally defined as dot products in the latent space. We formalize the learning of similarity functions as learning of the mappings that maximize the similarities of the observed query-document pairs on the enriched click-through bipartite graph. When queries and documents have multiple types of features, the similarity function is defined as a linear combination of multiple similarity functions, each based on one type of features. We further solve the learning problem by using a new technique called Multi-view Partial Least Squares (M-PLS). The advantages include the global optimum which can be obtained through Singular Value Decomposition (SVD) and the capability of finding high quality similar queries. We conducted large scale experiments on enterprise search data and web search data. The experimental results on relevance ranking and similar query finding demonstrate that the proposed method works significantly better than the baseline methods.",2013,Web Search and Data Mining,Fields of study: click through ratebipartite graphsingular value decompositionfeature vectorglobal optimizationworld wide webinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Estimating the Completion Time of Crowdsourced Tasks Using Survival Analysis Models,"J. Wang (New York University)S. Faridani (University of California, Berkeley)P.G. Ipeirotis (New York University)","2710605715,2100694258,94049422",-,2011,Web Search and Data Mining,Fields of study: data miningstatistics
Lessons from the journey: a query log analysis of within-session learning,Carsten Eickhoff (ETH Zurich)Jaime Teevan (Microsoft)Ryen White (Microsoft)Susan T. Dumais (Microsoft),"1992666041,1982462162,2096583854,676500258","The Internet is the largest source of information in the world. Search engines help people navigate the huge space of available data in order to acquire new skills and knowledge. In this paper, we present an in-depth analysis of sessions in which people explicitly search for new knowledge on the Web based on the log files of a popular search engine. We investigate within-session and cross-session developments of expertise, focusing on how the language and search behavior of a user on a topic evolves over time. In this way, we identify those sessions and page visits that appear to significantly boost the learning process. Our experiments demonstrate a strong connection between clicks and several metrics related to expertise. Based on models of the user and their specific context, we present a method capable of automatically predicting, with good accuracy, which clicks will lead to enhanced learning. Our findings provide insight into how search engines might better help users learn as they search.",2014,Web Search and Data Mining,Fields of study: search analyticsphrase searchsubject matter expertsearch enginesemantic searchdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Effective query formulation with multiple information sources,Michael Bendersky (University of Massachusetts Amherst)Donald Metzler (University of Southern California)W. Bruce Croft (University of Massachusetts Amherst),"2112702096,2151486164,2127889770","Most standard information retrieval models use a single source of information (e.g., the retrieval corpus) for query formulation tasks such as term and phrase weighting and query expansion. In contrast, in this paper, we present a unified framework that automatically optimizes the combination of information sources used for effective query formulation. The proposed framework produces fully weighted and expanded queries that are both more effective and more compact than those produced by the current state-of-the-art query expansion and weighting methods. We conduct an empirical evaluation of our framework for both newswire and web corpora. In all cases, our combination of multiple information sources for query formulation is found to be more effective than using any single source. The proposed query formulations are especially advantageous for large scale web corpora, where they also reduce the number of terms required for effective query expansion, and improve the diversity of the retrieved results.",2012,Web Search and Data Mining,Fields of study: rankingsargablerdf query languageboolean conjunctive queryonline aggregationweb search queryweb query classificationspatial queryquery by examplequery expansionquery optimizationquery languageinformation retrievaldata miningdatabasecomputer science
Tagging human knowledge,Paul Heymann (Stanford University)Andreas Paepcke (Stanford University)Hector Garcia-Molina (Stanford University),"2038619550,220422686,237419955","A fundamental premise of tagging systems is that regular users can organize large collections for browsing and other tasks using uncontrolled vocabularies. Until now, that premise has remained relatively unexamined. Using library data, we test the tagging approach to organizing a collection. We find that tagging systems have three major large scale organizational features: consistency, quality, and completeness. In addition to testing these features, we present results suggesting that users produce tags similar to the topics designed by experts, that paid tagging can effectively supplement tags in a tagging system, and that information integration may be possible across tagging systems.",2010,Web Search and Data Mining,Fields of study: information integrationworld wide webinformation retrievaldata miningcomputer science
Information Evolution in Social Networks,Lada A. Adamic (Facebook)Thomas M. Lento (Facebook)Eytan Adar (University of Michigan)Pauline C. Ng (Genome Institute of Singapore),"2716260478,2074288814,2305277957,2694837275","Social networks readily transmit information, albeit with less than perfect fidelity. We present a large-scale measurement of this imperfect information copying mechanism by examining the dissemination and evolution of thousands of memes, collectively replicated hundreds of millions of times in the online social network Facebook. The information undergoes an evolutionary process that exhibits several regularities. A meme's mutation rate characterizes the population distribution of its variants, in accordance with the Yule process. Variants further apart in the diffusion cascade have greater edit distance, as would be expected in an iterative, imperfect replication process. Some text sequences can confer a replicative advantage; these sequences are abundant and transfer ""laterally"" between different memes. Subpopulations of the social network can preferentially transmit a specific variant of a meme if the variant matches their beliefs or culture. Understanding the mechanism driving change in diffusing information has important implications for how we interpret and harness the information that reaches us through our social networks.",2016,Web Search and Data Mining,Fields of study: evolutionsocial computingsocial psychologyworld wide websocial scienceartificial intelligencemachine learningcomputer science
Sarcasm Detection on Twitter: A Behavioral Modeling Approach,Ashwin Rajadesingan (Arizona State University)Reza Zafarani (Arizona State University)Huan Liu (Arizona State University),"2228500892,2055981231,2122391114","Sarcasm is a nuanced form of language in which individuals state the opposite of what is implied. With this intentional ambiguity, sarcasm detection has always been a challenging task, even for humans. Current approaches to automatic sarcasm detection rely primarily on lexical and linguistic cues. This paper aims to address the difficult task of sarcasm detection on Twitter by leveraging behavioral traits intrinsic to users expressing sarcasm. We identify such traits using the user's past tweets. We employ theories from behavioral and psychological studies to construct a behavioral modeling framework tuned for detecting sarcasm. We evaluate our framework and demonstrate its efficiency in identifying sarcastic tweets.",2015,Web Search and Data Mining,Fields of study: behavioral modelingsocial computingworld wide webdata miningartificial intelligencecomputer science
On building entity recommender systems using user click log and freebase knowledge,Xiao Yu (University of Illinois at Urbana–Champaign)Hao Ma (Microsoft)Bo-June Paul Hsu (Microsoft)Jiawei Han (University of Illinois at Urbana–Champaign),"2160715520,2656995071,2130892346,2121939561","Due to their commercial value, search engines and recommender systems have become two popular research topics in both industry and academia over the past decade. Although these two fields have been actively and extensively studied separately, researchers are beginning to realize the importance of the scenarios at their intersection: providing an integrated search and information discovery user experience. In this paper, we study a novel application, i.e. , personalized entity recommendation for search engine users, by utilizing user click log and the knowledge extracted from Freebase. To better bridge the gap between search engines and recommender systems, we first discuss important heuristics and features of the datasets. We then propose a generic, robust, and time-aware personalized recommendation framework to utilize these heuristics and features at different granularity levels. Using movie recommendation as a case study, with user click log dataset collected from a widely used commercial search engine, we demonstrate the effectiveness of our proposed framework over other popular and state-of-the-art recommendation techniques.",2014,Web Search and Data Mining,Fields of study: personalizationmultimediaworld wide webinformation retrievaldata miningcomputer science
Tapping into knowledge base for concept feedback: leveraging conceptnet to improve search results for difficult queries,Alexander Kotov (University of Illinois at Urbana–Champaign)Cheng Xiang Zhai (University of Illinois at Urbana–Champaign),"2558015719,2152766206","Query expansion is an important and commonly used technique for improving Web search results. Existing methods for query expansion have mostly relied on global or local analysis of document collection, click-through data, or simple ontologies such as WordNet. In this paper, we present the results of a systematic study of the methods leveraging the ConceptNet knowledge base, an emerging new Web resource, for query expansion. Specifically, we focus on the methods leveraging ConceptNet to improve the search results for poorly performing (or difficult) queries. Unlike other lexico-semantic resources, such as WordNet and Wikipedia, which have been extensively studied in the past, ConceptNet features a graph-based representation model of commonsense knowledge, in which the terms are conceptually related through rich relational ontology. Such representation structure enables complex, multi-step inferences between the concepts, which can be applied to query expansion. We first demonstrate through simulation experiments that expanding queries with the related concepts from ConceptNet has great potential for improving the search results for difficult queries. We then propose and study several supervised and unsupervised methods for selecting the concepts from ConceptNet for automatic query expansion. The experimental results on multiple data sets indicate that the proposed methods can effectively leverage ConceptNet to improve the retrieval performance of difficult queries both when used in isolation as well as in combination with pseudo-relevance feedback.",2012,Web Search and Data Mining,Fields of study: web search queryweb query classificationquery expansionknowledge baseworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Dynamic ranked retrieval,Christina Brandt (Cornell University)Thorsten Joachims (Cornell University)Yisong Yue (Carnegie Mellon University)Jacob Bank (Cornell University),"2230648867,245171893,2133032401,2226835367","We present a theoretically well-founded retrieval model for dynamically generating rankings based on interactive user feedback. Unlike conventional rankings that remain static after the query was issued, dynamic rankings allow and anticipate user activity, thus providing a way to combine the otherwise contradictory goals of result diversification and high recall. We develop a decision-theoretic framework to guide the design and evaluation of algorithms for this interactive retrieval setting. Furthermore, we propose two dynamic ranking algorithms, both of which are computationally efficient. We prove that these algorithms provide retrieval performance that is guaranteed to be at least as good as the optimal static ranking algorithm. In empirical evaluations, dynamic ranking shows substantial improvements in retrieval performance over conventional static rankings.",2011,Web Search and Data Mining,Fields of study: rankingvector space modeldecision theoryworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Struggling or exploring?: disambiguating long search sessions,Ahmed Hassan (Microsoft)Ryen W. White (Microsoft)Susan T. Dumais (Microsoft)Yi-Min Wang (Microsoft),"2266125312,2096583854,676500258,2137802269","Web searchers often exhibit directed search behaviors such as navigating to a particular Website. However, in many circumstances they exhibit different behaviors that involve issuing many queries and visiting many results. In such cases, it is not clear whether the user's rationale is to intentionally explore the results or whether they are struggling to find the information they seek. Being able to disambiguate between these types of long search sessions is important for search engines both in performing retrospective analysis to understand search success, and in developing real-time support to assist searchers. The difficulty of this challenge is amplified since many of the characteristics of exploration (e.g., multiple queries, long duration) are also observed in sessions where people are struggling. In this paper, we analyze struggling and exploring behavior in Web search using log data from a commercial search engine. We first compare and contrast search behaviors along a number dimensions, including query dynamics during the session. We then build classifiers that can accurately distinguish between exploring and struggling sessions using behavioral and topical features. Finally, we show that by considering the struggling/exploring prediction we can more accurately predict search satisfaction.",2014,Web Search and Data Mining,Fields of study: multimediaworld wide webdata miningcomputer science
"Gathering and ranking photos of named entities with high precision, high recall, and diversity",Bilyana Taneva (Max Planck Society)Mouna Kacimi (Free University of Bozen-Bolzano)Gerhard Weikum (Max Planck Society),"2157970401,2629444457,514836396","Knowledge-sharing communities like Wikipedia and automated extraction methods like those of DBpedia enable the construction of large machine-processible knowledge bases with relational facts about entities. These endeavors lack multimodal data like photos and videos of people and places. While photos of famous entities are abundant on the Internet, they are much harder to retrieve for less popular entities such as notable computer scientists or regionally interesting churches. Querying the entity names in image search engines yields large candidate lists, but they often have low precision and unsatisfactory recall. Our goal is to populate a knowledge base with photos of named entities, with high precision, high recall, and diversity of photos for a given entity. We harness relational facts about entities for generating expanded queries to retrieve different candidate lists from image search engines. We use a weighted voting method to determine better rankings of an entity's photos. Appropriate weights are dependent on the type of entity (e.g., scientist vs. politician) and automatically computed from a small set of training entities. We also exploit visual similarity measures based on SIFT features, for higher diversity in the final rankings. Our experiments with photos of persons and landmarks show significant improvements of ranking measures like MAP and NDCG, and also for diversity-aware ranking.",2010,Web Search and Data Mining,Fields of study: query expansionrankingknowledge baseworld wide webinformation retrievaldata miningstatisticscomputer science
Exploring the Space of Topic Coherence Measures,Michael Röder (Leipzig University)Andreas Both (DATEV)Alexander Hinneburg (Martin Luther University of Halle-Wittenberg),"2140856638,2201954113,293376274","Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.",2015,Web Search and Data Mining,Fields of study: topic modeldata scienceinformation retrievaldata miningmachine learningcomputer science
WebChild: harvesting and organizing commonsense knowledge from the web,Niket Tandon (Max Planck Society)Gerard de Melo (Tsinghua University)Fabian M. Suchanek (Télécom ParisTech)Gerhard Weikum (Max Planck Society),"1990453627,2134233121,2681494453,514836396","This paper presents a method for automatically constructing a large commonsense knowledge base, called WebChild, from Web contents. WebChild contains triples that connect nouns with adjectives via fine-grained relations like hasShape, hasTaste, evokesEmotion, etc. The arguments of these assertions, nouns and adjectives, are disambiguated by mapping them onto their proper WordNet senses. Our method is based on semi-supervised Label Propagation over graphs of noisy candidate assertions. We automatically derive seeds from WordNet and by pattern matching from Web text collections. The Label Propagation algorithm provides us with domain sets and range sets for 19 different relations, and with confidence-ranked assertions between WordNet senses. Large-scale experiments demonstrate the high accuracy (more than 80 percent) and coverage (more than four million fine grained disambiguated assertions) of WebChild.",2014,Web Search and Data Mining,Fields of study: commonsense knowledgeweb miningnatural language processingworld wide webdata miningcomputer science
Exploring social influence via posterior effect of word-of-mouth recommendations,Junming Huang (Chinese Academy of Sciences)Xue-Qi Cheng (Chinese Academy of Sciences)Hua-Wei Shen (Chinese Academy of Sciences)Tao Zhou (University of Electronic Science and Technology of China)Xiaolong Jin (Chinese Academy of Sciences),"2172201243,2129598186,2106143704,2422184792,2098785527","Word-of-mouth has proven an effective strategy for promoting products through social relations. Particularly, existing studies have convincingly demonstrated that word-of-mouth recommendations can boost users' prior expectation and hence encourage them to adopt a certain innovation, such as buying a book or watching a movie. However, less attention has been paid to studying the posterior effect of word-of-mouth recommendations, i.e., whether or not word-of-mouth recommendations can influence users' posterior evaluation on the products or services recommended to them, the answer to which is critical to estimating user satisfaction when proposing a word-of-mouth marketing strategy. In order to fill this gap, in this paper we empirically study the above issue and verify that word-of-mouth recommendations are strongly associated with users' posterior evaluation. Through elaborately designed statistical hypothesis tests we prove the causality that word-of-mouth recommendations directly prompt the posterior evaluation of receivers. Finally, we propose a method for investigating users' social influence, namely, their ability to affect followers' posterior evaluation via word-of-mouth recommendations, by examining the number of their followers and their sensitivity of discovering good items. The experimental results on real datasets show that our method can successfully identify 78% influential friends with strong social influence.",2012,Web Search and Data Mining,Fields of study: marketing strategyword of mouthsocial influenceempirical researchstatistical hypothesis testingsocial relationworld wide websocial sciencedata mining
Temporal web dynamics and its application to information retrieval,Kira Radinsky (Technion – Israel Institute of Technology)Fernando Diaz 0001 (Microsoft)Susan T. Dumais (Microsoft)Milad Shokouhi (Microsoft)Anlei Dong (Yahoo!)Yi Chang (Yahoo!),"1780829609,2159093489,676500258,2072421081,2670482487,2168000538","The World Wide Web is highly dynamic and is constantly evolving to cover the latest information about the physical and social updates in the world. At the same time, the changes in web contents are entangled with new information needs and time-sensitive user interactions with information sources. To address these temporal information needs effectively, it is essential for the search engines to model web dynamics and understand the changes in user behavior over time that are caused by them. In this full-day tutorial, we focus on modeling time-sensitive content on the web, and discuss the state-of-the-art approaches for integrating temporal signals in web search. We address many of the related research topics including those associated with searching dynamic collections, defining time-sensitive relevance, understanding user query behavior over time, and investigating the mains reasons behind content changes. We also cover algorithms, architectures, evaluation methodologies and metrics for time-aware search, and discuss the latest breakthroughs and open challenges, both from the algorithmic and the architectural perspectives.",2013,Web Search and Data Mining,Fields of study: web modelingsocial semantic webweb analyticsweb standardsweb mappingmashupweb query classificationweb designweb navigationweb intelligenceweb engineeringmultimediaworld wide webinformation retrievaldata miningcomputer science
Object matching in tweets with spatial models,Nilesh N. Dalvi (Yahoo!)Ravi Kumar 0001 (Yahoo!)Bo Pang (Yahoo!),"1986584529,2232709231,2129095822","Despite their 140-character limitation, tweets embody a lot of valuable information, especially temporal and spatial. In this paper we study the geographic aspects of tweets, for a given object domain. We propose a user-level model for spatial encoding in tweets that goes beyond the explicit geo-coding or place name mentions; this model can be used to match objects to tweets. We illustrate our model and methodology using restaurants as the objects, and show a significant improvement in performance over using standard language models. En route, we obtain a method to geolocate users who tweet about geolocated objects; this may be of independent interest.",2012,Web Search and Data Mining,Fields of study: language modelmultimediaworld wide webdata miningcomputer science
Learning URL patterns for webpage de-duplication,Hema Swetha Koppula (Yahoo!)Krishna P. Leela (Yahoo!)Amit Agarwal (Yahoo!)Krishna Prasad Chitrapura (Yahoo!)Sachin Garg (Yahoo!)Amit Sasturkar (Yahoo!),"739620182,2222757186,2306482496,1691303182,2584178023,124421473","Presence of duplicate documents in the World Wide Web adversely affects crawling, indexing and relevance, which are the core building blocks of web search. In this paper, we present a set of techniques to mine rules from URLs and utilize these rules for de-duplication using just URL strings without fetching the content explicitly. Our technique is composed of mining the crawl logs and utilizing clusters of similar pages to extract transformation rules, which are used to normalize URLs belonging to each cluster. Preserving each mined rule for de-duplication is not efficient due to the large number of such rules. We present a machine learning technique to generalize the set of rules, which reduces the resource footprint to be usable at web-scale. The rule extraction techniques are robust against web-site specific URL conventions. We compare the precision and scalability of our approach with recent efforts in using URLs for de-duplication. Experimental results demonstrate that our approach achieves 2 times more reduction in duplicates with only half the rules compared to the most recent previous approach. Scalability of the framework is demonstrated by performing a large scale evaluation on a set of 3 Billion URLs, implemented using the MapReduce framework.",2010,Web Search and Data Mining,Fields of study: semantic urlrewrite engineurl normalizationsearch enginedecision treeworld wide webinformation retrievaldata miningmachine learningcomputer science
Cross lingual text classification by mining multilingual topics from wikipedia,Xiaochuan Ni (Microsoft)Jian-Tao Sun (Microsoft)Jian Hu (Tencent)Zheng Chen (Microsoft),"2110285684,2131116857,2172181550,2425877144","This paper investigates how to effectively do cross lingual text classification by leveraging a large scale and multilingual knowledge base, Wikipedia. Based on the observation that each Wikipedia concept is described by documents of different languages, we adapt existing topic modeling algorithms for mining multilingual topics from this knowledge base. The extracted topics have multiple types of representations, with each type corresponding to one language. In this work, we regard such topics extracted from Wikipedia documents as universal-topics, since each topic corresponds with same semantic information of different languages. Thus new documents of different languages can be represented in a space using a group of universal-topics. We use these universal-topics to do cross lingual text classification. Given the training data labeled for one language, we can train a text classifier to classify the documents of another language by mapping all documents of both languages into the universal-topic space. This approach does not require any additional linguistic resources, like bilingual dictionaries, machine translation tools, or labeling data for the target language. The evaluation results indicate that our topic modeling approach is effective for building cross lingual text classifier.",2011,Web Search and Data Mining,Fields of study: topic modelbrandmachine translationknowledge basenatural language processingspeech recognitioninformation retrievalmachine learningcomputer science
Who watches (and shares) what on youtube? and when?: using twitter to understand youtube viewership,Adiya Abisheva (ETH Zurich)Venkata Rama Kiran Garimella (Qatar Computing Research Institute)David Garcia (ETH Zurich)Ingmar Weber (Qatar Computing Research Institute),"1238960709,2016896753,2165280421,2074066684","By combining multiple social media datasets, it is possible to gain insight into each dataset that goes beyond what could be obtained with either individually. In this paper we combine user-centric data from Twitter with video-centric data from YouTube to build a rich picture of who watches and shares what on YouTube. We study 87K Twitter users, 5.6 million YouTube videos and 15 million video sharing events from user-, video- and sharing-event-centric perspectives. We show that features of Twitter users correlate with YouTube features and sharing-related features. For example, urban users are quicker to share than rural users. We find a superlinear relationship between initial Twitter shares and the final amounts of views. We discover that Twitter activity metrics play more role in video popularity than mere amount of followers. We also reveal the existence of correlated behavior concerning the time between video creation and sharing within certain timescales, showing the time onset for a coherent response, and the time limit after which collective responses are extremely unlikely. Response times depend on the category of the video, suggesting Twitter video sharing is highly dependent on the video content. To the best of our knowledge, this is the first large-scale study combining YouTube and Twitter data, and it reveals novel, detailed insights into who watches (and shares) what on YouTube, and when.",2014,Web Search and Data Mining,Fields of study: internet privacymultimediaworld wide web
You Are Where You Go: Inferring Demographic Attributes from Location Check-ins,Yuan Zhong (Northeastern University)Nicholas Jing Yuan (Microsoft)Wen Zhong (Stony Brook University)Fuzheng Zhang (University of Science and Technology of China)Xing Xie (Microsoft),"2222092705,2096490164,2629744130,2110384818,2125800575","User profiling is crucial to many online services. Several recent studies suggest that demographic attributes are predictable from different online behavioral data, such as users' ""Likes"" on Facebook, friendship relations, and the linguistic characteristics of tweets. But location check-ins, as a bridge of users' offline and online lives, have by and large been overlooked in inferring user profiles. In this paper, we investigate the predictive power of location check-ins for inferring users' demographics and propose a simple yet general location to profile (L2P) framework. More specifically, we extract rich semantics of users' check-ins in terms of spatiality, temporality, and location knowledge, where the location knowledge is enriched with semantics mined from heterogeneous domains including both online customer review sites and social networks. Additionally, tensor factorization is employed to draw out low dimensional representations of users' intrinsic check-in preferences considering the above factors. Meanwhile, the extracted features are used to train predictive models for inferring various demographic attributes. We collect a large dataset consisting of profiles of 159,530 verified users from an online social network. Extensive experimental results based upon this dataset validate that: 1) Location check-ins are diagnostic representations of a variety of demographic attributes, such as gender, age, education background, and marital status; 2) The proposed framework substantially outperforms compared models for profile inference in terms of various evaluation metrics, such as precision, recall, F-measure, and AUC.",2015,Web Search and Data Mining,Fields of study: temporalitypredictionworld wide webdata miningmachine learningstatistics
Mining social images with distance metric learning for automated image tagging,Pengcheng Wu (Nanyang Technological University)Steven Chu-Hong Hoi (Nanyang Technological University)Peilin Zhao (Nanyang Technological University)Ying He (Nanyang Technological University),"2108925152,108406206,2096910461,2109402491","With the popularity of various social media applications, massive social images associated with high quality tags have been made available in many social media web sites nowadays. Mining social images on the web has become an emerging important research topic in web search and data mining. In this paper, we propose a machine learning framework for mining social images and investigate its application to automated image tagging. To effectively discover knowledge from social images that are often associated with multimodal contents (including visual images and textual tags), we propose a novel Unified Distance Metric Learning (UDML) scheme, which not only exploits both visual and textual contents of social images, but also effectively unifies both inductive and transductive metric learning techniques in a systematic learning framework. We further develop an efficient stochastic gradient descent algorithm for solving the UDML optimization task and prove the convergence of the algorithm. By applying the proposed technique to the automated image tagging task in our experiments, we demonstrate that our technique is empirically effective and promising for mining social images towards some real applications.",2011,Web Search and Data Mining,Fields of study: transductionstochastic gradient descentsocial mediasemi supervised learningdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Early online identification of attention gathering items in social media,Michael Mathioudakis (University of Toronto)Nick Koudas (University of Toronto)Peter Marbach (University of Toronto),"2085699011,335443309,232791897","Activity in social media such as blogs, micro-blogs, social networks, etc is manifested via interaction that involves text, images, links and other information items. Naturally, some items attract more attention than others, expressed with large volumes of linking, commenting or tagging activity, to name a few examples. Moreover, high attention can be indicative of emerging events, breaking news or generally indicate information items of interest to a vast set of people. The numbers associated with digital social activity are astonishing: in excess of millions of blog posts, tweets and forums updates per day, millions of tags in photos, news articles or blogs. Being able to identify information items that gather much attention in such a real time information collective is a challenging task. In this paper, we consider the problem of early online identification of items that gather a lot of attention in social media. We model social media activity using ISIS, a stochastic model for Interacting Streaming Information Sources, that intuitively captures the concept of attention gathering information items. Given the challenge of the information overload characterizing digital social activity, we present sequential statistical tests that enable early identification of attention gathering items. This effectively reduces the set of items one has to monitor in real time in order to identify pieces of information attracting a lot of attention. Experiments on real data demonstrate the utility of our model, as well as the efficiency and effectiveness of the proposed sequential statistical tests.",2010,Web Search and Data Mining,Fields of study: social mediainformation overloadstochastic modellingstatistical hypothesis testingmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Retweet or not?: personalized tweet re-ranking,Wei Feng (Tsinghua University)Jianyong Wang (Tsinghua University),"2677617916,2635409833","With Twitter being widely used around the world, users are facing enormous new tweets every day. Tweets are ranked in chronological order regardless of their potential interestedness. Users have to scan through pages of tweets to find useful information. Thus more personalized ranking scheme is needed to filter the overwhelmed information. Since retweet history reveals users' personal preference for tweets, we study how to learn a predictive model to rank the tweets according to their probability of being retweeted. In this way, users can find interesting tweets in a short time. To model the retweet behavior, we build a graph made up of three types of nodes: users, publishers and tweets. To incorporate all sources of information like users' profile, tweet quality, interaction history, etc, nodes and edges are represented by feature vectors. All these feature vectors are mapped to node weights and edge weights. Based on the graph, we propose a feature-aware factorization model to re-rank the tweets, which unifies the linear discriminative model and the low-rank factorization model seamlessly. Finally, we conducted extensive experiments on a real dataset crawled from Twitter. Experimental results show the effectiveness of our model.",2013,Web Search and Data Mining,Fields of study: social mediarecommender systeminternet privacyworld wide webinformation retrievaldata miningcomputer science
Inferring the impacts of social media on crowdfunding,Chun Ta Lu (University of Illinois at Chicago)Sihong Xie (University of Illinois at Chicago)Xiangnan Kong (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2224372854,2106011892,2204127537,2125104194","Crowdfunding -- in which people can raise funds through collaborative contributions of general public (i.e., crowd) -- has emerged as a billion dollars business for supporting more than one million ventures. However, very few research works have examined the process of crowdfunding. In particular, none has studied how social networks help crowdfunding projects to succeed. To gain insights into the effects of social networks in crowdfunding, we analyze the hidden connections between the fundraising results of projects on crowdfunding websites and the corresponding promotion campaigns in social media. Our analysis considers the dynamics of crowdfunding from two aspects: how fundraising activities and promotional activities on social media simultaneously evolve over time, and how the promotion campaigns influence the final outcomes. From our investigation, we identify a number of important principles that provide a useful guide for devising effective campaigns. For example, we observe temporal distribution of customer interest, strong correlations between a crowdfunding project's early promotional activities and the final outcomes, and the importance of concurrent promotion from multiple sources. We then show that these discoveries can help predict several important quantities, including overall popularity and the success rate of the project. Finally, we show how to use these discoveries to help design crowdfunding sites.",2014,Web Search and Data Mining,Fields of study: social mediaworld wide webcomputer science
Understanding and predicting personal navigation,Jaime Teevan (Microsoft)Daniel J. Liebling (Microsoft)Gayathri Ravichandran Geetha (Microsoft),"1982462162,2303967954,2023017315","This paper presents an algorithm that predicts with very high accuracy which Web search result a user will click for one sixth of all Web queries. Prediction is done via a straightforward form of personalization that takes advantage of the fact that people often use search engines to re-find previously viewed resources. In our approach, an individual's past navigational behavior is identified via query log analysis and used to forecast identical future navigational behavior by the same individual. We compare the potential value of personal navigation with general navigation identified using aggregate user behavior. Although consistent navigational behavior across users can be useful for identifying a subset of navigational queries, different people often use the same queries to navigate to different resources. This is true even for queries comprised of unambiguous company names or URLs and typically thought of as navigational. We build an understanding of what personal navigation looks like, and identify ways to improve its coverage and accuracy by taking advantage of people's consistency over time and across groups of individuals.",2011,Web Search and Data Mining,Fields of study: turn by turn navigationweb search querysearch enginenavigationworld wide webinformation retrievaldata miningcomputer science
Quasi-succinct indices,Sebastiano Vigna (University of Milan),2010447242,"Compressed inverted indices in use today are based on the idea of gap compression: documents pointers are stored in increasing order, and the gaps between successive document pointers are stored using suitable codes which represent smaller gaps using less bits. Additional data such as counts and positions is stored using similar techniques. A large body of research has been built in the last 30 years around gap compression, including theoretical modeling of the gap distribution, specialized instantaneous codes suitable for gap encoding, and ad hoc document reorderings which increase the efficiency of instantaneous codes. This paper proposes to represent an index using a different architecture based on quasi-succinct representation of monotone sequences. We show that, besides being theoretically elegant and simple, the new index provides expected constant-time operations, space savings, and, in practice, significant performance improvements on conjunctive, phrasal and proximity queries.",2013,Web Search and Data Mining,Fields of study: succinct data structuretheoretical computer scienceworld wide webinformation retrievaldata miningalgorithmcomputer science
Citation recommendation without author supervision,Qi He (Pennsylvania State University)Daniel Kifer (Pennsylvania State University)Jian Pei (Simon Fraser University)Prasenjit Mitra (Pennsylvania State University)C. Lee Giles (Pennsylvania State University),"2309017108,2049563562,2126330539,2109624860,2124749556","Automatic recommendation of citations for a manuscript is highly valuable for scholarly activities since it can substantially improve the efficiency and quality of literature search. The prior techniques placed a considerable burden on users, who were required to provide a representative bibliography or to mark passages where citations are needed. In this paper we present a system that considerably reduces this burden: a user simply inputs a query manuscript ( without a bibliography) and our system automatically finds locations where citations are needed. We show that naive approaches do not work well due to massive noise in the document corpus. We produce a successful approach by carefully examining the relevance between segments in a query manuscript and the representative segments extracted from a document corpus. An extensive empirical evaluation using the CiteSeerX data set shows that our approach is effective.",2011,Web Search and Data Mining,Fields of study: bibliometricsextractionrecommender systemworld wide webinformation retrievaldata miningcomputer science
Query suggestion for E-commerce sites,Mohammad Al Hasan (Indiana University)Nish Parikh (eBay)Gyanit Singh (eBay)Neel Sundaresan (eBay),"2160841979,2125745058,2124838874,1981173961","Query suggestion module is an integral part of every search engine. It helps search engine users narrow or broaden their searches. Published work on query suggestion methods has mainly focused on the web domain. But, the module is also popular in the domain of e-commerce for product search. In this paper, we discuss query suggestion and its methodologies in the context of e-commerce search engines. We show that dynamic inventory combined with long and sparse tail of query distribution poses unique challenges to build a query suggestion method for an e-commerce marketplace. We compare and contrast the design of a query suggestion system for web search engines and e-commerce search engines. Further, we discuss interesting measures to quantify the effectiveness of our query suggestion methodologies. We also describe the learning gained from exposing our query suggestion module to a vibrant community of millions of users.",2011,Web Search and Data Mining,Fields of study: sargablerankingrdf query languagesearch oriented architectureweb search queryweb query classificationquery expansionquery optimizationquery languagesearch enginerecommender systemworld wide webinformation retrievaldata miningcomputer science
Query suggestion by constructing term-transition graphs,Yang Song (Microsoft)Dengyong Zhou (Microsoft)Li-wei He (Microsoft),"2021276105,2119648418,2683009472","Query suggestion is an interactive approach for search engines to better understand users information need. In this paper, we propose a novel query suggestion framework which leverages user re-query feedbacks from search engine logs. Specifically, we mined user query reformulation activities where the user only modifies part of the query by (1) adding terms after the query, (2) deleting terms within the query, or (3) modifying terms to new terms. We build a term-transition graph based on the mined data. Two models are proposed which address topic-level and term-level query suggestions, respectively. In the first topic-based unsupervised Pagerank model, we perform random walk on each of the topic-based term-transition graph and calculate the Pagerank for each term within a topic. Given a new query, we suggest relevant queries based on its topic distribution and term-transition probability within each topic. Our second model resembles the supervised learning-to-rank (LTR) framework, in which term modifications are treated as documents so that each query reformulation is treated as a training instance. A rich set of features are constructed for each (query, document) pair from Pagerank, Wikipedia, N-gram, ODP and so on. This supervised model is capable of suggesting new queries on a term level which addresses the limitation of previous methods. Experiments are conducted on a large data set from a commercial search engine. By comparing the with state-of-the-art query suggestion methods [4, 2], our proposals exhibit significant performance increase for all categories of queries.",2012,Web Search and Data Mining,Fields of study: sargablerankingrdf query languageboolean conjunctive queryonline aggregationweb search queryweb query classificationspatial queryviewquery by examplequery expansionrange queryquery optimizationinformation needsquery languagesearch enginemarkov chainlearning to ranksupervised learningworld wide webinformation retrievaldata miningmachine learningcomputer science
Less is more: sampling the neighborhood graph makes SALSA better and faster,Marc Najork (Microsoft)Sreenivas Gollapudi (Microsoft)Rina Panigrahy (Microsoft),"2027155665,2023254819,1923488504","In this paper, we attempt to improve the effectiveness and the efficiency of query-dependent link-based ranking algorithms such as HITS, MAX and SALSA. All these ranking algorithms view the results of a query as nodes in the web graph, expand the result set to include neighboring nodes, and compute scores on the induced neighborhood graph. In previous work it was shown that SALSA in particular is substantially more effective than query-independent link-based ranking algorithms such as PageRank. In this work, we show that whittling down the neighborhood graph through consistent sampling of nodes and edges makes SALSA and its cousins both faster (more efficient) and better (more effective). We offer a hypothesis as to why ""less is more"", i.e. why using a reduced graph improves performance.",2009,Web Search and Data Mining,Fields of study: hits algorithmtheoretical computer scienceworld wide webdata miningmachine learningcomputer science
Crawling deep web entity pages,Yeye He (University of Wisconsin-Madison)Dong Xin (Google)Venkatesh Ganti (Google)Sriram Rajaraman (Google)Nirav Shah (Google),"2170951142,1991372327,2609461227,2227615349,2231107177","Deep-web crawl is concerned with the problem of surfacing hidden content behind search interfaces on the Web. While many deep-web sites maintain document-oriented textual content (e.g., Wikipedia, PubMed, Twitter, etc.), which has traditionally been the focus of the deep-web literature, we observe that a significant portion of deep-web sites, including almost all online shopping sites, curate structured entities as opposed to text documents. Although crawling such entity-oriented content is clearly useful for a variety of purposes, existing crawling techniques optimized for document oriented content are not best suited for entity-oriented sites. In this work, we describe a prototype system we have built that specializes in crawling entity-oriented deep-web sites. We propose techniques tailored to tackle important subproblems including query generation, empty page filtering and URL deduplication in the specific context of entity oriented deep-web sites. These techniques are experimentally evaluated and shown to be effective.",2013,Web Search and Data Mining,Fields of study: distributed web crawlingentitymultimediaworld wide webinformation retrievaldata mining
A framework for quantitative analysis of cascades on networks,Rumi Ghosh (University of Southern California)Kristina Lerman (University of Southern California),"2111901679,2149625712","How does information flow in online social networks? How does the structure and size of the information cascade evolve in time? How can we efficiently mine the information contained in cascade dynamics? We approach these questions empirically and present an efficient and scalable mathematical framework for quantitative analysis of cascades on networks. We define a cascade generating function that captures the details of the microscopic dynamics of the cascades. We show that this function can also be used to compute the macroscopic properties of cascades, such as their size, spread, diameter, number of paths, and average path length. We present an algorithm to efficiently compute cascade generating function and demonstrate that while significantly compressing information within a cascade, it nevertheless allows us to accurately reconstruct its structure. We use this framework to study information dynamics on the social network of Digg. Digg allows users to post and vote on stories, and easily see the stories that friends have voted on. As a story spreads on Digg through voting, it generates cascades. We extract cascades of more than 3,500 Digg stories and calculate their macroscopic and microscopic properties. We identify several trends in cascade dynamics: spreading via chaining, branching and community. We discuss how these affect the spread of the story through the Digg social network. Our computational framework is general and offers a practical solution to quantitative analysis of the microscopic structure of even very large cascades.",2011,Web Search and Data Mining,Fields of study: average path lengthinformation cascadeinformation flowgenerating functionquantitative analysissocial networkdiffusiontheoretical computer sciencecombinatoricssocial scienceartificial intelligencemachine learningcomputer sciencemathematics
Optimized interleaving for online retrieval evaluation,Filip Radlinski (Microsoft)Nick Craswell (Microsoft),"2072292845,2009495402","Interleaving is an online evaluation technique for comparing the relative quality of information retrieval functions by combining their result lists and tracking clicks. A sequence of such algorithms have been proposed, each being shown to address problems in earlier algorithms. In this paper, we formalize and generalize this process, while introducing a formal model: We identify a set of desirable properties for interleaving, then show that an interleaving algorithm can be obtained as the solution to an optimization problem within those constraints. Our approach makes explicit the parameters of the algorithm, as well as assumptions about user behavior. Further, we show that our approach leads to an unbiased and more efficient interleaving algorithm than any previous approach, using a novel log-based analysis of user search behavior.",2013,Web Search and Data Mining,Fields of study: interleavingevaluationtheoretical computer scienceinformation retrievaldistributed computingcomputer science
Reusing historical interaction data for faster online learning to rank for IR,Katja Hofmann (University of Amsterdam)Anne Schuth (University of Amsterdam)Shimon Whiteson (University of Amsterdam)Maarten de Rijke (University of Amsterdam),"2138860655,1979729989,2042571382,401833296","Online learning to rank for information retrieval (IR) holds promise for allowing the development of ""self-learning"" search engines that can automatically adjust to their users. With the large amount of e.g., click data that can be collected in web search settings, such techniques could enable highly scalable ranking optimization. However, feedback obtained from user interactions is noisy, and developing approaches that can learn from this feedback quickly and reliably is a major challenge. In this paper we investigate whether and how previously collected (historical) interaction data can be used to speed up learning in online learning to rank for IR. We devise the first two methods that can utilize historical data (1) to make feedback available during learning more reliable and (2) to preselect candidate ranking functions to be evaluated in interactions with users of the retrieval system. We evaluate both approaches on 9 learning to rank data sets and find that historical data can speed up learning, leading to substantially and significantly higher online performance. In particular, our pre-selection method proves highly effective at compensating for noise in user feedback. Our results show that historical data can be used to make online learning to rank for IR much more effective than previously possible, especially when feedback is noisy.",2013,Web Search and Data Mining,Fields of study: online machine learninglearning to ranksemi supervised learningworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning recommender systems with adaptive regularization,Steffen Rendle (University of Konstanz),1585981875,"Many factorization models like matrix or tensor factorization have been proposed for the important application of recommender systems. The success of such factorization models depends largely on the choice of good values for the regularization parameters. Without a careful selection they result in poor prediction quality as they either underfit or overfit the data. Regularization values are typically determined by an expensive search that requires learning the model parameters several times: once for each tuple of candidate values for the regularization parameters. In this paper, we present a new method that adapts the regularization automatically while training the model parameters. To achieve this, we optimize simultaneously for two criteria: (1) as usual the model parameters for the regularized objective and (2) the regularization of future parameter updates for the best predictive quality on a validation set. We develop this for the generic model class of Factorization Machines which subsumes a wide variety of factorization models. We show empirically, that the advantages of our adaptive regularization method compared to expensive hyperparameter search do not come to the price of worse predictive quality. In total with our method, learning regularization parameters is as easy as learning model parameters and thus there is no need for any time-consuming search of regularization values because they are found on-the-fly. This makes our method highly attractive for practical use.",2012,Web Search and Data Mining,Fields of study: regularization perspectives on support vector machinesbackus gilbert methodregularizationmatrix decompositionfactor analysisrecommender systempattern recognitionmachine learningmathematical optimizationcomputer science
Absence time and user engagement: evaluating ranking functions,Georges Dupret (Yahoo!)Mounia Lalmas (Yahoo!),"2080443884,46148421","In the online industry, user engagement is measured with various engagement metrics used to assess users' depth of engagement with a website. Widely-used metrics include clickthrough rates, page views and dwell time. Relying solely on these metrics can lead to contradictory if not erroneous conclusions regarding user engagement. In this paper, we propose the time between two user visits, or the absence time, to measure user engagement. Our assumption is that if users find a website interesting, engaging or useful, they will return to it sooner -a reflection of their engagement with the site -than if this is not the case. This assumption has the advantage of being simple and intuitive and applicable to a large number of settings. As a case study, we use a community Q&A website, and compare the behaviour of users exposed to six functions used to rank past answers, both in terms of traditional metrics and absence time. We use Survival Analysis to show the relation between absence time and other engagement metrics. We demonstrate that the absence time leads to coherent, interpretable results and helps to better understand other metrics commonly used to evaluate user engagement in search.",2013,Web Search and Data Mining,Fields of study: metricssearch engineworld wide webdata miningsimulationcomputer science
Scalable topic-specific influence analysis on microblogs,"Bin Bi (University of California, Los Angeles)Yuanyuan Tian (IBM)Yannis Sismanis (Google)Andrey Balmin (IBM)Junghoo Cho (University of California, Los Angeles)","2139260861,2129760627,2637155312,1208114522,2167033418","Social influence analysis on microblog networks, such as Twitter, has been playing a crucial role in online advertising and brand management. While most previous influence analysis schemes rely only on the links between users to find key influencers, they omit the important text content created by the users. As a result, there is no way to differentiate the social influence in different aspects of life (topics). Although a few prior works do support topic-specific influence analysis, they either separate the analysis of content from the analysis of network structure, or assume that content is the only cause of links, which is clearly an inappropriate assumption for microblog networks. To address the limitations of the previous approaches, we propose a novel Followship-LDA (FLDA) model, which integrates both content topic discovery and social influence analysis in the same generative process. This model properly captures the content-related and content-independent reasons why a user follows another in a microblog network. We demonstrate that FLDA produces results with significantly better precision than existing approaches. Furthermore, we propose a distributed Gibbs sampling algorithm for FLDA, and demonstrate that it provides excellent scalability on large clusters. Finally, we incorporate the FLDA model in a general search framework for topic-specific influencers. A user freely expresses his/her interest by typing a few keywords, the search framework will return a ranked list of key influencers that satisfy the user's interest.",2014,Web Search and Data Mining,Fields of study: internet privacyworld wide webinformation retrievaldata miningmachine learningcomputer science
Inferring search behaviors using partially observable Markov (POM) model,Kuansan Wang (Microsoft)Nikolas Gloy (Microsoft)Xiaolong Li (Microsoft),"2127379895,2006084940,2645307360","This article describes an application of the partially observable Markov (POM) model to the analysis of a large scale commercial web search log. Mathematically, POM is a variant of the hidden Markov model in which all the hidden state transitions do not necessarily emit observable events. This property of POM is used to model, as the hidden process, a common search behavior that users would read and skip search results, leaving no observable user actions to record in the search logs. The Markov nature of the model further lends support to cope with the facts that a single observed sequence can be probabilistically associated with many hidden sequences that have variable lengths, and the search results can be read in various temporal orders that are not necessarily reflected in the observed sequence of user actions. To tackle the implementation challenges accompanying the flexibility and analytic powers of POM, we introduce segmental Viterbi algorithm based on segmental decoding and Viterbi training to train the POM model parameters and apply them to uncover hidden processes from the search logs. To validate the model, the latent variables modeling the browsing patterns on the search result page are compared with the experimental data of the eye tracking stu-dies. The close agreements suggest that the search logs do contain rich information of user behaviors in browsing the search result page even though they are not directly observable, and that using POM to understand these sophisticated search behaviors is a promising approach.",2010,Web Search and Data Mining,Fields of study: forward algorithmhidden semi markov modellatent variable modeleye trackingmarkov modelviterbi algorithmhidden markov modeldata miningmachine learningsimulationstatisticscomputer science
IR system evaluation using nugget-based test collections,Virgiliu Pavlu (Northeastern University)Shahzad Rajput (Northeastern University)Peter B. Golbus (Northeastern University)Javed A. Aslam (Northeastern University),"2135697225,2225830875,1912732802,1997938366","The development of information retrieval systems such as search engines relies on good test collections, including assessments of retrieved content. The widely employed Cranfield paradigm dictates that the information relevant to a topic be encoded at the level of documents, therefore requiring effectively complete document relevance assessments. As this is no longer practical for modern corpora, numerous problems arise, including scalability, reusability, and applicability. We propose a new method for relevance assessment based on relevant information, not relevant documents. Once the relevant 'nuggets' are collected, our matching method can assess any document for relevance with high accuracy, and so any retrieved list of documents can be assessed for performance. In this paper we analyze the performance of the matching function by looking at specific cases and by comparing with other methods. We then show how these inferred relevance assessments can be used to perform IR system evaluation, and we discuss in particular reusability and scalability. Our main contribution is a methodology for producing test collections that are highly accurate, more complete, scalable, reusable, and can be generated with similar amounts of effort as existing methods, with great potential for future applications.",2012,Web Search and Data Mining,Fields of study: relevancesearch engineworld wide webinformation retrievaldata miningdatabasecomputer science
"GOP primary season on twitter: ""popular"" political sentiment in social media",Yelena Mejova (Yahoo!)Padmini Srinivasan (University of Iowa)Bob Boynton (University of Iowa),"2083323769,2237621063,1988317330","As mainstream news media and political campaigns start to pay attention to the political discourse online, a systematic analysis of political speech in social media becomes more critical. What exactly do people say on these sites, and how useful is this data in estimating political popularity? In this study we examine Twitter discussions surrounding seven US Republican politicians who were running for the US Presidential nomination in 2011. We show this largely negative rhetoric to be laced with sarcasm and humor and dominated by a small portion of users. Furthermore, we show that using out-of-the-box classification tools results in a poor performance, and instead develop a highly optimized multi-stage approach designed for general-purpose political sentiment classification. Finally, we compare the change in sentiment detected in our dataset before and after 19 Republican debates, concluding that, at least in this case, the Twitter political chatter is not indicative of national political polls.",2013,Web Search and Data Mining,Fields of study: american political sciencesocial mediapolitical communicationsentiment analysisworld wide websocial sciencecomputer science
Negative Link Prediction in Social Media,Jiliang Tang (Arizona State University)Shiyu Chang (University of Illinois at Urbana–Champaign)Charu C. Aggarwal (IBM)Huan Liu (Arizona State University),"2147392410,2098291119,2146335907,2122391114","Signed network analysis has attracted increasing attention in recent years. This is in part because research on signed network analysis suggests that negative links have added value in the analytical process. A major impediment in their effective use is that most social media sites do not enable users to specify them explicitly. In other words, a gap exists between the importance of negative links and their availability in real data sets. Therefore, it is natural to explore whether one can predict negative links automatically from the commonly available social network data. In this paper, we investigate the novel problem of negative link prediction with only positive links and content-centric interactions in social media. We make a number of important observations about negative links, and propose a principled framework NeLP, which can exploit positive links and content-centric interactions to predict negative links. Our experimental results on real-world social networks demonstrate that the proposed NeLP framework can accurately predict negative links with positive links and content-centric interactions. Our detailed experiments also illustrate the relative importance of various factors to the effectiveness of the proposed framework.",2015,Web Search and Data Mining,Fields of study: social mediasocial psychologyworld wide webartificial intelligencecomputer science
Beyond ten blue links: enabling user click modeling in federated web search,Danqi Chen (Tsinghua University)Weizhu Chen (Microsoft)Haixun Wang (Microsoft)Zheng Chen (Microsoft)Qiang Yang (University of Hong Kong),"2104844286,2108390110,2116756368,2425877144,2109031554","Click models have been positioned as an effective approach to interpret user click behavior in search engines. Existing click models mostly focus on traditional Web search that considers only ten homogeneous Web HTML documents that appear on the first search-result page. However, in modern commercial search engines, more and more Web search results are federated from multiple sources and contain non-HTML results returned by other heterogeneous vertical engines, such as video or image search engines. In this paper, we study user click behavior in federated search. We observed that user click behavior in federated search is highly different from that in traditional Web search, making it difficult to interpret using existing click models. In response, we propose a novel federated click model (FCM) to interpret user click behavior in federated search. In particular, we take into considerations two new biases in FCM. The first comes from the observation that users tend to be attracted by vertical results and their visual attention on them may increase the examination probability of other nearby web results. The other illustrates that user click behavior on vertical results may lead to more clues of search relevance due to their presentation style in federated search. With these biases and an effective model to correct them, FCM is more accurate in characterizing user click behavior in federated search. Our extensive experimental results show that FCM can outperform other click models in interpreting user click behavior in federated search and achieve significant improvements in terms of both perplexity and log-likelihood.",2012,Web Search and Data Mining,Fields of study: click pathorganic searchsearch engineinternet privacymultimediaworld wide webinformation retrievaldata miningcomputer science
Sequence clustering and labeling for unsupervised query intent discovery,Jackie Chi Kit Cheung (University of Toronto)Xiao Li (Facebook),"2148676791,2309003130","One popular form of semantic search observed in several modern search engines is to recognize query patterns that trigger instant answers or domain-specific search, producing semantically enriched search results. This often requires understanding the query intent in addition to the meaning of the query terms in order to access structured data sources. A major challenge in intent understanding is to construct a domain-dependent schema and to annotate search queries based on such a schema, a process that to date has required much manual annotation effort. We present an unsupervised method for clustering queries with similar intent and for producing a pattern consisting of a sequence of semantic concepts and/or lexical items for each intent. Furthermore, we leverage the discovered intent patterns to automatically annotate a large number of queries beyond those used in clustering. We evaluated our method on 10 selected domains, discovering over 1400 intent patterns and automatically annotating 125K (and potentially many more) queries. We found that over 90% of patterns and 80% of instance annotations tested are judged to be correct by a majority of annotators.",2012,Web Search and Data Mining,Fields of study: web search querysearch enginedata modelcluster analysissemantic searchworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
A combined topical/non-topical approach to identifying web sites for children,Carsten Eickhoff (Delft University of Technology)Pavel Serdyukov (Delft University of Technology)Arjen P. de Vries (Centrum Wiskunde & Informatica),"1992666041,2130450538,2506496362","Today children interact more and more frequently with information services. Especially in on-line scenarios there is a great amount of content that is not suitable for their age group. Due to the growing importance and ubiquity of the Internet in today's world, denying children any unsupervised Web access is often not possible. This work presents an automatic way of distinguishing web pages for children from those for adults in order to improve child-appropriate web search engine performance. A range of 80 different features based on findings from cognitive sciences and children's psychology are discussed and evaluated. We conducted a large scale user study on the suitability of web sites and give detailed information about the insights gained. Finally a comparison to traditional web classification methods as well as human annotator performance reveals that our automatic classifier can reach a performance close to that of human agreement.",2011,Web Search and Data Mining,Fields of study: social semantic webweb analyticsweb standardsweb query classificationfilterbiological classificationweb intelligencemultimediaworld wide webinformation retrievaldata miningcomputer science
User Modeling for a Personal Assistant,Ramanathan V. Guha (Google)Vineet Gupta (Google)Vivek Raghunathan (Google)Ramakrishnan Srikant (Google),"2302699734,2192108129,2025335402,2069583943","We present a user modeling system that serves as the foundation of a personal assistant. The system ingests web search history for signed-in users, and identifies coherent contexts that correspond to tasks, interests, and habits. Unlike past work which focused on either in-session tasks or tasks over a few days, we look at several months of history in order to identify not just short-term tasks, but also long-term interests and habits. The features we use for identifying coherent contexts yield substantially higher precision and recall than past work. We also present an algorithm for identifying contexts that is 8 to 30 times faster than previous algorithms. The user modeling system has been deployed in production. It runs over hundreds of millions of users, and updates the models with a 10-minute latency. The contexts identified by the system serve as the foundation for generating recommendations in Google Now.",2015,Web Search and Data Mining,Fields of study: user modelinghuman computer interactionmultimediaworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Modeling the impact of lifestyle on health at scale,Adam Sadilek (University of Rochester)Henry A. Kautz (University of Rochester),"2005357825,1966271946","Research in computational epidemiology to date has concentrated on estimating summary statistics of populations and simulated scenarios of disease outbreaks. Detailed studies have been limited to small domains, as scaling the methods involved poses considerable challenges. By contrast, we model the associations of a large collection of social and environmental factors with the health of particular individuals. Instead of relying on surveys, we apply scalable machine learning techniques to noisy data mined from online social media and infer the health state of any given person in an automated way. We show that the learned patterns can be subsequently leveraged in descriptive as well as predictive fine-grained models of human health. Using a unified statistical model, we quantify the impact of social status, exposure to pollution, interpersonal interactions, and other important lifestyle factors on one's health. Our model explains more than 54% of the variance in people's health (as estimated from their online communication), and predicts the future health status of individuals with 91% accuracy. Our methods complement traditional studies in life sciences, as they enable us to perform large-scale and timely measurement, inference, and prediction of previously elusive factors that affect our everyday lives.",2013,Web Search and Data Mining,Fields of study: ubiquitous computingdata scienceworld wide webdata miningmachine learningsimulationstatisticscomputer science
Improving music genre classification using collaborative tagging data,Ling Chen (Nanyang Technological University)Phillip Wright (Georgia Institute of Technology)Wolfgang Nejdl (Leibniz University of Hanover),"2195436365,2624710834,2228144965","As a fundamental and critical component of music information retrieval (MIR) systems, music genre classification has attracted considerable research attention. Automatically classifying music by genre is, however, a challenging problem due to the fact that music is an evolving art. While most of the existing work categorizes music using features extracted from music audio signals, in this paper, we propose to exploit the semantic information embedded in tags supplied by users of social networking websites. Particularly, we consider the tag information by creating a graph of tracks so that tracks are neighbors if they are similar in terms of their associated tags. Two classification methods based on the track graph are developed. The first one employs a classification scheme which simultaneously considers the audio content and neighborhood of tracks. In contrast, the second one is a two-level classifier which initializes genre label for unknown tracks using their audio content, and then iteratively updates the genres considering the influence from their neighbors. A set of optimizing strategies are designed for the purpose of further enhancing the quality of the two-level classifier. Extensive experiments are conducted on real-world data collected from Last.fm. Promising experimental results demonstrate the benefit of using tags for accurate music genre classification.",2009,Web Search and Data Mining,Fields of study: social networkdata collectionfeature extractionworld wide webspeech recognitioninformation retrievalsocial sciencedata miningmachine learningstatisticscomputer science
Towards Twitter context summarization with user influence models,Yi Chang (Yahoo!)Xuanhui Wang (Facebook)Qiaozhu Mei (University of Michigan)Yan Liu (University of Southern California),"2168000538,2102775025,2166036605,2240541904","Twitter has become one of the most popular platforms for users to share information in real time. However, as an individual tweet is short and lacks sufficient contextual information, users cannot effectively understand or consume information on Twitter, which can either make users less engaged or even detached from using Twitter. In order to provide informative context to a Twitter user, we propose the task of Twitter context summarization, which generates a succinct summary from a large but noisy Twitter context tree. Traditional summarization techniques only consider text information, which is insufficient for Twitter context summarization task, since text information on Twitter is very sparse. Given that there are rich user interactions in Twitter, we thus study how to improve summarization methods by leveraging such signals. In particular, we study how user influence models, which project user interaction information onto a Twitter context tree, can help Twitter context summarization within a supervised learning framework. To evaluate our methods, we construct a data set by asking human editors to manually select the most informative tweets as a summary. Our experimental results based on this editorial data set show that Twitter context summarization is a promising research topic and pairwise user influence signals can significantly improve the task performance.",2013,Web Search and Data Mining,Fields of study: multi document summarizationautomatic summarizationinternet privacyworld wide webdata miningcomputer science
Studying inter-national mobility through IP geolocation,Bogdan State (Stanford University)Ingmar Weber (Qatar Computing Research Institute)Emilio Zagheni (Queens College),"2163048533,2074066684,773951722","The increasing ubiquity of Internet use has opened up new avenues in the study of human mobility. Easily-obtainable geolocation data resulting from repeated logins to the same website offer the possibility of observing long-term patterns of mobility for a large number of individuals. We use data on the geographic locations from where over 100 million anonymized users log into Yahoo!~services to generate the first global map of short- and medium-term mobility flows. We develop a protocol to identify anonymized users who, over a one-year period, had spent more than 3 months in a different country from their stated country of residence (""migrants""), and users who spent less than a month in another country (""tourists""). We compute aggregate estimates of migration propensities between countries, as inferred from a user's location over the observed period. Geolocation data allow us to characterize also the pendularity of migration flows -- i.e., the extent to which migrants travel back and forth between their countries of origin and destination. We use data regarding visa regimes, colonial ties, geographic location and economic development to predict migration and tourism flows. Our analysis shows the persistence of traditional migration patterns as well as the emergence of new routes. Migrations tend to be more pendular between countries that are close to each other. We observe particularly high levels of pendularity within the European Economic Area, even after we control for distance and visa regimes. The dataset, methodology and results presented have important implications for the travel industry, as well as for several disciplines in social sciences, including geography, demography and the sociology of networks.",2013,Web Search and Data Mining,Fields of study: tourismmobile computingworld wide webcomputer securitycomputer science
ETF: extended tensor factorization model for personalizing prediction of review helpfulness,Samaneh Moghaddam (Simon Fraser University)Mohsen Jamali (Simon Fraser University)Martin Ester (Simon Fraser University),"2126331285,2617375404,2067196623","Online reviews are valuable sources of information for a variety of decision-making processes such as purchasing products. As the number of online reviews is growing rapidly, it becomes increasingly difficult for users to identify those that are helpful. This has motivated research into the problem of identifying high quality and helpful reviews automatically. The current methods assume that the helpfulness of a review is independent from the readers of that review. However, we argue that the quality of a review may not be the same for different users. For example, a professional and an amateur photographer may rate the helpfulness of a review very differently. In this paper, we introduce the problem of predicting a personalized review quality for recommendation of helpful reviews. To address this problem, we propose a series of increasingly sophisticated probabilistic graphical models, based on Matrix Factorization and Tensor Factorization. We evaluate the proposed models using a database of 1.5 million reviews and more than 13 million quality ratings obtained from Epinions.com. The experiments demonstrate that the proposed latent factor models outperform the state-of-the art approaches using textual and social features. Finally, our experiments confirm that the helpfulness of a review is indeed not the same for all users and that there are some latent factors that affect a user's evaluation of the review quality.",2012,Web Search and Data Mining,Fields of study: decision makingmatrix decompositionfactor analysisdata sciencemultimediaworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Modeling opinion dynamics in social networks,Abhimanyu Das (Microsoft)Sreenivas Gollapudi (Microsoft)Kamesh Munagala (Duke University),"2480652307,2023254819,2257433360","Our opinions and judgments are increasingly shaped by what we read on social media -- whether they be tweets and posts in social networks, blog posts, or review boards. These opinions could be about topics such as consumer products, politics, life style, or celebrities. Understanding how users in a network update opinions based on their neighbor's opinions, as well as what global opinion structure is implied when users iteratively update opinions, is important in the context of viral marketing and information dissemination, as well as targeting messages to users in the network. In this paper, we consider the problem of modeling how users update opinions based on their neighbors' opinions. We perform a set of online user studies based on the celebrated conformity experiments of Asch [1]. Our experiments are carefully crafted to derive quantitative insights into developing a model for opinion updates (as opposed to deriving psychological insights). We show that existing and widely studied theoretical models do not explain the entire gamut of experimental observations we make. This leads us to posit a new, nuanced model that we term the BVM. We present preliminary theoretical and simulation results on the convergence and structure of opinions in the entire network when users iteratively update their respective opinions according to the BVM. We show that consensus and polarization of opinions arise naturally in this model under easy to interpret initial conditions on the network.",2014,Web Search and Data Mining,Fields of study: social networkworld wide websocial sciencedata miningmachine learning
Strength of social influence in trust networks in product review sites,Ching-man Au Yeung (Nippon Telegraph and Telephone)Tomoharu Iwata (Nippon Telegraph and Telephone),"2697177384,2108993706","Some popular product review sites such as Epinions allow users to establish a trust network among themselves, indicating who they trust in providing product reviews and ratings. While trust relations have been found to be useful in generating personalised recommendations, the relations between trust and product ratings has so far been overlooked. In this paper, we examine large datasets collected from Epinions and Ciao, two popular product review sites. We discover that in general users who trust each other tend to have smaller differences in their ratings as time passes, giving support to the theories of homophily and social influence. However, we also discover that this does not hold true across all trusted users. A trust relation does not guarantee that two users have similar preferences, implying that personalised recommendations based on trust relations do not necessarily produce more accurate predictions. We propose a method to estimate the strengths of trust relations so as to estimate the true influence among the trusted users. Our method extends the popular matrix factorisation technique for collaborative filtering, which allow us to generate more accurate rating predictions at the same time. We also show that the estimated strengths of trust relations correlate with the similarity among the users. Our work contributes to the understanding of the interplay between trust relations and product ratings, and suggests that trust networks may serve as a more general socialising venue than only an indication of similarity in user preferences.",2011,Web Search and Data Mining,Fields of study: collaborative filteringsocial influencematrix decompositionrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Relational click prediction for sponsored search,Chenyan Xiong (Chinese Academy of Sciences)Taifeng Wang (Microsoft)Wenkui Ding (Tsinghua University)Yidong Shen (Chinese Academy of Sciences)Tie-Yan Liu (Microsoft),"2226924701,2677542262,2684180398,2129952813,2108341226","This paper is concerned with the prediction of clicking an ad in sponsored search. The accurate prediction of user's click on an ad plays an important role in sponsored search, because it is widely used in both ranking and pricing of the ads. Previous work on click prediction usually takes a single ad as input, and ignores its relationship to the other ads shown in the same page. This independence assumption here, however, might not be valid in the real scenario. In this paper, we first perform an analysis on this issue by looking at the click-through rates (CTR) of the same ad, in the same position and for the same query, but surrounded by different ads. We found that in most cases the CTR varies largely, which suggests that the relationship between ads is really an important factor in predicting click probability. Furthermore, our investigation shows that the more similar the surrounding ads are to an ad, the lower the CTR of the ad is. Based on this observation, we design a continuous conditional random fields (CRF) based model for click prediction, which considers both the features of an ad and its similarity to the surrounding ads. We show that the model can be effectively learned using maximum likelihood estimation, and can also be efficiently inferred due to its closed form solution. Our experimental results on the click-through log from a commercial search engine show that the proposed model can predict clicks more accurately than previous independent models. To our best knowledge this is the first work that predicts ad clicks by considering the relationship between ads.",2012,Web Search and Data Mining,Fields of study: click through rateconditional random fieldsearch engineclosed form expressionmaximum likelihoodonline advertisingdata scienceworld wide webdata miningmachine learningcomputer science
Characterizing and supporting cross-device search tasks,Yu Wang (Emory University)Xiao Huang (Microsoft)Ryen W. White (Microsoft),"2642184498,2227002492,2096583854","Web searchers frequently transition from desktop computers and laptops to mobile devices, and vice versa. Little is known about the nature of cross-device search tasks, yet they represent an important opportunity for search engines to help their users, especially those on the target (post-switch) device. For example, the search engine could save the current session and re-instate it post switch, or it could capitalize on down-time between devices to proactively re-trieve content on behalf of the searcher. In this paper, we present a log-based study to define and characterize cross-device search be-havior and predict the resumption of cross-device tasks. Using data from a large commercial search engine, we show that there are dis-cernible and noteworthy patterns of search behavior associated with device transitions. We also develop learned models for predicting task resumption on the target device using behavioral, topical, geo-spatial, and temporal features. Our findings show that our models can attain strong prediction accuracy and have direct implications for the development of tools to help people search more effectively in a multi-device world.",2013,Web Search and Data Mining,Fields of study: search analyticspersonalizationsearch enginesemantic searchworld wide webinformation retrievaldata miningsimulationcomputer science
A two-view learning approach for image tag ranking,Jinfeng Zhuang (Nanyang Technological University)Steven C.H. Hoi (Nanyang Technological University),"2154702969,108406206","Tags of social images play a central role for text-based social image retrieval and browsing tasks. However, the original tags annotated by web users could be noisy, irrelevant, and often incomplete for describing the image contents, which may severely deteriorate the performance of text-based image retrieval models. In this paper, we aim to overcome the challenge of social tag ranking for a corpus of social images with rich user-generated tags by proposing a novel two-view learning approach. It can effectively exploit both textual and visual contents of social images to discover the complicated relationship between tags and images. Unlike the conventional learning approaches that usually assume some parametric models, our method is completely data-driven and makes no assumption of the underlying models, making the proposed solution practically more effective. We formally formulate our method as an optimization task and present an efficient algorithm to solve it. To evaluate the efficacy of our method, we conducted an extensive set of experiments by applying our technique to both text-based social image retrieval and automatic image annotation tasks, in which encouraging results showed that the proposed method is more effective than the conventional approaches.",2011,Web Search and Data Mining,Fields of study: visual wordparametric modelautomatic image annotationimage retrievalworld wide webinformation retrievaldata miningmachine learningcomputer science
LambdaMerge: merging the results of query reformulations,Daniel Sheldon (Oregon State University)Milad Shokouhi (Microsoft)Martin Szummer (Microsoft)Nick Craswell (Microsoft),"2114707312,2072421081,695485773,2009495402","Search engines can automatically reformulate user queries in a variety of ways, often leading to multiple queries that are candidates to replace the original. However, selecting a replacement can be risky: a reformulation may be more effective than the original or significantly worse, depending on the nature of the query, the source of reformulation candidates, and the corpus. In this paper, we explore methods to mitigate this risk by issuing several versions of the query (including the original) and merging their results. We focus on reformulations generated by random walks on the click graph, a method that can produce very good reformulations but is also variable and prone to topic drift. Our primary contribution is λ-Merge, a supervised merging method that is trained to directly optimize a retrieval metric (such as NDCG or MAP) using features that describe both the reformulations and the documents they return. In experiments on Bing data and GOV2, λ-Merge outperforms the original query and several unsupervised merging methods. λ-Merge also outperforms a supervised method to predict and select the best single formulation, and is competitive with an oracle that always selects the best formulation.",2011,Web Search and Data Mining,Fields of study: web search queryweb query classificationquery expansionquery optimizationsearch enginelearning to rankworld wide webinformation retrievaldata miningmachine learningcomputer science
Predicting response in mobile advertising with hierarchical importance-aware factorization machine,Richard Jayadi Oentaryo (Singapore Management University)Ee-Peng Lim (Singapore Management University)Jia-Wei Low (Singapore Management University)David Lo (Singapore Management University)Michael Finegold (Carnegie Mellon University),"1526539107,2130308643,2147395767,2132927693,2109492991","Mobile advertising has recently seen dramatic growth, fueled by the global proliferation of mobile phones and devices. The task of predicting ad response is thus crucial for maximizing business revenue. However, ad response data change dynamically over time, and are subject to cold-start situations in which limited history hinders reliable prediction. There is also a need for a robust regression estimation for high prediction accuracy, and good ranking to distinguish the impacts of different ads. To this end, we develop a Hierarchical Importance-aware Factorization Machine (HIFM), which provides an effective generic latent factor framework that incorporates importance weights and hierarchical learning. Comprehensive empirical studies on a real-world mobile advertising dataset show that HIFM outperforms the contemporary temporal latent factor models. The results also demonstrate the efficacy of the HIFM's importance-aware and hierarchical learning in improving the overall prediction and prediction in cold-start scenarios, respectively.",2014,Web Search and Data Mining,Fields of study: hierarchyworld wide webdata miningmachine learningsimulationcomputer science
Generating labels from clicks,Rakesh Agrawal (Microsoft)Alan Halverson (Microsoft)Krishnaram Kenthapadi (Microsoft)Nina Mishra (Microsoft)Panayiotis Tsaparas (Microsoft),"2537924216,2040370899,2088122068,2124493348,2234654910","The ranking function used by search engines to order results is learned from labeled training data. Each training point is a (query, URL) pair that is labeled by a human judge who assigns a score of Perfect, Excellent, etc., depending on how well the URL matches the query. In this paper, we study whether clicks can be used to automatically generate good labels. Intuitively, documents that are clicked (resp., skipped) in aggregate can indicate relevance (resp., lack of relevance). We give a novel way of transforming clicks into weighted, directed graphs inspired by eye-tracking studies and then devise an objective function for finding cuts in these graphs that induce a good labeling. In its full generality, the problem is NP-hard, but we show that, in the case of two labels, an optimum labeling can be found in linear time. For the more general case, we propose heuristic solutions. Experiments on real click logs show that click-based labels align with the opinion of a panel of judges, especially as the consensus of the panel grows stronger.",2009,Web Search and Data Mining,Fields of study: eye trackinggraph partitiondirected graphsearch enginetime complexityworld wide webinformation retrievaldata miningmachine learningcomputer science
Efficient entity resolution for large heterogeneous information spaces,George Papadakis (National Technical University of Athens)Ekaterini Ioannou (Technical University of Crete)Claudia Niederée (Leibniz University of Hanover)Peter Fankhauser (Fraunhofer Society),"2222819638,2082927750,1820140241,149446523","We have recently witnessed an enormous growth in the volume of structured and semi-structured data sets available on the Web. An important prerequisite for using and combining such data sets is the detection and merge of information that describes the same real-world entities, a task known as Entity Resolution. To make this quadratic task efficient, blocking techniques are typically employed. However, the high dynamics, loose schema binding, and heterogeneity of (semi-)structured data, impose new challenges to entity resolution. Existing blocking approaches become inapplicable because they rely on the homogeneity of the considered data and a-priory known schemata. In this paper, we introduce a novel approach for entity resolution, scaling it up for large, noisy, and heterogeneous information spaces. It combines an attribute-agnostic mechanism for building blocks with intelligent block processing techniques that boost blocks with high expected utility, propagate knowledge about identified matches, and preempt the resolution process when it gets too expensive. Our extensive evaluation on real-world, large, heterogeneous data sets verifies that the suggested approach is both effective and efficient.",2011,Web Search and Data Mining,Fields of study: name resolutionsemi structured dataexpected utility hypothesistheoretical computer sciencedata miningdatabasemachine learningcomputer science
Exploiting New Sentiment-Based Meta-level Features for Effective Sentiment Analysis,Sérgio D. Canuto (Universidade Federal de Minas Gerais)Marcos André Gonçalves (Universidade Federal de Minas Gerais)Fabrício Benevenuto (Universidade Federal de Minas Gerais),"2027273974,2115586749,1976666824","In this paper we address the problem of automatically learning to classify the sentiment of short messages/reviews by exploiting information derived from meta-level features i.e., features derived primarily from the original bag-of-words representation. We propose new meta-level features especially designed for the sentiment analysis of short messages such as: (i) information derived from the sentiment distribution among the k nearest neighbors of a given short test document x , (ii) the distribution of distances of x to their neighbors and (iii) the document polarity of these neighbors given by unsupervised lexical-based methods. Our approach is also capable of exploiting information from the neighborhood of document x regarding (highly noisy) data obtained from 1.6 million Twitter messages with emoticons. The set of proposed features is capable of transforming the original feature space into a new one, potentially smaller and more informed. Experiments performed with a substantial number of datasets (nineteen) demonstrate that the effectiveness of the proposed sentiment-based meta-level features is not only superior to the traditional bag-of-word representation (by up to 16%) but is also superior in most cases to state-of-art meta-level features previously proposed in the literature for text classification tasks that do not take into account some idiosyncrasies of sentiment analysis. Our proposal is also largely superior to the best lexicon-based methods as well as to supervised combinations of them. In fact, the proposed approach is the only one to produce the best results in all tested datasets in all scenarios.",2016,Web Search and Data Mining,Fields of study: sentiment analysisworld wide webinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Multilingual probabilistic topic modeling and its applications in web mining and search,Marie-Francine Moens (Katholieke Universiteit Leuven)Ivan Vulié (Katholieke Universiteit Leuven),"1931663571,2227083720","Multilingual topic models are a fairly novel group of unsupervised, language-independent and generative machine learning models. This tutorial covers all key aspects of their probabilistic framework and demonstrates how to easily integrate these models into frameworks for cross-lingual and multilingual Web mining and search.",2014,Web Search and Data Mining,Fields of study: text miningnatural language processinginformation retrievaldata miningcomputer science
How user behavior is related to social affinity,Rina Panigrahy (Microsoft)Marc Najork (Microsoft)Yinglian Xie (Microsoft),"1923488504,2027155665,2122250353","Previous research has suggested that people who are in the same social circle exhibit similar behaviors and tastes. The rise of social networks gives us insights into the social circles of web users, and recommendation services (including search engines, advertisement engines, and collaborative filtering engines) provide a motivation to adapt recommendations to the interests of the audience. An important primitive for supporting these applications is the ability to quantify how connected two users are in a social network. The shortest-path distance between a pair of users is an obvious candidate measure. This paper introduces a new measure of ""affinity"" in social networks that takes into account not only the distance between two users, but also the number of edge-disjoint paths between them, i.e. the ""robustness"" of their connection. Our measure is based on a sketch-based approach, and affinity queries can be answered extremely efficiently (at the expense of a one-time offline sketch computation). We compare this affinity measure against the ""approximate shortest-path distance"", a sketch-based distance measure with similar efficiency characteristics. Our empirical study is based on a Hotmail email exchange graph combined with demographic information and Bing query history, and a Twitter mention-graph together with the text of the underlying tweets. We found that users who are close to each other - either in terms of distance or affinity - have a higher similarity in terms of demographics, queries, and tweets.",2012,Web Search and Data Mining,Fields of study: social networkworld wide webinformation retrievalsocial sciencedata miningmachine learningcomputer science
Detecting cohesive and 2-mode communities indirected and undirected networks,Jaewon Yang (Stanford University)Julian J. McAuley (Stanford University)Jure Leskovec (Stanford University),"2131921352,2041520510,1878631932","Networks are a general language for representing relational information among objects. An effective way to model, reason about, and summarize networks, is to discover sets of nodes with common connectivity patterns. Such sets are commonly referred to as network communities. Research on network community detection has predominantly focused on identifying communities of densely connected nodes in undirected networks. In this paper we develop a novel overlapping community detection method that scales to networks of millions of nodes and edges and advances research along two dimensions: the connectivity structure of communities, and the use of edge directedness for community detection. First, we extend traditional definitions of network communities by building on the observation that nodes can be densely interlinked in two different ways: In cohesive communities nodes link to each other, while in 2-mode communities nodes link in a bipartite fashion, where links predominate between the two partitions rather than inside them. Our method successfully detects both 2-mode as well as cohesive communities, that may also overlap or be hierarchically nested. Second, while most existing community detection methods treat directed edges as though they were undirected, our method accounts for edge directions and is able to identify novel and meaningful community structures in both directed and undirected networks, using data from social, biological, and ecological domains.",2014,Web Search and Data Mining,Fields of study: clique percolation methodcommunity structuredistributed computingdata miningmathematics
Post-click conversion modeling and analysis for non-guaranteed delivery display advertising,Rómer Rosales (Yahoo!)Haibin Cheng (Yahoo!)Eren Manavoglu (Yahoo!),"2318686101,2653230632,26108554","In on-line search and display advertising, the click-trough rate (CTR) has been traditionally a key measure of ad/campaign effectiveness. More recently, the market has gained interest in more direct measures of profitability, one early alternative is the conversion rate (CVR). CVRs measure the proportion of certain users who take a predefined, desirable action, such as a purchase, registration, download, etc.; as compared to simply page browsing. We provide a detailed analysis of conversion rates in the context of non-guaranteed delivery targeted advertising. In particular we focus on the post-click conversion (PCC) problem or the analysis of conversions after a user click on a referring ad. The key elements we study are the probability of a conversion given a click in a user/page context, P(conversion | click, context). We provide various fundamental properties of this process based on contextual information, formalize the problem of predicting PCC, and propose an approach for measuring attribute relevance when the underlying attribute distribution is non-stationary. We provide experimental analyses based on logged events from a large-scale advertising platform.",2012,Web Search and Data Mining,Fields of study: conversion marketingline searchprofitability indexmultimediaworld wide webdata mining
Evolution of two-sided markets,Ravi Kumar (Yahoo!)Yury Lifshits (Yahoo!)Andrew Tomkins (Google),"2232709231,2123167677,2535415812","Two-sided markets arise when two different types of users may realize gains by interacting with one another through one or more platforms or mediators. We initiate a study of the evolution of such markets. We present an empirical analysis of the value accruing to members of each side of the market, based on the presence of the other side. We codify the range of value curves into a general theoretical model, characterize the equilibrium states of two-sided markets in our model, and prove that each platform will converge to one of these equilibria. We give some early experimental results of the stability of two-sided markets, and close with a theoretical treatment of the formation of different kinds of coalitions in such markets.",2010,Web Search and Data Mining,Fields of study: thermodynamic equilibrium
Efficient and effective retrieval using selective pruning,Nicola Tonellotto (National Research Council)Craig Macdonald (University of Glasgow)Iadh Ounis (University of Glasgow),"1923078747,2148910894,336997814","Retrieval can be made more efficient by deploying dynamic pruning strategies such as WAND, which do not degrade effectiveness up to a given rank. It is possible to increase the efficiency of such techniques by pruning more 'aggressively'. However, this may reduce effectiveness. In this work, we propose a novel selective framework that determines the appropriate amount of pruning aggressiveness on a per-query basis, thereby increasing overall efficiency without significantly reducing overall effectiveness. We postulate two hypotheses about the queries that should be pruned more aggressively, which generate two approaches within our framework, based on query performance predictors and query efficiency predictors, respectively. We thoroughly experiment to ascertain the efficiency and effectiveness impacts of the proposed approaches, as part of a search engine deploying state-of-the-art learning to rank techniques. Our results on 50 million documents of the TREC ClueWeb09 collection show that by using query efficiency predictors to target inefficient queries, we observe that a 36% reduction in mean response time and a 50% reduction of the response times experienced by the slowest 10% of queries can be achieved while still ensuring effectiveness.",2013,Web Search and Data Mining,Fields of study: learning to ranktheoretical computer sciencedata miningmachine learningcomputer science
News recommendation via hypergraph learning: encapsulation of user behavior and news content,Lei Li (Florida International University)Tao Li (Florida International University),"2432045905,2472069284","Personalized news recommender systems have gained increasing attention in recent years. Within a news reading community, the implicit correlations among news readers, news articles, topics and named entities, e.g., what types of named entities in articles are preferred by users, and why users like the articles, could be valuable for building an effective news recommender. In this paper, we propose a novel news personalization framework by mining such correlations. We use hypergraph to model various high-order relations among different objects in news data, and formulate news recommendation as a ranking problem on fine-grained hypergraphs. In addition, by transductive inference, our proposed algorithm is capable of effectively handling the so-called cold-start problem. Extensive experiments on a data set collected from various news websites have demonstrated the effectiveness of our proposed algorithm.",2013,Web Search and Data Mining,Fields of study: personalizationworld wide webinformation retrievaldata miningmachine learningcomputer science
Effective latent space graph-based re-ranking model with global consistency,Hongbo Deng (The Chinese University of Hong Kong)Michael R. Lyu (The Chinese University of Hong Kong)Irwin King (The Chinese University of Hong Kong),"2153851291,2227744130,2121363826","Recently the re-ranking algorithms have been quite popular for web search and data mining. However, one of the issues is that those algorithms treat the content and link information individually. Inspired by graph-based machine learning algorithms, we propose a novel and general framework to model the re-ranking algorithm, by regularizing the smoothness of ranking scores over the graph, along with a regularizer on the initial ranking scores (which are obtained by the base ranker). The intuition behind the model is the global consistency over the graph: similar entities are likely to have the same ranking scores with respect to a query. Our approach simultaneously incorporates the content with other explicit or implicit link information in a latent space graph. Then an effective unified re-ranking algorithm is performed on the graph with respect to the query. To illustrate our methodology, we apply the framework to literature retrieval and expert finding applications on DBLP bibliography data. We compare the proposed method with the initial language model method and another PageRank-style re-ranking method. Also, we evaluate the proposed method with varying graphs and settings. Experimental results show that the improvement in our proposed method is consistent and promising.",2009,Web Search and Data Mining,Fields of study: rankingranking svmnull modelregularizationlanguage modelinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Adapting information bottleneck method for automatic construction of domain-oriented sentiment lexicon,Weifu DuSongbo Tan (Chinese Academy of Sciences)Xueqi Cheng (Chinese Academy of Sciences)Xiaochun Yun (Chinese Academy of Sciences),"2628090783,2162871507,2129598186,2679855209","Domain-oriented sentiment lexicons are widely used for fine-grained sentiment analysis on reviews; therefore, the automatic construction of domain-oriented sentiment lexicon is a fundamental and important task for sentiment analysis research. Most of existing construction approaches take only the kind of relationships between words into account, which makes them have a lot of room for improvement. This paper proposes an adapted information bottleneck method for the construction of domain-oriented sentiment lexicon. This approach can naturally make full use of the mutual reinforcement between documents and words by fusing three kinds of relationships either from words to documents or from words to words; either homogeneous or heterogeneous; either within-domain or cross-domain. The experimental results demonstrate that proposed method could dramatically improve the accuracy of the baseline approach on the construction of out-of-domain sentiment lexicon.",2010,Web Search and Data Mining,Fields of study: information bottleneck methodsentiment analysisnatural language processinginformation retrievaldata miningcomputer science
Personalized click model through collaborative filtering,Si Shen (Hong Kong University of Science and Technology)Botao Hu (Tsinghua University)Weizhu Chen (Microsoft)Qiang Yang (Hong Kong University of Science and Technology),"2231995331,2716949120,2108390110,2109031554","Click modeling aims to interpret the users' search click data in order to predict their clicking behavior. Existing models can well characterize the position bias of documents and snippets in relation to users' mainstream click behavior. Yet, current advances depict users' search actions only in a general setting by implicitly assuming that all users act in the same way, regardless of the fact that anyone, motivated with some individual interest, is more likely to click on a link than others. It is in light of this that we put forward a novel personalized click model to describe the user-oriented click preferences, which applies and extends matrix / tensor factorization from the view of collaborative filtering to connect users, queries and documents together. Our model serves as a generalized personalization framework that can be incorporated to the previously proposed click models and, in many cases, to their future extensions. Despite the sparsity of search click data, our personalized model demonstrates its advantage over the best click models previously discussed in the Web-search literature, supported by our large-scale experiments on a real dataset. A delightful bonus is the model's ability to gain insights into queries and documents through latent feature vectors, and hence to handle rare and even new query-document pairs much better than previous click models.",2012,Web Search and Data Mining,Fields of study: click pathpersonalizationcollaborative filteringsearch enginefeature vectormultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Disorder inequality: a combinatorial approach to nearest neighbor search,Navin Goyal (Georgia Institute of Technology)Yury Lifshits (California Institute of Technology)Hinrich Schütze (University of Stuttgart),"2240589970,2123167677,2035156685","We say that an algorithm for nearest neighbor search is combinatorial if only direct comparisons between two pairwise similarity values are allowed. Combinatorial algorithms for nearest neighbor search have two important advantages: (1) they do not map similarity values to artificial distance values and do not use the triangle inequality for the latter, and (2) they work for arbitrarily complicated data representations and similarity functions. In this paper we introduce a special property of the similarity function on a set S that leads to efficient combinatorial algorithms for S . The disorder constant D ( S ) of a set S is defined to ensure the following inequality: if x is the a 'th most similar object to z and y is the b 'th most similar object to z , then x is among the D ( S ) ( a + b ) most similar objects to y . Assuming that disorder is small we present the first two known combinatorial algorithms for nearest neighbors whose query time has logarithmic dependence on the size of S . The first one, called Ranwalk, is a randomized zero-error algorithm that always returns the exact nearest neighbor. It uses space quadratic in the input size in preprocessing, but is very efficient in query processing. The second algorithm, called Arwalk, uses near-linear space. It uses random choices in preprocessing, but the query processing is essentially deterministic. For an arbitrary query q , there is only a small probability that the chosen data structure does not support q Finally, we show that for the Reuters corpus average disorder is indeed quite small and that Ranwalk efficiently computes the nearest neighbor in most cases.",2008,Web Search and Data Mining,Fields of study: nearest neighbor chain algorithmfixed radius near neighborsbest bin firstnearest neighbor graphnearest neighbor searchrandomized algorithmdata structuremachine learningcomputer science
Harmony and dissonance: organizing the people's voices on political controversies,Rawia Awadallah (Max Planck Society)Maya Ramanath (Indian Institute of Technology Delhi)Gerhard Weikum (Max Planck Society),"2162925022,2061296320,514836396","The wikileaks documents about the death of Osama Bin Laden and the debates about the economic crisis in Greece and other European countries are some of the controversial topics being played on the news everyday. Each of these topics has many different aspects, and there is no absolute, simple truth in answering questions such as: should the EU guarantee the financial stability of each member country, or should the countries themselves be solely responsible? To understand the landscape of opinions, it would be helpful to know which politician or other stakeholder takes which position - support or opposition - on these aspects of controversial topics.",2012,Web Search and Data Mining,Fields of study: sentiment analysisnatural language processingsocial sciencedata miningcomputer science
Patent partner recommendation in enterprise social networks,Sen Wu (Tsinghua University)Jimeng Sun (IBM)Jie Tang (Tsinghua University),"2443423181,2110385854,2158012360","It is often challenging to incorporate users' interactions into a recommendation framework in an online model. In this paper, we propose a novel interactive learning framework to formulate the problem of recommending patent partners into a factor graph model. The framework involves three phases: 1) candidate generation, where we identify the potential set of collaborators; 2) candidate refinement, where a factor graph model is used to adjust the candidate rankings; 3) interactive learning method to efficiently update the existing recommendation model based on inventors' feedback. We evaluate our proposed model on large enterprise patent networks. Experimental results demonstrate that the recommendation accuracy of the proposed model significantly outperforms several baselines methods using content similarity, collaborative filtering and SVM-Rank. We also demonstrate the effectiveness and efficiency of the interactive learning, which performs almost as well as offline re-training, but with only 1 percent of the running time.",2013,Web Search and Data Mining,Fields of study: predictive modellingsocial networkknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
Domain bias in web search,Samuel Ieong (Microsoft)Nina Mishra (Microsoft)Eldar Sadikov (Stanford University)Li Zhang (Microsoft),"2267310192,2124493348,1993458034,2605633800","This paper uncovers a new phenomenon in web search that we call domain bias --- a user's propensity to believe that a page is more relevant just because it comes from a particular domain. We provide evidence of the existence of domain bias in click activity as well as in human judgments via a comprehensive collection of experiments. We begin by studying the difference between domains that a search engine surfaces and that users click. Surprisingly, we find that despite changes in the overall distribution of surfaced domains, there has not been a comparable shift in the distribution of clicked domains. Users seem to have learned the landscape of the internet and their click behavior has thus become more predictable over time. Next, we run a blind domain test, akin to a Pepsi/Coke taste test, to determine whether domains can shift a user's opinion of which page is more relevant. We find that domains can actually flip a user's preference about 25% of the time. Finally, we demonstrate the existence of systematic domain preferences, even after factoring out confounding issues such as position bias and relevance, two factors that have been used extensively in past work to explain user behavior. The existence of domain bias has numerous consequences including, for example, the importance of discounting click activity from reputable domains.",2012,Web Search and Data Mining,Fields of study: search engineworld wide webdata miningsimulationcomputer science
Efficient misbehaving user detection in online video chat services,Hanqiang Cheng (McGill University)Yu-Li Liang (University of Colorado Boulder)Xinyu Xing (Georgia Institute of Technology)Xue Liu (McGill University)Richard Han (University of Colorado Boulder)Qin Lv (University of Colorado Boulder)Shivakant Mishra (University of Colorado Boulder),"2231295513,2132264088,2282059511,2229430579,2128661168,2154485217,2110219690","Online video chat services, such as Chatroulette, Omegle, and vChatter are becoming increasingly popular and have attracted millions of users. One critical problem encountered in such applications is the presence of misbehaving users (""flashers"") and obscene content. Automatically filtering out obscene content from these systems in an efficient manner poses a difficult challenge. This paper presents a novel Fine-Grained Cascaded (FGC) classification solution that significantly speeds up the compute-intensive process of classifying misbehaving users by dividing image feature extraction into multiple stages and filtering out easily classified images in earlier stages, thus saving unnecessary computation costs of feature extraction in later stages. Our work is further enhanced by integrating new webcam-related contextual information (illumination and color) into the classification process, and a 2-stage soft margin SVM algorithm for combining multiple features. Evaluation results using real-world data set obtained from Chatroulette show that the proposed FGC based classification solution significantly outperforms state-of-the-art techniques.",2012,Web Search and Data Mining,Fields of study: featurefeature extractioninternet privacymultimediaworld wide webdata miningmachine learningcomputer science
Beyond 100 million entities: large-scale blocking-based resolution for heterogeneous data,George Papadakis (National Technical University of Athens)Ekaterini Ioannou (Technical University of Crete)Claudia Niederée (Leibniz University of Hanover)Themis Palpanas (University of Trento)Wolfgang Nejdl (Leibniz University of Hanover),"2222819638,2082927750,1820140241,2010554420,2228144965","A prerequisite for leveraging the vast amount of data available on the Web is Entity Resolution, i.e., the process of identifying and linking data that describe the same real-world objects. To make this inherently quadratic process applicable to large data sets, blocking is typically employed: entities (records) are grouped into clusters - the blocks - of matching candidates and only entities of the same block are compared. However, novel blocking techniques are required for dealing with the noisy, heterogeneous, semi-structured, user-generateddata in the Web, as traditional blocking techniques are inapplicable due to their reliance on schema information. The introduction of redundancy, improves the robustness of blocking methods but comes at the price of additional computational cost. In this paper, we present methods for enhancing the efficiency of redundancy-bearing blocking methods, such as our attribute-agnostic blocking approach. We introduce novel blocking schemes that build blocks based on a variety of evidences, including entity identifiers and relationships between entities; they significantly reduce the required number of comparisons, while maintaining blocking effectiveness at very high levels. We also introduce two theoretical measures that provide a reliable estimation of the performance of a blocking method, without requiring the analytical processing of its blocks. Based on these measures, we develop two techniques for improving the performance of blocking: combining individual, complementary blocking schemes, and purging blocks until given criteria are satisfied. We test our methods through an extensive experimental evaluation, using a voluminous data set with 182 million heterogeneous entities. The outcomes of our study show the applicability and the high performance of our approach.",2012,Web Search and Data Mining,Fields of study: name resolutionlinked datasatisfiabilitytheoretical computer scienceworld wide webdata miningdatabasecomputer science
On compressing the textual web,Paolo Ferragina (University of Pisa)Giovanni Manzini (University of Eastern Piedmont),"531878810,2022609102","Nowadays we know how to effectively compress most basic components of any modern search engine, such as, the graphs arising from the Web structure and/or its usage, the posting lists, and the dictionary of terms. But we are not aware of any study which has deeply addressed the issue of compressing the raw Web pages. Many Web applications use simple compression algorithms--- e.g. gzip, or word-based Move-to-Front or Huffman coders-and conclude that, even compressed, raw data take more space than Inverted Lists. In this paper we investigate two typical scenarios of use of data compression for large Web collections. In the first scenario, the compressed pages are stored on disk and we only need to support the fast scanning of large parts of the compressed collection (such as for map-reduce paradigms). In the second scenario, we consider the fast access to individual pages of the compressed collection that is distributed among the RAMs of many PCs (such as for search engines and miners). For the first scenario, we provide a thorough experimental comparison among state-of-the-art compressors thus indicating pros and cons of the available solutions. For the second scenario, we compare known compressed-storage solutions with the new algorithmic technology of compressed self-indexes [NM07]. Our results show that Web pages are more compressible than expected and, consequently, that some common beliefs in this area should be reconsidered. Our results are novel for the large spectrum of tested approaches and the size of datasets, and provide a threefold contribution: a non-trivial baseline for designing new compressed-storage solutions, a guide for software developers faced with Web-page storage, and a natural complement to the recent figures on InvertedList-compression achieved by [Yan et al, sigir 09 and www 09].",2010,Web Search and Data Mining,Fields of study: data compressiontheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Collaborative annotation for context-aware retrieval,Stefano Mizzaro (University of Udine)Elena Nazzi (University of Udine)Luca Vassena (University of Udine),"156657161,1137116929,1423430044","We discuss how collaborative annotations can be exploited to simplify and improve the management of context and resources in the context-aware retrieval field. We apply this approach to our Context Aware Browser, a general purpose solution to Web content perusal by means of mobile devices, based on the user's context. Instead of relying on a pool of experts and on a rigid categorization, as it is usually done in the context-aware field, our solution allows the crowd of users to model, control and manage the contextual knowledge through collaboration and participation. We propose two models and we outline an example of application.",2009,Web Search and Data Mining,Fields of study: mobile deviceworld wide webinformation retrievaldata miningcomputer science
Arrival and departure dynamics in social networks,Shaomei Wu (Facebook)Atish Das Sarma (eBay)Alex Fabrikant (Google)Silvio Lattanzi (Google)Andrew Tomkins (Google),"2655709087,2266878914,2619392593,1989808900,2535415812","In this paper, we consider the natural arrival and departure of users in a social network, and ask whether the dynamics of arrival, which have been studied in some depth, also explain the dynamics of departure, which are not as well studied. Through study of the DBLP co-authorship network and a large online social network, we show that the dynamics of departure behave differently from the dynamics of formation. In particular, the probability of departure of a user with few friends may be understood most accurately as a function of the raw number of friends who are active. For users with more friends, however, the probability of departure is best predicted by the overall fraction of the user's neighborhood that is active, independent of size. We then study global properties of the sub-graphs induced by active and inactive users, and show that active users tend to belong to a core that is densifying and is significantly denser than the inactive users. Further, the inactive set of users exhibit a higher density and lower conductance than the degree distribution alone can explain. These two aspects suggest that nodes at the fringe are more likely to depart and subsequent departure are correlated among neighboring nodes in tightly-knit communities.",2013,Web Search and Data Mining,Fields of study: social networksimulation
Real-Time Bidding: A New Frontier of Computational Advertising Research,Jun Wang (University College London)Shuai Yuan (University College London),"2557836567,2683024208","In display and mobile advertising, the most significant development in recent years is the Real-Time Bidding (RTB), which allows selling and buying in real-time one ad impression at a time. Since then, RTB has fundamentally changed the landscape of the digital marketing by scaling the buying process across a large number of available inventories. The demand for automation, integration and optimisation in RTB brings new research opportunities in the IR/DM/ML fields. However, despite its rapid growth and huge potential, many aspects of RTB remain unknown to the research community for many reasons. In this tutorial, together with invited distinguished speakers from online advertising industry, we aim to bring the insightful knowledge from the real-world systems to bridge the gaps and provide an overview of the fundamental infrastructure, algorithms, and technical and research challenges of this new frontier of computational advertising. We will also introduce to researchers the datasets, tools, and platforms which are publicly available thus they can get hands-on quickly.",2015,Web Search and Data Mining,Fields of study: real time biddingworld wide webdata miningcomputer science
Crowdsourcing 101: putting the WSDM of crowds to work for you,Omar Alonso (Microsoft)Matthew Lease (University of Texas at Austin),"2292406529,2123681105","Crowdsourcing has emerged in recent years as an exciting new avenue for leveraging the tremendous potential and resources of today's digitally-connected, diverse, distributed workforce. Generally speaking, crowdsourcing describes outsourcing of tasks to a large group of people instead of assigning such tasks to an in-house employee or contractor. Crowdsourcing platforms such as Amazon Mechanical Turk and CrowdFlower have gained particular attention as active online market places for reaching and tapping into this glut of a still largely under-utilized workforce. Crowdsourcing offers intriguing new opportunities for accomplishing different kinds of tasks or achieving broader participation than previously possible, as well as completing standard tasks more accurately in less time and at lower cost. Unlocking the potential of crowdsourcing in practice, however, requires a tri-partite understanding of principles, platforms, and best practices. This tutorial will introduce the opportunities and challenges of crowdsourcing while discussing the three issues above. This will provide attendees with a basic foundation to begin applying crowdsourcing in the context of their own particular tasks.",2011,Web Search and Data Mining,Fields of study: crowdsourcing software developmentcrowdsourcingbest practicedata scienceknowledge managementworld wide webdata miningsimulationcomputer science
A straw shows which way the wind blows: ranking potentially popular items from early votes,Peifeng Yin (Pennsylvania State University)Ping Luo (Hewlett-Packard)Min Wang (Hewlett-Packard)Wang-Chien Lee (Pennsylvania State University),"2113084173,2291210646,2467205710,2143778659","Prediction of popular items in online content sharing systems has recently attracted a lot of attention due to the tremendous need of users and its commercial values. Different from previous works that make prediction by fitting a popularity growth model, we tackle this problem by exploiting the latent conforming and maverick personalities of those who vote to assess the quality of on-line items. We argue that the former personality prompts a user to cast her vote conforming to the majority of the service community while on the contrary the later personality makes her vote different from the community. We thus propose a Conformer-Maverick (CM) model to simulate the voting process and use it to rank top- k potentially popular items based on the early votes they received. Through an extensive experimental evaluation, we validate our ideas and find that our proposed CM model achieves better performance than baseline solutions, especially for smaller k .",2012,Web Search and Data Mining,Fields of study: generative modelconformational isomerismworld wide webdata miningmachine learningsimulationstatisticscomputer science
Collaborative Denoising Auto-Encoders for Top-N Recommender Systems,Yao Wu (Simon Fraser University)Christopher DuBoisAlice X. Zheng (Microsoft)Martin Ester (Simon Fraser University),"2139499555,2653695610,2005707679,2067196623","Most real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics.",2016,Web Search and Data Mining,Fields of study: collaborative filteringrecommender systemmultimediaworld wide webdata miningmachine learningcomputer science
Entity linking and retrieval for semantic search,Edgar Meij (Yahoo!)Krisztian Balog (University of Stavanger)Daan Odijk (University of Amsterdam),"2160283388,2100338238,1988427373","More and more search engine users are expecting direct answers to their information needs, rather than links to documents. Semantic search and its recent applications enabled search engines to organize their wealth of information around entities. Entity linking and retrieval provide the building stones for organizing the web of entities. This tutorial aims to cover all facets of semantic search from a unified point of view and connect real-world applications with results from scientific publications. We provide a comprehensive overview of entity linking and retrieval in the context of semantic search and thoroughly explore techniques for query understanding, entity-based retrieval and ranking on unstructured text, structured knowledge repositories, and a mixture of these. We point out the connections between published approaches and applications, and provide hands-on examples on real-world use cases and datasets.",2014,Web Search and Data Mining,Fields of study: human computer information retrievalconcept searchsearch engineentity linkingsemantic searchinformation retrievaldata miningdatabasecomputer science
Expediting search trend detection via prediction of query counts,Nadav Golbandi Golbandi (Yahoo!)Liran Katzir Katzir (Microsoft)Yehuda Koren Koren (Google)Ronny Lempel Lempel (Yahoo!),"2642611369,2664919080,1966367906,2249016471","The massive volume of queries submitted to major Web search engines reflects human interest at a global scale. While the popularity of many search queries is stable over time or fluctuates with periodic regularity, some queries experience a sudden and ephemeral rise in popularity that is unexplained by their past volumes. Typically the popularity surge is precipitated by some real-life event in the news cycle. Such queries form what are known as search trends. All major search engines, using query log analysis and other signals, invest in detecting such trends. The goal is to surface trends accurately, with low latency relative to the actual event that sparked the trend. This work formally defines precision, recall and latency metrics related to top-k search trend detection. Then, observing that many trend detection algorithms rely on query counts, we develop a linear auto-regression model to predict future query counts. Subsequently, we tap the predicted counts to expedite search trend detection by plugging them into an existing trend detection scheme. Experimenting with query logs from a major Web search engine, we report both the stand-alone accuracy of our query count predictions, as well as the task-oriented effects of the prediction on the emitted trends. We show an average reduction in trend detection latency of roughly twenty minutes, with a negligible impact on the precision and recall metrics.",2013,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Normalizing web product attributes and discovering domain ontology with minimal effort,Tak-Lam Wong (The Chinese University of Hong Kong)Lidong Bing (The Chinese University of Hong Kong)Wai Lam (The Chinese University of Hong Kong),"2141897598,2160800796,2119595446","We have developed a framework aiming at normalizing product attributes from Web pages collected from different Web sites without the need of labeled training examples. It can deal with pages composed of different layout format and content in an unsupervised manner. As a result, it can handle a variety of different domains with minimal effort. Our model is based on a generative probabilistic graphical model incorporated with Hidden Markov Models (HMM) considering both attribute names and attribute values to extract and normalize text fragments from Web pages in a unified manner. Dirichlet Process is employed to handle the unlimited number of attributes in a domain. An unsupervised inference method is proposed to predict the unobservable variables. We have also developed a method to automatically construct a domain ontology using the normalized product attributes which are the output of the inference on the graphical model. We have conducted extensive experiments and compared with existing works using prouct Web pages collected from real-world Web sites in three different domains to demonstrate the effectiveness of our framework.",2011,Web Search and Data Mining,Fields of study: web modelinggraphical modelweb mininginformation extractionhidden markov modeldata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Mining common topics from multiple asynchronous text streams,Xiang Wang (Tsinghua University)Kai Zhang (Tsinghua University)Xiaoming Jin (Tsinghua University)Dou Shen (Microsoft),"2099725100,2663094198,2127078753,2136428695","Text streams are becoming more and more ubiquitous, in the forms of news feeds, weblog archives and so on, which result in a large volume of data. An effective way to explore the semantic as well as temporal information in text streams is topic mining, which can further facilitate other knowledge discovery procedures. In many applications, we are facing multiple text streams which are related to each other and share common topics. The correlation among these streams can provide more meaningful and comprehensive clues for topic mining than those from each individual stream. However, it is nontrivial to explore the correlation with the existence of asynchronism among multiple streams, i.e. documents from different streams about the same topic may have different timestamps, which remains unsolved in the context of topic mining. In this paper, we formally address this problem and put forward a novel algorithm based on the generative topic model. Our algorithm consists of two alternate steps: the first step extracts common topics from multiple streams based on the adjusted timestamps by the second step; the second step adjusts the timestamps of the documents according to the time distribution of the discovered topics by the first step. We perform these two steps alternately and a monotone convergence of our objective function is guaranteed. The effectiveness and advantage of our approach were justified by extensive empirical studies on two real data sets consisting of six research paper streams and two news article streams, respectively.",2009,Web Search and Data Mining,Fields of study: topic modelempirical researchtext miningworld wide webinformation retrievaldata miningmachine learningcomputer science
Adapting deep RankNet for personalized search,Yang Song (Microsoft)Hongning Wang (University of Illinois at Urbana–Champaign)Xiaodong He (Microsoft),"2021276105,2157880984,2106698597","RankNet is one of the widely adopted ranking models for web search tasks. However, adapting a generic RankNet for personalized search is little studied. In this paper, we first continue-trained a variety of RankNets with different number of hidden layers and network structures over a previously trained global RankNet model, and observed that a deep neural network with five hidden layers gives the best performance. To further improve the performance of adaptation, we propose a set of novel methods categorized into two groups. In the first group, three methods are proposed to properly assess the usefulness of each adaptation instance and only leverage the most informative instances to adapt a user-specific RankNet model. These assessments are based on KL-divergence, click entropy or a heuristic to ignore top clicks in adaptation queries. In the second group, two methods are proposed to regularize the training of the neural network in RankNet: one of these methods regularize the error back-propagation via a truncated gradient approach, while the other method limits the depth of the back propagation when adapting the neural network. We empirically evaluate our approaches using a large-scale real-world data set. Experimental results exhibit that our methods all give significant improvements over a strong baseline ranking system, and the truncated gradient approach gives the best performance, significantly better than all others.",2014,Web Search and Data Mining,Fields of study: deep learningworld wide webinformation retrievaldata miningartificial intelligencemachine learningcomputer science
"Heterogeneous graph-based intent learning with queries, web pages and Wikipedia concepts",Xiang Ren (University of Illinois at Urbana–Champaign)Yujing Wang (Microsoft)Xiao Yu (University of Illinois at Urbana–Champaign)Jun Yan (Microsoft)Zheng Chen (Microsoft)Jiawei Han (University of Illinois at Urbana–Champaign),"2129405715,2307008282,2160715520,2150635322,2425877144,2121939561","The problem of learning user search intents has attracted intensive attention from both industry and academia. However, state-of-the-art intent learning algorithms suffer from different drawbacks when only using a single type of data source. For example, query text has difficulty in distinguishing ambiguous queries; search log is bias to the order of search results and users' noisy click behaviors. In this work, we for the first time leverage three types of objects, namely queries, web pages and Wikipedia concepts collaboratively for learning generic search intents and construct a heterogeneous graph to represent multiple types of relationships between them. A novel unsupervised method called heterogeneous graph-based soft-clustering is developed to derive an intent indicator for each object based on the constructed heterogeneous graph. With the proposed co-clustering method, one can enhance the quality of intent understanding by taking advantage of different types of data, which complement each other, and make the implicit intents easier to interpret with explicit knowledge from Wikipedia concepts. Experiments on two real-world datasets demonstrate the power of the proposed method where it achieves a 9.25% improvement in terms of NDCG on search ranking task and a 4.67% enhancement in terms of Rand index on object co-clustering task compared to the best state-of-the-art method.",2014,Web Search and Data Mining,Fields of study: brandsemantic searchworld wide webinformation retrievaldata miningmachine learningcomputer science
Fast learning of document ranking functions with the committee perceptron,Jonathan L. Elsas (Carnegie Mellon University)Vitor R. Carvalho (Carnegie Mellon University)Jaime G. Carbonell (Carnegie Mellon University),"2132217740,2047752476,2100444261","This paper presents a new variant of the perceptron algorithm using selective committee averaging (or voting). We apply this agorithm to the problem of learning ranking functions for document retrieval, known as the ""Learning to Rank"" problem. Most previous algorithms proposed to address this problem focus on minimizing the number of misranked document pairs in the training set. The committee perceptron algorithm improves upon existing solutions by biasing the final solution towards maximizing an arbitrary rank-based performance metrics. This method performs comparably or better than two state-of-the-art rank learning algorithms, and also provides significant training time improvements over those methods, showing over a 45-fold reduction in training time compared to ranking SVM",2008,Web Search and Data Mining,Fields of study: ranking svmperceptronlearning to rankdocument retrievaldata miningpattern recognitionmachine learningcomputer science
Optimizing budget constrained spend in search advertising,Chinmay Karande (Facebook)Aranyak Mehta (Google)Ramakrishnan Srikant (Google),"2437772621,2282895076,2069583943","Search engine ad auctions typically have a significant fraction of advertisers who are budget constrained, i.e., if allowed to participate in every auction that they bid on, they would spend more than their budget. This yields an important problem: selecting the ad auctions which these advertisers participate, in order to optimize different system objectives such as the return on investment for advertisers, and the quality of ads shown to users. We present a system and algorithms for optimizing budget constrained spend. The system is designed be deployed in a large search engine, with hundreds of thousands of advertisers, millions of searches per hour, and with the query stream being only partially predictable. We have validated the system design by implementing it in the Google ads serving system and running experiments on live traffic. We have also compared our algorithm to previous work that casts this problem as a large linear programming problem limited to popular queries, and show that our algorithms yield substantially better results.",2013,Web Search and Data Mining,Fields of study: share of voiceonline advertisingworld wide webdata miningsimulationcomputer science
To each his own: personalized content selection based on text comprehensibility,Chenhao Tan (Cornell University)Evgeniy Gabrilovich (Yahoo!)Bo Pang (Yahoo!),"2707943876,1804802447,2129095822","Imagine a physician and a patient doing a search on antibiotic resistance. Or a chess amateur and a grandmaster conducting a search on Alekhine's Defence. Although the topic is the same, arguably the two users in each case will satisfy their information needs with very different texts. Yet today search engines mostly adopt the one-size-fits-all solution, where personalization is restricted to topical preference. We found that users do not uniformly prefer simple texts, and that the text comprehensibility level should match the user's level of preparedness. Consequently, we propose to model the comprehensibility of texts as well as the users' reading proficiency in order to better explain how different users choose content for further exploration. We also model topic-specific reading proficiency, which allows us to better explain why a physician might choose to read sophisticated medical articles yet simple descriptions of SLR cameras. We explore different ways to build user profiles, and use collaborative filtering techniques to overcome data sparsity. We conducted experiments on large-scale datasets from a major Web search engine and a community question answering forum. Our findings confirm that explicitly modeling text comprehensibility can significantly improve content ranking (search results or answers, respectively).",2012,Web Search and Data Mining,Fields of study: user modelingquestion answeringweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning multiple-question decision trees for cold-start recommendation,Mingxuan Sun (Georgia Institute of Technology)Fuxin Li (Georgia Institute of Technology)Joonseok Lee (Georgia Institute of Technology)Ke Zhou (Georgia Institute of Technology)Guy Lebanon (Georgia Institute of Technology)Hongyuan Zha (Georgia Institute of Technology),"2306158810,2210731946,2141663339,2311638158,2312000221,2099091510","For cold-start recommendation, it is important to rapidly profile new users and generate a good initial set of recommendations through an interview process --- users should be queried adaptively in a sequential fashion, and multiple items should be offered for opinion solicitation at each trial. In this work, we propose a novel algorithm that learns to conduct the interview process guided by a decision tree with multiple questions at each split. The splits, represented as sparse weight vectors, are learned through an L_1-constrained optimization framework. The users are directed to child nodes according to the inner product of their responses and the corresponding weight vector. More importantly, to account for the variety of responses coming to a node, a linear regressor is learned within each node using all the previously obtained answers as input to predict item ratings. A user study, preliminary but first in its kind in cold-start recommendation, is conducted to explore the efficient number and format of questions being asked in a recommendation survey to minimize user cognitive efforts. Quantitative experimental validations also show that the proposed algorithm outperforms state-of-the-art approaches in terms of both the prediction accuracy and user cognitive efforts.",2013,Web Search and Data Mining,Fields of study: cold startcollaborative filteringdecision treerecommender systemworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Learning similarity function for rare queries,Jingfang Xu (Microsoft)Gu Xu (Microsoft),"2257428657,2716064681","The key element of many query processing tasks can be formalized as calculation of similarities between queries. These include query suggestion, query reformulation, and query expansion. Although many methods have been proposed for query similarity calculation, they could perform poorly on rare queries. As far as we know, there was no previous work particularly about rare query similarity calculation, and this paper tries to study this problem. Specifically, we address three problems. Firstly, we define an n-gram space to represent queries with their own content and a similarity function to measure the similarities between queries. Secondly, we propose learning the similarity function by leveraging the training data derived from user behavior data. This is formalized as an optimization problem and a metric learning approach is employed to solve it efficiently. Finally, we exploit locality sensitive hashing for efficient retrieval of similar queries from a large query repository. We experimentally verified the effectiveness of the proposed approach by showing that our method can indeed enhance the accuracy of query similarity calculation for rare queries and efficiently retrieve similar queries. As an application, we also experimentally demonstrated that the similar queries found by our method can significantly improve search relevance.",2011,Web Search and Data Mining,Fields of study: rankingsargablerdf query languageboolean conjunctive queryonline aggregationweb search queryweb query classificationlocality sensitive hashingspatial queryquery by examplequery expansionrange queryquery optimizationquery languageoptimization probleminformation retrievaldata miningdatabasemachine learningcomputer science
Modeling and Predicting Retweeting Dynamics on Microblogging Platforms,Shuai Gao (Shandong University)Jun Ma (Shandong University)Zhumin Chen (Shandong University),"2670111539,2640993773,2701381446","Popularity prediction on microblogging platforms aims to predict the future popularity of a message based on its retweeting dynamics in the early stages. Existing works mainly focus on exploring effective features for prediction, while ignoring the underlying arrival process of retweets. Also, the effect of user activity variation on the retweeting dynamics in the early stages has been neglected. In this paper, we propose an extended reinforced Poisson process model with time mapping process to model the retweeting dynamics and predict the future popularity. The proposed model explicitly characterizes the process through which a message gain its retweets, by capturing a power-law temporal relaxation function corresponding to the aging in the ability of the message to attract new retweets and an exponential reinforcement mechanism characterizing the ""richer-get-richer"" phenomenon. Further, we introduce the notation of weibo time and integrate a time mapping process into the proposed model to eliminate the effect of user activity variation. Extensive experiments on two Weibo datasets, with 10K and 18K messages respectively, well demonstrate the effectiveness of our proposed model in popularity prediction.",2015,Web Search and Data Mining,Fields of study: data scienceworld wide webdata miningsimulationcomputer science
"Anomaly, event, and fraud detection in large network datasets",Leman Akoglu (Stony Brook University)Christos Faloutsos (Carnegie Mellon University),"2288278917,2198983026","Detecting anomalies and events in data is a vital task, with numerous applications in security, finance, health care, law enforcement, and many others. While many techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured graph data have been of focus recently. As objects in graphs have long-range correlations, novel technology has been developed for abnormality detection in graph data. The goal of this tutorial is to provide a general, comprehensive overview of the state-of-the-art methods for anomaly, event, and fraud detection in data represented as graphs. As a key contribution, we provide a thorough exploration of both data mining and machine learning algorithms for these detection tasks. We give a general framework for the algorithms, categorized under various settings: unsupervised vs.(semi-)supervised, for static vs. dynamic data. We focus on the scalability and effectiveness aspects of the methods, and highlight results on crucial real-world applications, including accounting fraud and opinion spam detection.",2013,Web Search and Data Mining,Fields of study: anomaly detectiondata scienceworld wide webdata miningmachine learningcomputer science
Efficient indexing of repeated n-grams,Samuel Huston (University of Massachusetts Amherst)Alistair Moffat (University of Melbourne)W. Bruce Croft (University of Massachusetts Amherst),"2093587599,2155888323,2127889770","The identification of repeated n -gram phrases in text has many practical applications, including authorship attribution, text reuse identification, and plagiarism detection. We consider methods for finding the repeated n -grams in text corpora, with emphasis on techniques that can be effectively scaled across a cluster of processors to handle very large amounts of text. We compare our proposed method to existing techniques using the 1.5 TB TREC ClueWeb-B text collection, using both single-processor and multi-processor approaches. The experiments show that our method offers an important tradeoff between speed and temporary storage space, and provides an alternative to previous approaches that scales almost linearly in the length of the sequence, is largely independent of n , and provides a uniform workload balance across the set of available processors.",2011,Web Search and Data Mining,Fields of study: hash filtern gramscalabilityperformancetheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
On clustering heterogeneous social media objects with outlier links,Guo-Jun Qi (University of Illinois at Urbana–Champaign)Charu C. Aggarwal (IBM)Thomas S. Huang (University of Illinois at Urbana–Champaign),"2237849324,2146335907,2149631809","The clustering of social media objects provides intrinsic understanding of the similarity relationships between documents, images, and their contextual sources. Both content and link structure provide important cues for an effective clustering algorithm of the underlying objects. While link information provides useful hints for improving the clustering process, it also contains a significant amount of noisy information. Therefore, a robust clustering algorithm is required to reduce the impact of noisy links. In order to address the aforementioned problems, we propose heterogeneous random fields to model the structure and content of social media networks. We design a probability measure on the social media networks which output a configuration of clusters that are consistent with both content and link structure. Furthermore, noisy links can also be detected, and their impact on the clustering algorithm can be significantly reduced. We conduct experiments on a real social media network and show the advantage of the method over other state-of-the-art algorithms.",2012,Web Search and Data Mining,Fields of study: hierarchical clustering of networksflame clusteringcorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmsocial mediafuzzy clusteringclustering high dimensional datarandom fieldprobability measurecluster analysisconsensus clusteringtheoretical computer sciencedata miningmachine learningstatisticscomputer science
Of hammers and nails: an empirical comparison of three paradigms for processing large graphs,Marc Najork (Microsoft)Dennis Fetterly (Microsoft)Alan Halverson (Microsoft)Krishnaram Kenthapadi (Microsoft)Sreenivas Gollapudi (Microsoft),"2027155665,1992570377,2040370899,2088122068,2023254819","Many phenomena and artifacts such as road networks, social networks and the web can be modeled as large graphs and analyzed using graph algorithms. However, given the size of the underlying graphs, efficient implementation of basic operations such as connected component analysis, approximate shortest paths, and link-based ranking ( e.g. PageRank) becomes challenging. This paper presents an empirical study of computations on such large graphs in three well-studied platform models, viz ., a relational model, a data-parallel model, and a special-purpose in-memory model. We choose a prototypical member of each platform model and analyze the computational efficiencies and requirements for five basic graph operations used in the analysis of real-world graphs viz ., PageRank, SALSA, Strongly Connected Components (SCC), Weakly Connected Components (WCC), and Approximate Shortest Paths (ASP). Further, we characterize each platform in terms of these computations using model-specific implementations of these algorithms on a large web graph. Our experiments show that there is no single platform that performs best across different classes of operations on large graphs. While relational databases are powerful and flexible tools that support a wide variety of computations, there are computations that benefit from using special-purpose storage systems and others that can exploit data-parallel platforms.",2012,Web Search and Data Mining,Fields of study: modular decompositionmemory modelstrongly connected componentconnected componentshortest path problemrelational modelspecificationrelational databaseempirical researchsocial networktheoretical computer scienceworld wide webdistributed computingdata miningmachine learningcomputer science
Understanding and Predicting Graded Search Satisfaction,Jiepu Jiang (University of Massachusetts Amherst)Ahmed Hassan Awadallah (Microsoft)Xiaolin Shi (Microsoft)Ryen W. White (Microsoft),"2635748659,2094223786,2693734624,2096583854","Understanding and estimating satisfaction with search engines is an important aspect of evaluating retrieval performance. Research to date has modeled and predicted search satisfaction on a binary scale, i.e., the searchers are either satisfied or dissatisfied with their search outcome. However, users' search experience is a complex construct and there are different degrees of satisfaction. As such, binary classification of satisfaction may be limiting. To the best of our knowledge, we are the first to study the problem of understanding and predicting graded (multi-level) search satisfaction. We ex-amine sessions mined from search engine logs, where searcher satisfaction was also assessed on multi-point scale by human annotators. Leveraging these search log data, we observe rich and non-monotonous changes in search behavior in sessions with different degrees of satisfaction. The findings suggest that we should predict finer-grained satisfaction levels. To address this issue, we model search satisfaction using features indicating search outcome, search effort, and changes in both outcome and effort during a session. We show that our approach can predict subtle changes in search satisfaction more accurately than state-of-the-art methods, affording greater insight into search satisfaction. The strong performance of our models has implications for search providers seeking to accu-rately measure satisfaction with their services.",2015,Web Search and Data Mining,Fields of study: computer user satisfactionutilityevaluationknowledge managementdata miningsimulationcomputer science
Crawl ordering by search impact,Sandeep Pandey (Carnegie Mellon University)Christopher Olston (Yahoo!),"2137133237,2023450202","We study how to prioritize the fetching of new pages under the objective of maximizing the quality of search results. In particular, our objective is to fetch new pages that have the most impact, where the impact of a page is equal to the number of times the page appears in the top K search results for queries, for some constant K , e.g., K = 10. Since the impact of a page depends on its relevance score for queries, which in turn depends on the page content, the main difficulty lies in estimating the impact of the page before actually fetching it. Hence, impact must be estimated based on the limited information that is available prior to fetching page content, e.g., the URL string, number of in-links, referring anchortext We formally characterize this problem and study its hardness. We leverage our formalism to design a new impact-driven crawling policy, and demonstrate its effectiveness using real world data. Our technique ensures that the crawler acquires content relevant to ""tail topics"" that are obscure but of interest to some users, rather than just redundantly accumulating content on popular topics.",2008,Web Search and Data Mining,Fields of study: page viewweb crawlermultimediaworld wide webinformation retrievaldata miningsimulationcomputer science
Precomputing search features for fast and accurate query classification,Venkatesh Ganti (Microsoft)Arnd Christian König (Microsoft)Xiao Li (Microsoft),"2675821039,2157050567,2645835011","Query intent classification is crucial for web search and advertising. It is known to be challenging because web queries contain less than three words on average, and so provide little signal to base classification decisions on. At the same time, the vocabulary used in search queries is vast: thus, classifiers based on word-occurrence have to deal with a very sparse feature space, and often require large amounts of training data. Prior efforts to address the issue of feature sparseness augmented the feature space using features computed from the results obtained by issuing the query to be classified against a web search engine. However, these approaches induce high latency, making them unacceptable in practice. In this paper, we propose a new class of features that realizes the benefit of search-based features without high latency. These leverage co-occurrence between the query keywords and tags applied to documents in search results, resulting in a significant boost to web query classification accuracy. By pre-computing the tag incidence for a suitably chosen set of keyword-combinations, we are able to generate the features online with low latency and memory requirements. We evaluate the accuracy of our approach using a large corpus of real web queries in the context of commercial search.",2010,Web Search and Data Mining,Fields of study: sargablesearch analyticsphrase searchbeam searchweb search queryweb query classificationquery expansionlow latencysearch enginefeature vectorsemantic searchweb search engineworld wide webinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Mining named entities with temporally correlated bursts from multilingual web news streams,Alexander Kotov (University of Illinois at Urbana–Champaign)ChengXiang Zhai (University of Illinois at Urbana–Champaign)Richard Sproat (University of Illinois at Urbana–Champaign),"2558015719,2152766206,721973866","In this work, we study a new text mining problem of discovering named entities with temporally correlated bursts of mention counts in multiple multilingual Web news streams. Mining named entities with temporally correlated bursts of mention counts in multilingual text streams has many interesting and important applications, such as identification of the latent events, attracting the attention of on-line media in different countries, and valuable linguistic knowledge in the form of transliterations. While mining ""bursty"" terms in a single text stream has been studied before, the problem of detecting terms with temporally correlated bursts in multilingual Web streams raises two new challenges: (i) correlated terms in multiple streams may have bursts that are of different orders of magnitude in their intensity and (ii) bursts of correlated terms may be separated by time gaps. We propose a two-stage method for mining items with temporally correlated bursts from multiple data streams, which addresses both challenges. In the first stage of the method, the temporal behavior of different entities is normalized by modeling them with the Markov-Modulated Poisson Process. In the second stage, a dynamic programming algorithm is used to discover correlated bursts of different items, that can be potentially separated by time gaps. We evaluated our method with the task of discovering transliterations of named entities from multilingual Web news streams. Experimental results indicate that our method can not only effectively discover named entities with correlated bursts in multilingual Web news streams, but also outperforms two state-of-the-art baseline methods for unsupervised discovery of transliterations in static text collections.",2011,Web Search and Data Mining,Fields of study: dynamic programmingtext miningdata scienceworld wide webdata miningmachine learningcomputer science
Web-scale table census and classification,Eric Crestan (Yahoo!)Patrick Pantel (Microsoft),"2704220796,2250462127","We report on a census of the types of HTML tables on the Web according to a fine-grained classification taxonomy describing the semantics that they express. For each relational table type, we describe open challenges for extracting from them semantic triples, i.e., knowledge. We also present TabEx, a supervised framework for web-scale HTML table classification and apply it to the task of classifying HTML tables into our taxonomy. We show empirical evidence, through a large-scale experimental analysis over a crawl of the Web, that classification accuracy significantly outperforms several baselines. We present a detailed feature analysis and outline the most salient features for each table type.",2011,Web Search and Data Mining,Fields of study: pattern recognitionexperimental analysis of behaviorempirical evidencedata modelbiological classificationinformation extractiondata scienceworld wide webinformation retrievaldata miningcomputer science
Will This Paper Increase Your h -index?: Scientific Impact Prediction,Yuxiao Dong (University of Notre Dame)Reid A. Johnson (University of Notre Dame)Nitesh V. Chawla (University of Notre Dame),"2157080782,2127251370,1979796846","Scientific impact plays a central role in the evaluation of the output of scholars, departments, and institutions. A widely used measure of scientific impact is citations, with a growing body of literature focused on predicting the number of citations obtained by any given publication. The effectiveness of such predictions, however, is fundamentally limited by the power-law distribution of citations, whereby publications with few citations are extremely common and publications with many citations are relatively rare. Given this limitation, in this work we instead address a related question asked by many academic researchers in the course of writing a paper, namely: ""Will this paper increase my h-index?"" Using a real academic dataset with over 1.7 million authors, 2 million papers, and 8 million citation relationships from the premier online academic service ArnetMiner, we formalize a novel scientific impact prediction problem to examine several factors that can drive a paper to increase the primary author's h-index. We find that the researcher's authority on the publication topic and the venue in which the paper is published are crucial factors to the increase of the primary author's h-index, while the topic popularity and the co-authors' h-indices are of surprisingly little relevance. By leveraging relevant factors, we find a greater than 87.5% potential predictability for whether a paper will contribute to an author's h-index within five years. As a further experiment, we generate a self-prediction for this paper, estimating that there is a 76% probability that it will contribute to the h-index of the co-author with the highest current h-index in five years. We conclude that our findings on the quantification of scientific impact can help researchers to expand their influence and more effectively leverage their position of ""standing on the shoulders of giants.""",2015,Web Search and Data Mining,Fields of study: data scienceworld wide webdata miningcomputer science
Web usage mining for enhancing search-result delivery and helping users to find interesting web content,Ida Mele (Sapienza University of Rome),1999225486,"Web usage mining is the application of data mining techniques to the data generated by the interactions of users with web servers. This kind of data, stored in server logs, represents a valuable source of information, which can be exploited to optimize the document-retrieval task, or to better understand, and thus, satisfy user needs. Our research focuses on two important issues: improving search-engine performance through static caching of search results, and helping users to find interesting web pages by recommending news articles and blog posts. Concerning the static caching of search results, we present the query covering approach. The general idea is to populate the cache with those documents that contribute to the result pages of a large number of queries, as opposed to caching the top documents of most frequent queries. For the recommendation of web pages, we present a graph-based approach, which leverages the user-browsing logs to identify early adopters. These users discover interesting content before others, and monitoring their activity we can find web pages to recommend.",2013,Web Search and Data Mining,Fields of study: web 2 0web modelingdata webweb standardsweb mappingweb search queryweb query classificationweb developmentweb navigationweb serverweb serviceweb pageweb miningworld wide webinformation retrievaldata miningcomputer science
Threading machine generated email,Nir Ailon (Technion – Israel Institute of Technology)Zohar Shay Karnin (Yahoo!)Edo Liberty (Yahoo!)Yoelle Maarek (Yahoo!),"327757988,1985648170,1215165747,262608878","Viewing email messages as parts of a sequence or a thread is a convenient way to quickly understand their context. Current threading techniques rely on purely syntactic methods, matching sender information, subject line, and reply/forward prefixes. As such, they are mostly limited to personal conversations. In contrast, machine-generated email, which amount, as per our experiments, to more than 60% of the overall email traffic, requires a different kind of threading that should reflect how a sequence of emails is caused by a few related user actions. For example, purchasing goods from an online store will result in a receipt or a confirmation message, which may be followed, possibly after a few days, by a shipment notification message from an express shipping service. In today's mail systems, they will not be a part of the same thread, while we believe they should. In this paper, we focus on this type of threading that we coin ""causal threading"". We demonstrate that, by analyzing recurring patterns over hundreds of millions of mail users, we can infer a causality relation between these two individual messages. In addition, by observing multiple causal relations over common messages, we can generate ""causal threads"" over a sequence of messages. The four key stages of our approach consist of: (1) identifying messages that are instances of the same email type or ""template"" (generated by the same machine process on the sender side) (2) building a causal graph, in which nodes correspond to email templates and edges indicate potential causal relations (3) learning a causal relation prediction function, and (4) automatically ""threading"" the incoming email stream. We present detailed experimental results obtained by analyzing the inboxes of 12.5 million Yahoo! Mail users, who voluntarily opted-in for such research. Supervised editorial judgments show that we can identify more than 70% (recall rate) of all ""causal threads"" at a precision level of 90%. In addition, for a search scenario we show that we achieve a precision close to 80% at 90% recall. We believe that supporting causal threads in email clients opens new grounds for improving both email search and browsing experiences.",2013,Web Search and Data Mining,Fields of study: html emailuser experience designinternet privacyworld wide webdata miningmachine learningcomputer science
Comparative Document Analysis for Large Text Corpora,Xiang Ren (University of Illinois at Urbana–Champaign)Yuanhua Lv (Microsoft)Kuansan Wang (Microsoft)Jiawei Han (University of Illinois at Urbana–Champaign),"2129405715,2132538679,2127379895,2121939561","This paper presents a novel research problem, Comparative Document Analysis (CDA), that is, joint discovery of commonalities and differences between two individual documents (or two sets of documents) in a large text corpus. Given any pair of documents from a (background) document collection, CDA aims to automatically identify sets of quality phrases to summarize the commonalities of both documents and highlight the distinctions of each with respect to the other informatively and concisely. Our solution uses a general graph-based framework to derive novel measures on phrase semantic commonality and pairwise distinction, where the background corpus is used for computing phrase-document semantic relevance. We use the measures to guide the selection of sets of phrases by solving two joint optimization problems. A scalable iterative algorithm is developed to integrate the maximization of phrase commonality or distinction measure with the learning of phrase-document semantic relevance. Experiments on large text corpora from two different domains---scientific papers and news---demonstrate the effectiveness and robustness of the proposed framework on comparing documents. Analysis on a 10GB+ text corpus demonstrates the scalability of our method, whose computation time grows linearly as the corpus size increases. Our case study on comparing news articles published at different dates shows the power of the proposed method on comparing sets of documents.",2017,Web Search and Data Mining,Fields of study: automatic summarizationnatural language processingworld wide webinformation retrievaldata miningcomputer science
Time Will Tell: Leveraging Temporal Expressions in IR,Irem Arikan (Max Planck Society)Srikanta J. Bedathur (Max Planck Society)Klaus Berberich (Max Planck Society),"2414091202,1218200837,2064029816",-,2009,Web Search and Data Mining,Fields of study: term discriminationlanguage modelnatural language processinginformation retrievaldata miningcomputer science
LASER: a scalable response prediction platform for online advertising,Deepak Agarwal (LinkedIn)Bo Long (LinkedIn)Jonathan Traupman (LinkedIn)Doris Xin (LinkedIn)Liang Zhang (LinkedIn),"2116605949,2512786853,1858799930,2504418705,2306956169","We describe LASER, a scalable response prediction platform currently used as part of a social network advertising system. LASER enables the familiar logistic regression model to be applied to very large scale response prediction problems, including ones beyond advertising. Though the underlying model is well understood, we apply a whole-system approach to address model accuracy, scalability, explore-exploit, and real-time inference. To facilitate training with both large numbers of training examples and high dimensional features on commodity clustered hardware, we employ the Alternating Direction Method of Multipliers (ADMM). Because online advertising applications are much less static than classical presentations of response prediction, LASER employs a number of techniques that allows it to adapt in real time. LASER models can be divided into components with different re-training frequencies, allowing us to learn from changes in ad campaign performance frequently without incurring the cost of retraining larger, more stable sections of the model. Thompson sampling during online inference further helps by efficiently balancing exploration of new ads with exploitation of long running ones. To enable predictions made with the most recent feature data, we employ a range of techniques, including extensive caching and lazy evaluation, to permit real time, low latency scoring. LASER models are defined using a configuration language that ties together the training, validation, and inference pieces and permits even non-programming analysts to experiment with different model structures without modifications to code or interruptions to running servers. Finally, we show via extensive offline experiments and online A/B tests that this system provides significant benefits to prediction accuracy, gains in revenue and CTR, and reductions in system latency.",2014,Web Search and Data Mining,Fields of study: scalabilitylogistic regressionworld wide webdata miningmachine learningsimulationstatisticscomputer science
Personal name classification in web queries,Dou Shen (Microsoft)Toby Walkery (Microsoft)Zijian Zhengy (Microsoft)Qiang Yangz (Hong Kong University of Science and Technology)Ying Li (Microsoft),"2136428695,2226663594,2226514573,2223389837,2699950441","Personal names are an important kind of Web queries in Web search, and yet they are special in many ways. Strategies for retrieving information on personal names should therefore be different from the strategies for other types of queries. To improve the search quality for personal names, a first step is to detect whether a query is a personal name. Despite the importance of this problem, relatively little previous research has been done on this topic. Since Web queries are usually short, conventional supervised machine-learning algorithms cannot be applied directly. An alternative is to apply some heuristic rules coupled with name-term dictionaries. However, when the dictionaries are small, this method tends to make false negatives; when the dictionaries are large, it tends to generate false positives. A more serious problem is that this method cannot provide a good trade-off between precision and recall. To solve these problems, we propose an approach based on the construction of probabilistic name-term dictionaries and personal name grammars, and use this algorithm to predict the probability of a query to be a personal name. In this paper, we develop four different methods for building probabilistic name-term dictionaries in which a term is assigned with a probability value of the term being a name term. We compared our approach with baseline algorithms such as dictionary-based look-up methods and supervised classification algorithms including logistic regression and SVM on some manually labeled test sets. The results validate the effectiveness of our approach, whose F1 value is more than 79.8%, which outperforms the best baseline by more than 11.3%",2008,Web Search and Data Mining,Fields of study: web search queryweb query classificationtype i and type ii errorslogistic regressionworld wide webinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
Identifying users' topical tasks in web search,Wen Hua (Renmin University of China)Yangqiu Song (Microsoft)Haixun Wang (Microsoft)Xiaofang Zhou (University of Queensland),"2228359806,2099747503,2116756368,2128990482","A search task represents an atomic information need of a user in web search. Tasks consist of queries and their reformulations, and identifying tasks is important for search engines since they provide valuable information for determining user satisfaction with search results, predicting user search intent, and suggesting queries to the user. Traditional approaches to identifying tasks exploit either temporal or lexical features of queries. However, many query refinements are topical, which means that a query and its refinements may not be similar on the lexical level. Furthermore, multiple tasks in the same search session may interleave, which means we cannot simply order the searches by their timestamps and divide the session into multiple tasks. Thus, in order to identify tasks correctly, we need to be able to compare two queries at the semantic level. In this paper, we use a knowledgebase known as Probase to infer the conceptual meanings of queries, and automatically identify the topical query refinements in the tasks. Experimental results on real search log data demonstrate that Probase can indeed help estimate the topical affinity between queries, and thus enable us to merge queries that are topically related but dissimilar at the lexical level.",2013,Web Search and Data Mining,Fields of study: web query classificationconceptualizationworld wide webinformation retrievaldata miningdatabasecomputer science
PRED: Periodic Region Detection for Mobility Modeling of Social Media Users,Quan Yuan (University of Illinois at Urbana–Champaign)Wei Zhang (East China Normal University)Chao Zhang (University of Illinois at Urbana–Champaign)Xinhe Geng (University of Illinois at Urbana–Champaign)Gao Cong (Nanyang Technological University)Jiawei Han (University of Illinois at Urbana–Champaign),"2683532865,2723820743,2618902948,2583697975,2295915604,2121939561","The availability of massive geo-annotated social media data sheds light on studying human mobility patterns. Among them, periodic pattern, \ie an individual visiting a geographical region with some specific time interval, has been recognized as one of the most important. Mining periodic patterns has a variety of applications, such as location prediction, anomaly detection, and location- and time-aware recommendation. However, it is a challenging task: the regions of a person and the periods of each region are both unknown. The interdependency between them makes the task even harder. Hence, existing methods are far from satisfactory for detecting periodic patterns from the low-sampling and noisy social media data. We propose a Bayesian non-parametric model, named \textbf{P}eriodic \textbf{RE}gion \textbf{D}etection (PRED), to discover periodic mobility patterns by jointly modeling the geographical and temporal information. Our method differs from previous studies in that it is non-parametric and thus does not require priori knowledge about an individual's mobility (\eg number of regions, period length, region size). Meanwhile, it models the time gap between two consecutive records rather than the exact visit time, making it less sensitive to data noise. Extensive experimental results on both synthetic and real-world datasets show that PRED outperforms the state-of-the-art methods significantly in four tasks: periodic region discovery, outlier movement finding, period detection, and location prediction.",2017,Web Search and Data Mining,Fields of study: data miningartificial intelligencesimulation
Scalable clustering of news search results,Srinivas Vadrevu (Yahoo!)Choon Hui Teo (Yahoo!)Suju Rajan (Yahoo!)Kunal Punera (Yahoo!)Byron Dom (Yahoo!)Alexander J. Smola (Yahoo!)Yi Chang (Yahoo!)Zhaohui Zheng (Yahoo!),"1903928458,2108769517,2229133469,2343758766,2375461491,1972291593,2168000538,2089011938","In this paper, we present a system for clustering the search results of a news search engine. The news search interface includes the relevant news articles to a given query organized in terms of related news stories. Here each cluster corresponds to a news story and the news articles are clustered into stories. We present a system that clusters the search results of a news search system in a fast and scalable manner. The clustering system is organized into three components including offline clustering, incremental clustering and realtime clustering. We propose novel techniques for clustering the search results in realtime. The experimental results with large collections of news documents reveal that our system is both scalable and also achieves good accuracy in clustering the news search results.",2011,Web Search and Data Mining,Fields of study: flame clusteringbrown clusteringcanopy clustering algorithmdbscancorrelation clusteringdata stream clusteringcure data clustering algorithmfuzzy clusteringclustering high dimensional datasearch enginecluster analysisconsensus clusteringconceptual clusteringworld wide webinformation retrievaldata miningmachine learningcomputer science
Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising,Amr Ahmed (Google)Abhimanyu Das (Microsoft)Alexander J. Smola (Carnegie Mellon University),"2259645355,2480652307,1972291593",Many estimation tasks come in groups and hierarchies of related problems. In this paper we propose a hierarchical model and a scalable algorithm to perform inference for multitask learning. It infers task correlation and subtask structure in a joint sparse setting. Implementation is achieved by a distributed subgradient oracle and the successive application of prox-operators pertaining to groups and subgroups of variables. We apply this algorithm to conversion optimization in display advertising. Experimental results on over 1TB data for up to 1 billion observations and 1 million attributes show that the algorithm provides significantly better prediction accuracy while simultaneously beingefficiently scalable by distributed parameter synchronization.,2014,Web Search and Data Mining,Fields of study: multi task learningsparsity of effects principletheoretical computer sciencedata miningmachine learningstatisticscomputer science
Data-oriented content query system: searching for data into text on the web,Mianwei Zhou (University of Illinois at Urbana–Champaign)Tao Cheng (University of Illinois at Urbana–Champaign)Kevin Chen Chuan Chang (University of Illinois at Urbana–Champaign),"2135817545,2285779824,2434208492","As the Web provides rich data embedded in the immense contents inside pages, we witness many ad-hoc efforts for exploiting fine granularity information across Web text, such as Web information extraction, typed-entity search, and question answering. To unify and generalize these efforts, this paper proposes a general search system--Data-oriented Content Query System(DoCQS)--to search directly into document contents for finding relevant values of desired data types. Motivated by the current limitations, we start by distilling the essential capabilities needed by such content querying. The capabilities call for a conceptually relational model, upon which we design a powerful Content Query Language (CQL). For efficient processing, we design novel index structures and query processing algorithms. We evaluate our proposal over two concrete domains of realistic Web corpora, demonstrating that our query language is rather flexible and expressive, and our query processing is efficient with reasonable index overhead.",2010,Web Search and Data Mining,Fields of study: sargablerankingrdf query languageboolean conjunctive queryonline aggregationobject query languageweb search queryweb query classificationviewquery by exampleinverted indexquery expansionquery optimizationquery languagedata typerelational modelquestion answeringworld wide webinformation retrievaldata miningdatabasecomputer science
On Integrating Network and Community Discovery,Jialu Liu (University of Illinois at Urbana–Champaign)Charu C. Aggarwal (IBM)Jiawei Han (University of Illinois at Urbana–Champaign),"2095732305,2146335907,2121939561","The problem of community detection has recently been studied widely in the context of the web and social media networks. Most algorithms for community detection assume that the entire network is available for online analysis. In practice, this is not really true, because only restricted portions of the network may be available at any given time for analysis. Many social networks such as Facebook have privacy constraints, which do not allow the discovery of the entire structure of the social network. Even in the case of more open networks such as Twitter , it may often be challenging to crawl the entire network from a practical perspective. For many other scenarios such as adversarial networks, the discovery of the entire network may itself be a costly task, and only a small portion of the network may be discovered at any given time. Therefore, it can be useful to investigate whether network mining algorithms can integrate the network discovery process tightly into the mining process, so that the best results are achieved for particular constraints on discovery costs. In this context, we will discuss algorithms for integrating community detection with network discovery. We will tightly integrate with the cost of actually discovering a network with the community detection process, so that the two processes can support each other and are performed in a mutually cohesive way. We present experimental results illustrating the advantages of the approach.",2015,Web Search and Data Mining,Fields of study: dynamic network analysisservice discoveryinteraction networknetwork simulationdata scienceworld wide webdata miningmachine learningcomputer science
Transient crowd discovery on the real-time social web,Krishna Yeshwanth Kamath (Texas A&M University)James Caverlee (Texas A&M University),"2481205152,2028974103","In this paper, we study the problem of automatically discovering and tracking transient crowds in highly-dynamic social messaging systems like Twitter and Facebook. Unlike the more static and long-lived group-based membership offered on many social networks (e.g., fan of the LA Lakers), a transient crowd is a short-lived ad-hoc collection of users, representing a ""hotspot"" on the real-time web. Successful detection of these hotspots can positively impact related research directions in online event detection, content personalization, social information discovery, etc. Concretely, we propose to model crowd formation and dispersion through a message-based communication clustering approach over time-evolving graphs that captures the natural conversational nature of social messaging systems. Two of the salient features of the proposed approach are (i) an efficient locality- based clustering approach for identifying crowds of users in near real-time compared to more heavyweight static clustering algorithms; and (ii) a novel crowd tracking and evolution approach for linking crowds across time periods. We find that the locality-based clustering approach results in empirically high-quality clusters relative to static graph clus- tering techniques at a fraction of the computational cost. Based on a three month snapshot of Twitter consisting of 711,612 users and 61.3 million messages, we show how the proposed approach can successfully identify and track interesting crowds based on the Twitter communication structure and uncover crowd-based topics of interest.",2011,Web Search and Data Mining,Fields of study: social websocial mediacommunity structuresocial networkcluster analysisinternet privacymultimediaworld wide webdata miningcomputer science
Unbiased Learning-to-Rank with Biased Feedback,Thorsten Joachims (Cornell University)Adith Swaminathan (Cornell University)Tobias Schnabel (Cornell University),"245171893,2144842984,2072477554","Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-biasing the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance.",2017,Web Search and Data Mining,Fields of study: ranking svmlearning to rankdata miningmachine learningstatisticscomputer science
Predicting content change on the web,Kira Radinsky (Technion – Israel Institute of Technology)Paul N. Bennett (Microsoft),"1780829609,2137013502","Accurate prediction of changing web page content improves a variety of retrieval and web related components. For example, given such a prediction algorithm one can both design a better crawling strategy that only recrawls pages when necessary as well as a proactive mechanism for personalization that pushes content associated with user revisitation directly to the user. While many techniques for modeling change have focused simply on past change frequency, our work goes beyond that by additionally studying the usefulness in page change prediction of: the page's content; the degree and relationship among the prediction page's observed changes; the relatedness to other pages and the similarity in the types of changes they undergo. We present an expert prediction framework that incorporates the information from these other signals more effectively than standard ensemble or basic relational learning techniques. In an empirical analysis, we find that using page content as well as related pages significantly improves prediction accuracy and compare it to common approaches. We present numerous similarity metrics to identify related pages and focus specifically on measures of temporal content similarity. We observe that the different metrics yield related pages that are qualitatively different in nature and have different effects on the prediction performance.",2013,Web Search and Data Mining,Fields of study: web crawlerworld wide webinformation retrievaldata miningcomputer science
FLAME: A Probabilistic Model Combining Aspect Based Opinion Mining and Collaborative Filtering,Yao Wu (Simon Fraser University)Martin Ester (Simon Fraser University),"2139499555,2067196623","Aspect-based opinion mining from online reviews has attracted a lot of attention recently. Given a set of reviews, the main task of aspect-based opinion mining is to extract major aspects of the items and to infer the latent aspect ratings from each review. However, users may have different preferences which might lead to different opinions on the same aspect of an item. Even if fine-grained aspect rating analysis is provided for each review, it is still difficult for a user to judge whether a specific aspect of an item meets his own expectation. In this paper, we study the problem of estimating personalized sentiment polarities on different aspects of the items. We propose a unified probabilistic model called Factorized Latent Aspect ModEl (FLAME), which combines the advantages of collaborative filtering and aspect based opinion mining. FLAME learns users' personalized preferences on different aspects from their past reviews, and predicts users' aspect ratings on new items by collective intelligence. Experiments on two online review datasets show that FLAME outperforms state-of-the-art methods on the tasks of aspect identification and aspect rating prediction.",2015,Web Search and Data Mining,Fields of study: collaborative filteringtext miningdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Information-theoretic measures of influence based on content dynamics,Greg Ver Steeg (Information Sciences Institute)Aram Galstyan (Information Sciences Institute),"1808124004,2117285942","The fundamental building block of social influence is for one person to elicit a response in another. Researchers measuring a ""response"" in social media typically depend either on detailed models of human behavior or on platform-specific cues such as re-tweets, hash tags, URLs, or mentions. Most content on social networks is difficult to model because the modes and motivation of human expression are diverse and incompletely understood. We introduce content transfer, an information-theoretic measure with a predictive interpretation that directly quantifies the strength of the effect of one user's content on another's in a model-free way. Estimating this measure is made possible by combining recent advances in non-parametric entropy estimation with increasingly sophisticated tools for content representation. We demonstrate on Twitter data collected for thousands of users that content transfer is able to capture non-trivial, predictive relationships even for pairs of users not linked in the follower or mention graph. We suggest that this measure makes large quantities of previously under-utilized social media content accessible to rigorous statistical causal analysis.",2013,Web Search and Data Mining,Fields of study: causalityentropysocial networksocial psychologyworld wide websocial sciencedata miningmachine learningstatisticscomputer science
Just in Time Recommendations: Modeling the Dynamics of Boredom in Activity Streams,Komal Kapoor (University of Minnesota)Karthik Subbian (University of Minnesota)Jaideep Srivastava (University of Minnesota)Paul R Schrater (University of Minnesota),"2280298947,2230469306,2192802387,220185405","Recommendation methods have mainly dealt with the problem of recommending new items to the user while user visitation behavior to the familiar items (items which have been consumed before) are little understood. In this paper, we analyze user activity streams and show that user's temporal consumption of familiar items is driven by boredom. Specifically, users move on to a different item when bored and return to the same item when their interest is restored. To model this behavior we include two latent psychological states of preference for items - sensitization and boredom. In the sensitization state the user is highly engaged with the item, while in the boredom state the user is disinterested. We model this behavior using a Hidden Semi-Markov Model for the gaps between user consumption activities. We show that our model performs much better than the state-of-the-art temporal recommendation models at predicting the revisit time to the item. Moreover, we attribute two main reasons for this: (1) recommending items that are not in the bored state for the user, (2) recommending items where user has restored her interests.",2015,Web Search and Data Mining,Fields of study: multimedia
Tagging with Queries: How and Why?,Ioannis Antonellis (Stanford University)Hector Garcia-Molina (Stanford University)Jawed Karim (Stanford University),"2570902819,237419955,2107435621","Web search queries capture the information need of search engine users. Search engines store these queries in their logs and analyze them to guide their search results. In this work, we argue that not only a search engine can benefit from data stored in these logs, but also the web users. We first show how clickthrough logs can be collected in a distributed fashion using the http referer field in web server access logs. We then perform a set of experiments to study the information value of search engine queries when treated as ""tags"" or ""labels"" for the web pages that both appear as a result and the user actually clicks on. We ask how much extra information these query tags provide for web pages by comparing them to tags from the del.icio.us bookmarking site and to the pagetext. We find that query tags can provide substantially many (on average 250 tags per URL), new tags (on average 125 tags per URL are not present in the pagetext) for a large fraction of the Web.",2009,Web Search and Data Mining,Fields of study: rewrite enginestatic web pagesite mapweb search queryweb query classificationspamdexingweb crawlerweb navigationvalue of informationinformation needsweb pagesearch enginesemantic searchmetasearch engineweb search engineworld wide webinformation retrievaldatabasecomputer science
Selecting actions for resource-bounded information extraction using reinforcement learning,Pallika H. Kanani (University of Massachusetts Amherst)Andrew K. McCallum (University of Massachusetts Amherst),"2158429353,2131293038","Given a database with missing or uncertain content, our goal is to correct and fill the database by extracting specific information from a large corpus such as the Web, and to do so under resource limitations. We formulate the information gathering task as a series of choices among alternative, resource-consuming actions and use reinforcement learning to select the best action at each time step. We use temporal difference q-learning method to train the function that selects these actions, and compare it to an online, error-driven algorithm called SampleRank. We present a system that finds information such as email, job title and department affiliation for the faculty at our university, and show that the learning-based approach accomplishes this task efficiently under a limited action budget. Our evaluations show that we can obtain 92.4% of the final F1, by only using 14.3% of all possible actions.",2012,Web Search and Data Mining,Fields of study: error driven learningweb miningreinforcement learninginformation extractionknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
Customized tour recommendations in urban areas,Aristides Gionis (Aalto University)Theodoros Lappas (Stevens Institute of Technology)Konstantinos Pelechrinis (University of Pittsburgh)Evimaria Terzi (Boston University),"737311942,2028397797,155875377,2110675235","The ever-increasing urbanization coupled with the unprecedented capacity to collect and process large amounts of data have helped to create the vision of intelligent urban environments. One key aspect of such environments is that they allow people to effectively navigate through their city. While GPS technology and route-planning services have undoubtedly helped towards this direction, there is room for improvement in intelligent urban navigation. This vision can be fostered by the proliferation of location-based social networks, such as Foursquare or Path, which record the physical presence of users in different venues through check-ins. This information can then be used to enhance intelligent urban navigation, by generating customized path recommendations for users. In this paper, we focus on the problem of recommending customized tours in urban settings. These tours are generated so that they consider (a) the different types of venues that the user wants to visit, as well as the order in which the user wants to visit them, (b) limitations on the time to be spent or distance to be covered, and (c) the merit of visiting the included venues. We capture these requirements in a generic definition that we refer to as the TourRec problem. We then introduce two instances of the TourRec problem, study their complexity, and propose efficient algorithmic solutions. Our experiments on real data collected from Foursquare demonstrate the efficacy of our algorithms and the practical utility of the reported recommendations.",2014,Web Search and Data Mining,Fields of study: multimediaworld wide webdata miningsimulationcomputer science
Searching patterns for relation extraction over the web: rediscovering the pattern-relation duality,Yuan Fang (University of Illinois at Urbana–Champaign)Kevin Chen Chuan Chang (University of Illinois at Urbana–Champaign),"2323377214,2434208492","While tuple extraction for a given relation has been an active research area, its dual problem of pattern search-- to find and rank patterns in a principled way-- has not been studied explicitly. In this paper, we propose and address the problem of pattern search, in addition to tuple extraction. As our objectives, we stress reusability for pattern search and scalability of tuple extraction, such that our approach can be applied to very large corpora like the Web. As the key foundation, we propose a conceptual model PRDualRank to capture the notion of precision and recall for both tuples and patterns in a principled way, leading to the ""rediscovery"" of the Pattern-Relation Duality-- the formal quantification of the reinforcement between patterns and tuples with the metrics of precision and recall. We also develop a concrete framework for PRDualRank, guided by the principles of a perfect sampling process over a complete corpus. Finally, we evaluated our framework over the real Web. Experiments show that on all three target relations our principled approach greatly outperforms the previous state-of-the-art system in both effectiveness and efficiency. In particular, we improved optimal F -score by up to 64%.",2011,Web Search and Data Mining,Fields of study: rankingpattern searchrelationconceptual modelpatterndesignperformanceweb mininginformation extractiontheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Exploiting user disagreement for web search evaluation: an experimental approach,Thomas Demeester (Ghent University)Robin Aly (University of Twente)Djoerd Hiemstra (University of Twente)Dong Nguyen (University of Twente)Dolf Trieschnigg (University of Twente)Chris Develder (Ghent University),"2253240189,2030477395,2125867230,2112184148,2035566089,2037926187","To express a more nuanced notion of relevance as compared to binary judgments, graded relevance levels can be used for the evaluation of search results. Especially in Web search, users strongly prefer top results over less relevant results, and yet they often disagree on which are the top results for a given information need. Whereas previous works have generally considered disagreement as a negative effect, this paper proposes a method to exploit this user disagreement by integrating it into the evaluation procedure. First, we present experiments that investigate the user disagreement. We argue that, with a high disagreement, lower relevance levels might need to be promoted more than in the case where there is global consensus on the top results. This is formalized by introducing the User Disagreement Model, resulting in a weighting of the relevance levels with a probabilistic interpretation. A validity analysis is given, and we explain how to integrate the model with well-established evaluation metrics. Finally, we discuss a specific application of the model, in the estimation of suitable weights for the combined relevance of Web search snippets and pages.",2014,Web Search and Data Mining,Fields of study: evaluationworld wide webinformation retrievaldata miningcomputer science
Inferring Movement Trajectories from GPS Snippets,Mu Li (Carnegie Mellon University)Amr Ahmed (Google)Alexander J. Smola (Carnegie Mellon University),"2658285018,2259645355,1972291593","Inferring movement trajectories can be a challenging task, in particular when detailed tracking information is not available due to privacy and data collection constraints. In this paper we present a complete and computationally tractable model for estimating and predicting trajectories based on sparsely sampled, anonymous GPS land-marks that we call GPS snippets. To combat data sparsity we use mapping data as side information to constrain the inference process. We show the efficacy of our approach on a set of prediction tasks over data collected from different cities in the US.",2015,Web Search and Data Mining,Fields of study: global positioning systemcomputer visiondata miningsimulation
Learning social network embeddings for predicting information diffusion,Simon Bourigault (University of Paris)Cedric LagnierSylvain Lamprier (Pierre-and-Marie-Curie University)Ludovic Denoyer (University of Paris)Patrick Gallinari (Pierre-and-Marie-Curie University),"2342564854,321716061,2544443577,2080627981,2235456028","Analyzing and modeling the temporal diffusion of information on social media has mainly been treated as a diffusion process on known graphs or proximity structures. The underlying phenomenon results however from the interactions of several actors and media and is more complex than what these models can account for and cannot be explained using such limiting assumptions. We introduce here a new approach to this problem whose goal is to learn a mapping of the observed temporal dynamic onto a continuous space. Nodes participating to diffusion cascades are projected in a latent representation space in such a way that information diffusion can be modeled efficiently using a heat diffusion process. This amounts to learning a diffusion kernel for which the proximity of nodes in the projection space reflects the proximity of their infection time in cascades. The proposed approach possesses several unique characteristics compared to existing ones. Since its parameters are directly learned from cascade samples without requiring any additional information, it does not rely on any pre-existing diffusion structure. Because the solution to the diffusion equation can be expressed in a closed form in the projection space, the inference time for predicting the diffusion of a new piece of information is greatly reduced compared to discrete models. Experiments and comparisons with baselines and alternative models have been performed on both synthetic networks and real datasets. They show the effectiveness of the proposed method both in terms of prediction quality and of inference speed.",2014,Web Search and Data Mining,Fields of study: diffusion mapsocial networkdata miningartificial intelligencemachine learningsimulationstatisticscomputer science
Concept Graph Learning from Educational Data,Yiming Yang (Carnegie Mellon University)Hanxiao Liu (Carnegie Mellon University)Jaime G. Carbonell (Carnegie Mellon University)Wanli Ma (Carnegie Mellon University),"2159253281,2167236151,2100444261,2223140111","This paper addresses an open challenge in educational data mining, i.e., the problem of using observed prerequisite relations among courses to learn a directed universal concept graph, and using the induced graph to predict unobserved prerequisite relations among a broader range of courses. This is particularly useful to induce prerequisite relations among courses from different providers (universities, MOOCs, etc.). We propose a new framework for inference within and across two graphs---at the course level and at the induced concept level---which we call Concept Graph Learning (CGL). In the training phase, our system projects the course-level links onto the concept space to induce directed concept links; in the testing phase, the concept links are used to predict (unobserved) prerequisite links for test-set courses within the same institution or across institutions. The dual mappings enable our system to perform an interlingua-style transfer learning, e.g. treating the concept graph as the interlingua, and inducing prerequisite links in a transferable manner across different universities. Experiments on our newly collected data sets of courses from MIT, Caltech, Princeton and CMU show promising results, including the viability of CGL for transfer learning.",2015,Web Search and Data Mining,Fields of study: transfer of learningeducational technologyworld wide websocial sciencedata miningartificial intelligencemachine learningsimulationcomputer science
Optimizing parallel algorithms for all pairs similarity search,"Maha Ahmed Alabduljalil (University of California, Santa Barbara)Xun Tang (University of California, Santa Barbara)Tao Yang (University of California, Santa Barbara)","2230478641,2227421255,2584189575","All pairs similarity search is used in many web search and data mining applications. Previous work has used comparison filtering, inverted indexing, and parallel accumulation of partial intermediate results to expedite its execution. However, shuffling intermediate results can incur significant communication overhead as data scales up. This paper studies a scalable two-step approach called Partition-based Similarity Search (PSS) which incorporates several optimization techniques. First, PSS uses a static partitioning algorithm that places dissimilar vectors into different groups and balance the comparison workload with a circular assignment. Second, PSS executes comparison tasks in parallel, each using a hybrid data structure that combines the advantages of forward and inverted indexing. Our evaluation results show that the proposed approach leads to an early elimination of unnecessary I/O and data communication while sustaining parallel efficiency. As a result, it improves performance by an order of magnitude when dealing with large datasets.",2013,Web Search and Data Mining,Fields of study: load balancingfiltertheoretical computer sciencedistributed computingdata miningmachine learningcomputer science
Deep classifier: automatically categorizing search results into large-scale hierarchies,Dikan Xing (Shanghai Jiao Tong University)Gui-Rong Xue (Shanghai Jiao Tong University)Qiang Yang (Hong Kong University of Science and Technology)Yong Yu (Shanghai Jiao Tong University),"2142001927,2167947354,2109031554,2119244895","Organizing Web search results into hierarchical categories facilitates users' browsing through Web search results, especially for ambiguous queries where the potential results are mixed together. Previous methods on search result classification are usually based on pre-training a classification model on some fixed and shallow hierarchical categories, where only the top-two-level categories of a Web taxonomy is used. Such classification methods may be too coarse for users to browse, since most search results would be classified into only two or three shallow categories. Instead, a deep hierarchical classifier must provide many more categories. However, the performance of such classifiers is usually limited because their classification effectiveness can deteriorate rapidly at the third or fourth level of a hierarchy. In this paper, we propose a novel algorithm known as Deep Classifier to classify the search results into detailed hierarchical categories with higher effectiveness than previous approaches. Given the search results in response to a query, the algorithm first prunes a wide-ranged hierarchy into a narrow one with the help of some Web directories. Different strategies are proposed to select the training data by utilizing the hierarchical structures. Finally, a discriminative naive Bayesian classifier is developed to perform efficient and effective classification. As a result, the algorithm can provide more meaningful and specific class labels for search result browsing than shallow style of classification. We conduct experiments to show that the Deep Classifier can achieve significant improvement over state-of-the-art algorithms. In addition, with sufficient off-line preparation, the efficiency of the proposed algorithm is suitable for online application",2008,Web Search and Data Mining,Fields of study: web query classificationnaive bayes classifierinformation retrievaldata miningpattern recognitionmachine learningcomputer science
DiFacto: Distributed Factorization Machines,Mu Li (Carnegie Mellon University)Ziqi Liu (Xi'an Jiaotong University)Alexander J. Smola (Carnegie Mellon University)Yu-Xiang Wang (Carnegie Mellon University),"2658285018,2115722469,1972291593,2231647228","Factorization Machines offer good performance and useful embeddings of data. However, they are costly to scale to large amounts of data and large numbers of features. In this paper we describe DiFacto, which uses a refined Factorization Machine model with sparse memory adaptive constraints and frequency adaptive regularization. We show how to distribute DiFacto over multiple machines using the Parameter Server framework by computing distributed subgradients on minibatches asynchronously. We analyze its convergence and demonstrate its efficiency in computational advertising datasets with billions examples and features.",2016,Web Search and Data Mining,Fields of study: recommender systemtheoretical computer sciencedistributed computingdata miningmachine learningstatisticscomputer science
Sharding social networks,Quang Duong (Google)Sharad Goel (Microsoft)Jake M. Hofman (Microsoft)Sergei Vassilvitskii (Google),"2231949333,2148409872,2311169505,2156675704","Online social networking platforms regularly support hundreds of millions of users, who in aggregate generate substantially more data than can be stored on any single physical server. As such, user data are distributed, or sharded, across many machines. A key requirement in this setting is rapid retrieval not only of a given user's information, but also of all data associated with his or her social contacts, suggesting that one should consider the topology of the social network in selecting a sharding policy. In this paper we formalize the problem of efficiently sharding large social network databases, and evaluate several sharding strategies, both analytically and empirically. We find that random sharding---the de facto standard---results in provably poor performance even when frequently accessed nodes are replicated to many shards. By contrast, we demonstrate that one can substantially reduce querying costs by identifying and assigning tightly knit communities to shards. In particular, our theoretical analysis motivates a novel, scalable sharding algorithm that outperforms both random and location-based sharding schemes.",2013,Web Search and Data Mining,Fields of study: social networkworld wide webdistributed computingdata miningmachine learningcomputer science
Low-order tensor decompositions for social tagging recommendation,Yuanzhe Cai (University of Texas at Arlington)Miao Zhang (University of Texas at Arlington)Dijun Luo (University of Texas at Arlington)Chris H. Q. Ding (University of Texas at Arlington)Sharma Chakravarthy (University of Texas at Arlington),"2153170976,2298492283,2166799549,2119616764,2207808857","Social tagging recommendation is an urgent and useful enabling technology for Web 2.0. In this paper, we present a systematic study of low-order tensor decomposition approach that are specifically targeted at the very sparse data problem in tagging recommendation problem. Low-order polynomials have low functional complexity, are uniquely capable of enhancing statistics and also avoids over-fitting than traditional tensor decompositions such as Tucker and Parafac decompositions. We perform extensive experiments on several datasets and compared with 6 existing methods. Experimental results demonstrate that our approach outperforms existing approaches.",2011,Web Search and Data Mining,Fields of study: sparse matrixsocial networkrecommender systemdata scienceworld wide websocial sciencedata miningmachine learningcomputer science
Modeling Check-in Preferences with Multidimensional Knowledge: A Minimax Entropy Approach,Jingjing Wang (University of Illinois at Urbana–Champaign)Min Li (University of Illinois at Urbana–Champaign)Jiawei Han (University of Illinois at Urbana–Champaign)Xiaolong Wang (University of Illinois at Urbana–Champaign),"2140412951,2628784956,2121939561,2591453536","We propose a single unified minimax entropy approach for user preference modeling with multidimensional knowledge. Our approach provides a discriminative learning protocol which is able to simultaneously a) leverage explicit human knowledge, which are encoded as explicit features, and b) model the more ambiguous hidden intent, which are encoded as latent features. A latent feature can be carved by any parametric form, which allows it to accommodate arbitrary underlying assumptions. We present our approach in the scenario of check-in preference learning and demonstrate it is capable of modeling user preference in an optimized manner. Check-in preference is a fundamental component of Point-of-Interest (POI) prediction and recommendation. A user's check-in can be affected at multiple dimensions, such as the particular time, popularity of the place, his/her category and geographic preference, etc. With the geographic preferences modeled as latent features and the rest as explicit features, our approach provides an in-depth understanding of users' time-varying preferences over different POIs, as well as a reasonable representation of the hidden geographic clusters in a joint manner. Experimental results based on the task of POI prediction/recommendation with two real-world check-in datasets demonstrate that our approach can accurately model the check-in preferences and significantly outperforms the state-of-art models.",2016,Web Search and Data Mining,Fields of study: preference learningdata miningpattern recognitionmachine learning
Optimizing top-k document retrieval strategies for block-max indexes,Constantinos Dimopoulos (Polytechnic Institute of New York University)Sergey Nepomnyachiy (Polytechnic Institute of New York University)Torsten Suel (Polytechnic Institute of New York University),"2225374625,217074000,2639959275","Large web search engines use significant hardware and energy resources to process hundreds of millions of queries each day, and a lot of research has focused on how to improve query processing efficiency. One general class of optimizations called early termination techniques is used in all major engines, and essentially involves computing top results without an exhaustive traversal and scoring of all potentially relevant index entries. Recent work in [9,7] proposed several early termination algorithms for disjunctive top-k query processing, based on a new augmented index structure called Block-Max Index that enables aggressive skipping in the index. In this paper, we build on this work by studying new algorithms and optimizations for Block-Max indexes that achieve significant performance gains over the work in [9,7]. We start by implementing and comparing Block-Max oriented algorithms based on the well-known Maxscore and WAND approaches. Then we study how to build better Block-Max index structures and design better index-traversal strategies, resulting in new algorithms that achieve a factor of 2 speed-up over the best results in [9] with acceptable space overheads. We also describe and evaluate a hierarchical algorithm for a new recursive Block-Max index structure.",2013,Web Search and Data Mining,Fields of study: theoretical computer scienceworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
The virtual lab,Duncan J. Watts (Microsoft),2138805444,"The Internet and the Web have transformed society, spawning new industries, altering social and cultural practices, and challenging long-accepted notions of individual privacy, intellectual property, and national security. In this talk, I argue that social science is also being transformed. In particular, I describe how crowd sourcing sites like Amazon's Mechanical Turk are increasingly being used by researchers to create ""virtual labs"" in which they can conduct behavioral experiments on a scale and speed that would have been hard to imagine just a decade ago. To illustrate the point, I describe some recent experiments that showcase the advantages of virtual over traditional physical labs, as well as some of the limitations. I then discuss how this relatively new experimental capability may unfold in the near future, along with some implications for social and behavioral science.",2013,Web Search and Data Mining,Fields of study: multimediaworld wide websocial sciencedata miningsimulationcomputer science
Modeling Website Popularity Competition in the Attention-Activity Marketplace,Bruno Ribeiro (Carnegie Mellon University)Christos Faloutsos (Carnegie Mellon University),"2249226172,2198983026","How does a new startup drive the popularity of competing websites into oblivion like Facebook famously did to MySpace? This question is of great interest to academics, technologists, and financial investors alike. In this work we exploit the singular way in which Facebook wiped out the popularity of MySpace, Hi5, Friendster, and Multiply to guide the design of a new popularity competition model. Our model provides new insights into what Nobel Laure- ate Herbert A. Simon called the ""marketplace of attention,"" which we recast as the attention-activity marketplace. Our model design is further substantiated by user-level activity of 250,000 MySpace users obtained between 2004 and 2009. The resulting model not only accurately fits the observed Daily Active Users (DAU) of Facebook and its competitors but also predicts their fate four years into the future.",2015,Web Search and Data Mining,Fields of study: advertisingpublic relationsmarketingsocial scienceeconomics
Finding Subgraphs with Maximum Total Density and Limited Overlap,Oana Denisa Balalau (Institut Mines-Télécom)Francesco Bonchi (Yahoo!)T-H. Hubert Chan (University of Hong Kong)Francesco Gullo (Yahoo!)Mauro Sozio (Institut Mines-Télécom),"2227051084,2176652147,2148041579,1979201319,2661201427","Finding dense subgraphs in large graphs is a key primitive in a variety of real-world application domains, encompassing social network analytics, event detection, biology, and finance. In most such applications, one typically aims at finding several (possibly overlapping) dense subgraphs which might correspond to communities in social networks or interesting events. While a large amount of work is devoted to finding a single densest subgraph, perhaps surprisingly, the problem of finding several dense subgraphs with limited overlap has not been studied in a principled way, to the best of our knowledge. In this work we define and study a natural generalization of the densest subgraph problem, where the main goal is to find at most $k$ subgraphs with maximum total aggregate density, while satisfying an upper bound on the pairwise Jaccard coefficient between the sets of nodes of the subgraphs. After showing that such a problem is NP-Hard, we devise an efficient algorithm that comes with provable guarantees in some cases of interest, as well as, an efficient practical heuristic. Our extensive evaluation on large real-world graphs confirms the efficiency and effectiveness of our algorithms.",2015,Web Search and Data Mining,Fields of study: mathematical optimization
On the Accuracy of Hyper-local Geotagging of Social Media Content,David Flatow (Stanford University)Mor Naaman (Cornell University)Ke Eddie Xie (Twitter)Yana Volkovich (Cornell University)Yaron Kanza (Cornell University),"2221991608,1220470961,2223808483,2223950294,2303208731","Social media users share billions of items per year, only a small fraction of which is geotagged. We present a data-driven approach for identifying non-geotagged content items that can be associated with a hyper-local geographic area by modeling the location distributions of n-grams that appear in the text. We explore the trade-off between accuracy and coverage of this method. Further, we explore differences across content received from multiple platforms and devices, and show, for example, that content shared via different sources and applications produces significantly different geographic distributions, and that it is preferred to model and predict location for items according to their source. Our findings show the potential and the bounds of a data-driven approach to assigning location data to short social media texts, and offer implications for all applications that use data-driven approaches to locate content.",2015,Web Search and Data Mining,Fields of study: geotagginglocation based servicesocial mediainternet privacyworld wide webdata miningcomputer science
Overcoming browser cookie churn with clustering,Anirban Dasgupta 0001 (Yahoo!)Maxim Gurevich (Yahoo!)Liang Zhang (Yahoo!)Belle L. Tseng (Yahoo!)Achint Oommen Thomas (Yahoo!),"2138105752,2027890328,2306956169,1990119318,2618456494","Many large Internet websites are accessed by users anonymously, without requiring registration or logging-in. However, to provide personalized service these sites build anonymous, yet persistent, user models based on repeated user visits. Cookies, issued when a web browser first visits a site, are typically employed to anonymously associate a website visit with a distinct user (web browser). However, users may reset cookies, making such association short-lived and noisy. In this paper we propose a solution to the cookie churn problem: a novel algorithm for grouping similar cookies into clusters that are more persistent than individual cookies. Such clustering could potentially allow more robust estimation of the number of unique visitors of the site over a certain long time period, and also better user modeling which is key to plenty of web applications such as advertising and recommender systems. We present a novel method to cluster browser cookies into groups that are likely to belong to the same browser based on a statistical model of browser visitation patterns. We address each step of the clustering as a binary classification problem estimating the probability that two different subsets of cookies belong to the same browser. We observe that our clustering problem is a generalized interval graph coloring problem, and propose a greedy heuristic algorithm for solving it. The scalability of this method allows us to cluster hundreds of millions of browser cookies and provides significant improvements over baselines such as constrained K-means.",2012,Web Search and Data Mining,Fields of study: interval graphbayes factorbinary classificationuser modelingk means clusteringrobust statisticsgreedy algorithmcluster analysisstatistical modelrecommender systeminternet privacyworld wide webdata miningmachine learningcomputer science
Joint Deep Modeling of Users and Items Using Reviews for Recommendation,Lei Zheng (University of Illinois at Chicago)Vahid Noroozi (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2575172844,2602517610,2125104194","A large amount of information exists in reviews written by users. This source of information has been ignored by most of the current recommender systems while it can potentially alleviate the sparsity problem and improve the quality of recommendations. In this paper, we present a deep model to learn item properties and user behaviors jointly from review text. The proposed model, named Deep Cooperative Neural Networks (DeepCoNN), consists of two parallel neural networks coupled in the last layers. One of the networks focuses on learning user behaviors exploiting reviews written by the user, and the other one learns item properties from the reviews written for the item. A shared layer is introduced on the top to couple these two networks together. The shared layer enables latent factors learned for users and items to interact with each other in a manner similar to factorization machine techniques. Experimental results demonstrate that DeepCoNN significantly outperforms all baseline recommender systems on a variety of datasets.",2017,Web Search and Data Mining,Fields of study: deep learningworld wide webdata miningmachine learningcomputer science
Translating related words to videos and back through latent topics,Pradipto Das (University at Buffalo)Rohini K. Srihari (University at Buffalo)Jason J. Corso (University at Buffalo),"2153482658,2099189041,2073062517","Documents containing video and text are becoming more and more widespread and yet content analysis of those documents depends primarily on the text. Although automated discovery of semantically related words from text improves free text query understanding, translating videos into text summaries facilitates better video search particularly in the absence of accompanying text. In this paper, we propose a multimedia topic modeling framework suitable for providing a basis for automatically discovering and translating semantically related words obtained from textual metadata of multimedia documents to semantically related videos or frames from videos. The framework jointly models video and text and is flexible enough to handle different types of document features in their constituent domains such as discrete and real valued features from videos representing actions, objects, colors and scenes as well as discrete features from text. Our proposed models show much better fit to the multimedia data in terms of held-out data log likelihoods. For a given query video, our models translate low level vision features into bag of keyword summaries which can be further translated using simple natural language generation techniques into human readable paragraphs. We quantitatively compare the results of video to bag of words translation against a state-of-the-art baseline object recognition model from computer vision. We show that text translations from multimodal topic models vastly outperform the baseline on a multimedia dataset downloaded from the Internet.",2013,Web Search and Data Mining,Fields of study: multimediaworld wide webinformation retrievaldata miningcomputer science
Evaluating the visual quality of web pages using a computational aesthetic approach,Ou Wu (Chinese Academy of Sciences)Yunfei Chen (Chinese Academy of Sciences)Bing Li (Chinese Academy of Sciences)Weiming Hu (Chinese Academy of Sciences),"2131587498,2139321662,2602233432,2124189993","Current Web mining explores useful and valuable information (content) online for users. However, there is scant research on the overall visual aspect of Web pages, even though visual elements such as aesthetics significantly influence user experience. A beautiful and well-laid out Web page greatly facilitates users' accessing and enhances browsing experiences.We use ""visual quality (VisQ)"" to denote the aesthetics of Web pages. In this paper, a computational aesthetics approach is proposed to learn the evaluation model for the visual quality of Web pages. First, a Web page layout extraction algorithm (V-LBE) is introduced to partition a Web page into major layout blocks. Then, regarding a Web page as a semi-structured image, features (e.g., layout,visual complexity, colorfulness) known to significantly affect the visual quality of a Web page are extracted to construct a feature vector. We present a multi-cost-sensitive learning for visual quality classification and a multi-value regression for visual quality score assignment. Our experiments compare the extracted features and conclude that the Web page's layout visual features (LV) and text visual features (TV) are the primary affecting factors toward Web page's visual quality. The performance of the learned visual quality classifier is close to some persons'. The learned regression function also achieves promising results.",2011,Web Search and Data Mining,Fields of study: website parse templatesocial semantic webweb analyticsweb mappingmashupweb designweb navigationweb pagefeature vectorfeatureself informationweb miningmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Detecting duplicate web documents using clickthrough data,Filip Radlinski (Microsoft)Paul N. Bennett (Microsoft)Emine Yilmaz (Microsoft),"2072292845,2137013502,2342836604","The web contains many duplicate and near-duplicate documents. Given that user satisfaction is negatively affected by redundant information in search results, a significant amount of research has been devoted to developing duplicate detection algorithms. However, most such algorithms rely solely on document content to detect duplication, ignoring the fact that a primary goal of duplicate detection is to identify documents that contain redundant information with respect to a particular user query . Similarly, although query- dependent result diversification algorithms compute a query-dependent ranking, they tend to do so on the basis of a query-independent content similarity score. In this paper, we bridge the gap between query-dependent redundancy and query-independent duplication by showing how user click behavior following a query provides evidence about the relative novelty of web documents. While most previous work on interpreting user clicks on search results has assumed that they reflect just result relevance, we show that clicks also provide information about duplication between web documents since users consider search results in the context of previously seen documents. Moreover, we find that duplication explains a substantial amount of presentation bias observed in clicking behavior. We identify three distinct types of redundancy that commonly occur on the web and show how click data can be used to detect these different types.",2011,Web Search and Data Mining,Fields of study: rankingaffectutilitygene duplicationredundancyworld wide webinformation retrievaldata miningcomputer science
Large-Scale Deep Learning For Building Intelligent Computer Systems,Jeffrey Dean (Google),2429370538,"For the past five years, the Google Brain team has focused on conducting research in difficult problems in artificial intelligence, on building large-scale computer systems for machine learning research, and, in collaboration with many teams at Google, on applying our research and systems to dozens of Google products. Our group has recently open-sourced the TensorFlow system (tensorflow.org), a system designed to easily express machine ideas, and to quickly train, evaluate and deploy machine learning systems. In this talk, I'll highlight some of the design decisions we made in building TensorFlow, discuss research results produced within our group, and describe ways in which these ideas have been applied to a variety of problems in Google's products, usually in close collaboration with other teams. This talk describes joint work with many people at Google.",2016,Web Search and Data Mining,Fields of study: deep learningworld wide webdata miningartificial intelligencemachine learningsimulationcomputer science
"Ranking from pairs and triplets: information quality, evaluation methods and query complexity",Kira Radinsky (Technion – Israel Institute of Technology)Nir Ailon (Technion – Israel Institute of Technology),"1780829609,327757988","Obtaining judgments from human raters is a vital part in the design of search engines' evaluation. Today, a discrepancy exists between judgment acquisition from raters (training phase) and use of the responses for retrieval evaluation (evaluation phase). This discrepancy is due to the inconsistency between the representation of the information in both phases. During training, raters are requested to provide a relevance score for an individual result in the context of a query, whereas the evaluation is performed on ordered lists of search results, with the results' relative position (compared to other results) taken into account. As an alternative to the practice of learning to rank using relevance judgments for individual search results, more and more focus has recently been diverted to the theory and practice of learning from answers to combinatorial questions about sets of search results. That is, users, during training, are asked to rank small sets (typically pairs). Human rater responses to questions about the relevance of individual results are first compared to their responses to questions about the relevance of pairs of results. We empirically show that neither type of response can be deduced from the other, and that the added context created when results are shown together changes the raters' evaluation process. Since pairwise judgments are directly related to ranking, we conclude they are more accurate for that purpose. We go beyond pairs to show that triplets do not contain significantly more information than pairs for the purpose of measuring statistical preference. These two results establish good stability properties of pairwise comparisons for the purpose of learning to rank. We further analyze different scenarios, in which results of varying quality are added as ""decoys"". A recurring source of worry in papers focusing on pairwise comparison is the quadratic number of pairs in a set of results. Which preferences do we choose to solicit from paid raters? Can we provably eliminate a quadratic cost? We employ results from statistical learning theory to show that the quadratic cost can be provably eliminated in certain cases. More precisely, we show that in order to obtain a ranking in which each element is an average of O ( n/C ) positions away from its position in the optimal ranking, one needs to sample O ( nC 2 ) pairs uniformly at random, for any C > 0. We also present an active learning algorithm which samples the pairs adaptively, and conjecture that it provides additional improvement.",2011,Web Search and Data Mining,Fields of study: rankinginformation qualityactive learninglearning to rankworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Ranking in heterogeneous social media,Min-Hsuan Tsai (Google)Charu C. Aggarwal (IBM)Thomas S. Huang (University of Illinois at Urbana–Champaign),"2227891643,2146335907,2149631809","The problem of image search has been studied extensively in recent years because of the large and increasing repositories of images on the web, social media, and other linked networks. Most of the available techniques for keyword-based image search on the web use the text in the surrounding or linked text in order to retrieve related images. Many image repositories on the web are built upon social media platforms such as Flickr. Such platforms provide a rich level of information in terms of the user linkage information to images, tags or other comments which are contributed by the users. It is reasonable to assume that the content of the images, users and other social cues such as tags and comments are often related to one another. Therefore, such cues can be useful for improving the effectiveness of search and ranking algorithms. In this paper, we propose SocialRank, which is a technique for using social hints in order to improve the image search and ranking process. Furthermore, we propose a holistic framework to combine social tags, social network text, linkage between actors and images, as well as the actual image features in order to create a ranking technique for image search. We design a PageRank-like method which can combine these different methods in order to provide an effective method for image search and ranking in social networks.",2014,Web Search and Data Mining,Fields of study: heterogeneous networkrandom walkimage retrievalworld wide webinformation retrievaldata miningstatisticscomputer science
On the prediction of popularity of trends and hits for user generated videos,Flavio Figueiredo (Universidade Federal de Minas Gerais),2034386535,"User generated content (UGC) has emerged as the predominant form of media publishing on the Web 2.0. Motivated by the large adoption of video sharing on the Web 2.0, the objective of our work is to understand and predict popularity trends (e.g, will a video be viral?) and hits (e.g, how may views will a video receive?) of user generated videos. Such knowledge is paramount to the effective design of various services including content distribution and advertising. Thus, in this paper we formalize the problem of predicting trends and hits in user generated videos. Also, we describe our research methodology on approaching this problem. To the best of knowledge, our work is novel in focusing on the problem of predicting popularity trends complementary to hits. Moreover, we intend on evaluating efficacy of our results not only based on common statistical error metrics, but also on the possible online advertising revenues our predictions can generate. After describing our proposal, we here summarize our latest findings regarding (1) uncovering common popularity trends; (2) measuring associations between UGC features and popularity trends; and (3) assessing the effectiveness of models for predicting popularity trends.",2013,Web Search and Data Mining,Fields of study: user generated contentvideointernet privacymultimediaworld wide webdata miningcomputer science
Learning latent representations of nodes for classifying in heterogeneous social networks,Yann Jacob (University of Paris)Ludovic Denoyer (University of Paris)Patrick Gallinari (University of Paris),"2131217544,2080627981,2638033927","Social networks are heterogeneous systems composed of different types of nodes (e.g. users, content, groups, etc.) and relations (e.g. social or similarity relations). While learning and performing inference on homogeneous networks have motivated a large amount of research, few work exists on heterogeneous networks and there are open and challenging issues for existing methods that were previously developed for homogeneous networks. We address here the specific problem of nodes classification and tagging in heterogeneous social networks, where different types of nodes are considered, each type with its own label or tag set. We propose a new method for learning node representations onto a latent space, common to all the different node types. Inference is then performed in this latent space. In this framework, two nodes connected in the network will tend to share similar representations regardless of their types. This allows bypassing limitations of the methods based on direct extensions of homogenous frameworks and exploiting the dependencies and correlations between the different node types. The proposed method is tested on two representative datasets and compared to state-of-the-art methods and to baselines.",2014,Web Search and Data Mining,Fields of study: evolving networkssocial networkbiological classificationdata miningartificial intelligencemachine learningcomputer science
Understanding temporal aspects in document classification,Fernando Mourão (Universidade Federal de Minas Gerais)Leonardo C. da Rocha (Universidade Federal de Minas Gerais)Renata Braga Araújo (Universidade Federal de Minas Gerais)Thierson Couto (Universidade Federal de Minas Gerais)Marcos André Gonçalves (Universidade Federal de Minas Gerais)Wagner Meira (Universidade Federal de Minas Gerais),"2012617867,2175269910,2153982562,2279325506,2115586749,2165931068","Due to the increasing amount of information present on the Web, Automatic Document Classification (ADC) has become an important research topic. ADC usually follows a standard supervised learning strategy, where we first build a model using preclassified documents and then use it to classify new unseen documents. One major challenge for ADC in many scenarios is that the characteristics of the documents and the classes to which they belong may change over time. However, most of the current techniques for ADC are applied without taking into account the temporal evolution of the collection of documents In this work, we perform a detailed study of the temporal evolution in the ADC, introducing an analysis methodology. We discuss that temporal evolution may be explained by three factors: 1) class distribution; 2) term distribution; and 3) class similarity. We employ metrics and experimental strategies capable of isolating each of these factors in order to analyze them separately, using two very different document collections: the ACM Digital Library and the Medline medical collections. Moreover, we present some preliminary results of potential gains that could be obtained by varying the training set to find the ideal size that minimizes the time effects. We show that by using just 69% of the ACM database, we are able to have an accuracy of 89.76%, and with only 25% of the Medline, an accuracy of 87.57%, which means gains of up to 20% in accuracy with much smaller training sets",2008,Web Search and Data Mining,Fields of study: digital librarydata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
The Troll-Trust Model for Ranking in Signed Networks,Zhaoming Wu (Georgia Institute of Technology)Charu C. Aggarwal (IBM)Jimeng Sun (Georgia Institute of Technology),"2565898709,2146335907,2110385854","Signed social networks have become increasingly important in recent years because of the ability to model trust-based relationships in review sites like Slashdot, Epinions, and Wikipedia. As a result, many traditional network mining problems have been re-visited in the context of networks in which signs are associated with the links. Examples of such problems include community detection, link prediction, and low rank approximation. In this paper, we will examine the problem of ranking nodes in signed networks. In particular, we will design a ranking model, which has a clear physical interpretation in terms of the sign of the edges in the network. Specifically, we propose the Troll-Trust model that models the probability of trustworthiness of individual data sources as an interpretation for the underlying ranking values. We will show the advantages of this approach over a variety of baselines.",2016,Web Search and Data Mining,Fields of study: rankingdata miningartificial intelligencemachine learningcomputer science
A new visual search interface for web browsing,Songhua Xu (Zhejiang University)Tao Jin (University of Hong Kong)Francis Chi-Moon Lau (University of Hong Kong),"2630999881,2296427687,2135205842","We introduce a new visual search interface for search engines. The interface is a user-friendly and informative graphical front-end for organizing and presenting search results in the form of topic groups. Such a semantics-oriented search result presentation is in contrast with conventional search interfaces which present search results according to the physical structures of the information. Given a user query, our interface first retrieves relevant online materials via a third-party search engine. And then we analyze the semantics of search results to detect latent topics in the result set. Once the topics are detected, we map the search result pages into topic clusters. According to the topic clustering result, we divide the available screen space for our visual interface into multiple topic displaying regions, one for each topic. For each topic's displaying region, we summarize the information contained in the search results under the corresponding topic so that only key messages will be displayed. With this new visual search interface, users are conveyed the key information in the search results expediently. With the key information, users can navigate to the final, desired results with less effort and time than conventional searching. Supplementary materials for this paper are available at http://www.cs.hku.hk/~songhua/visualsearch/ .",2009,Web Search and Data Mining,Fields of study: search analyticsphrase searchorganic searchonline searchweb search queryvisual searchfront and back endssearch enginesemantic searchmultimediaworld wide webinformation retrievalcomputer science
Sentiment analysis on evolving social streams: how self-report imbalances can help,Pedro Henrique Calais Guerra (Universidade Federal de Minas Gerais)Wagner Meira (Universidade Federal de Minas Gerais)Claire Cardie (Cornell University),"2224746110,2630377516,229573375","Real-time sentiment analysis is a challenging machine learning task, due to scarcity of labeled data and sudden changes in sentiment caused by real-world events that need to be instantly interpreted. In this paper we propose solutions to acquire labels and cope with concept drift in this setting, by using findings from social psychology on how humans prefer to disclose some types of emotions. In particular, we use findings that humans are more motivated to report positive feelings rather than negative feelings and also prefer to report extreme feelings rather than average feelings. We map each of these self-report imbalances on two machine learning sub-tasks. The preference on the disclosure of positive feelings can be explored to generate labeled data on polarizing topics, where a positive event for one group usually induces negative feelings from the opposing group, generating an imbalance on user activity that unveils the current dominant sentiment. Based on the knowledge that extreme experiences are more reported than average experiences, we propose a feature representation strategy that focus on terms which appear at spikes in the social stream. When comparing to a static text representation (TF-IDF), we found that our feature representation is more capable of detecting new informative features that capture the sudden changes on sentiment stream caused by real-world events. We show that our social psychology-inspired framework produces accuracies up to 84% while analyzing live reactions in the debate of two popular sports on Twitter - soccer and football - despite requiring no human effort in generating supervisory labels.",2014,Web Search and Data Mining,Fields of study: sentiment analysisworld wide webdata miningmachine learningcomputer science
Embedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks,Linchuan Xu (Hong Kong Polytechnic University)Xiaokai Wei (University of Illinois at Chicago)Jiannong Cao (Hong Kong Polytechnic University)Philip S. Yu (University of Illinois at Chicago),"2594127968,2405326445,2150384665,2125104194","Network embedding is increasingly employed to assist network analysis as it is effective to learn latent features that encode linkage information. Various network embedding methods have been proposed, but they are only designed for a single network scenario. In the era of big data, different types of related information can be fused together to form a coupled heterogeneous network, which consists of two different but related sub-networks connected by inter-network edges. In this scenario, the inter-network edges can act as comple- mentary information in the presence of intra-network ones. This complementary information is important because it can make latent features more comprehensive and accurate. And it is more important when the intra-network edges are ab- sent, which can be referred to as the cold-start problem. In this paper, we thus propose a method named embedding of embedding (EOE) for coupled heterogeneous networks. In the EOE, latent features encode not only intra-network edges, but also inter-network ones. To tackle the challenge of heterogeneities of two networks, the EOE incorporates a harmonious embedding matrix to further embed the em- beddings that only encode intra-network edges. Empirical experiments on a variety of real-world datasets demonstrate the EOE outperforms consistently single network embedding methods in applications including visualization, link prediction multi-class classification, and multi-label classification.",2017,Web Search and Data Mining,Fields of study: theoretical computer sciencedistributed computingmachine learningcomputer science
Ranking with query-dependent loss for web search,Jiang Bian (Georgia Institute of Technology)Tie-Yan Liu (Microsoft)Tao Qin (Microsoft)Hongyuan Zha (Georgia Institute of Technology),"2155810403,2640187116,2645702713,2099091510","Queries describe the users' search intent and therefore they play an essential role in the context of ranking for information retrieval and Web search. However, most of existing approaches for ranking do not explicitly take into consideration the fact that queries vary significantly along several dimensions and entail different treatments regarding the ranking models. In this paper, we propose to incorporate query difference into ranking by introducing query-dependent loss functions. In the context of Web search, query difference is usually represented as different query categories; and, queries are usually classified according to search intent such as navigational, informational and transactional queries. Based on the observation that such kind of query categorization has high correlation with the user's different expectation on the result accuracy on different rank positions, we develop position-sensitive query-dependent loss functions exploring such kind of query categorization. Beyond the simple learning method that builds ranking functions with pre-defined query categorization, we further propose a new method that learns both ranking functions and query categorization simultaneously. We apply the query-dependent loss functions to two particular ranking algorithms, RankNet and ListMLE. Experimental results demonstrate that query-dependent loss functions can be exploited to significantly improve the accuracy of learned ranking functions. We also show that the ranking function jointly learned with query categorization can achieve better performance than that learned with pre-defined query categorization. Finally, we provide analysis and conduct additional experiments to gain deeper understanding on the advantages of ranking with query-dependent loss functions over other query-dependent ranking approaches and query-independent approaches.",2010,Web Search and Data Mining,Fields of study: rankingranking svmweb search queryweb query classificationquery expansionquery optimizationquery languageloss functionworld wide webinformation retrievaldata miningmachine learningcomputer science
No search result left behind: branching behavior with browser tabs,Jeff Huang (University of Washington)Thomas Lin (University of Washington)Ryen W. White (Microsoft),"2115870741,2397256036,2096583854","Today's Web browsers allow users to open links in new windows or tabs. This action, which we call 'branching', is sometimes performed on search results when the user plans to eventually visit multiple results. We detect branching behavior on a large commercial search engine with a client-side script on the results page. Two-fifths of all users spawned new tabs on search results in the timeframe of our study; branching usage varied with different query types and vertical. Both branching and backtracking are viable methods for visiting multiple search results. To understand user search strategies, we treat multiple result clicks following a query as ordered events to understand user search strategies. Users branching in a query are more likely to click search results from top to bottom, while users who backtrack are less likely to do so; this is especially true for queries involving more than two clicks. These findings inform an experiment in which we take a popular click model and modify it to account for the differing user behavior when branching. By understanding that users continue examining search results before viewing a branched result, we can improve the click model for branching queries.",2012,Web Search and Data Mining,Fields of study: search analyticsphrase searchorganic searchsearch enginemultimediaworld wide webinformation retrievaldata miningdatabasecomputer science
"From machu_picchu to ""rafting the urubamba river"": anticipating information needs via the entity-query graph",Ilaria Bordino (Yahoo!)Gianmarco De Francisci Morales (Yahoo!)Ingmar Weber (Qatar Computing Research Institute)Francesco Bonchi (Yahoo!),"22319059,2153118160,2074066684,2176652147","We study the problem of anticipating user search needs, based on their browsing activity. Given the current web page p that a user is visiting we want to recommend a small and diverse set of search queries that are relevant to the content of p, but also non-obvious and serendipitous. We introduce a novel method that is based on the content of the page visited, rather than on past browsing patterns as in previous literature. Our content-based approach can be used even for previously unseen pages. We represent the topics of a page by the set of Wikipedia entities extracted from it. To obtain useful query suggestions for these entities, we exploit a novel graph model that we call EQGraph (Entity-Query Graph), containing entities, queries, and transitions between entities, between queries, as well as from entities to queries. We perform Personalized PageRank computation on such a graph to expand the set of entities extracted from a page into a richer set of entities, and to associate these entities with relevant query suggestions. We develop an efficient implementation to deal with large graph instances and suggest queries from a large and diverse pool. We perform a user study that shows that our method produces relevant and interesting recommendations, and outperforms an alternative method based on reverse IR.",2013,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningmachine learningcomputer science
Automatic Gloss Finding for a Knowledge Base using Ontological Constraints,Bhavana Bharat Dalvi (Carnegie Mellon University)Einat Minkov (University of Haifa)Partha Pratim Talukdar (Indian Institute of Science)William W. Cohen (Carnegie Mellon University),"2081006310,1891675207,2407474466,2115385359","While there has been much research on automatically constructing structured Knowledge Bases (KBs), most of it has focused on generating facts to populate a KB. However, a useful KB must go beyond facts. For example, glosses (short natural language definitions) have been found to be very useful in tasks such as Word Sense Disambiguation. However, the important problem of Automatic Gloss Finding, i.e., assigning glosses to entities in an initially gloss-free KB, is relatively unexplored. We address that gap in this paper. In particular, we propose GLOFIN, a hierarchical semi-supervised learning algorithm for this problem which makes effective use of limited amounts of supervision and available ontological constraints. To the best of our knowledge, GLOFIN is the first system for this task. Through extensive experiments on real-world datasets, we demonstrate GLOFIN's effectiveness. It is encouraging to see that GLOFIN outperforms other state-of-the-art SSL algorithms, especially in low supervision settings. We also demonstrate GLOFIN's robustness to noise through experiments on a wide variety of KBs, ranging from user contributed (e.g., Freebase) to automatically constructed (e.g., NELL). To facilitate further research in this area, we have made the datasets and code used in this paper publicly available.",2015,Web Search and Data Mining,Fields of study: web miningdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Semantic Documents Relatedness using Concept Graph Representation,Yuan Ni (IBM)Qiong Kai Xu (IBM)Feng Cao (IBM)Yosi Mass (IBM)Dafna Sheinwald (IBM)Hui Jia Zhu (IBM)Shao Sheng Cao (Xidian University),"2669498312,2227099082,2428634916,2117117435,97365951,2485477641,2342455663","We deal with the problem of document representation for the task of measuring semantic relatedness between documents. A document is represented as a compact concept graph where nodes represent concepts extracted from the document through references to entities in a knowledge base such as DBpedia. Edges represent the semantic and structural relationships among the concepts. Several methods are presented to measure the strength of those relationships. Concepts are weighted through the concept graph using closeness centrality measure which reflects their relevance to the aspects of the document. A novel similarity measure between two concept graphs is presented. The similarity measure first represents concepts as continuous vectors by means of neural networks. Second, the continuous vectors are used to accumulate pairwise similarity between pairs of concepts while considering their assigned weights. We evaluate our method on a standard benchmark for document similarity. Our method outperforms state-of-the-art methods including ESA (Explicit Semantic Annotation) while our concept graphs are much smaller than the concept vectors generated by ESA. Moreover, we show that by combining our concept graph with ESA, we obtain an even further improvement.",2016,Web Search and Data Mining,Fields of study: semantic similarityartificial neural networknatural language processinginformation retrievaldata miningmachine learningcomputer science
Modeling and Predicting Learning Behavior in MOOCs,Jiezhong Qiu (Tsinghua University)Jie Tang (Tsinghua University)Tracy Xiao Liu (Tsinghua University)Jie Gong (National University of Singapore)Chenhui Zhang (Tsinghua University)Qian Zhang (Tsinghua University)Yufei Xue (Tsinghua University),"2416947802,2158012360,2401874336,2342907022,2703734514,2666129334,2712880692","Massive Open Online Courses (MOOCs), which collect complete records of all student interactions in an online learning environment, offer us an unprecedented opportunity to analyze students' learning behavior at a very fine granularity than ever before. Using dataset from xuetangX, one of the largest MOOCs from China, we analyze key factors that influence students' engagement in MOOCs and study to what extent we could infer a student's learning effectiveness. We observe significant behavioral heterogeneity in students' course selection as well as their learning patterns. For example, students who exert higher effort and ask more questions are not necessarily more likely to get certificates. Additionally, the probability that a student obtains the course certificate increases dramatically (3 x higher) when she has one or more ""certificate friends"". Moreover, we develop a unified model to predict students' learning effectiveness, by incorporating user demographics, forum activities, and learning behavior. We demonstrate that the proposed model significantly outperforms (+2.03-9.03% by F1-score) several alternative methods in predicting students' performance on assignments and course certificates. The model is flexible and can be applied to various settings. For example, we are deploying a new feature into xuetangX to help teachers dynamically optimize the teaching process.",2016,Web Search and Data Mining,Fields of study: predictive modellingmultimediaworld wide webmachine learningsimulationcomputer science
Online community detection in social sensing,Guo-Jun Qi (University of Illinois at Urbana–Champaign)Charu C. Aggarwal (IBM)Thomas S. Huang (University of Illinois at Urbana–Champaign),"2237849324,2146335907,2149631809","The proliferation of location and GPS data streams which are collected in a wide variety of participatory sensing applications has created numerous possibilities for analysis of the underlying patterns of activity. Typically, the spatio-temporal patterns arising from such activity can be analyzed in order to determine the latent community structure in the underlying data. In this paper, we will examine the problem of online community detection from the location data collected from such social sensing applications in real time. Such data brings numerous challenges associated with it, in that they can be of a relatively large scale, and can be extremely noisy from the perspective of both data representation and analysis. Furthermore, the community structure in the underlying data cannot be directly inferred from the shape of the underlying trajectories, since a considerable amount of variation may exist in terms of trajectories of individuals belonging to the same community. In this paper, we will design online algorithms for community detection in social sensing applications. Our algorithm uses a robust and efficiently updateable model with the use of Gibbs sampling, and we will show its effectiveness and efficiency for social sensing applications.",2013,Web Search and Data Mining,Fields of study: data sciencedata miningmachine learningcomputer science
Overlapping clusters for distributed computation,Reid Andersen (Microsoft)David F. Gleich (Purdue University)Vahab S. Mirrokni (Google),"2137555013,2148810670,2331823467","Most graph decomposition procedures seek to partition a graph into disjoint sets of vertices. Motivated by applications of clustering in distributed computation, we describe a graph decomposition algorithm for the paradigm where the partitions intersect. This algorithm covers the vertex set with a collection of overlapping clusters. Each vertex in the graph is well-contained within some cluster in the collection. We then describe a framework for distributed computation across a collection of overlapping clusters and describe how this framework can be used in various algorithms based on the graph diffusion process. In particular, we focus on two illustrative examples: (i) the simulation of a randomly walking particle and (ii) the solution of a linear system, e.g. PageRank. Our simulation results for these two cases show a significant reduction in swapping between clusters in a random walk, a significant decrease in communication volume during a linear system solve in a geometric mesh, and some ability to reduce the communication volume during a linear system solve in an information network.",2012,Web Search and Data Mining,Fields of study: simplex graphstrength of a graphquartic graphvoltage graphcomplement graphgraph bandwidththeta graphbutterfly graphstring graphlevel structurenull graphadditive schwarz methodfeedback vertex setrandom geometric graphcycle graphvertexconductanceloopregular graphdegreegraph partitiondiffusion processrandom walkimplementationsocial networklinear systemdesigndiffusionprobabilitydistributed algorithmtheoretical computer sciencedata miningmachine learningstatisticscomputer science
Improving search relevance for short queries in community question answering,Haocheng Wu (University of Science and Technology of China)Wei Wu (Microsoft)Ming Zhou (Microsoft)Enhong Chen (University of Science and Technology of China)Lei Duan (Microsoft)Heung-Yeung Shum (Microsoft),"2131380619,2590381716,2143584880,2136372366,2675109907,2147729234","Relevant question retrieval and ranking is a typical task in community question answering (CQA). Existing methods mainly focus on long and syntactically structured queries. However, when an input query is short, the task becomes challenging, due to a lack information regarding user intent. In this paper, we mine different types of user intent from various sources for short queries. With these intent signals, we propose a new intent-based language model. The model takes advantage of both state-of-the-art relevance models and the extra intent information mined from multiple sources. We further employ a state-of-the-art learning-to-rank approach to estimate parameters in the model from training data. Experiments show that by leveraging user intent prediction, our model significantly outperforms the state-of-the-art relevance models in question search.",2014,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
Contrasting Controlled Vocabulary and Tagging: Experts Choose the Right Names to Label the Wrong Things.,Paul Heymann (Stanford University)Hector Garcia-Molina (Stanford University),"2038619550,237419955","Social cataloging sites---tagging systems where users tag books---provide us with a rare opportunity to contrast tags to other information organization systems. We contrast tags to a controlled vocabulary, the Library of Congress Subject Headings, which has been developed over several decades. We find that many of the keywords designated by tags and LCSH are similar or the same, but that usage of keywords by annotators is quite different.",2009,Web Search and Data Mining,Fields of study: controlled vocabularyworld wide webinformation retrievalcomputer science
Wiki3C: exploiting wikipedia for context-aware concept categorization,Peng Jiang (HP Labs)Huiman Hou (Baidu)Lijiang Chen (HP Labs)Shimin Chen (HP Labs)Conglei Yao (Tencent)Chengkai Li (University of Texas at Arlington)Min Wang (HP Labs),"2667544051,2110510069,2311253366,2161123335,2635114253,2145831560,2467205710","Wikipedia is an important human generated knowledge base containing over 21 million articles organized by millions of categories. In this paper, we exploit Wikipedia for a new task of text mining: Context-aware Concept Categorization. In the task, we focus on categorizing concepts according to their context. We exploit article link feature and category structure in Wikipedia, followed by introducing Wiki3C, an unsupervised and domain independent concept categorization approach based on context. In the approach, we investigate two strategies to select and filter Wikipedia articles for the category representation. Besides, a probabilistic model is employed to compute the semantic relatedness between two concepts in Wikipedia. Experimental evaluation using manually labeled ground truth shows that our proposed Wiki3C can achieve a noticeable improvement over the baselines without considering contextual information.",2013,Web Search and Data Mining,Fields of study: brandtext miningnatural language processinginformation retrievaldata miningcomputer science
Latent factor models with additive and hierarchically-smoothed user preferences,Amr Ahmed (Google)Bhargav Kanagal (Google)Sandeep Pandey (Twitter)Vanja Josifovski (Google)Lluis Garcia Pueyo (Google)Jeffrey Yuan (Yahoo!),"2259645355,311418139,2723427591,344688379,2228477446,2308087448","Items in recommender systems are usually associated with annotated attributes: for e.g., brand and price for products; agency for news articles, etc. Such attributes are highly informative and must be exploited for accurate recommendation. While learning a user preference model over these attributes can result in an interpretable recommender system and can hands the cold start problem, it suffers from two major drawbacks: data sparsity and the inability to model random effects. On the other hand, latent-factor collaborative filtering models have shown great promise in recommender systems; however, its performance on rare items is poor. In this paper we propose a novel model LFUM, which provides the advantages of both of the above models. We learn user preferences (over the attributes) using a personalized Bayesian hierarchical model that uses a combination(additive model) of a globally learned preference model along with user-specific preferences. To combat data-sparsity, we smooth these preferences over the item-taxonomy using an efficient forward-filtering and backward-smoothing inference algorithm. Our inference algorithms can handle both discrete attributes (e.g., item brands) and continuous attributes (e.g., item prices). We combine the user preferences with the latent-factor models and train the resulting collaborative filtering system end-to-end using the successful BPR ranking algorithm. In our extensive experimental analysis, we show that our proposed model outperforms several commonly used baselines and we carry out an ablation study showing the benefits of each component of our model.",2013,Web Search and Data Mining,Fields of study: collaborative filteringworld wide webdata miningmachine learningstatistics
LaFT-tree: perceiving the expansion trace of one's circle of friends in online social networks,Jun Zhang (Tsinghua University)Chaokun Wang (Tsinghua University)Jianmin Wang (Tsinghua University)Philip S. Yu (University of Illinois at Chicago),"2664544038,2106340623,2310637432,2125104194","Many patterns have been discovered to explain and analyze how people make friends. Among them is the triadic closure, supported by the principle of the transitivity of friendship, which means for an individual the friends of her friend are more likely to become her new friends. However, people's motivations under this principle haven't been well studied, and it's still unknown that how this principle works in diverse situations. In this paper, we try to study this principle deeply based on the behavior modeling. We study how one expands her egocentric network via her friends, also called intermediaries, based on the transitivity of friendship. We propose LaFT-Tree, a tree-based representation of friendship formation inspired from triadic closure. LaFT-Tree provides a hierarchical view of the flat structure of one's egocentric network by visualizing the expansion trace of one's egocentric network. We model people's friend-making behaviors using LaFT-LDA, a generative model for LaFT-Tree learning. The proposed model is evaluated on both synthetic and real-world social networks and experimental results demonstrate the effectiveness of LaFT-LDA for LaFT-Tree inference. We also present some interesting applications of the LaFT-Tree, showing that our model can be generalized and benefit other social network analysis tasks.",2013,Web Search and Data Mining,Fields of study: triadic closuresocial networksocial scienceartificial intelligence
Using linked data to mine RDF from wikipedia's tables,"Emir Muñoz (Fujitsu)Aidan Hogan (University of Chile)Alessandra Mileo (National University of Ireland, Galway)","2165782363,2136710978,2252971944","The tables embedded in Wikipedia articles contain rich, semi-structured encyclopaedic content. However, the cumulative content of these tables cannot be queried against. We thus propose methods to recover the semantics of Wikipedia tables and, in particular, to extract facts from them in the form of RDF triples. Our core method uses an existing Linked Data knowledge-base to find pre-existing relations between entities in Wikipedia tables, suggesting the same relations as holding for other entities in analogous columns on different rows. We find that such an approach extracts RDF triples from Wikipedia's tables at a raw precision of 40%. To improve the raw precision, we define a set of features for extracted triples that are tracked during the extraction phase. Using a manually labelled gold standard, we then test a variety of machine learning methods for classifying correct/incorrect triples. One such method extracts 7.9 million unique and novel RDF triples from over one million Wikipedia tables at an estimated precision of 81.5%.",2014,Web Search and Data Mining,Fields of study: brandlinked datadata analysisworld wide webinformation retrievaldata miningcomputer science
Bid generation for advanced match in sponsored search,Andrei Z. Broder (Yahoo!)Evgeniy Gabrilovich (Yahoo!)Vanja Josifovski (Yahoo!)George Mavromatis (Yahoo!)Alexander J. Smola (Yahoo!),"2637163715,1804802447,344688379,1973313823,1972291593","Sponsored search is a three-way interaction between advertisers, users, and the search engine. The basic ad selection in sponsored search, lets the advertiser choose the exact queries where the ad is to be shown. To increase advertising volume, many advertisers opt into advanced match , where the search engine can select additional queries that are deemed relevant for the advertiser's ad. In advanced match, the search engine is effectively bidding on the behalf of the advertisers. While advanced match has been extensively studied in the literature from the ad relevance perspective there is little work that discusses how to infer the appropriate bid value for a given advanced match. The bid value is crucial as it affects both the ad placement in revenue reordering and the amount advertisers are charged in case of a click. We propose a statistical approach to solve the bid generation problem and examine two information sources: the bidding behavior of advertisers, and the conversion data. Our key finding suggests that sophisticated advertisers' bids are driven by many factors beyond clicks and immediate measurable conversions, likely capturing the value chain of an ad display ranging from views, clicks, profit margins, etc., representing the total ROI from the advertising.",2011,Web Search and Data Mining,Fields of study: share of voicevalue chainprofitability indexsearch engineworld wide webdata miningmachine learningcomputer science
Extracting search-focused key n-grams for relevance ranking in web search,Chen Wang (Fudan University)Keping Bi (Peking University)Yunhua Hu (Microsoft)Hang Li (Microsoft)Guihong Cao (Microsoft),"2672058280,2222600076,2110062735,2128739099,2716051477","In web search, relevance ranking of popular pages is relatively easy, because of the inclusion of strong signals such as anchor text and search log data. In contrast, with less popular pages, relevance ranking becomes very challenging due to a lack of information. In this paper the former is referred to as head pages, and the latter tail pages. We address the challenge by learning a model that can extract search-focused key n-grams from web pages, and using the key n-grams for searches of the pages, particularly, the tail pages. To the best of our knowledge, this problem has not been previously studied. Our approach has four characteristics. First, key n-grams are search-focused in the sense that they are defined as those which can compose ""good queries"" for searching the page. Second, key n-grams are learned in a relative sense using learning to rank techniques. Third, key n-grams are learned using search log data, such that the characteristics of key n-grams in the search log data, particularly in the heads; can be applied to the other data, particularly to the tails. Fourth, the extracted key n-grams are used as features of the relevance ranking model also trained with learning to rank techniques. Experiments validate the effectiveness of the proposed approach with large-scale web search datasets. The results show that our approach can significantly improve relevance ranking performance on both heads and tails; and particularly tails, compared with baseline approaches. Characteristics of our approach have also been fully investigated through comprehensive experiments.",2012,Web Search and Data Mining,Fields of study: rankingranking svmanchor textrankingweb pagelearning to rankworld wide webinformation retrievaldata miningcomputer science
Connecting comments and tags: improved modeling of social tagging systems,Dawei Yin (Lehigh University)Shengbo Guo (Xerox)Boris Chidlovskii (Xerox)Brian D. Davison (Lehigh University)Cedric Archambeau (Xerox)Guillaume Bouchard (Xerox),"2170531144,2168690967,36378520,2203702053,2006974593,2336810427","Collaborative tagging systems are now deployed extensively to help users share and organize resources. Tag prediction and recommendation can simplify and streamline the user experience, and by modeling user preferences, predictive accuracy can be significantly improved. However, previous methods typically model user behavior based only on a log of prior tags, neglecting other behaviors and information in social tagging systems, e.g., commenting on items and connecting with other users. On the other hand, little is known about the connection and correlations among these behaviors and contexts in social tagging systems. In this paper, we investigate improved modeling for predictive social tagging systems. Our explanatory analyses demonstrate three significant challenges: coupled high order interaction, data sparsity and cold start on items. We tackle these problems by using a generalized latent factor model and fully Bayesian treatment. To evaluate performance, we test on two real-world data sets from Flickr and Bibsonomy. Our experiments on these data sets show that to achieve best predictive performance, it is necessary to employ a fully Bayesian treatment in modeling high order relations in social tagging system. Our methods noticeably outperform state-of-the-art approaches.",2013,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
"You've got Mail, and Here is What you Could do With It!: Analyzing and Predicting Actions on Email Messages",Dotan Di Castro (Yahoo!)Zohar Shay Karnin (Yahoo!)Liane Lewin-Eytan (Yahoo!)Yoelle Maarek (Yahoo!),"2163216773,1985648170,2022197843,262608878","With email traffic increasing, leading Web mail services have started to offer features that assist users in reading and processing their inboxes. One approach is to identify ""important"" messages, while a complementary one is to bundle messages, especially machine-generated ones, in pre-defined categories. We rather propose here to go back to the task at hand and consider what actions the users might conduct on received messages. We thoroughly studied, in a privacy-preserving manner, the actions of a large number of users in Yahoo mail, and found out that the most frequent actions are typically read, reply, delete and a sub-type of delete, delete-without-read . We devised a learning framework for predicting these four actions, for users with various levels of activity per action. Our framework leverages both vertical learning for personalization and horizontal learning for regularization purposes. In order to verify the quality of our predictions, we conducted a large-scale experiment involving users who had previously agreed to participate in such research studies. Our results show that, for recall values of 90%, we can predict important actions such as read or reply at precision levels up to 40% for active users, which we consider pretty encouraging for an assistance task. For less active users, we show that our regularization achieves an increase in AUC of close to 50%. To the best of our knowledge, our work is the first to provide a unified framework of this scale for predicting multiple actions on Web email, which hopefully provides a new ground for inventing new user experiences to help users process their inboxes.",2016,Web Search and Data Mining,Fields of study: structural loadmultimediaworld wide webdata miningcomputer science
Fair and balanced: learning to present news stories,Amr Ahmed (Yahoo!)Choon Hui Teo (Yahoo!)S. V. N. Vishwanathan (Purdue University)Alexander J. Smola (Yahoo!),"2259645355,2108769517,2584127737,1972291593","Relevance, diversity and personalization are key issues when presenting content which is apt to pique a user's interest. This is particularly true when presenting an engaging set of news stories. In this paper we propose an efficient algorithm for selecting a small subset of relevant articles from a streaming news corpus. It offers three key pieces of improvement over past work: 1) It is based on a detailed model of a user's viewing behavior which does not require explicit feedback. 2) We use the notion of submodularity to estimate the propensity of interacting with content. This improves over the classical context independent relevance ranking algorithms. Unlike existing methods, we learn the submodular function from the data. 3) We present an efficient online algorithm which can be adapted for personalization, story adaptation, and factorization models. Experiments show that our system yields a significant improvement over a retrieval system deployed in production.",2012,Web Search and Data Mining,Fields of study: graphical modelmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
On Obtaining Effort Based Judgements for Information Retrieval,Manisha Verma (University College London)Emine Yilmaz (University College London)Nick Craswell (Microsoft),"2289163828,2342836604,2009495402","Document relevance has been the primary focus in the design, optimization and evaluation of retrieval systems. Traditional testcollections are constructed by asking judges the relevance grade for a document with respect to an input query. Recent work of Yilmaz et al. found an evidence that effort is another important factor in determining document utility, suggesting that more thought should be given into incorporating effort into information retrieval. However, that work did not ask judges to directly assess the level of effort required to consume a document or analyse how effort judgements relate to traditional relevance judgements. In this work, focusing on three aspects associated with effort, we show that it is possible to get judgements of effort from the assessors. We further show that given documents of the same relevance grade, effort needed to find the portion of the document relevant to the query is a significant factor in determining user satisfaction as well as user preference between these documents. Our results suggest that if the end goal is to build retrieval systems that optimize user satisfaction, effort should be included as an additional factor to relevance in building and evaluating retrieval systems. We further show that new retrieval features are needed if the goal is to build retrieval systems that jointly optimize relevance and effort and propose a set of such features. Finally, we focus on the evaluation of retrieval systems and show that incorporating effort into retrieval evaluation could lead to significant differences regarding the performance of retrieval systems.",2016,Web Search and Data Mining,Fields of study: effort heuristichuman computer information retrievalrelevanceevaluationmultimediainformation retrievaldata miningcomputer science
Towards web-scale structured web data extraction,Tomas Grigalis (Vilnius Gediminas Technical University),184707232,"In this paper we present an ongoing PhD research on unsupervised and domain-independent structured data extraction from the Web. We propose a novel method to extract structured data records from template-generated Web pages. The method is based on clustering visually similar Web page elements by exploiting their visual formatting and HTML structural features. Tag paths of clustered Web page elements are then employed to derive extraction rules. These rules, called wrappers, can be later reused on thousands of same template-generated Web pages. This opens the possibility for the proposed method to be deployed in Web-Scale structured data extraction systems.",2013,Web Search and Data Mining,Fields of study: website parse templatedata webmashupdata modelinformation extractionworld wide webinformation retrievaldata miningcomputer science
Toward Predicting the Outcome of an A/B Experiment for Search Relevance,Lihong Li (Microsoft)Jin Young Kim (Microsoft)Imed Zitouni (Microsoft),"2125714999,2152189701,2507515815","A standard approach to estimating online click-based metrics of a ranking function is to run it in a controlled experiment on live users. While reliable and popular in practice, configuring and running an online experiment is cumbersome and time-intensive. In this work, inspired by recent successes of offline evaluation techniques for recommender systems, we study an alternative that uses historical search log to reliably predict online click-based metrics of a \emph{new} ranking function, without actually running it on live users. To tackle novel challenges encountered in Web search, variations of the basic techniques are proposed. The first is to take advantage of diversified behavior of a search engine over a long period of time to simulate randomized data collection, so that our approach can be used at very low cost. The second is to replace exact matching (of recommended items in previous work) by \emph{fuzzy} matching (of search result pages) to increase data efficiency, via a better trade-off of bias and variance. Extensive experimental results based on large-scale real search data from a major commercial search engine in the US market demonstrate our approach is promising and has potential for wide use in Web search.",2015,Web Search and Data Mining,Fields of study: search analyticsbeam searchsearch engineevaluationsemantic searchworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Driven by Food: Modeling Geographic Choice,Ravi Kumar (Google)Mohammad Mahdian (Google)Bo Pang (Google)Andrew Tomkins (Google)Sergei Vassilvitskii (Google),"2232709231,2161106313,2559233551,2535415812,2156675704","In this work we study the dynamics of geographic choice, i.e., how users choose one from a set of objects in a geographic region. We postulate a model in which an object is selected from a slate of candidates with probability that depends on how far it is (distance) and how many closer alternatives exist (rank). Under a discrete choice formulation, we argue that there exists a factored form in which unknown functions of rank and distance may be combined to produce an accurate estimate of the likelihood that a user will select each alternative. We then learn these hidden functions and show that each can be closely approximated by an appropriately parameterized lognormal, even though the respective marginals look quite different. We give a theoretical justification to support the presence of lognormal distributions. We then apply this framework to study restaurant choices in map search logs. We show that a four-parameter model based on combinations of lognormals has excellent performance at predicting restaurant choice, even compared to baseline models with access to the full (densely parameterized) marginal distribution for rank and distance. Finally, we show how this framework can be extended to simultaneously learn a per-restaurant quality score representing the residual likelihood of choice after distance and rank have been accounted for. We show that, compared to a per-place score that predicts likelihood without factoring out rank and distance, our score is a significantly better predictor of user quality judgments.",2015,Web Search and Data Mining,Fields of study: data miningmachine learningstatistics
The last click: why users give up information network navigation,Aju Thalappillil Scaria (Google)Rose Marie Philip (Facebook)Robert West (Stanford University)Jure Leskovec (Stanford University),"2250242932,2232515672,2119386814,1878631932","An important part of finding information online involves clicking from page to page until an information need is fully satisfied. This is a complex task that can easily be frustrating and force users to give up prematurely. An empirical analysis of what makes users abandon click-based navigation tasks is hard, since most passively collected browsing logs do not specify the exact target page that a user was trying to reach. We propose to overcome this problem by using data collected via Wikispeedia, a Wikipedia-based human-computation game, in which users are asked to navigate from a start page to an explicitly given target page (both Wikipedia articles) by only tracing hyperlinks between Wikipedia articles. Our contributions are two-fold. First, by analyzing the differences between successful and abandoned navigation paths, we aim to understand what types of behavior are indicative of users giving up their navigation task. We also investigate how users make use of back clicks during their navigation. We find that users prefer backtracking to high-degree nodes that serve as landmarks and hubs for exploring the network of pages. Second, based on our analysis, we build statistical models for predicting whether a user will finish or abandon a navigation task, and if the next action will be a back click. Being able to predict these events is important as it can potentially help us design more human-friendly browsing interfaces and retain users who would otherwise have given up navigating a website.",2014,Web Search and Data Mining,Fields of study: printer friendlybrandnavigationinternet privacymultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Combining named entities and tags for novel sentence detection,Yi Zhang (Nanyang Technological University)Flora S. Tsai (Nanyang Technological University),"2683528774,2159372297","Novel sentence detection aims at identifying novel information from an incoming stream of sentences. Our research applies named entity recognition (NER) and part-of-speech (POS) tagging on sentence-level novelty detection and proposes a mixed method to utilize these two techniques. Furthermore, we discuss the performance when setting different history sentence sets. Experimental results of different approaches on TREC'04 Novelty Track show that our new combined method outperforms some other novelty detection methods in terms of precision and recall. The experimental observations of each approach are also discussed.",2009,Web Search and Data Mining,Fields of study: part of speechnatural language processingspeech recognitionpattern recognitioncomputer science
OOLAM: an opinion oriented link analysis model for influence persona discovery,Keke Cai (IBM)Shenghua Bao (IBM)Zi Yang (Tsinghua University)Jie Tang (Tsinghua University)Rui Ma (IBM)Li Zhang (IBM)Zhong Su (IBM),"2137653166,2135877978,2136972039,2158012360,2289455761,2435248972,2305826094","Social influence is a complex and subtle force that governs the dynamics of social networks. In the past years, a lot of research work has been conducted to understand the spread patterns of social influence. However, most of approaches assume that influence exists between users with active social interactions, but ignore the question of what kind of influence happens between them. As such one interesting and also fundamental question is raised here: ""in a social network, could the social connection reflect users'influence from both positive and negative aspects?"". To this end, an Opinion Oriented Link Analysis Model (OOLAM) is proposed in this paper to characterize users' influence personae in order to exhibit their distinguishing influence ability in the social network. In particular, three types of influence personae are generalized and the problem of influence persona discovery is formally defined. Within the OOLAM model, two factors, i.e., opinion consistency and opinion creditability , are defined to capture the persona information from public opinion perspective. Extensive experimental studies have been performed to demonstrate the effectiveness of the proposed approach on influence persona analysis using real web data sets.",2011,Web Search and Data Mining,Fields of study: public opinionlink analysissocial influencesocial networksocial relationworld wide websocial sciencedata mining
Exploring structure and content on the web: extraction and integration of the semi-structured web,Tim Weninger (University of Illinois at Urbana–Champaign)Jiawei Han (University of Illinois at Urbana–Champaign),"2037649753,2121939561","In this tutorial we view the World Wide Web as a type of massive, decentralized database. At present, this ""Web database"" is presented in a manner largely devoid of any consistent meaning or schema. That is not to say that Web-data lacks an underlying organization; in fact, most Web content is generated from an underlying schema-bound, or otherwise structured database. Information extraction is generally concerned with the reconciliation of unstructured or semi-structured Web content with the neatly structured database paradigm. With this Web-database in hand, researchers and practitioners have recently begun developing mechanisms which return structured results in response to an unstructured query. These new developments are a product of (1) record, list and table extraction from large numbers of semi-structured Web pages, (2) integration of these disparate extraction results into a consistent form, and (3) analysis of the newly extracted and integrated Web data. Among the many fruits of this line of work is the ability for semi-structured Web data to enhance the search capabilities of a schema-bound database. Alternatively, structured database records have also been used to augment Web page collections typically used by Web search engines. We will cover several key technologies, and principles explored so far in the area of Web information extraction, search and exploration.",2013,Web Search and Data Mining,Fields of study: web 2 0semantic web stackweb modelingsocial semantic webdata webweb standardsweb mappingmashupweb search queryweb developmentsemi structured dataweb designweb navigationinformation integrationweb serviceweb pageweb intelligenceweb mininginformation extractionworld wide webinformation retrievaldata miningcomputer science
Comment spam detection by sequence mining,Ravi Kant (Yahoo!)Srinivasan H. Sengamedu (Yahoo!)Krishnan S. Kumar (Yahoo!),"2302013680,1823577077,2222108565","Comments are supported by several web sites to increase user participation. Users can usually comment on a variety of media types - photos, videos, news articles, blogs, etc. Comment spam is one of the biggest challenges facing this feature. The traditional approach to combat spam is to train classifiers using various machine learning techniques. Since the commonly used classifiers work on the entire comment text, it is easy to mislead them by embedding spam content in good content. In this paper, we make several contributions towards comment spam detection. (1) We propose a new framework for spam detection that is immune to embed attacks. We characterize spam by a set of frequently occurring sequential patterns. (2) We introduce a variant (called min-closed) of the frequent closed sequence mining problem that succinctly captures all the frequently occurring patterns. We prove as well as experimentally show that the set of min-closed sequences is an order of magnitude smaller than the set of closed sequences and yet has exactly the same coverage. (3) We describe MC PRISM , extension of the recently published PRISM algorithm that effectively mines min-closed sequences, using prime encoding. In the process, we solve the open problem of using the prime-encoding technique to speed up traditional closed sequence mining. (4) We finally need to whittle down the set of frequent subsequences to a small set without sacrificing coverage. This problem is NP-Hard but we show that the coverage function is submodular and hence the greedy heuristic gives a fast algorithm that is close to optimal. We then describe the experiments that were carried out on a large real world comment data and the publicly available Gazelle dataset. (1) We show that nearly 80% of spam on real world data can be effectively captured by the mined sequences at very low false positive rates. (2) The sequences mined are highly discriminative. (3) On Gazelle data, the proposed algorithmic enhancements are faster by at least by a factor and by an order of magnitude on the larger comment dataset.",2012,Web Search and Data Mining,Fields of study: sequential pattern miningfalse positive rategreedy algorithmworld wide webinformation retrievaldata miningmachine learningcomputer science
"Trust, but verify: predicting contribution quality for knowledge base construction and curation",Chun How Tan (Google)Eugene Agichtein (Emory University)Panos Ipeirotis (New York University)Evgeniy Gabrilovich (Google),"2139746272,2283615530,2176350363,1804802447","The largest publicly available knowledge repositories, such as Wikipedia and Freebase, owe their existence and growth to volunteer contributors around the globe. While the majority of contributions are correct, errors can still creep in, due to editors' carelessness, misunderstanding of the schema, malice, or even lack of accepted ground truth. If left undetected, inaccuracies often degrade the experience of users and the performance of applications that rely on these knowledge repositories. We present a new method, CQUAL, for automatically predicting the quality of contributions submitted to a knowledge base. Significantly expanding upon previous work, our method holistically exploits a variety of signals, including the user's domains of expertise as reflected in her prior contribution history, and the historical accuracy rates of different types of facts. In a large-scale human evaluation, our method exhibits precision of 91% at 80% recall. Our model verifies whether a contribution is correct immediately after it is submitted, significantly alleviating the need for post-submission human reviewing.",2014,Web Search and Data Mining,Fields of study: crowdsourcingdata scienceknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
Recurrent Recommender Networks,Chao-Yuan Wu (University of Texas at Austin)Amr Ahmed (Google)Alex Beutel (Google)Alexander J. Smola (Carnegie Mellon University)How Jing (LinkedIn),"2538604194,2259645355,2661927815,1972291593,2592724704","Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed, e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics, in addition to a more traditional low-rank factorization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function.",2017,Web Search and Data Mining,Fields of study: recurrent neural networkrecommender systemworld wide webdata miningmachine learningsimulationcomputer science
Detecting non-gaussian geographical topics in tagged photo collections,Christoph Carl KlingJérôme Kunegis (Technical University of Berlin)Sergej Sizov (University of Düsseldorf)Steffen Staab (Karlsruhe Institute of Technology),"2135862140,2232072325,2619768059,1941402522","Nowadays, large collections of photos are tagged with GPS coordinates. The modelling of such large geo-tagged corpora is an important problem in data mining and information retrieval, and involves the use of geographical information to detect topics with a spatial component. In this paper, we propose a novel geographical topic model which captures dependencies between geographical regions to support the detection of topics with complex, non-Gaussian distributed spatial structures. The model is based on a multi-Dirichlet process (MDP), a novel generalisation of the hierarchical Dirichlet process extended to support multiple base distributions. Our method thus is called the MDP-based geographical topic model (MGTM). We show how to use a MDP to dynamically smooth topic distributions between groups of spatially adjacent documents. In systematic quantitative and qualitative evaluations using independent datasets from prior related work, we show that such a model can exploit the adjacency of regions and leads to a significant improvement in the quality of topics compared to the state of the art in geographical topic modelling.",2014,Web Search and Data Mining,Fields of study: topic modelgraphical modeldata scienceinformation retrievaldata miningmachine learningcomputer science
Speeding up algorithms on compressed web graphs,Chinmay Karande (Facebook)Kumar Chellapilla (Microsoft)Reid Andersen (Microsoft),"2437772621,2010097212,2137555013","A variety of lossless compression schemes have been proposed to reduce the storage requirements of web graphs. One successful approach is virtual node compression [7], in which often-used patterns of links are replaced by links to virtual nodes, creating a compressed graph that succinctly represents the original. In this paper, we show that several important classes of web graph algorithms can be extended to run directly on virtual node compressed graphs, such that their running times depend on the size of the compressed graph rather than the original. These include algorithms for link analysis, estimating the size of vertex neighborhoods, and a variety of algorithms based on matrix-vector products and random walks. Similar speed-ups have been obtained previously for classical graph algorithms like shortest paths and maximum bipartite matching. We measure the performance of our modified algorithms on several publicly available web graph datasets, and demonstrate significant empirical speedups that nearly match the compression ratios.",2009,Web Search and Data Mining,Fields of study: factor critical graphimplicit graphfolded cube graphdistance hereditary graphvoltage graphcomplement graphgraph bandwidthgraph powercomparability graphlattice graphnull graphclique widthgraphgraph rewritingstochastic processtheoretical computer sciencemachine learningstatisticscomputer science
Multi-view Machines,Bokai Cao (University of Illinois at Chicago)Hucheng Zhou (Microsoft)Guoqiang Li (Huawei)Philip S. Yu (University of Illinois at Chicago),"2131202988,2700341554,2717444168,2125104194","With rapidly growing amount of data available on the web, it becomes increasingly likely to obtain data from different perspectives for multi-view learning. Some successive examples of web applications include recommendation and target advertising. Specifically, to predict whether a user will click an ad in a query context, there are available features extracted from user profile, ad information and query description, and each of them can only capture part of the task signals from a particular aspect/view. Different views provide complementary information to learn a practical model for these applications. Therefore, an effective integration of the multi-view information is critical to facilitate the learning performance. In this paper, we propose a general predictor, named multi-view machines (MVMs), that can effectively explore the full-order interactions between features from multiple views. A joint factorization is applied for the interaction parameters which makes parameter estimation more accurate under sparsity and renders the model with the capacity to avoid overfitting. Moreover, MVMs can work in conjunction with different loss functions for a variety of machine learning tasks. The advantages of MVMs are illustrated through comparison with other methods for multi-view prediction, including support vector machines (SVMs), support tensor machines (STMs) and factorization machines (FMs). A stochastic gradient descent method and a distributed implementation on Spark are presented to learn the MVM model. Through empirical studies on two real-world web application datasets, we demonstrate the effectiveness of MVMs on modeling feature interactions in multi-view data. A 3.51\% accuracy improvement is shown on MVMs over FMs for the problem of movie rating prediction, and 0.57\% for ad click prediction.",2016,Web Search and Data Mining,Fields of study: factorizationdata sciencedata miningmachine learningstatisticscomputer science
Back to the Past: Supporting Interpretations of Forgotten Stories by Time-aware Re-Contextualization,Nam Khanh Tran (Leibniz University of Hanover)Andrea Ceroni (Leibniz University of Hanover)Nattiya Kanhabua (Leibniz University of Hanover)Claudia Niederée (Leibniz University of Hanover),"2106148903,1994078628,2278903833,1820140241","Fully understanding an older news article requires context knowledge from the time of article creation. Finding information about such context is a tedious and time-consuming task, which distracts the reader. Simple contextualization via Wikification is not sufficient here. The retrieved context information has to be time-aware, concise (not full Wikipages) and focused on the coherence of the article topic. In this paper, we present an approach for time-aware recontextualization, which takes those requirements into account in order to improve reading experience. For this purpose, we propose (1) different query formulation methods for retrieving contextualization candidates and (2) ranking methods taking into account topical and temporal relevance as well as complementarity with respect to the original text. We evaluate our proposed approaches through extensive experiments using real-world datasets and ground-truth consisting of over 9,400 article/context pairs. To this end, our experimental results show that our approaches retrieve contextualization information for older articles from the New York Times Archive with high precision and outperform baselines significantly.",2015,Web Search and Data Mining,Fields of study: newscomplementarityinterpretationworld wide webinformation retrievaldata miningcomputer science
Optimized top-k processing with global page scores on block-max indexes,Dongdong Shan (Peking University)Shuai Ding (Polytechnic Institute of New York University)Jing He (Peking University)Hongfei Yan (Peking University)Xiaoming Li (Peking University),"2112634141,2700792776,2617871696,2096609276,2633873560","Large web search engines are facing formidable performance challenges because they have to process thousands of queries per second on tens of billions of documents, within interactive response time. Among many others, Top-k query processing (also called early termination or dynamic pruning) is an important class of optimization techniques that can improve the search efficiency and achieve faster query processing by avoiding the scoring of documents that are unlikely to be in the top results. One recent technique is using Block-Max index. In the Block-Max index, the posting lists are organized as blocks and the maximum score for each block is stored to improve the query efficiency. Although query processing speedup is achieved with Block-Max index, the ranking function for the Top-k results is the term-based approach. It is well known that documents' static scores are also important for a good ranking function. In this paper, we show that the performance of the state-of-the-art algorithms with the Block-Max index is degraded when the static score is added in the ranking function. Then we study efficient techniques for Top-k query processing in the case where a page's static score is given, such as PageRank, in addition to the term-based approach. In particular, we propose a set of new algorithms based on the WAND and MaxScore with Block-Max index using local score, which outperform the existing ones. Then we propose new techniques to estimate a better score upper bound for each block. We also study the search efficiency on different index structures where the document identifiers are assigned by URL sorting or by static document scores. Experiments on TREC GOV2 and ClueWeb09B show that considerable performance gains are achieved.",2012,Web Search and Data Mining,Fields of study: sargablerankingrange queryweb query classificationinverted indexquery expansionquery optimizationupper and lower boundsweb search engineworld wide webinformation retrievaldata miningdatabasecomputer science
Top- k aggregation using intersections of ranked inputs,Ravi Kumar (Yahoo!)Kunal Punera (Yahoo!)Torsten Suel (Yahoo!)Sergei Vassilvitskii (Yahoo!),"2232709231,2343758766,702140476,2156675704","There has been considerable past work on efficiently computing top k objects by aggregating information from multiple ranked lists of these objects. An important instance of this problem is query processing in search engines: One has to combine information from several different posting lists (rankings) of web pages (objects) to obtain the top k web pages to answer user queries. Two particularly well-studied approaches to achieve efficiency in top- k aggregation include early-termination algorithms (e.g., TA and NRA) and preaggregation of some of the input lists. However, there has been little work on a rigorous treatment of combining these approaches. We generalize the TA and NRA algorithms to the case when preaggregated intersection lists are available in addition to the original lists. We show that our versions of TA and NRA continue to remain ""instance optimal,"" a very strong optimality notion that is a highlight of the original TA and NRA algorithms. Using an index of millions of web pages and real-world search engine queries, we empirically characterize the performance gains offered by our new algorithms. We show that the practical benefits of intersection lists can be fully realized only with an early-termination algorithm.",2009,Web Search and Data Mining,Fields of study: web pagesearch engineworld wide webinformation retrievaldata miningdatabasecomputer science
Barbara Made the News: Mining the Behavior of Crowds for Time-Aware Learning to Rank,Flávio Martins (Universidade Nova de Lisboa)João Magalhães (Universidade Nova de Lisboa)Jamie Callan (Carnegie Mellon University),"2296538460,2132348484,2148123616","In Twitter, and other microblogging services, the generation of new content by the crowd is often biased towards immediacy: what is happening now. Prompted by the propagation of commentary and information through multiple mediums, users on the Web interact with and produce new posts about newsworthy topics and give rise to trending topics. This paper proposes to leverage on the behavioral dynamics of users to estimate the most relevant time periods for a topic. Our hypothesis stems from the fact that when a real-world event occurs it usually has peak times on the Web: a higher volume of tweets, new visits and edits to related Wikipedia articles, and news published about the event. In this paper, we propose a novel time-aware ranking model that leverages on multiple sources of crowd signals. Our approach builds on two major novelties. First, a unifying approach that given query q, mines and represents temporal evidence from multiple sources of crowd signals. This allows us to predict the temporal relevance of documents for query q. Second, a principled retrieval model that integrates temporal signals in a learning to rank framework, to rank results according to the predicted temporal relevance. Evaluation on the TREC 2013 and 2014 Microblog track datasets demonstrates that the proposed model achieves a relative improvement of 13.2% over lexical retrieval models and 6.2% over a learning to rank baseline.",2016,Web Search and Data Mining,Fields of study: rankingsocial medialearning to rankworld wide webinformation retrievaldata miningmachine learningcomputer science
Constructing and Embedding Abstract Event Causality Networks from Text Snippets,Sendong Zhao (Harbin Institute of Technology)Quan Wang (Chinese Academy of Sciences)Sean Massung (University of Illinois at Urbana–Champaign)Bing Qin (Harbin Institute of Technology)Ting Liu (Harbin Institute of Technology)Bin Wang (Chinese Academy of Sciences)ChengXiang Zhai (University of Illinois at Urbana–Champaign),"2107290083,2652197308,284929341,2714865119,2659255845,2716215576,2152766206","In this paper, we formally define the problem of representing and leveraging abstract event causality to power downstream applications. We propose a novel solution to this problem, which build an abstract causality network and embed the causality network into a continuous vector space. The abstract causality network is generalized from a specific one, with abstract event nodes represented by frequently co-occurring word pairs. To perform the embedding task, we design a dual cause-effect transition model. Therefore, the proposed method can obtain general, frequent, and simple causality patterns, meanwhile, simplify event matching. Given the causality network and the learned embeddings, our model can be applied to a wide range of applications such as event prediction, event clustering and stock market movement prediction. Experimental results demonstrate that 1) the abstract causality network is effective for discovering high-level causality rules behind specific causal events; 2) the embedding models perform better than state-of-the-art link prediction techniques in predicting events; and 3) the event causality embedding is an easy-to-use and sophisticated feature for downstream applications such as stock market movement prediction.",2017,Web Search and Data Mining,Fields of study: causalitytheoretical computer sciencedata miningmachine learning
Link Prediction with Cardinality Constraint,Jiawei Zhang (University of Illinois at Chicago)Jianhui Chen (Yahoo!)Junxing Zhu (National University of Defense Technology)Yi Chang (Huawei)Philip S. Yu (University of Illinois at Chicago),"2305185572,2641700479,2127287138,2168000538,2125104194","Inferring the links among entities in networks is an important research problem for various disciplines. Depending on the specific application settings, the links to be inferred are usually subject to different cardinality constraints, like one-to-one, one-to-many and many-to-many. However, most existing research works on link prediction problems fail to consider such a kind of constraint. In this paper, we propose to study the link prediction problem with general cardinality constraints, which is formally defined as the CLP (Cardinality Constrained Link Prediction) problem. By minimizing the projection loss of links from feature vectors to labels, the CLP problem is formulated as an optimization problem involving multiple variables, where the cardinality constraints are modeled as mathematical constraints on node degrees. The objective function is shown to be not jointly convex and the optimal solution subject to the cardinality constraints can be very time-consuming to achieve. To solve the optimization problem, an iterative variable updating based link prediction framework ITERCLIPS (Iterative Constrained Link Prediction & Selection) is introduced in this paper, which involves the steps on link updating and selection alternatively. To overcome the high time cost problem, a greedy link selection step is introduced in this paper, which picks links greedily while preserving the link cardinality constraints simultaneously. Meanwhile, to ensure the effectiveness of ITERCLIPS on large-scale networks, a distributed implementation of ITERCLIPS is further presented as a scalable solution to the CLP problem. Extensive experiments have been done on three real-world network datasets with different types of cardinality constraints, and the experimental results achieved by ITERCLIPS on all these datasets can demonstrate the effectiveness and advantages of ITERCLIPS in solving the CLP problem.",2017,Web Search and Data Mining,Fields of study: data miningmachine learningmathematical optimizationcomputer science
Relationship Queries on Extended Knowledge Graphs,Mohamed Yahya (Max Planck Society)Denilson Barbosa (University of Alberta)Klaus Berberich (Max Planck Society)Qiuyue Wang (Renmin University of China)Gerhard Weikum (Max Planck Society),"2162700791,2117262728,2064029816,2658203450,514836396","Entity search over text corpora is not geared for relationship queries where answers are tuples of related entities and where a query often requires joining cues from multiple documents. With large knowledge graphs, structured querying on their relational facts is an alternative, but often suffers from poor recall because of mismatches between user queries and the knowledge graph or because of weakly populated relations. This paper presents the TriniT search engine for querying and ranking on extended knowledge graphs that combine relational facts with textual web contents. Our query language is designed on the paradigm of SPO triple patterns, but is more expressive, supporting textual phrases for each of the SPO arguments. We present a model for automatic query relaxation to compensate for mismatches between the data and a user's query. Query answers -- tuples of entities -- are ranked by a statistical language model. We present experiments with different benchmarks, including complex relationship queries, over a combination of the Yago knowledge graph and the entity-annotated ClueWeb'09 corpus.",2016,Web Search and Data Mining,Fields of study: sargablerange queryboolean conjunctive queryweb search queryweb query classificationspatial queryquery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningdatabasecomputer science
Search and exploration of X-Rated information (SEXI 2013),Vanessa Murdock (Yahoo!)Charles L.A. Clarke (University of Waterloo)Jaap Kamps (University of Amsterdam)Jussi Karlgren (Swedish Institute of Computer Science),"1858435594,2098618034,2088944921,2629262436","Adult content is pervasive on the Web, has been a driving factor in the adoption of the Internet medium. It is responsible for a significant fraction of traffic and revenues, yet rarely attracts attention in research. We propose that the research questions surrounding adult content access behaviors are unique, and we believe interesting and valuable research in this area can be done ethically. The workshop on Search and Exploration of X-Rated Information (SEXI) addresses these issues for information access tasks related to adult content.",2013,Web Search and Data Mining,Fields of study: multimediaworld wide webdata mining
Multidimensional mining of large-scale search logs: a topic-concept cube approach,Dongyeop Kang (KAIST)Daxin Jiang (Microsoft)Jian Pei (Simon Fraser University)Zhen Liao (Nankai University)Xiaohui Sun (Microsoft)Ho-Jin Choi (KAIST),"2160241336,2123654898,2126330539,2150519155,2496682552,2705154414","In addition to search queries and the corresponding clickthrough information, search engine logs record multidimensional information about user search activities, such as search time, location, vertical, and search device. Multidimensional mining of search logs can provide novel insights and useful knowledge for both search engine users and developers. In this paper, we describe our topic-concept cube project, which addresses the business need of supporting multidimensional mining of search logs effectively and efficiently. We answer two challenges. First, search queries and click-through data are well recognized sparse, and thus have to be aggregated properly for effective analysis. Second, there is often a gap between the topic hierarchies in multidimensional aggregate analysis and queries in search logs. To address those challenges, we develop a novel topic-concept model that learns a hierarchy of concepts and topics automatically from search logs. Enabled by the topicconcept model, we construct a topic-concept cube that supports online multidimensional mining of search log data. A distinct feature of our approach is that, in addition to the standard dimensions such as time and location, our topic-concept cube has a dimension of topics and concepts, which substantially facilitates the analysis of log data. To handle a huge amount of log data, we develop distributed algorithms for learning model parameters efficiently. We also devise approaches to computing a topic-concept cube. We report an empirical study verifying the effectiveness and efficiency of our approach on a real data set of 1.96 billion queries and 2.73 billion clicks.",2011,Web Search and Data Mining,Fields of study: search analyticsincremental heuristic searchbeam searchonline analytical processingsearch engineempirical researchsemantic searchdistributed algorithmdata scienceworld wide webinformation retrievaldata miningcomputer science
"Entity linking at the tail: sparse signals, unknown entities, and phrase models",Yuzhe Jin (Microsoft)Emre Kıcıman (Microsoft)Kuansan Wang (Microsoft)Ricky Loynd (Microsoft),"2676906140,1994052019,2127379895,2075524279","Web search is seeing a paradigm shift from keyword based search to an entity-centric organization of web data. To support web search with this deeper level of understanding, a web-scale entity linking system must have 3 key properties: First, its feature extraction must be robust to the diversity of web documents and their varied writing styles and content structures. Second, it must maintain high-precision linking for ""tail"" (unpopular) entities that is robust to the existence of confounding entities outside of the knowledge base and entity profiles with minimal information. Finally, the system must represent large-scale knowledge bases with a scalable and powerful feature representation. We have built and deployed a web-scale unsupervised entity linking system for a commercial search engine that addresses these requirements by combining new developments in sparse signal recovery to identify the most discriminative features from noisy, free-text web documents; explicit modeling of out-of-knowledge-base entities to improve precision at the tail; and the development of a new phrase-unigram language model to efficiently capture high-order dependencies in lexical features. Using a knowledge base of 100M unique people from a popular social networking site, we present experimental results in the challenging domain of people-linking at the tail, where most entities have limited web presence. Our experimental results show that this system substantially improves on the precision-recall tradeoff over baseline methods, achieving precision over 95% with recall over 60%.",2014,Web Search and Data Mining,Fields of study: weak entitysparsity of effects principleworld wide webinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
DiSMEC: Distributed Sparse Machines for Extreme Multi-label Classification,Rohit Babbar (Max Planck Society)Bernhard Schölkopf (Max Planck Society),"2717257300,297432538","Extreme multi-label classification refers to supervised multi-label learning involving hundreds of thousands or even millions of labels. Datasets in extreme classification exhibit fit to power-law distribution, i.e. a large fraction of labels have very few positive instances in the data distribution. Most state-of-the-art approaches for extreme multi-label classification attempt to capture correlation among labels by embedding the label matrix to a low-dimensional linear sub-space. However, in the presence of power-law distributed extremely large and diverse label spaces, structural assumptions such as low rank can be easily violated. In this work, we present DiSMEC, which is a large-scale distributed framework for learning one-versus-rest linear classifiers coupled with explicit capacity control to control model size. Unlike most state-of-the-art methods, DiSMEC does not make any low rank assumptions on the label matrix. Using double layer of parallelization, DiSMEC can learn classifiers for datasets consisting hundreds of thousands labels within few hours. The explicit capacity control mechanism filters out spurious parameters which keep the model compact in size, without losing prediction accuracy. We conduct extensive empirical evaluation on publicly available real-world datasets consisting upto 670,000 labels. We compare DiSMEC with recent state-of-the-art approaches, including - SLEEC which is a leading approach for learning sparse local embeddings, and FastXML which is a tree-based approach optimizing ranking based loss function. On some of the datasets, DiSMEC can significantly boost prediction accuracies - 10% better compared to SLECC and 15% better compared to FastXML, in absolute terms.",2017,Web Search and Data Mining,Fields of study: data miningpattern recognitionmachine learningstatisticsmathematics
An efficient framework for online advertising effectiveness measurement and comparison,Pengyuan Wang (Yahoo!)Yechao Liu (Yahoo!)Marsha Meytlis (Yahoo!)Han-Yun Tsao (Yahoo!)Jian Yang (Yahoo!)Pei Huang (Yahoo!),"2157416250,2680656046,662370049,2658353285,2550117728,2229338874","In online advertising market it is crucial to provide advertisers with a reliable measurement of advertising effectiveness to make better marketing campaign planning. The basic idea for ad effectiveness measurement is to compare the performance (e.g., success rate) among users who were and who were not exposed to a certain treatment of ads. When a randomized experiment is not available, a naive comparison can be biased because exposed and unexposed populations typically have different features. One solid methodology for a fair comparison is to apply inverse propensity weighting with doubly robust estimation to the observational data. However the existing methods were not designed for the online advertising campaign, which usually suffers from huge volume of users, high dimensionality, high sparsity and imbalance. We propose an efficient framework to address these challenges in a real campaign circumstance. We utilize gradient boosting stumps for feature selection and gradient boosting trees for model fitting, and propose a subsampling-and-backscaling procedure that enables analysis on extremely sparse conversion data. The choice of features, models and feature selection scheme are validated with irrelevant conversion test. We further propose a parallel computing strategy, combined with the subsampling-and-backscaling procedure to reach computational efficiency. Our framework is applied to an online campaign involving millions of unique users, which shows substantially better model fitting and efficiency. Our framework can be further generalized to comparison of multiple treatments and more general treatment regimes, as sketched in the paper. Our framework is not limited to online advertising, but also applicable to other circumstances (e.g., social science) where a 'fair' comparison is needed with observational data.",2014,Web Search and Data Mining,Fields of study: causal inferencepropensity score matchingfeature selectionworld wide webdata miningmachine learningsimulationstatisticscomputer science
Cross-modality Consistent Regression for Joint Visual-Textual Sentiment Analysis of Social Multimedia,Quanzeng You (University of Rochester)Jiebo Luo (University of Rochester)Hailin Jin (Adobe Systems)Jianchao Yang (Adobe Systems),"2112374298,2059910451,2139630916,2121082737","Sentiment analysis of online user generated content is important for many social media analytics tasks. Researchers have largely relied on textual sentiment analysis to develop systems to predict political elections, measure economic indicators, and so on. Recently, social media users are increasingly using additional images and videos to express their opinions and share their experiences. Sentiment analysis of such large-scale textual and visual content can help better extract user sentiments toward events or topics. Motivated by the needs to leverage large-scale social multimedia content for sentiment analysis, we propose a cross-modality consistent regression (CCR) model, which is able to utilize both the state-of-the-art visual and textual sentiment analysis techniques. We first fine-tune a convolutional neural network (CNN) for image sentiment analysis and train a paragraph vector model for textual sentiment analysis. On top of them, we train our multi-modality regression model. We use sentimental queries to obtain half a million training samples from Getty Images. We have conducted extensive experiments on both machine weakly labeled and manually labeled image tweets. The results show that the proposed model can achieve better performance than the state-of-the-art textual and visual sentiment analysis algorithms alone.",2016,Web Search and Data Mining,Fields of study: sentiment analysismultimediaworld wide webdata miningcomputer science
User modeling in search logs via a nonparametric bayesian approach,Hongning Wang (University of Illinois at Urbana–Champaign)ChengXiang Zhai (University of Illinois at Urbana–Champaign)Feng Liang (University of Illinois at Urbana–Champaign)Anlei Dong (Yahoo!)Yi Chang (Yahoo!),"2157880984,2152766206,2641064211,2102564942,2168000538","Searchers' information needs are diverse and cover a broad range of topics; hence, it is important for search engines to accurately understand each individual user's search intents in order to provide optimal search results. Search log data, which records users' search behaviors when interacting with search engines, provides a valuable source of information about users' search intents. Therefore, properly characterizing the heterogeneity among the users' observed search behaviors is the key to accurately understanding their search intents and to further predicting their behaviors. In this work, we study the problem of user modeling in the search log data and propose a generative model, dpRank, within a non-parametric Bayesian framework. By postulating generative assumptions about a user's search behaviors, dpRank identifies each individual user's latent search interests and his/her distinct result preferences in a joint manner. Experimental results on a large-scale news search log data set validate the effectiveness of the proposed approach, which not only provides in-depth understanding of a user's search intents but also benefits a variety of personalized applications.",2014,Web Search and Data Mining,Fields of study: search analyticsuser modelingsearch enginesemantic searchdata scienceworld wide webdata miningmachine learningcomputer science
"Answers, not links: extracting tips from yahoo! answers to address how-to web queries",Ingmar Weber (Yahoo!)Antti Ukkonen (Yahoo!)Aristides Gionis (Yahoo!),"2074066684,2635975366,737311942","We investigate the problem of mining ""tips"" from Yahoo! Answers and displaying those tips in response to related web queries. Here, a ""tip"" is a short, concrete and self-contained bit of non-obvious advice such as ""To zest a lime if you don't have a zester : use a cheese grater."" First, we estimate the volume of web queries with ""how-to"" intent, which could be potentially addressed by a tip. Second, we analyze how to detect such queries automatically without solely relying on literal ""how to *"" patterns. Third, we describe how to derive potential tips automatically from Yahoo! Answers, and we develop machine-learning techniques to remove low-quality tips. Finally, we discuss how to match web queries with ""how-to"" intent to tips. We evaluate both the quality of these direct displays as well as the size of the query volume that can be addressed by serving tips.",2012,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningmachine learningcomputer science
Enterprise Employee Training via Project Team Formation,Jiawei Zhang (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago)Yuanhua Lv (Microsoft),"2305185572,2125104194,2132538679","Professional career training for novice employees at elementary levels to help them master necessary working skills is critical for both achieving employees' professional success and enhancing the enterprise growth. Besides adopting professional services from external career training agencies, companies can actually train the employees more effectively by involving them in various internal projects carried out in the companies. In this paper, we will study the ""Employee Training"" (ET) problem by assigning the employees to various concrete company internal projects. From the company perspective, besides training the employees, another important objective of carrying out these projects is to finish them successfully. The successful accomplishment of projects depends on various issues, like the skill qualification of the built teams and the effective collaboration among the team members. To achieve these two objectives simultaneously, a novel framework named ""Team foRmAtion based employee traINing"" (TRAIN) is proposed in this paper. TRAIN formulates the ET problem as a joint optimization problem, where the objective function considers the employees' overall skill gain and the team internal communication costs at the same time. To ensure the success of the projects, a new team skill qualification constraint is proposed and added to the optimization problem. Extensive experiments conducted on the real-world enterprise employee project team dataset demonstrate the effectiveness of TRAIN in addressing the problem.",2017,Web Search and Data Mining,Fields of study: knowledge managementcomputer science
Discovering common motifs in cursor movement data for improving web search,Dmitry Lagun (Emory University)Mikhail Ageev (Moscow State University)Qi Guo (Microsoft)Eugene Agichtein (Emory University),"826397576,2030298875,2569180702,2283615530","Web search behavior and interaction data, such as mouse cursor movements, can provide valuable information on how searchers examine and engage with the web search results. This interaction data is far richer than traditional search click data, and can be used to improve search ranking, evaluation, and presentation. Unfortunately, the diversity and complexity inherent in this interaction data make it more difficult to capture salient behavior characteristics through traditional feature engineering. To address this problem, we introduce a novel approach of automatically discovering frequent subsequences, or motifs, in mouse cursor movement data. In order to scale our approach to realistic datasets, we introduce novel optimizations for motif discovery, specifically designed for mining cursor movement data. As a practical application, we show that by encoding the motifs discovered from thousands of real web search sessions as features, enables significant improvements on result relevance estimation and re-ranking tasks, compared to a state-of-the-art baseline that relies on extensive feature engineering. These results, complemented with visualization and qualitative analysis, demonstrate that our approach is able to automatically capture key characteristics of mouse cursor movement behavior, providing a valuable new tool for search behavior analysis.",2014,Web Search and Data Mining,Fields of study: world wide webbioinformaticsdata miningmachine learningcomputer science
"""I loan because..."": understanding motivations for pro-social lending",Yang Liu (University of Michigan)Roy Chen (University of Michigan)Yan Chen (University of Michigan)Qiaozhu Mei (University of Michigan)Suzy Salib (University of Michigan),"2640269351,2123992474,2168098082,2166036605,2230405766","As a new paradigm of online communities, microfinance sites such as Kiva.org have attracted much public attention. To understand lender motivations on Kiva, we classify the lenders' self-stated motivations into ten categories with human coders and machine learning based classifiers. We employ text classifiers using lexical features, along with social features based on lender activity information on Kiva, to predict the categories of lender motivation statements. Although the task appears to be much more challenging than traditional topic-based categorization, our classifiers can achieve high precision in most categories. Using the results of this classification along with Kiva teams information, we predict lending activity from lender motivation and team affiliations. Finally, we make design recommendations regarding Kiva practices which might increase pro-social lending.",2012,Web Search and Data Mining,Fields of study: microfinancemachine learningcomputer science
Improving social bookmark search using personalised latent variable language models,Morgan Harvey (University of Strathclyde)Ian Ruthven (University of Strathclyde)Mark James Carman (University of Lugano),"2109966068,2629636978,2123487663","Social tagging systems have recently become very popular as a method of categorising information online and have been used to annotate a wide range of different resources. In such systems users are free to choose whatever keywords or ""tags"" they wish to annotate each resource, resulting in a highly personalised, unrestricted vocabulary. While this freedom of choice has several notable advantages, it does come at the cost of making searching of these systems more difficult as the vocabulary problem introduced is more pronounced than in a normal information retrieval setting. In this paper we propose to use hidden topic models as a principled way of reducing the dimensionality of this data to provide more accurate resource rankings with higher recall. We first describe Latent Dirichlet Allocation (LDA), a simple topic model and then introduce 2 extended models which can be used to personalise the results by including information about the user who made each annotation. We test these 3 models and compare them with 3 non-topic model baselines on a large data sample obtained from the Delicious social bookmarking site. Our evaluations show that our methods significantly outperform all of the baselines with the personalised models also improving significantly upon unpersonalised LDA.",2011,Web Search and Data Mining,Fields of study: topic modellatent dirichlet allocationlatent variablelanguage modelworld wide webinformation retrievaldata miningmachine learningcomputer science
Measuring the reusability of test collections,Ben Carterette (University of Delaware)Evgeniy Gabrilovich (Yahoo!)Vanja Josifovski (Yahoo!)Donald Metzler (Yahoo!),"2645247999,1804802447,344688379,2151486164","While test collection construction is a time-consuming and expensive process, the true cost is amortized by reusing the collection over hundreds or thousands of experiments. Some of these experiments may involve systems that retrieve documents not judged during the initial construction phase, and some of these systems may be ""hard"" to evaluate: depending on which judgments are missing and which judged documents were retrieved, the experimenter's confidence in an evaluation could potentially be very low. We propose two methods for quantifying the reusability of a test collection for evaluating new systems. The proposed methods provide simple yet highly effective tests for determining whether an existing set of judgments is useful for evaluating a new system. Empirical evaluations using TREC datasets confirm the usefulness of our proposed reusability measures. In particular, we show that our methods can reliably estimate confidence intervals that are indicative of collection reusability.",2010,Web Search and Data Mining,Fields of study: reusabilityconfidence intervalevaluationdata miningdatabasecomputer science
S-HOT: Scalable High-Order Tucker Decomposition,"Jinoh Oh (Pohang University of Science and Technology)Kijung Shin (Carnegie Mellon University)Evangelos E. Papalexakis (University of California, Riverside)Christos Faloutsos (Carnegie Mellon University)Hwanjo Yu (Pohang University of Science and Technology)","2164587646,2226806500,1418764031,2198983026,2641944078","Multi-aspect data appear frequently in many web-related applications. For example, product reviews are quadruplets of (user, product, keyword, timestamp). How can we analyze such web-scale multi-aspect data? Can we analyze them on an off-the-shelf workstation with limited amount of memory? Tucker decomposition has been widely used for discovering patterns in relationships among entities in multi-aspect data, naturally expressed as high-order tensors. However, existing algorithms for Tucker decomposition have limited scalability, and especially, fail to decompose high-order tensors since they explicitly materialize intermediate data, whose size rapidly grows as the order increases (≥ 4). We call this problem M-Bottleneck (""Materialization Bottleneck""). To avoid M-Bottleneck, we propose S-HOT, a scalable high-order tucker decomposition method that employs the on-the-fly computation to minimize the materialized intermediate data. Moreover, S-HOT is designed for handling disk-resident tensors, too large to fit in memory, without loading them all in memory at once. We provide theoretical analysis on the amount of memory space and the number of scans of data required by S-HOT. In our experiments, S-HOT showed better scalability not only with the order but also with the dimensionality and the rank than baseline methods. In particular, S-HOT decomposed tensors 1000× larger than baseline methods in terms dimensionality. S- HOT also successfully analyzed real-world tensors that are both large-scale and high-order on an off-the-shelf workstation with limited amount of memory, while baseline methods failed. The source code of S-HOT is publicly available at http://dm.postech.ac.kr/shot to encourage reproducibility.",2017,Web Search and Data Mining,Fields of study: semantic searchtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Online selection of diverse results,Debmalya Panigrahi (Duke University)Atish Das Sarma (Google)Gagan Aggarwal (Google)Andrew Tomkins (Google),"2138771547,2266878914,2140110832,2535415812","The phenomenal growth in the volume of easily accessible information via various web-based services has made it essential for service providers to provide users with personalized representative summaries of such information. Further, online commercial services including social networking and micro-blogging websites, e-commerce portals, leisure and entertainment websites, etc. recommend interesting content to users that is simultaneously diverse on many different axes such as topic, geographic specificity, etc. The key algorithmic question in all these applications is the generation of a succinct, representative, and relevant summary from a large stream of data coming from a variety of sources. In this paper, we formally model this optimization problem, identify its key structural characteristics, and use these observations to design an extremely scalable and efficient algorithm. We analyze the algorithm using theoretical techniques to show that it always produces a nearly optimal solution. In addition, we perform large-scale experiments on both real-world and synthetically generated datasets, which confirm that our algorithm performs even better than its analytical guarantees in practice, and also outperforms other candidate algorithms for the problem by a wide margin.",2012,Web Search and Data Mining,Fields of study: online algorithmservice providersocial networkoptimization probleme commerceworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
SimApp: A Framework for Detecting Similar Mobile Applications by Online Kernel Learning,Ning Chen (Nanyang Technological University)Steven C.H. Hoi (Singapore Management University)Shaohua Li (Nanyang Technological University)Xiaokui Xiao (Nanyang Technological University),"2719510244,108406206,2647733229,2157867657","With the popularity of smart phones and mobile devices, the number of mobile applications (a.k.a. ""apps"") has been growing rapidly. Detecting semantically similar apps from a large pool of apps is a basic and important problem, as it is beneficial for various applications, such as app recommendation, app search, etc. However, there is no systematic and comprehensive work so far that focuses on addressing this problem. In order to fill this gap, in this paper, we explore multi-modal heterogeneous data in app markets (e.g., description text, images, user reviews, etc.), and present ""SimApp"" -- a novel framework for detecting similar apps using machine learning. Specifically, it consists of two stages: (i) a variety of kernel functions are constructed to measure app similarity for each modality of data; and (ii) an online kernel learning algorithm is proposed to learn the optimal combination of similarity functions of multiple modalities. We conduct an extensive set of experiments on a real-world dataset crawled from Google Play to evaluate SimApp, from which the encouraging results demonstrate that SimApp is effective and promising.",2015,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningmachine learningcomputer science
Learning to Recommend Related Entities to Search Users,"Bin Bi (University of California, Los Angeles)Hao Ma (Microsoft)Bo-June Paul Hsu (Microsoft)Wei Chu (Microsoft)Kuansan Wang (Microsoft)Junghoo Cho (University of California, Los Angeles)","2139260861,2656995071,2130892346,2467733054,2127379895,2167033418","Over the past few years, major web search engines have introduced knowledge bases to offer popular facts about people, places, and things on the entity pane next to regular search results. In addition to information about the entity searched by the user, the entity pane often provides a ranked list of related entities. To keep users engaged, it is important to develop a recommendation model that tailors the related entities to individual user interests. We propose a probabilistic Three-way Entity Model (TEM) that provides personalized recommendation of related entities using three data sources: knowledge base, search click log, and entity pane log. Specifically, TEM is capable of extracting hidden structures and capturing underlying correlations among users, main entities, and related entities. Moreover, the TEM model can also exploit the click signals derived from the entity pane log. We further provide an inference technique to learn the parameters in TEM, and propose a principled preference learning method specifically designed for ranking related entities. Extensive experiments with two real-world datasets show that TEM with our probabilistic framework significantly outperforms a state of the art baseline, confirming the effectiveness of TEM and our probabilistic framework in related entity recommendation.",2015,Web Search and Data Mining,Fields of study: weak entityrecommender systeminternet privacyworld wide webinformation retrievaldata miningmachine learningcomputer science
Enhanced email spam filtering through combining similarity graphs,Anirban Dasgupta (Yahoo!)Maxim Gurevich (Yahoo!)Kunal Punera (Yahoo!),"2138105752,2027890328,2343758766","Over the last decade Email Spam has evolved from being just an irritant to users to being truly dangerous. This has led web-mail providers and academic researchers to dedicate considerable resources towards tackling this problem [9, 21, 22, 24, 26]. However, we argue that some aspects of the spam filtering problem are not handled appropriately in existing work. Principal among these are adversarial spammer efforts -- spammers routinely tune their spam emails to bypass spam-filters, and contaminate ground truth via fake HAM/SPAM votes -- and the scale and sparsity of the problem, which essentially precludes learning with a very large set of parameters. In this paper we propose an approach that learns to filter spam by striking a balance between generalizing HAM/SPAM votes across users and emails (to alleviate sparsity) and learning local models for each user (to limit effect of adversarial votes); votes are shared only amongst users and emails that are ""similar"" to one another. Moreover, we define user-user and email-email similarities using spam-resilient features that are extremely difficult for spammers to fake. We give a methodology that learns to combine multiple features into similarity values while directly optimizing the objective of better spam filtering. A useful side effect of this methodology is that the number of parameters that need to be estimated is very small: this helps us use off-the-shelf learning algorithms to achieve good accuracy while preventing over-training to the adversarial noise in the data. Finally, our approach gives a systematic way to incorporate existing spam-fighting technologies such as IP blacklists, keyword based classifiers, etc into one framework. Experiments on a real-world email dataset show that our approach leads to significant improvements compared to two state-of-the-art baselines.",2011,Web Search and Data Mining,Fields of study: spambotadversarial information retrievalbag of words modelpersonalizationcollaborative filteringground truthside effectsearch engine indexinginternet privacyworld wide webinformation retrievaldata miningmachine learningcomputer science
Large-scale hierarchical text classification without labelled data,Viet Ha-Thuc (University of Iowa)Jean-Michel Renders (Xerox),"268511090,2097538086","The traditional machine learning approaches for text classification often require labelled data for learning classifiers. However, when applied to large-scale classification involving thousands of categories, creating such labelled data is extremely expensive since typically the data is manually labelled by humans. Motivated by this, we propose a novel approach for large-scale hierarchical text classification which does not require any labelled data. We explore a perspective where the meaning of a category is not defined by human-labelled documents, but by its description and more importantly its relationships with other categories (e.g. its ascendants and descendants). Specifically, we take advantage of the ontological knowledge in all phases of the whole process, namely when retrieving pseudo-labelled documents, when iteratively training the category models and when categorizing test documents. Our experiments based on a taxonomy containing 1131 categories and widely adopted in the news industry as a standard for the NewsML framework demonstrate the effectiveness of our approach in these phases both qualitatively and quantitatively. In particular, we emphasize that just by taking the simple ontological knowledge defined in the category hierarchy, we could automatically build a large-scale hierarchical classifier with reasonable performance of 67% in terms of the hierarchy-based F-1 measure.",2011,Web Search and Data Mining,Fields of study: one class classificationtopic modellibrary classificationinformation retrievaldata miningpattern recognitionmachine learningcomputer science
WorkerRank: Using Employer Implicit Judgements to Infer Worker Reputation,"Maria Daltayanni (University of California, Santa Cruz)Luca de Alfaro (University of California, Santa Cruz)Panagiotis Papadimitriou (Stanford University)","229371862,2129359981,2027183093","In online labor marketplaces two parties are involved; employers and workers. An employer posts a job in the marketplace to receive applications from interested workers. After evaluating the match to the job, the employer hires one (or more workers) to accomplish the job via an online contract. At the end of the contract, the employer can provide his worker with some rating that becomes visible in the worker online profile. This form of explicit feedback guides future hiring decisions, since it is indicative of worker true ability. In this paper, first we discuss some of the shortcomings of the existing reputation systems that are based on the end-of-contract ratings. Then we propose a new reputation mechanism that uses Bayesian updates to combine employer implicit feedback signals in a link-analysis approach. The new system addresses the shortcomings of existing approaches, while yielding better signal for the worker quality towards hiring decision.",2015,Web Search and Data Mining,Fields of study: crowdsourcinglink analysisknowledge managementstatisticscomputer science
Finding the right consumer: optimizing for conversion in display advertising campaigns,Yandong Liu (Carnegie Mellon University)Sandeep Pandey (Yahoo!)Deepak Agarwal (Yahoo!)Vanja Josifovski (Yahoo!),"2309858515,2137133237,2591515730,344688379","The ultimate goal of advertisers are conversions representing desired user actions on the advertisers' websites in the form of purchases and product information request. In this paper we address the problem of finding the right audience for display campaigns by finding the users that are most likely to convert. This challenging problem is at the heart of display campaign optimization and has to deal with several issues such as very small percentage of converters in the general population, high-dimensional representation of the user profiles, large churning rate of users and advertisers. To overcome these difficulties, in our approach we use two sources of information: a seed set of users that have converted for a campaign in the past; and a description of the campaign based on the advertiser's website. We explore the importance of the information provided by each of these two sources in a principled manner and then combine them to propose models for predicting converters. In particular, we show how seed set can be used to capture the campaign-specific targeting constraints, while the campaign metadata allows to share targeting knowledge across campaigns. We give methods for learning these models and perform experiments on real-world advertising campaigns. Our findings show that the seed set and the campaign metadata are complimentary to each other and both sources provide valuable information for conversion optimization.",2012,Web Search and Data Mining,Fields of study: share of voicesystems modelingworld wide webdata mining
Batch query processing for web search engines,Shuai Ding (Polytechnic Institute of New York University)Josh Attenberg (Polytechnic Institute of New York University)Ricardo A. Baeza-Yates (Yahoo!)Torsten Suel (Polytechnic Institute of New York University),"2097420345,2065581641,528588921,702140476","Large web search engines are now processing billions of queries per day. Most of these queries are interactive in nature, requiring a response in fractions of a second. However, there are also a number of important scenarios where large batches of queries are submitted for various web mining and system optimization tasks that do not require an immediate response. Given the significant cost of executing search queries over billions of web pages, it is a natural question to ask if such batches of queries can be more efficiently executed than interactive queries. In this paper, we motivate and discuss the problem of batch query processing in search engines, identify basic mechanisms for improving the performance of such queries, and provide a preliminary experimental evaluation of the proposed techniques. Our conclusion is that significant cost reductions are possible by using specialized mechanisms for executing batch queries in Web search engines.",2011,Web Search and Data Mining,Fields of study: queries per secondsite mapweb search queryweb query classificationweb crawlerquery expansionweb pagesearch enginesemantic searchmetasearch engineweb miningweb search engineworld wide webinformation retrievaldata miningdatabasecomputer science
Your Cart tells You: Inferring Demographic Attributes from Purchase Data,Pengfei Wang (Chinese Academy of Sciences)Jiafeng Guo (Chinese Academy of Sciences)Yanyan Lan (Chinese Academy of Sciences)Jun Xu (Chinese Academy of Sciences)Xueqi Cheng (Chinese Academy of Sciences),"2671177797,2581340266,2154124860,2598177019,2129598186","Demographic attributes play an important role in retail market to characterize different types of users. Such signals however are often only available for a small fraction of users in practice due to the difficulty in manual collection process by retailers. In this paper, we aim to harness the power of big data to automatically infer users' demographic attributes based on their purchase data. Typically, demographic prediction can be formalized as a multi-task multi-class prediction problem, i.e., multiple demographic attributes (e.g., gender, age and income) are to be inferred for each user where each attribute may belong to one of N possible classes (N-2). Most previous work on this problem explores different types of features and usually predicts different attributes independently. However, modeling the tasks separately may lose the ability to leverage the correlations among different attributes. Meanwhile, manually defined features require professional knowledge and often suffer from under specification. To address these problems, we propose a novel Structured Neural Embedding (SNE) model to automatically learn the representations from users' purchase data for predicting multiple demographic attributes simultaneously. Experiments are conducted on a real-world retail dataset where five attributes (gender, marital status, income, age, and education level) are to be predicted. The empirical results show that our SNE model can improve the performance significantly compared with state-of-the-art baselines.",2016,Web Search and Data Mining,Fields of study: world wide webdata miningmachine learningsimulation
Learning from User Interactions,Thorsten Joachims (Cornell University),245171893,"The ability to learn from user interactions can give systems access to unprecedented amounts of world knowledge. This is already evident in search engines, recommender systems, and electronic commerce, and other applications are likely to follow in the near future (e.g., education, smart homes). More generally, the ability to learn from user interactions promises pathways for solving knowledge-intensive tasks ranging from natural language understanding to autonomous robotics. Learning from user interactions, however, means learning from data that does not necessarily fit the assumptions of the standard machine learning models. Since interaction data consists of the choices that humans make, it has to be interpreted with respect to how humans make decisions, which is influenced by the decision context and constraints like human motivation and human abilities. In this talk, I argue that we need learning approaches that explicitly model user-interaction data as the result of human decision making. To this effect, the talk explores how integrating microeconomic models of human behavior into the learning process leads to new learning algorithms that have provable guarantees under verifiable assumptions and to learning systems that perform robustly in practice. These findings imply that the design space of such human-interactive learning systems encompasses not only the machine learning algorithm itself, but also the design of the interaction under an appropriate model of user behavior.",2015,Web Search and Data Mining,Fields of study: stabilityinductive transfermulti task learningrobot learningsynchronous learningactive learningerror driven learningactive learningalgorithmic learning theoryproactive learningsequence learningcomputational learning theoryinstance based learningknowledge managementworld wide webdata miningmachine learningsimulationcomputer science
Delayed-Dynamic-Selective (DDS) Prediction for Reducing Extreme Tail Latency in Web Search,Saehoon Kim (Pohang University of Science and Technology)Yuxiong He (Microsoft)Seung-won Hwang (Pohang University of Science and Technology)Sameh Elnikety (Microsoft)Seungjin Choi (Pohang University of Science and Technology),"2232528631,2166872174,2168667670,2017883357,2128913862","A commercial web search engine shards its index among many servers, and therefore the response time of a search query is dominated by the slowest server that processes the query. Prior approaches target improving responsiveness by reducing the tail latency of an individual search server. They predict query execution time, and if a query is predicted to be long-running, it runs in parallel, otherwise it runs sequentially. These approaches are, however, not accurate enough for reducing a high tail latency when responses are aggregated from many servers because this requires each server to reduce a substantially higher tail latency (e.g., the 99.99th-percentile), which we call extreme tail latency. We propose a prediction framework to reduce the extreme tail latency of search servers. The framework has a unique set of characteristics to predict long-running queries with high recall and improved precision. Specifically, prediction is delayed by a short duration to allow many short-running queries to complete without parallelization, and to allow the predictor to collect a set of dynamic features using runtime information. These features estimate query execution time with high accuracy. We also use them to estimate the prediction errors to override an uncertain prediction by selectively accelerating the query for a higher recall. We evaluate the proposed prediction framework to improve search engine performance in two scenarios using a simulation study: (1) query parallelization on a multicore processor, and (2) query scheduling on a heterogeneous processor. The results show that, for both scenarios, the proposed framework is effective in reducing the extreme tail latency compared to a start-of-the-art predictor because of its higher recall, and it improves server throughput by more than 70% because of its improved precision.",2015,Web Search and Data Mining,Fields of study: sargablesearch enginepredictionworld wide webdata miningdatabasereal time computingstatisticscomputer science
Making Sense of Big Data with the Berkeley Data Analytics Stack,"Michael J. Franklin (University of California, Berkeley)",2523407221,"The Berkeley AMPLab is creating a new approach to data analytics. Launching in early 2011, the lab aims to seamlessly integrate the three main resources available for making sense of data at scale: Algorithms (machine learning and statistical techniques), Machines (in the form of scalable clusters and elastic cloud computing), and People (both individually as analysts and in crowds). The lab is realizing its ideas through the development of a freely-available Open Source software stack called BDAS: the Berkeley Data Analytics Stack. In the four years the lab has been in operation, we've released major components of BDAS. Several of these components have gained significant traction in industry and elsewhere: the Mesos cluster resource manager, the Spark in-memory computation framework, and the Shark query processing system. BDAS features prominently in many industry discussions of the future of the Big Data analytics ecosystem -- a rare degree of impact for an ongoing academic project. Given this initial success, the lab is continuing on its research path, moving ""up the stack"" to better integrate and support advanced analytics and to make people a full-fledged resource for making sense of data. In this talk, I'll first outline the motivation and insights behind our research approach and describe how we have organized to address the cross-disciplinary nature of Big Data challenges. I will then describe the current state of BDAS with an emphasis on our newest efforts, including some or all of: the GraphX graph processing system, the Velox and MLBase machine learning platforms, and the SampleClean framework for hybrid human/computer data cleaning. Finally I will present our current views of how all the pieces will fit together to form a system that can adaptively bring the right resources to bear on a given data-driven question to meet time, cost and quality requirements throughout the analytics lifecycle.",2015,Web Search and Data Mining,Fields of study: analyticsbig datadata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
3rd workshop on context-awareness in retrieval and recommendation,Matthias Böhmer 0001 (German Research Centre for Artificial Intelligence)Ernesto William De Luca (Technical University of Berlin)Alan Said (Technical University of Berlin)Jaime Teevan (Microsoft),"2105339162,2207200232,2104679579,1982462162","Context-aware information is widely available in various ways and is becoming more and more important for enhancing retrieval performance and recommendation results. The current main issue to cope with is not only recommending or retrieving the most relevant items and content, but defining them ad hoc. Other relevant issues include personalizing and adapting the information and the way it is displayed to the user's current situation and interests. Ubiquitous computing further provides new means for capturing user feedback on items and providing information.",2013,Web Search and Data Mining,Fields of study: recommender systemworld wide webinformation retrievaldata miningcomputer science
D-Cube: Dense-Block Detection in Terabyte-Scale Tensors,Kijung Shin (Carnegie Mellon University)Bryan Hooi (Carnegie Mellon University)Jisu Kim (Carnegie Mellon University)Christos Faloutsos (Carnegie Mellon University),"2226806500,1755863881,2656375196,2198983026","How can we detect fraudulent lockstep behavior in large-scale multi-aspect data (i.e., tensors)? Can we detect it when data are too large to fit in memory or even on a disk? Past studies have shown that dense blocks in real-world tensors (e.g., social media, Wikipedia, TCP dumps, etc.) signal anomalous or fraudulent behavior such as retweet boosting, bot activities, and network attacks. Thus, various approaches, including tensor decomposition and search, have been used for rapid and accurate dense-block detection in tensors. However, all such methods have low accuracy, or assume that tensors are small enough to fit in main memory, which is not true in many real-world applications such as social media and web. To overcome these limitations, we propose D-Cube, a disk-based dense-block detection method, which also can be run in a distributed manner across multiple machines. Compared with state-of-the-art methods, D-Cube is (1) Memory Efficient: requires up to 1,600 times less memory and handles 1,000 times larger data (2.6TB), (2) Fast: up to 5 times faster due to its near-linear scalability with all aspects of data, (3) Provably Accurate: gives a guarantee on the densities of the blocks it finds, and (4) Effective: successfully spotted network attacks from TCP dumps and synchronized behavior in rating data with the highest accuracy.",2017,Web Search and Data Mining,Fields of study: tensoranomaly detectiontheoretical computer scienceworld wide webcomputer securitydata miningmachine learningcomputer science
Understanding cyclic trends in social choices,Anish Das Sarma (Google)Sreenivas Gollapudi (Microsoft)Rina Panigrahy (Microsoft)Li Zhang (Microsoft),"2103056292,2023254819,1923488504,2605633800","Motivated by trends in popularity of products, we present a formal model for studying trends in our choice of products in terms of three parameters: (1) their innate utility; (2) individual boredom associated with repeated usage of an item; and (3) social influences associated with the preferences from other people. Different from previous work, in this paper we introduce boredom to explain the cyclic pattern in individual and social choices. We formally model boredom and show that a rational individual would make cyclic choices when considering the boredom factor. Furthermore, we extend the model to social choices by showing that a society that votes for a particular style or product can be viewed as a single individual cycling through different choices. We adopt a natural model of utility an individual derives from using an item, i.e., the utility of an item gets discounted by its repeated use and increases when the item is not used. We address the problem of optimally choosing items for usage, so as to maximize overall user satisfaction over a period of time. First we show that the simple greedy heuristic of always choosing the item with the maximum current composite utility can be arbitrarily worse than the optimal. Second, we prove that even with just a single individual, determining the optimal strategy for choosing items is NP-hard. Third, we show that a simple modification to the greedy algorithm is a provably close approximation to the optimal strategy. Finally, we present an experimental study over real-world data collected from query logs to compare our algorithms.",2012,Web Search and Data Mining,Fields of study: greedy algorithmdata miningartificial intelligencemachine learningstatisticscomputer science
Improving Website Hyperlink Structure Using Server Logs,Ashwin Paranjape (Stanford University)Robert West (Stanford University)Leila ZiaJure Leskovec (Stanford University),"2242317802,2119386814,2632174330,1878631932","Good websites should be easy to navigate via hyperlinks, yet maintaining a high-quality link structure is difficult. Identifying pairs of pages that should be linked may be hard for human editors, especially if the site is large and changes frequently. Further, given a set of useful link candidates, the task of incorporating them into the site can be expensive, since it typically involves humans editing pages. In the light of these challenges, it is desirable to develop data-driven methods for automating the link placement task. Here we develop an approach for automatically finding useful hyperlinks to add to a website. We show that passively collected server logs, beyond telling us which existing links are useful, also contain implicit signals indicating which nonexistent links would be useful if they were to be introduced. We leverage these signals to model the future usefulness of yet nonexistent links. Based on our model, we define the problem of link placement under budget constraints and propose an efficient algorithm for solving it. We demonstrate the effectiveness of our approach by evaluating it on Wikipedia, a large website for which we have access to both server logs (used for finding useful new links) and the complete revision history (containing a ground truth of new links). As our method is based exclusively on standard server logs, it may also be applied to any other website, as we show with the example of the biomedical research site Simtk.",2016,Web Search and Data Mining,Fields of study: navigationworld wide webdata miningdatabasecomputer science
Online Actions with Offline Impact: How Online Social Networks Influence Online and Offline User Behavior,Tim Althoff (Stanford University)Pranav Jindal (Stanford University)Jure Leskovec (Stanford University),"2227326281,2586380945,1878631932","Many of today's most widely used computing applications utilize social networking features and allow users to connect, follow each other, share content, and comment on others' posts. However, despite the widespread adoption of these features, there is little understanding of the consequences that social networking has on user retention, engagement, and online as well as offline behavior. Here, we study how social networks influence user behavior in a physical activity tracking application. We analyze 791 million online and offline actions of 6 million users over the course of 5 years, and show that social networking leads to a significant increase in users' online as well as offline activities. Specifically, we establish a causal effect of how social networks influence user behavior. We show that the creation of new social connections increases user online in-application activity by 30%, user retention by 17%, and user offline real-world physical activity by 7% (about 400 steps per day). By exploiting a natural experiment we distinguish the effect of social influence of new social connections from the simultaneous increase in user's motivation to use the app and take more steps. We show that social influence accounts for 55% of the observed changes in user behavior, while the remaining 45% can be explained by the user's increased motivation to use the app. Further, we show that subsequent, individual edge formations in the social network lead to significant increases in daily steps. These effects diminish with each additional edge and vary based on edge attributes and user demographics. Finally, we utilize these insights to develop a model that accurately predicts which users will be most influenced by the creation of new social network connections.",2017,Web Search and Data Mining,Fields of study: social influencehealthmultimediasocial psychologyworld wide websocial sciencecomputer science
Scaling up Link Prediction with Ensembles,Liang Duan (Beihang University)Charu Aggarwal (IBM)Shuai Ma (Beihang University)Renjun Hu (Beihang University)Jinpeng Huai (Beihang University),"2239208256,2146335907,2119375424,2280707507,2709855640","A network with $n$ nodes contains O ( n 2 ) possible links. Even for networks of modest size, it is often difficult to evaluate all pairwise possibilities for links in a meaningful way. Furthermore, even though link prediction is closely related to missing value estimation problems, such as collaborative filtering, it is often difficult to use sophisticated models such as latent factor methods because of their computational complexity over very large networks. Due to this computational complexity, most known link prediction methods are designed for evaluating the link propensity over a specified subset of links, rather than for performing a global search over the entire networks. In practice, however, it is essential to perform an exhaustive search over the entire networks. In this paper, we propose an ensemble enabled approach to scaling up link prediction, which is able to decompose traditional link prediction problems into subproblems of smaller size. These subproblems are each solved with the use of latent factor models, which can be effectively implemented over networks of modest size. Furthermore, the ensemble enabled approach has several advantages in terms of performance. We show the advantage of using ensemble-based latent factor models with experiments on very large networks. Experimental results demonstrate the effectiveness and scalability of our approach.",2016,Web Search and Data Mining,Fields of study: big datadata miningmachine learningstatisticscomputer science
Optimizing two-dimensional search results presentation,Flavio Chierichetti (Cornell University)Ravi Kumar (Yahoo!)Prabhakar Raghavan (Yahoo!),"2082432826,2232709231,2195048431","Classic search engine results are presented as an ordered list of documents and the problem of presentation trivially reduces to ordering documents by their scores. This is because users scan a list presentation from top to bottom. This leads to natural list optimization measures such as the discounted cumulative gain (DCG) and the rank-biased precision (RBP). Increasingly, search engines are using two-dimensional results presentations; image and shopping search results are long-standing examples. The simplistic heuristic used in practice is to place images by row-major order in the matrix presentation. However, a variety of evidence suggests that users' scan of pages is not in this matrix order. In this paper we (1) view users' scan of a results page as a Markov chain, which yields DCG and RBP as special cases for linear lists; (2) formulate, study, and develop solutions for the problem of inferring the Markov chain from click logs; (3) from these inferred Markov chains, empirically validate folklore phenomena (e.g., the ""golden triangle"" of user scans in two dimensions); and (4) develop and experimentally compare algorithms for optimizing user utility in matrix presentations. The theory and algorithms extend naturally beyond matrix presentations.",2011,Web Search and Data Mining,Fields of study: page layoutsearch enginecumulantmarkov chaintwo dimensional spacetheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningsimulationstatisticscomputer science
Robust Tree-based Causal Inference for Complex Ad Effectiveness Analysis,Pengyuan Wang (Yahoo!)Wei Sun (Purdue University)Dawei Yin (Yahoo!)Jian Yang (Yahoo!)Yi Chang (Yahoo!),"2157416250,2659073981,2170531144,2550117728,2168000538","As the online advertising industry has evolved into an age of diverse ad formats and delivery channels, users are exposed to complex ad treatments involving various ad characteristics. The diversity and generality of ad treatments call for accurate and causal measurement of ad effectiveness, i.e., how the ad treatment causes the changes in outcomes without the confounding effect by user characteristics. Various causal inference approaches have been proposed to measure the causal effect of ad treatments. However, most existing causal inference methods focus on univariate and binary treatment and are not well suited for complex ad treatments. Moreover, to be practical in the data-rich online environment, the measurement needs to be highly general and efficient, which is not addressed in conventional causal inference approaches. In this paper we propose a novel causal inference framework for assessing the impact of general advertising treatments. Our new framework enables analysis on uni- or multi-dimensional ad treatments, where each dimension (ad treatment factor) could be discrete or continuous. We prove that our approach is able to provide an unbiased estimation of the ad effectiveness by controlling the confounding effect of user characteristics. The framework is computationally efficient by employing a tree structure that specifies the relationship between user characteristics and the corresponding ad treatment. This tree-based framework is robust to model misspecification and highly flexible with minimal manual tuning. To demonstrate the efficacy of our approach, we apply it to two advertising campaigns. In the first campaign we evaluate the impact of different ad frequencies, and in the second one we consider the synthetic ad effectiveness across TV and online platforms. Our framework successfully provides the causal impact of ads with different frequencies in both campaigns. Moreover, it shows that the ad frequency usually has a treatment effect cap, which is usually over-estimated by naive estimation.",2015,Web Search and Data Mining,Fields of study: causal inferencedata miningsimulationstatisticscomputer science
A noise-aware click model for web search,"Weizhu Chen (Microsoft)Dong Wang (Microsoft)Yuchen Zhang (Microsoft)Zheng Chen (Microsoft)Adish Kumar Singla (Microsoft)Qiang Yang (University of Science and Technology, Sana'a)","2108390110,2665529436,2657274593,2425877144,2155576873,2109031554","Recent advances in click model have established it as an attractive approach to infer document relevance. Most of these advances consider the user click/skip behavior as binary events but neglect the context in which a click happens. We show that real click behavior in industrial search engines is often noisy and not always a good indication of relevance. For a considerable percentage of clicks, users select what turn out to be irrelevant documents and these clicks should not be directly used as evidence for relevance inference. Thus in this paper, we put forward an observation that the relevance indication degree of a click is not a constant, but can be differentiated by user preferences and the context in which the user makes her click decision. In particular, to interpret the click behavior discriminatingly, we propose a Noise-aware Click Model (NCM) by characterizing the noise degree of a click, which indicates the quality of the click for inferring relevance. Specifically, the lower the click noise is, the more important the click is in its role for relevance inference. To verify the necessity of explicitly accounting for the uninformative noise in a user click, we conducted experiments on a billion-scale dataset. Extensive experimental results demonstrate that as compared with two state-of-the-art click models in Web Search, NCM can better interpret user click behavior and achieve significant improvements in terms of both perplexity and NDCG.",2012,Web Search and Data Mining,Fields of study: click pathorganic searchsearch enginemultimediaworld wide webspeech recognitioncomputer science
Second Workshop on Search and Exploration of X-Rated Information (SEXI'16): WSDM Workshop Summary,Vanessa Murdock (Microsoft)Charles L.A. Clarke (University of Waterloo)Jaap Kamps (University of Amsterdam)Jussi Karlgren (Royal Institute of Technology),"2597241764,2098618034,2088944921,1073530958","Adult content is pervasive on the web, has been a driving factor in the adoption of the Internet medium, and is responsible for a significant fraction of traffic and revenues, yet rarely attracts attention in research. The research questions surrounding adult content access behaviors are unique, and interesting and valuable research in this area can be done ethically. WSDM 2016 features a half day workshop on Search and Exploration of X-Rated Information (SEXI) for information access tasks related to adult content. While the scope of the workshop remains broad, special attention is devoted to the privacy and security issues surrounding adult content by inviting keynote speakers with extensive experience on these topics. The recent release of the personal data belonging to customers of the adult dating site Ashley Madison provides a timely context for the focus on privacy and security.",2016,Web Search and Data Mining,Fields of study: research ethicsinternet privacyworld wide webinformation retrievaldata mining
On placing skips optimally in expectation,Flavio Chierichetti (Sapienza University of Rome)Silvio Lattanzi (Sapienza University of Rome)Federico Mari (Sapienza University of Rome)Alessandro Panconesi (Sapienza University of Rome),"2082432826,1989808900,2465427139,2193688032","We study the problem of optimal skip placement in an inverted list. Assuming the query distribution to be known in advance, we formally prove that an optimal skip placement can be computed quite efficiently. Our best algorithm runs in time O ( n log n ), n being the length of the list. The placement is optimal in the sense that it minimizes the expected time to process a query. Our theoretical results are matched by experiments with a real corpus, showing that substantial savings can be obtained with respect to the traditional skip placement strategy, that of placing consecutive skips, each spanning √ n many locations.",2008,Web Search and Data Mining,Fields of study: inverted indexprobabilistic analysis of algorithmsmathematical optimizationalgorithmcomputer science
"Bing dialog model: intent, knowledge and user interaction",Harry Shum (Microsoft),2147729234,"The decade-old Internet search outcomes, manifested in the form of ""ten blue links,"" are no longer sufficient for Internet users. Many studies have shown that when users are ushered off the conventional search result pages through blue links, their needs are often partially met at best in a ""hit-or-miss"" fashion. To tackle this challenge, we have designed Bing, Microsoft's decision engine, to not just navigate users to a landing page through a blue link but to continue engaging with users to clarify intent and facilitate task completion. Underlying this new paradigm is the Bing Dialog Model that consists of three building blocks: an indexing system that comprehensively collects information from the web and systematically harvests knowledge, an intent model that statistically infers user intent and predicts next action, and an interaction model that elicits user intent through mathematically optimized presentations of web information and domain knowledge that matches user needs. In this talk, I'll describe Bing Dialog Model in details and demonstrate it in action through some innovative features since the launch of www.Bing.com.",2011,Web Search and Data Mining,Fields of study: domain knowledgestatistical inferenceknowledgeworld wide webinformation retrievaldata miningmachine learningsimulationstatisticscomputer science
Hiring Behavior Models for Online Labor Markets,Marios Kokkodis (New York University Stern School of Business)Panagiotis Papadimitriou (Stanford University)Panagiotis G. Ipeirotis (New York University Stern School of Business),"186271914,2027183093,94049422","In an online labor marketplace employers post jobs, receive freelancer applications and make hiring decisions. These hiring decisions are based on the freelancer's observed (e.g., education) and latent (e.g., ability) characteristics. Because of the heterogeneity that appears in the observed characteristics, and the existence of latent ones, identifying and hiring the best possible applicant is a very challenging task. In this work we study and model the employer's hiring behavior. We assume that employers are utility maximizers and make rational decisions by hiring the best possible applicant at hand. Based on this premise, we propose a series of probabilistic models that estimate the hiring probability of each applicant. We train and test our models on more than 600,000 job applications obtained by oDesk.com, and we show evidence that the proposed models outperform currently in-use baselines. To get further insights, we conduct an econometric analysis and observe that the attributes that are strongly correlated with the hiring probability are whether or not the freelancer and the employer have previously worked together, the available information on the freelancer's profile, the countries of the employer and the freelancer and the skillset of the freelancer. Finally, we find that the faster a freelancer applies to an opening, the higher is the probability to get the job.",2015,Web Search and Data Mining,Fields of study: rankingbayesian networkmachine learningcomputer science
Mining slang and urban opinion words and phrases from cQA services: an optimization approach,Hadi Amiri (National University of Singapore)Tat-Seng Chua (National University of Singapore),"2009160502,2160663097","Current opinion lexicons contain most of the common opinion words, but they miss slang and so-called urban opinion words and phrases (e.g. delish, cozy, yummy, nerdy , and yuck ). These subjectivity clues are frequently used in community questions and are useful for opinion question analysis. This paper introduces a principled approach to constructing an opinion lexicon for community-based question answering (cQA) services. We formulate the opinion lexicon induction as a semi-supervised learning task in the graph context. Our method makes use of existing opinion words to extract new opinion entities (slang and urban words/phrases) from community questions. It then models the opinion entities in a graph context to learn the polarity of the new opinion entities based on the graph connectivity information. In contrast to previous approaches, our method not only learns such polarities from the labeled data but also from the unlabeled data and is more feasible in the web context where the dictionary-based relations (such as synonym, antonym , or hyponym ) between most words are not available for constructing a high quality graph. The experiments show that our approach is effective both in terms of the quality of the discovered new opinion entities as well as its ability in inferring their polarity. Furthermore, since the value of opinion lexicons lies in their usefulness in applications, we show the utility of the constructed lexicon in the sentiment classification task.",2012,Web Search and Data Mining,Fields of study: connectivitysentiment analysisnatural language processingdata miningpattern recognitioncomputer science
Faceted search and retrieval based on semantically annotated product family ontology,Soon Chong Johnson Lim (Hong Kong Polytechnic University)Ying Liu (Hong Kong Polytechnic University)Wing Bun Lee (Hong Kong Polytechnic University),"2127021197,2585657217,2246527134","With the advent of various services and applications of Semantic Web, semantic annotation had emerged as an important research area. The use of semantically annotated ontology had been evident in numerous information processing and retrieval tasks. One of such tasks is utilizing the semantically annotated ontology in product design which is able to suggest many important applications that are critical to aid various design related tasks. However, ontology development in design engineering remains a time consuming and tedious task that demands tremendous human efforts. In the context of product family design, management of different product information that features efficient indexing, update, navigation, search and retrieval across product families is both desirable and challenging. This paper attempts to address this issue by proposing an information management and retrieval framework based on the semantically annotated product family ontology. Particularly, we propose a document profile (DP) model to suggest semantic tags for annotation purpose. Using a case study of digital camera families, we illustrate how the faceted search and retrieval of product information can be accomplished based on the semantically annotated camera family ontology. Lastly, we briefly discuss some further research and application in design decision support, e.g. commonality and variety, based on the semantically annotated product family ontology.",2009,Web Search and Data Mining,Fields of study: bibliographic ontologyontology based data integrationupper ontologyontologysemantic webproduct designontologyinformation managementinformation processingworld wide webinformation retrievaldata miningdatabasecomputer science
Reducing Controversy by Connecting Opposing Views,Kiran Garimella (Aalto University)Gianmarco De Francisci Morales (Qatar Computing Research Institute)Aristides Gionis (Aalto University)Michael Mathioudakis (Aalto University),"1979823234,2153118160,737311942,2085699011","Society is often polarized by controversial issues that split the population into groups with opposing views. When such issues emerge on social media, we often observe the creation of `echo chambers', i.e., situations where like-minded people reinforce each other's opinion, but do not get exposed to the views of the opposing side. In this paper we study algorithmic techniques for bridging these chambers, and thus reduce controversy. Specifically, we represent the discussion on a controversial issue with an endorsement graph , and cast our problem as an edge-recommendation problem on this graph. The goal of the recommendation is to reduce the controversy score of the graph, which is measured by a recently-developed metric based on random walks. At the same time, we take into account the acceptance probability of the recommended edge, which represents how likely the edge is to materialize in the endorsement graph. We propose a simple model based on a recently-developed user-level controversy score, that is competitive with state-of-the-art link-prediction algorithms. Our goal then becomes finding the edges that produce the largest reduction in the controversy score, in expectation. To solve this problem, we propose an efficient algorithm that considers only a fraction of all the possible combinations of edges. Experimental results show that our algorithm is more efficient than a simple greedy heuristic, while producing comparable score reduction. Finally, a comparison with other state-of-the-art edge-addition algorithms shows that this problem is fundamentally different from what has been studied in the literature.",2017,Web Search and Data Mining,Fields of study: social mediapolarizationmanagement scienceworld wide webdata miningartificial intelligencesimulationcomputer science
Connectivity structure of bipartite graphs via the KNC-plot,Ravi Kumar (Yahoo!)Andrew Tomkins (Yahoo!)Erik Vee (Yahoo!),"2232709231,2130754085,2134018118","In this paper we introduce the k-neighbor connectivity plot, or KNC-plot, as a tool to study the macroscopic connectiv-ity structure of sparse bipartite graphs. Given a bipartite graph G = ( U, V, E ), we say that two nodes in U are k-neighbors if there exist at least k distinct length-two paths between them; this defines a k-neighborhood graph on U where the edges are given by the k -neighbor relation. For example, in a bipartite graph of users and interests, two users are k -neighbors if they have at least k common interests. The KNC-plot shows the degradation of connectivity of the graph as a function of k . We show that this tool provides an effective and interpretable high-level characterization of the connectivity of a bipartite graph However, naive algorithms to compute the KNC-plot are inefficient for k > 1. We give an efficient and practical algorithm that runs in sub-quadratic time O (| E | 2-1/ k ) and is a non-trivial improvement over the obvious quadratic-time algorithms for this problem. We prove significant improvements in this runtime for graphs with power-law degree distributions, and give a different algorithm with near-linear runtime when V grows slowly as a function of the size of the graph We compute the KNC-plot of four large real-world bipartite graphs, and discuss the structural properties of these graphs that emerge. We conclude that the KNC-plot represents a useful and practical tool for macroscopic analysis of large bipartite graphs.",2008,Web Search and Data Mining,Fields of study: biregular graphfoster graphvoltage graphhopcroft karp algorithmforbidden graph characterizationpancyclic graphvertex transitive graph1 planar graphtriangle free graphedge transitive graphcographclique widthdense graphcomplete bipartite graphblossom algorithmpathwidthline graphfactor graphconnected componentbipartite graphmatchingtheoretical computer science
Revisiting globally sorted indexes for efficient document retrieval,Fan Zhang (Nankai University)Shuming Shi (Microsoft)Hao Yan (Polytechnic Institute of New York University)Ji-Rong Wen (Microsoft),"2617298555,2105557964,2435650621,2066159008","There has been a large amount of research on efficient document retrieval in both IR and web search areas. One important technique to improve retrieval efficiency is early termination, which speeds up query processing by avoiding scanning the entire inverted lists. Most early termination techniques first build new inverted indexes by sorting the inverted lists in the order of either the term-dependent information, e.g., term frequencies or term IR scores, or the term-independent information, e.g., static rank of the document; and then apply appropriate retrieval strategies on the resulting indexes. Although the methods based only on the static rank have been shown to be ineffective for the early termination, there are still many advantages of using the methods based on term-independent information. In this paper, we propose new techniques to organize inverted indexes based on the term-independent information beyond static rank and study the new retrieval strategies on the resulting indexes. We perform a detailed experimental evaluation on our new techniques and compare them with the existing approaches. Our results on the TREC GOV and GOV2 data sets show that our techniques can improve query efficiency significantly.",2010,Web Search and Data Mining,Fields of study: term discriminationinverted indextf idfquery expansiondocument retrievalworld wide webinformation retrievaldata miningdatabasecomputer science
Long-tail Vocabulary Dictionary Extraction from the Web,Zhe Chen (University of Michigan)Michael J. Cafarella (University of Michigan)H. V. Jagadish (University of Michigan),"2302085265,2893888,360112113","A dictionary --- a set of instances belonging to the same conceptual class --- is central to information extraction and is a useful primitive for many applications, including query log analysis and document categorization. Considerable work has focused on generating accurate dictionaries given a few example seeds, but methods to date cannot obtain long-tail (rare) items with high accuracy and recall. In this paper, we develop a novel method to construct high-quality dictionaries, especially for long-tail vocabularies, using just a few user-provided seeds for each topic. Our algorithm obtains long-tail (i.e., rare) items by building and executing high-quality webpage-specific extractors. We use webpage-specific structural and textual information to build more accurate per-page extractors in order to detect the long-tail items from a single webpage. These webpage-specific extractors are obtained via a co-training procedure using distantly-supervised training data. By aggregating the page-specific dictionaries of many webpages, Lyretail is able to output a high-quality comprehensive dictionary. Our experiments demonstrate that in long-tail vocabulary settings, we obtained a 17.3% improvement on mean average precision for the dictionary generation process, and a 30.7% improvement on F1 for the page-specific extraction, when compared to previous state-of-the-art methods.",2016,Web Search and Data Mining,Fields of study: information extractionnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Multileave Gradient Descent for Fast Online Learning to Rank,Anne Schuth (University of Amsterdam)Harrie Oosterhuis (University of Amsterdam)Shimon Whiteson (University of Oxford)Maarten de Rijke (University of Amsterdam),"1979729989,2226973173,2042571382,401833296","Modern search systems are based on dozens or even hundreds of ranking features. The dueling bandit gradient descent (DBGD) algorithm has been shown to effectively learn combinations of these features solely from user interactions. DBGD explores the search space by comparing a possibly improved ranker to the current production ranker. To this end, it uses interleaved comparison methods, which can infer with high sensitivity a preference between two rankings based only on interaction data. A limiting factor is that it can compare only to a single exploratory ranker. We propose an online learning to rank algorithm called multileave gradient descent (MGD) that extends DBGD to learn from so-called multileaved comparison methods that can compare a set of rankings instead of merely a pair. We show experimentally that MGD allows for better selection of candidates than DBGD without the need for more comparisons involving users. An important implication of our results is that orders of magnitude less user interaction data is required to find good rankers when multileaved comparisons are used within online learning to rank. Hence, fewer users need to be exposed to possibly inferior rankers and our method allows search engines to adapt more quickly to changes in user preferences.",2016,Web Search and Data Mining,Fields of study: learning to rankinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
Crowdsourcing for search and data mining,Vitor R. Carvalho (Microsoft)Matthew Lease (University of Texas at Austin)Emine Yilmaz (Microsoft),"2047752476,2123681105,2342836604","The advent of crowdsourcing is revolutionizing data annotation, evaluation, and other traditionally manual-labor intensive processes by dramatically reducing the time, cost, and effort involved. This in turn is driving a disruptive shift in search and data mining methodology in areas such as: Evaluation: the Cranfield paradigm for search evaluation requires manually assessing document relevance to search queries. Recent work on stochastic evaluation has reduced but not removed this need for manual assessment. Supervised Learning: while traditional costs associated with data annotation have driven recent machine learning work (e.g. Learning to Rank) toward greater use of unsupervised and semi-supervised methods, the emergence of crowdsourcing has made labeled data far easier to acquire, thereby driving a potential resurgence in fully-supervised methods. Applications: Crowdsourcing has introduced exciting new opportunities to integrate human labor into automated systems: handling difficult cases where automation fails, exploiting the breadth of backgrounds, geographic dispersion, real-time response, etc.",2011,Web Search and Data Mining,Fields of study: crowdsourcinglearning to ranksupervised learningdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Have you done anything like that?: predicting performance using inter-category reputation,Marios Kokkodis (New York University Stern School of Business)Panagiotis G. Ipeirotis (New York University Stern School of Business),"186271914,94049422","Online labor markets such as oDesk and Amazon Mechanical Turk have been growing in importance over the last few years. In these markets, employers post tasks on which remote contractors work and deliver the product of their work. As in most online marketplaces, reputation mechanisms play a very important role in facilitating transactions, since they instill trust and are often predictive of the future satisfaction of the employer. However, labor markets are usually highly heterogeneous in terms of available task categories; in such scenarios, past performance may not be a representative signal of future performance. To account for this heterogeneity, in our work, we build models that predict the performance of a worker based on prior, category-specific feedback. Our models assume that each worker has a category-specific quality, which is latent and not directly observable; what is observable, though, is the set of feedback ratings of the worker and of other contractors with similar work histories. Based on this information, we build a multi-level, hierarchical scheme that deals effectively with the data sparseness, which is inherent in many cases of interest (i.e., contractors with relatively brief work histories). We evaluate our models on a large corpus of real transactional data from oDesk, an online labor market with hundreds of millions of dollars in transaction volume. Our results show an improved accuracy of up to 47% compared to the existing baseline.",2013,Web Search and Data Mining,Fields of study: reputationbayesian inferenceworld wide webdata miningsimulationstatistics
Wikipedia pages as entry points for book search,Marijn Koolen (University of Amsterdam)Gabriella Kazai (Microsoft)Nick Craswell (Microsoft),"2165198141,114700236,2009495402","A lot of the world's knowledge is stored in books, which, as a result of recent mass-digitisation efforts, are increasingly available online. Search engines, such as Google Books, provide mechanisms for searchers to enter this vast knowledge space using queries as entry points. In this paper, we view Wikipedia as a summary of this world knowledge and aim to use this resource to guide users to relevant books. Thus, we investigate possible ways of using Wikipedia as an intermediary between the user's query and a collection of books being searched. We experiment with traditional query expansion techniques, exploiting Wikipedia articles as rich sources of information that can augment the user's query. We then propose a novel approach based on link distance in an extended Wikipedia graph: we associate books with Wikipedia pages that cite these books and use the link distance between these nodes and the pages that match the user query as an estimation of a book's relevance to the query. Our results show that a) classical query expansion using terms extracted from query pages leads to increased precision, and b) link distance between query and book pages in Wikipedia provides a good indicator of relevance that can boost the retrieval score of relevant books in the result ranking of a book search engine.",2009,Web Search and Data Mining,Fields of study: rankingsargableweb search queryweb query classificationbranddomain specific languagequery expansionquery optimizationquery languagesearch engineworld wide webinformation retrievaldata miningcomputer science
Ensemble Models for Data-driven Prediction of Malware Infections,"Chanhyun Kang (University of Maryland, College Park)Noseong Park (University of Maryland, College Park)B. Aditya Prakash (Virginia Tech)Edoardo Serra (Boise State University)V. S. Subrahmanian (University of Maryland, College Park)","2102885882,2304434517,2124002246,2142191961,2261167843","Given a history of detected malware attacks, can we predict the number of malware infections in a country? Can we do this for different malware and countries? This is an important question which has numerous implications for cyber security, right from designing better anti-virus software, to designing and implementing targeted patches to more accurately measuring the economic impact of breaches. This problem is compounded by the fact that, as externals, we can only detect a fraction of actual malware infections. In this paper we address this problem using data from Symantec covering more than 1.4 million hosts and 50 malware spread across 2 years and multiple countries. We first carefully design domain-based features from both malware and machine-hosts perspectives. Secondly, inspired by epidemiological and information diffusion models, we design a novel temporal non-linear model for malware spread and detection. Finally we present ESM, an ensemble-based approach which combines both these methods to construct a more accurate algorithm. Using extensive experiments spanning multiple malware and countries, we show that ESM can effectively predict malware infection ratios over time (both the actual number and trend) upto 4 times better compared to several baselines on various metrics. Furthermore, ESM's performance is stable and robust even when the number of detected infections is low.",2016,Web Search and Data Mining,Fields of study: predictive modellinginternet privacyworld wide webcomputer securitydata miningmachine learningcomputer science
Exploiting contextual factors for click modeling in sponsored search,Dawei Yin (Lehigh University)Shike Mei (University of Wisconsin-Madison)Bin Cao (Microsoft)Jian-Tao Sun (Microsoft)Brian D. Davison (Lehigh University),"2170531144,2631136332,2618926548,2131116857,2203702053","Sponsored search is the primary business for today's commercial search engines. Accurate prediction of the Click-Through Rate (CTR) for ads is key to displaying relevant ads to users. In this paper, we systematically study the two kinds of contextual factors influencing the CTR: 1) In micro factors, we focus on the factors for mainline ads, including ad depth, query diversity, ad interaction. 2) In macro factors, we try to understand the correlations of clicks between organic search and sponsored search. Based on this data analysis, we propose novel click models which harvest these new explored factors. To the best of our knowledge, this is the first paper to examine and model the effects of the above contextual factors in sponsored search. Extensive experiments on large-scale real-world datasets show that by incorporating these contextual factors, our novel click models can outperform state-of-the-art methods.",2014,Web Search and Data Mining,Fields of study: click through ratedata scienceworld wide webdata mining
Understanding and promoting micro-finance activities in Kiva.org,Jaegul Choo (Georgia Institute of Technology)Changhyun Lee (Georgia Institute of Technology)Daniel Lee (Georgia Tech Research Institute)Hongyuan Zha (Georgia Institute of Technology)Haesun Park (Georgia Institute of Technology),"2148380128,2597514406,2430643664,2099091510,2123241397","Non-profit Micro-finance organizations provide loaning opportunities to eradicate poverty by financially equipping impoverished, yet skilled entrepreneurs who are in desperate need of an institution that lends to those who have little. Kiva.org, a widely-used crowd-funded micro-financial service, provides researchers with an extensive amount of publicly available data containing a rich set of heterogeneous information regarding micro-financial transactions. Our objective in this paper is to identify the key factors that encourage people to make micro-financing donations, and ultimately, to keep them actively involved. In our contribution to further promote a healthy micro-finance ecosystem, we detail our personalized loan recommendation system which we formulate as a supervised learning problem where we try to predict how likely a given lender will fund a new loan. We construct the features for each data item by utilizing the available connectivity relationships in order to integrate all the available Kiva data sources. For those lenders with no such relationships, e.g., first-time lenders, we propose a novel method of feature construction by computing joint nonnegative matrix factorizations. Utilizing gradient boosting tree methods, a state-of-the-art prediction model, we are able to achieve up to 0.92 AUC (area under the curve) value, which shows the potential of our methods for practical deployment. Finally, we point out several interesting phenomena on lenders' social behaviors in micro-finance activities.",2014,Web Search and Data Mining,Fields of study: gradient boostingcold startmicrofinancerecommender systemworld wide webdata miningmachine learningsimulationcomputer science
Multilinear Factorization Machines for Multi-Task Multi-View Learning,Chun-Ta Lu (University of Illinois at Chicago)Lifang He (Shenzhen University)Weixiang Shao (University of Illinois at Chicago)Bokai Cao (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2224372854,2555188826,2151340973,2131202988,2125104194","Many real-world problems, such as web image analysis, document categorization and product recommendation, often exhibit dual-heterogeneity: heterogeneous features obtained in multiple views, and multiple tasks might be related to each other through one or more shared views. To address these Multi-Task Multi-View (MTMV) problems, we propose a tensor-based framework for learning the predictive multilinear structure from the full-order feature interactions within the heterogeneous data. The usage of tensor structure is to strengthen and capture the complex relationships between multiple tasks with multiple views. We further develop efficient multilinear factorization machines (MFMs) that can learn the task-specific feature map and the task-view shared multilinear structures, without physically building the tensor. In the proposed method, a joint factorization is applied to the full-order interactions such that the consensus representation can be learned. In this manner, it can deal with the partially incomplete data without difficulty as the learning procedure does not simply rely on any particular view. Furthermore, the complexity of MFMs is linear in the number of parameters, which makes MFMs suitable to large-scale real-world problems. Extensive experiments on four real-world datasets demonstrate that the proposed method significantly outperforms several state-of-the-art methods in a wide variety of MTMV problems.",2017,Web Search and Data Mining,Fields of study: multilinear subspace learningmultilinear principal component analysistheoretical computer sciencedata miningmachine learning
Joint training for open-domain extraction on the web: exploiting overlap when supervision is limited,Rahul Gupta (Indian Institute of Technology Bombay)Sunita Sarawagi (Indian Institute of Technology Bombay),"2223724845,156875573","We consider the problem of jointly training structured models for extraction from multiple web sources whose records enjoy partial content overlap . This has important applications in open-domain extraction, e.g. a user materializing a table of interest from multiple relevant unstructured sources; or a site like Freebase augmenting an incomplete relation by extracting more rows from web sources. Such applications require extraction over arbitrary domains, so one cannot use a pre-trained extractor or demand a huge labeled dataset. We propose to overcome this lack of supervision by using content overlap across the related web sources. Existing methods of exploiting overlap have been developed under settings that do not generalize easily to the scale and diversity of overlap seen on Web sources. We present an agreement-based learning framework that jointly trains the models by biasing them to agree on the agreement regions , i.e. shared text segments. We present alternatives within our framework to trade-off tractability, robustness to noise, and extent of agreement enforced; and propose a scheme of partitioning agreement regions that leads to efficient training while maximizing overall accuracy. Further, we present a principled scheme to discover low-noise agreement regions in unlabeled data across multiple sources. Through extensive experiments over 58 different extraction domains, we establish that our framework provides significant boosts over uncoupled training, and scores over alternatives such as collective inference, staged training, and multi-view learning.",2011,Web Search and Data Mining,Fields of study: graphical modelinformation extractiondata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Quality Management in Crowdsourcing using Gold Judges Behavior,Gabriella Kazai (Microsoft)Imed Zitouni (Microsoft),"114700236,2507515815","Crowdsourcing relevance labels has become an accepted practice for the evaluation of IR systems, where the task of constructing a test collection is distributed over large populations of unknown users with widely varied skills and motivations. Typical methods to check and ensure the quality of the crowd's output is to inject work tasks with known answers (gold tasks) on which workers' performance can be measured. However, gold tasks are expensive to create and have limited application. A more recent trend is to monitor the workers' interactions during a task and estimate their work quality based on their behavior. In this paper, we show that without gold behavior signals that reflect trusted interaction patterns, classifiers can perform poorly, especially for complex tasks, which can lead to high quality crowd workers getting blocked while poorly performing workers remain undetected. Through a series of crowdsourcing experiments, we compare the behaviors of trained professional judges and crowd workers and then use the trained judges' behavior signals as gold behavior to train a classifier to detect poorly performing crowd workers. Our experiments show that classification accuracy almost doubles in some tasks with the use of gold behavior data.",2016,Web Search and Data Mining,Fields of study: measurementworld wide webcomputer securitydata miningmachine learningsimulationcomputer science
Result enrichment in commerce search using browse trails,Debmalya Panigrahi (Massachusetts Institute of Technology)Sreenivas Gollapudi (Microsoft),"2138771547,2023254819","Commerce search engines have become popular in recent years, as users increasingly search for (and buy) products on the web. In response to an user query, they surface links to products in their catalog (or index) that match the requirements specified in the query. Often, few or no product in the catalog matches the user query exactly, and the search engine is forced to return a set of products that partially match the query. This paper considers the problem of choosing a set of products in response to an user query, so as to ensure maximum user satisfaction. We call this the result enrichment problem in commerce search. The challenge in result enrichment is two-fold: the search engine needs to estimate the extent to which a user genuinely cares about an attribute that she has specified in a query; then, it must display products in the catalog that match the user requirement on the important attributes, but have a similar but possibly non-identical value on the less important ones. To this end, we propose a technique for measuring the importance of individual attribute values and the similarity between different values of an attribute. A novelty of our approach is that we use entire browse trails, rather than just clickthrough rates, in this estimation algorithm. We develop a model for this problem, propose an algorithm to solve it, and support our theoretical findings via experiments conducted on actual user data.",2011,Web Search and Data Mining,Fields of study: rankingweb search queryweb query classificationstreaming algorithmquery expansionsearch engineworld wide webinformation retrievaldata miningdatabasecomputer science
Language models for keyword search over data graphs,Yosi Mass (IBM)Yehoshua Sagiv (Hebrew University of Jerusalem),"2117117435,734152518","In keyword search over data graphs, an answer is a non-redundant subtree that includes the given keywords. This paper focuses on improving the effectiveness of that type of search. A novel approach that combines language models with structural relevance is described. The proposed approach consists of three steps. First, language models are used to assign dynamic, query-dependent weights to the graph. Those weights complement static weights that are pre-assigned to the graph. Second, an existing algorithm returns candidate answers based on their weights. Third, the candidate answers are re-ranked by creating a language model for each one. The effectiveness of the proposed approach is verified on a benchmark of three datasets: IMDB, Wikipedia and Mondial. The proposed approach outperforms all existing systems on the three datasets, which is a testament to its robustness. It is also shown that the effectiveness can be further improved by augmenting keyword queries with very basic knowledge about the structure.",2012,Web Search and Data Mining,Fields of study: rankinglanguage modelnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Sponsored search auctions with conflict constraints,Panagiotis Papadimitriou (Stanford University)Hector Garcia-Molina (Stanford University),"2027183093,237419955","In sponsored search auctions advertisers compete for ad slots in the search engine results page, by bidding on keywords of interest. To improve advertiser expressiveness, we augment the bidding process with conflict constraints. With such constraints, advertisers can condition their bids on the non-appearance of certain undesired ads on the results page. We study the complexity of the allocation problem in these augmented SSA and we introduce an algorithm that can efficiently allocate the ad slots to advertisers. We evaluate the algorithm run time in simulated conflict scenarios and we study the implications of the conflict constraints on search engine revenue. Our results show that the allocation problem can be solved within few tens of milliseconds and that the adoption of conflict constraints can potentially increase search engine revenue.",2012,Web Search and Data Mining,Fields of study: branch and boundsearch engineworld wide websimulationcomputer science
Portrait of an Online Shopper: Understanding and Predicting Consumer Behavior,Farshad Kooti (University of Southern California)Kristina Lerman (University of Southern California)Luca Maria Aiello (Yahoo!)Mihajlo Grbovic (Yahoo!)Nemanja Djuric (Yahoo!)Vladan Radosavljevic (Yahoo!),"1923168926,2149625712,2072290952,2000240052,2128657275,1981991050","Consumer spending accounts for a large fraction of economic footprint of modern countries. Increasingly, consumer activity is moving to the web, where digital receipts of online purchases provide valuable data sources detailing consumer behavior. We consider such data extracted from emails and combined with with consumers' demographic information, which we use to characterize, model, and predict purchasing behavior. We analyze such behavior of consumers in different age and gender groups, and find interesting, actionable patterns that can be used to improve ad targeting systems. For example, we found that the amount of money spent on online purchases grows sharply with age, peaking in the late 30s, while shoppers from wealthy areas tend to purchase more expensive items and buy them more frequently. Furthermore, we look at the influence of social connections on purchasing habits, as well as at the temporal dynamics of online shopping where we discovered daily and weekly behavioral patterns. Finally, we build a model to predict when shoppers are most likely to make a purchase and how much will they spend, showing improvement over baseline approaches. The presented results paint a clear picture of a modern online shopper, and allow better understanding of consumer behavior that can help improve marketing efforts and make shopping more pleasant and efficient experience for online customers.",2016,Web Search and Data Mining,Fields of study: predictionstatisticsmathematics
Learning to rank with multi-aspect relevance for vertical search,Changsung Kang (Yahoo!)Xuanhui Wang (Yahoo!)Yi Chang (Yahoo!)Belle L. Tseng (Yahoo!),"2672672574,2102775025,2168000538,1990119318","Many vertical search tasks such as local search focus on specific domains. The meaning of relevance in these verticals is domain-specific and usually consists of multiple well-defined aspects (e.g., text matching and distance in local search). Thus the overall relevance between a query and a document is a tradeoff between multiple relevance aspects. Such a tradeoff can vary for different types of queries or in different contexts. In this paper, we explore these vertical-specific aspects in the learning to rank setting. We propose a novel formulation in which the relevance between a query and a document is assessed with respect to each aspect, forming the multi-aspect relevance. In order to compute a ranking function, we study two types of learning-based approaches to estimate the tradeoff between these relevance aspects: a label aggregation method and a model aggregation method. Since there are only a few aspects, a minimal amount of training data is needed to learn the tradeoff. We conduct both offline and online test experiments on a local search engine and the experimental results show that our proposed multi-aspect relevance formulation is very promising. The two types of aggregation methods perform more effectively than a set of baseline methods including a conventional learning to rank method.",2012,Web Search and Data Mining,Fields of study: rankinglocal searchlearning to rankinformation retrievaldata miningmachine learningcomputer science
NCDawareRank: a novel ranking method that exploits the decomposable structure of the web,Athanasios N. Nikolakopoulos (University of Patras)John D. Garofalakis (University of Patras),"743683647,1060563842","Research about the topological characteristics of the hyperlink graph has shown that Web possesses a nested block structure, indicative of its innate hierarchical organization. This crucial observation opens the way for new approaches that can usefully regard Web as a Nearly Completely Decomposable(NCD) system; In recent years, such approaches gave birth to various efficient methods and algorithms that exploit NCD from a computational point of view and manage to considerably accelerate the extraction of the PageRank vector. However, very little have been done towards the qualitative exploitation of NCD. In this paper we propose NCDawareRank, a novel ranking method that uses the intuition behind NCD to generalize and refine PageRank. NCDawareRank considers both the link structure and the hierarchical nature of the Web in a way that preserves the mathematically attractive characteristics of PageRank and at the same time manages to successfully resolve many of its known problems, including Web Spamming Susceptibility and Biased Ranking of Newly Emerging Pages. Experimental results show that NCDawareRank is more resistant to direct manipulation, alleviates the problems caused by the sparseness of the link graph and assigns more reasonable ranking scores to newly added pages, while maintaining the ability to be easily implemented on a large-scale and in a computationally efficient manner.",2013,Web Search and Data Mining,Fields of study: link farmrankinglink analysissparsity of effects principletheoretical computer science +4 others
Predicting future reviews: sentiment analysis models for collaborative filtering,Noriaki Kawamae (Tokyo Denki University),279243410,"This paper presents hierarchical topic models for integrating sentiment analysis with collaborative filtering. Our goal is to automatically predict future reviews to a given author from previous reviews. For this goal, we focus on differentiating author's preference, while previous sentiment analysis models process these review articles without this difference. Therefore, we propose a Latent Evaluation Topic model (LET) that infer each author's preference by introducing novel latent variables into author and his/her document layer. Because these variables distinguish the variety of words in each article by merging similar word distributions, LET incorporates the difference of writers' preferences into sentiment analysis. Consequently LET can determine the attitude of writers, and predict their reviews based on like-minded writers' reviews in the collaborative filtering approach. Experiments on review articles show that the proposed model can reduce the dimensionality of reviews to the low-dimensional set of these latent variables, and is a significant improvement over standard sentiment analysis models and collaborative filtering algorithms.",2011,Web Search and Data Mining,Fields of study: probabilistic latent semantic analysislatent variable modelcollaborative filteringlatent variablesentiment analysis +7 others
Social collaborative retrieval,Ko-Jen Hsiao (University of Michigan)Alex Kulesza (University of Michigan)Alfred O. Hero (University of Michigan),"2148582035,2064347415,2139712442","Socially-based recommendation systems have recently attracted significant interest, and a number of studies have shown that social information can dramatically improve a system's predictions of user interests. Meanwhile, there are now many potential applications that involve aspects of both recommendation and information retrieval, and the task of collaborative retrieval---a combination of these two traditional problems---has recently been introduced. Successful collaborative retrieval requires overcoming severe data sparsity, making additional sources of information, such as social graphs, particularly valuable. In this paper we propose a new model for collaborative retrieval, and show that our algorithm outperforms current state-of-the-art approaches by incorporating information from social networks. We also provide empirical analyses of the ways in which cultural interests propagate along a social graph using a real-world music dataset.",2014,Web Search and Data Mining,Fields of study: cognitive models of information retrievalhuman computer information retrievalcollaborative filteringsocial networkworld wide web +4 others
Shopping for products you don't know you need,Srikanth Jagabathula (Massachusetts Institute of Technology)Nina Mishra (Microsoft)Sreenivas Gollapudi (Microsoft),"233778557,2124493348,2023254819","Recommendation engines today suggest one product to another, e.g., an accessory to a product. However, intent to buy often precedes a user's appearance in a commerce vertical: someone interested in buying a skateboard may have earlier searched for {varial heelflip}, a trick performed on a skateboard. This paper considers how a search engine can provide early warning of commercial intent. The naive algorithm of counting how often an interest precedes a commercial query is not sufficient due to the number of related ways of expressing an interest. Thus, methods are needed for finding sets of queries where all pairs are related, what we call a query community , and this is the technical contribution of the paper. We describe a random model by which we obtain relationships between search queries and then prove general conditions under which we can reconstruct query communities. We propose two complementary approaches for inferring recommendations that utilize query communities in order to magnify the recommendation signal beyond what an individual query can provide. An extensive series of experiments on real search logs shows that the query communities found by our algorithm are more interesting and unexpected than a baseline of clustering the query-click graph. Also, whereas existing query suggestion algorithms are not designed for making commercial recommendations, we show that our algorithms do succeed in forecasting commercial intent. Query communities increase both the quantity and quality of recommendations.",2011,Web Search and Data Mining,Fields of study: sargablerankingrange queryweb query classificationquery expansion +7 others
Inferring search behaviors using partially observable markov model with duration (POMD),Yin He (University of Science and Technology of China)Kuansan Wang (Microsoft),"2632315648,2127379895","This paper presents Partially Observable Markov model with Duration (POMD), a statistical method that addresses the challenge of understanding sophisticated user behaviors from the search log in which some user actions, such as reading and skipping search results, cannot be observed and recorded. POMD utilizes not only the positional but also the temporal information of the clicks in the log. In this work, we treat the user engagements with a search engine as a Markov process, and model the unobservable engagements as hidden states. POMD differs from the traditional hidden Markov model (HMM) in that not all the hidden state transitions emit observable events, and that the duration of staying in each state is explicitly factored into the core statistical model. To address the training and decoding issues emerged as the results of the variations, we propose an iterative two-stage training algorithm and a greedy segmental decoding algorithm respectively. We validate the proposed algorithm with two sets of experiments. First, we show that the search behavioral patterns inferred by POMD match well with those reported in the eye tracking experiments. Secondly, through a series of A/B comparison experiments, we demonstrate that POMD can distinguish the ranking qualities of different search engine configurations much better than the patterns inferred by the model proposed in the previous work. Both of the experimental results suggest that POMD can provide a statistical and quantitative way to understand the sophisticated search behaviors by simply mining the search logs.",2011,Web Search and Data Mining,Fields of study: hidden semi markov modeleye trackingdurationmarkov modelsearch engine +8 others
"User Browsing Graph: Structure, Evolution and Application.",Yiqun Liu (Tsinghua University)Min Zhang 0006 (Tsinghua University)Shaoping Ma (Tsinghua University)Liyun Ru (Tsinghua University),"2111097927,2526008467,2109195263,2113600213",-,2009,Web Search and Data Mining,Fields of study: search analyticsweb modelinglink farmweb search queryweb accessibility +9 others
A model for fast web mining prototyping,R Álvaro Pereira (Universidade Federal de Minas Gerais)Ricardo A. Baeza-Yates (Yahoo!)Nivio Ziviani (Universidade Federal de Minas Gerais)Jesus Bisbal (Pompeu Fabra University),"2163577707,528588921,252533809,2048581437","Web mining is a computation intensive task, even after the mining tool itself has been developed. Most mining software are developed ad-hoc and usually are not scalable nor reused for other mining tasks. The objective of this paper is to present a model for fast Web mining prototyping, referred to as WIM -- Web Information Mining. The underlying conceptual model of WIM provides its users with a level of abstraction appropriate for prototyping and experimentation throughout the Web data mining task. Abstracting from the idiosyncrasies of raw Web data representations facilitates the inherently iterative mining process. We present the WIM conceptual model, its associated algebra, and the WIM tool software architecture, which implements the WIM model. We also illustrate how the model can be applied to real Web data mining tasks. The experimentation of WIM in real use cases has shown to significantly facilitate Web mining prototyping.",2009,Web Search and Data Mining,Fields of study: web modelingweb mappingassociative algebrause casesoftware architecture +11 others
Diluted Treatment Effect Estimation for Trigger Analysis in Online Controlled Experiments,Alex Deng (Microsoft)Victor Hu (Microsoft),"2172042952,2223791086","Online controlled experiments, also called A/B testing, is playing a central role in many data-driven web-facing companies. It is well known and intuitively obvious to many practitioners that when testing a feature with low coverage, analyzing all data collected without zooming into the part that could be affected by the treatment often leads to under-powered hypothesis testing. A common practice is to use triggered analysis. To estimate the overall treatment effect, certain dilution formula is then applied to translate the estimated effect in triggered analysis back to the original all up population. In this paper, we discuss two different types of trigger analyses. We derive correct dilution formulas and show for a set of widely used metrics, namely ratio metrics, correctly deriving and applying those dilution formulas are not trivial. We observe many practitioners in this industry are often applying approximate formulas or even wrong formulas when doing effect dilution calculation. To deal with that, instead of estimating trigger treatment effect followed by effect translation using dilution formula, we aim at combining these two steps into one streamlined analysis, producing more accurate estimation of overall treatment effect together with even higher statistical power than a triggered analysis. The approach we propose in this paper is intuitive, easy to apply and general enough for all types of triggered analyses and all types of metrics.",2015,Web Search and Data Mining,Fields of study: dilutionvariance reductionmetricdata miningstatistics
Who Will Reply to/Retweet This Tweet?: The Dynamics of Intimacy from Online Social Interactions,Nicholas Jing Yuan (Microsoft)Yuan Zhong (Northeastern University)Fuzheng Zhang (Microsoft)Xing Xie (Microsoft)Chin-Yew Lin (Microsoft)Yong Rui (Microsoft),"2096490164,2222092705,2110384818,2125800575,2159460278,2130014478","Friendships are dynamic. Previous studies have converged to suggest that social interactions, in both online and offline social networks, are diagnostic reflections of friendship relations (also called social ties). However, most existing approaches consider a social tie as either a binary relation, or a fixed value (named tie strength). In this paper, we investigate the dynamics of dyadic friend relationships through online social interactions, in terms of a variety of aspects, such as reciprocity, temporality, and contextuality. In turn, we propose a model to predict repliers and retweeters given a particular tweet posted at a certain time in a microblog-based social network. More specifically, we have devised a learning-to-rank approach to train a ranker that considers elaborate user-level and tweet-level features (like sentiment, self-disclosure, and responsiveness) to address these dynamics. In the prediction phase, a tweet posted by a user is deemed a query and the predicted repliers/retweeters are retrieved using the learned ranker. We have collected a large dataset containing 73.3 million dyadic relationships with their interactions (replies and retweets). Extensive experimental results based on this dataset show that by incorporating the dynamics of friendship relations, our approach significantly outperforms state-of-the-art models in terms of multiple evaluation metrics, such as MAP, NDCG and Topmost Accuracy. In particular, the advantage of our model is even more promising in predicting the exact sequence of repliers/retweeters considering their orders. Furthermore, the proposed approach provides emerging implications for many high-value applications in online social networks.",2016,Web Search and Data Mining,Fields of study: world wide webdata miningartificial intelligencemachine learning
MergeRUCB: A Method for Large-Scale Online Ranker Evaluation,Masrour Zoghi (University of Amsterdam)Shimon Whiteson (University of Amsterdam)Maarten de Rijke (University of Amsterdam),"2170892963,2042571382,401833296","A key challenge in information retrieval is that of on-line ranker evaluation: determining which one of a finite set of rankers performs the best in expectation on the basis of user clicks on presented document lists. When the presented lists are constructed using interleaved comparison methods, which interleave lists proposed by two different candidate rankers, then the problem of minimizing the total regret accumulated while evaluating the rankers can be formalized as a K-armed dueling bandit problem. In the setting of web search, the number of rankers under consideration may be large. Scaling effectively in the presence of so many rankers is a key challenge not adequately addressed by existing algorithms. We propose a new method, which we call mergeRUCB, that uses ""localized"" comparisons to provide the first provably scalable K-armed dueling bandit algorithm. Empirical comparisons on several large learning to rank datasets show that mergeRUCB can substantially outperform the state of the art K-armed dueling bandit algorithms when many rankers must be compared. Moreover, we provide theoretical guarantees demonstrating the soundness of our algorithm.",2015,Web Search and Data Mining,Fields of study: evaluationtheoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer science
The Power of Random Neighbors in Social Networks,Silvio Lattanzi (Google)Yaron Singer (Harvard University),"1989808900,2155009540","The friendship paradox is a sociological phenomenon first discovered by Feld which states that individuals are likely to have fewer friends than their friends do, on average. This phenomenon has become common knowledge, has several interesting applications, and has also been observed in various data sets. In his seminal paper Feld provides an intuitive explanation by showing that in any graph the average degree of edges in the graph is an upper bound on the average degree of nodes. Despite the appeal of this argument, it does not prove the existence of the friendship paradox. In fact, it is easy to construct networks -- even with power law degree distributions -- where the ratio between the average degree of neighbors and the average degree of nodes is high, but all nodes have the exact same degree as their neighbors. Which models, then, explain the friendship paradox? In this paper we give a strong characterization that provides a formal understanding of the friendship paradox. We show that for any power law graph with exponential parameter in (1,3), when every edge is rewired with constant probability, the friendship paradox holds, i.e. there is an asymptotic gap between the average degree of the sample of polylogarithmic size and the average degree of a random set of its neighbors of equal size. To examine this characterization on real data, we performed several experiments on social network data sets that complement our theoretical analysis. We also discuss the applications of our result to influence maximization.",2015,Web Search and Data Mining,Fields of study: friendship paradoxdegree distributionsocial network
A probabilistic approach for learning folksonomies from structured data,"Anon Plangprasopchok (Information Sciences Institute)Kristina Lerman (Information Sciences Institute)Lise Getoor (University of Maryland, College Park)","150165597,2149625712,1984940772","Learning structured representations has emerged as an important problem in many domains, including document and Web data mining, bioinformatics, and image analysis. One approach to learning complex structures is to integrate many smaller, incomplete and noisy structure fragments. In this work, we present an unsupervised probabilistic approach that extends affinity propagation [7] to combine the small ontological fragments into a collection of integrated, consistent, and larger folksonomies. This is a challenging task because the method must aggregate similar structures while avoiding structural inconsistencies and handling noise. We validate the approach on a real-world social media dataset, comprised of shallow personal hierarchies specified by many individual users, collected from the photosharing website Flickr. Our empirical results show that our proposed approach is able to construct deeper and denser structures, compared to an approach using only the standard affinity propagation algorithm. Additionally, the approach yields better overall integration quality than a state-of-the-art approach based on incremental relational clustering.",2011,Web Search and Data Mining,Fields of study: affinity propagationsocial information processingsocial mediacollective intelligencegeneralized complex structuredata modelimage analysisdata scienceworld wide webdata miningartificial intelligencemachine learningcomputer science
Fast top-k retrieval for model based recommendation,Deepak Agarwal (Yahoo!)Maxim Gurevich (Yahoo!),"2591515730,2027890328","A crucial task in many recommender problems like computational advertising, content optimization, and others is to retrieve a small set of items by scoring a large item inventory through some elaborate statistical/machine-learned model. This is challenging since the retrieval has to be fast (few milliseconds) to load the page quickly. Fast retrieval is well studied in the information retrieval (IR) literature, especially in the context of document retrieval for queries. When queries and documents have sparse representation and relevance is measured through cosine similarity (or some variant thereof), one could build highly efficient retrieval algorithms that scale gracefully to increasing item inventory. The key components exploited by such algorithms is sparse query-document representation and the special form of the relevance function. Many machine-learned models used in modern recommender problems do not satisfy these properties and since brute force evaluation is not an option with large item inventory, heuristics that filter out some items are often employed to reduce model computations at runtime. In this paper, we take a two-stage approach where the first stage retrieves top-K items using our approximate procedures and the second stage selects the desired top-k using brute force model evaluation on the K retrieved items. The main idea of our approach is to reduce the first stage to a standard IR problem, where each item is represented by a sparse feature vector (a.k.a. the vector-space representation) and the query-item relevance score is given by vector dot product. The sparse item representation is learnt to closely approximate the original machine-learned score by using retrospective data. Such a reduction allows leveraging extensive work in IR that resulted in highly efficient retrieval systems. Our approach is model-agnostic, relying only on data generated from the machine-learned model. We obtain significant improvements in the computational cost vs. accuracy tradeoff compared to several baselines in our empirical evaluation on both synthetic models and on a click-through (CTR) model used in online advertising.",2012,Web Search and Data Mining,Fields of study: support vector machineonline advertisingdocument retrievalworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Incorporating Phrase-level Sentiment Analysis on Textual Reviews for Personalized Recommendation,Yongfeng Zhang (Tsinghua University),2706158359,"Previous research on Recommender Systems (RS), especially the continuously popular approach of Collaborative Filtering (CF), has been mostly focusing on the information resource of explicit user numerical ratings or implicit (still numerical) feedbacks. However, the ever-growing availability of textual user reviews has become an important information resource, where a wealth of explicit product attributes/features and user attitudes/sentiments are expressed therein. This information rich resource of textual reviews have clearly exhibited brand-new approaches to solving many of the important problems that have been perplexing the research community for years, such as the paradox of cold-start, the explanation of recommendation, and the automatic generation of user or item profiles. However, it is only recently that the fundamental importance of textual reviews has gained wide recognition, perhaps mainly because of the difficulty in formatting, structuring and analyzing the free-texts. In this research, we stress the importance of incorporating textual reviews for recommendation through phrase-level sentiment analysis, and further investigate the role that the texts play in various important recommendation tasks.",2015,Web Search and Data Mining,Fields of study: collaborative filteringsentiment analysistext miningworld wide webinformation retrievaldata miningmachine learningcomputer science
Incorporating revisiting behaviors into click models,Danqing Xu (Tsinghua University)Yiqun Liu (Tsinghua University)Min Zhang (Tsinghua University)Shaoping Ma (Tsinghua University)Liyun Ru (Tsinghua University),"2166503173,2111097927,2526008467,2109195263,2113600213","Click-through behaviors are treated as invaluable sources of user feedback and they have been leveraged in several commercial search engines in recent years. However, estimating unbiased relevance is always a challenging task because of position bias. To solve this problem, many researchers have proposed a variety of assumptions to model click-through behaviors. Most of these models share a common examination hypothesis, which is that users examine search results from the top to the bottom. Nevertheless, this model cannot draw a complete picture of information-seeking behaviors. Many eye-tracking studies find that user interactions are not sequential but contain revisiting patterns. If a user clicks on a higher ranked document after having clicked on a lower-ranked one, we call this scenario a revisiting pattern, and we believe that the revisiting patterns are important signals regarding a user's click preferences. This paper incorporates revisiting behaviors into click models and introduces a novel click model named Temporal Hidden Click Model (THCM). This model dynamically models users' click behaviors with a temporal order. In our experiment, we collect over 115 million query sessions from a widely-used commercial search engine and then conduct a comparative analysis between our model and several state-of-the-art click models. The experimental results show that the THCM model achieves a significant improvement in the Normalized Discounted Cumulative Gain (NDCG), the click perplexity and click distributions metrics.",2012,Web Search and Data Mining,Fields of study: click patheye trackingsearch enginequalitative comparative analysiscumulantmultimediaworld wide webmachine learningsimulationstatisticscomputer science
Hierarchical Semi-supervised Classification with Incomplete Class Hierarchies,Bhavana Dalvi (Carnegie Mellon University)Aditya Kumar Mishra (Seattle University)William W. Cohen (Carnegie Mellon University),"2081006310,2192177076,2115385359","In an entity classification task, topic or concept hierarchies are often incomplete. Previous work by Dalvi et al. [12] has showed that in non-hierarchical semi-supervised classification tasks, the presence of such unanticipated classes can cause semantic drift for seeded classes. The Exploratory learning [12] method was proposed to solve this problem; however it is limited to the flat classification task. This paper builds such exploratory learning methods for hierarchical classification tasks. We experimented with subsets of the NELL [8] ontology and text, and HTML table datasets derived from the ClueWeb09 corpus. Our method (OptDAC-ExploreEM) outperforms the existing Exploratory EM method, and its naive extension (DAC-ExploreEM), in terms of seed class F1 on average by 10% and 7% respectively.",2016,Web Search and Data Mining,Fields of study: one class classificationsemi supervised learningdata miningpattern recognitionmachine learningcomputer science
EgoSet: Exploiting Word Ego-networks and User-generated Ontology for Multifaceted Set Expansion,Xin Rong (University of Michigan)Zhe Chen (University of Michigan)Qiaozhu Mei (University of Michigan)Eytan Adar (University of Michigan),"2145659280,2302085265,2166036605,2305277957","A key challenge of entity set expansion is that multifaceted input seeds can lead to significant incoherence in the result set. In this paper, we present a novel solution to handling multifaceted seeds by combining existing user-generated ontologies with a novel word-similarity metric based on skip-grams. By blending the two resources we are able to produce sparse word ego-networks that are centered on the seed terms and are able to capture semantic equivalence among words. We demonstrate that the resulting networks possess internally-coherent clusters, which can be exploited to provide non-overlapping expansions, in order to reflect different semantic classes of the seeds. Empirical evaluation against state-of-the-art baselines shows that our solution, EgoSet, is able to not only capture multiple facets in the input query, but also generate expansions for each facet with higher precision.",2016,Web Search and Data Mining,Fields of study: web mininginformation extractioninformation retrievaldata miningmachine learningcomputer science
On discovering non-obvious recommendations: using unexpectedness and neighborhood selection methods in collaborative filtering systems,Panagiotis Adamopoulos (New York University Stern School of Business),2308814756,"This paper proposes a number of studies in order to move the field of recommender systems beyond the traditional paradigm and the classical perspective of rating prediction accuracy. We contribute to existing helpful but less explored recommendation strategies and propose new approaches targeting to more useful recommendations for both users and businesses. Working toward this direction, we discuss the studies we have conducted so far and present our future research plans. The overall goal of this research program is to expand our focus from even more accurate rating predictions toward a more holistic experience for the users, by providing them with non-obvious but high quality recommendations and avoiding the over-specialization and concentration bias problems. In particular, we propose a new probabilistic neighborhood-based method as an improvement of the standard $k$-nearest neighbors approach, alleviating some of the most common problems of collaborative filtering recommender systems, based on classical metrics of dispersion and diversity as well as some newly proposed metrics. Furthermore, we propose a concept of unexpectedness in recommender systems and operationalize it by suggesting various mechanisms for specifying the expectations of the users and proposing a recommendation method for providing the users with unexpected but high quality personalized recommendations that fairly match their interests. Besides, in order to generate utility-based recommendations for Massive Open Online Courses (MOOCs) that better serve the educational needs of students, we study the satisfaction of users with online courses vis-a-vis student retention. Finally, we summarize the conclusions of the conducted studies, discuss the limitations of our work and also outline the managerial implications of the proposed stream of research.",2014,Web Search and Data Mining,Fields of study: algorithm designrecommender systemknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
Enforcing k-anonymity in Web Mail Auditing,Dotan Di Castro (Yahoo!)Liane Lewin-Eytan (Yahoo!)Yoelle Maarek (Yahoo!)Ran Wolff (Yahoo!)Eyal Zohar (Yahoo!),"2163216773,2022197843,262608878,2343137924,2232485004","We study the problem of k-anonymization of mail messages in the realistic scenario of auditing mail traffic in a major commercial Web mail service. Mail auditing is necessary in various Web mail debugging and quality assurance activities, such as anti-spam or the qualitative evaluation of novel mail features. It is conducted by trained professionals, often referred to as ""auditors"", who are shown messages that could expose personally identifiable information. We address here the challenge of k-anonymizing such messages, focusing on machine generated mail messages that represent more than 90% of today's mail traffic. We introduce a novel message signature Mail-Hash , specifically tailored to identifying structurally-similar messages, which allows us to put such messages in a same equivalence class. We then define a process that generates, for each class, masked mail samples that can be shown to auditors, while guaranteeing the k-anonymity of users. The productivity of auditors is measured by the amount of non-hidden mail content they can see every day, while considering normal working conditions, which set a limit to the number of mail samples they can review. In addition, we consider k-anonymity over time since, by definition of k-anonymity, every new release places additional constraints on the assignment of samples. We describe in details the results we obtained over actual Yahoo mail traffic, and thus demonstrate that our methods are feasible at Web mail scale. Given the constantly growing concern of users over their email being scanned by others, we argue that it is critical to devise such algorithms that guarantee k-anonymity, and implement associated processes in order to restore the trust of mail users.",2016,Web Search and Data Mining,Fields of study: open mail relayquality assuranceinternet privacyworld wide webcomputer securitydata miningcomputer science
Efficient online ad serving in a display advertising exchange,Kevin J. Lang (Yahoo!)Joaquin Delgado (Yahoo!)Dongming Jiang (Yahoo!)Bhaskar Ghosh (LinkedIn)Shirshanka Das (LinkedIn)Amita Gajewar (Yahoo!)Swaroop Jagadish (Yahoo!)Arathi Seshan (Yahoo!)Chavdar Botev (LinkedIn)Michael Bindeberger-Ortega (Google)Sunil Nagaraj (Yahoo!)Raymie Stata (Yahoo!),"2126750883,2119581266,2309516219,2146212157,2183445425,1965592084,2141583939,1936962255,2229643139,2231511993,2614138978,2284088324","We introduce and formalize a novel constrained path optimization problem that is the heart of the real-time ad serving task in the Yahoo! (formerly RightMedia) Display Advertising Exchange. In the Exchange, the ad server's task for each display opportunity is to compute, with low latency, an optimal valid path through a directed graph representing the business arrangements between the hundreds of thousands of business entities that are participating in the Exchange. These entities include not only publishers and advertisers, but also intermediate entities called ""ad networks"" which have delegated their ad serving responsibilities to the Exchange. Path optimality is determined by the payment to the publisher, and is affected by an advertiser's bid and also by the revenue-sharing agreements between the entities in the chosen path leading back to the publisher. Path validity is determined by constraints which focus on the following three issues: 1) suitability of the opportunity's web page and its publisher 2)suitability of the user who is currently viewing that web page, and 3) suitability of a candidate ad and its advertiser. Because the Exchange's constrained path optimization task is novel, there are no published algorithms for it. This paper describes two different algorithms that have both been successfully used in the actual Yahoo! ad server. The first algorithm has the advantage of being extremely simple, while the second is more robust thanks to its polynomial worst-case running time. In both cases, meeting latency caps has required that the basic algorithms be improved by optimizations; we will describe a candidate ordering scheme and a pre-computation scheme that have both been effective in reducing latency in the real ad serving system that serves over ten billion ad calls per day.",2011,Web Search and Data Mining,Fields of study: low latencyweb pagedirected graphoptimization problemonline advertisinginternet privacyworld wide webinformation retrievaldistributed computingdata miningmachine learningcomputer science
Equality and Social Mobility in Twitter Discussion Groups,"Katherine Ellis (University of California, San Diego)Moisés Goldszmidt (Samsung)Gert R. G. Lanckriet (University of California, San Diego)Nina Mishra (Stanford University)Omer Reingold (Samsung)","2023840590,2342582627,2704758895,2124493348,2675525272","Online groups, including chat groups and forums, are becoming important avenues for gathering and exchanging information ranging from troubleshooting devices, to sharing experiences, to finding medical information and advice. Thus, issues about the health and stability of these groups are of particular interest to both industry and academia. In this paper we conduct a large scale study with the objectives of first, characterizing essential aspects of the interactions between the participants of such groups and second, characterizing how the nature of these interactions relate to the health of the groups. Specifically, we concentrate on Twitter Discussion Groups (TDGs), self-organized groups that meet on Twitter by agreeing on a hashtag, date and time. These groups have repeated, real-time meetings and are a rising phenomenon on Twitter. We examine the interactions in these groups in terms of the social equality and mobility of the exchange of attention between participants, according to the @mention convention on Twitter. We estimate the health of a group by measuring the retention rate of participants and the change in the number of meetings over time. We find that social equality and mobility are correlated, and that equality and mobility are related to a group's health. In fact, equality and mobility are as predictive of a group's health as some prior characteristics used to predict health of other online groups. Our findings are based on studying 100 thousand sessions of over two thousand discussion groups over the period of June 2012 to June 2013. These finding are not only relevant to stakeholders interested in maintaining these groups, but to researchers and academics interested in understanding the behavior of participants in online discussions. We also find the parallel with findings on the relationship between economic mobility and equality and health indicators in real-world nations striking and thought-provoking.",2016,Web Search and Data Mining,Fields of study: power graph analysisgenerative modelsocial networkworld wide websocial sciencedata miningmachine learningcomputer science
Engagement Periodicity in Search Engine Usage: Analysis and its Application to Search Quality Evaluation,Alexey Drutsa (Yandex)Gleb Gusev (Yandex)Pavel Serdyukov (Yandex),"2229408502,2005728791,2130450538","Nowadays, billions of people use the Web in connection with their daily needs. A significant part of the needs are constituted by search tasks that are usually addressed by search engines. Thus, daily search needs result in regular user engagement with a search engine. User engagement with web sites and services was studied in various aspects, but there appear to be no studies of its regularity and periodicity. In this paper, we studied periodicity of the user engagement with a popular search engine through applying spectrum analysis to temporal sequences of different engagement metrics. We found periodicity patterns of user engagement and revealed classes of users whose periodicity patterns do not change over a long period of time. In addition, we used the spectrum series as metrics to evaluate search quality.",2015,Web Search and Data Mining,Fields of study: discrete fourier transformspectrum analyzermultimediaworld wide websimulationcomputer science
Measuring the similarity between implicit semantic relations using web search engines,Danushka Bollegala (University of Tokyo)Yutaka Matsuo (University of Tokyo)Mitsuru Ishizuka (University of Tokyo),"2029493321,2717383051,1972809410","Measuring the similarity between implicit semantic relations is an important task in information retrieval and natural language processing. For example, consider the situation where you know an entity-pair (e.g. Google, YouTube ), between which a particular relation holds (e.g. acquisition), and you are interested in retrieving other entity-pairs for which the same relation holds (e.g. Yahoo, Inktomi ). Existing keyword-based search engines cannot be directly applied in this case because in keyword-based search, the goal is to retrieve documents that are relevant to the words used in the query -- not necessarily to the relations implied by a pair of words. Accurate measurement of relational similarity is an important step in numerous natural language processing tasks such as identification of word analogies, and classification of noun-modifier pairs. We propose a method that uses Web search engines to efficiently compute the relational similarity between two pairs of words. Our method consists of three components: representing the various semantic relations that exist between a pair of words using automatically extracted lexical patterns, clustering the extracted lexical patterns to identify the different semantic relations implied by them, and measuring the similarity between different semantic relations using an inter-cluster correlation matrix. We propose a pattern extraction algorithm to extract a large number of lexical patterns that express numerous semantic relations. We then present an efficient clustering algorithm to cluster the extracted lexical patterns. Finally, we measure the relational similarity between word-pairs using inter-cluster correlation. We evaluate the proposed method in a relation classification task. Experimental results on a dataset covering multiple relation types show a statistically significant improvement over the current state-of-the-art relational similarity measures.",2009,Web Search and Data Mining,Fields of study: semantic computingsemantic similaritynounnatural languagesearch enginecovariance matrixstatistical significancesemantic searchweb miningweb search enginenatural language processingworld wide webinformation retrievaldata miningcomputer science
Collective extraction from heterogeneous web lists,Ashwin Machanavajjhala (Yahoo!)Arun Shankar Iyer (Yahoo!)Philip Bohannon (Yahoo!)Srujana Merugu (Yahoo!),"2653972899,2128888966,2003419062,2019029176","Automatic extraction of structured records from inconsistently formatted lists on the web is challenging: different lists present disparate sets of attributes with variations in the ordering of attributes; many lists contain additional attributes and noise that can confuse the extraction process; and formatting within a list may be inconsistent due to missing attributes or manual formatting on some sites. We present a novel solution to this extraction problem that is based on i ) collective extraction from multiple lists simultaneously and ii ) careful exploitation of a small database of seed entities. Our approach addresses the layout homogeneity within the individual lists, content redundancy across some snippets from different sources, and the noisy attribute rendering process. We experimentally evaluate variants of this algorithm on real world data sets and show that our approach is a promising direction for extraction from noisy lists, requiring mild and thus inexpensive supervision suitable for extraction from the tail of the web.",2011,Web Search and Data Mining,Fields of study: bayesian inferencehidden markov modeldata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Who Will Reply to/Retweet This Tweet?: The Dynamics of Intimacy from Online Social Interactions,Nicholas Jing Yuan (Microsoft)Yuan Zhong (Northeastern University)Fuzheng Zhang (Microsoft)Xing Xie (Microsoft)Chin-Yew Lin (Microsoft)Yong Rui (Microsoft),"2096490164,2222092705,2110384818,2125800575,2159460278,2130014478","Friendships are dynamic. Previous studies have converged to suggest that social interactions, in both online and offline social networks, are diagnostic reflections of friendship relations (also called social ties). However, most existing approaches consider a social tie as either a binary relation, or a fixed value (named tie strength). In this paper, we investigate the dynamics of dyadic friend relationships through online social interactions, in terms of a variety of aspects, such as reciprocity, temporality, and contextuality. In turn, we propose a model to predict repliers and retweeters given a particular tweet posted at a certain time in a microblog-based social network. More specifically, we have devised a learning-to-rank approach to train a ranker that considers elaborate user-level and tweet-level features (like sentiment, self-disclosure, and responsiveness) to address these dynamics. In the prediction phase, a tweet posted by a user is deemed a query and the predicted repliers/retweeters are retrieved using the learned ranker. We have collected a large dataset containing 73.3 million dyadic relationships with their interactions (replies and retweets). Extensive experimental results based on this dataset show that by incorporating the dynamics of friendship relations, our approach significantly outperforms state-of-the-art models in terms of multiple evaluation metrics, such as MAP, NDCG and Topmost Accuracy. In particular, the advantage of our model is even more promising in predicting the exact sequence of repliers/retweeters considering their orders. Furthermore, the proposed approach provides emerging implications for many high-value applications in online social networks.",2016,Web Search and Data Mining,Fields of study: world wide webdata miningartificial intelligencemachine learning
MergeRUCB: A Method for Large-Scale Online Ranker Evaluation,Masrour Zoghi (University of Amsterdam)Shimon Whiteson (University of Amsterdam)Maarten de Rijke (University of Amsterdam),"2170892963,2042571382,401833296","A key challenge in information retrieval is that of on-line ranker evaluation: determining which one of a finite set of rankers performs the best in expectation on the basis of user clicks on presented document lists. When the presented lists are constructed using interleaved comparison methods, which interleave lists proposed by two different candidate rankers, then the problem of minimizing the total regret accumulated while evaluating the rankers can be formalized as a K-armed dueling bandit problem. In the setting of web search, the number of rankers under consideration may be large. Scaling effectively in the presence of so many rankers is a key challenge not adequately addressed by existing algorithms. We propose a new method, which we call mergeRUCB, that uses ""localized"" comparisons to provide the first provably scalable K-armed dueling bandit algorithm. Empirical comparisons on several large learning to rank datasets show that mergeRUCB can substantially outperform the state of the art K-armed dueling bandit algorithms when many rankers must be compared. Moreover, we provide theoretical guarantees demonstrating the soundness of our algorithm.",2015,Web Search and Data Mining,Fields of study: evaluationtheoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer science
The Power of Random Neighbors in Social Networks,Silvio Lattanzi (Google)Yaron Singer (Harvard University),"1989808900,2155009540","The friendship paradox is a sociological phenomenon first discovered by Feld which states that individuals are likely to have fewer friends than their friends do, on average. This phenomenon has become common knowledge, has several interesting applications, and has also been observed in various data sets. In his seminal paper Feld provides an intuitive explanation by showing that in any graph the average degree of edges in the graph is an upper bound on the average degree of nodes. Despite the appeal of this argument, it does not prove the existence of the friendship paradox. In fact, it is easy to construct networks -- even with power law degree distributions -- where the ratio between the average degree of neighbors and the average degree of nodes is high, but all nodes have the exact same degree as their neighbors. Which models, then, explain the friendship paradox? In this paper we give a strong characterization that provides a formal understanding of the friendship paradox. We show that for any power law graph with exponential parameter in (1,3), when every edge is rewired with constant probability, the friendship paradox holds, i.e. there is an asymptotic gap between the average degree of the sample of polylogarithmic size and the average degree of a random set of its neighbors of equal size. To examine this characterization on real data, we performed several experiments on social network data sets that complement our theoretical analysis. We also discuss the applications of our result to influence maximization.",2015,Web Search and Data Mining,Fields of study: friendship paradoxdegree distributionsocial network
A probabilistic approach for learning folksonomies from structured data,"Anon Plangprasopchok (Information Sciences Institute)Kristina Lerman (Information Sciences Institute)Lise Getoor (University of Maryland, College Park)","150165597,2149625712,1984940772","Learning structured representations has emerged as an important problem in many domains, including document and Web data mining, bioinformatics, and image analysis. One approach to learning complex structures is to integrate many smaller, incomplete and noisy structure fragments. In this work, we present an unsupervised probabilistic approach that extends affinity propagation [7] to combine the small ontological fragments into a collection of integrated, consistent, and larger folksonomies. This is a challenging task because the method must aggregate similar structures while avoiding structural inconsistencies and handling noise. We validate the approach on a real-world social media dataset, comprised of shallow personal hierarchies specified by many individual users, collected from the photosharing website Flickr. Our empirical results show that our proposed approach is able to construct deeper and denser structures, compared to an approach using only the standard affinity propagation algorithm. Additionally, the approach yields better overall integration quality than a state-of-the-art approach based on incremental relational clustering.",2011,Web Search and Data Mining,Fields of study: affinity propagationsocial information processingsocial mediacollective intelligencegeneralized complex structuredata modelimage analysisdata scienceworld wide webdata miningartificial intelligencemachine learningcomputer science
Fast top-k retrieval for model based recommendation,Deepak Agarwal (Yahoo!)Maxim Gurevich (Yahoo!),"2591515730,2027890328","A crucial task in many recommender problems like computational advertising, content optimization, and others is to retrieve a small set of items by scoring a large item inventory through some elaborate statistical/machine-learned model. This is challenging since the retrieval has to be fast (few milliseconds) to load the page quickly. Fast retrieval is well studied in the information retrieval (IR) literature, especially in the context of document retrieval for queries. When queries and documents have sparse representation and relevance is measured through cosine similarity (or some variant thereof), one could build highly efficient retrieval algorithms that scale gracefully to increasing item inventory. The key components exploited by such algorithms is sparse query-document representation and the special form of the relevance function. Many machine-learned models used in modern recommender problems do not satisfy these properties and since brute force evaluation is not an option with large item inventory, heuristics that filter out some items are often employed to reduce model computations at runtime. In this paper, we take a two-stage approach where the first stage retrieves top-K items using our approximate procedures and the second stage selects the desired top-k using brute force model evaluation on the K retrieved items. The main idea of our approach is to reduce the first stage to a standard IR problem, where each item is represented by a sparse feature vector (a.k.a. the vector-space representation) and the query-item relevance score is given by vector dot product. The sparse item representation is learnt to closely approximate the original machine-learned score by using retrospective data. Such a reduction allows leveraging extensive work in IR that resulted in highly efficient retrieval systems. Our approach is model-agnostic, relying only on data generated from the machine-learned model. We obtain significant improvements in the computational cost vs. accuracy tradeoff compared to several baselines in our empirical evaluation on both synthetic models and on a click-through (CTR) model used in online advertising.",2012,Web Search and Data Mining,Fields of study: support vector machineonline advertisingdocument retrievalworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Incorporating Phrase-level Sentiment Analysis on Textual Reviews for Personalized Recommendation,Yongfeng Zhang (Tsinghua University),2706158359,"Previous research on Recommender Systems (RS), especially the continuously popular approach of Collaborative Filtering (CF), has been mostly focusing on the information resource of explicit user numerical ratings or implicit (still numerical) feedbacks. However, the ever-growing availability of textual user reviews has become an important information resource, where a wealth of explicit product attributes/features and user attitudes/sentiments are expressed therein. This information rich resource of textual reviews have clearly exhibited brand-new approaches to solving many of the important problems that have been perplexing the research community for years, such as the paradox of cold-start, the explanation of recommendation, and the automatic generation of user or item profiles. However, it is only recently that the fundamental importance of textual reviews has gained wide recognition, perhaps mainly because of the difficulty in formatting, structuring and analyzing the free-texts. In this research, we stress the importance of incorporating textual reviews for recommendation through phrase-level sentiment analysis, and further investigate the role that the texts play in various important recommendation tasks.",2015,Web Search and Data Mining,Fields of study: collaborative filteringsentiment analysistext miningworld wide webinformation retrievaldata miningmachine learningcomputer science
Incorporating revisiting behaviors into click models,Danqing Xu (Tsinghua University)Yiqun Liu (Tsinghua University)Min Zhang (Tsinghua University)Shaoping Ma (Tsinghua University)Liyun Ru (Tsinghua University),"2166503173,2111097927,2526008467,2109195263,2113600213","Click-through behaviors are treated as invaluable sources of user feedback and they have been leveraged in several commercial search engines in recent years. However, estimating unbiased relevance is always a challenging task because of position bias. To solve this problem, many researchers have proposed a variety of assumptions to model click-through behaviors. Most of these models share a common examination hypothesis, which is that users examine search results from the top to the bottom. Nevertheless, this model cannot draw a complete picture of information-seeking behaviors. Many eye-tracking studies find that user interactions are not sequential but contain revisiting patterns. If a user clicks on a higher ranked document after having clicked on a lower-ranked one, we call this scenario a revisiting pattern, and we believe that the revisiting patterns are important signals regarding a user's click preferences. This paper incorporates revisiting behaviors into click models and introduces a novel click model named Temporal Hidden Click Model (THCM). This model dynamically models users' click behaviors with a temporal order. In our experiment, we collect over 115 million query sessions from a widely-used commercial search engine and then conduct a comparative analysis between our model and several state-of-the-art click models. The experimental results show that the THCM model achieves a significant improvement in the Normalized Discounted Cumulative Gain (NDCG), the click perplexity and click distributions metrics.",2012,Web Search and Data Mining,Fields of study: click patheye trackingsearch enginequalitative comparative analysiscumulantmultimediaworld wide webmachine learningsimulationstatisticscomputer science
Hierarchical Semi-supervised Classification with Incomplete Class Hierarchies,Bhavana Dalvi (Carnegie Mellon University)Aditya Kumar Mishra (Seattle University)William W. Cohen (Carnegie Mellon University),"2081006310,2192177076,2115385359","In an entity classification task, topic or concept hierarchies are often incomplete. Previous work by Dalvi et al. [12] has showed that in non-hierarchical semi-supervised classification tasks, the presence of such unanticipated classes can cause semantic drift for seeded classes. The Exploratory learning [12] method was proposed to solve this problem; however it is limited to the flat classification task. This paper builds such exploratory learning methods for hierarchical classification tasks. We experimented with subsets of the NELL [8] ontology and text, and HTML table datasets derived from the ClueWeb09 corpus. Our method (OptDAC-ExploreEM) outperforms the existing Exploratory EM method, and its naive extension (DAC-ExploreEM), in terms of seed class F1 on average by 10% and 7% respectively.",2016,Web Search and Data Mining,Fields of study: one class classificationsemi supervised learningdata miningpattern recognitionmachine learningcomputer science
Improving the efficiency of multi-site web search engines,Guillem Francès (Pompeu Fabra University)Xiao Bai 0002 (Yahoo!)Berkant Barla Cambazoglu (Yahoo!)Ricardo A. Baeza-Yates (Yahoo!),"2109897952,2104717575,2044137649,528588921","A multi-site web search engine is composed of a number of search sites geographically distributed around the world. Each search site is typically responsible for crawling and indexing the web pages that are in its geographical neighborhood. A query is selectively processed on a subset of search sites that are predicted to return the best-matching results. The scalability and efficiency of multi-site web search engines have attracted a lot of research attention in recent years. In particular, research has focused on replicating important web pages across sites, forwarding queries to relevant sites, and caching results of previous queries. Yet, these problems have only been studied in isolation, but no prior work has properly investigated the interplay between them. In this paper, we take this challenge up and conduct what we believe is the first comprehensive analysis of a full stack of techniques for efficient multi-site web search. Specifically, we propose a document replication technique that improves the query locality of the state-of-the-art approaches with various replication budget distribution strategies. We devise a machine learning approach to decide the query forwarding patterns, achieving a significantly lower false positive ratio than a state-of-the-art thresholding approach with little negative impact on search result quality. We propose three result caching strategies that reduce the number of forwarded queries and analyze the trade-off they introduce in terms of storage and network overheads. Finally, we show that the combination of the best-of-the-class techniques yields very promising search efficiency, rendering multi-site, geographically distributed web search engines an attractive alternative to centralized web search engines.",2014,Web Search and Data Mining,Fields of study: search analyticsdistributed web crawlingbeam searchweb search queryweb query classificationquery expansionsearch engine indexingsearch engineefficiencysemantic searchmetasearch engineworld wide webinformation retrievaldata miningcomputer science
Proceedings of the third ACM international conference on Web search and data mining,Brian D. Davison (Lehigh University)Torsten Suel (Polytechnic Institute of New York University)Nick Craswell (Microsoft)Bing Liu (University of Illinois at Chicago),"2203702053,702140476,2009495402,2244698799","We welcome you to the Third ACM International Conference on Web Search and Data Mining (WSDM) held February 3--6, 2010 in New York City. As a premier conference in the field, WSDM 2010 provides a highly competitive forum for reporting the latest developments in the research and application of Web search and data mining. We are pleased to present the proceedings of the conference as its published record. WSDM (pronounced ""wisdom"") is a young conference for research in the areas of search and retrieval, Web mining, economics implications, and in depth analysis of accuracy and performance of search and mining systems. Although it is only in its third year, it has already witnessed significant growth. As evidence of that, WSDM 2010 received a record 290 submissions, representing a 70% increase compared to WSDM 2009. The conference accepted 45 papers (15.5%). The authors of submitted papers come from 35 countries and regions. Authors of accepted papers are from 11 countries.",2010,Web Search and Data Mining,Fields of study: operations researchdata miningcomputer science
Visualizing brand associations from web community photos,Gunhee Kim (Carnegie Mellon University)Eric P. Xing (Carnegie Mellon University),"2210743192,351197510","Brand Associations, one of central concepts in marketing, describe customers' top-of-mind attitudes or feelings toward a brand. Thus, this consumer-driven brand equity often attains the grounds for purchasing products or services of the brand. Traditionally, brand associations are measured by analyzing the text data from consumers' responses to the survey or their online conversation logs. In this paper, we propose to go beyond text data and leverage large-scale online photo collections contributed by the general public, which have not been explored so far. As a first technical step toward the study of photo-based brand associations, we aim to jointly achieve the following two visualization tasks in a mutually-rewarding way: (i) detecting and visualizing core visual concepts associated with brands, and (ii) localizing the regions of brand in the images. With experiments on about five millions of images of 48 brands crawled from five popular online photo sharing sites, we demonstrate that our approach can discover complementary views on the brand associations that are hardly mined from the text data. We also quantitatively show that our approach outperforms other candidate methods on the both visualization tasks.",2014,Web Search and Data Mining,Fields of study: image segmentationmultimediaworld wide webdata miningcomputer science
Review Synthesis for Micro-Review Summarization,Thanh-Son Nguyen (Singapore Management University)Hady Wirawan Lauw (Singapore Management University)Panayiotis Tsaparas (University of Ioannina),"2227568756,2024254804,2234654910","Micro-reviews is a new type of user-generated content arising from the prevalence of mobile devices and social media in the past few years. Micro-reviews are bite-size reviews (usually under 200 characters), commonly posted on social media or check-in services, using a mobile device. They capture the immediate reaction of users, and they are rich in information, concise, and to the point. However, the abundance of micro-reviews, and their telegraphic nature make it increasingly difficult to go through them and extract the useful information, especially on a mobile device. In this paper, we address the problem of summarizing the micro-reviews of an entity, such that the summary is representative, compact, and readable. We formulate the summarization problem as that of synthesizing a new ``review'' using snippets of full-text reviews. To produce a summary that naturally balances compactness and representativeness, we work within the Minimum Description Length framework. We show that finding the optimal summary is NP-hard, and we consider approximation and heuristic algorithms. We perform a thorough evaluation of our methodology on real-life data collected from Foursquare and Yelp. We demonstrate that our summaries outperform individual reviews, as well as existing summarization approaches.",2015,Web Search and Data Mining,Fields of study: multi document summarizationautomatic summarizationmultimediaworld wide webinformation retrievaldata miningcomputer science
Scalable K-Means by ranked retrieval,Andrei Broder (Google)Lluis Garcia-Pueyo (Google)Vanja Josifovski (Google)Sergei Vassilvitskii (Google)Srihari Venkatesan (Yahoo!),"2720205684,1975913520,344688379,2156675704,2250799269","The k-means clustering algorithm has a long history and a proven practical performance, however it does not scale to clustering millions of data points into thousands of clusters in high dimensional spaces. The main computational bottleneck is the need to recompute the nearest centroid for every data point at every iteration, aprohibitive cost when the number of clusters is large. In this paper we show how to reduce the cost of the k-means algorithm by large factors by adapting ranked retrieval techniques. Using a combination of heuristics, on two real life data sets the wall clock time per iteration is reduced from 445 minutes to less than 4, and from 705 minutes to 1.4, while the clustering quality remains within 0.5% of the k-means quality. The key insight is to invert the process of point-to-centroid assignment by creating an inverted index over all the points and then using the current centroids as queries to this index to decide on cluster membership. In other words, rather than each iteration consisting of ""points picking centroids"", each iteration now consists of ""centroids picking points"". This is much more efficient, but comes at the cost of leaving some points unassigned to any centroid. We show experimentally that the number of such points is low and thus they can be separately assigned once the final centroids are decided. To speed up the computation we sparsify the centroids by pruning low weight features. Finally, to further reduce the running time and the number of unassigned points, we propose a variant of the WAND algorithm that uses the results of the intermediate results of nearest neighbor computations to improve performance.",2014,Web Search and Data Mining,Fields of study: k means clusteringworld wide webdata miningmachine learningstatisticsalgorithmcomputer science
Modelling growth of urban crowd-sourced information,Giovanni Quattrone (University College London)Afra J. Mashhadi (Bell Labs)Daniele Quercia (Yahoo!)Chris Smith-Clarke (University College London)Licia Capra (University College London),"2046545277,1964163228,284367085,2059698387,2105995467","Urban crowd-sourcing has become a popular paradigm to harvest spatial information about our evolving cities directly from citizens. OpenStreetMap is a successful example of such paradigm, with an accuracy of its user-generated content comparable to that of curated databases (e.g., Ordnance Survey). Coverage is however low and most importantly non-uniformly distributed across the city. Being able to model the spontaneous growth of digital information in these domains is required, so to be able to plan interventions aimed at gathering content about areas that would otherwise be neglected. Inspired by models of physical urban growth developed by urban planners, we build a model of digital growth of crowd-sourced spatial information that is both easy to interpret and dynamic, so to be able to determine what factors impact growth and how these change over time. We build and test the model against five years of OpenStreetMap data for the city of London, UK. We then run the model against two other cities, chosen for their different physical and digital growth's characteristics, so to stress-test the model. We conclude with a discussion of the implications of this work on both developers and users of urban crowd-sourcing applications.",2014,Web Search and Data Mining,Fields of study: cellular automatonoperations researchworld wide websocial sciencedata miningsimulationcomputer science
A self-adapting latency/power tradeoff model for replicated search engines,Ana Freire (University of A Coruña)Craig Macdonald (University of Glasgow)Nicola Tonellotto (National Research Council)Iadh Ounis (University of Glasgow)Fidel Cacheda (University of A Coruña),"2158002596,2148910894,1923078747,336997814,135441323","For many search settings, distributed/replicated search engines deploy a large number of machines to ensure efficient retrieval. This paper investigates how the power consumption of a replicated search engine can be automatically reduced when the system has low contention, without compromising its efficiency. We propose a novel self-adapting model to analyse the trade-off between latency and power consumption for distributed search engines. When query volumes are high and there is contention for the resources, the model automatically increases the necessary number of active machines in the system to maintain acceptable query response times. On the other hand, when the load of the system is low and the queries can be served easily, the model is able to reduce the number of active machines, leading to power savings. The model bases its decisions on examining the current and historical query loads of the search engine. Our proposal is formulated as a general dynamic decision problem, which can be quickly solved by dynamic programming in response to changing query loads. Thorough experiments are conducted to validate the usefulness of the proposed adaptive model using historical Web search traffic submitted to a commercial search engine. Our results show that our proposed self-adapting model can achieve an energy saving of 33% while only degrading mean query completion time by 10 ms compared to a baseline that provisions replicas based on a previous day's traffic.",2014,Web Search and Data Mining,Fields of study: beam searchsearch engineworld wide webinformation retrievaldata miningreal time computingmachine learningsimulationcomputer science
TYPiMatch: type-specific unsupervised learning of keys and key values for heterogeneous web data integration,Yongtao Ma (Karlsruhe Institute of Technology)Thanh Tran (Karlsruhe Institute of Technology),"2155662080,2190125403","Instance matching and blocking, a preprocessing step used for selecting candidate matches, require determining the most representative attributes of instances called keys, based on which similarities between instances are computed. We show that for the problem of learning blocking keys and key values, both generic techniques that do not exploit type information and supervised learning techniques optimized for one single predefined type of instances do not perform well on heterogeneous Web data capturing instances for which the predefined type is too general. That is, they actually belong to some subtypes that are not explicitly specified in the data. We propose an unsupervised approach for learning these subtypes and the subtype-specific blocking keys and key values. Compared to state-of-the-art supervised and unsupervised learning approaches that are optimized for one single type, our approach improves efficiency as well as result quality. In particular, we show that the proposed strategy of learning subtype-specific blocking keys and key values improves both blocking and instance matching results.",2013,Web Search and Data Mining,Fields of study: information integrationsemi supervised learninginstance based learningunsupervised learningdata miningpattern recognitionmachine learningcomputer science
WSDM Cup 2016: Entity Ranking Challenge,Alex D. Wade (Microsoft)Kuansan Wang (Microsoft)Yizhou Sun (Northeastern University)Antonio Gulli (Elsevier),"2072405598,2127379895,2131539564,2280805969","In this paper, we describe the WSDM Cup entity ranking challenge held in conjunction with the 2016 Web Search and Data Mining conference (WSDM 2016). Participants in the challenge were provided access to the Microsoft Academic Graph (MAG), a large heterogeneous graph of academic entities, and were invited to calculate the query-independent importance of each publication in the graph. Submissions for the challenge were open from August through November 2015, and a public leaderboard displayed teams? progress against a set of training judgements. Final evaluations were performed against a separate, withheld portion of the evaluation judgements. The top eight performing teams were then invited to submit papers to the WSDM Cup workshop, held at the WSDM 2016 conference.",2016,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningcomputer science
Feedback Control of Real-Time Display Advertising,Weinan Zhang (University College London)Yifei RongJun Wang (University College London)Tianchi ZhuXiaofan Wang (Shanghai Jiao Tong University),"2527611484,2343807655,2557836567,2343383173,2642540248","Real-Time Bidding (RTB) is revolutionising display advertising by facilitating per-impression auctions to buy ad impressions as they are being generated. Being able to use impression-level data, such as user cookies, encourages user behaviour targeting, and hence has significantly improved the effectiveness of ad campaigns. However, a fundamental drawback of RTB is its instability because the bid decision is made per impression and there are enormous fluctuations in campaigns' key performance indicators (KPIs). As such, advertisers face great difficulty in controlling their campaign performance against the associated costs. In this paper, we propose a feedback control mechanism for RTB which helps advertisers dynamically adjust the bids to effectively control the KPIs, e.g., the auction winning ratio and the effective cost per click. We further formulate an optimisation framework to show that the proposed feedback control mechanism also has the ability of optimising campaign performance. By settling the effective cost per click at an optimal reference value, the number of campaign's ad clicks can be maximised with the budget constraint. Our empirical study based on real-world data verifies the effectiveness and robustness of our RTB control system in various situations. The proposed feedback control mechanism has also been deployed on a commercial RTB platform and the online test has shown its success in generating controllable advertising performance.",2016,Web Search and Data Mining,Fields of study: technologyadvertisingmicroeconomicsmarketingsimulationcomputer science
Camera brand congruence in the Flickr social graph,Adish Singla (École Polytechnique Fédérale de Lausanne)Ingmar Weber (École Polytechnique Fédérale de Lausanne),"2568430679,2074066684","Given that my friends on Flickr use cameras of brand X, am I more likely to also use a camera of brand X? Given that one of these friends changes her brand, am I likely to do the same? These are the kind of questions addressed in this work. Direct applications involve personalized advertising in social networks. For our study we crawled a complete connected component of the Flickr friendship graph with a total of 67M edges and 3.9M users. Camera brands and models were assigned to users and time slots according to the model specific meta data pertaining to their images taken during these time slots. Similarly, we used, where provided in a user's profile, information about a user's geographic location and the groups joined on Flickr. Our main findings are the following. First, a pair of friends on Flickr has a significantly higher probability of being congruent, i.e., using the same brand, compared to two random users (27% vs. 19%). Second, the degree of congruence goes up for pairs of friends (i) in the same country (29%), (ii) who both only have very few friends (30%), and (iii) with a very high cliqueness (38%). Third, given that a user changes her camera model between March-May 2007 and March-May 2008, high cliqueness friends are more likely than random users to do the same (54% vs. 48%). Fourth, users using high-end cameras are far more loyal to their brand than users using point-and-shoot cameras, with a probability of staying with the same brand of 60% vs 33%, given that a new camera is bought. Fifth, these ""expert"" users' brand congruence reaches 66% (!) for high cliqueness friends. To the best of our knowledge this is the first time that the phenomenon of brand congruence is studied for hundreds of thousands of users and over a period of two years.",2009,Web Search and Data Mining,Fields of study: specificationsocial networkinternet privacyworld wide websocial science
Inverting a Steady-State,Ravi Kumar (Google)Andrew Tomkins (Google)Sergei Vassilvitskii (Google)Erik Vee (Google),"2232709231,2535415812,2156675704,2134018118","We consider the problem of inferring choices made by users based only on aggregate data containing the relative popularity of each item. We propose a framework that models the problem as that of inferring a Markov chain given a stationary distribution. Formally, we are given a graph and a target steady-state distribution on its nodes. We are also give a mapping from per-node scores to a transition matrix, from a broad family of such mappings. The goal is to set the scores of each node such that the resulting transition matrix induces the desired steady state. We prove sufficient conditions under which this problem is feasible and, for the feasible instances, obtain a simple algorithm for a generic version of the problem. This iterative algorithm provably finds the unique solution to this problem and has a polynomial rate of convergence; in practice we find that the algorithm converges after fewer than ten iterations. We then apply this framework to choice problems in online settings and show that our algorithm is able to explain the observed data and predict the user choices much better than other competing baselines across a variety of diverse datasets.",2015,Web Search and Data Mining,Fields of study: stochastic matrixmarkov chainrational choice theorydata miningmachine learningmathematical optimizationstatistics
WSCD 2012: workshop on web search click data 2012,Pavel Serdyukov (Yandex)Georges Dupret (Microsoft)Nick Craswell (Yahoo!),"2130450538,2615789374,2616630328","WSCD 2013 is the third workshop on Web Search Click Data, following WSCD 2009 and WSCD 2012. It is a forum for new research relating to Web search usage logs and for discussing desirable properties of publicly released search log datasets. Research relating to search logs has been hampered by the limited availability of click datasets. This workshop comes with a new dataset based on logged user search behaviour and an accompanying challenge to predict switches between search engines within a given search session.",2012,Web Search and Data Mining,Fields of study: click pathsearch analyticsorganic searchsearch engine optimizationweb search querysearch engineweb search engineworld wide webinformation retrievaldata miningcomputer science
Evaluating search in personal social media collections,Chia-Jung Lee (University of Massachusetts Amherst)W. Bruce Croft (University of Massachusetts Amherst)Jin Young Kim (University of Massachusetts Amherst),"2166010901,2127889770,2152189701","The prevalence of social media applications is generating potentially large personal archives of posts, tweets, and other communications. The existence of these archives creates a need for search tools, which can be seen as an extension of current desktop search services. Little is currently known about the best search techniques for personal archives of social data, because of the difficulty of creating test collections. In this paper, we describe how test collections for personal social data can be created by using games to collect queries. We then compare a range of retrieval models that exploit the semi-structured nature of social data. Our results show that a mixture of language models with field distribution estimation can be effective for this type of data, with certain fields, such as the name of the poster, being particularly important. We also analyze the properties of the queries that were generated by users with two versions of the games.",2012,Web Search and Data Mining,Fields of study: social medialanguage modelinternet privacymultimediaworld wide webinformation retrievaldata miningcomputer science
Cross-language query classification using web search for exogenous knowledge,Xuerui Wang (University of Massachusetts Amherst)Andrei Z. Broder (Yahoo!)Evgeniy Gabrilovich (Yahoo!)Vanja Josifovski (Yahoo!)Bo Pang (Yahoo!),"2152778655,2637163715,1804802447,344688379,2129095822","The non-English Web is growing at phenomenal speed, but available language processing tools and resources are predominantly English-based. Taxonomies are a case in point: while there are plenty of commercial and non-commercial taxonomies for the English Web, taxonomies for other languages are either not available or of arguable quality. Given that building comprehensive taxonomies for each language is prohibitively expensive, it is natural to ask whether existing English taxonomies can be leveraged, possibly via machine translation, to enable text processing tasks in other languages. Our experimental results confirm that the answer is affirmative with respect to at least one task. In this study we focus on query classification, which is essential for understanding the user intent both in Web search and in online advertising. We propose a robust method for classifying non-English queries into an English taxonomy, using an existing English text classifier and off-the-shelf machine translation systems. In particular, we show that by considering the Web search results in the query's original language as additional sources of information, we can alleviate the effect of erroneous machine translation. Empirical evaluation on query sets in languages as diverse as Chinese and Russian yields very encouraging results; consequently, we believe that our approach is also applicable to many additional languages.",2009,Web Search and Data Mining,Fields of study: web search queryweb query classificationquery expansionquery languageonline advertisingmachine translationnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Playing by the rules: mining query associations to predict search performance,Youngho Kim (University of Massachusetts Amherst)Ahmed Hassan (Microsoft)Ryen W. White (Microsoft)Yi-Min Wang (Microsoft),"2311461839,2266125312,2096583854,2137802269","Understanding the characteristics of queries where a search engine is failing is important for improving engine performance. Previous work largely relies on user-interaction features (e.g., clickthrough statistics) to identify such underperforming queries. However, relying on interaction behavior means that searchers need to become dissatisfied and need to exhibit that in their search behavior, by which point it may be too late to help them. In this paper, we propose a method to generate underperforming query identification rules instantly using topical and lexical attributes. The method first generates query attributes using sources such as topics, concepts (entities), and keywords in queries. Then, association rules are learned by exploiting the FP-growth algorithm and decision trees using underperforming query examples. We develop a query classification model capable of accurately estimating dissatisfaction using the generated rules, and demonstrate significant performance gains over state-of-the-art query performance prediction models.",2013,Web Search and Data Mining,Fields of study: sargableweb search queryweb query classificationspatial queryquery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningmachine learningcomputer science
Relative confidence sampling for efficient on-line ranker evaluation,Masrour Zoghi (University of Amsterdam)Shimon A. Whiteson (University of Amsterdam)Maarten de Rijke (University of Amsterdam)Remi Munos (French Institute for Research in Computer Science and Automation),"2170892963,2042571382,401833296,254054780","A key challenge in information retrieval is that of on-line ranker evaluation: determining which one of a finite set of rankers performs the best in expectation on the basis of user clicks on presented document lists. When the presented lists are constructed using interleaved comparison methods, which interleave lists proposed by two different candidate rankers, then the problem of minimizing the total regret accumulated while evaluating the rankers can be formalized as a K-armed dueling bandits problem. In this paper, we propose a new method called relative confidence sampling (RCS) that aims to reduce cumulative regret by being less conservative than existing methods in eliminating rankers from contention. In addition, we present an empirical comparison between RCS and two state-of-the-art methods, relative upper confidence bound and SAVAGE. The results demonstrate that RCS can substantially outperform these alternatives on several large learning to rank datasets.",2014,Web Search and Data Mining,Fields of study: evaluationdata miningartificial intelligencemachine learningstatisticscomputer science
"Big Data: New Paradigm or ""Sound and Fury, Signifying Nothing""?","Andrei Z. Broder (Google)Lada A. Adamic (Facebook)Michael J. Franklin (University of California, Berkeley)Maarten de Rijke (University of Amsterdam)Eric P. Xing (Carnegie Mellon University)Kai Yu (Baidu)","2720205684,2716260478,2523407221,401833296,351197510,2159960587","The Gartner's 2014 Hype Cycle released last August moves Big Data technology from the Peak of Inflated Expectations to the beginning of the Trough of Disillusionment when interest starts to wane as reality does not live up to previous promises. As the hype is starting to dissipate it is worth asking what Big Data (however defined) means from a scientific perspective: Did the emergence of gigantic corpora exposed the limits of classical information retrieval and data mining and led to new concepts and challenges, the way say, the study of electromagnetism showed the limits of Newtonian mechanics and led to Relativity Theory, or is it all just ""sound and fury, signifying nothing"", simply a matter of scaling up well understood technologies? To answer this question, we have assembled a distinguished panel of eminent scientists, from both Industry and Academia: Lada Adamic (Facebook), Michael Franklin (University of California at Berkeley), Maarten de Rijke (University of Amsterdam), Eric Xing (Carnegie Mellon University), and Kai Yu (Baidu) will share their point of view and take questions from the moderator and the audience.",2015,Web Search and Data Mining,Fields of study: big datasocial scienceartificial intelligencecomputer science
Triplex transfer learning: exploiting both shared and distinct concepts for text classification,Fuzhen Zhuang (Chinese Academy of Sciences)Ping Luo (Hewlett-Packard)Changying Du (Chinese Academy of Sciences)Qing He (Chinese Academy of Sciences)Zhongzhi Shi (Chinese Academy of Sciences),"2050314250,2291210646,2116524837,2167314737,2112067332","Transfer learning focuses on the learning scenarios when the test data from target domains and the training data from source domains are drawn from similar but different data distribution with respect to the raw features. Some recent studies argued that the high-level concepts (e.g. word clusters) can help model the data distribution difference, and thus are more appropriate for classification. Specifically, these methods assume that all the data domains have the same set of shared concepts, which are used as the bridge for knowledge transfer. However, besides these shared concepts each domain may have its own distinct concepts. To address this point, we propose a general transfer learning framework based on non-negative matrix tri-factorization which allows to explore both shared and distinct concepts among all the domains simultaneously. Since this model provides more flexibility in fitting the data it may lead to better classification accuracy. To solve the proposed optimization problem we develop an iterative algorithm and also theoretically analyze its convergence. Finally, extensive experiments show the significant superiority of our model over the baseline methods. In particular, we show that our method works much better in the more challenging tasks when distinct concepts may exist.",2013,Web Search and Data Mining,Fields of study: transfer of learningtheoretical computer sciencedata miningmachine learningcomputer science
eBay: an E-commerce marketplace as a complex network,Zeqian Shen (eBay)Neel Sundaresan (eBay),"2503946360,1981173961","Commerce networks involve buying and selling activities among individuals or organizations. As the growing of the Internet and e-commerce, it brings opportunities for obtaining real world online commerce networks, which are magnitude larger than before. Getting a deeper understanding of e-commerce networks, such as the eBay marketplace, in terms of what structure they have, what kind of interactions they afford, what trust and reputation measures exist, and how they evolve has tremendous value in suggesting business opportunities and building effective user applications. In this paper, we modeled the eBay network as a complex network. We analyzed the macroscopic shape of the network using degree distribution and the bow-tie model. Networks of different eBay categories are also compared. The results suggest that the categories vary from collector networks to retail networks. We also studied the local structures of the networks using motif profiling. Finally, patterns of preferential connections are visually analyzed using Auroral diagrams.",2011,Web Search and Data Mining,Fields of study: evolving networksnetwork motifdegree distributioncomplex networkpower lawe commerceworld wide webcomputer science
On the Efficiency of the Information Networks in Social Media,Mahmoudreza Babaei (Max Planck Society)Przemyslaw A. Grabowicz (Max Planck Society)Isabel Valera (Max Planck Society)Krishna P. Gummadi (Max Planck Society)Manuel Gomez-Rodriguez (Max Planck Society),"2125359842,2074278657,2096884534,1982116827,2279633593","Social media sites are information marketplaces, where users produce and consume a wide variety of information and ideas. In these sites, users typically choose their information sources, which in turn determine what specific information they receive, how much information they receive and how quickly this information is shown to them. In this context, a natural question that arises is how efficient are social media users at selecting their information sources. In this work, we propose a computational framework to quantify users' efficiency at selecting information sources. Our framework is based on the assumption that the goal of users is to acquire a set of unique pieces of information. To quantify user's efficiency, we ask if the user could have acquired the same pieces of information from another set of sources more efficiently. We define three different notions of efficiency -- link, in-flow, and delay -- corresponding to the number of sources the user follows, the amount of (redundant) information she acquires and the delay with which she receives the information. Our definitions of efficiency are general and applicable to any social media system with an underlying in- formation network, in which every user follows others to receive the information they produce. In our experiments, we measure the efficiency of Twitter users at acquiring different types of information. We find that Twitter users exhibit sub-optimal efficiency across the three notions of efficiency, although they tend to be more efficient at acquiring non- popular pieces of information than they are at acquiring popular pieces of information. We then show that this lack of efficiency is a consequence of the triadic closure mechanism by which users typically discover and follow other users in social media. Thus, our study reveals a tradeoff between the efficiency and discoverability of information sources. Finally, we develop a heuristic algorithm that enables users to be significantly more efficient at acquiring the same unique pieces of information.",2016,Web Search and Data Mining,Fields of study: information algebrainformation filtering systeminteraction informationsocial medialossless compressioninformationefficiencytheoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer sciencemathematics
Understanding User Attention and Engagement in Online News Reading,Dmitry Lagun (Google)Mounia Lalmas (Yahoo!),"2281438794,46148421","Prior work on user engagement with online media identified web page dwell time as a key metric reflecting level of user engagement with online news articles. While on average, dwell time gives a reasonable estimate of user experience with a news article, it is not able to capture important aspects of user interaction with the page, such as how much time a user spends reading the article vs. viewing the comment posted by other users, or the actual proportion of article read by the user. In this paper, we propose a set of user engagement classes along with new user engagement metrics that, unlike dwell time, more accurately reflect user experience with the content. Our user engagement classes provide clear and interpretable taxonomy of user engagement with online news, and are defined based on amount of time user spends on the page, proportion of the article user actually reads and the amount of interaction users performs with the comments. Moreover, we demonstrate that our metrics are relatively easier to predict from the news article content, compared to the dwell time, making optimization of user engagement more attainable goal.",2016,Web Search and Data Mining,Fields of study: user journeycomputer user satisfactiontopic modeluser requirements documentuseruser modelingattentionuser experience designhuman computer interactionmultimediaworld wide webmachine learningcomputer science
Statistical Spoken Dialogue Systems and the Challenges for Machine Learning,Steve Young (University of Cambridge),2125228453,"This talk will review the principal components of a spoken dialogue system and then discuss the opportunities for applying machine learning for building robust high performance open-domain systems. The talk will be illustrated by recent work at Cambridge University using machine learning for belief tracking, reward estimation, multi-domain policy learning and natural language generation. The talk will conclude by discussing some of the key challenges in scaling these solutions to work in practical systems.",2017,Web Search and Data Mining,Fields of study: robot learninggaussian processactive learningerror driven learningalgorithmic learning theorycomputational learning theoryinstance based learningreinforcement learningnatural language processingspeech recognitionartificial intelligencemachine learningcomputer science
Spatial compactness meets topical consistency: jointly modeling links and content for community detection,Mrinmaya Sachan (Carnegie Mellon University)Avinava Dubey (Carnegie Mellon University)Shashank Srivastava (Carnegie Mellon University)Eric P. Xing (Carnegie Mellon University)Eduard H. Hovy (Carnegie Mellon University),"2035754532,2112473960,2120421114,351197510,2706585063","In this paper, we address the problem of discovering topically meaningful, yet compact (densely connected) communities in a social network. Assuming the social network to be an integer-weighted graph (where the weights can be intuitively defined as the number of common friends, followers, documents exchanged, etc.), we transform the social network to a more efficient representation. In this new representation, each user is a bag of her one-hop neighbors. We propose a mixed-membership model to identify compact communities using this transformation. Next, we augment the representation and the model to incorporate user-content information imposing topical consistency in the communities. In our model a user can belong to multiple communities and a community can participate in multiple topics. This allows us to discover community memberships as well as community and user interests. Our method outperforms other well known baselines on two real-world social networks. Finally, we also provide a fast, parallel approximation of the same.",2014,Web Search and Data Mining,Fields of study: graphical modelsocial networkdata scienceworld wide webdata miningmachine learningstatisticscomputer science
Time-sensitive web image ranking and retrieval via dynamic multi-task regression,Gunhee Kim (Carnegie Mellon University)Eric P. Xing (Carnegie Mellon University),"2210743192,351197510","In this paper, we investigate a time-sensitive image retrieval problem, in which given a query keyword, a query time point, and optionally user information, we retrieve the most relevant and temporally suitable images from the database. Inspired by recently emerging interests on query dynamics in information retrieval research, our time-sensitive image retrieval algorithm can infer users' implicit search intent better and provide more engaging and diverse search results according to temporal trends of Web user photos. We model observed image streams as instances of multivariate point processes represented by several different descriptors, and develop a regularized multi-task regression framework that automatically selects and learns stochastic parametric models to solve the relations between image occurrence probabilities and various temporal factors that influence them. Using Flickr datasets of more than seven million images of 30 topics, our experimental results show that the proposed algorithm is more successful in time-sensitive image retrieval than other candidate methods, including ranking SVM, a PageRank-based image ranking, and a generative temporal topic model.",2013,Web Search and Data Mining,Fields of study: rankingvisual wordquery expansionpoint processautomatic image annotationimage retrievalworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Going beyond Corr-LDA for detecting specific comments on news & blogs,Mrinal Kanti Das (Indian Institute of Science)Trapit Bansal (Indian Institute of Science)Chiranjib Bhattacharyya (Indian Institute of Science),"2160029775,2128154164,2169305403","Understanding user generated comments in response to news and blog posts is an important area of research. After ignoring irrelevant comments, one finds that a large fraction, approximately 50%, of the comments are very specific and can be further related to certain parts of the article instead of the entire story. For example, in a recent product review of Google Nexus 7 in ArsTechnica (a popular blog), the reviewer talks about the prospect of ""Retina equipped iPad mini"" in a few sentences. It is interesting that although the article is on Nexus 7, but a significant number of comments are focused on this specific point regarding ""iPad"". We pose the problem of detecting such comments as specific comments location (SCL) problem. SCL is an important open problem with no prior work. SCL can be posed as a correspondence problem between comments and the parts of the relevant article, and one could potentially use Corr-LDA type models. Unfortunately, such models do not give satisfactory performance as they are restricted to using a single topic vector per article-comments pair. In this paper we propose to go beyond the single topic vector assumption and propose a novel correspondence topic model, namely SCTM, which admits multiple topic vectors (MTV) per article-comments pair. The resulting inference problem is quite complicated because of MTV and has no off-the-shelf solution. One of the major contributions of this paper is to show that using stick-breaking process as a prior over MTV, one can derive a collapsed Gibbs sampling procedure, which empirically works well for SCL. SCTM is rigorously evaluated on three datasets, crawled from Yahoo! News (138,000 comments) and two blogs, ArsTechnica (AT) Science (90,000 comments) and AT-Gadget (160,000 comments). We observe that SCTM performs better than Corr-LDA, not only in terms of metrics like perplexity and topic coherence but also discovers more unique topics. We see that this immediately leads to an order of magnitude improvement in F1 score over Corr-LDA for SCL.",2014,Web Search and Data Mining,Fields of study: newsworld wide webspeech recognitioninformation retrievaldata miningartificial intelligencemachine learningstatisticscomputer science
Let web spammers expose themselves,Zhicong Cheng (Peking University)Bin Gao (Microsoft)Congkai Sun (University of Southern California)Yanbing Jiang (Peking University)Tie-Yan Liu (Microsoft),"2222019574,2616890138,2237454410,2609774266,2108341226","This paper is concerned with mining link spams (e.g., link farm and link exchange) from search engine optimization (SEO) forums. To provide quality services, it is critical for search engines to address web spam. Several techniques such as TrustRank, BadRank, and SpamRank have been proposed for this purpose. Most of these methods try to downgrade the effects of the spam websites by identifying specific link patterns of them. However, spam websites have appeared to be more and more similar to normal or even good websites in their link structures, by reforming their spam techniques. As a result, it is very challenging to automatically detect link spams from the Web graph. In this paper, we propose a different approach, which detects link spams by looking at how web spammers make link spam happen. We find that web spammers usually ally with each other, and SEO forum is one of the major means for them to form the alliance. We therefore propose mining suspicious link spams directly from the posts in the SEO forums. However, the task is non-trivial because there are also other information and even noises contained in these posts, in addition to useful clues of link spam. To tackle the challenges, we first extract all the URLs contained in the posts of the SEO forums. Second, we extract features for the URLs from their relationships with forum users (potential spammers) and from their link structure in the web graph. Third, we build a semi-supervised learning framework to calculate the spam scores for the URLs, which encodes several heuristics such as spam websites usually linking to each other, and good websites seldom linking to spam websites. We tested our approach on seven major SEO forums. A lot of spam websites were identified, a significant proportion of which cannot be detected by conventional anti-spam methods. It indicates that the proposed approach can be a good complement of existing anti-spam techniques.",2011,Web Search and Data Mining,Fields of study: spingforum spamspam blogspambotsocial spamspammingsearch engine optimizationspamdexingsearch enginesemi supervised learninginternet privacyworld wide webinformation retrievaldata miningcomputer science
Improving IP Geolocation using Query Logs,Ovidiu Dan (Lehigh University)Vaibhav Parikh (Microsoft)Brian D. Davison (Lehigh University),"2163457310,2282422544,2203702053","IP geolocation databases map IP addresses to their geographical locations. These databases are important for several applications such as local search engine relevance, credit card fraud protection, geotargetted advertising, and online content delivery. While they are the most popular method of geolocation, they can have low accuracy at the city level. In this paper we evaluate and improve IP geolocation databases using data collected from search engine logs. We generate a large ground-truth dataset using real time global positioning data extracted from search engine logs. We show that incorrect geolocation information can have a negative impact on implicit user metrics. Using the dataset we measure the accuracy of three state-of-the-art commercial IP geolocation databases. We then introduce a technique to improve existing geolocation databases by mining explicit locations from query logs. We show significant accuracy gains in 44 to 49 out of the top 50 countries, depending on the IP geolocation database. Finally, we validate the approach with a large scale A/B experiment that shows improvements in several user metrics.",2016,Web Search and Data Mining,Fields of study: geolocationlocal searchinternet privacyworld wide webdata mining
Keeping Apace with Progress in Natural Language Processing,Claire Cardie (Cornell University),229573375,"Increasingly central to online search and information discovery are methods from Natural Language Processing (NLP). Research in the field, however, is progressing at what feels a frenetic pace, making it a daunting task to keep up with the latest results. This talk will describe some of the tasks and sub-areas of NLP that have experienced fundamental advances in the state of the art over past few years, focusing on what these advances mean for understanding and extracting information from online text.",2017,Web Search and Data Mining,Fields of study: natural language processingartificial intelligencecomputer science
Evolution of Privacy Loss in Wikipedia,Marian-Andrei Rizoiu (Australian National University)Lexing Xie (Australian National University)Tiberio Caetano (Australian National University)Manuel Cebrian (Massachusetts Institute of Technology),"297821025,2100918400,1982686475,2138148202","The cumulative effect of collective online participation has an important and adverse impact on individual privacy. As an online system evolves over time, new digital traces of individual behavior may uncover previously hidden statistical links between an individual's past actions and her private traits. To quantify this effect, we analyze the evolution of individual privacy loss by studying the edit history of Wikipedia over 13 years, including more than 117,523 different users performing 188,805,088 edits. We trace each Wikipedia's contributor using apparently harmless features, such as the number of edits performed on predefined broad categories in a given time period (e.g. Mathematics, Culture or Nature). We show that even at this unspecific level of behavior description, it is possible to use off-the-shelf machine learning algorithms to uncover usually undisclosed personal traits, such as gender, religion or education. We provide empirical evidence that the prediction accuracy for almost all private traits consistently improves over time. Surprisingly, the prediction performance for users who stopped editing after a given time still improves. The activities performed by new users seem to have contributed more to this effect than additional activities from existing (but still active) users. Insights from this work should help users, system designers, and policy makers understand and make long-term design choices in online content creation systems.",2016,Web Search and Data Mining,Fields of study: internet privacyworld wide webdata miningmachine learningcomputer science
Query independent measures of annotation and annotator impact,James Lanagan (Dublin City University)Alan F. Smeaton (Dublin City University),"1987444593,2326079530","The modern-day web-user plays a far more active role in the creation of content for the web as a whole. In this paper we present Annoby, a free-text annotation system built to give users a more interactive experience of the events of the Rugby World Cup 2007. Annotations can be used for query-independent ranking of both the annotations and the original recorded video footage (or documents) which has been annotated, based on the social interactions of a community of users. We present two algorithms, AuthorRank and MessageRank, designed to take advantage of these interactions so as to provide a means of ranking documents by their social impact.",2009,Web Search and Data Mining,Fields of study: web 2 0data qualitysocial networksocial relationworld wide webinformation retrievalsocial sciencedata miningcomputer science
Dynamic Collective Entity Representations for Entity Ranking,David Graus (University of Amsterdam)Manos Tsagkias (University of Amsterdam)Wouter Weerkamp (University of Amsterdam)Edgar Meij (Yahoo!)Maarten de Rijke (University of Amsterdam),"664220817,207528511,197647246,2160283388,401833296","Entity ranking, i.e., successfully positioning a relevant entity at the top of the ranking for a given query, is inherently difficult due to the potential mismatch between the entity's description in a knowledge base, and the way people refer to the entity when searching for it. To counter this issue we propose a method for constructing dynamic collective entity representations. We collect entity descriptions from a variety of sources and combine them into a single entity representation by learning to weight the content from different sources that are associated with an entity for optimal retrieval effectiveness. Our method is able to add new descriptions in real time and learn the best representation as time evolves so as to capture the dynamics of how people search entities. Incorporating dynamic description sources into dynamic collective entity representations improves retrieval effectiveness by 7% over a state-of-the-art learning to rank baseline. Periodic retraining of the ranker enables higher ranking effectiveness for dynamic collective entity representations.",2016,Web Search and Data Mining,Fields of study: weak entityentity linkinginformation retrievaldata miningmachine learning
A few good predictions: selective node labeling in a social network,Gaurish Chaudhari (Indian Institute of Technology Bombay)Vashist Avadhanula (Indian Institute of Technology Bombay)Sunita Sarawagi (Indian Institute of Technology Bombay),"2485306153,2689558043,156875573","Many social network applications face the following problem: given a network G =(V,E) with labels on a small subset O \subset V of nodes and an optional set of features on nodes and edges, predict the labels of the remaining nodes. Much research has gone into designing learning models and inference algorithms for accurate predictions in this setting. However, a core hurdle to any prediction effort is that for many nodes there is insufficient evidence for inferring a label. We propose that instead of focusing on the impossible task of providing high accuracy over all nodes, we should focus on selectively making the few node predictions which will be correct with high probability. Any selective prediction strategy will require that the scores attached to node predictions be well-calibrated. Our evaluations show that existing prediction algorithms are poorly calibrated. We propose a new method of training a graphical model using a conditional likelihood objective that provides better calibration than the existing joint likelihood objective. We augment it with a decoupled confidence model created using a novel unbiased training process. Empirical evaluation on two large social networks show that we are able to select a large number of predictions with accuracy as high as 95%, even when the best overall accuracy is only 40%.",2014,Web Search and Data Mining,Fields of study: graphical modeldata miningmachine learningstatisticscomputer science
Algorithms for Active Classifier Selection: Maximizing Recall with Precision Constraints,Paul N. Bennett (Microsoft)David Maxwell Chickering (Microsoft)Christopher Meek (Microsoft)Xiaojin Zhu (University of Wisconsin-Madison),"2137013502,659530374,2422299352,2132213614","Software applications often use classification models to trigger specialized experiences for users. Search engines, for example, use query classifiers to trigger specialized ""instant answer"" experiences where information satisfying the user query is shown directly on the result page, and email applications use classification models to automatically move messages to a spam folder. When such applications have acceptable default (i.e., non-specialized) behavior, users are often more sensitive to failures in model precision than failures in model recall. In this paper, we consider model-selection algorithms for these precision-constrained scenarios. We develop adaptive model-selection algorithms to identify, using as few samples as possible, the best classifier from among a set of (precision) qualifying classifiers. We provide statistical correctness and sample complexity guarantees for our algorithms. We show with an empirical validation that our algorithms work well in practice.",2017,Web Search and Data Mining,Fields of study: model selectiontheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks,Ali Zarezade (Sharif University of Technology)Utkarsh Upadhyay (Max Planck Society)Hamid R. Rabiee (Sharif University of Technology)Manuel Gomez-Rodriguez (Max Planck Society),"727719436,2353884032,2032985511,2279633593","Users in social networks whose posts stay at the top of their followers' feeds the longest time are more likely to be noticed. Can we design an online algorithm to help them decide when to post to stay at the top? In this paper, we address this question as a novel optimal control problem for jump stochastic differential equations. For a wide variety of feed dynamics, we show that the optimal broadcasting intensity for any user is surprisingly simple ? it is given by the position of her most recent post on each of her follower's feeds. As a consequence, we are able to develop a simple and highly efficient online algorithm, RedQueen, to sample the optimal times for the user to post. Experiments on both synthetic and real data gathered from Twitter show that our algorithm is able to consistently make a user's posts more visible over time, is robust to volume changes on her followers' feeds, and significantly outperforms the state of the art.",2017,Web Search and Data Mining,Fields of study: social networkdata structuredistributed computingreal time computingmachine learningsimulationstatisticscomputer science
Wikipedia entity expansion and attribute extraction from the web using semi-supervised learning,Lidong Bing (The Chinese University of Hong Kong)Wai Lam (The Chinese University of Hong Kong)Tak-Lam Wong (Hong Kong Institute of Education),"2160800796,2119595446,2141897598",We develop a new framework to achieve the goal of Wikipedia entity expansion and attribute extraction from the Web. Our framework takes a few existing entities that are automatically collected from a particular Wikipedia category as seed input and explores their attribute infoboxes to obtain clues for the discovery of more entities for this category and the attribute content of the newly discovered entities. One characteristic of our framework is to conduct discovery and extraction from desirable semi-structured data record sets which are automatically collected from the Web. A semi-supervised learning model with Conditional Random Fields is developed to deal with the issues of extraction learning and limited number of labeled examples derived from the seed entities. We make use of a proximate record graph to guide the semi-supervised learning process. The graph captures alignment similarity among data records. Then the semi-supervised learning process can leverage the unlabeled data in the record set by controlling the label regularization under the guidance of the proximate record graph. Extensive experiments on different domains have been conducted to demonstrate its superiority for discovering new entities and extracting attribute content.,2013,Web Search and Data Mining,Fields of study: semi structured dataconditional random fieldinformation extractionworld wide webinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Distributed Balanced Partitioning via Linear Embedding,Kevin Aydin (Google)MohammadHossein Bateni (Google)Vahab S. Mirrokni (Google),"2289114484,1978978852,2331823467","Balanced partitioning is often a crucial first step in solving large-scale graph optimization problems: in some cases, a big graph is chopped into pieces that fit on one machine to be processed independently before stitching the results together, leading to certain suboptimality from the interaction among different pieces. In other cases, links between different parts may show up in the running time and/or network communications cost, hence the desire to have small cut size. We study a distributed balanced partitioning problem where the goal is to partition the vertices of a given graph into k pieces, minimizing the total cut size. Our algorithm is composed of a few steps that are easily implementable in distributed computation frameworks, e.g., MapReduce. The algorithm first embeds nodes of the graph onto a line, and then processes nodes in a distributed manner guided by the linear embedding order. We examine various ways to find the first embedding, e.g., via a hierarchical clustering or Hilbert curves. Then we apply four different techniques such as local swaps, minimum cuts on partition boundaries, as well as contraction and dynamic programming. Our empirical study compares the above techniques with each other, and to previous work in distributed algorithms, e.g., a label propagation method, FENNEL and Spinner. We report our results both on a private map graph and several public social networks, and show that our results beat previous distributed algorithms: we notice, e.g., 15-25% reduction in cut size over [UB13]. We also observe that our algorithms allow for scalable distributed implementation for any number of partitions. Finally, we apply our techniques for the Google Maps Driving Directions to minimize the number of multi-shard queries with the goal of saving in CPU usage. During live experiments, we observe an ≈ 40% drop in the number of multi-shard queries when comparing our method with a standard geography-based method.",2016,Web Search and Data Mining,Fields of study: cutgraph partitionsocial networktheoretical computer scienceparallel computingoperating systemsocial sciencedistributed computingmathematical optimizationalgorithmcomputer science
Learning to re-rank web search results with multiple pairwise features,Changsung Kang (Yahoo!)Xuanhui Wang (Yahoo!)Jiang Chen (Google)Ciya Liao (Microsoft)Yi Chang (Yahoo!)Belle L. Tseng (Yahoo!)Zhaohui Zheng (Yahoo!),"2672672574,2102775025,2710106538,2656175497,2168000538,1990119318,2089011938","Web search ranking functions are typically learned to rank search results based on features of individual documents, i.e., pointwise features. Hence, the rich relationships among documents, which contain multiple types of useful information, are either totally ignored or just explored very limitedly. In this paper, we propose to explore multiple pairwise relationships between documents in a learning setting to rerank search results. In particular, we use a set of pairwise features to capture various kinds of pairwise relationships and design two machine learned re-ranking methods to effectively combine these features with a base ranking function: a pairwise comparison method and a pairwise function decomposition method. Furthermore, we propose several schemes to estimate the potential gains of our re-ranking methods on each query and selectively apply them to queries with high confidence. Our experiments on a large scale commercial search engine editorial data set show that considering multiple pairwise relationships is quite beneficial and our proposed methods can achieve significant gain over methods which only consider pointwise features or a single type of pairwise relationship.",2011,Web Search and Data Mining,Fields of study: potentially all pairwise rankings of all possible alternativesfunctional decompositionsearch enginelearning to rankdata miningpattern recognitionmachine learningcomputer science
Group sparse topical coding: from code to topic,Lu Bai (Chinese Academy of Sciences)Jiafeng Guo (Chinese Academy of Sciences)Yanyan Lan (Chinese Academy of Sciences)Xueqi Cheng (Chinese Academy of Sciences),"2693294072,2581340266,2154124860,2129598186","Learning low dimensional representations of text corpora is critical in many content analysis and data mining applications. It is even more desired and challenging to learn a sparse representation in practice for large scale text modeling. However, traditional probabilistic topic models (PTM) lack a mechanism to directly control the posterior sparsity of the inferred representations; While the emerged non-probabilistic models (NPM) can explicitly control sparsity using sparse constraint like l_1 norm, they convey different limitations in latent representations. To address the existing problems, we propose a novel non-probabilistic topic model for discovering sparse latent representations of large text corpora, referred as group sparse topical coding (GSTC). Our model enjoys both the merits of the PTMs and NPMs. On one hand, GSTC can naturally derive document-level admixture proportions in topic simplex like PTMs, which is useful for semantic analysis, classification or retrieval. On the other hand, GSTC can directly control the sparsity of the inferred representations with group lasso by relaxing the normalization constraint. Moreover, the relaxed non-probabilistic GSTC can be effectively learned using coordinate descent method. Experimental results on benchmark datasets show that GSTC can discover meaningful compact latent representations of documents, and improve the document classification accuracy and time efficiency.",2013,Web Search and Data Mining,Fields of study: topic modelneural codingcontent analysisinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
Search engine click spam detection based on bipartite graph propagation,Xin Li (Tsinghua University)Min Zhang (Tsinghua University)Yiqun Liu (Tsinghua University)Shaoping Ma (Tsinghua University)Yijiang Jin (Tsinghua University)Liyun Ru (Tsinghua University),"2682567659,2526008467,2111097927,2109195263,2293900567,2113600213","Using search engines to retrieve information has become an important part of people's daily lives. For most search engines, click information is an important factor in document ranking. As a result, some websites cheat to obtain a higher rank by fraudulently increasing clicks to their pages, which is referred to as ""Click Spam"". Based on an analysis of the features of fraudulent clicks, a novel automatic click spam detection approach is proposed in this paper, which consists of 1. modeling user sessions with a triple sequence, which, to the best of our knowledge, takes into account not only the user action but also the action objective and the time interval between actions for the first time; 2. using the user-session bipartite graph propagation algorithm to take advantage of cheating users to find more cheating sessions; and 3. using the pattern-session bipartite graph propagation algorithm to obtain cheating session patterns to achieve higher precision and recall of click spam detection. Experimental results based on a Chinese commercial search engine using real-world log data containing approximately 80 million user clicks per day show that 2.6% of all clicks were detected as spam with a precision of up to 97%.",2014,Web Search and Data Mining,Fields of study: internet privacymultimediaworld wide webcomputer science
Hierarchical Label Propagation and Discovery for Machine Generated Email,James B. Wendt (Google)Michael Bendersky (Google)Lluis Garcia-Pueyo (Google)Vanja Josifovski (Yahoo!)Balint Miklos (Google)Ivo Krka (Google)Amitabh Saikia (Google)Jie Yang (Google)Marc-Allen Cartright (Google)Sujith Ravi (Google),"2342718078,2345232400,1975913520,344688379,2342928363,2658596234,2344699057,2304724589,2342761430,2590734359","Machine-generated documents such as email or dynamic web pages are single instantiations of a pre-defined structural template. As such, they can be viewed as a hierarchy of template and document specific content. This hierarchical template representation has several important advantages for document clustering and classification. First, templates capture common topics among the documents, while filtering out the potentially noisy variabilities such as personal information. Second, template representations scale far better than document representations since a single template captures numerous documents. Finally, since templates group together structurally similar documents, they can propagate properties between all the documents that match the template. In this paper, we use these advantages for document classification by formulating an efficient and effective hierarchical label propagation and discovery algorithm. The labels are propagated first over a template graph (constructed based on either term-based or topic-based similarities), and then to the matching documents. We evaluate the performance of the proposed algorithm using a large donated email corpus and show that the resulting template graph is significantly more compact than the corresponding document graph and the hierarchical label propagation is both efficient and effective in increasing the coverage of the baseline document classification algorithm. We demonstrate that the template label propagation achieves more than 91% precision and 93% recall, while increasing the label coverage by more than 11%.",2016,Web Search and Data Mining,Fields of study: template method patternworld wide webdata miningpattern recognitioncomputer science
Optimal Space-time Tradeoffs for Inverted Indexes,Giuseppe Ottaviano (National Research Council)Nicola Tonellotto (National Research Council)Rossano Venturini (University of Pisa),"2153528897,1923078747,2277909408","Inverted indexes are usually represented by dividing posting lists into constant-sized blocks and representing them with an encoder for sequences of integers. Different encoders yield a different point in the space-time trade-off curve, with the fastest being several times larger than the most space-efficient. An important design decision for an index is thus the choice of the fastest encoding method such that the index fits in the available memory. However, a better usage of the space budget could be obtained by using faster encoders for frequently accessed blocks, and more space-efficient ones those that are rarely accessed. To perform this choice optimally, we introduce a linear time algorithm that, given a query distribution and a set of encoders, selects the best encoder for each index block to obtain the lowest expected query processing time respecting a given space constraint. To demonstrate the effectiveness of this approach we perform an extensive experimental analysis, which shows that our algorithm produces indexes which are significantly faster than single-encoder indexes under several query processing strategies, while respecting the same space constraints.",2015,Web Search and Data Mining,Fields of study: compressiontheoretical computer sciencemachine learningmathematical optimizationalgorithm
Robust query rewriting using anchor data,Nick Craswell (Microsoft)Bodo von Billerbeck (Microsoft)Dennis Fetterly (Microsoft)Marc Najork (Microsoft),"2009495402,2076708895,1992570377,2027155665","Query rewriting algorithms can be used as a form of query expansion, by combining the user's original query with automatically generated rewrites. Rewriting algorithms bring linguistic datasets to bear without the need for iterative relevance feedback, but most studies of rewriting have used proprietary datasets such as large-scale search logs. By contrast this paper uses readily available data, particularly ClueWeb09 link text with over 1.2 billion anchor phrases, to generate rewrites. To avoid overfitting, our initial analysis is performed using Million Query Track queries, leading us to identify three algorithms which perform well. We then test the algorithms on Web and newswire data. Results show good properties in terms of robustness and early precision.",2013,Web Search and Data Mining,Fields of study: web search queryweb query classificationanchor textquery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningdatabasecomputer science
Introduction to display advertising: a half-day tutorial,Andrei Z. Broder (Yahoo!)Vanja Josifovski (Yahoo!)Jayavel Shanmugasundaram (Yahoo!),"2637163715,344688379,1989847040","Display advertising is one of the two major advertising channels on the web (in addition to search advertising). Display advertising on the Web is usually done by graphical ads placed on the publishers' Web pages. There is no explicit user query, and the ad selection is performed based on the page where the ad is placed (contextual targeting) or user's past activities (behavioral targeting). In both cases, sophisticated text analysis and learning algorithms are needed to provide relevant ads to the user. In this tutorial we will overview the display advertising marketplace, and technologies that power the display advertising platforms.",2011,Web Search and Data Mining,Fields of study: native advertisingkeyword advertisingsearch advertisingadvertising campaigncompensation methodstargetingweb pagecontextual advertisingonline advertisingtext miningmultimediaworld wide webcomputer science
Project Success Prediction in Crowdfunding Environments,Yan Li (Wayne State University)Vineeth Rakesh (Wayne State University)Chandan K. Reddy (Wayne State University),"2607418379,2153695164,2100435683","Crowdfunding has gained widespread attention in recent years. Despite the huge success of crowdfunding platforms, the percentage of projects that succeed in achieving their desired goal amount is only around 40%. Moreover, many of these crowdfunding platforms follow ""all-or-nothing"" policy which means the pledged amount is collected only if the goal is reached within a certain predefined time duration. Hence, estimating the probability of success for a project is one of the most important research challenges in the crowdfunding domain. To predict the project success, there is a need for new prediction models that can potentially combine the power of both classification (which incorporate both successful and failed projects) and regression (for estimating the time for success). In this paper, we formulate the project success prediction as a survival analysis problem and apply the censored regression approach where one can perform regression in the presence of partial information. We rigorously study the project success time distribution of crowdfunding data and show that the logistic and log-logistic distributions are a natural choice for learning from such data. We investigate various censored regression models using comprehensive data of 18K Kickstarter (a popular crowdfunding platform) projects and 116K corresponding tweets collected from Twitter. We show that the models that take complete advantage of both the successful and failed projects during the training phase will perform significantly better at predicting the success of future projects compared to the ones that only use the successful projects. We provide a rigorous evaluation on many sets of relevant features and show that adding few temporal features that are obtained at the project's early stages can dramatically improve the performance.",2016,Web Search and Data Mining,Fields of study: survival analysisregressionpredictiondata miningsimulationstatistics
"Web information management: past, present and future",Hector Garcia-Molina (Stanford University),237419955,"In this talk I will give a brief retrospective on Web Information Management, and will discuss some of the key challenges for the future. I will not give a survey of all work in the area; instead I will give my personal perspective based on work in the InfoLab at Stanford. In particular, I will touch on our lab's work on crawling, indexing, ranking, personalization, and more recently on spam detection and social networking.",2008,Web Search and Data Mining,Fields of study: social networkinformation managementinternet privacyworld wide webinformation retrievalsocial sciencedata miningcomputer science
Leveraging In-Batch Annotation Bias for Crowdsourced Active Learning,Honglei Zhuang (University of Illinois at Urbana–Champaign)Joel Young (LinkedIn),"2128637305,2723965205","Data annotation bias is found in many situations. Often it can be ignored as just another component of the noise floor. However, it is especially prevalent in crowdsourcing tasks and must be actively managed. Annotation bias on single data items has been studied with regard to data difficulty, annotator bias, etc., while annotation bias on batches of multiple data items simultaneously presented to annotators has not been studied. In this paper, we verify the existence of ""in-batch annotation bias"" between data items in the same batch. We propose a factor graph based batch annotation model to quantitatively capture the in-batch annotation bias, and measure the bias during a crowdsourcing annotation process of inappropriate comments in LinkedIn. We discover that annotators tend to make polarized annotations for the entire batch of data items in our task. We further leverage the batch annotation model to propose a novel batch active learning algorithm. We test the algorithm on a real crowdsourcing platform and find that it outperforms in-batch bias naive algorithms.",2015,Web Search and Data Mining,Fields of study: crowdsourcingactive learningworld wide webinformation retrievaldata miningcomputer science
Evaluation of semantic events for legal case retrieval,K. Tamsin Maxwell (University of Edinburgh)Jon Oberlander (University of Edinburgh)Victor Lavrenko (University of Edinburgh),"2128368488,2116426151,2093531752","Legal argument is based on the facts of a case as well as legal issues, concepts and factors. We assess the feasibility of using semantic events extracted from court judgements to adequately represent the legal concepts and factual content of cases for legal information retrieval (IR). Results of a preliminary study show extracted events are attributed with 74% accuracy, 72% legal importance, and representing 86% of sentence meaning.",2009,Web Search and Data Mining,Fields of study: information retrievaldata miningdatabasecomputer science
Representation Learning for Information Diffusion through Social Networks: an Embedded Cascade Model,Simon Bourigault (University of Paris)Sylvain Lamprier (University of Paris)Patrick Gallinari (University of Paris),"2342564854,2591467125,2638033927","In this paper, we focus on information diffusion through social networks. Based on the well-known Independent Cascade model, we embed users of the social network in a latent space to extract more robust diffusion probabilities than those defined by classical graphical learning approaches. Better generalization abilities provided by the use of such a projection space allows our approach to present good performances on various real-world datasets, for both diffusion prediction and influence relationships inference tasks. Additionally, the use of a projection space enables our model to deal with larger social networks.",2016,Web Search and Data Mining,Fields of study: feature learningtheoretical computer sciencedata miningartificial intelligencemachine learningcomputer science
Models and algorithms for social influence analysis,Jimeng Sun (IBM)Jie Tang (Tsinghua University),"2110385854,2158012360","Social influence is the behavioral change of a person because of the perceived relationship with other people, organizations and society in general. Social influence has been a widely accepted phenomenon in social networks for decades. Many applications have been built based around the implicit notation of social influence between people, such as marketing, advertisement and recommendations. With the exponential growth of online social network services such as Facebook and Twitter, social influence can for the first time be measured over a large population. In this tutorial, we survey the research on social influence analysis with a focus on the computational aspects. First, we introduce how to verify the existence of social influence in various social networks. Second, we present computational models for quantifying social influence. Third, we describe how social influence can help real applications. In particular, we will focus on opinion leader finding and influence maximization for viral marketing. Finally, we apply the selected algorithms of social influence analysis on different social network data, such as twitter, arnetminer data, weibo, and slashdot forum.",2013,Web Search and Data Mining,Fields of study: social heuristicssocial learningsocial influencesocial networksocial computingmanagement sciencesocial science
CCCF: Improving Collaborative Filtering via Scalable User-Item Co-Clustering,Yao Wu (Simon Fraser University)Xudong Liu (Chinese Academy of Sciences)Min Xie (Walmart Labs)Martin Ester (Simon Fraser University)Qing Yang (Chinese Academy of Sciences),"2139499555,2693378432,2396864932,2067196623,2697632922","Collaborative Filtering (CF) is the most popular method for recommender systems. The principal idea of CF is that users might be interested in items that are favorited by similar users, and most of the existing CF methods measure users' preferences by their behaviours over all the items. However, users might have different interests over different topics, thus might share similar preferences with different groups of users over different sets of items. In this paper, we propose a novel and scalable method CCCF which improves the performance of CF methods via user-item co-clustering. CCCF first clusters users and items into several subgroups, where each subgroup includes a set of like-minded users and a set of items in which these users share their interests. Then, traditional CF methods can be easily applied to each subgroup, and the recommendation results from all the subgroups can be easily aggregated. Compared with previous works, CCCF has several advantages including scalability, flexibility, interpretability and extensibility. Experimental results on four real world data sets demonstrate that the proposed method significantly improves the performance of several state-of-the-art recommendation algorithms.",2016,Web Search and Data Mining,Fields of study: collaborative filteringbiclusteringworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Adaptive weighing designs for keyword value computation,John W. Byers (Boston University)Michael Mitzenmacher (Harvard University)Georgios Zervas (Boston University),"2101152111,1988080645,2080016373","Attributing a dollar value to a keyword is an essential part of running any profitable search engine advertising campaign. When an advertiser has complete control over the interaction with and monetization of each user arriving on a given keyword, the value of that term can be accurately tracked. However, in many instances, the advertiser may monetize arrivals indirectly through one or more third parties. In such cases, it is typical for the third party to provide only coarse-grained reporting: rather than report each monetization event, users are aggregated into larger channels and the third party reports aggregate information such as total daily revenue for each channel. Examples of third parties that use channels include Amazon and Google AdSense. In such scenarios, the number of channels is generally much smaller than the number of keywords whose value per click (VPC) we wish to learn. However, the advertiser has flexibility as to how to assign keywords to channels over time. We introduce the channelization problem: how do we adaptively assign keywords to channels over the course of multiple days to quickly obtain accurate VPC estimates of all keywords? We relate this problem to classical results in weighing design, devise new adaptive algorithms for this problem, and quantify the performance of these algorithms experimentally. Our results demonstrate that adaptive weighing designs that exploit statistics of term frequency, variability in VPCs across keywords, and flexible channel assignments over time provide the best estimators of keyword VPCs.",2010,Web Search and Data Mining,Fields of study: design of experimentsleast squaresworld wide webinformation retrievaldata miningmachine learningsimulationstatisticscomputer science
"Mining billion-node graphs: patterns, generators and tools",Christos Faloutsos (Carnegie Mellon University),2198983026,"What do graphs look like? How do they evolve over time? How to handle a graph with a billion nodes? We present a comprehensive list of static and temporal laws, and some recent observations on real graphs (like, e.g., ""eigenSpokes""). For generators, we describe some recent ones, which naturally match all of the known properties of real graphs. Finally, for tools, we present ""oddBall"" for discovering anomalies and patterns, as well as an overview of the PEGASUS system which is designed for handling Billion-node graphs, running on top of the ""hadoop"" system.",2011,Web Search and Data Mining,Fields of study: videodata sciencetheoretical computer sciencedata miningcomputer science
Temporally Factorized Network Modeling for Evolutionary Network Analysis,"Wenchao Yu (University of California, Los Angeles)Charu C. Aggarwal (IBM)Wei Wang (University of California, Los Angeles)","2656167906,2146335907,2680973771","The problem of evolutionary network analysis has gained increasing attention in recent years, because of an increasing number of networks, which are encountered in temporal settings. For example, social networks, communication networks, and information networks continuously evolve over time, and it is desirable to learn interesting trends about how the network structure evolves over time, and in terms of other interesting trends. One challenging aspect of networks is that they are inherently resistant to parametric modeling, which allows us to truly express the edges in the network as functions of time. This is because, unlike multidimensional data, the edges in the network reflect interactions among nodes, and it is difficult to independently model the edge as a function of time, without taking into account its correlations and interactions with neighboring edges. Fortunately, we show that it is indeed possible to achieve this goal with the use of a matrix factorization, in which the entries are parameterized by time. This approach allows us to represent the edge structure of the network purely as a function of time, and predict the evolution of the network over time. This opens the possibility of using the approach for a wide variety of temporal network analysis problems, such as predicting future trends in structures, predicting links, and node-centric anomaly/event detection. This flexibility is because of the general way in which the approach allows us to express the structure of the network as a function of time. We present a number of experimental results on a number of temporal data sets showing the effectiveness of the approach.",2017,Web Search and Data Mining,Fields of study: evolving networksdynamic network analysisnetwork formationinteraction networknetwork simulationanomaly detectiondata miningartificial intelligencemachine learningcomputer science
Stochastic query covering,Aris Anagnostopoulos (Sapienza University of Rome)Luca Becchetti (Sapienza University of Rome)Stefano Leonardi (Sapienza University of Rome)Ida Mele (Sapienza University of Rome)Piotr Sankowski (University of Warsaw),"2136686850,2095497563,2155997025,1999225486,1514551219","In this paper we introduce the problem of query covering as a means to efficiently cache query results. The general idea is to populate the cache with documents that contribute to the result pages of a large number of queries, as opposed to caching the top documents for each query. It turns out that the problem is hard and solving it requires knowledge of the structure of the queries and the results space, as well as knowledge of the input query distribution. We formulate the problem under the framework of stochastic optimization; theoretically it can be seen as a stochastic universal version of set multicover. While the problem is NP-hard to be solved exactly, we show that for any distribution it can be approximated using a simple greedy approach. Our theoretical findings are complemented by experimental activity on real datasets, showing the feasibility and potential interest of query-covering approaches in practice.",2011,Web Search and Data Mining,Fields of study: sargablerankingboolean conjunctive queryweb query classificationspatial queryquery expansionquery optimizationstochastic optimizationtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learning
Estimating content concreteness for finding comprehensible documents,Shinya Tanaka (Kyoto University)Adam Jatowt (Kyoto University)Makoto P. Kato (Kyoto University)Katsumi Tanaka (Kyoto University),"2307353705,13250842,1993270567,2100196114","Document comprehensibility is one of key factors determining document quality and, in result, user's satisfaction. Relevant web pages are of little utility if they are incomprehensible or impose too much cognitive burden on readers. Traditional measures of text difficulty focus often on syntactic factors of text such as sentence length, word length, syllable count, or they utilize fixed list of common terms. However, document comprehensibility depends on many factors, of which concreteness and the ease of concept visualization are crucial ones. In this paper, we first propose a method for predicting the concreteness of terms using SVM regression. We then extend it to calculating document concreteness level. The experimental results indicate satisfactory accuracy in estimating both term and document concreteness as well as demonstrate positive correlation between the document concreteness and comprehensibility. Our ultimate goal is to enable comprehension-driven search, which will return both relevant and comprehensible results.",2013,Web Search and Data Mining,Fields of study: natural language processingspeech recognitioninformation retrievalcomputer science
Motifs in Temporal Networks,Ashwin Paranjape (Stanford University)Austin R. Benson (Stanford University)Jure Leskovec (Stanford University),"2242317802,2117961877,1878631932","Networks are a fundamental tool for modeling complex systems in a variety of domains including social and communication networks as well as biology and neuroscience. The counts of small subgraph patterns in networks, called network motifs, are crucial to understanding the structure and function of these systems. However, the role of network motifs for temporal networks, which contain many timestamped links between nodes, is not well understood. Here we develop a notion of a temporal network motif as an elementary unit of temporal networks and provide a general methodology for counting such motifs. We define temporal network motifs as induced subgraphs on sequences of edges, design several fast algorithms for counting temporal network motifs, and prove their runtime complexity. We also show that our fast algorithms achieve 1.3x to 56.5x speedups compared to a baseline method. We use our algorithms to count temporal network motifs in a variety of real-world datasets. Results show that networks from different domains have significantly different motif frequencies, whereas networks from the same domain tend to have similar motif frequencies. We also find that measuring motif counts at various time scales reveals different behavior.",2017,Web Search and Data Mining,Fields of study: network motifbioinformaticsdata miningmachine learningcomputer science
Lightweight Multilingual Entity Extraction and Linking,Aasish Pappu (Yahoo!)Roi Blanco (University of A Coruña)Yashar Mehdad (University of Trento)Amanda Stent (Bloomberg L.P.)Kapil Thadani (Yahoo!),"2664253316,2128286424,166776453,2607095750,2606611009","Text analytics systems often rely heavily on detecting and linking entity mentions in documents to knowledge bases for downstream applications such as sentiment analysis, question answering and recommender systems. A major challenge for this task is to be able to accurately detect entities in new languages with limited labeled resources. In this paper we present an accurate and lightweight, multilingual named entity recognition (NER) and linking (NEL) system. The contributions of this paper are three-fold: 1) Lightweight named entity recognition with competitive accuracy; 2) Candidate entity retrieval that uses search click-log data and entity embeddings to achieve high precision with a low memory footprint; and 3) efficient entity disambiguation. Our system achieves state-of-the-art performance on TAC KBP 2013 multilingual data and on English AIDA CONLL data.",2017,Web Search and Data Mining,Fields of study: document processingentity linkingunsupervised learningnatural language processinginformation retrievaldata miningcomputer science
Discriminative Learning of Infection Models,Nir Rosenfeld (Hebrew University of Jerusalem)Mor Nitzan (Hebrew University of Jerusalem)Amir Globerson (Tel Aviv University),"2156764571,2473050311,1484279603","Infection and diffusion processes over networks arise in many domains. These introduce many challenging prediction tasks, such as influence estimation, trend prediction, and epidemic source localization. The standard approach to such problems is generative: assume an underlying infection model, learn its parameters, and infer the required output. In order to learn efficiently, the chosen infection models are often simple, and learning is focused on inferring the parameters of the model rather than on optimizing prediction accuracy. Here we argue that for prediction tasks, a discriminative approach is more adequate. We introduce DIMPLE, a novel discriminative learning framework for training classifiers based on dynamic infection models. We show how highly non-linear predictors based on infection models can be ""linearized"" by considering a larger class of prediction functions. Efficient learning over this class is performed by constructing ""infection kernels"" based on the outputs of infection models, and can be plugged into any kernel-supporting framework. DIMPLE can be applied to virtually any infection-related prediction task and any infection model for which the desired output can be calculated or simulated. For influence estimation in well-known infection models, we show that the kernel can either be computed in closed form, or reduces to estimating co-influence of seed pairs. We apply DIMPLE to the tasks of influence estimation on synthetic and real data from Digg, and to predicting customer network value in Polly, a viral phone-based development-related service deployed in low-literate communities. Our results show that DIMPLE outperforms strong baselines.",2016,Web Search and Data Mining,Fields of study: discriminative modelkernel methodsocial networksocial sciencedata miningmachine learningsimulationstatisticscomputer science
Probabilistic Group Recommendation Model for Crowdfunding Domains,Vineeth Rakesh (Wayne State University)Wang Chien Lee (Pennsylvania State University)Chandan K. Reddy (Wayne State University),"2153695164,2143778659,2100435683","Crowdfunding has gained a widespread popularity by fueling the creative minds of entrepreneurs. Not only has it democratized the funding of startups, it has also bridged the gap between the venture capitalists and the entrepreneurs by providing a plethora of opportunities for people seeking to invest in new business ventures. Nonetheless, despite the huge success of the crowdfunding platforms, not every project reaches its funding goal. One of the main reasons for a project's failure is the difficulty in establishing a linkage between it's founders and those investors who are interested in funding such projects. A potential solution to this problem is to develop recommendation systems that suggest suitable projects to crowdfunding investors by capturing their interests. In this paper, we explore Kickstarter, a popular reward-based crowdfunding platform. Being a highly heterogeneous platform, Kickstarter is fuelled by a dynamic community of people who constantly interact with each other before investing in projects. Therefore, the decision to invest in a project depends not only on the preference of individuals, but also on the influence of groups that a person belongs and the on-going status of the projects. In this paper, we propose a probabilistic recommendation model, called CrowdRec, that recommends Kickstarter projects to a group of investors by incorporating the on-going status of projects, the personal preference of individual members, and the collective preference of the group . Using a comprehensive dataset of over 40K crowdfunding groups and 5K projects, we show that our model is effective in recommending projects to groups of Kickstarter users.",2016,Web Search and Data Mining,Fields of study: topic modelworld wide webdata miningmachine learningcomputer science
Centrality-Aware Link Recommendations,Nikos Parotsidis (University of Rome Tor Vergata)Evaggelia Pitoura (University of Ioannina)Panayiotis Tsaparas (University of Ioannina),"2280510899,2242762518,2234654910","Link recommendations are critical for both improving the utility and expediting the growth of social networks. Most previous approaches focus on suggesting links that are highly likely to be adopted. In this paper, we add a different perspective to the problem by aiming at recommending links that also improve specific properties of the network. In particular, our goal is to recommend to users links that if adopted would improve their centrality in the network. Specifically, we introduce the centrality-aware link recommendation problem as the problem of recommending to a user u , k links from a pool of recommended links so as to maximize the expected decrease of the sum of the shortest path distances of $u$ to all other nodes in the network. We show that the problem is NP-hard, but our optimization function is monotone and sub-modular which guarantees a constant approximation ratio for the greedy algorithm. We present a fast algorithm for computing the expected decrease caused by a set of recommendations which we use as a building block in our algorithms. We provide experimental results that evaluate the performance of our algorithms with respect to both the accuracy of the prediction and the improvement in the centrality of the nodes, and we study the tradeoff between the two.",2016,Web Search and Data Mining,Fields of study: social networkdistributed computingdata miningmachine learning
Bursty subgraphs in social networks,Milad Eftekhar (University of Toronto)Nick Koudas (University of Toronto)Yashar Ganjali (University of Toronto),"2123746623,335443309,1982628752","Data available through social media and content sharing platforms present opportunities for analysis and mining. In the context of social networks, it is interesting to formalize and locate bursts of activities amongst users, related to a particular event and to report sets of socially connected users participating in such bursts. Such collections present new opportunities for understanding social events, and render new ways of online marketing. In this paper, we model social information using two conceptualized graph models. The first one (the action graph) provides a detailed model of all activities of all users while the second one (the holistic graph) provides an aggregate view on each user in the social media. We also propose two models to define the notion of ""burst"". The first model (intrinsic burst model) takes the intrinsic characteristics of each user into account to recognize the bursty behaviors; while the second model (social burst model) considers neighbors' influences when identifying bursts. We provide two linear algorithms to detect bursts based on the proposed models. These algorithms have been extensively evaluated on a month of full Twitter dataset certifying the practicality of our approach. A detailed qualitative study of our techniques is also presented.",2013,Web Search and Data Mining,Fields of study: social networkworld wide webdata miningcomputer science
ANNE: Improving Source Code Search using Entity Retrieval Approach,Venkatesh Vinayakarao (Indraprastha Institute of Information Technology)Anita Sarma (Oregon State University)Rahul Purandare (Indraprastha Institute of Information Technology)Shuktika Jain (Indraprastha Institute of Information Technology)Saumya Jain (Indraprastha Institute of Information Technology),"2229336357,2150694261,2304868683,2223598248,2225853807","Code search with natural language terms performs poorly because programming concepts do not always lexically match their syntactic forms. For example, in Java, the programming concept ""array"" does not match with its syntactic representation of ""[ ]"". Code search engines can assist developers more effectively over natural language queries if such mappings existed for a variety of programming languages. In this work, we present a programming language agnostic technique to discover such mappings between syntactic forms and natural language terms representing programming concepts. We use the questions and answers in Stack Overflow to create this mapping. We implement our approach in a tool called ANNE. To evaluate its effectiveness, we conduct a user study in an academic setting in which teaching assistants use ANNE to search for code snippets in student submissions. With the use of ANNE, we find that the participants are 29% quicker with no significant drop in correctness and completeness.",2017,Web Search and Data Mining,Fields of study: first generation programming languageprogramming domainvery high level programming languagehigh level programming languageprogramming paradigmlow level programming languagenatural language programmingtheoretical computer sciencenatural language processingworld wide webinformation retrievaldata miningmachine learningprogramming languagealgorithmcomputer science
Beyond Ranking: Optimizing Whole-Page Presentation,Yue Wang (University of Michigan)Dawei Yin (Yahoo!)Luo Jie (Idiap Research Institute)Pengyuan Wang (Yahoo!)Makoto Yamada (Kyoto University)Yi Chang (Yahoo!)Qiaozhu Mei (University of Michigan),"2618535762,2170531144,2095673574,2157416250,2164730556,2168000538,2166036605","Modern search engines aggregate results from different verticals: webpages, news, images, video, shopping, knowledge cards, local maps, etc. Unlike ""ten blue links"", these search results are heterogeneous in nature and not even arranged in a list on the page. This revolution directly challenges the conventional ""ranked list"" formulation in ad hoc search. Therefore, finding proper presentation for a gallery of heterogeneous results is critical for modern search engines. We propose a novel framework that learns the optimal page presentation to render heterogeneous results onto search result page (SERP). Page presentation is broadly defined as the strategy to present a set of items on SERP, much more expressive than a ranked list. It can specify item positions, image sizes, text fonts, and any other styles as long as variations are within business and design constraints. The learned presentation is content-aware, i.e. tailored to specific queries and returned results. Simulation experiments show that the framework automatically learns eye-catchy presentations for relevant results. Experiments on real data show that simple instantiations of the framework already outperform leading algorithm in federated search result presentation. It means the framework can learn its own result presentation strategy purely from data, without even knowing the ""probability ranking principle"".",2016,Web Search and Data Mining,Fields of study: multimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Searching and exploring controlled vocabularies,Alasdair J. G. Gray (University of Glasgow)Norman Gray (University of Leicester)Iadh Ounis (University of Glasgow),"2126464511,2097258391,336997814","Within most domains of discourse, there exists different terminology used by distinct sub-groups. Often the terms used can be, or have already been, organised into controlled vocabularies which can be encoded into SKOS, a W3C standard for representing vocabularies. This terminology can then be used to help users to search for and discover resources. This requires a search mechanism to go from a user-supplied string to a vocabulary concept. In this paper, we discuss the issues encountered in developing a web service for searching and exploring the concepts in SKOS encoded astronomical vocabularies. Our prototype service takes in a query and responds with the concepts which are the ""best match"". It then supports the user in exploring the concepts' formal definition and alternative forms, as well as their relationship to other concepts. When we add mappings between the concepts in different vocabularies (where available), these further enrich the explorations of vocabulary concepts.",2009,Web Search and Data Mining,Fields of study: controlled vocabularynatural language processingworld wide webdata miningcomputer science
Nowcasting the macroeconomy with search engine data,Hal R. Varian (Google),125896300,"It is now possible to acquire real time information on economic variables of interest from various commercial sources. I illustrate how one can use Google Trends data to measure the state of the macroeconomy in various sectors, and discuss some of the ramifications for research and policy.",2012,Web Search and Data Mining,Fields of study: search engineforecastingdata sciencedata miningsimulationstatisticscomputer science
Online multi-modal distance learning for scalable multimedia retrieval,Hao Xia (Nanyang Technological University)Pengcheng Wu (Nanyang Technological University)Steven C.H. Hoi (Nanyang Technological University),"2306943459,2108925152,108406206","In many real-word scenarios, e.g., multimedia applications, data often originates from multiple heterogeneous sources or are represented by diverse types of representation, which is often referred to as ""multi-modal data"". The definition of distance between any two objects/items on multi-modal data is a key challenge encountered by many real-world applications, including multimedia retrieval. In this paper, we present a novel online learning framework for learning distance functions on multi-modal data through the combination of multiple kernels. In order to attack large-scale multimedia applications, we propose Online Multi-modal Distance Learning (OMDL) algorithms, which are significantly more efficient and scalable than the state-of-the-art techniques. We conducted an extensive set of experiments on multi-modal image retrieval applications, in which encouraging results validate the efficacy of the proposed technique.",2013,Web Search and Data Mining,Fields of study: laplacian matrixtheoretical computer scienceworld wide webinformation retrievalmachine learningcomputer science
Estimating ad group performance in sponsored search,Dawei Yin (Lehigh University)Bin Cao (Microsoft)Jian-Tao Sun (Microsoft)Brian D. Davison (Lehigh University),"2170531144,2618926548,2131116857,2203702053","In modern commercial search engines, the pay-per-click (PPC) advertising model is widely used in sponsored search. The search engines try to deliver ads which can produce greater click yields (the total number of clicks for the list of ads per impression). Therefore, predicting user clicks plays a critical role in sponsored search. The current ad-delivery strategy is a two-step approach which first predicts individual ad CTR for the given query and then selects the ads with higher predicted CTR. However, this strategy is naturally suboptimal and correlation between ads is often ignored under this strategy. The learning problem is focused on predicting individual performance rather than group performance which is the more important measurement. In this paper, we study click yield measurement in sponsored search and focus on the problem---predicting group performance (click yields) in sponsored search. To tackle all challenges in this problem---depth effects, interactive influence, cold start and sparseness of ad textual information---we first investigate several effects and propose a novel framework that could directly predict group performance for lists of ads. Our extensive experiments on a large-scale real-world dataset from a commercial search engine show that we achieve significant improvement by solving the sponsored search problem from the new perspective. Our methods noticeably outperform existing state-of-the-art approaches.",2014,Web Search and Data Mining,Fields of study: click through rateworld wide webdata miningsimulation
Understanding and Identifying Advocates for Political Campaigns on Social Media,Suhas Ranganath (Arizona State University)Xia Hu (Texas A&M University)Jiliang Tang (Yahoo!)Huan Liu (Arizona State University),"2154873622,2161448330,2147392410,2122391114",-,2016,Web Search and Data Mining,-
Ten Years of Wisdom,Ricardo A. Baeza-Yates (Yahoo!),528588921,"In this keynote we attempt to cover the first ten years of ACM WSDM, the main conference on web search and data mining. We start from its inception during 2006 to the first conference held at Stanford in 2008, driven by some key people in the main web search engines of that time. We were confident on its success, but we never expected to become so fast the best venue for our research topics. We also cover the main highlights during all these years as well as current and future trends.",2017,Web Search and Data Mining,Fields of study: operations research
"Maguro, a system for indexing and searching over very large text collections",Knut Magne Risvik (Microsoft)Trishul M. Chilimbi (Microsoft)Henry Tan (Microsoft)Karthik Kalyanaraman (Microsoft)Chris Anderson (Microsoft),"192618403,2077038638,2475726060,1964246453,2571170104","Maguro is a system for efficiently searching very large collections of text content of up to 1 trillion documents at low cost. Search engines span across content that is very dynamic and highly augmented with metadata to the tail content of the web. A long tail distribution of content calls for different trade-offs in the design space for good efficiency across the entire index range. Maguro is designed for the long tail of content with less dynamics and less metadata, but very good cost efficiency. Maguro is part of the serving stack in Bing and allows us to scale the index significantly better.",2013,Web Search and Data Mining,Fields of study: scalabilityworld wide webinformation retrievaldata miningdatabasecomputer science
Querying and Tracking Influencers in Social Streams,Karthik Subbian (University of Minnesota)Charu C. Aggarwal (IBM)Jaideep Srivastava (University of Minnesota),"2230469306,2146335907,2192802387","Influence analysis is an important problem in social network analysis due to its impact on viral marketing and targeted advertisements. Most of the existing influence analysis methods determine the influencers in a static network with an influence propagation model based on pre-defined edge propagation probabilities. However, none of these models can be queried to find influencers in both context and time-sensitive fashion from a streaming social data. In this paper, we propose an approach to maintain real-time influence scores of users in a social stream using a topic and time-sensitive approach, while the network and topic is constantly evolving over time. We show that our approach is efficient in terms of online maintenance and effective in terms various types of real-time context- and time-sensitive queries. We evaluate our results on both social and collaborative network data sets.",2016,Web Search and Data Mining,Fields of study: data scienceworld wide webdata miningcomputer science
"Big graph mining for the web and social media: algorithms, anomaly detection, and applications",U. Kang (KAIST)Leman Akoglu (Stony Brook University)Duen Horng Chau (Georgia Institute of Technology),"2638161336,2288278917,2024561599","Graphs are everywhere: social networks, computer net- works, mobile call networks, the World Wide Web, protein interaction networks, and many more. The lower cost of disk storage, the success of social networking websites and Web 2.0 applications, and the high availability of data sources lead to graphs being generated at unprecedented size. They are now measured in terabytes or even petabytes, with more than billions of nodes and edges. Finding patterns on large graphs have a lot of applica- tions including cyber security on the Web, social media min- ing (Facebook, Twitter), and fraud detection, among others. This tutorial will cover topics related to finding patterns and anomalies and sensemaking in large-scale graphs with appli- cations to real-world problems in social media and the Web. Specifically, we aim to answer the following questions: How can we scale up graph mining algorithms for massive graphs with billions of edges? How can we find anomalies in such large-scale graphs? How can we make sense of disk-resident large graphs, what and how can we do visual analytics? How can we use the algorithms and anomaly detection techniques to solve challenging real-world problems that play key role in social media and the Web? Our tutorial consists of three main parts. We start with scalable graph mining algorithms for billion-scale graphs, in- cluding structure analysis, eigensolvers, storage and index- ing, and graph layout and graph compression. Next we de- scribe anomaly detection techniques for large scale graphs with applications on social media. Finally, we discuss vi- sual analytics techniques which leverage these algorithms and anomaly detection techniques in the previous parts.",2014,Web Search and Data Mining,Fields of study: graph kernelvisual analyticsanomaly detectiondata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
"On Stability, Clarity, and Co-occurrence of Self-Tagging.",Aixin Sun (Nanyang Technological University)Anwitaman Datta (Nanyang Technological University),"2124989948,2298696728",-,2009,Web Search and Data Mining,Fields of study: computer science
Exploration and mining of web repositories,Nan Zhang (George Washington University)Gautam Das (University of Texas at Arlington),"2166589344,2112689123","With the proliferation of very large data repositories hidden behind web interfaces, e.g., keyword search, form-like search and hierarchical/graph-based browsing interfaces for Amazon.com, eBay.com, etc., efficient ways of searching, exploring and/or mining such web data are of increasing importance. There are two key challenges facing these tasks: how to properly understand web interfaces, and how to bypass the interface restrictions. In this tutorial, we start with a general overview of web search and data mining, including various exciting applications enabled by the effective search, exploration, and mining of web repositories. Then, we focus on the fundamental developments in the field, including web interface understanding, crawling, sampling, and data analytics over web repositories with various types of interfaces. We also discuss the potential changes required for query processing, data mining and machine learning algorithms to be applied to web data. Our goal is two-fold: one is to promote the awareness of existing web data search/explora-tion/mining techniques among all web researchers who are interested in leveraging web data, and the other is to encourage researchers, especially those who have not previously worked in web search and mining before, to initiate their own research in these exciting areas.",2014,Web Search and Data Mining,Fields of study: web 2 0web modelingsocial semantic webweb analyticsdata webweb standardsweb mappingweb application securityweb search queryweb developmentweb designweb navigationweb serviceweb pagedata analysisweb intelligencedeep webweb miningdata scienceworld wide webinformation retrievaldata miningcomputer science
Differences in search engine evaluations between query owners and non-owners,Alexandra Chouldechova (Stanford University)David Mease (Google),"2336117416,2611703289","The query-document relevance judgments used in web search engine evaluation are traditionally provided by human assessors who have no particular association with the specific queries selected for the evaluation. Most commonly, queries are randomly sampled from search logs and in turn randomly assigned to the human assessors. In this paper, we consider a very different approach in which we instead ask the human assessors to provide their own queries from their recent search experiences. Using these queries as our sample, we compare the relevance judgments from the ""owners"" of the queries to the relevance judgments of the non-owners. We conduct experiments which reveal that query ownership has a substantial and beneficial impact on the accuracy of relevance judgments. In particular, we observe that owners are more consistently able to distinguish a higher quality set of search results from a lower quality set in a blind comparison. The implication for web search evaluation is that query owners provide more valuable relevance judgments than non-owners, presumably due to the background knowledge associated with their queries. We quantify the benefit of using owner assessments versus non-owner assessments in terms of sample size reduction. We also touch on some of the practical challenges associated with using query owners as assessors.",2013,Web Search and Data Mining,Fields of study: evaluationdesign of experimentsworld wide webinformation retrievaldata miningdatabasestatisticscomputer science
Latent dirichlet allocation based diversified retrieval for e-commerce search,Jun Yu (Oregon State University)Sunil Mohan (eBay)Duangmanee (Pew) Putthividhya (Google)Weng-Keen Wong (Oregon State University),"2246618435,2652482172,2311023838,2102128069","Diversified retrieval is a very important problem on many e-commerce sites, e.g. eBay and Amazon. Using IR approaches without optimizing for diversity results in a clutter of redundant items that belong to the same products. Most existing product taxonomies are often too noisy, with overlapping structures and non-uniform granularity, to be used directly in diversified retrieval. To address this problem, we propose a Latent Dirichlet Allocation (LDA) based diversified retrieval approach that selects diverse items based on the hidden user intents. Our approach first discovers the hidden user intents of a query using the LDA model, and then ranks the user intents by making trade-offs between their relevance and information novelty. Finally, it chooses the most representative item for each user intent to display. To evaluate the diversity in the search results on e-commerce sites, we propose a new metric, average satisfaction, measuring user satisfaction with the search results. Through our empirical study on eBay, we show that the LDA model discovers meaningful user intents and the LDA-based approach provides significantly higher user satisfaction than the eBay production ranker and three other diversified retrieval approaches.",2014,Web Search and Data Mining,Fields of study: latent dirichlet allocationworld wide webinformation retrievaldata miningmachine learningcomputer science
Deep Memory Networks for Attitude Identification,Cheng Li (University of Michigan)Xiaoxiao Guo (University of Michigan)Qiaozhu Mei (University of Michigan),"2674810995,2684295031,2166036605","We consider the task of identifying attitudes towards a given set of entities from text. Conventionally, this task is decomposed into two separate subtasks: target detection that identifies whether each entity is mentioned in the text, either explicitly or implicitly, and polarity classification that classifies the exact sentiment towards an identified entity (the target) into positive, negative, or neutral. Instead, we show that attitude identification can be solved with an end-to-end machine learning architecture, in which the two subtasks are interleaved by a deep memory network. In this way, signals produced in target detection provide clues for polarity classification, and reversely, the predicted polarity provides feedback to the identification of targets. Moreover, the treatments for the set of targets also influence each other -- the learned representations may share the same semantics for some targets but vary for others. The proposed deep memory network, the AttNet, outperforms methods that do not consider the interactions between the subtasks or those among the targets, including conventional machine learning methods and the state-of-the-art deep learning models.",2017,Web Search and Data Mining,Fields of study: deep learningsentiment analysisartificial intelligencemachine learningcomputer science
Beyond the Words: Predicting User Personality from Heterogeneous Information,Honghao Wei (Tsinghua University)Fuzheng Zhang (Microsoft)Nicholas Jing Yuan (Microsoft)Chuan Cao (Microsoft)Hao Fu (Microsoft)Xing Xie (Microsoft)Yong Rui (Microsoft)Wei-Ying Ma (Microsoft),"2656481244,2110384818,2096490164,2596658987,2594992494,2125800575,2130014478,2134693834","An incisive understanding of user personality is not only essential to many scientific disciplines, but also has a profound business impact on practical applications such as digital marketing, personalized recommendation, mental diagnosis, and human resources management. Previous studies have demonstrated that language usage in social media is effective in personality prediction. However, except for single language features, a less researched direction is how to leverage the heterogeneous information on social media to have a better understanding of user personality. In this paper, we propose a Heterogeneous Information Ensemble framework, called HIE, to predict users' personality traits by integrating heterogeneous information including self-language usage, avatar, emoticon, and responsive patterns. In our framework, to improve the performance of personality prediction, we have designed different strategies extracting semantic representations to fully leverage heterogeneous information on social media. We evaluate our methods with extensive experiments based on a real-world data covering both personality survey results and social media usage from thousands of volunteers. The results reveal that our approaches significantly outperform several widely adopted state-of-the-art baseline methods. To figure out the utility of HIE in a real-world interactive setting, we also present DiPsy, a personalized chatbot to predict user personality through heterogeneous information in digital traces and conversation logs.",2017,Web Search and Data Mining,Fields of study: knowledge managementmultimediaworld wide webinformation retrievaldata miningmachine learning
Relational Learning with Social Status Analysis,Liang Wu (Arizona State University)Xia Hu (Texas A&M University)Huan Liu (Arizona State University),"2666048107,2161448330,2122391114","Relational learning has been proposed to cope with the interdependency among linked instances in social network analysis, which often adopts network connectivity and social media content for prediction. A common assumption in existing relational learning methods is that data instances are equally important. The algorithms developed based on the assumption may be significantly affected by outlier data and thus less robust. In the meantime, it has been well established in social sciences that actors are naturally of different social status in a social network. Motivated by findings from social sciences, in this paper, we investigate whether social status analysis could facilitate relational learning. Particularly, we propose a novel framework RESA to model social status using the network structure. It extracts robust and intrinsic latent social dimensions for social actors, which are further exploited as features for supervised learning models. The proposed method is applicable for real-world relational learning problems where noise exists. Extensive experiments are conducted on datasets obtained from real-world social media platforms. Empirical results demonstrate the effectiveness of RESA and further experiments are conducted to help understand the effects of parameter settings to the proposed model and how local social status works.",2016,Web Search and Data Mining,Fields of study: social heuristicssocial mediasocial learningsocial networkstatistical relational learningknowledge managementworld wide webdata miningmachine learningcomputer science
"Harvesting, searching, and ranking knowledge on the web: invited talk",Gerhard Weikum (Max Planck Society),514836396,"There are major trends to advance the functionality of search engines to a more expressive semantic level (e.g., [2, 4, 6, 7, 8, 9, 13, 14, 18]). This is enabled by employing large-scale information extraction [1, 11, 20] of entities and relationships from semistructured as well as natural-language Web sources. In addition, harnessing Semantic-Web-style ontologies [22] and reaching into Deep-Web sources [16] can contribute towards a grand vision of turning the Web into a comprehensive knowledge base that can be efficiently searched with high precision. This talk presents ongoing research towards this objective, with emphasis on our work on the YAGO knowledge base [23, 24] and the NAGA search engine [14] but also covering related projects. YAGO is a large collection of entities and relational facts that are harvested from Wikipedia and WordNet with high accuracy and reconciled into a consistent RDF-style ""semantic"" graph. For further growing YAGO from Web sources while retaining its high quality, pattern-based extraction is combined with logic-based consistency checking in a unified framework [25]. NAGA provides graph-template-based search over this data, with powerful ranking capabilities based on a statistical language model for graphs. Advanced queries and the need for ranking approximate matches pose efficiency and scalability challenges that are addressed by algorithmic and indexing techniques [15, 17]. YAGO is publicly available and has been imported into various other knowledge-management projects including DB-pedia. YAGO shares many of its goals and methodologies with parallel projects along related lines. These include Avatar [19], Cimple/DBlife [10, 21], DBpedia [3], Know-ItAll/TextRunner [12, 5], Kylin/KOG [26, 27], and the Libra technology [18, 28] (and more). Together they form an exciting trend towards providing comprehensive knowledge bases with semantic search capabilities.",2009,Web Search and Data Mining,Fields of study: semantic webscalabilitynatural languagesearch enginesemantic searchinformation extractionknowledge baseworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Log-based personalization: the 4th web search click data (WSCD) workshop,Pavel Serdyukov (Yandex)Georges Dupret (Yahoo!)Nick Craswell (Microsoft),"2130450538,2080443884,2009495402","WSCD 2014 is the fourth workshop on Web Search Click Data, following WSCD 2009, WSCD 2011 and WSCD 2012. It is a forum for new research relating to Web search usage logs and for discussing desirable properties of publicly released search log datasets. Research relating to search logs has been hampered by the limited availability of click datasets. This series of workshops comes with new datasets based on logged user search behaviour and accompanying data mining challenges. This year the challenge and the workshop are focused on the tasks of personalization using logs.",2014,Web Search and Data Mining,Fields of study: click pathweb analyticsweb search queryweb search enginedata scienceworld wide webdata miningcomputer science
WSDM 2017 Workshop on Mining Online Health Reports: MOHRS 2017,Nigel Collier (University of Cambridge)Nut Limsopatham (University of Cambridge)Aron Culotta (Illinois Institute of Technology)Mike Conway (University of Utah)Ingemar J. Cox (University College London)Vasileios Lampos (University College London),"2686504317,2670406119,2151487642,2156711264,2684480055,100906785","The workshop on Mining Online Health Reports (MOHRS) draws upon the rapidly developing field of Computational Health, focusing on textual content that has been generated through the various facets of Web activity. Online user-generated information mining, especially from social media platforms and search engines, has been in the forefront of many research efforts, especially in the fields of Information Retrieval and Natural Language Processing. The incorporation of such data and techniques in a number of health-oriented applications has provided strong evidence about the potential benefits, which include better population coverage, timeliness and the operational ability in places with less established health infrastructure. The workshop aims to create a platform where relevant state-of-the-art research is presented, but at the same time discussions among researchers with cross-disciplinary backgrounds can take place. It will focus on the characterisation of data sources, the essential methods for mining this textual information, as well as potential real-world applications and the arising ethical issues. MOHRS '17 will feature 3 keynote talks and 4 accepted paper presentations, together with a panel discussion session.",2017,Web Search and Data Mining,Fields of study: user generated contentdata sciencenatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Collective inference for network data with copula latent markov networks,Rongjing Xiang (Purdue University)Jennifer Neville (Purdue University),"2122756025,2124572662","The popularity of online social networks and social media has increased the amount of linked data available in Web domains. Relational and Gaussian Markov networks have both been applied successfully for classification in these relational settings. However, since Gaussian Markov networks model joint distributions over continuous label space, it is difficult to use them to reason about uncertainty in discrete labels. On the other hand, relational Markov networks model probability distributions over discrete label space, but since they condition on the graph structure, the marginal probability for an instance will vary based on the structure of the subnetwork observed around the instance. This implies that the marginals will not be identical across instances and can sometimes result in poor prediction performance. In this work, we propose a novel latent relational model based on copulas which allows use to make predictions in a discrete label space while ensuring identical marginals and at the same time incorporating some desirable properties of modeling relational dependencies in a continuous space. While copulas have recently been used for descriptive modeling, they have not been used for collective classification in large scale network data and the associated conditional inference problem has not been considered before. We develop an approximate inference algorithm, and demonstrate empirically that our proposed Copula Latent Markov Network models based on approximate inference outperform a number of competing relational classification models over a range of real-world relational classification tasks.",2013,Web Search and Data Mining,Fields of study: statistical relational learningdata miningpattern recognitionmachine learningstatisticscomputer science
New Directions in Recommender Systems,Jure Leskovec (Stanford University),1878631932,"Recommender systems are an integral part of how we experience the Web today and they have become so ubiquitous that we do not even notice them anymore. However, today's recommender systems mostly treat items they recommend as black boxes and primarily focus on extracting correlations and co-counts from user behavior data. In this talk I argue that next generation recommender systems will require deep understanding of items being recommended as well as modeling the relationships between those items. I will present examples how auxiliary data about items (descriptions, reviews, product specifications) can be used to improve recommendations.",2015,Web Search and Data Mining,Fields of study: recommender systemmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Reducing Click and Skip Errors in Search Result Ranking,Jiepu Jiang (University of Massachusetts Amherst)James Allan (University of Massachusetts Amherst),"2278350695,2097030689","Search engines provide result summaries to help users quickly identify whether or not it is worthwhile to click on a result and read in detail. However, users may visit non-relevant results and/or skip relevant ones. These actions are usually harmful to the user experience, but few considered this problem in search result ranking. This paper optimizes relevance of results and user click and skip activities at the same time. Comparing two equally relevant results, our approach learns to rank the one that users are more likely to click on at a higher position. Similarly, it demotes non-relevant web pages with high click probabilities. Experimental results show this approach reduces about 10%-20% of the click and skip errors with a trade off of 2.1% decline in nDCG@10.",2016,Web Search and Data Mining,Fields of study: click pathorganic searchmultimediaworld wide webdata miningcomputer science
A Cost Model for Long-Term Compressed Data Retention,Kewen Liao (University of Melbourne)Alistair Moffat (University of Melbourne)Matthias Petri (University of Melbourne)Anthony Wirth (University of Melbourne),"2425785559,2155888323,1986955645,2091550662","Vast amounts of data are collected and stored every day, as part of corporate knowledge bases and as a response to legislative compliance requirements. To reduce the cost of retaining such data, compression tools are often applied. But simply seeking the best compression ratio is not necessarily the most economical choice, and other factors also come in to play, including compression and decompression throughput, the main memory required to support a given level of on-going access to the stored data, and the types of storage available. Here we develop a model for the total retention cost (TRC) of a data archiving regime, and by applying the charging rates associated with a cloud computing provider, are able to derive dollar amounts for a range of compression options, and hence guide the development of new approaches that are more cost-effective than current mechanisms. In particular, we describe an enhancement to the Relative Lempel Ziv (RLZ) compression scheme, and show that in terms of TRC, it outperforms previous approaches in terms of providing economical long-term data retention.",2017,Web Search and Data Mining,Fields of study: data compressionworld wide webdata miningdatabasesimulationstatisticscomputer science
Regressing Towards Simpler Prediction Systems,Tushar Chandra (Google),2150538384,"This talk will focus on our experience in managing the complexity of Sibyl, a large scale machine learning system that is widely used within Google. We believe that a large fraction of the challenges faced by Sibyl are inherent to large scale production machine learning and that other production systems are likely to encounter them as well [1]. Thus, these challenges present interesting opportunities for future research. The Sibyl system is complex for a number of reasons. We have learnt that a complete end-to-end machine learning solution has to have subsystems to address a variety of different needs: data ingestion, data analysis, data verification, experimentation, model analysis, model serving, configuration, data transformations, support for different kinds of loss functions and modeling, machine learning algorithm implementations, etc. Machine learning algorithms themselves constitute a relatively small fraction of the overall system. Each subsystem consists of a number of distinct components to support the variety of product needs. For example, Sibyl supports more than 5 different model serving systems, each with its own idiosyncrasies and challenges. In addition, Sibyl configuration contains more lines of code than the core Sibyl learner itself. Finally existing solutions for some of the challenges don't feel adequate and we believe these challenges present opportunities for future research. Though the overall system is complex, our users need to be able to deploy solutions quickly. This is because a machine learning deployment is typically an iterative process of model improvements. At each iteration, our users experiment with new features, find those that improve the model's prediction capability, and then ""launch"" a new model with those improved features. A user may go through 10 or more such productive launches. Not only is speed of iteration crucial to our users, but they are often willing to sacrifice the improved prediction quality of a high quality but cumbersome system for the speed of iteration of a lower quality but nimble system. In this talk I will give an example of how simplification drives systems design and sometimes the design of novel algorithms.",2015,Web Search and Data Mining,Fields of study: world wide webdata miningartificial intelligencemachine learningsimulationcomputer science
Spatially-aware indexing for image object retrieval,Roelof van Zwol (Yahoo!)Lluis Garcia Pueyo (Yahoo!),"281648438,2052979281","The success of image object retrieval systems relies on the visual bag-of-words paradigm, which allows image retrieval systems to adopt a retrieval strategy analogous to text retrieval. In this paper we propose two spatially-aware retrieval strategies for image object retrieval that replaces the vector space model. The advantage of the proposed spatially-aware indexing and retrieval strategies are threefold: (1) It allows for the deployment of small visual vocabularies, (2) the number of images evaluated at retrieval time is significantly reduced, and (3) it eliminates the need for a post-retrieval phase, which is normally used to test the spatial composition of the visual words in the retrieved images. The first spatially-aware retrieval strategy explores the direct neighbourhood of two local features for common visual words to determine the similarity of the region surrounding the local features. The second strategy embeds the spatial composition of its neighbourhood directly in the index using edge signatures. Both strategies rely on the coherence of the neighbourhood of points in different images containing similar objects. The comparison of the spatially-aware retrieval strategies against the vector space baseline shows a significant improvement in terms of early precision, and at the same time significantly reduce the number of candidates to be considered at retrieval time.",2012,Web Search and Data Mining,Fields of study: divergence from randomness modelterm discriminationconcept searchvisual wordbag of words modelvector space modelquantizationvector spaceautomatic image annotationimage retrievaldocument retrievalinformation retrievalcomputer visionpattern recognitionmachine learningcomputer science
Prediction in a microblog hybrid network using bonacich potential,"Shanchan Wu (HP Labs)Louiqa Raschid (University of Maryland, College Park)","2680823087,285822418","Microblogs such as Twitter support a rich variety of user interactions using hashtags, urls, retweets and mentions. Microblogs are an exemplar of a hybrid network; there is an explicit network of followers, as well as an implicit network of users who retweet other users, and users who mention other users. These networks are important proxies for influence. In this paper, we develop a comprehensive behavioral model of an individual user and her interactions in the hybrid network. We choose a focal user and predict those users who will be influenced by her, and will retweet and/or mention the focal user, in the near future. We define a potential function, based on a hybrid network, which reflects the likelihood of a candidate user being influenced by, and having a specific type of link to, a focal user, in the future. We show that the potential function based prediction model converges to the Bonacich centrality metric. We develop a fast unsupervised solution which approximates the future hybrid network and the future Bonacich potential. We perform an extensive evaluation over a microblog network and a stream of tweets from Twitter. Our solution outperforms several baseline methods including ones based on singular value decomposition (SVD) and a supervised Ranking SVM.",2014,Web Search and Data Mining,Fields of study: microblogginglinksocial mediahybridsocial networkpredictioninternet privacyworld wide webdata miningcomputer science
Advanced graph mining for community evaluation in social networks and the web,Christos Giatsidis (École Polytechnique)Fragkiskos D. Malliaros (École Polytechnique)Michalis Vazirgiannis (Athens University of Economics and Business),"1958188848,6790893,1914497179","Graphs constitute a dominant data structure and appear essentially in all forms of information. Examples are the Web graph, numerous social networks, protein interaction networks, terms dependency graphs and network topologies. The main features of these graphs are their huge volume and rate of change. Presumably, there is important hidden knowledge in the macroscopic topology and features of these graphs. A cornerstone issue here is the detection and evaluation of communities -- bearing multiple and diverse semantics. The tutorial reports the basic models of graph structures for undirected, directed and signed graphs and their properties. Next we offer a thorough review of fundamental methods for graph clustering and community detection, on both undirected and directed graphs. Then we survey community evaluation measures, including both the individual node based ones as well as those that take into account aggregate properties of communities. A special mention is made on approaches that capitalize on the concept of degeneracy (k-cores and extensions), as a novel means of community detection and evaluation. We justify the above foundational framework with applications on citation graphs, trust networks and protein graphs.",2013,Web Search and Data Mining,Fields of study: graphcommunity structuresocial network analysiscomplex networkeconomic graphtheoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer science
Scalability and Efficiency Challenges in Large-Scale Web Search Engines,Berkant Barla Cambazoglu (Yahoo!)Ricardo A. Baeza-Yates (Yahoo!),"2044137649,528588921","Commercial web search engines need to process thousands of queries every second and provide responses to user queries within a few hundred milliseconds. As a consequence of these tight performance constraints, search engines construct and maintain very large computing infrastructures for crawling the Web, indexing discovered pages, and processing user queries. The scalability and efficiency of these infrastructures require careful performance optimizations in every major component of the search engine. This tutorial aims to provide a fairly comprehensive overview of the scalability and efficiency challenges in large-scale web search engines. In particular, the tutorial provides an in-depth architectural overview of a web search engine, mainly focusing on the web crawling, indexing, and query processing components. The scalability and efficiency issues encountered in the above-mentioned components are presented at four different granularities: at the level of a single computer, a cluster of computers, a single data center, and a multi-center search engine. The tutorial also points at the open research problems and provides recommendations to researchers who are new to the field.",2015,Web Search and Data Mining,Fields of study: search analyticsdistributed web crawlingweb search queryweb query classificationcrawlingweb crawlerquery expansionscalabilitysearch engine indexingsearch engineefficiencysemantic searchmetasearch engineworld wide webinformation retrievaldata miningdatabasecomputer science
Searchable web sites recommendation,Yang Song (Microsoft)Nam Nguyen (Microsoft)Li-wei He (Microsoft)Scott Imig (Microsoft)Robert Rounthwaite (Microsoft),"2021276105,2482593273,2683009472,2117929733,1974613367","In this paper, we propose a new framework for searchable web sites recommendation. Given a query, our system will recommend a list of searchable web sites ranked by relevance, which can be used to complement the web page results and ads from a search engine. We model the conditional probability of a searchable web site being relevant to a given query in term of three main components: the language model of the query, the language model of the content within the web site, and the reputation of the web site searching capability (static rank). The language models for queries and searchable sites are built using information mined from client-side browsing logs. The static rank for each searchable site leverages features extracted from these client-side logs such as number of queries that are submitted to this site, and features extracted from general search engines such as the number of web pages that indexed for this site, number of clicks per query, and the dwell-time that a user spends on the search result page and on the clicked result web pages. We also learn a weight for each kind of feature to optimize the ranking performance. In our experiment, we discover 10.5 thousand searchable sites and use 5 million unique queries, extracted from one week of log data to build and demonstrate the effectiveness of our searchable web site recommendation system.",2011,Web Search and Data Mining,Fields of study: static web pagesite mapweb search queryweb query classificationdwell timeweb serviceconditional probabilityweb pagesearch enginefeature extractionsemantic searchlanguage modelrecommender systemweb search engineworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Sentiment-Specific Representation Learning for Document-Level Sentiment Analysis,Duyu Tang (Harbin Institute of Technology),2145601749,"In this paper, we propose a representation learning research framework for document-level sentiment analysis. Given a document as the input, document-level sentiment analysis aims to automatically classify its sentiment/opinion (such as thumbs up or thumbs down) based on the textural information. Despite the success of feature engineering in many previous studies, the hand-coded features do not well capture the semantics of texts. In this research, we argue that learning sentiment-specific semantic representations of documents is crucial for document-level sentiment analysis. We decompose the document semantics into four cascaded constitutes: (1) word representation, (2) sentence structure, (3) sentence composition and (4) document composition. Specifically, we learn sentiment-specific word representations, which simultaneously encode the contexts of words and the sentiment supervisions of texts into the continuous representation space. According to the principle of compositionality, we learn sentiment-specific sentence structures and sentence-level composition functions to produce the representation of each sentence based on the representations of the words it contains. The semantic representations of documents are obtained through document composition, which leverages the sentiment-sensitive discourse relations and sentence representations.",2015,Web Search and Data Mining,Fields of study: deep learningsentiment analysisnatural language processingpattern recognitionmachine learningcomputer science
The Past and Future of Systems for Current Events,Mor Naaman (Cornell University),1220470961,"People share in social media an overwhelming amount of content from real-world events. These events range from major global events like an uprising or an earthquake, to local events and emergencies such as a fire or a parade; from media events like the Oscar's, to events that enjoy little media coverage such as a conference or a music concert. This shared media represents an important part of our society, culture and history. At the same time, this social media content is still fragmented across services, hard to find, and difficult to consume and understand.",2016,Web Search and Data Mining,Fields of study: social mediainternet privacyworld wide websimulationcomputer science
Neural Text Embeddings for Information Retrieval,Bhaskar Mitra (Microsoft)Nick Craswell (Microsoft),"2229276239,2009495402","In the last few years, neural representation learning approaches have achieved very good performance on many natural language processing tasks, such as language modelling and machine translation. This suggests that neural models will also achieve good performance on information retrieval (IR) tasks, such as relevance ranking, addressing the query-document vocabulary mismatch problem by using a semantic rather than lexical matching. Although initial iterations of neural models do not outperform traditional lexical-matching baselines, the level of interest and effort in this area is increasing, potentially leading to a breakthrough. The popularity of the recent SIGIR 2016 workshop on Neural Information Retrieval provides evidence to the growing interest in neural models for IR. While recent tutorials have covered some aspects of deep learning for retrieval tasks, there is a significant scope for organizing a tutorial that focuses on the fundamentals of representation learning for text retrieval. The goal of this tutorial will be to introduce state-of-the-art neural embedding models and bridge the gap between these neural models with early representation learning approaches in IR (e.g., LSA). We will discuss some of the key challenges and insights in making these models work in practice, and demonstrate one of the toolsets available to researchers interested in this area.",2017,Web Search and Data Mining,Fields of study: cognitive models of information retrievalartificial neural networkworld wide webinformation retrievaldata miningartificial intelligencemachine learningcomputer science
"To Suggest, or Not to Suggest for Queries with Diverse Intents: Optimizing Search Result Presentation",Makoto P. Kato (Kyoto University)Katsumi Tanaka (Kyoto University),"1993270567,2100196114","We propose a method of optimizing search result presentation for queries with diverse intents, by selectively presenting query suggestions for leading users to more relevant search results. The optimization is based on a probabilistic model of users who click on query suggestions in accordance with their intents, and modified versions of intent-aware evaluation metrics that take into account the co-occurrence between intents. Showing many query suggestions simply increases a chance to satisfy users with diverse intents in this model, while it in fact requires users to spend additional time for scanning and selecting suggestions, and may result in low satisfaction for some users. Therefore, we measured the loss of time caused by query suggestion presentation by conducting a user study in different settings, and included its negative effects in our optimization problem. Our experiments revealed that the optimization of search result presentation significantly improved that of a single ranked list, and was beneficial especially for patient users. Moreover, experimental results showed that our optimization was effective particularly when intents of a query often co-occur with a small subset of intents.",2016,Web Search and Data Mining,Fields of study: web query classificationworld wide webinformation retrievaldata miningcomputer science
Terminological cleansing for improved information retrieval based on ontological terms,Antonio Jimeno-Yepes (European Bioinformatics Institute)Rafael Berlanga-Llavori (James I University)Dietrich Rebholz-Schuhmann (European Bioinformatics Institute),"2005986326,1089258844,2019845195","Ontologies are frequently used in information retrieval being their main applications the expansion of queries, semantic indexing of documents and the organization of search results. However, the optimization of an ontology to perform information retrieval tasks is still unclear. In this paper, we propose an ontology query model to analyze the usefulness of ontologies in effectively performing document searches. Moreover, we propose a series of heuristic techniques that optimize ontologies for information retrieval tasks. Preliminary results demonstrate that current domain ontologies provide enough information to support user requests and that ontologies might be improved with simple methods.",2009,Web Search and Data Mining,Fields of study: cognitive models of information retrievalidef5human computer information retrievalprocess ontologyupper ontologyconcept searchontologyvector space modelrelevanceinformation retrievaldata miningdatabasecomputer science
Offline Evaluation and Optimization for Interactive Systems,Lihong Li (Microsoft),2125714999,"Evaluating and optimizing an interactive system (like search engines, recommender and advertising systems) from historical data against a predefined online metric is challenging, especially when that metric is computed from user feedback such as clicks and payments. The key challenge is counterfactual in nature: we only observe a user's feedback for actions taken by the system, but we do not know what that user would have reacted to a different action. The golden standard to evaluate such metrics of a user-interacting system is online A/B experiments (a.k.a. randomized controlled experiments), which can be expensive in terms of both time and engineering resources. Offline evaluation/optimization (sometimes referred to as off-policy learning in the literature) thus becomes critical, aiming to evaluate the same metrics without running (many) expensive A/B experiments on live users. One approach to offline evaluation is to build a user model that simulates user behavior (clicks, purchases, etc.) under various contexts, and then evaluate metrics of a system with this simulator. While being straightforward and common in practice, the reliability of such model-based approaches relies heavily on how well the user model is built. Furthermore, it is often difficult to know a priori whether a user model is good enough to be trustable. Recent years have seen a growing interest in another solution to the offline evaluation problem. Using statistical techniques like importance sampling and doubly robust estimation, the approach can give unbiased estimates of metrics for a wide range of problems. It enjoys other benefits as well. For example, it often allows data scientists to obtain a confidence interval for the estimate to quantify the amount of uncertainty; it does not require building user models, so is more robust and easier to apply. All these benefits make the approach particularly attractive to a wide range of problems. Successful applications have been reported in the last few years by some of the industrial leaders. This tutorial gives a review of the basic theory and representative techniques. Applications of these techniques are illustrated through several case studies done at Microsoft and Yahoo!.",2015,Web Search and Data Mining,Fields of study: impact evaluationrecommender systemmultimediaworld wide webinformation retrievaldata miningmachine learningsimulationstatisticscomputer science
WSDM'15 Workshop Summary / Scalable Data Analytics: Theory and Applications,Kaizhu Huang (Xi'an Jiaotong-Liverpool University)Haiqin Yang (The Chinese University of Hong Kong)Irwin King (The Chinese University of Hong Kong)Michael R. Lyu (The Chinese University of Hong Kong),"2142894599,2167365918,2121363826,2227744130","The SDA workshop at WSDM 2015 is the fifth International Workshop on Scalable Data Analytics, following the previous four workshops of SDA respectively held at IEEE Big Data 2013, PAKDD 2014, IEEE Big Data 2014, and IEEE ICDM 2014. This series of workshops aims to provide professionals, researchers, and technologists with a single forum where they can discuss and share the state-of-the-art theories and applications of scalable data analytics technologies. In particular, in the era of information explosion, the scientific, biomedical, and engineering research communities are undergoing a profound transformation where discoveries and innovations increasingly rely on massive amounts of data. The characteristics of volume, velocity, variety and veracity originated in the massive big data then bring challenges to current data analytics techniques. The focus of the fifth SDA is to discuss how we can scale up data analytics techniques for modeling and analyzing big data from various domains.",2015,Web Search and Data Mining,Fields of study: software analyticsanalyticsscalabilitydata analysisbig datadata scienceworld wide webdata miningcomputer science
Document assignment in multi-site search engines,Ulf Brefeld (Yahoo!)Berkant Barla Cambazoglu (Yahoo!)Flavio Paiva Junqueira (Yahoo!),"2655389208,2044137649,2308249582","Assigning documents accurately to sites is critical for the performance of multi-site Web search engines. In such settings, sites crawl only documents they index and forward queries to obtain best-matching documents from other sites. Inaccurate assignments may lead to inefficiencies when crawling Web pages or processing user queries. In this work, we propose a machine-learned document assignment strategy that uses the locality of document views in search results to decide upon assignments. We evaluate the performance of our strategy using various document features extracted from a large Web collection. Our experimental setup uses query logs from a number of search front-ends spread across different geographic locations and uses these logs to learn the document access patterns. We compare our technique against baselines such as region- and language-based document assignment and observe that our technique achieves substantial performance improvements with respect to recall. With our technique, we are able to obtain a small query forwarding rate (0.04) requiring roughly 45% less replication of documents compared to replicating all documents across all sites.",2011,Web Search and Data Mining,Fields of study: web search queryweb query classificationquery expansionforward rateweb pagefront and back endssearch enginefeature extractionbiological classificationweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning About Health and Medicine from Internet Data,Elad Yom-Tov (Microsoft)Ingemar Johansson Cox (University College London)Vasileios Lampos (University College London),"205587521,2684480055,100906785","Surveys show that around 70% of US Internet users consult the Internet when they require medical information. People seek this information using both traditional search engines and via social media. The information created using the search process offers an unprecedented opportunity for applications to monitor and improve the quality of life of people with a variety of medical conditions. In recent years, research in this area has addressed public-health questions such as the effect of media on development of anorexia, developed tools for measuring influenza rates and assessing drug safety, and examined the effects of health information on individual wellbeing. This tutorial will show how Internet data can facilitate medical research, providing an overview of the state-of-the-art in this area. During the tutorial we will discuss the information which can be gleaned from a variety of Internet data sources, including social media, search engines, and specialized medical websites. We will provide an overview of analysis methods used in recent literature, and show how results can be evaluated using publicly-available health information and online experimentation. Finally, we will discuss ethical and privacy issues and possible technological solutions. This tutorial is intended for researchers of user generated content who are interested in applying their knowledge to improve health and medicine.",2015,Web Search and Data Mining,Fields of study: data sciencemultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Term-by-Term Query Auto-Completion for Mobile Search,Saúl Vargas (University of Glasgow)Roi Blanco (Yahoo!)Peter Mika (Yahoo!),"2343595513,2128286424,2251781635","With the ever increasing usage of mobile search, where text input is typically slow and error-prone, assisting users to formulate their queries contributes to a more satisfactory search experience. Query auto-completion (QAC) techniques, which predict possible completions for user queries, are the archetypal example of query assistance and are present in most search engines. We argue, however, that classic QAC, which operates by suggesting whole-query completions, may be sub-optimal for the case of mobile search as the available screen real estate to show suggestions is limited and editing is typically slower than in desktop search. In this paper we propose the idea of term-by-term QAC, which is a new technique inspired by predictive keyboards that suggests to the user one term at a time, instead of whole-query completions. We describe an efficient mechanism to implement this technique and an adaptation of a prior user model to evaluate the effectiveness of both standard and term-by-term QAC approaches using query log data. Our experiments with a mobile query log from a commercial search engine show the validity of our approach according to this user model with respect to saved characters, saved terms and examination effort. Finally, a user study provides further insights about our term-by-term technique compared with standard QAC with respect to the variables analyzed in the query log-based evaluation and additional variables related to the successfulness, the speed of the interactions and the properties of the submitted queries.",2016,Web Search and Data Mining,Fields of study: sargableweb search queryweb query classificationquery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Adaptive subjective triggers for opinionated document retrieval,Kazuhiro Seki (Kobe University)Kuniaki Uehara (Kobe University),"2230355992,2075153189","This paper proposes a novel application of a statistical language model to opinionated document retrieval targeting weblogs (blogs). In particular, we explore the use of the trigger model---originally developed for incorporating distant word dependencies---in order to model the characteristics of personal opinions that cannot be properly modeled by standard n -grams. Our primary assumption is that there are two constituents to form a subjective opinion. One is the subject of the opinion or the object that the opinion is about, and the other is a subjective expression; the former is regarded as a triggering word and the latter as a triggered word. We automatically identify those subjective trigger patterns to build a language model from a corpus of product customer reviews. Experimental results on the TREC Blog Track test collections show that, when used for reranking initial search results, our proposed model significantly improves opinionated document retrieval by over 20% in MAP. In addition, we report on an experiment on dynamic adaptation of the model to a given query, which is found effective for most of difficult queries categorized under politics and organizations.",2009,Web Search and Data Mining,Fields of study: language modeldocument retrievalnatural language processingworld wide webinformation retrievaldata miningcomputer science
Label Informed Attributed Network Embedding,Xiao Huang (Texas A&M University)Jundong Li (Arizona State University)Xia Hu (Texas A&M University),"2311247448,2149809093,2161448330","Attributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more difficult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art embedding algorithms.",2017,Web Search and Data Mining,Fields of study: data miningpattern recognitionmachine learning
Exploiting statistical and relational information on the web and in social media,"Lise Getoor (University of Maryland, College Park)Lilyana Mihalkova (University of Maryland, College Park)","1984940772,2345836963","The popularity of Web 2.0, characterized by a proliferation of social media sites, and Web 3.0, with more richly semantically annotated objects and relationships, brings to light a variety of important prediction, ranking, and extraction tasks. The input to these tasks is often best seen as a (noisy) multi-relational graph, such as the click graph, defined by user interactions with Web sites; and the social graph, defined by friendships and affiliations on social media sites. This tutorial will provide an overview of statistical relational learning and inference techniques, motivating and illustrating them using web and social media applications. We will start by briefly surveying some of the sources of statistical and relational information on the web and in social media and will then dedicate most of the tutorial time to an introduction to representations and techniques for learning and reasoning with multi-relational information, viewing them through the lens of web and social media domains. We will end with a discussion of current trends and related fields, such as privacy in social networks.",2011,Web Search and Data Mining,Fields of study: web modelingsocial semantic webpower graph analysissocial mediasocial networkstatistical relational learningworld wide webinformation retrievalsocial sciencedata miningmachine learningcomputer science
KMV-peer: a robust and adaptive peer-selection algorithm,Yosi Mass (IBM)Yehoshua Sagiv (Hebrew University of Jerusalem)Michal Shmueli-Scheuer (IBM),"2117117435,734152518,251771576","The problem of fully decentralized search over many collections is considered. The objective is to approximate the results of centralized search (namely, using a central index) while controlling the communication cost and involving only a small number of collections. The proposed solution is couched in a peer-to-peer (P2P) network, but can also be applied in other setups. Peers publish per-term summaries of their collections. Specifically, for each term, the range of document scores is divided into intervals; and for each interval, a KMV (K Minimal Values) synopsis of its documents is created. A new peer-selection algorithm uses the KMV synopses and two scoring functions in order to adaptively rank the peers, according to the relevance of their documents to a given query. The proposed method achieves high-quality results while meeting the above criteria of efficiency. In particular, experiments are done on two large, real-world datasets; one is blogs and the other is web data. These experiments show that the algorithm outperforms the state-of-the-art approaches and is robust over different collections, various scoring functions and multi-term queries.",2011,Web Search and Data Mining,Fields of study: peer to peerscoreworld wide webinformation retrievaldata miningdatabasemachine learningstatisticscomputer science
Bartering Books to Beers: A Recommender System for Exchange Platforms,"Jérémie Rappaz (École Polytechnique Fédérale de Lausanne)Maria-Luiza Vladarean (École Polytechnique Fédérale de Lausanne)Julian McAuley (University of California, San Diego)Michele Catasta (École Polytechnique Fédérale de Lausanne)","2583099998,2584033298,2041520510,2031671722","Bartering is a timeless practice that is becoming increasingly popular on the Web. Recommending trades for an online bartering platform shares many similarities with traditional approaches to recommendation, in particular the need to model the preferences of users and the properties of the items they consume. However, there are several aspects that make bartering problems interesting and challenging, specifically the fact that users are both suppliers and consumers, and that the trading environment is highly dynamic. Thus, a successful model of bartering requires us to understand not just users' preferences, but also the social dynamics of who trades with whom, and the temporal dynamics of when trades occur. We propose new models for bartering-based recommendation, for which we introduce three novel datasets from online bartering platforms. Surprisingly, we find that existing methods (based on matching algorithms) perform poorly on real-world platforms, as they rely on idealized assumptions that are not supported by real bartering data. We develop approaches based on Matrix Factorization in order to model the reciprocal interest between users and each other's items. We also find that the social ties between members have a strong influence, as does the time at which they trade, therefore we extend our model to be socially- and temporally-aware. We evaluate our approach on trades covering books, video games, and beers, where we obtain promising empirical performance compared to existing techniques.",2017,Web Search and Data Mining,Fields of study: barterswapreciprocitycollaborative filteringmatrix decompositionsocial dynamicsworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Neural Models for Full Text Search,Nick Craswell (Microsoft),2009495402,"A fundamental concern in search engines is to determine which documents have the best content for satisfying the user, based on analysis of the user's query and the text of documents. For this query-content match, many learning to rank systems make use of IR features developed in the 1990s in the TREC framework. Such features are still important in a variety of search tasks, and particularly in the long tail where clicks, links and social media signals become sparse. I will present our current progress, in particular three different neural models, with the goal of surpassing the 1990s models in full text search. This will include evidence, using proprietary Bing datasets, that large-scale training data can be useful. I will also argue that for the field to make progress on query-content relevance modeling, it may be valuable to set up a shared blind evaluation similar to 1990s TREC, possibly with large-scale training data.",2017,Web Search and Data Mining,Fields of study: data compressionworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
The Influence of Early Respondents: Information Cascade Effects in Online Event Scheduling,Daniel M. Romero (University of Michigan)Katharina Reinecke (University of Washington)Lionel P. Robert (University of Michigan),"2133929192,2136495853,2224006450","Sequential group decision-making processes, such as online event scheduling, can be subject to social influence if the decisions involve individuals? subjective preferences and values. Indeed, prior work has shown that scheduling polls that allow respondents to see others' answers are more likely to succeed than polls that hide other responses, suggesting the impact of social influence and coordination. In this paper, we investigate whether this difference is due to information cascade effects in which later respondents adopt the decisions of earlier respondents. Analyzing more than 1.3 million Doodle polls, we found evidence that cascading effects take place during event scheduling, and in particular, that early respondents have a larger influence on the outcome of a poll than people who come late. Drawing on simulations of an event scheduling model, we compare possible interventions to mitigate this bias and show that we can optimize the success of polls by hiding the responses of a small percentage of low availability respondents.",2017,Web Search and Data Mining,Fields of study: serial position effectinformation cascadeherd behaviorgroup decision makingsocial influenceteamworkworld wide webdata miningsimulation
Behavioral data mining and network analysis in massive online games,Muhammad Aurangzeb Ahmad (University of Minnesota)Jaideep Srivastava (University of Minnesota),"2441308221,2192802387","The last decade has been characterized by an explosion of social media in a variety of forms. Since the data is captured in digital form it has become possible for the first time study human behavior at a massive scale. Not only is it possible to address traditional questions in the social sciences regarding collective dynamics of human behaviors but it is also possible to study new types of human behaviors which have arisen as a result of usage of new mediums like twitter, YouTube, Facebook, one games etc. Each of these mediums has its respective limitations and affordances. Out of all these mediums the most complex and data rich medium is that of Massive Online Games (MOGs). MOGs refer to massive online persistent environments (World of Warcraft, EVE Online, EverQuest etc) shared by millions of people . In general these environments are characterized by a rich array of activities and social interactions with a wide array of behaviors e.g., cooperation, trade, quest, deceit, mentoring etc. Such environments allow one to study human behavior at a level of granularity where it was not possible to do so previously. Given the challenges associated with analyzing this type of data traditional techniques in data mining and social network analysis have to be extended with insights from the social sciences. The tutorial will cover predictive and generative models in the study of MOGs. Additionally we will cover some SNA techniques which are more appropriate for MOGs given the multi-dimensionality of the data (P*/ERGM Models, IR Based Network Analysis, Hypergrah based Techniques, Coextensive Social Networks etc). We also describe the various ways in which MOGs exhibit similarities to the real world e.g., economic behaviors, clandestine behaviors, mentoring etc).",2014,Web Search and Data Mining,Fields of study: social network analysismultimediaworld wide webdata miningmachine learningsimulation
Supervised N-gram topic model,Noriaki Kawamae (Tokyo Denki University),279243410,"We propose a Bayesian nonparametric topic model that rep- resents relationships between given labels and the corre- sponding words/phrases, from supervised articles. Unlike existing supervised topic models, our proposal, supervised N-gram topic model (SNT), focuses on both a number of topics and power-law distribution in the word frequencies to extract topic specific N-grams. To achieve this goal, SNT takes a Bayesian nonparametric approach to topic sampling, which generates word distribution jointly with the given variable in textual order, and then form each N-gram word as a hierarchy of Pitman-Yor process priors. Experiments on labeled text data show that SNT is useful as a generative model for discovering more phrases that complement human experts and domain specific knowledge than the existing al- ternatives. The results show that SNT can be applied to various tasks such as automatic annotation.",2014,Web Search and Data Mining,Fields of study: topic modelgraphical modelsentiment analysisnatural language processingdata miningpattern recognitionmachine learningcomputer science
Optimizing Search Interactions within Professional Social Networks,Nikita V. Spirin (University of Illinois at Urbana–Champaign),2145605135,"To help users cope with the scale and influx of new information, professional social networks (PSNs) provide a search functionality. However, most of the search engines within PSNs today only support keyword queries and basic faceted search capabilities overlooking serendipitous network exploration and search for relationships between entities. This results in siloed information and a limited search space. My thesis is that we must redesign all major elements of a search user interface, such as input, control, and informational, to enable more effective search interactions within PSNs. I will introduce new insights and algorithms supporting the thesis.",2016,Web Search and Data Mining,Fields of study: search analyticsphrase searchweb search querysearch enginefiltersemantic searchworld wide webinformation retrievaldata miningmachine learningcomputer science
Nonparametric bayesian upstream supervised multi-modal topic models,Renjie Liao (The Chinese University of Hong Kong)Jun Zhu (Tsinghua University)Zengchang Qin (Beihang University),"2107277143,2655877268,2673783438","Learning with multi-modal data is at the core of many multimedia applications, such as cross-modal retrieval and image annotation. In this paper, we present a nonparametric Bayesian approach to learning upstream supervised topic models for analyzing multi-modal data. Our model develops a compound nonparametric Bayesian multi-modal prior to describe the correlation structure of data both within each individual modality and between different modalities. It extends the hierarchical Dirichlet process (HDP) through incorporating upstream supervised response variables and values of latent functions under Gaussian process (GP). Upstream responses shared by data from multiple modalities are beneficial for discriminatively training and GP allows flexible structure learning of correlations. Hence, our model inherits the automatic determination of the number of topics from HDP, structure learning from GP and enhanced predictive capacity from upstream supervision. We also provide efficient variational inference and prediction algorithms. Empirical studies demonstrate superior performances on several benchmark datasets compared with previous competitors.",2014,Web Search and Data Mining,Fields of study: topic modeldata miningpattern recognitionmachine learningstatisticscomputer science
"Big data, lifelong machine learning and transfer learning",Qiang Yang (Huawei),2109031554,"A major challenge in today's world is the Big Data problem, which manifests itself in Web and Mobile domains as rapidly changing and heterogeneous data streams. A data-mining system must be able to cope with the influx of changing data in a continual manner. This calls for Lifelong Machine Learning, which in contrast to the traditional one-shot learning, should be able to identify the learning tasks at hand and adapt to the learning problems in a sustainable manner. A foundation for lifelong machine learning is transfer learning, whereby knowledge gained in a related but different domain may be transferred to benefit learning for a current task. To make effective transfer learning, it is important to maintain a continual and sustainable channel in the life time of a user in which the data are annotated. In this talk, I outline the lifelong machine learning situations, give several examples of transfer learning and applications for lifelong machine learning, and discuss cases of successful extraction of data annotations to meet the Big Data challenge.",2013,Web Search and Data Mining,Fields of study: inductive transfermulti task learningtransfer of learningrobot learningsynchronous learningactive learningactive learningerror driven learningproactive learningbig datainstance based learningdata scienceworld wide webdata miningartificial intelligencemachine learningcomputer science
Is a picture really worth a thousand words?: - on the role of images in e-commerce,Wei Di (eBay)Neel Sundaresan (eBay)Robinson Piramuthu (eBay)Anurag Bhardwaj (eBay),"2311154374,1981173961,866809645,2152063300","In online peer-to-peer commerce places where physical examination of the goods is infeasible, textual descriptions, images of the products, reputation of the participants, play key roles. Visual image is a powerful channel to convey crucial information towards e-shoppers and influence their choice. In this paper, we investigate a well-known online marketplace where over millions of products change hands and most are described with the help of one or more images. We present a systematic data mining and knowledge discovery approach that aims to quantitatively dissect the role of images in e-commerce in great detail. Our goal is two-fold. First, we aim to get a thorough understanding of impact of images across various dimensions: product categories, user segments, conversion rate. We present quantitative evaluation of the influence of images and show how to leverage different image aspects, such as quantity and quality, to effectively raise sale. Second, we study interaction of image data with other selling dimensions by jointly modeling them with user behavior data. Results suggest that ""watch"" behavior encodes complex signals combining both attention and hesitation from buyer, in which image still holds an important role when compared to other selling variables, especially for products for which appearance is important. We conclude on how these findings can benefit sellers in a high competitive online e-commerce market.",2014,Web Search and Data Mining,Fields of study: imageimage qualitye commerceconsumer behaviourmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Action prediction and identification from mining temporal user behaviors,Dakan Wang (Microsoft)Gang Wang (Microsoft)Xiaofeng Ke (Microsoft)Weizhu Chen (Microsoft),"2666228537,2485622092,2149087405,2108390110","Predicting user's action provides many monetization opportunities to web service providers. If a user's future action can be predicted and identified correctly in time or in advance, we cannot only satisfy user's current need, but also facilitate and simplify user's future online activities. Traditional works on user behavior modeling such as implicit feedback or personalization mainly investigate on users' immediate, short-term or aggregate behaviors. Hence, it is difficult to understand the diversity in temporal user behavior and predict user's future action. In this paper, we consider a forecasting problem of temporal user behavior modeling. Our first objective is able to capture relevant users that will perform an action. The second objective is able to identify whether a user has finished the action, even when the action happened offline. We propose an ensemble algorithm to achieve both objectives. The experiment compares several implementation methods and demonstrates the temporal user behavior modeling using the ensemble algorithm significantly outperforms other methods.",2011,Web Search and Data Mining,Fields of study: computer user satisfactionensemble forecastinguseruser modelingweb servicebehavioral modelingsatisfiabilityworld wide webdata miningmachine learningsimulationcomputer science
CMAP: effective fusion of quality and relevance for multi-criteria recommendation,Xin Xin (The Chinese University of Hong Kong)Michael R. Lyu (The Chinese University of Hong Kong)Irwin King (AT&T Labs),"2672966945,2227744130,2121363826","The research issue of recommender systems has been treated as a classical regression problem over the decades and has obtained a great success. In the next generation of recommender systems, multi-criteria recommendation has been predicted as an important direction. Different from traditional recommender systems that aim particularly at recommending high-quality items evaluated by users' ratings, inmulti-criteria recommendation, quality only serves as one criterion, and many other criteria such as relevance, coverage, and diversity should be simultaneously optimized. Although recently there is work investigating each single criterion, there is rarely any literature that reports how each single criterion impacts each other and how to combine them in real applications. Thus in this paper, we study the relationship of two criteria, quality and relevance, as a preliminary work in multi-criteria recommendation. We first give qualitative and quantitative analysis of competitive quality-based and relevance-based algorithms in these two criteria to show that both algorithms cannot work well in the opposite criteria. Then we propose an integrated metric and finally investigate how to combine previous work together into an unified model. In the combination, we introduce a Continuous-time MArkov Process (CMAP) algorithm for ranking, which enables principled and natural integration with features derived from both quality-based and relevance-based algorithms. Through experimental verification, the combined methods can significantly outperform either single quality-based or relevance-based algorithms in the integrated metric and the CMAP model outperforms traditional combination methods by around 3%. Its linear complexity with respect to the number of users and items leads to satisfactory performance, as demonstrated by the around 7-hour computational time for over 480k users and almost 20k items.",2011,Web Search and Data Mining,Fields of study: collaborative filteringunified modelrecommender systemworld wide webinformation retrievaldata miningartificial intelligencemachine learningcomputer science
Effective co-betweenness centrality computation,Mostafa Haghir Chehreghani (Katholieke Universiteit Leuven),2277421228,"Betweenness centrality of vertices is essential in the analysis of social and information networks, and co-betweenness centrality is one of two natural ways to extend it to sets of vertices. Existing algorithms for co-betweenness centrality computation suffer from at least one of the following problems: i) their applicability is limited to special cases like sequences, sets of size two, and ii) they are not efficient in terms of time complexity. In this paper, we present efficient algorithms for co-betweenness centrality computation of any set or sequence of vertices in weighted and unweighted networks. We also develop effective methods for co-betweenness centrality computation of sets and sequences of edges. These results provide a clear and extensive view about the complexity of co-betweenness centrality computation for vertices and edges in weighted and un-weighted networks. Finally, we perform extensive experiments on real-world networks from different domains including social, information and communication networks, to show the empirical efficiency of the proposed methods.",2014,Web Search and Data Mining,Fields of study: alpha centralityrandom walk closeness centralitykatz centralitynetwork controllabilitycentralitynetwork sciencebetweenness centralitynetwork theorycomplexitynetwork analysissocial networkmachine learningcomputer science
On the streaming complexity of computing local clustering coefficients,Konstantin Kutzkov (IT University of Copenhagen)Rasmus Pagh (IT University of Copenhagen),"280017384,1864519460","Due to a large number of applications, the problem of estimating the number of triangles in graphs revealed as a stream of edges, and the closely related problem of estimating the graph's clustering coefficient, have received considerable attention in the last decade. Both efficient algorithms and impossibility results have shed light on the computational complexity of the problem. Motivated by applications in Web mining, Becchetti et al.~presented new algorithms for the estimation of the local number of triangles, i.e., the number of triangles incident to individual vertices. The algorithms are shown, both theoretically and experimentally, to efficiently handle the problem. However, at least two passes over the data are needed and thus the algorithms are not suitable for real streaming scenarios. In the present work, we consider the problem of estimating the clustering coefficient of individual vertices in a graph over n vertices revealed as a stream of m edges. As a first result we show that any one pass randomized streaming algorithm that can distinguish a graph with no triangles from a graph having a vertex of degree d with clustering coefficient > 1/2 must use Ω(m/d) bits of space in expectation. Our second result is a new randomized one pass algorithm estimating the local clustering coefficient of each vertex with degree at least d. The space requirement of our algorithm is within a logarithmic factor of the lower bound, thus our approach is close to optimal. We also extend the algorithm to local triangle counting and report experimental results on its performance on real-life graphs.",2013,Web Search and Data Mining,Fields of study: neighbourhoodcomplement graphmultiple edgeslevel structurecorrelation clusteringdata stream clusteringcycle graphvertexclustering coefficientdegreemachine learningmathematical optimizationstatistics
Active learning for networked data based on non-progressive diffusion model,Zhilin Yang (Tsinghua University)Jie Tang (Tsinghua University)Bin Xu (Tsinghua University)Chunxiao Xing (Tsinghua University),"2489788272,2158012360,2617033824,2648381266","We study the problem of active learning for networked data, where samples are connected with links and their labels are correlated with each other. We particularly focus on the setting of using the probabilistic graphical model to model the networked data, due to its effectiveness in capturing the dependency between labels of linked samples. We propose a novel idea of connecting the graphical model to the information diffusion process, and precisely define the active learning problem based on the non-progressive diffusion model. We show the NP-hardness of the problem and propose a method called MaxCo to solve it. We derive the lower bound for the optimal solution for the active learning setting, and develop an iterative greedy algorithm with provable approximation guarantees. We also theoretically prove the convergence and correctness of MaxCo. We evaluate MaxCo on four different genres of datasets: Coauthor, Slashdot, Mobile, and Enron. Our experiments show a consistent improvement over other competing approaches.",2014,Web Search and Data Mining,Fields of study: active learningactive learningworld wide webdata miningmachine learningsimulationstatisticscomputer science
Inferring Latent Triggers of Purchases with Consideration of Social Effects and Media Advertisements,Yusuke Tanaka (Nippon Telegraph and Telephone)Takeshi Kurashima (Nippon Telegraph and Telephone)Yasuhiro Fujiwara (Nippon Telegraph and Telephone)Tomoharu Iwata (Nippon Telegraph and Telephone)Hiroshi Sawada (Nippon Telegraph and Telephone),"2493874103,2090365413,2157865440,2108993706,2099875912",-,2016,Web Search and Data Mining,-
Partner tiering in display advertising,Anand Bhalgat (Facebook)Nitish Korula (Google)Hennadiy Leontyev (Google)Max Lin (Google)Vahab S. Mirrokni (Google),"2306120609,1991329380,2228460341,2223391994,2331823467","Display ads on the Internet are often sold by publishers to advertisers in bundles of thousands or millions of impressions over a particular time period. The ad delivery systems assign ads to pages on behalf of publishers to satisfy these contracts, and at the same time, try to maximize the overall quality of assignment. This is usually modeled in the literature as an online allocation problem, where contracts are represented by overall delivery constraints. However an important aspect of these contracts is missed by the classical formulation: a majority of these contracts are not between advertisers and publishers; a set of publishers is typically represented by a middle-man and advertisers buy inventory from the middle man. As publishers vary in quality and importance, advertisers prefer these publishers differently. Similarly, as the inventory of ads is limited, ad-delivery engine needs to prefer a high-quality publisher over a low quality publisher for supplying ads. We formulate this problem as a hierarchical online matching problem where each incoming impression has a level indicating its importance, and study its theoretical properties. We also design practical solutions to this problem and study their performance on real data sets.",2014,Web Search and Data Mining,Fields of study: world wide webdata mining
A Comparison of Document-at-a-Time and Score-at-a-Time Query Evaluation,Matt Crane (University of Waterloo)J. Shane Culpepper (RMIT University)Jimmy J. Lin (University of Waterloo)Joel Mackenzie (RMIT University)Andrew Trotman (University of Otago),"2114244232,1944334593,2163619555,2343398192,2110053611","We present an empirical comparison between document-at-a-time (DaaT) and score-at-a-time (SaaT) document ranking strategies within a common framework. Although both strategies have been extensively explored, the literature lacks a fair, direct comparison: such a study has been difficult due to vastly different query evaluation mechanics and index organizations. Our work controls for score quantization, document processing, compression, implementation language, implementation effort, and a number of details, arriving at an empirical evaluation that fairly characterizes the performance of three specific techniques: WAND (DaaT), BMW (DaaT), and JASS (SaaT). Experiments reveal a number of interesting findings. The performance gap between WAND and BMW is not as clear as the literature suggests, and both methods are susceptible to tail queries that may take orders of magnitude longer than the median query to execute. Surprisingly, approximate query evaluation in WAND and BMW does not significantly reduce the risk of these tail queries. Overall, JASS is slightly slower than either WAND or BMW, but exhibits much lower variance in query latencies and is much less susceptible to tail query effects. Furthermore, JASS query latency is not particularly sensitive to the retrieval depth, making it an appealing solution for performance-sensitive applications where bounds on query latencies are desirable.",2017,Web Search and Data Mining,Fields of study: efficiencymeasurementworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Delving Deep into Personal Photo and Video Search,Lu Jiang (Carnegie Mellon University)Yannis Kalantidis (Yahoo!)Liangliang Cao (Yahoo!)Sachin Farfade (Yahoo!)Jiliang Tang (Michigan State University)Alexander G. Hauptmann (Carnegie Mellon University),"2118651624,2643138879,2630277302,690374842,2147392410,2113269357","The ubiquity of mobile devices and cloud services has led to an unprecedented growth of online personal photo and video collections. Due to the scarcity of personal media search log data, research to date has mainly focused on searching images and videos on the web. However, in order to manage the exploding amount of personal photos and videos, we raise a fundamental question: what are the differences and similarities when users search their own photos versus the photos on the web? To the best of our knowledge, this paper is the first to study personal media search using large-scale real-world search logs. We analyze different types of search sessions mined from Flickr search logs and discover a number of interesting characteristics of personal media search in terms of information needs and click behaviors. The insightful observations will not only be instrumental in guiding future personal media search methods, but also benefit related tasks such as personal photo browsing and recommendation. Our findings suggest there is a significant gap between personal queries and automatically detected concepts, which is responsible for the low accuracy of many personal media search queries. To bridge the gap, we propose the deep query understanding model to learn a mapping from the personal queries to the concepts in the clicked photos. Experimental results verify the efficacy of the proposed method in improving personal media search, where the proposed method consistently outperforms baseline methods.",2017,Web Search and Data Mining,Fields of study: personal information managementrecurrent neural networksemantic searchdeep learninginternet privacymultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning Distributed Representations of Data in Community Question Answering for Question Retrieval,Kai Zhang (Beihang University)Wei Wu (Microsoft)Fang Wang (Beihang University)Ming Zhou (Microsoft)Zhoujun Li (Beihang University),"2677559652,2590381716,2717619201,2143584880,2133880114","We study the problem of question retrieval in community question answering (CQA). The biggest challenge within this task is lexical gaps between questions since similar questions are usually expressed with different but semantically related words. To bridge the gaps, state-of-the-art methods incorporate extra information such as word-to-word translation and categories of questions into the traditional language models. We find that the existing language model based methods can be interpreted using a new framework, that is they represent words and question categories in a vector space and calculate question-question similarities with a linear combination of dot products of the vectors. The problem is that these methods are either heuristic on data representation or difficult to scale up. We propose a principled and efficient approach to learning representations of data in CQA. In our method, we simultaneously learn vectors of words and vectors of question categories by optimizing an objective function naturally derived from the framework. In question retrieval, we incorporate learnt representations into traditional language models in an effective and efficient way. We conduct experiments on large scale data from Yahoo! Answers and Baidu Knows, and compared our method with state-of-the-art methods on two public data sets. Experimental results show that our method can significantly improve on baseline methods for retrieval relevance. On 1 million training data, our method takes less than 50 minutes to learn a model on a single multicore machine, while the translation based language model needs more than 2 days to learn a translation table on the same machine.",2016,Web Search and Data Mining,Fields of study: question answeringnatural language processinginformation retrievaldata miningmachine learningcomputer science
Partitioning and Segment Organization Strategies for Real-Time Selective Search on Document Streams,"Yulu Wang (University of Maryland, College Park)Jimmy J. Lin (University of Waterloo)","2122263988,2163619555","The basic idea behind selective search is to partition a collection into topical clusters, and for each query, consider only a subset of the clusters that are likely to contain relevant documents. Previous work on web collections has shown that it is possible to retain high-quality results while considering only a small fraction of the collection. These studies, however, assume static collections where it is feasible to run batch clustering algorithms for partitioning. In this work, we consider the novel formulation of selective search on document streams (specifically, tweets), where partitioning must be performed incrementally. In our approach, documents are partitioned into temporal segments and selective search is performed within each segment: these segments can either be clustered using batch or online algorithms, and at different temporal granularities. For efficiency, we take advantage of word embeddings to reduce the dimensionality of the document vectors. Experiments with test collections from the TREC Microblog Tracks show that we are able to achieve precision indistinguishable from exhaustive search while considering only around 5% of the collection. Interestingly, we observe no significant effectiveness differences between batch vs. online clustering and between hourly vs. daily temporal segments, despite them being very different index organizations. This suggests that architectural choices should be primarily guided by efficiency considerations.",2017,Web Search and Data Mining,Fields of study: cluster analysisworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
The Predictive Power of Massive Data about our Fine-Grained Behavior,Foster J. Provost (New York University),2158932634,"What really is it about ""big data"" that makes it different from traditional data? In this talk I illustrate one important aspect: massive ultra-fine-grained data on individuals' behaviors holds remarkable predictive power. I examine several applications to marketing-related tasks, showing how machine learning methods can extract the predictive power and how the value of the data ""asset"" seems different from the value of traditional data used for predictive modeling. I then dig deeper into explaining the predictions made from massive numbers of fine-grained behaviors by applying a counter-factual framework for explaining model behavior based on treating the individual behaviors as evidence that is combined by the model. This analysis shows that the fine-grained behavior data incorporate various sorts of information that we traditionally have sought to capture by other means. For example, for marketing modeling the behavior data effectively incorporate demographics, psychographics, category interest, and purchase intent. Finally, I discuss the flip side of the coin: the remarkable predictive power based on fine-grained information on individuals raises new privacy concerns. In particular, I discuss privacy concerns based on inferences drawn about us (in contrast to privacy concerns stemming from violations to data confidentiality). The evidence counterfactual approach used to explain the predictions also can be used to provide online consumers with transparency into the reasons why inferences are drawn about them. In addition, it offers the possibility to design novel solutions such as a privacy-friendly ""cloaking device"" to inhibit inferences from being drawn based on particular behaviors.",2016,Web Search and Data Mining,Fields of study: world wide webdata miningsimulationstatisticscomputer science
Recommender Systems: Research Direction,"Manoj Reddy Dareddy (University of California, Los Angeles)",2572845080,"Recommender systems are omnipresent on the web. They aim to address the problem of information overload. Recommender systems personalizes the content to each individual user based on their preferences. Currently, these systems are used to recommend movies, music, news, products to buy etc. They essentially assist us in making decisions. This paper presents the author's plan for his PhD research in this domain and research questions to be discussed at the WSDM 2017 Doctoral Consortium.",2017,Web Search and Data Mining,Fields of study: artificial neural networkmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
An algorithmic treatment of strong queries,Ravi Kumar (Yahoo!)Silvio Lattanzi (Sapienza University of Rome)Prabhakar Raghavan (Yahoo!),"2232709231,1989808900,2195048431","A strong query for a target document with respect to an index is the smallest query for which the target document is returned by the index as the top result for the query. The strong query problem was first studied more than a decade ago in the context of measuring search engine overlap. Despite its simple-to-state nature and its longevity in the field, this problem has not been sufficiently addressed in a formal manner. In this paper we provide the first rigorous treatment of the strong query problem. We show an interesting connection between this problem and the set cover problem, and use it to obtain basic hardness and algorithmic results. Experiments on more than 10K documents show that our proposed algorithm performs much better than the widely-used word frequency-based heuristic. En route, our study suggests that less than four words on average can be sufficient to uniquely identify web pages.",2011,Web Search and Data Mining,Fields of study: sargablerankingrange queryweb search queryweb query classificationquery expansionquery optimizationset cover problemtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Counting Graphlets: Space vs Time,Marco Bressan (Sapienza University of Rome)Flavio Chierichetti (Sapienza University of Rome)Ravi Kumar (Google)Stefano Leucci (Sapienza University of Rome)Alessandro Panconesi (Sapienza University of Rome),"2516098459,2082432826,2232709231,2290155465,2193688032","Counting graphlets is a well-studied problem in graph mining and social network analysis. Recently, several papers explored very simple and natural approaches based on Monte Carlo sampling of Markov Chains (MC), and reported encouraging results. We show, perhaps surprisingly, that this approach is outperformed by a carefully engineered version of color coding (CC) [1], a sophisticated algorithmic technique that we extend to the case of graphlet sampling and for which we prove strong statistical guarantees. Our computational experiments on graphs with millions of nodes show CC to be more accurate than MC. Furthermore, we formally show that the mixing time of the MC approach is too high in general, even when the input graph has high conductance. All this comes at a price however. While MC is very efficient in terms of space, CC's memory requirements become demanding when the size of the input graph and that of the graphlets grow. And yet, our experiments show that a careful implementation of CC can push the limits of the state of the art, both in terms of the size of the input graph and of that of the graphlets.",2017,Web Search and Data Mining,Fields of study: color codingrandom walktheoretical computer sciencedata miningmachine learningstatisticscomputer science
iPhone's Digital Marketplace: Characterizing the Big Spenders,Farshad Kooti (University of Southern California)Mihajlo Grbovic (Yahoo!)Luca Maria Aiello (Bell Labs)Eric Bax (Yahoo!)Kristina Lerman (Information Sciences Institute),"1923168926,2000240052,2677626719,2144337901,2149625712","With mobile shopping surging in popularity, people are spending ever more money on digital purchases through their mobile devices and phones. However, few large-scale studies of mobile shopping exist. In this paper we analyze a large data set consisting of more than 776M digital purchases made on Apple mobile devices that include songs, apps, and in-app purchases. We find that 61% of all the spending is on in-app purchases and that the top 1% of users are responsible for 59% of all the spending. These big spenders are more likely to be male and older, and less likely to be from the US. We study how they adopt and abandon individual app, and find that, after an initial phase of increased daily spending, users gradually lose interest: the delay between their purchases increases and the spending decreases with a sharp drop toward the end. Finally, we model the in-app purchasing behavior in multiple steps: 1) we model the time between purchases; 2) we train a classifier to predict whether the user will make a purchase from a new app or continue purchasing from the existing app; and 3) based on the outcome of the previous step, we attempt to predict the exact app, new or existing, from which the next purchase will come. The results yield new insights into spending habits in the mobile digital marketplace.",2017,Web Search and Data Mining,Fields of study: predictioninternet privacyworld wide webstatisticsmathematics
Real-Time Bidding by Reinforcement Learning in Display Advertising,Han Cai (Shanghai Jiao Tong University)Kan Ren (Shanghai Jiao Tong University)Weinan Zhang (Shanghai Jiao Tong University)Kleanthis Malialis (University College London)Jun Wang (University College London)Yong Yu (Shanghai Jiao Tong University)Defeng Guo,"2584166797,2277084468,2527611484,22316737,2557836567,2119244895,2636606475","The majority of online display ads are served through real-time bidding (RTB) --- each ad display impression is auctioned off in real-time when it is just being generated from a user visit. To place an ad automatically and optimally, it is critical for advertisers to devise a learning algorithm to cleverly bid an ad impression in real-time. Most previous works consider the bid decision as a static optimization problem of either treating the value of each impression independently or setting a bid price to each segment of ad volume. However, the bidding for a given ad campaign would repeatedly happen during its life span before the budget runs out. As such, each bid is strategically correlated by the constrained budget and the overall effectiveness of the campaign (e.g., the rewards from generated clicks), which is only observed after the campaign has completed. Thus, it is of great interest to devise an optimal bidding strategy sequentially so that the campaign budget can be dynamically allocated across all the available impressions on the basis of both the immediate and future rewards. In this paper, we formulate the bid decision process as a reinforcement learning problem, where the state space is represented by the auction information and the campaign's real-time parameters, while an action is the bid price to set. By modeling the state transition via auction competition, we build a Markov Decision Process framework for learning the optimal bidding policy to optimize the advertising performance in the dynamic real-time bidding environment. Furthermore, the scalability problem from the large real-world auction volume and campaign budget is well handled by state value approximation using neural networks. The empirical study on two large-scale real-world datasets and the live A/B testing on a commercial platform have demonstrated the superior performance and high efficiency compared to state-of-the-art methods.",2017,Web Search and Data Mining,Fields of study: unique bid auctionbid shadingreal time biddingauction snipingenglish auctionreinforcement learningmachine learningsimulationcomputer science
Dynamic Information Retrieval Modeling,Hui Yang (Georgetown University)Marc Sloan (University College London)Jun Wang (University College London),"2635419647,2165594676,2557836567","In Dynamic Information Retrieval modeling we model dynamic systems which change or adapt over time or a sequence of events using a range of techniques from artificial intelligence and reinforcement learning. Many of the open problems in current IR research can be described as dynamic systems, for instance, session search or computational advertising. State of the art research provides solutions to these problems that are responsive to a changing environment, learn from past interactions and predict future utility. Advances in IR interface, personalization and ad display demand models that can react to users in real time and in an intelligent, contextual way. The objective of this half-day tutorial is to provide a comprehensive and up-to-date introduction to Dynamic Information Retrieval Modeling. We motivate a conceptual model linking static, interactive and dynamic retrieval and use this to define dynamics within the context of IR. We then cover a number of algorithms and techniques from the artificial intelligence (AI) and online learning literature such as Markov Decision Processes (MDP), their partially observable variation (POMDP) and multi-armed bandits. Following this we describe how to identify dynamics in an IR problem and demonstrate how to model them using the described techniques. The remainder of the tutorial will then cover an array of state-of-the-art research on dynamic systems in IR and how they can be modeled using using dynamic IR. We use research on session search, multi-page search and online advertising as in-depth examples of such work. This tutorial is of relevance to IR practitioners and researchers, where we will present the merits of dynamic information retrieval modeling and introduce the relevant techniques. The content will be of particular interest to researchers working in the areas of statistical modeling, personalization and recommendation, and is also relevant to practitioners in Web search, online advertising and anyone who works with big data. After this tutorial, attendees will: Be able to identify the dynamics in an IR system; Be able to model these dynamics using techniques from AI and reinforcement learning; Have knowledge of the state-of-the-art research in dynamic information retrieval modeling.",2015,Web Search and Data Mining,Fields of study: human computer information retrievalprobabilistic relevance modelreinforcement learningmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Event Search and Analytics: Detecting Events in Semantically Annotated Corpora for Search & Analytics,Dhruv Gupta (Max Planck Society),2492420228,"In this article, I present the questions that I seek to answer in my PhD research. I posit to analyze natural language text with the help of semantic annotations and mine important events for navigating large text corpora. Semantic annotations such as named entities, geographic locations, and temporal expressions can help us mine events from the given corpora. These events thus provide us with useful means to discover the locked knowledge in them. I pose three problems that can help unlock this knowledge vault in semantically annotated text corpora: i. identifying important events; ii. semantic search; iii. and event analytics.",2016,Web Search and Data Mining,Fields of study: semantic analyticssemantic searchtext miningnatural language processingworld wide webinformation retrievaldata miningcomputer science
Keynote Speaker Bio,Yiling Chen (Harvard University),2711338314,-,2016,Web Search and Data Mining,Fields of study: internet privacyworld wide webdata miningcomputer science
Representation Learning with Pair-wise Constraints for Collaborative Ranking,Fuzhen Zhuang (Chinese Academy of Sciences)Dan Luo (Chinese Academy of Sciences)Nicholas Jing Yuan (Microsoft)Xing Xie (Microsoft)Qing He (Chinese Academy of Sciences),"2050314250,2499683477,2096490164,2125800575,2167314737","Last decades have witnessed a vast amount of interest and research in recommendation systems. Collaborative filtering, which uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users, is one of the most successful approaches to build recommendation systems. Most previous collaborative filtering approaches employ the matrix factorization techniques to learn latent user feature profiles and item feature profiles. Also many subsequent works are proposed to incorporate users' social network information and items' attributions to further improve recommendation performance under the matrix factorization framework. However, the matrix factorization based methods may not make full use of the rating information, leading to unsatisfying performance. Recently deep learning has been approved to be able to find good representations in natural language processing, image classification, and so on. Along this line, we propose a collaborative ranking framework via representation learning with pair-wise constraints (REAP for short), in which autoencoder is used to simultaneously learn the latent factors of both users and items and pair-wise ranked loss defined by (user, item) pairs is considered. Extensive experiments are conducted on five data sets to demonstrate the effectiveness of the proposed framework.",2017,Web Search and Data Mining,Fields of study: autoencodercollaborative filteringfeature learningworld wide webinformation retrievaldata miningmachine learningcomputer science
What blogs tell us about websites: a demographics study,Matthew Michelson (University of Southern California)Sofus A. Macskassy (Rutgers University),"2128498655,279168326","One challenge for content providers on the Web is determining who consumes their content. For instance, online newspapers want to know who is reading their articles. Previous approaches have tried to determine such audience demographics by placing cookies on users' systems, or by directly asking consumers (e.g., through surveys). The first approach may make users uncomfortable, and the second is not scalable. In this paper we focus on determining the demographics of a Website's audience by analyzing the blogs that link to the Website. We analyze both the text of the blogs and the network connectivity of the blog network to determine demographics such as whether a person ""is married"" or ""has pets."" Presumably bloggers linking to sites also consume the content of those sites. Therefore, the discovered demographics for the bloggers can be used to represent a proxy set of demographics for a subset of the Website's consumers. We demonstrate that in many cases we can infer sub-audiences for a site from these demographics. Further, this feasibility demonstrates that very specific demographics for sites can be generated as we improve the methods for determining them (e.g., finding people who play video games). In our study we analyze blogs collected from more than 590,000 bloggers collected over a six month period that link to more than 488,000 distinct, external websites.",2011,Web Search and Data Mining,Fields of study: internet privacymultimediaworld wide web
How Smart Does Your Profile Image Look?: Estimating Intelligence from Social Network Profile Images,Xingjie Wei (University of Cambridge)David Stillwell (University of Cambridge),"2677342658,2054835453","Profile images on social networks are users' opportunity to present themselves and to affect how others judge them. We examine what Facebook images say about users' perceived and measured intelligence. 1,122 Facebook users completed a matrices intelligence test and shared their current Facebook profile image. Strangers also rated the images for perceived intelligence. We use automatically extracted image features to predict both measured and perceived intelligence. Intelligence estimation from images is a difficult task even for humans, but experimental results show that human accuracy can be equalled using computing methods. We report the image features that predict both measured and perceived intelligence, and highlight misleading features such as ""smiling'' and ""wearing glasses'' that are correlated with perceived but not measured intelligence. Our results give insights into inaccurate stereotyping from profile images and also have implications for privacy, especially since in most social networks profile images are public by default.",2017,Web Search and Data Mining,Fields of study: intelligence quotientmultimediaartificial intelligence
Sampling dilemma: towards effective data sampling for click prediction in sponsored search,Jun Feng (Tsinghua University)Jiang Bian (Microsoft)Taifeng Wang (Microsoft)Wei Chen (Microsoft)Xiaoyan Zhu (Tsinghua University)Tie-Yan Liu (Microsoft),"2439759743,2609123459,2157154139,2527738285,2686766185,2108341226","Precise prediction of the probability that users click on ads plays a key role in sponsored search. State-of-the-art sponsored search systems typically employ a machine learning approach to conduct click prediction. While paying much attention to extracting useful features and building effective models, previous studies have overshadowed seemingly less obvious but essentially important challenges in terms of data sampling. To fulfill the learning objective of click prediction, it is not only necessary to ensure that the sampled training data implies the similar input distribution compared with the real world one, but also to guarantee that the sampled training data yield the consistent conditional output distribution, i.e. click-through rate (CTR), with the real world data. However, due to the sparseness of clicks in sponsored search, it is a bit contradictory to address these two challenges simultaneously. In this paper, we first take a theoretical analysis to reveal this sampling dilemma, followed by a thorough data analysis which demonstrates that the straightforward random sampling method may not be effective to balance these two kinds of consistency in sampling dilemma simultaneously. To address this problem, we propose a new sampling algorithm which can succeed in retaining the consistency between the sampled data and real world in terms of both input distribution and conditional output distribution. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that this new sampling algorithm can effectively address the sampling dilemma. Further experiments illustrate that, by using the training data obtained by our new sampling algorithm, we can learn the model with much higher accuracy in click prediction.",2014,Web Search and Data Mining,Fields of study: online advertisingdata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
"Long, often quite boring, notes of meetings",Maarten Marx (University of Amsterdam),2195082027,"Meeting notes are documents which contain lots of structure. This structure is often implicit in layout and reserved words. On the other hand, since meetings tend to occur regularly and are repeated for long periods of time, this structure is often (semi-)formalized. This makes these documents suitable for automatic semantic annotation efforts. We describe the annotation we performed on the notes of more than 20 years of Dutch parliamentary debates. We annotated every word spoken in parliament with 1) the speaker, 2) her party at the time of speaking, 3) her role/function in parliament and 4) the iso-date. These annotations yield numerous new ways of searching, browsing, mining and summarizing these documents. Meetings are always too long, whence so are their verbatim notes. But of course they contain valuable information and notes have to be consulted from time to time. In this paper we show that semantic annotation can make finding things easier, and more fun.",2009,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
On Tag Recommendation for Expertise Profiling: A Case Study in the Scientific Domain,Isac S. Ribeiro (Universidade Federal de Minas Gerais)Rodrygo L. T. Santos (Universidade Federal de Minas Gerais)Marcos André Gonçalves (Universidade Federal de Minas Gerais)Alberto H. F. Laender (Universidade Federal de Minas Gerais),"2228581304,2138048039,2115586749,57505073","Building expertise profiles is a crucial step towards identifying experts in different knowledge areas. However, summarizing the topics of expertise of a given individual is a challenging task, primarily due to the semi-structured and heterogeneous nature of the documentary evidence available for this task. In this paper, we investigate the suitability of tag recommendation as a mechanism to produce effective expertise profiles. In particular, we perform a large-scale user study with academic experts from different knowledge areas to assess the effectiveness of multiple supervised and unsupervised tag recommendation approaches as well as multiple sources of textual evidence. Our analysis reveals that traditional content-based tag recommenders perform well at identifying expertise-oriented tags, with article keywords being a particularly effective source of evidence across profiles in different knowledge areas and with various levels of sparsity. Moreover, by combining multiple recommenders and sources of evidence as learning signals, we further demonstrate the effectiveness of tag recommendation for expertise profiling.",2015,Web Search and Data Mining,Fields of study: learning to rankworld wide webinformation retrievaldata miningmachine learningcomputer science
A Semantic Graph based Topic Model for Question Retrieval in Community Question Answering,"Long Chen (University of Glasgow)Joemon M. Jose (University of Glasgow)Haitao Yu (University of Tsukuba)Fajie Yuan (University of Glasgow)Dell Zhang (Birkbeck, University of London)","2342807686,2167481407,2344089676,2342748603,2158284782","Community Question Answering (CQA) services, such as Yahoo! Answers and WikiAnswers, have become popular with users as one of the central paradigms for satisfying users' information needs. The task of question retrieval aims to resolve one's query directly by finding the most relevant questions (together with their answers) from an archive of past questions. However, as the text of each question is short, there is usually a lexical gap between the queried question and the past questions. To alleviate this problem, we present a hybrid approach that blends several language modelling techniques for question retrieval, namely, the classic (query-likelihood) language model, the state-of-the-art translation-based language model, and our proposed semantics-based language model. The semantics of each candidate question is given by a probabilistic topic model which makes use of local and global semantic graphs for capturing the hidden interactions among entities (e.g., people, places, and concepts) in question-answer pairs. Experiments on two real-world datasets show that our approach can significantly outperform existing ones.",2016,Web Search and Data Mining,Fields of study: topic modelquestion answeringnatural language processinginformation retrievaldata miningmachine learningcomputer science
An Information-Theoretic Approach to Individual Sequential Data Sanitization,"Luca Bonomi (University of California, San Diego)Liyue Fan (University of Southern California)Hongxia Jin (Samsung)","1974069277,2109596318,2707082889","Fine-grained, personal data has been largely, continuously generated nowadays, such as location check-ins, web histories, physical activities, etc. Those data sequences are typically shared with untrusted parties for data analysis and promotional services. However, the individually-generated sequential data contains behavior patterns and may disclose sensitive information if not properly sanitized. Furthermore, the utility of the released sequence can be adversely affected by sanitization techniques. In this paper, we study the problem of individual sequence data sanitization with minimum utility loss, given user-specified sensitive patterns. We propose a privacy notion based on information theory and sanitize sequence data via generalization. We show the optimization problem is hard and develop two efficient heuristic solutions. Extensive experimental evaluations are conducted on real-world datasets and the results demonstrate the efficiency and effectiveness of our solutions.",2016,Web Search and Data Mining,Fields of study: mutual informationcomputer securitydata miningdatabasestatisticscomputer science
Three findings regarding privacy online,Catherine Elizabeth Tucker (Massachusetts Institute of Technology),2103055115,The Internet now enables firms to collect detailed and potentially intrusive data about their customers both easily and cheaply. I discuss three empirical results related to customer privacy-protection that is enacted in response to this change. 1) Privacy protection that focuses on obtaining consent appears to lead to less effective advertising. This is based on results from extensive empirical analysis into how effectiveness of online advertising changed in response to the implementation of the E-Privacy Directive in Europe. 2) Privacy protection which gives direct control over customers' privacy appears to enhance economic outcomes. This is based on a detailed case study of customer responsiveness to different forms of advertising in the wake of a change in Facebook privacy policies. 3) Restricting the length of time that potentially private data is stored appears to have little economic impact. This is based on empirical analysis of aggregate search behavior following a change in the length of time search engines were told they could store search engine query data in Europe.,2013,Web Search and Data Mining,Fields of study: privacy softwareprivacy by designprivacy policyinformation privacyinternet privacyworld wide webdata mining
AMiner: Toward Understanding Big Scholar Data,Jie Tang (Tsinghua University),2158012360,"In this talk, I will present a novel academic search and mining system, AMiner , the second generation of the ArnetMiner system. Different from traditional academic search systems that focus on document (paper) search, AMiner aims to provide a systematic modeling approach for researchers (authors), ultimately to gain a deep understanding of the big (heterogeneous) network formed by authors, papers they have published, and venues they published those papers. The system extracts researchers' profiles automatically from the Web and integrates the researcher profiles with publication papers after name disambiguation. For now, the system has collected a big scholar data with more than 130,000,000 researcher profiles and 100,000,000 papers from multiple publication databases. We also developed an approach named COSNET to connect AMiner with several professional social networks such as LinkedIn and VideoLectures, which significantly enriches the metadata of the scholarly data. Based on the integrated big scholar data, we devise a unified topic modeling approach for modeling the different entities (authors, papers, venues) simultaneously and provide a topic-level expertise search by leveraging the modeling results. In addition, AMiner offers a set of researcher-centered functions including social influence analysis, influence visualization, collaboration recommendation, relationship mining, similarity analysis and community evolution. The system has been put into operation since 2006 and has attracted more than 7,000,000 independent IP accesses from over 200 countries/regions.",2016,Web Search and Data Mining,Fields of study: social influencedata scienceworld wide webinformation retrievaldata miningcomputer science
Proceedings of the fifth ACM international conference on Web search and data mining,Eytan Adar (University of Michigan)Jaime Teevan (Microsoft)Eugene Agichtein (Emory University)Yoelle Maarek (Yahoo!),"2305277957,1982462162,2283615530,262608878","We are delighted to welcome you to the Fifth ACM International Conference on Web Search and Data Mining (WSDM 2012) held on February 8--12, 2012 in Seattle, Washington. As in the previous years, WSDM has attracted an impressive number of submissions tackling the most recent technical challenges in Web search and data mining, with an ever-growing interest in their social aspects. Now in its fifth year, the conference has reached maturity and has become a leading forum for reporting the latest research developments in the field. We are happy to present here the proceedings of the conference. We received a total of 362 submissions from 38 countries and regions, out of which 75 were accepted for full paper publication in the proceedings, thus reaching an acceptance rate of 20.7% (compared to 22.3% last year). The accepted papers are from 17 countries, spanning four continents -- making this a truly international forum. Oral presentation slots were allocated to all papers. Yet, in order to maintain the single track model that most attendees prefer, we introduced this year a ""spotlight"" type of oral presentation. Out of the 75 accepted papers, 45 were assigned such a ""spotlight"" slot, while 30 were assigned a plenary slot. The type of slot was chosen by the Senior PC members and Program chairs, mostly based on whether the topic and the content of the paper were best suited for a large group presentation or for a more focused and interactive ""spotlight"" style of presentation.",2012,Web Search and Data Mining,Fields of study: operations researchworld wide webdata miningcomputer science
Uncovering the Dynamics of Crowdlearning and the Value of Knowledge,Utkarsh Upadhyay (Max Planck Society)Isabel Valera (Max Planck Society)Manuel Gomez-Rodriguez (Max Planck Society),"2353884032,2096884534,2279633593","Learning from the crowd has become increasingly popular in the Web and social media. There is a wide variety of crowdlearning sites in which, on the one hand, users learn from the knowledge that other users contribute to the site, and, on the other hand, knowledge is reviewed and curated by the same users using assessment measures such as upvotes or likes. In this paper, we present a probabilistic modeling framework of crowdlearning, which uncovers the evolution of a user's expertise over time by leveraging other users' assessments of her contributions. The model allows for both off-site and on-site learning and captures forgetting of knowledge. We then develop a scalable estimation method to fit the model parameters from millions of recorded learning and contributing events. We show the effectiveness of our model by tracing activity of ~25 thousand users in Stack Overflow over a 4.5 year period. We find that answers with high knowledge value are rare. Newbies and experts tend to acquire less knowledge than users in the middle range. Prolific learners tend to be also proficient contributors that post answers with high knowledge value.",2017,Web Search and Data Mining,Fields of study: data scienceknowledge managementworld wide webdata miningmachine learning
Rank quantization,Ravi Kumar (Google)Ronny Lempel (Yahoo!)Roy Schwartz (Technion – Israel Institute of Technology)Sergei Vassilvitskii (Google),"2232709231,2249016471,2109728239,2156675704","We study the problem of aggregating and summarizing partial orders, on a large scale. Our motivation is two-fold: to discover elements at similar preference levels and to reduce the number of bits needed to store an element's position in a full ranking.We proceed in two steps: first, we find a total order by linearizing the rankings induced by the multiple partial orders and removing potentially inconsistent pairwise preferences. Next, given a total order, we introduce and formalize the rank quantization problem, which intuitively aims to bucketize the total order in a manner that mostly preserves the relations appearing in the partial orders. We show an exact quadratic-time quantization algorithm, as well as a greedy 2/3-approximation algorithm whose running is substantially faster on sparse instances. As an application, we aggregate rankings of top-10 search results over millions of search engine queries, approximately reproducing and then efficiently encoding the underlying static ranks used by the engine. We evaluate the performance of our algorithms on a web dataset of 12 million(2^{23.5}) unique pages and show that we can quantize the pages' static ranks using as few as eight bits, with only a minor degradation in search quality.",2013,Web Search and Data Mining,Fields of study: theoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer science
Kangaroo: Workload-Aware Processing of Range Data and Range Queries in Hadoop,Ahmed M. Aly (Google)Hazem Elmeleegy (Purdue University)Yan Qi 0002Walid G. Aref (Purdue University),"2121339343,1228265868,2636699861,220758600","Despite the importance and widespread use of range data, e.g., time intervals, spatial ranges, etc., little attention has been devoted to study the processing and querying of range data in the context of big data. The main challenge relies in the nature of the traditional index structures e.g., B-Tree and R-Tree, being centralized by nature, and hence are almost crippled when deployed in a distributed environment. To address this challenge, this paper presents Kangaroo, a system built on top of Hadoop to optimize the execution of range queries over range data. The main idea behind Kangaroo is to split the data into non-overlapping partitions in a way that minimizes the query execution time. Kangaroo is query workload-aware, i.e., results in partitioning layouts that minimize the query processing time of given query patterns. In this paper, we study the design challenges Kangaroo addresses in order to be deployed on top of a distributed file system, i.e., HDFS. We also study four different partitioning schemes that Kangaroo can support. With extensive experiments using real range data of more than one billion records and real query workload of more than 30,000 queries, we show that the partitioning schemes of Kangaroo can significantly reduce the I/O of range queries on range data.",2016,Web Search and Data Mining,Fields of study: search engine indexingbig dataworld wide webdata miningdatabasecomputer science
User modeling for web applications,David Carmel (IBM)Vanja Josifovski (Yahoo!)Yoelle Maarek (Yahoo!),"2088014474,344688379,262608878","Users have taken a more and more central role in the Web. Their role is both explicit, as they become more savvy, they have more expectations, and new interactive features keep appearing, and implicit, as their actions are monitored at various levels of granularity for various needs from live traffic evaluation for usage data mining to improve ranking, spelling etc. In a few years, most Web applications will have the ability to successfully adapt to both the explicit and implicit needs and tastes of their users. Such adaptation requires the ability to model the user's personal goals, interests, preferences and knowledge, and to apply this model while users interact with various applications. While adaptive applications that are based on user modeling have attracted the attention of multiple communities, from AI to UI, there is no forum that specifically focuses on user modeling and adaptive applications in the Web domain. This workshop will focus on user modeling and the usage of these models in Web applications. The emphasis of the workshop will be on modeling techniques that scale for the Web. User modeling might be based on explicit and implicit user feedback gathered from variety of sources such as sign-on information, clickthrough data, user previous queries, social network, purchases, and real-world activity. Adaptive Web based applications include search personalization, advertisement targeting, recommendation systems, social networks, on-line shopping, etc.",2011,Web Search and Data Mining,Fields of study: user journeycomputer user satisfactionweb modelingweb accessibility initiativeweb developmentweb designuser interface designweb navigationuser modelingweb serviceweb engineeringrecommender systemmultimediaworld wide webinformation retrievaldata miningcomputer science
The early bird gets the buzz: detecting anomalies and emerging trends in information networks,Brian Thompson (Rutgers University),2159049435,"In this work we propose a novel approach to anomaly detection in streaming communication data. We first build a stochastic model for the system based on temporal communication patterns across each edge, which we call the REWARDS (REneWal theory Approach for Real-time Data Streams) model. We then define a measure of anomaly for an arbitrary subgraph based on the likelihood of its recent activity given past behavior. Finally, we develop an algorithm to efficiently identify subgraphs with the most anomalous activity. Although our work has until now focused on the cybersecurity domain, the model we present is more broadly applicable to information retrieval in data streams and information networks.",2012,Web Search and Data Mining,Fields of study: renewal theoryreal time datastochastic modellingtime seriesanomaly detectiontheoretical computer scienceworld wide webdata miningmachine learningstatisticscomputer science
Related Event Discovery,Cheng Li (University of Michigan)Michael Bendersky (Google)Vijay Garg (Google)Sujith Ravi (Google),"2674810995,2345232400,2592615203,2590734359","We consider the problem of discovering local events on the web, where events are entities extracted from webpages. Examples of such local events include small venue concerts, farmers markets, sports activities, etc. Given an event entity, we propose a graph-based framework for retrieving a ranked list of related events that a user is likely to be interested in attending. Due to the difficulty of obtaining ground-truth labels for event entities, which are temporal and are constrained by location, our retrieval framework is unsupervised, and its graph-based formulation addresses (a) the challenge of feature sparseness and noisiness, and (b) the semantic mismatch problem in a self-contained and principled manner. To validate our methods, we collect human annotations and conduct a comprehensive empirical study, analyzing the performance of our methods with regard to relevance, recall, and diversity. This study shows that our graph-based framework is significantly better than any individual feature source, and can be further improved with minimal supervision.",2017,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
Mining the Web for Intelligent Problem Solving for Programmers,Xin Rong (University of Michigan),2145659280,"Programming can be hard to learn and master. Novice programmers often find themselves struggling with terminology, concepts, or different solutions to the same problem with little clue on how to choose the best one. Professional programmers often spend a considerable amount of time learning to use third-party libraries, APIs, or an unfamiliar piece of code. Although programmers can turn to search engines or question-and-answer websites for help, the problem solving process can often take multiple iterations and can be time-consuming. An integrated system that can recognize a programmer's difficulties and provide contextualized solutions is thus desirable, as it may significantly reduce the amount of manual effort required in the loop of troubleshooting. Ideally, a programmer should be able to interact with such an intelligent system using natural language, in a way similar to how they document code or communicate with peers. However, using automatic natural language processing techniques to address programming questions is very difficult, mainly due to the following reasons: (1) the terms and common expressions vary greatly across different domains and individual programmers, making it difficult to associate relevant concepts together; (2) the solution to the user's trouble in programming often requires multiple steps or different resources, which requires deep understanding of the relations or dependencies of the possible solutions, as well as the user's personal capability of handling those solutions; (3) the documents in the training data usually include a mixture of general-domain expressions with mentions of variables, functions, and classes, as well as source code, making low-level text processing difficult; (4) the evaluation of the system generally requires skilled experts to provide ground truth, which is expensive and often unreliable. We address the above difficulties and build an intelligent programming helper system by mining the massive data available online related to programming, including question-and-answer websites, tutorials, blogs, and code repositories. In specific, the study involves three important components. First, we use information extraction techniques to extract common programming tasks, issues, and solutions from the Web data, and establish connections between these extracted elements by leveraging their discrete or distributed representations (e.g., using neural embedding models). Such techniques have been shown to be useful in helping general users solve problems that require interactions with a complex computer software application through the interface of natural language. Second, we study how to handle complicated problems that require multiple steps to solve. The existing troubleshooting instances documented online are collectively modeled as a heterogeneous network, on which the random walk paths can be exploited to recommend solutions. Third, we study how to personalize the problem-solving process for users with varying levels of skills and background knowledge. In particular, each user's past adoptions of technologies and the adoption behavior in his/her social community can be jointly leveraged to provide the appropriate recommendations of technologies and may even promote innovations (e.g., new algorithms) in the process. Collectively, these three components form an integral solution to computer-assisted problem solving for programmers driven by big data, and may have impact on various different domains, including information extraction, language modeling, natural language understanding, automatic problem solving, and social network analysis.",2016,Web Search and Data Mining,Fields of study: language modeltheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Pairwise cross-domain factor model for heterogeneous transfer ranking,Bo Long (Yahoo!)Yi Chang (Yahoo!)Anlei Dong (Yahoo!)Jianzhang He (Yahoo!),"2512786853,2168000538,2102564942,2679762972","Learning to rank arises in many information retrieval applications, ranging from Web search engine, online advertising to recommendation systems. Traditional ranking mainly focuses on one type of data source, and effective modeling relies on a sufficiently large number of labeled examples, which require expensive and time-consuming labeling process. However, in many real-world applications, ranking over multiple related heterogeneous domains becomes a common situation, where in some domains we may have a relatively large amount of training data while in some other domains we can only collect very little. Theretofore, how to leverage labeled information from related heterogeneous domain to improve ranking in a target domain has become a problem of great interests. In this paper, we propose a novel probabilistic model, pairwise cross-domain factor model, to address this problem. The proposed model learns latent factors(features) for multi-domain data in partially-overlapped heterogeneous feature spaces. It is capable of learning homogeneous feature correlation, heterogeneous feature correlation, and pairwise preference correlation for cross-domain knowledge transfer. We also derive two PCDF variations to address two important special cases. Under the PCDF model, we derive a stochastic gradient based algorithm, which facilitates distributed optimization and is flexible to adopt different loss functions and regularization functions to accommodate different data distributions. The extensive experiments on real world data sets demonstrate the effectiveness of the proposed model and algorithm.",2012,Web Search and Data Mining,Fields of study: stochastic gradient descentrankingdomain knowledgefeature vectorfactor analysisloss functionstatistical modellearning to rankonline advertisingrecommender systemweb search engineworld wide webinformation retrievaldata miningpattern recognitionmachine learningstatisticscomputer science
Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification,"Ting Chen (University of California, Los Angeles)Yizhou Sun (University of California, Los Angeles)","2614454399,2652044142","In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods.",2017,Web Search and Data Mining,Fields of study: theoretical computer sciencedata miningmachine learningcomputer science
Web-scale Multimedia Search for Internet Video Content,Lu Jiang (Carnegie Mellon University),2118651624,"The Internet has been witnessing an explosion of video content. According to a Cisco study, video content is estimated to account for 80% of all the entire world's internet traffic by 2019. Video data are becoming one of the most valuable sources to assess information and knowledge. However, existing video search solutions are still based on text matching (text-to-text search), and could fail for the huge volumes of videos that have little relevant metadata or no metadata at all. The need for large-scale and intelligent video search, which bridges the gap between the user's information need and the video content, seems to be urgent. In this thesis, we propose an accurate, efficient and scalable search method for video content. As opposed to text matching, the proposed method relies on automatic video content understanding, and allows for intelligent and flexible search paradigms over the video content, including text-to-video and text&video-to-video search. Suppose our goal is to search the videos about birthday party. In traditional text-to-text queries, we have to search the keywords in the user-generated metadata (titles or descriptions). In a text-to-video query, however, we might look for visual clues in the video content such as ""cake"", ""gift"" and ""kids"", audio clues like ""birthday song"" and ""cheering sound"", or visible text like ""happy birthday"". Text-to-video queries are flexible and can be further refined by Boolean and temporal operators. After watching the retrieved videos, the user may select a few interesting videos to find more relevant videos like these. This can be achieved by issuing a text&video-to-video query which adds the selected video examples to the query. The proposed method provides a new dimension of looking at content-based video search, from finding a simple concept like ""puppy"" to searching a complex incident like ""a scene in urban area where people running away after an explosion"". To achieve this ambitious goal, we propose several novel methods focusing on accuracy, efficiency and scalability in the novel search paradigm. First, we introduce a novel self-paced curriculum learning theory that allows for training more accurate semantic concepts. Second, we propose a novel and scalable approach to index semantic concepts that can significantly improve the search efficiency with minimum accuracy loss. Third, we design a novel video reranking algorithm that can boost accuracy for video retrieval. The extensive experiments demonstrate that the proposed methods are able to surpass state-of-the-art accuracy on multiple datasets. In addition, our method can efficiently scale up the search to hundreds of millions videos, and only takes about 0.2 second to search a semantic query on a collection of 100 million videos, 1 second to process a hybrid query over 1 million videos. Based on the proposed methods, we implement E-Lamp Lite, the first of its kind large-scale semantic search engine for Internet videos. According to National Institute of Standards and Technology (NIST), it achieved the best accuracy in the TRECVID Multimedia Event Detection (MED) 2013, 2014 and 2015, the most representative task for content-based video search. To the best of our knowledge, E-Lamp Lite is the first content-based semantic search engine that is capable of indexing and searching a collection of 100 million videos.",2016,Web Search and Data Mining,Fields of study: video trackingsemantic searchbig datamultimediaworld wide webinformation retrievaldata miningcomputer science
Scalable Text Analysis,"Zijun Xue (University of California, Los Angeles)",2611534268,"Latent Dirichlet Allocation (LDA) is an extremely popular probabilistic topic model used for a diverse class of appications. While highly effective, one important limitation of LDA is the high memory footprint of its inferencing algorithm, making it difficult to scale to a large dataset. In my thesis, I propose sdLDA, a highly-scalable disk-based LDA that (1) leverages the plentiful space available in disk to reduce its main-memory footprint and (2) preserves the sparsity of the extracted topics during sampling to improve both memory efficiency and sampling complexity of the inferencing algorithm. Our extensive experiments show that sdLDA scales to datasets that are two orders of magnitude larger than what existing main-memory-based algorithms can handle. Furthermore, sdLDA exhibits similar (or even better) performance compared to main-memory-based LDAs in terms of running time.",2017,Web Search and Data Mining,Fields of study: topic modelscalabilitytext miningdata scienceinformation retrievaldata miningmachine learningcomputer science
Mobile App Tagging,Ning Chen (Alibaba Group)Steven C.H. Hoi (Singapore Management University)Shaohua Li (Nanyang Technological University)Xiaokui Xiao (Nanyang Technological University),"2719510244,108406206,2647733229,2157867657","Mobile app tagging aims to assign a list of keywords indicating core functionalities, main contents, key features or concepts of a mobile app. Mobile app tags can be potentially useful for app ecosystem stakeholders or other parties to improve app search, browsing, categorization, and advertising, etc. However, most mainstream app markets, e.g., Google Play, Apple App Store, etc., currently do not explicitly support such tags for apps. To address this problem, we propose a novel auto mobile app tagging framework for annotating a given mobile app automatically, which is based on a search-based annotation paradigm powered by machine learning techniques. Specifically, given a novel query app without tags, our proposed framework (i) first explores online kernel learning techniques to retrieve a set of top-N similar apps that are semantically most similar to the query app from a large app repository; and (ii) then mines the text data of both the query app and the top-N similar apps to discover the most relevant tags for annotating the query app. To evaluate the efficacy of our proposed framework, we conduct an extensive set of experiments on a large real-world dataset crawled from Google Play. The encouraging results demonstrate that our technique is effective and promising.",2016,Web Search and Data Mining,Fields of study: mobile deep linkinginternet privacymultimediaworld wide webcomputer science
big) usage data in web search,Ricardo A. Baeza-Yates (Yahoo!)Yoelle Maarek (Yahoo!),"528588921,262608878","Web Search, which takes its root in the mature field of information retrieval, evolved tremendously over the last 15 years. The field encountered its first revolution when it started to deal with huge amounts of Web pages. Then, a major step was accomplished when engines started to consider the structure of the Web graph and leveraged link analysis in both crawling and ranking. Finally, a more discrete, but no less critical step, was made when search engines started to monitor and exploit the numerous (mostly implicit) signals provided by users while interacting with the search engine. In this tutorial we focus on this ""revolution"" of large scale usage data. In the first part of this tutorial, we focus on usage data, which typically refers to any type of information provided by the user while interacting with the search engine. It comes first under its raw form as a set of individual signals, but is typically mined after multiple signals have been aggregated and linked to the same interaction event. The two major types of such data are (1) query streams, which include the query string that the user issued, together with the time-stamp of the query, a user identifier, possibly the IP of the machine on which the browser runs, and (2) click data, which include the reference to the element the user clicked on the page together with the timestamp, user identifier, possibly IP, the rank of the link if it is a result, etc. Exploiting usage data under its multiple forms brought an unprecedented wealth of implicit information to Web Search. We discuss in the second part of this tutorial some of the key Web search applications that it made possible. One such example is the query spelling correction feature embodied now in all search engines. In fact, after years of very sophisticated spell checking research, simply counting similar queries at a small edit distance would in most cases surface the most popular spelling as the correct one, a beautiful and simple demonstration of the wisdom of crowds principle.",2013,Web Search and Data Mining,Fields of study: rankingweb search queryweb query classificationquery expansionsearch engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Data-driven political science,Ingmar Weber (Qatar Computing Research Institute)Ana Maria PopescuMarco Pennacchiotti (eBay),"2074066684,2663428585,2618302306","The tutorial will summarize the state-of-the art in the growing area of computational political science. Like many others, this research domain is being revolutionized by the availability of open, big data and the increasing reach and importance of social media. The surging interest on the part of the academic community is matched by intense efforts on the part of political campaigns to use online data in order to learn how to best disseminate information and reach the right potential donors or voters. In this context, a tutorial can summarize existing methods in a fascinating, high-interest area and allow participants with diverse backgrounds to get inspiration from the methods and problems studied. The tutorial will feature seminal research concerning (i) political polarization, (ii) election prediction and polling, and (iii) political campaigning and influence propagation. The goal is not only to familiarize attendees with ideas from related conferences such as WWW, ICWSM or CIKM, but also to present ideas and quantitative methods closer to political science such as Poole's and Rosenthal's NOMINATE score for a politician's political orientation.",2013,Web Search and Data Mining,Fields of study: american political sciencevoting behaviorpolitical communicationbig dataoperations researchworld wide websocial sciencedata miningcomputer science
DL-WSDM'15: Workshop on Deep Learning for Web Search and Data Mining,Bin Gao (Microsoft)Jiang Bian (Microsoft),"2616890138,2609123459","In recent years, deep learning has been a very hot topic in the machine learning community. It has brought break-through results in image classification and speech recognition. Most recently, researchers have also got many promising results in natural language processing using deep learning techniques. As machine learning techniques are widely used in the Web search and data mining applications, many researchers and practitioners are studying the possibility of applying the recently-developed deep learning techniques into these applications. Some of them have made very promising progress, and thus it is a good time to hold a workshop to discuss and share the problems and progress in using deep learning techniques to improve Web search and data mining tasks.",2015,Web Search and Data Mining,Fields of study: inductive transferhyper heuristicdeep learninginstance based learningdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Geographic Segmentation via Latent Poisson Factor Model,Rose Yu (University of Southern California)Andrew Gelfand (Yahoo!)Suju Rajan (Yahoo!)Cyrus Shahabi (University of Southern California)Yan Liu (University of Southern California),"2107161032,2344402029,2229133469,240820708,2240541904","Discovering latent structures in spatial data is of critical importance to understanding the user behavior of location-based services. In this paper, we study the problem of geographic segmentation of spatial data, which involves dividing a collection of observations into distinct geo-spatial regions and uncovering abstract correlation structures in the data. We introduce a novel, Latent Poisson Factor (LPF) model to describe spatial count data. The model describes the spatial counts as a Poisson distribution with a mean that factors over a joint item-location latent space. The latent factors are constrained with weak labels to help uncover interesting spatial dependencies. We study the LPF model on a mobile app usage data set and a news article readership data set. We empirically demonstrate its effectiveness on a variety of prediction tasks on these two data sets.",2016,Web Search and Data Mining,Fields of study: probabilistic latent semantic analysisspatial analysisdata scienceworld wide webdata miningstatisticscomputer science
Web retrieval: the role of users,Ricardo A. Baeza-Yates (Yahoo!)Yoelle Maarek (Yahoo!),"528588921,262608878","Web retrieval methods have evolved through three major steps in the last decade or so. They started from standard documentcentric IR in the early days of the Web, then made a major step forward by leveraging the structure of the Web, using link analysis techniques in both crawling and ranking challenges. A more recent, no less important but maybe more discrete step forward, has been to enter the user in this equation in two ways: (1) implicitly, through the analysis of usage data captured by query logs, and session and click information in general, the goal being to improve ranking as well as to measure user's happiness and engagement; (2) explicitly, by offering novel interactive features; the goal here being to better answer users' needs. In this tutorial, we will cover the user-related challenges associated with the implicit and explicit role of users in Web retrieval. We will review and discuss challenges associated with two types of activities, namely: Usage data analysis and metrics - It is critical to monitor how users interact with Web retrieval systems, as this implicit relevant feedback aggregated at a large scale can approximate quite accurately the level of success of a given feature. Here we have to consider not only clicks statistics but also the time spent in a page, the number of actions per session, etc. User interaction - Given the intrinsic problems posed by the Web, the key challenge for the user is to conceive a good query, one that leads to a manageable and relevant answer. The retrieval system must complete search requests fast and give back relevant results, even for poorly formulated queries. Web retrieval engines thus interact with the user at two key stages, each associated with its own challenges: (1) Expressing a query: Human beings have needs or tasks to accomplish, which are frequently not easy to express as 'queries'. Queries are just a reflection of human needs and are thus, by definition, imperfect. The issue here is for the engine both to assist the user in reflecting this need and to capture the intent behind the query even if the information is incomplete or poorly expressed. (2) Interpreting and using results: Even if the user is able to perfectly express a query, the answer might be split over thousands or millions of Web pages or not exist at all. In this context, numerous questions need to be addressed. Examples include: How do we handle a large answer? How do we select or maybe synthesize the documents that really are of interest to the user? Even in the case of a single document candidate, the document itself could be large. How do we browse such documents efficiently? How to help the user take advantage of results, and possibly combine with applications to perform the task that drove the query? The goal of this tutorial is to teach the key principles and technologies behind the activities and challenges briefly outlined above, bring new understanding and insights to the attendees, and hopefully foster future research. A previous version of this tutorial was offered at the ACM SIGIR",2011,Web Search and Data Mining,Fields of study: rankingweb modelingweb query classificationautomatic identification and data capturequery expansionlink analysisweb pagedata analysisworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Leveraging Behavioral Factorization and Prior Knowledge for Community Discovery and Profiling,Mohammad Akbari (National University of Singapore)Tat-Seng Chua (National University of Singapore),"2517358299,2160663097","Recently community detection has attracted much interest in social media to understand the collective behaviours of users and allow individuals to be modeled in the context of the group. Most existing approaches for community detection exploit either users' social links or their published content, aiming at discovering groups of densely connected or highly similar users. They often fail to find effective communities due to excessive noise in content, sparsity in links, and heterogenous behaviours of users in social media. Further, they are unable to provide insights and rationales behind the formation of the group and the collective behaviours of the users. To tackle these challenges, we propose to discover communities in a low- dimensional latent space in which we simultaneously learn the representation of users and communities. In particular, we integrated different social views of the network into a low-dimensional latent space in which we sought dense clusters of users as communities. By imposing a Laplacian regularizer into affiliation matrix, we further incorporated prior knowledge into the community discovery process. Finally community profiles were computed by a linear operator integrating the profiles of members. Taking the wellness domain as an example, we conducted experiments on a large scale real world dataset of users tweeting about diabetes and its related concepts, which demonstrate the effectiveness of our approach in discovering and profiling user communities.",2017,Web Search and Data Mining,Fields of study: factorizationsocial networkdata scienceworld wide webdata mining
A Concise Integer Linear Programming Formulation for Implicit Search Result Diversification,Haitao Yu (University of Tsukuba)Adam Jatowt (Kyoto University)Roi Blanco (Yahoo!)Hideo Joho (University of Tsukuba)Joemon M. Jose (University of Glasgow)Long Chen (University of Glasgow)Fajie Yuan (University of Glasgow),"2344089676,13250842,2128286424,256360013,2167481407,2342807686,2342748603","To cope with ambiguous and/or underspecified queries, search result diversification (SRD) is a key technique that has attracted a lot of attention. This paper focuses on implicit SRD , where the possible subtopics underlying a query are unknown beforehand. We formulate implicit SRD as a process of selecting and ranking k exemplar documents that utilizes integer linear programming (ILP). Unlike the common practice of relying on approximate methods, this formulation enables us to obtain the optimal solution of the objective function. Based on four benchmark collections, our extensive empirical experiments reveal that: (1) The factors, such as different initial runs , the number of input documents , query types and the ways of computing document similarity significantly affect the performance of diversification models. Careful examinations of these factors are highly recommended in the development of implicit SRD methods. (2) The proposed method can achieve substantially improved performance over the state-of-the-art unsupervised methods for implicit SRD.",2017,Web Search and Data Mining,Fields of study: integer programmingdata miningmachine learningmathematical optimizationalgorithmcomputer science
Predicting Completeness in Knowledge Bases,Luis Galárraga (Télécom ParisTech)Simon Razniewski (Free University of Bozen-Bolzano)Antoine Amarilli (Télécom ParisTech)Fabian M. Suchanek (Télécom ParisTech),"2110653650,314715041,2670394074,2681494453","Knowledge bases such as Wikidata, DBpedia, or YAGO contain millions of entities and facts. In some knowledge bases, the correctness of these facts has been evaluated. However, much less is known about their completeness, i.e., the proportion of real facts that the knowledge bases cover. In this work, we investigate different signals to identify the areas where a knowledge base is complete. We show that we can combine these signals in a rule mining approach, which allows us to predict where facts may be missing. We also show that completeness predictions can help other applications such as fact prediction.",2017,Web Search and Data Mining,Fields of study: recalldata miningartificial intelligencealgorithm
Exploration and discovery of user-generated content in large information spaces,Luca Chiarandini (Pompeu Fabra University),2403961532,"The accumulation of large collections of social media data poses new challenges for the design of exploratory experiences, such as when a user browses through a collection to discover content (e.g. exploring photo collections, network of friends, etc). Cardinality and characteristics of the set, together with volatility of the information, resulting from fast and continuous creation, deletion and updating of entries, trigger novel research questions. In this context, we plan to investigate and contribute to the data analysis, and user interface design of exploratory experiences. The proposed approach is an iterative process where analysis and design phases are performed in cycles. The long-term vision is to understand the underlying reasoning in order to be able to automatically replicate it.",2012,Web Search and Data Mining,Fields of study: user interface designsocial mediauser generated contentuser interfacedata analysisuser experience designdata scienceworld wide webinformation retrievaldata miningcomputer science
Summarizing Answers in Non-Factoid Community Question-Answering,Hongya Song (Shandong University)Zhaochun Ren (University College London)Shangsong Liang (University College London)Piji Li (The Chinese University of Hong Kong)Jun Ma (Shandong University)Maarten de Rijke (University of Amsterdam),"2583647448,2158267603,2131113258,2700721659,2690534472,401833296","We aim at summarizing answers in community question-answering (CQA). While most previous work focuses on factoid question-answering, we focus on the non-factoid question-answering. Unlike factoid CQA, non-factoid question-answering usually requires passages as answers. The shortness, sparsity and diversity of answers form interesting challenges for summarization. To tackle these challenges, we propose a sparse coding-based summarization strategy that includes three core ingredients: short document expansion, sentence vectorization, and a sparse-coding optimization framework. Specifically, we extend each answer in a question-answering thread to a more comprehensive representation via entity linking and sentence ranking strategies. From answers extended in this manner, each sentence is represented as a feature vector trained from a short text convolutional neural network model. We then use these sentence representations to estimate the saliency of candidate sentences via a sparse-coding framework that jointly considers candidate sentences and Wikipedia sentences as reconstruction items. Given the saliency vectors for all candidate sentences, we extract sentences to generate an answer summary based on a maximal marginal relevance algorithm. Experimental results on a benchmark data collection confirm the effectiveness of our proposed method in answer summarization of non-factoid CQA, and moreover, its significant improvement compared to state-of-the-art baselines in terms of ROUGE metrics.",2017,Web Search and Data Mining,Fields of study: neural codingautomatic summarizationnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Social Collaborative Viewpoint Regression with Explainable Recommendations,Zhaochun Ren (University College London)Shangsong Liang (University College London)Piji Li (The Chinese University of Hong Kong)Shuaiqiang Wang (University of Jyväskylä)Maarten de Rijke (University of Amsterdam),"2158267603,2131113258,2700721659,2166001617,401833296","A recommendation is called explainable if it not only predicts a numerical rating for an item, but also generates explanations for users' preferences. Most existing methods for explainable recommendation apply topic models to analyze user reviews to provide descriptions along with the recommendations they produce. So far, such methods have neglected user opinions and influences from social relations as a source of information for recommendations, even though these are known to improve the rating prediction. In this paper, we propose a latent variable model, called social collaborative viewpoint regression (sCVR), for predicting item ratings based on user opinions and social relations. To this end, we use so-called viewpoints, represented as tuples of a concept, topic, and a sentiment label from both user reviews and trusted social relations. In addition, such viewpoints can be used as explanations. We apply a Gibbs EM sampler to infer posterior distributions of sCVR. Experiments conducted on three large benchmark datasets show the effectiveness of our proposed method for predicting item ratings and for generating explanations.",2017,Web Search and Data Mining,Fields of study: topic modelrecommender systemknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
"Detecting Social Media Icebergs by Their Tips: Rumors, Persuasion Campaigns, and Information Needs",Zhe Zhao (University of Michigan),2719009751,-,2016,Web Search and Data Mining,Fields of study: internet privacy
Context-aware item-to-item recommendation within the factorization framework,Balázs Hidasi (Budapest University of Technology and Economics)Domonkos Tikk (Óbuda University),"1950878799,165729861","Item-to-item recommendation -- when the most similar items sought to the actual item -- is an important recommendation scenario in practical recommender systems. One way to solve this task is to use the similarity between item feature vectors of factorization models. By doing so, one may transfer the well-known accuracy of factorization models observed at the personalized recommendations to the item-to-item case. This paper introduces context-awareness to item similarities in the factorization framework. Two levels of context-aware similarities are defined and applied to two context-aware implicit feedback based factorization methods (iTALS and iTALSx). We investigate the advantages and drawbacks of the approaches on four real life implicit feedback data sets and we characterize the conditions for their application. The results suggest that it is worth using contextual information for item-to-item recommendations in the factorization framework, however, one should carefully select the appropriate method to achieve similar accuracy gain than in the case of the more general item-to-user recommendation scenario.",2013,Web Search and Data Mining,Fields of study: factorizationrecommender systemmultimediainformation retrievaldata mining
Groove Radio: A Bayesian Hierarchical Model for Personalized Playlist Generation,Shay Ben-Elazar (Microsoft)Gal Lavee (Microsoft)Noam Koenigstein (Microsoft)Oren Barkan (Microsoft)Hilik Berezin (Microsoft)Ulrich Paquet (Microsoft)Tal Zaccai (Microsoft),"1983766046,1987825461,281847691,2598048354,2585999609,1773006169,2585758341","This paper describes an algorithm designed for Microsoft's Groove music service, which serves millions of users world wide. We consider the problem of automatically generating personalized music playlists based on queries containing a ``seed'' artist and the listener's user ID. Playlist generation may be informed by a number of information sources including: user specific listening patterns, domain knowledge encoded in a taxonomy, acoustic features of audio tracks, and overall popularity of tracks and artists. The importance assigned to each of these information sources may vary depending on the specific combination of user and seed~artist. The paper presents a method based on a variational Bayes solution for learning the parameters of a model containing a four-level hierarchy of global preferences, genres, sub-genres and artists. The proposed model further incorporates a personalization component for user-specific preferences. Empirical evaluations on both proprietary and public datasets demonstrate the effectiveness of the algorithm and showcase the contribution of each of its components.",2017,Web Search and Data Mining,Fields of study: personalizationradiomultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
"Trustworthy Analysis of Online A/B Tests: Pitfalls, challenges and solutions",Alex Deng (Microsoft)Jiannan Lu (Microsoft)Jonthan Litz (Microsoft),"2172042952,2498265925,2585488094","A/B tests (or randomized controlled experiments) play an integral role in the research and development cycles of technology companies. As in classic randomized experiments (e.g., clinical trials), the underlying statistical analysis of A/B tests is based on assuming the randomization unit is independent and identically distributed (\iid). However, the randomization mechanisms utilized in online A/B tests can be quite complex and may render this assumption invalid. Analysis that unjustifiably relies on this assumption can yield untrustworthy results and lead to incorrect conclusions. Motivated by challenging problems arising from actual online experiments, we propose a new method of variance estimation that relies only on practically plausible assumptions, is directly applicable to a wide of range of randomization mechanisms, and can be implemented easily. We examine its performance and illustrate its advantages over two commonly used methods of variance estimation on both simulated and empirical datasets. Our results lead to a deeper understanding of the conditions under which the randomization unit can be treated as \iid In particular, we show that for purposes of variance estimation, the randomization unit can be approximated as \iid when the individual treatment effect variation is small; however, this approximation can lead to variance under-estimation when the individual treatment effect variation is large.",2017,Web Search and Data Mining,Fields of study: restricted randomizationdelta methoddata miningstatistics
Crowdsourcing High Quality Labels with a Tight Budget,Qi Li (University at Buffalo)Fenglong Ma (University at Buffalo)Jing Gao (University at Buffalo)Lu Su (University at Buffalo)Christopher J. Quinn (Purdue University),"2261907930,2227076362,2096731881,2148733542,2100786728","In the past decade, commercial crowdsourcing platforms have revolutionized the ways of classifying and annotating data, especially for large datasets. Obtaining labels for a single instance can be inexpensive, but for large datasets, it is important to allocate budgets wisely. With limited budgets, requesters must trade-off between the quantity of labeled instances and the quality of the final results. Existing budget allocation methods can achieve good quantity but cannot guarantee high quality of individual instances under a tight budget. However, in some scenarios, requesters may be willing to label fewer instances but of higher quality. Moreover, they may have different requirements on quality for different tasks. To address these challenges, we propose a flexible budget allocation framework called Requallo. Requallo allows requesters to set their specific requirements on the labeling quality and maximizes the number of labeled instances that achieve the quality requirement under a tight budget. The budget allocation problem is modeled as a Markov decision process and a sequential labeling policy is produced. The proposed policy greedily searches for the instance to query next as the one that can provide the maximum reward for the goal. The Requallo framework is further extended to consider worker reliability so that the budget can be better allocated. Experiments on two real-world crowdsourcing tasks as well as a simulated task demonstrate that when the budget is tight, the proposed Requallo framework outperforms existing state-of-the-art budget allocation methods from both quantity and quality aspects.",2016,Web Search and Data Mining,Fields of study: crowdsourcingmanagement sciencedata miningcomputer science
Directed Edge Recommender System,"Ios Kotsogiannis (Duke University)Elena Zheleva (University of Maryland, College Park)Ashwin Machanavajjhala (Duke University)","2583951938,1837768759,2073648588","Recommender systems have become ubiquitous in online applications where companies personalize the user experience based on explicit or inferred user preferences. Most modern recommender systems concentrate on finding relevant items for each individual user. In this paper, we describe the problem of directed edge recommendations where the system recommends the best item that a user can gift, share or recommend to another user that he/she is connected to. We propose algorithms that utilize the preferences of both the sender and the recipient by integrating individual user preference models (e.g., based on items each user purchased for themselves) with models of sharing preferences (e.g., gift purchases for others) into the recommendation process. We compare our work to group recommender systems and social network edge labeling, showing that incorporating the task context leads to more accurate recommendations.",2017,Web Search and Data Mining,Fields of study: social networkrecommender systemknowledge managementworld wide webcomputer science
Multi-Score Position Auctions,Denis Xavier Charles (Microsoft)Nikhil R. Devanur (Microsoft)Balasubramanian Sivan (Microsoft),"2121586545,344142878,1994492417","In this paper we propose a general family of position auctions used in paid search, which we call multi-score position auctions. These auctions contain the GSP auction and the GSP auction with squashing as special cases. We show experimentally that these auctions contain special cases that perform better than the GSP auction with squashing, in terms of revenue, and the number of clicks on ads. In particular, we study in detail the special case that squashes the first slot alone and show that this beats pure squashing (which squashes all slots uniformly). We study the equilibria that arise in this special case to examine both the first order and the second order effect of moving from the squashing-all-slots auction to the squash-only-the-top-slot auction. For studying the second order effect, we simulate auctions using the value-relevance correlated distribution suggested in Lahaie and Pennock [2007]. Since this distribution is derived from a study of value and relevance distributions in Yahoo! we believe the insights derived from this simulation to be valuable. For measuring the first order effect, in addition to the said simulation, we also conduct experiments using auction data from Bing over several weeks that includes a random sample of all auctions.",2016,Web Search and Data Mining,Fields of study: unique bid auctiongeneralized second price auctionrevenue equivalenceenglish auctioncombinatorial auctionauction theorycommon value auctioncomputer science
WSDM 2016 Workshop on the Ethics of Online Experimentation,Fernando Diaz (Microsoft)Solon Barocas (Princeton University),"2159093489,2010964403",-,2016,Web Search and Data Mining,Fields of study: ethicsmanagement sciencecomputer science
Listwise Approach for Rank Aggregation in Crowdsourcing,Shuzi Niu (Chinese Academy of Sciences)Yanyan Lan (Chinese Academy of Sciences)Jiafeng Guo (Chinese Academy of Sciences)Xueqi Cheng (Chinese Academy of Sciences)Lei Yu (Chinese Academy of Sciences)Guoping Long (Chinese Academy of Sciences),"2121488763,2154124860,2581340266,2129598186,2636888902,2694218951","Inferring a gold-standard ranking over a set of objects, such as documents or images, is a key task to build test collections for various applications like Web search and recommender systems. Crowdsourcing services provide an efficient and inexpensive way to collect judgments via labeling by sets of annotators. We thus study the problem of finding a consensus ranking from crowdsourced judgments. In contrast to conventional rank aggregation methods which minimize the distance between predicted ranking and input judgments from either pointwise or pairwise perspective, we argue that it is critical to consider the distance in a listwise way to emphasize the position importance in ranking. Therefore, we introduce a new listwise approach in this paper, where ranking measure based objective functions are utilized for optimization. In addition, we also incorporate the annotator quality into our model since the reliability of annotators can vary significantly in crowdsourcing. For optimization, we transform the optimization problem to the Linear Sum Assignment Problem, and then solve it by a very efficient algorithm named CrowdAgg guaranteeing the optimal solution. Experimental results on two benchmark data sets from different crowdsourcing tasks show that our algorithm is much more effective, efficient and robust than traditional methods.",2015,Web Search and Data Mining,Fields of study: ranking svmoptimization probleminformation retrievaldata miningmachine learningmathematical optimizationcomputer science
Social Media Anomaly Detection: Challenges and Solutions,Yan Liu (University of Southern California)Sanjay Chawla (University of Sydney),"2240541904,2201421368","Anomaly detection is of critical importance to prevent malicious activities such as bullying, terrorist attack planning, and fraud information dissemination. With the recent popularity of social media, new types of anomalous behaviors arise, causing concerns from various parties. While a large body of work haven been dedicated to traditional anomaly detection problems, we observe a surge of research interests in the new realm of social media anomaly detection. In this tutorial, we survey existing work on social media anomaly detection, focusing on the new anomalous phenomena in social media and most recent techniques to detect those special types of anomalies. We aim to provide a general overview of the problem domain, common formulations, existing methodologies and future directions.",2017,Web Search and Data Mining,Fields of study: internet privacycomputer securitymachine learningcomputer science
Online social networks: modeling and mining: invited talk,Ravi Kumar (Yahoo!),2232709231,"Online social networks have become major and driving phenomena on the Web. In this talk, we will address key modeling and algorithmic questions related to large online social networks. From the modeling perspective, we raise the question of whether there is a generative model for network evolution. The availability of time-stamped data makes it possible to study this question at an extremely fine granularity. We exhibit a simple, natural model that leads to synthetic networks with properties similar to the online ones. From an algorithmic viewpoint, we focus on data mining challenges posed by the magnitude of data in these networks. In particular, we examine topics related to influence and correlation in user activities and compressibility of such networks.",2009,Web Search and Data Mining,Fields of study: evolving networksdynamic network analysisnetwork sciencecomplex networksocial networkdata scienceworld wide websocial sciencedata miningmachine learningcomputer science
Modeling Event Importance for Ranking Daily News Events,Vinay Setty (Max Planck Society)Abhijit Anand (Leibniz University of Hanover)Arunav Mishra (Max Planck Society)Avishek Anand (Leibniz University of Hanover),"2125694979,2477640381,2193995480,2576154677","We deal with the problem of ranking news events on a daily basis for large news corpora, an essential building block for news aggregation. News ranking has been addressed in the literature before but with individual news articles as the unit of ranking. However, estimating event importance accurately requires models to quantify current day event importance as well as its significance in the historical context. Consequently, in this paper we show that a cluster of news articles representing an event is a better unit of ranking as it provides an improved estimation of popularity, source diversity and authority cues. In addition, events facilitate quantifying their historical significance by linking them with long-running topics and recent chain of events. Our main contribution in this paper is to provide effective models for improved news event ranking. To this end, we propose novel event mining and feature generation approaches for improving estimates of event importance. Finally, we conduct extensive evaluation of our approaches on two large real-world news corpora each of which span for more than a year with a large volume of up to tens of thousands of daily news articles. Our evaluations are large-scale and based on a clean human curated ground-truth from Wikipedia Current Events Portal. Experimental comparison with a state-of-the-art news ranking technique based on language models demonstrates the effectiveness of our approach.",2017,Web Search and Data Mining,Fields of study: learning to rankworld wide webinformation retrievaldata miningmachine learningcomputer science
Democracy is good for ranking: towards multi-view rank learning and adaptation in web search,Wei Gao (Qatar Computing Research Institute)Pei Yang (South China University of Technology),"2627838519,2628924214","Web search ranking models are learned from features originated from different views or perspectives of document relevancy, such as query dependent or independent features. This seems intuitively conformant to the principle of multi-view approach that leverages distinct complementary views to improve model learning. In this paper, we aim to obtain optimal separation of ranking features into non-overlapping subsets (i.e., views), and use such different views for rank learning and adaptation. We present a novel semi-supervised multi-view ranking model, which is then extended into an adaptive ranker for search domains where no training data exists. The core idea is to proactively strengthen view consistency (i.e., the consistency between different rankings each predicted by a distinct view-based ranker) especially when training and test data follow divergent distributions. For this purpose, we propose a unified framework based on listwise ranking scheme to mutually reinforce the view consistency of target queries and the appropriate weighting of source queries that act as prior knowledge. Based on LETOR and Yahoo Learning to Rank datasets, our method significantly outperforms some strong baselines including single-view ranking models commonly used and multi-view ranking models that do not impose view consistency on target data.",2014,Web Search and Data Mining,Fields of study: rankingranking svmlearning to rankdata miningpattern recognitionmachine learning
"Proceedings of the Third International Conference on Web Search and Web Data Mining, WSDM 2010, New York, NY, USA, February 4-6, 2010",Brian D. Davison (Lehigh University)Torsten Suel (Polytechnic Institute of New York University)Nick Craswell (Microsoft)Bing Liu (University of Illinois at Chicago),"2203702053,702140476,2009495402,2244698799",-,2010,Web Search and Data Mining,Fields of study: data scienceworld wide webcomputer science
Fun Facts: Automatic Trivia Fact Extraction from Wikipedia,David Tsurel (Hebrew University of Jerusalem)Dan Pelleg (Yahoo!)Ido Guy (Yahoo!)Dafna Shahaf (Hebrew University of Jerusalem),"2561781278,1551887306,2669811300,2563709684","A significant portion of web search queries directly refers to named entities. Search engines explore various ways to improve the user experience for such queries. We suggest augmenting search results with trivia facts about the searched entity. Trivia is widely played throughout the world, and was shown to increase users' engagement and retention. Most random facts are not suitable for the trivia section. There is skill (and art) to curating good trivia. In this paper, we formalize a notion of trivia-worthiness and propose an algorithm that automatically mines trivia facts from Wikipedia. We take advantage of Wikipedia's category structure, and rank an entity's categories by their trivia-quality. Our algorithm is capable of finding interesting facts, such as Obama's Grammy or Elvis' stint as a tank gunner. In user studies, our algorithm captures the intuitive notion of ""good trivia"" 45% higher than prior work. Search-page tests show a 22% decrease in bounce rates and a 12% increase in dwell time, proving our facts hold users' attention.",2017,Web Search and Data Mining,Fields of study: world wide webdata miningartificial intelligencemachine learningcomputer sciencemathematics
Multi-Product Utility Maximization for Economic Recommendation,"Qi Zhao (University of California, Santa Cruz)Yongfeng Zhang (University of Massachusetts Amherst)Yi Zhang (University of California, Santa Cruz)Daniel Friedman (University of California, Santa Cruz)","2662047542,2617042463,2671671868,2111008785","Basic economic relations such as substitutability and complementarity between products are crucial for recommendation tasks, since the utility of one product may depend on whether or not other products are purchased. For example, the utility of a camera lens could be high if the user possesses the right camera (complementarity), while the utility of another camera could be low because the user has already purchased one (substitutability). We propose \emph{multi-product utility maximization} (MPUM) as a general approach to recommendation driven by economic principles. MPUM integrates the economic theory of consumer choice with personalized recommendation, and focuses on the utility of \textit{sets} of products for individual users. MPUM considers what the users already have when recommending additional products. We evaluate MPUM against several popular recommendation algorithms on two real-world E-commerce datasets. Results confirm the underlying economic intuition, and show that MPUM significantly outperforms the comparison algorithms under top-K evaluation metrics.",2017,Web Search and Data Mining,Fields of study: collaborative filteringrecommender systemworld wide webdata miningmachine learningcomputer science
Machine reading at web scale,Oren Etzioni (University of Washington),57747768,-,2008,Web Search and Data Mining,Fields of study: information extractionnatural language processingworld wide webinformation retrievalcomputer science
Concept Embedded Convolutional Semantic Model for Question Retrieval,Pengwei Wang (South China University of Technology)Yong Zhang (Weber State University)Lei Ji (Microsoft)Jun Yan (Microsoft)Lianwen Jin (South China University of Technology),"2501582042,2639793481,2106100428,2150635322,2719437060","The question retrieval, which aims to find similar questions of a given question, is playing pivotal role in various question answering (QA) systems. This task is quite challenging mainly on three aspects: lexical gap, polysemy and word order. In this paper, we propose a unified framework to simultaneously handle these three problems. We use word combined with corresponding concept information to handle the polysemous problem. The concept embedding and word embedding are learned at the same time from both context-dependent and context-independent view. The lexical gap problem is handled since the semantic information has been encoded into the embedding. Then, we propose to use a high-level feature embedded convolutional semantic model to learn the question embedding by inputting the concept embedding and word embedding without manually labeling training data. The proposed framework nicely represent the hierarchical structures of word information and concept information in sentences with their layer-by-layer composition and pooling. Finally, the framework is trained in a weakly-supervised manner on question answer pairs, which can be directly obtained without manually labeling. Experiments on two real question answering datasets show that the proposed framework can significantly outperform the state-of-the-art solutions.",2017,Web Search and Data Mining,Fields of study: natural language processinginformation retrievaldata mining
Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,Paul N. Bennett (Microsoft)Vanja Josifovski (Yahoo!)Jennifer Neville (Purdue University)Filip Radlinski (Microsoft),"2137013502,344688379,2124572662,2072292845","Welcome to WSDM, the 9th annual ACM International Conference on Web Search and Data Mining, held in San Francisco, USA. WSDM is one of the premier conferences on web inspired research involving search and data mining. We are pleased to present here the proceedings of the conference. The program reflects the breadth and diversity of research in the field and showcases the latest developments in the field. The conference received a total of 368 submissions, out of which 67 were accepted for publication. As has been customary for the conference, we used a two-tier single-blind review process. In the first stage, three to four program committee members were assigned to every paper. The PC members provided ratings and comments while evaluating the papers according to the standard criteria of relevance, quality, reproducibility, clarity, and impact. In the second stage, every paper was assigned nto a senior PC member. The senior PC member was tasked to oversee a discussion amongst the reviewers and attempt to reach a consensus recommendation for the paper. The final decisions were based on all of the above, as well as the senior PC member's recommendation. Ultimately 67 papers were selected for inclusion in the program. The WSDM 2016 acceptance rate of 18.2% is comparable to the previous years. The accepted papers are from 90 institutions in 18 countries. The top technical areas covered by the accepted papers (as indicated by paper keywords) are machine learning (19%), social networks (16%), search (15%), social media (10%), and ranking (9%). This year, continuing with the WSDM tradition, oral presentation slots were allocated to all 67 accepted papers. Out of the 67 papers, 20 were assigned long presentation slots and 47 were assigned short presentation slots. This assignment was based on the topic and results in each paper, with the Program Chairs assigning long slots to papers more likely to appeal to a broader audience. In addition to the oral presentations, all papers will be presented as posters in interactive sessions. We would like to acknowledge the tremendous work of the 41 senior program committee members, 243 program committee members, and 133 additional reviewers. Much of the credit for creating a high quality technical program goes to them. To recognize the hard work of the best reviewers, which is rarely publicized, we have awarded 21 Outstanding Reviewer Awards to members of the program committee, who were nominated by senior PC members as standing out amongst the reviewers. The technical program this year also features keynotes by prominent researchers from academia and industry, Jeff Dean (Google), Yiling Chen (Harvard University), and Foster Provost (New York University). The program also features four invited Practice & Experience talks, which were introduced for the first time at WSDM 2014. These comprise Yoelle Maarek (Yahoo Labs), Jie Tang (Tsinghua University), Lars Backstrom (Facebook), and Mor Naaman (Cornell Tech/Seen.co). We would like to thank the keynote and P&E speakers for sharing their technical insights and research contributions with the conference attendees. In addition, the program includes five workshops, two tutorials, and the WSDM Doctoral Consortium. We are happy to announce the first WSDM Cup Competition and expanded Industry Day that includes talks from venture capital investors and startups, taking advantage of the San Francisco location. The challenge in the inaugural 2016 WSDM CUP, organized by Microsoft and Elsevier, was to assess the query-independent importance of scholarly articles using data from the Microsoft Academic Graph. The VC & Industry Day includes four keynote and invited talks, three panels, and a poster session, discussing the role and application of data science in industry.",2016,Web Search and Data Mining,Fields of study: operations researchworld wide websocial sciencedata miningcomputer science
Machine learning for query-document matching in search,Hang Li (Microsoft)Jun Xu (Microsoft),"2128739099,2598177019","In web search, relevance is one of the most important factors to meet users' satisfaction, and the success of a web search engine heavily depends on its performance on relevance. It has been observed that many hard cases in search relevance are due to term mismatch between query and documnt (e.g., query 'ny times' does not match well with document only containing 'new york times'), and thus it is not exaggerated to say that dealing with mismatch between query and document is one of the most critical research problems in web search. Recently researchers have spent significant effort to address the grand challenge. The major approach is to conduct more query and document understanding, and perform better matching between enriched query and document representations. With the availability of large amount of log data and advanced machine learning techniques, this becomes more feasible and significant progress has been made recently. In this tutorial, we will give a systematic and detailed presentation on newly developed machine learning technologies for query document matching in search. We will focus on the fundamental problems, as well as the novel solutions for query document matching at word form level, word sense level, topic level, and structure level. We will talk about novel technologies about query spelling error correction [3, 13], query rewriting [1, 4, 6, 7], query classification [2], topic modeling of documents [5, 9], query document matching [8, 10, 11, 12], and query document-title translation. The ideas and solutions introduced in this tutorial may motivate industrial practitioners to turn the research fruits into product reality. The summary of the state-of-the-art methods and the discussions on the technical issues in this tutorial may stimulate academic researchers to find new research directions and solutions. Matching between query and document is not limited to search, and similar problems can be observed at online advertisement, recommendation system, and other applications, as matching between objects from two spaces. The technologies we introduce can be generalized into more general machine learning techniques, which we call learning to match.",2012,Web Search and Data Mining,Fields of study: sargablerankingrdf query languageonline aggregationweb search queryweb query classificationquery by examplequery expansionquery optimizationquery languagesearch engineerror detection and correctiononline advertisingrecommender systemweb search engineworld wide webinformation retrievaldata miningmachine learningcomputer science
Understanding Offline Political Systems by Mining Online Political Data,David Lazer (Northeastern University)Oren Tsur (Northeastern University)Tina Eliassi-Rad (Rutgers University),"2082712981,766307452,218538652","""Man is by nature a political animal"", as asserted by Aristotle. This political nature manifests itself in the data we produce and the traces we leave online. In this tutorial, we address a number of fundamental issues regarding mining of political data: What types of data could be considered political? What can we learn from such data? Can we use the data for prediction of political changes, etc? How can these prediction tasks be done efficiently? Can we use online socio-political data in order to get a better understanding of our political systems and of recent political changes? What are the pitfalls and inherent shortcomings of using online data for political analysis? In recent years, with the abundance of data, these questions, among others, have gained importance, especially in light of the global political turmoil and the upcoming 2016 US presidential election. We introduce relevant political science theory, describe the challenges within the framework of computational social science and present state of the art approaches bridging social network analysis, graph mining, and natural language processing.",2016,Web Search and Data Mining,Fields of study: american political sciencepolitical methodologyvoting behaviorcomputational sociologypolitical communicationmanagement sciencedata scienceworld wide websocial sciencedata miningmachine learningcomputer science
Reliable Medical Diagnosis from Crowdsourcing: Discover Trustworthy Answers from Non-Experts,Yaliang Li (University at Buffalo)Nan Du (Baidu)Chaochun Liu (Baidu)Yusheng Xie (Baidu)Wei Fan (Baidu)Qi Li (University at Buffalo)Jing Gao (University at Buffalo)Huan Sun (Ohio State University),"2116094297,2711557452,2591552934,2602397988,2422054197,2261907930,2096731881,2594620155","Nowadays, increasingly more people are receiving medical diagnoses from healthcare-related question answering platforms as people can get diagnoses quickly and conveniently. However, such diagnoses from non-expert crowdsourcing users are noisy or even wrong due to the lack of medical domain knowledge, which can cause serious consequences. To unleash the power of crowdsourcing on healthcare question answering, it is important to identify trustworthy answers and filter out noisy ones from user-generated data. Truth discovery methods estimate user reliability degrees and infer trustworthy information simultaneously, and thus these methods can be adopted to discover trustworthy diagnoses from crowdsourced answers. However, existing truth discovery methods do not take into account the rich semantic meanings of the answers. In the light of this challenge, we propose a method to automatically capture the semantic meanings of answers, where answers are represented as real-valued vectors in the semantic space. To learn such vector representations from noisy user-generated data, we tightly combine the truth discovery and vector learning processes. In this way, the learned vector representations enable truth discovery method to model the semantic relations among answers, and the information trustworthiness inferred by truth discovery can help the procedure of vector representation learning. To demonstrate the effectiveness of the proposed method, we collect a large-scale real-world dataset that involves 219,527 medical diagnosis questions and 23,657 non-expert users. Experimental results show that the proposed method improves the accuracy of identified trustworthy answers due to the successful consideration of answers' semantic meanings. Further, we demonstrate the fast convergence and good scalability of the proposed method, which makes it practical for real-world applications.",2017,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningcomputer science
Managing Risk of Bidding in Display Advertising,Haifeng Zhang (Peking University)Weinan Zhang (Shanghai Jiao Tong University)Yifei RongKan Ren (Shanghai Jiao Tong University)Wenxin Li (Peking University)Jun Wang (University College London),"2575368951,2527611484,2343807655,2277084468,2652710644,2557836567","In this paper, we deal with the uncertainty of bidding for display advertising. Similar to the financial market trading, real-time bidding (RTB) based display advertising employs an auction mechanism to automate the impression level media buying; and running a campaign is no different than an investment of acquiring new customers in return for obtaining additional converted sales. Thus, how to optimally bid on an ad impression to drive the profit and return-on-investment becomes essential. However, the large randomness of the user behaviors and the cost uncertainty caused by the auction competition may result in a significant risk from the campaign performance estimation. In this paper, we explicitly model the uncertainty of user click-through rate estimation and auction competition to capture the risk. We borrow an idea from finance and derive the value at risk for each ad display opportunity. Our formulation results in two risk-aware bidding strategies that penalize risky ad impressions and focus more on the ones with higher expected return and lower risk. The empirical study on real-world data demonstrates the effectiveness of our proposed risk-aware bidding strategies: yielding profit gains of 15.4% in offline experiments and up to 17.5% in an online A/B test on a commercial RTB platform over the widely applied bidding strategies.",2017,Web Search and Data Mining,Fields of study: ebiddingreal time biddingvalue at riskcommercemicroeconomicsmarketingeconomics
Building user profiles to improve user experience in recommender systems,Anisio Lacerda (Universidade Federal de Minas Gerais)Nivio Ziviani (Universidade Federal de Minas Gerais),"2474864134,252533809","Recommender systems are quickly becoming ubiquitous in many Web applications, including e-commerce, social media channels, content providers, among others. These systems act as an enabling mechanism designed to overcome the information overload problem by improving browsing and consumption experience. Crucial to the performance of a recommender system is the accuracy of the user profiles used to represent the interests of the users. In this proposal, we analyze three different aspects of user profiling: (i) selecting the most informative events from the interaction between users and the system, (ii) combining different recommendation algorithms to (iii) including trust-aware information in user profiles to improve the accuracy of recommender systems.",2013,Web Search and Data Mining,Fields of study: recommender systemknowledge managementmultimediaworld wide webmachine learningcomputer science
Econometric analysis and digital marketing: how to measure the effectiveness of an ad,Ayman Farahat (Adobe Systems)James Shanahan,"2492218439,2609097300","Over the past 18 years online advertising has grown to a $70 billion industry worldwide annually. Despite this impressive growth, online advertising faces many (and some would say traditional) challenges including how to measure the efficiency or the potential loss of sales caused by the inefficient use of advertising dollars. Consequently, it is vital to measure, maximize, and benchmark the efficiency of advertising media expenditures. This tutorial introduces the field of econometrics as a means of measuring the effectiveness of digital marketing. Econometrics is a field that extends and applies statistical methods to the analysis of economic phenomena. In that vein, econometrics goes beyond traditional statistics and explicitly recognizes the complexities of human behavior. Consider for example the impact of deep discounts on survival of restaurants. Struggling businesses are more likely to offer these deep discounts and eventually fail. A naive application of statistical techniques will overestimate the impact of deep discounts on business survival. In this case, the discounts are an endogenous variable as compared to an exogenous variable. This type of specification error highlights why we need a deeper look at the variables that go into statistical models. Econometrics addresses these and other issues in a formal and rigorous manner.",2013,Web Search and Data Mining,Fields of study: big dataworld wide websocial sciencedata miningstatisticscomputer science
Web-scale classification: web classification in the big data era,"Ioannis Partalas (Joseph Fourier University)Massih-Reza Amini (Centre national de la recherche scientifique)Ion Androutsopoulos (Athens University of Economics and Business)Thierry Artieres (University of Paris)Patrick Gallinari (University of Paris)Eric Gaussier (Xerox)Georgios Paliouras (National Centre of Scientific Research ""Demokritos"")","127847919,2111378394,1808727851,68675087,2638033927,1119378480,2086391101","This paper provides an overview of the workshop Web-Scale Classification: Web Classification in the Big Data Era which was held in New York City, on February 28th as a workshop of the seventh International Conference on Web Search and Data Mining. The goal of the workshop was to discuss and assess recent research focusing on classification and mining in Web-scale category systems. The workshop brought together members of several communities such web mining, machine learning, text classification and social media mining.",2014,Web Search and Data Mining,Fields of study: web miningdata scienceworld wide webdata miningcomputer science
Random Semantic Tensor Ensemble for Scalable Knowledge Graph Link Prediction,"Yi Tay (Nanyang Technological University)Anh Tuan Luu (Agency for Science, Technology and Research)Siu Cheung Hui (Nanyang Technological University)Falk Brauer","2565870016,2257712515,2688219371,2642079232","Link prediction on knowledge graphs is useful in numerous application areas such as semantic search, question answering, entity disambiguation, enterprise decision support, recommender systems and so on. While many of these applications require a reasonably quick response and may operate on data that is constantly changing, existing methods often lack speed and adaptability to cope with these requirements. This is aggravated by the fact that knowledge graphs are often extremely large and may easily contain millions of entities rendering many of these methods impractical. In this paper, we address the weaknesses of current methods by proposing Random Semantic Tensor Ensemble (RSTE), a scalable ensemble-enabled framework based on tensor factorization. Our proposed approach samples a knowledge graph tensor in its graph representation and performs link prediction via ensembles of tensor factorization. Our experiments on both publicly available datasets and real world enterprise/sales knowledge bases have shown that our approach is not only highly scalable, parallelizable and memory efficient, but also able to increase the prediction accuracy significantly across all datasets.",2017,Web Search and Data Mining,Fields of study: semantic searchtheoretical computer scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Not Enough Data?: Joint Inferring Multiple Diffusion Networks via Network Generation Priors,Xinran He (University of Southern California)Yan Liu (University of Southern California),"2096901250,2240541904","Network Inference, i.e., discovering latent diffusion networks from observed cascades, has been studied extensively in recent years, leading to a series of excellent work. However, it has been observed that the accuracy of existing methods deteriorates significantly when the number of cascades are limited (compared with the large number of nodes), which is the norm in real world applications. Meanwhile, we are able to collect cascades on many different topics or over a long time period: the associated influence networks (either topic-specific or time-specific) are highly correlated while the number of cascade observations associated with each network is very limited. In this work, we propose a generative model, referred to as the MultiCascades model (MCM), to address the challenge of data scarcity by exploring the commonality between multiple related diffusion networks. MCM builds a hierarchical graphical model, where all the diffusion networks share the same network prior, e.g., the popular Stochastic Blockmodels or the latent space models. The parameters of the network priors can be effectively learned by gleaning evidence from a large number of inferred networks. In return, each individual network can be inferred more accurately thanks to the prior information. Furthermore, we develop efficient inference and learning algorithms so that MCM is scalable for practical applications. The results on both synthetic datasets and real-world datasets demonstrate that MCM infers both topic-specific and time-varying diffusion networks more accurately.",2017,Web Search and Data Mining,Fields of study: evolving networkssocial influencedata miningmachine learningstatisticscomputer science
"Proceedings of the International Conference on Web Search and Web Data Mining, WSDM 2008, Palo Alto, California, USA, February 11-12, 2008",Marc Najork (Microsoft)Andrei Broder (IBM)Soumen Chakrabarti (Indian Institute of Technology Bombay),"2027155665,1970098533,2103349674",-,2008,Web Search and Data Mining,Fields of study: data scienceworld wide webdata miningcomputer science
Raising Graphs From Randomness to Reveal Information Networks,Róbert Pálovics (Hungarian Academy of Sciences)András A. Benczúr (Hungarian Academy of Sciences),"258293863,701011148","We analyze the fine-grained connections between the average degree and the power-law degree distribution exponent in growing information networks. Our starting observation is a power-law degree distribution with a decreasing exponent and increasing average degree as a function of the network size. Our experiments are based on three Twitter at-mention networks and three more from the Koblenz Network Collection. We observe that popular network models cannot explain decreasing power-law degree distribution exponent and increasing average degree at the same time. We propose a model that is the combination of exponential growth, and a power-law developing network, in which new ""homophily"" edges are continuously added to nodes proportional to their current homophily degree. Parameters of the average degree growth and the power-law degree distribution exponent functions depend on the ratio of the network growth exponent parameters. Specifically, we connect the growth of the average degree to the decreasing exponent of the power-law degree distribution. Prior to our work, only one of the two cases were handled. Existing models and even their combinations can only reproduce some of our key new observations in growing information networks.",2017,Web Search and Data Mining,Fields of study: urban densityexponential growthdegree distributionpower lawstatistics
Applying Space Syntax to Online Mapping Tools,Yandi Li (Polytechnic University of Catalonia)Nicola Barbieri (Yahoo!)Daniele Quercia (Bell Labs),"2585451821,2155070167,2714967879","To walk around the city, individuals use mobile mapping services, and such services mostly suggest shortest routes. To go beyond recommending such walkable routes, we propose a new framework for automatic wayfinding for pedestrians. This framework tackles two main drawbacks from which past work suffers, namely coarse-grained representation of space and absence of contextual dynamics. We model the human tendency to regularize space by borrowing a spatial representation, Space Syntax, from the discipline of Architecture. Moreover, the proposed framework accounts for contextual dynamics of individual streets by predicting the popularity of each street under different contexts (e.g., at a given time, with a certain weather condition). Using Foursquare check-ins (i.e., whereabouts of the users of the popular location-based service) and publicly available weather data, we validate our framework in the entire city of Barcelona. We find that, with paths slightly longer than the shortest ones, our framework is able to accommodate our mental topography and effectively capture contextual changes.",2017,Web Search and Data Mining,Fields of study: world wide webdata miningartificial intelligencemachine learningsimulationcomputer science
Wiggins: Detecting Valuable Information in Dynamic Networks Using Limited Resources,Ahmad Mahmoody (Brown University)Matteo Riondato (Brown University)Eli Upfal (Brown University),"2090690368,1555209364,2685185700","Detecting new information and events in a dynamic network by probing individual nodes has many practical applications: discovering new webpages, analyzing influence properties in network, and detecting failure propagation in electronic circuits or infections in public drinkable water systems. In practice, it is infeasible for anyone but the owner of the network (if existent) to monitor all nodes at all times. In this work we study the constrained setting when the observer can only probe a small set of nodes at each time step to check whether new pieces of information (items) have reached those nodes. We formally define the problem through an infinite time generating process that places new items in subsets of nodes according to an unknown probability distribution. Items have an exponentially decaying novelty, modeling their decreasing value. The observer uses a probing schedule (i.e., a probability distribution over the set of nodes) to choose, at each time step, a small set of nodes to check for new items. The goal is to compute a schedule that minimizes the average novelty of undetected items. We present an algorithm, WIGGINS, to compute the optimal schedule through convex optimization, and then show how it can be adapted when the parameters of the problem must be learned or change over time. We also present a scalable variant of WIGGINS for the MapReduce framework. The results of our experimental evaluation on real social networks demonstrate the practicality of our approach.",2016,Web Search and Data Mining,Fields of study: social networkcombinatoricsworld wide websocial sciencedata miningartificial intelligencemachine learningstatisticscomputer science
Evolution of Ego-networks in Social Media with Link Recommendations,Luca Maria Aiello (Bell Labs)Nicola Barbieri (Yahoo!),"2677626719,2155070167","Ego-networks are fundamental structures in social graphs, yet the process of their evolution is still widely unexplored. In an online context, a key question is how link recommender systems may skew the growth of these networks, possibly restraining diversity. To shed light on this matter, we analyze the complete temporal evolution of 170M ego-networks extracted from Flickr and Tumblr, comparing links that are created spontaneously with those that have been algorithmically recommended. We find that the evolution of ego-networks is bursty, community-driven, and characterized by subsequent phases of explosive diameter increase, slight shrinking, and stabilization. Recommendations favor popular and well-connected nodes, limiting the diameter expansion. With a matching experiment aimed at detecting causal relationships from observational data, we find that the bias introduced by the recommendations fosters global diversity in the process of neighbor selection. Last, with two link prediction experiments, we show how insights from our analysis can be used to improve the effectiveness of social recommender systems.",2017,Web Search and Data Mining,Fields of study: social mediaworld wide webdata miningmachine learningcomputer science
Who likes it more?: mining worth-recommending items from long tails by modeling relative preference,Yu-Chieh Ho (National Taiwan University)Yi-Ting Chiang (Academia Sinica)Jane Yung-Jen Hsu (National Taiwan University),"2686868479,2645202830,2644136586","Recommender systems are useful tools that help people to filter and explore massive information. While the accuracy of recommender systems is important, many recent research indicated that focusing merely on accuracy not only is insufficient to meet user needs, but also may be harmful. Other characteristics such as novelty, unexpectedness and diversity should also be taken into consideration. Previous work has shown that more the sales of long-tail items could be more beneficial to both customers and some business models. However, the majority of collaborative filtering approaches tends to recommend popular selling items. In this work, we focus on long-tail item promotion and aggregate diversity enhancement, and propose a novel approach which diversifies the results of recommender systems by considering ``recommendations"" as resources to be allocated to the items. Our approach increases the quantity and quality of long-tail item recommendations by adding more variation into the recommendation and maintains a certain level of accuracy simultaneously. The experimental results show that this approach can discover more worth-recommending items from Long Tails and improves user experience.",2014,Web Search and Data Mining,Fields of study: collaborative filteringlong tailrecommender systemworld wide webinformation retrievaldata miningmachine learningcomputer science
Query Understanding for Search on All Devices at WSDM 2016,Amit Goyal (Yahoo!)Jianfeng Gao (Microsoft)Hongbo Deng (Yahoo!)Yi Chang (Yahoo!),"2234909068,2698072812,2682826105,2168000538",-,2016,Web Search and Data Mining,Fields of study: sargablerankingrdf query languageonline aggregationmobile searchweb search queryweb query classificationquery by examplequery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningdatabasecomputer science
Synthesis of Forgiving Data Extractors,Adi Omari (Technion – Israel Institute of Technology)Sharon Shoham (Tel Aviv University)Eran Yahav (Technion – Israel Institute of Technology),"2480507036,2144636783,2194672974","We address the problem of synthesizing a robust data-extractor from a family of websites that contain the same kind of information. This problem is common when trying to aggregate information from many web sites, for example, when extracting information for a price-comparison site. Given a set of example annotated web pages from multiple sites in a family, our goal is to synthesize a robust data extractor that performs well on all sites in the family (not only on the provided example pages). The main challenge is the need to trade off precision for generality and robustness. Our key contribution is the introduction of forgiving extractors that dynamically adjust their precision to handle structural changes, without sacrificing precision on the training set. Our approach uses decision tree learning to create a generalized extractor and converts it into a forgiving extractor, inthe form of an XPath query. The forgiving extractor captures a series of pruned decision trees with monotonically decreasing precision, and monotonically increasing recall, and dynamically adjusts precision to guarantee sufficient recall. We have implemented our approach in a tool called TREEX and applied it to synthesize extractors for real-world large scale web sites. We evaluate the robustness and generality of the forgiving extractors by evaluating their precision and recall on: (i) different pages from sites in the training set (ii) pages from different versions of sites in the training set (iii) pages from different (unseen) sites. We compare the results of our synthesized extractor to those of classifier-based extractors, and pattern-based extractors, and show that TREEX significantly improves extraction accuracy.",2017,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Find me opinion sources in blogosphere: a unified framework for opinionated blog feed retrieval,Xueke Xu (Chinese Academy of Sciences)Songbo Tan (Chinese Academy of Sciences)Yue Liu (Chinese Academy of Sciences)Xueqi Cheng (Chinese Academy of Sciences)Zheng Lin (Chinese Academy of Sciences)Jiafeng Guo (Chinese Academy of Sciences),"2637515203,2162871507,2695326095,2129598186,2085002608,2581340266","This paper aims to find blog feeds having a principal inclination towards making opinionated comments on the given topic, so that we can subscribe to them to track influential and interesting opinions in the blogosphere. One major challenge is assigning topic-related opinion scores to blog feeds, which is embodied in two aspects. Firstly, we should identify whether the blog feed has a principal on-topic opinionated inclination. This inclination should be collectively revealed by all posts of the feed. We should fully consider evidences from all the posts of the feed to identify salient information among many posts of the feed. Secondly, we should capture topic-related opinions in the blog feed while ignoring irrelevant opinions. In this paper, we propose a unified framework for opinionated blog feed retrieval, which combines topic relevance and opinion scores with a generative model. Furthermore, we propose a language modeling approach to estimating opinion scores that is seamlessly integrated into the framework, where two language models, Topic-specific Opinion Model (TOM) and Topic-biased Feed Model (TFM), work collectively to reflect whether the blog feed shows a principal on-topic opinionated inclination. To estimate TFM, we propose a topic-biased random walk to exploit both content and structural information to capture topic-biased salient information in the feed. As for TOM estimation, we propose to use a generative mixture model with prior guidance to effectively capture topic-specific opinion expressing language usage. The conducted experiments in the context of the TREC 2009-2010 Blog Track show the effectiveness of our proposed approaches.",2012,Web Search and Data Mining,Fields of study: mixture modelrandom walklanguage modeldata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Learning website hierarchies for keyword enrichment in contextual advertising,Pavan Kumar Gm (Yahoo!)Krishna P. Leela (Microsoft)Mehul Parsana (Microsoft)Sachin Garg (Yahoo!),"2226880941,2311381166,2303083129,2584178023","In Contextual advertising, textual ads relevant to the content in a webpage are embedded in the page. Content keywords are extracted offline by crawling webpages and then stored in an index for fast serving. Given a page, ad selection involves index lookup, computing similarity between the keywords of the page and those of candidate ads and returning the top- k scoring ads. In this approach, ad relevance can suffer in two scenarios. First, since page-ad similarity is computed using keywords extracted only from that particular page, a few non pertinent keywords can skew ad selection. Second, requesting page may not be present in the index but we still need to serve relevant ads. We propose a novel mechanism to mitigate these problems in the same framework. The basic idea is to enrich keywords of a particular page with keywords from other but ""similar"" pages. The scheme involves learning a website specific hierarchy from (page, URL) pairs of the website. Next, keywords are populated on the nodes via successive top-down and bottom-up iterations over the hierarchy. We evaluate our approach on three data sets, one small human labeled set and two large-scale sets from Yahoo's contextual advertising system. Empirical evaluation show that ads fetched by enriching keywords has 2-3% higher nDCG compared to ads fetched based on a recent semantic approach even though the index size of our approach is 7 times less than the index size of semantic approach. Evaluation over pages which are not present in the index shows that ads fetched by our method has 6-7% higher nDCG compared to ads fetched based on a recent approach which uses first N bytes of the page content. Scalability is demonstrated via map-reduce adoption of our method and training on a large data set of 220 million pages from 95,104 websites.",2011,Web Search and Data Mining,Fields of study: top down and bottom up designcontextual advertisingworld wide webinformation retrievaldata miningdatabasecomputer science
Serving a Billion Personalized News Feeds,Lars Backstrom (Facebook),2096207090,"Feed ranking's goal is to provide perople with over a billion personalized experiences. We strive to provide the most compelling content to each person, personalized to them so that they are most likely to see the content that is most interesting to them. Similar to a newspaper, putting the right stories above the fold has always been critical to engaging customers and interesting them in the rest of the paper. In feed ranking, we face a similar challenge, but on a grander scale. Each time a person visits, we need to find the best piece of content out of all the available stories and put it at the top of feed where people are most likely to see it. To accomplish this, we do large-scale machine learning to model each person, figure out which friends, pages and topics they care about and pick the stories each particular person is interested in. In addition to the large-scale machine learning problems we work on, another primary area of research is understanding the value we are creating for people and making sure that our objective function is in alignment with what people want.",2016,Web Search and Data Mining,Fields of study: social networkmultimediaworld wide webdata miningmachine learningcomputer science
Online Matrix Completion for Signed Link Prediction,Jing Wang (Rutgers University)Jie Shen (Rutgers University)Ping Li (Rutgers University)Huan Xu (Georgia Institute of Technology),"2709616673,2479609018,2721445647,2604443296","This work studies the binary matrix completion problem underlying a large body of real-world applications such as signed link prediction and information propagation. That is, each entry of the matrix indicates a binary preference such as ""like"" or ""dislike"", ""trust"" or ""distrust"". However, the performance of existing matrix completion methods may be hindered owing to three practical challenges: 1) the observed data are with binary label (i.e., not real value); 2) the data are typically sampled non-uniformly (i.e., positive links dominate the negative ones) and 3) a network may have a huge volume of data (i.e., memory and computational issue). In order to remedy these problems, we propose a novel framework which { i } maximizes the resemblance between predicted and observed matrices as well as penalizing the logistic loss to fit the binary data to produce binary estimates; { ii } constrains the matrix max-norm and maximizes the F-score to handle non-uniformness and { iii } presents online optimization technique, hence mitigating the memory cost. Extensive experiments performed on four large-scale datasets with up to hundreds of thousands of users demonstrate the superiority of our framework over the state-of-the-art matrix completion based methods and popular link prediction approaches.",2017,Web Search and Data Mining,Fields of study: decision matrixtheoretical computer sciencedata miningmachine learningstatistics
Data that matter: opportunities in crisis informatics research,Leysia Palen (University of Colorado Boulder),2171737383,"In an increasingly global society and on a planet experiencing effects of climate change, large-scale emergencies both instigated by humans and arising from nature can devastate human life and our tightly- woven social fabric. With a promise of improved warning and coordination, a prevailing hope is that information and communication technology (ICT) can help reduce the impacts of large-scale disruptions, including political crises, natural disasters, pandemics, and terrorist threats. Much of the focus of development has been on the formal emergency response effort. However, social computing is changing the way we understand information distribution. By viewing the citizenry as a powerful, self-organizing, and collectively intelligent force, ICT is now playing a remarkable and transformational role in the way society responds to mass emergencies and disasters. Furthermore, this view of a civil society that can be augmented by ICT is based on social and behavioral knowledge about how people truly respond in disaster, rather than on simplified and mythical portrayals of people unable to help themselves [2]. Indeed, long before the advent of widely available social computing platforms, research has shown that disaster victims themselves are the true first responders, frequently acting on the basis of knowledge not available to officials [1, 3, 6]. We argue that this transformative view is critical to our global future: When large-scale emergencies happen, there is often no way to survive it in practical terms unless we rely on each other for help. The urgency and scale of many disaster events are such that no one, not even the most experienced and best technology- equipped responders' can rescue all victims or direct all people over the span of the event as to what the best course of action might be. Climate change and population migration to geographically vulnerable areas mean that naturally occurring hazards will exert increasingly extensive damage. Man-made and terrorist threats can also have greater potential to cause lasting damage to the social and built environment. It is instead necessary, through innovative ICT, to leverage the power of the collective intelligence of the citizenry to support natural instincts, which are to search for reliable information using any means possible to optimize for local conditions [5].",2014,Web Search and Data Mining,Fields of study: social mediaemergencydisastersocial computingworld wide websocial sciencedata miningsimulationcomputer science
Click Models for Web Search and their Applications to IR: WSDM 2016 Tutorial,Aleksandr Chuklin (Google)Ilya Markov (University of Amsterdam)Maarten de Rijke (University of Amsterdam),"113447990,2311084885,401833296","In this tutorial we give an overview of click models for web search. We show how the framework of probabilistic graphical models helps to explain user behavior, build new evaluation metrics and perform simulations. The tutorial discusses foundational aspects alongside experimental details and applications, with live demos and discussions of publicly available resources.",2016,Web Search and Data Mining,Fields of study: data sciencemultimediaworld wide webcomputer science
1st workshop on diffusion networks and cascade analytics,Peng Cui (Tsinghua University)Fei Wang (IBM)Hanghang Tong (City University of New York)Manuel Gomez Rodriguez (Max Planck Society),"2684699003,2465953593,2650474510,2421855118","Diffusion and cascades have been studied for many years in sociology, and different theoretical models have been developed. However, experimental validation has been always carried out in relatively small datasets. In recent years, with the availability of large-scale network and cascade data, research on cascading and diffusion phenomena has aroused considerable interests from various fields in computer science. One of the main goals is to discover different propagation patterns from historical cascade data. In this context, understanding the mechanisms underlying diffusion in both micro- and macro-scale levels and further develop predictive model of diffusion are fundamental problems of crucial importance.",2014,Web Search and Data Mining,Fields of study: data scienceartificial intelligencesimulationcomputer science
Distributed Graph Algorithmics: Theory and Practice,Silvio Lattanzi (Google)Vahab S. Mirrokni (Google),"1989808900,2331823467","As a fundamental tool in modeling and analyzing social, and information networks, large-scale graph mining is an important component of any tool set for big data analysis. Processing graphs with hundreds of billions of edges is only possible via developing distributed algorithms under distributed graph mining frameworks such as MapReduce, Pregel, Gigraph, and alike. For these distributed algorithms to work well in practice, we need to take into account several metrics such as the number of rounds of computation and the communication complexity of each round. For example, given the popularity and ease-of-use of MapReduce framework, developing practical algorithms with good theoretical guarantees for basic graph algorithms is a problem of great importance. In this tutorial, we first discuss how to design and implement algorithms based on traditional MapReduce architecture. In this regard, we discuss various basic graph theoretic problems such as computing connected components, maximum matching, MST, counting triangle and overlapping or balanced clustering. We discuss a computation model for MapReduce and describe the sampling, filtering, local random walk, and core-set techniques to develop efficient algorithms in this framework. At the end, we explore the possibility of employing other distributed graph processing frameworks. In particular, we study the effect of augmenting MapReduce with a distributed hash table (DHT) service and also discuss the use of a new graph processing framework called ASYMP based on asynchronous message-passing method. In particular, we will show that using ASyMP, one can improve the CPU usage, and achieve significantly improved running time.",2015,Web Search and Data Mining,Fields of study: graphtheoretical computer scienceworld wide webdistributed computingdata miningmachine learningcomputer science
Understanding Diffusion Processes: Inference and Theory,Xinran He (University of Southern California),2096901250,"With increasing popularity of social media and social networks sites, analyzing the social networks offers great potential to shed light on human social structure and provides great marketing opportunities. Usually, social network analysis starts with extracting or learning the social network and the associated parameters. Contrary to other analytical tasks, this step is highly non-trivial due to amorphous nature of social ties and the challenges of noisy and incomplete observations. My research focuses on improving accuracy in inferring the network as well as analyzing the consequences when the extracted network is noisy or erroneous. To be more precise, I propose to study the following two questions with a special focus on analyzing diffusion behaviors: (1) How to utilize special properties of social networks to improve accuracy of the extracted network under noisy and missing data; (2) How to characterize the impact of noise in the inferred network and carry out robust analysis and optimization.",2016,Web Search and Data Mining,Fields of study: organizational network analysisdynamic network analysisnetwork sciencenetwork formationsocial network analysisnetwork simulationdiffusion processdata miningmachine learningstatisticscomputer science
Materializing multi-relational databases from the web using taxonomic queries,"Matthew Michelson (University of Southern California)Sofus A. Macskassy (Rutgers University)Steven N. Minton (Information Sciences Institute)Lise Getoor (University of Maryland, College Park)","2128498655,279168326,2122533181,1984940772","Recently, much attention has been given to extracting tables from Web data. In this problem, the column definitions and tuples (such as what ""company"" is headquartered in what ""city,"") are extracted from Web text, structured Web data such as lists, or results of querying the deep Web, creating the table of interest. In this paper, we examine the problem of extracting and discovering multiple tables in a given domain, generating a truly multi-relational database as output. Beyond discovering the relations that define single tables, our approach discovers and leverages ""within column"" set membership relations, and discovers relations across the extracted tables (e.g., joins). By leveraging within-column relations our method can extract table instances that are ambiguous or rare, and by discovering joins, our method generates truly multi-relational output. Further, our approach uses taxonomic queries to bootstrap the extraction, rather than the more traditional ""seed instances."" Creating seeds often requires more domain knowledge than taxonomic queries, and previous work has shown that extraction methods may be sensitive to which input seeds they are given. We test our approach on two real world domains: NBA basketball and cancer information. Our results demonstrate that our approach generates databases of relevant tables from disparate Web information, and discovers the relations between them. Further, we show that by leveraging the ""within column"" relation our approach can identify a significant number of relevant tuples that would be difficult to do so otherwise.",2011,Web Search and Data Mining,Fields of study: relational databasedeep webworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
2nd international workshop on diversity in document retrieval (DDR 2012),Craig Macdonald (University of Glasgow)Jun Wang 0012 (University College London)Charles L. A. Clarke (University of Waterloo),"2148910894,2557836567,2098618034","When an ambiguous query is received, a sensible approach is for the information retrieval (IR) system to diversify the results retrieved for this query, in the hope that at least one of the interpretations of the query intent will satisfy the user. Diversity is an increasingly important topic, of interest to both academic researchers (such as participants in the TREC Web and Blog track diversity tasks, or the NTCIR INTENT task), as well as to search engines professionals. In the 2nd edition of the Diversity in Document Retrieval workshop (DDR 2012), we solicited submissions both on approaches and models for diversity, the evaluation of diverse search results, and on applications of diverse search results. This workshop builds upon a successful 1st edition of DDR which was held at ECIR 2011 in Dublin, Ireland.",2012,Web Search and Data Mining,Fields of study: human computer information retrievalconcept searchweb search queryquery expansionsearch enginesatisfiabilitydocument retrievalworld wide webinformation retrievaldata miningcomputer science
Semantic-aware Query Processing for Activity Trajectories,Huiwen Liu (Soochow University)Jiajie Xu (Soochow University)Kai Zheng (Soochow University)Chengfei Liu (Swinburne University of Technology)Lan Du (Monash University)Xian Wu (Soochow University),"2609685881,2124260618,2638596557,2144108974,2669369480,2689796184","Nowadays, users of social networks like tweets and weibo have generated massive geo-tagged records, and these records reveal their activities in the physical world together with spatio-temporal dynamics. Existing trajectory data management studies mainly focus on analyzing the spatio-temporal properties of trajectories, while leaving the understanding of their activities largely untouched. In this paper, we incorporate the semantic analysis of the activity information embedded in trajectories into query modelling and processing, with the aim of providing end users more accurate and meaningful trip recommendations. To this end, we propose a novel trajectory query that not only considers the spatio-temporal closeness but also, more importantly, leverages probabilistic topic modelling to capture the semantic relevance of the activities between data and query. To support efficient query processing, we design a novel hybrid index structure, namely ST-tree, to organize the trajectory points hierarchically, which enables us to prune the search space in spatial and topic dimensions simultaneously. The experimental results on real datasets demonstrate the efficiency and scalability of the proposed index structure and search algorithms.",2017,Web Search and Data Mining,Fields of study: sargableweb query classificationquery expansionquery optimizationworld wide webinformation retrievaldata miningdatabasecomputer science
Strategy in action: analyzing online search behavior bymining search strategies,Chathra Hendahewa (Rutgers University),1971503322,"Analyzing people's Web search behavior has been a significant topic of interest in the Information Retrieval domain and search engine industry over the past decade. Research in this area has focused on improving search and retrieval capabilities leading to high demands and expectations of Web search users. Understanding and analyzing the Web search process when users are performing Web search tasks is a challenging problem due to many reasons such as subjectivity, dynamic nature, difficulty in measurement of success and difficulty in evaluation. I propose to analyze the users' Web search behavior in order to identify the strategies and tactics they use in fulfilling their task. In order to achieve this, I intend to use data mining and machine learning methods with an emphasis on time series analysis given that the user search process can be considered as a sequence of time related events.",2014,Web Search and Data Mining,Fields of study: search analyticshuman computer information retrievalweb modelingconcept searchweb query classificationspamdexingsearch engine indexingsearch enginetime seriessemantic searchmetasearch engineworld wide webinformation retrievaldata miningcomputer science
Workshop on Scholarly Web Mining (SWM 2017),Robert M. Patton (Oak Ridge National Laboratory)Thomas E. Potok (Oak Ridge National Laboratory)Petr Knoth (Open University)Drahomira Herrmannova (Open University),"2070538502,92205643,2146652743,1964662896",-,2017,Web Search and Data Mining,Fields of study: web intelligenceweb miningworld wide webinformation retrievaldatabasecomputer science
Beyond Query Logs: Recommendation and Evaluation,Matthew Ryan Mitsui (Rutgers University),2226264982,"Query recommendation in Web search is typically manifested in algorithms that 1) recommend previously issued queries from a query log or 2) make incremental changes to queries in a user's current session. While such approaches have been effective in improving retrieval, they either are limited to suggesting queries in a query log or fail to make appropriate leaps that are necessary for query recommendation. More crucially, these approaches only recommend queries that are a coarse approximation of the information a user needs to complete their goal. They do not directly attempt to model the need and generate recommendations from it. This work will propose a framework for generating novel yet focused queries for query recommendation.",2017,Web Search and Data Mining,Fields of study: sargablerankingrange queryrdf query languageonline aggregationweb search queryweb query classificationspatial queryquery expansionquery optimizationquery languageworld wide webinformation retrievaldata miningcomputer science
Learning Parametric Models for Context-Aware Query Auto-Completion via Hawkes Processes,Liangda Li (Yahoo!)Hongbo Deng (Google)Jianhui Chen (Yahoo!)Yi Chang (Huawei),"2148021991,2682826105,2486916609,2168000538","Query auto completion (QAC) is a prominent feature in modern search engines. High quality QAC substantially improves search experiences by helping users in typing less while submitting the queries. Many studies have been proposed to improve quality and relevance of the QAC methods from different perspectives, including leveraging contexts in long term and short term query histories, investigating the temporal information for time-sensitive QAC, and analyzing user behaviors. Although these studies have shown the context, temporal, and user behavior data carry valuable information, most existing QAC approaches do not fully exploit or even completely ignore these information. We propose a novel Hawkes process based QAC algorithm, comprehensively taking into account the context, temporal, and position of the clicked recommended query completions (a type of user behavior data), for reliable query completion prediction. Our understanding of ranking query completions is consistent with the mathematical rationale of Hawke process; such a coincidence in turn validates our motivation of using Hawkes process for QAC. We also develop an efficient inference algorithm to compute the optimal solutions of the proposed QAC algorithm. The proposed method is evaluated on two real-world benchmark data in comparison with state-of-art methods, and the obtained experiments clearly demonstrate their effectiveness.",2017,Web Search and Data Mining,Fields of study: contextual designdata scienceworld wide webinformation retrievaldata miningdatabasemachine learningstatisticscomputer science
On the quest of discovering cultural trails in social media,Ruth Olimpia Garcia Gavilanes (Pompeu Fabra University),2568228774,"With the constant increasing reach of the Web and in particular of Social Media, people create and share content that harbors information about habits, norms, preferences and values. Consequently, studying how culture influences users in online social media has increased the interest of several sectors such as the advertising industry, search engines and corporations. As a consequence, anthropological and computational models need to interact and complement each other to better target these new demands. Recently, several studies have analyzed culture from large-scale data but not many took into consideration the cultural models proposed by anthropological theory. By carrying out several experiments on large-scale data from the Web, we propose to combine theoretical concepts of culture with information technology techniques to process, analyze, model and interpret data from the Web. We plan to discover synergies between traditional social studies of culture and those derived from our experiments.",2013,Web Search and Data Mining,Fields of study: social mediasocial networkcultural economicssentiment analysisworld wide websocial sciencedata miningcomputer science
E-commerce Product Recommendation by Personalized Promotion and Total Surplus Maximization,"Qi Zhao (University of California, Santa Cruz)",2645093691,"Existing recommendation algorithms treat recommendation problem as rating prediction and the recommendation quality is measured by RMSE or other similar metrics. However, we argued that when it comes to E-commerce product recommendation, recommendation is more than rating prediction by realizing the fact price plays a critical role in recommendation result. In this work, we propose to build E-commerce product recommender systems based on fundamental economic notions. We first proposed an incentive compatible method that can effectively elicit consumer's willingness-to-pay in a typical E-commerce setting and in a further step, we formalize the recommendation problem as maximizing total surplus. We validated the proposed WTP elicitation algorithm through crowd sourcing and the results demonstrated that the proposed approach can achieve higher seller profit by personalizing promotion. We also proposed a total surplus maximization (TSM) based recommendation framework. We specified TSM by three of the most representative settings - e-commerce where the product quantity can be viewed as infinity, P2P lending where the resource is bounded and freelancer marketing where the resource (job) can be assigned to one freelancer. The experimental results of the corresponding datasets shows that TSM exceeds existing approach in terms of total surplus.",2016,Web Search and Data Mining,Fields of study: e commerceworld wide webdata miningcomputer science
Optimizing merchant revenue with rebates,Rakesh Agrawal (Microsoft)Samuel Ieong (Microsoft)Raja Velu (Syracuse University),"2537924216,2267310192,2112285161","We study an online advertising model in which the merchant reimburses a portion of the transacted amount to the customer in a form of rebate. The customer referral and the rebate transfer might be mediated by a search engine. We investigate how the merchants can set rebate rates across different products to maximize their revenue. We consider two widely used demand models in economics---linear and log-linear---and explain how the effects of rebates can be incorporated in these models. Treating the parameters estimated as inputs to a revenue maximization problem, we develop convex optimization formulations of the problem and combinatorial algorithms for solving them. We validate our modeling assumptions using real transaction data. We conduct an extensive simulation study to evaluate the performance of our approach on maximizing revenue, and found that it generates significantly higher revenues for merchants compared to other rebate strategies. The rebate rates selected are extremely close to the optimal rates selected in hindsight.",2011,Web Search and Data Mining,Fields of study: transaction datasearch engineestimation theoryonline advertisingworld wide webcomputer science
1st International Workshop on Search and Mining Terrorist Online Content & Advances in Data Science for Cyber Security and Risk on the Web,Theodora Tsikrika (College of Western Idaho)Babak Akhgar (Sheffield Hallam University)Vasilis Katos (Bournemouth University)Stefanos Vrochidis (Information Technology Institute)Pete Burnap (Cardiff University)Matthew L. Williams (Cardiff University),"1906782994,1876602472,2687934997,1240892430,2082340395,2178033187","The deliberate misuse of technical infrastructure (including the Web and social media) for cyber deviant and cybercriminal behaviour, ranging from the spreading of extremist and terrorism-related material to online fraud and cyber security attacks, is on the rise. This workshop aims to better understand such phenomena and develop methods for tackling them in an effective and efficient manner. The workshop brings together interdisciplinary researchers and experts in Web search, security informatics, social media analysis, machine learning, and digital forensics, with particular interests in cyber security. The workshop programme includes refereed papers, invited talks and a panel discussion for better understanding the current landscape, as well as the future of data mining for detecting cyber deviance.",2017,Web Search and Data Mining,Fields of study: internet privacyworld wide webcomputer securitydata miningcomputer science
Detecting and Characterizing Eating-Disorder Communities on Social Media,Tao Wang (University of Southampton)Markus Brede (University of Southampton)Antonella Ianni (University of Southampton)Emmanouil Mentzakis (University of Southampton),"2667351675,2140342150,2003505738,1809609881","Eating disorders are complex mental disorders and responsible for the highest mortality rate among mental illnesses. Recent studies reveal that user-generated content on social media provides useful information in understanding these disorders. Most previous studies focus on studying communities of people who discuss eating disorders on social media, while few studies have explored community structures and interactions among individuals who suffer from this disease over social media. In this paper, we first develop a snowball sampling method to automatically gather individuals who self-identify as eating disordered in their profile descriptions, as well as their social network connections with one another on Twitter. Then, we verify the effectiveness of our sampling method by: 1. quantifying differences between the sampled eating disordered users and two sets of reference data collected for non-disordered users in social status, behavioral patterns and psychometric properties; 2. building predictive models to classify eating disordered and non-disordered users. Finally, leveraging the data of social connections between eating disordered individuals on Twitter, we present the first homophily study among eating-disorder communities on social media. Our findings shed new light on how an eating-disorder community develops on social media.",2017,Web Search and Data Mining,Fields of study: social medianetwork analysismental healthtext miningworld wide webcomputer science
Publication Date Prediction through Reverse Engineering of the Web,Liudmila Ostroumova Prokhorenkova (Yandex)Petr Prokhorenkov (Yandex)Egor Samosvat (Yandex)Pavel Serdyukov (Yandex),"824616043,2343798077,1805976719,2130450538","In this paper, we focus on one of the most challenging tasks in temporal information retrieval: detection of a web page publication date. The natural approach to this problem is to find the publication date in the HTML body of a page. However, there are two fundamental problems with this approach. First, not all web pages contain the publication dates in their texts. Second, it is hard to distinguish the publication date among all the dates found in the page's text. The approach we suggest in this paper supplements methods of date extraction from the page's text with novel link-based methods of dating. Some of our link-based methods are based on a probabilistic model of the Web graph structure evolution, which relies on the publication dates of web pages as on its parameters. We use this model to estimate the publication dates of web pages: based only on the link structure currently observed, we perform a ``reverse engineering'' to reveal the whole process of the Web's evolution.",2016,Web Search and Data Mining,Fields of study: web pageworld wide webinformation retrievaldata miningcomputer science
Neural Survival Recommender,How Jing (LinkedIn)Alexander J. Smola (Amazon.com),"2592724704,2593672690","The ability to predict future user activity is invaluable when it comes to content recommendation and personalization. For instance, knowing when users will return to an online music service and what they will listen to increases user satisfaction and therefore user retention. We present a model based on Long-Short Term Memory to estimate when a user will return to a site and what their future listening behavior will be. In doing so, we aim to solve the problem of Just-In-Time recommendation, that is, to recommend the right items at the right time. We use tools from survival analysis for return time prediction and exponential families for future activity analysis. We show that the resulting multitask problem can be solved accurately, when applied to two real-world datasets.",2017,Web Search and Data Mining,Fields of study: behavioral modelingsurvival analysisartificial neural networkworld wide webdata miningartificial intelligencemachine learningstatisticscomputer science
Proceedings of the 7th ACM international conference on Web search and data mining,Ben Carterette (University of Delaware)Fernando Diaz (Microsoft)Carlos Castillo (Qatar Computing Research Institute)Donald Metzler (Google),"2645247999,2159093489,2479708560,2682520147","It is our great pleasure to welcome you to the Seventh ACM International Conference on Web Search and Data Mining (WSDM 2014) held on February 24--28, 2014 in New York City, New York, USA. As with previous installments, WSDM attracted many high quality submissions covering a broad spectrum of Web search and data mining topics. WSDM continues be a leading forum for reporting the latest research developments in the field. We are delighted to present here the proceedings of the conference. We received a total of 355 submissions from a diverse group of 44 countries and regions, of which 64 were accepted for full paper publication in the proceedings, thus achieving an acceptance rate of 18%. The accepted papers are from 20 different countries and represent a nice mix of academic and industrial research, making this a truly international and diverse forum. Some of the most popular research topics this year include Web search, computational advertising, recommender systems, and social networks. As in the past, WSDM 2014 continues to be a single track conference. To accommodate this, 19 papers were chosen to be presented as long presentations, while the remaining 45 will be presented as short presentations. As in the past, all authors of accepted papers were afforded the opportunity to present a poster during the poster session. There were many remarkable papers submitted to the conference. We chose 10 of the most exceptional papers as Best Paper Award candidates.",2014,Web Search and Data Mining,Fields of study: operations researchworld wide webcomputer science
"Mining, searching and exploiting collaboratively generated content on the web",Eugene Agichtein (Emory University)Evgeniy Gabrilovich (Yahoo!),"2283615530,1804802447","Proliferation of ubiquitous access to the Internet enables millions of Web users to collaborate online on a variety of activities. Many of these activities result in the construction of large repositories of knowledge, either as their primary aim (e.g., Wikipedia) or as a by-product (e.g., Yahoo! Answers). In this tutorial, we will discuss organizing and exploiting Collaboratively Generated Content (CGC) for information organization and retrieval. Specifically, we intend to cover two complementary areas of the problem: (1) using such content as a powerful enabling resource for knowledge-enriched, intelligent representations and new information retrieval algorithms, and (2) development of supporting technologies for extracting, filtering, and organizing collaboratively created content. The unprecedented amounts of information in CGC enable new, knowledge-rich approaches to information access, which are significantly more powerful than the conventional word-based methods. Considerable progress has been made in this direction over the last few years. Examples include explicit manipulation of human-defined concepts and their use to augment the bag of words (cf. Explicit Semantic Analysis), using large-scale taxonomies of topics from Wikipedia or the Open Directory Project to construct additional class-based features, or using Wikipedia for better word sense disambiguation. However, the quality and comprehensiveness of collaboratively created content vary significantly, and in order for this resource to be useful, a significant amount of preprocessing, filtering, and organization is necessary. Consequently, new methods for analyzing CGC and corresponding user interactions are required to effectively harness the resulting knowledge. Thus, not only the content repositories can be used to improve IR methods, but the reverse pollination is also possible, as better information extraction methods can be used for automatically collecting more knowledge, or verifying the contributed content. This natural connection between modeling the generation process of CGC and effectively using the accumulated knowledge suggests covering both areas together in a single tutorial. The intended audience of the tutorial includes IR researchers and graduate students, who would like to learn about the recent advances and research opportunities in working with collaboratively generated content. The emphasis of the tutorial is on comparing the existing approaches and presenting practical techniques that IR practitioners can use in their research. We also cover open research challenges, as well as survey available resources (software tools and data) for getting started in this research field.",2012,Web Search and Data Mining,Fields of study: explicit semantic analysisbag of words modelinformation extractionnatural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning from User Interactions in Personal Search via Attribute Parameterization,Michael Bendersky (Google)Xuanhui Wang (Google)Donald Metzler (Google)Marc Najork (Google),"2345232400,2487513008,2682520147,2477457921","User interaction data (e.g., click data) has proven to be a powerful signal for learning-to-rank models in web search. However, such models require observing multiple interactions across many users for the same query-document pair to achieve statistically meaningful gains. Therefore, utilizing user interaction data for improving search over personal, rather than public, content is a challenging problem. First, the documents (e.g., emails or private files) are not shared across users. Second, user search queries are of personal nature (e.g., ""alice's address"") and may not generalize well across users. In this paper, we propose a solution to these challenges, by projecting user queries and documents into a multi-dimensional space of fine-grained and semantically coherent attributes. We then introduce a novel parameterization technique to overcome sparsity in the multi-dimensional attribute space. Attribute parameterization enables effective usage of cross-user interactions for improving personal search quality -- which is a first such published result, to the best of our knowledge. Experiments with a dataset derived from interactions of users of one of the world's largest personal search engines demonstrate the effectiveness of the proposed attribute parameterization technique.",2017,Web Search and Data Mining,Fields of study: world wide webinformation retrievaldata miningcomputer science
An Approach to the Problem of Annotation of Research Publications,Ekaterina Chernyak (Health and Safety Executive),2681643628,"An approach to multiple labelling research papers is explored. We develop techniques for annotating/labeling research papers in informatics and computer sciences with key phrases taken from the ACM Computing Classification System. The techniques utilize a phrase-to-text relevance measure so that only those phrases that are most relevant go to the annotation. Three phrase-to-text relevance measures are experimentally compared in this setting. The measures are: (a) cosine relevance score between conventional vector space representations of the texts coded with tf-idf weighting; (b) popular characteristic of probability of term generation BM25; and (c) an in-house characteristic of conditional probability of symbols averaged over matching fragments in suffix trees representing texts and phrases, CPAMF. In an experiment conducted over a set of texts published in journals of the ACM and manually annotated by their authors, CPAMF outperforms both the cosine measure and BM25 by a wide margin.",2015,Web Search and Data Mining,Fields of study: natural language processingworld wide webinformation retrievaldata miningmachine learningcomputer science
German Typographers vs. German Grammar: Decomposition of Wikipedia Category Labels into Attribute-Value Pairs,Marius Paşca (Google),1892622091,"Given an instance (Julieta Pinto), most methods for open-domain information extraction focus on acquiring knowledge in the form of either class labels (Costa Rican short story writers, Women novelists) referring to concepts to which the instance belongs; or facts (nationality: Costa Rica) connecting the instance (Julieta Pinto) to other instances or concepts (Costa Rica), where the fact and the other instance often take the form of an attribute (nationality) and a value (Costa Rica) respectively. From extraction through internal representation and storage, class labels and facts are treated as if they carved out disconnected slices within the larger space of factual knowledge. This paper argues that class labels and facts pertaining to an instance exist in symbiosis rather than as a dichotomy. A constituent (Costa Rican) within a class label (Costa Rican short story writers) of an instance may be indicative of a fact (nationality: Costa Rica) applicable to the instance and vice-versa. As an illustration of the relationship between class labels and facts, the paper introduces an open-domain method for the better understanding of the semantics of class labels in one of the larger and most widely-used repositories of knowledge, namely the categories in the Wikipedia category network. The method exploits the category network to associate constituents (Costa Rican) within names of Wikipedia categories, with attributes (nationality) that explain their role.",2017,Web Search and Data Mining,Fields of study: data miningartificial intelligencealgorithmcomputer science
Proceedings of the Second ACM International Conference on Web Search and Data Mining,Ricardo Baeza-Yates (Yahoo!)Paolo Boldi (University of Milan)Berthier Ribeiro-Neto (Google)B. Barla Cambazoglu (Yahoo!),"528588921,252564519,293896549,2044137649","WSDM (pronounced ""wisdom"") is a young ACM conference intended to be the publication venue for research in the areas of Web search and data mining. Indeed, the importance of these topics and their pace of innovation prevent proper coverage by conferences of broader scope, as shown in the first edition held last February in Stanford, USA, which attracted more people than we expected. The need for this new conference was also recognized by the sponsorship of four ACM SIGs: SIGIR, SIGKDD, SIGMOD and SIGWEB, which have also allowed to have the content of the conference freely available in the Web for the first three years. This trend continued this year across the Atlantic, in Barcelona, one of the most visited European cities. Barcelona, the capital of the autonomous community of Catalonia, is well known for its history, architecture and culture. However, recently it has also developed a technological neighborhood, 22@, where the conference venue is located. Providing users with appropriate and relevant search results is a challenging task. Not only the interests and preferences of people change over time, but they also vary drastically from user to user; what is relevant and significant to a user might appear uninteresting and even offensive to another user. Further, Web pages change constantly and spamming becomes more dynamic and complex by the day. To cope with these challenges, search engines need to evolve to provide for personalized, context-sensitive, adaptive search, which uses information explicitly or implicitly offered by the user to improve results. Often, such systems will have to exploit classification techniques and to analyze data extracted from Web documents and/or from query logs to improve precision or to diversify search results. Plain and simple, search is hard! This time we received 170 papers from all around the world, and 29 of them were selected (17% acceptance ratio). The varied set of challenging problems in Web search and the key role that technologies like data mining and classification play in the solutions can be appreciated in the program of this second WSDM conference. It provides a fresh snapshot of the state-of-art in Web search; one that is broad, deep, and challenging to all those interested in research on this fascinating area of technology.",2009,Web Search and Data Mining,Fields of study: web query classificationmultimediaworld wide webinformation retrievaldata miningcomputer science
"Proceedings of the Second International Conference on Web Search and Web Data Mining, WSDM 2009, Barcelona, Spain, February 9-11, 2009",Ricardo A. Baeza-yates (Yahoo!)Paolo Boldi (University of Milan)Berthier A. Ribeiro-neto (Universidade Federal de Minas Gerais)Berkant Barla Cambazoglu (Yahoo!),"528588921,252564519,293896549,2044137649",-,2009,Web Search and Data Mining,Fields of study: web miningdata scienceworld wide webdata miningcomputer science
HIA'15: Heterogeneous Information Access Workshop at WSDM 2015,Ke Zhou (Yahoo!)Roger Jie Luo (Yahoo!)Djoerd Hiemstra (University of Twente)Joemon M. Jose (University of Glasgow),"2308026972,2226359548,2125867230,2167481407","The HIA'15 workshop aims to bring together information retrieval practitioners from industry and academic researchers concerned with heterogeneous information access and search federation. We would like to create a forum to encourage discussion and exchange of ideas on heterogeneous information access in different contexts. To facilitate the discussion, we encourage submissions on ideas and results from different aspects of heterogeneous information access including aggregated search, composite retrieval, personal search, structured search, etc. Another objective of the workshop is to encourage submissions with novel ideas (e.g. new applications) on heterogeneous information access and potential future directions of this area.",2015,Web Search and Data Mining,Fields of study: human computer information retrievalworld wide webinformation retrievaldata miningcomputer science
Workshop on large-scale and distributed systems for information retrieval (LSDS-IR 2013),Ismail Sengör Altingövde (Middle East Technical University)Berkant Barla Cambazoglu (Yahoo!)Craig Macdonald (University of Glasgow)Nicola Tonellotto (National Research Council),"686977125,2044137649,2148910894,1923078747","The LSDS-IR'13 workshop aims to bring together both information retrieval practitioners from industry, as well as academic researchers concerned with efficient and distributed IR systems. The workshop also welcomes contributions that propose different ways of leveraging diversity and multiplicity of resources available in distributed systems. The main goal of the workshop is to attract people from industry and academia to present and discuss ideas, problems and results in efficiency of large scale and distributed information retrieval systems, and to foster their participation to the WSDM conference.",2013,Web Search and Data Mining,Fields of study: scalabilityefficiencymanagement sciencedata scienceworld wide webinformation retrievaldata miningcomputer science
Modeling Document Networks with Tree-Averaged Copula Regularization,Yuan He (Tongji University)Cheng Wang (Tongji University)Changjun Jiang (Tongji University),"2682831565,2614286577,2103290824","Document network is a kind of intriguing dataset which provides both topical (texts) and topological (links) information. Most previous work assumes that documents closely linked with each other share common topics. However, the associations among documents are usually complex, which are not limited to the homophily (i.e., tendency to link to similar others). Actually, the heterophily (i.e., tendency to link to different others) is another pervasive phenomenon in social networks. In this paper, we introduce a new tool, called copula, to separately model the documents and links, so that different copula functions can be applied to capture different correlation patterns. In statistics, a copula is a powerful framework for explicitly modeling the dependence of random variables by separating the marginals and their correlations. Though widely used in Economics, copulas have not been paid enough attention to by researchers in machine learning field. Besides, to further capture the potential associations among the unconnected documents, we apply the tree-averaged copula instead of a single copula function. This improvement makes our model achieve better expressive power, and also more elegant in algebra. We derive efficient EM algorithms to estimate the model parameters, and evaluate the performance of our model on three different datasets. Experimental results show that our approach achieves significant improvements on both topic and link modeling compared with the current state of the art.",2017,Web Search and Data Mining,Fields of study: copulatopic modelprobabilistic latent semantic analysisworld wide webdata miningpattern recognitionmachine learningstatisticscomputer science
Adapting Information Retrieval to User Signals via Stochastic Models,Maria Maistro (University of Padua),1972856993,"To address the challenge of adapting Information Retrieval (IR) to the constantly evolving user tasks and needs and to adjust it to user interactions and preferences we develop a new model of user behavior based on Markov chains. We aim at integrating the proposed model into several aspects of IR, i.e. evaluation measures, systems and collections. Firstly, we studied IR evaluation measures and we propose a theoretical framework to describe their properties. Then, we presented a new family of evaluation measures, called Markov Precision (MP), based on the proposed model and able to explicitly link lab-style and on-line evaluation metrics. Future work will include the presented model into Learning to Rank (LtR) algorithms and will define a collection for evaluation and comparison of Personalized Information Retrieval (PIR) systems.",2017,Web Search and Data Mining,Fields of study: user modelingevaluationworld wide webinformation retrievaldata miningmachine learningsimulationstatisticscomputer science
Characterizing and harnessing peer-production of information in social tagging systems,Elizeu Santos-Neto (University of British Columbia),2063457925,"Assessing the value of individual users' contributions in peer-production systems is paramount to the design of mechanisms that support collaboration and improve users' experience. For instance, to incentivize contributions, file sharing systems based on the BitTorrent protocol equate value with volume of contributed content and use a prioritization mechanism to reward users who contribute more. This approach and similar techniques used in resource sharing systems rely on the fact that the physical resources shared among users are easily quantifiable. In contrast, information-sharing systems, like social tagging systems, lack the notion of a physical resource unit (e.g., content size, bandwidth) that facilitates the task of evaluating user contributions. For this reason, the issue of estimating the value of user contributions in information sharing systems remains largely unexplored. This paper outlines a research project to tackle the problem of assessing the value of contributions in social tagging systems.",2012,Web Search and Data Mining,Fields of study: many to manybittorrentfile sharingvalue of informationsocial systemproduction systemshared resourcesocialsystemknowledge managementworld wide webdata miningcomputer science
Unsupervised Ranking using Graph Structures and Node Attributes,Chin-Chi Hsu (Academia Sinica)Yi-An Lai (National Taiwan University)Wen-Hao Chen (National Taiwan University)Ming-Han Feng (National Taiwan University)Shou-De Lin (National Taiwan University),"2644580650,2604487228,2585039825,2604402196,2692208725","PageRank has been the signature unsupervised ranking model for ranking node importance in a graph. One potential drawback of PageRank is that its computation depends only on input graph structures, not considering external information such as the attributes of nodes. This work proposes AttriRank, an unsupervised ranking model that considers not only graph structure but also the attributes of nodes. AttriRank is unsupervised and domain-independent, which is different from most of the existing works requiring either ground-truth labels or specific domain knowledge. Combining two reasonable assumptions about PageRank and node attributes, AttriRank transfers extra node information into a Markov chain model to obtain the ranking. We further develop approximation for AttriRank and reduce its complexity to be linear to the number of nodes or links in the graph, which makes it feasible for large network data. The experiments show that AttriRank outperforms competing models in diverse graph ranking applications.",2017,Web Search and Data Mining,Fields of study: ranking svmunsupervised learningdata miningpattern recognitionmachine learningcomputer science
Proceedings of the sixth ACM international conference on Web search and data mining,Stefano Leonardi (Sapienza University of Rome)Alessandro Panconesi (Sapienza University of Rome)Paolo Ferragina (University of Pisa)Aristides Gionis (Yahoo!),"2155997025,2193688032,531878810,737311942","We are delighted to welcome you to the sixth ACM International Conference on Web Search and Data Mining (WSDM 2013) held on February 4-8, 2013, in Rome, Italy. As in the previous years, WSDM has attracted an impressive number of submissions tackling the most recent technical challenges in Web search and data mining, with an ever-growing interest in their social aspects. Now in its sixth year, the conference has reached maturity and has become a leading forum for disseminating the latest research developments in the field. We are happy to present here the proceedings of the conference. We received a total of 387 submissions (compared to 362 of the last year) from 36 countries and regions, out of which 73 were accepted for full paper publication in the proceedings, thus reaching an acceptance rate of 18.9% (compared to 20.7% of last year and 22.3% of two years ago). The authors of the accepted papers are from 20 countries, spanning four continents - making this a truly international forum. Oral presentation slots were allocated to all papers. Yet, in order to maintain the single-track model that most attendees prefer, we preserved this year the format with ""spotlight"" type and ""plenary"" type presentations. Out of the 73 accepted papers, 40 were assigned a ""spotlight"" slot, while 33 were assigned a plenary slot. The type of slot was chosen by the Program Chairs, mostly based on whether the topic and the content of the paper were best suited for a large group presentation or for a more focused and interactive ""spotlight"" style of presentation.",2013,Web Search and Data Mining,Fields of study: multimediaoperations researchworld wide webdata miningcomputer science
Transductive Classification on Heterogeneous Information Networks with Edge Betweenness-based Normalization,Phiradet Bangcharoensap (Tokyo Institute of Technology)Tsuyoshi Murata (Tokyo Institute of Technology)Hayato Kobayashi (Yahoo!)Nobuyuki Shimizu (Yahoo!),"2544115597,2143393253,2150231234,2144851756","This paper proposes a novel method for transductive classification on heterogeneous information networks composed of multiple types of vertices. Such networks naturally represent many real-world Web data such as DBLP data (author, paper, and conference). Given a network where some vertices are labeled, the classifier aims to predict labels for the remaining vertices by propagating the labels to the entire network. In the label propagation process, many studies reduce the importance of edges connecting to a high-degree vertex. The assumption is unsatisfactory when reliability of a label of a vertex cannot be implied from its degree. On the basis of our intuition that edges bridging across communities are less trustworthy, we adapt edge betweenness to imply the importance of edges. Since directly applying the conventional edge betweenness is inefficient on heterogeneous networks, we propose two additional refinements. First, the centrality utilizes the fact that networks contain multiple types of vertices. Second, the centrality ignores flows originating from endpoints of considering edges. The experimental results on real-world datasets show our proposed method is more effective than a state-of-the-art method, GNetMine. On average, our method yields 92.79 ± 1.25% accuracy on a DBLP network even if only 1.92% of vertices are labeled. Our simple weighting scheme results in more than 5 percentage points increase in accuracy compared with GNetMine.",2016,Web Search and Data Mining,Fields of study: betweenness centralitydata miningpattern recognitionmachine learning
Proceedings of the 2008 International Conference on Web Search and Data Mining,Marc Najork (Microsoft)Andrei Broder (Yahoo!)Soumen Chakrabarti (Indian Institute of Technology Bombay),"2027155665,2637163715,2103349674","WSDM was announced at WWW 2007 in Banff in May 2007 and thereafter on several electronic bulletin boards. Abstracts were sought by 30th July and full paper submissions by the 6th August. Despite the rather short notice and tight deadlines, we received 151 submissions from around the world. With the help of the steering committee we decided on novel reviewing system and a two-tier technical program committee was formed There were 52 regular program committee members. Each paper was first reviewed by at least three regular PC members. After this phase was completed, we retained about 60 papers with the highest scores for a second round of evaluation by a senior program committee with 11 members. Each retained paper was reviewed by two senior PC members, who strove to ensure that all regular PC members had a consistent view of the contributions of the paper (although their opinions could, of course, differ quantitatively) and had written clear, well-justified and useful reviews for the authors. In many cases, the senior PCs effectively made accept/reject decisions. The final decision was made by the PC chairs who took into account all the scores and comments, novelty, technical depth, elegance, practical application, impact, and presentation. Notifications of acceptance of 24 full papers were sent out on 20th October Overall, we are pleased with the quality and mix of the papers we accepted. Most are solidly practical papers with extensive experimental evaluation while a few are of a more theoretical nature, but we believe all of them have the potential to significantly influence the practice of Web search and mining in coming years. The acceptance ratio of 24/151 = 16 percent is consistent with the leading ACM and IEEE conferences in similar or related areas. For the first ever WSDM conference, we decided to have only a single track of full-length papers and not have short papers, poster papers, or demos, although this might change over time",2008,Web Search and Data Mining,Fields of study: operations researchworld wide webdata miningcomputer science
Document selection for tiered indexing in commerce search,Debmalya Panigrahi (Microsoft)Sreenivas Gollapudi (Microsoft),"2620374017,2023254819","A search engine aims to return a set of relevant documents in response to a query, while minimizing the response time. This has led to the use of a tiered index, where the search engine maintains a small cache of documents that can serve a large fraction of queries. We give a novel algorithm for the selection of documents in a tiered index for commerce search (i.e. users searching for products on the web) that effectively exploits the superior structural characteristics of commerce search queries. This is in sharp contrast to previous approaches to tiered indexing that were aimed at general web search where queries are typically unstructured. We theoretically analyze our algorithms and give performance guarantees even in worst-case scenarios. We then complement and strengthen our theoretical claims by performing exhaustive experiments on real-world commerce search data, and show that our algorithm outperforms state-of-the-art tiered indexing techniques that were developed for general web search.",2013,Web Search and Data Mining,Fields of study: beam searchsearch engineworld wide webinformation retrievaldata miningdatabasecomputer science
Does Document Relevance Affect the Searcher's Perception of Time?,Cheng Luo (Tsinghua University)Yiqun Liu (Tsinghua University)Tetsuya Sakai (Waseda University)Ke Zhou (University of Nottingham)Fan Zhang (Tsinghua University)Xue Li (Tsinghua University)Shaoping Ma (Tsinghua University),"2579811973,2111097927,2655523027,2308026972,2699831961,2685248820,2109195263","Time plays an essential role in multiple areas of Information Retrieval (IR) studies such as search evaluation, user behavior analysis, temporal search result ranking and query understanding. Especially, in search evaluation studies, time is usually adopted as a measure to quantify users' efforts in search processes. Psychological studies have reported that the time perception of human beings can be affected by many stimuli, such as attention and motivation, which are closely related to many cognitive factors in search. Considering the fact that users' search experiences are affected by their subjective feelings of time, rather than the objective time measured by timing devices, it is necessary to look into the different factors that have impacts on search users' perception of time. In this work, we make a first step towards revealing the time perception mechanism of search users with the following contributions: (1) We establish an experimental research framework to measure the subjective perception of time while reading documents in search scenario, which originates from but is also different from traditional time perception measurements in psychological studies. (2) With the framework, we show that while users are reading result documents, document relevance has small yet visible effect on search users' perception of time. By further examining the impact of other factors, we demonstrate that the effect on relevant documents can also be influenced by individuals and tasks. (3) We conduct a preliminary experiment in which the difference between perceived time and dwell time is taken into consideration in a search evaluation task. We found that the revised framework achieved a better correlation with users' satisfaction feedbacks. This work may help us better understand the time perception mechanism of search users and provide insights in how to better incorporate time factor in search evaluation studies.",2017,Web Search and Data Mining,Fields of study: time perceptionmultimediaworld wide webinformation retrievalsimulation
WSDM Cup 2017: Vandalism Detection and Triple Scoring,Stefan Heindorf (University of Paderborn)Martin Potthast (Weimar Institute)Hannah Bast (University of Freiburg)Björn Buchhold (University of Freiburg)Elmar Haussmann (University of Freiburg),"2229693617,1678657404,1884751247,1986642271,2122394792","The WSDM Cup 2017 was a data mining challenge held in conjunction with the 10th International Conference on Web Search and Data Mining (WSDM). It addressed key challenges of knowledge bases today: quality assurance and entity search. For quality assurance, we tackle the task of vandalism detection, based on a dataset of more than 82 million user-contributed revisions of the Wikidata knowledge base, all of which annotated with regard to whether or not they are vandalism. For entity search, we tackle the task of triple scoring, using a dataset that comprises relevance scores for triples from type-like relations including occupation and country of citizenship, based on about 10,000 human relevance judgments. For reproducibility sake, participants were asked to submit their software on TIRA, a cloud-based evaluation platform, and they were incentivized to share their approaches open source.",2017,Web Search and Data Mining,Fields of study: data qualityknowledge basedata scienceworld wide webinformation retrievaldata miningcomputer science
"Diversity and novelty in web search, recommender systems and data streams",Rodrygo L.T. Santos (Universidade Federal de Minas Gerais)Pablo Castells (Autonomous University of Madrid)Ismail Sengor Altingovde (Middle East Technical University)Fazli Can (Bilkent University),"2138048039,2008802352,686977125,2135311499","This tutorial aims to provide a unifying account of current research on diversity and novelty in the domains of web search, recommender systems, and data stream processing.",2014,Web Search and Data Mining,Fields of study: relevanceredundancyworld wide webdata miningmachine learningcomputer science
"Collaborative information seeking: understanding users, systems, and content",Chirag Shah (Rutgers University),2122808819,"The course will introduce the student to theories, methodologies, and tools that focus on information retrieval/seeking in collaboration. The student will have an opportunity to learn about the social aspect of IR with a focus on collaborative information seeking (CIS) situations, systems, and evaluation techniques. Traditionally, IR is considered an individual pursuit, and not surprisingly, the majority of tools, techniques, and models developed for addressing information need, retrieval, and usage have focused on single users. The assumption of information seekers being independent and IR problem being individual has been challenged often in the recent past. This course will introduce such works to the students, with an emphasis on understanding models and systems that support collaborative search or browsing. In addition, the course will provide samples of data collected through several experiments to demonstrate various mining and analysis techniques. Specifically, the course will (1) outline the research and latest developments in the field of collaborative IR, (2) list the challenges for designing and evaluating collaborative IR systems, and (3) show how traditional single user IR models and systems could be mapped to those for CIS. This will be achieved through introduction to appropriate literature, algorithms and interfaces that facilitate CIS, and methodologies for studying and evaluating them. Thus, the course will offer a balance between theoretical and practical elements of CIS.",2012,Web Search and Data Mining,Fields of study: information needsdata collectionknowledge managementmultimediaworld wide webinformation retrievaldata miningstatisticscomputer science
Chinese-English mixed text normalization,Qi Zhang (Fudan University)Huan Chen (Fudan University)Xuanjing Huang (Fudan University),"2484821979,2490167463,2161482855","Along with the expansion of globalization, multilingualism has become a popular social phenomenon. More than one language may occur in the context of a single conversation. This phenomenon is also prevalent in China. A huge variety of informal Chinese texts contain English words, especially in emails, social media, and other user generated informal contents. Since most of the existing natural language processing algorithms were designed for processing monolingual information, mixed multilingual texts cannot be well analyzed by them. Hence, it is of critical importance to preprocess the mixed texts before applying other tasks. In this paper, we firstly analyze the phenomena of mixed usage of Chinese and English in Chinese microblogs. Then, we detail the proposed two-stage method for normalizing mixed texts. We propose to use a noisy channel approach to translate in-vocabulary words into Chinese. For better incorporating the historical information of users, we introduce a novel user aware neural network language model. For the out-of-vocabulary words (such as pronunciations, informal expressions and et al.), we propose to use a graph-based unsupervised method to categorize them. Experimental results on a manually annotated microblog dataset demonstrate the effectiveness of the proposed method. We also evaluate three natural language parsers with and without using the proposed method as the preprocessing step. From the results, we can see that the proposed method can significantly benefit other NLP tasks in processing mixed text.",2014,Web Search and Data Mining,Fields of study: natural language processingworld wide webspeech recognitioninformation retrievaldata miningmachine learningcomputer science
Generating Illustrative Snippets for Open Data on the Web,Gong Cheng (Nanjing University)Cheng Jin (Nanjing University)Wentao Ding (Nanjing University)Danyun Xu (Nanjing University)Yuzhong Qu (Nanjing University),"2123905177,2572635064,2667695168,2168478668,2106974636","To embrace the open data movement, increasingly many datasets have been published on the Web to be reused. Users, when assessing the usefulness of an unfamiliar dataset, need means to quickly inspect its contents. To satisfy the needs, we propose to automatically extract an optimal small portion from a dataset, called a snippet, to concisely illustrate the contents of the dataset. We consider the quality of a snippet from three aspects: coverage, familiarity, and cohesion, which are jointly formulated in a new combinatorial optimization problem called the maximum-weight-and-coverage connected graph problem (MwcCG). We give a constant-factor approximation algorithm for this NP-hard problem, and experiment with our solution on real-world datasets. Our quantitative analysis and user study show that our approach outperforms a baseline approach.",2017,Web Search and Data Mining,Fields of study: approximation algorithmcombinatorial optimizationdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Primum Non Nocere: Healthcare In The Digital Age,Anjali Joshi (Google),2583798975,"Internet search has become the first stop in many users' health journeys. Today, about 1 in 20 Google searches are related to healthcare. These queries span a broad range of information needs as people are looking for possible conditions related to their symptoms and are seeking to understand their diagnoses and prescribed treatments, decipher their test results, find pathways of self-care as well as connect to people with similar experiences. This talk will cover the approaches that we at Google have used to meet these diverse user needs. We will also discuss how we constructed and curated the Health Knowledge Graph, a large scale resource of highly accurate medical knowledge that powers many of our health applications. In the second part of the talk, we will show how the confluence of advances in technology enables us to revolutionize health data collection and perform it at unprecedented scale and granularity. Combined with contextual signals, anonymous aggregated user activity can be used to quantify public health phenomena and provide concerned authorities with actionable information about seasonal or situational health issues. We will conclude the talk with an outline of research directions that could enable people and organizations in personal and public health settings obtain actionable information in a timely manner. The work presented here was the product of collaboration of multiple teams at Google.",2017,Web Search and Data Mining,Fields of study: health careknowledge managementworld wide webinformation retrievaldata miningcomputer science
Machine Learning at Amazon,Ralf Herbrich (Amazon.com),2227627541,"In this talk I will give an introduction into the field of machine learning and discuss why it is a crucial technology for Amazon. Machine learning is the science of automatically extracting patterns from data in order to make automated predictions of future data. One way to differentiate machine learning tasks is by the following two factors: (1) How much noise is contained in the data? and (2) How far into the future is the prediction task? The former presents a limit to the learnability of task --- regardless which learning algorithm is used --- whereas the latter has a crucial implication on the representation of the predictions: while most tasks in search and advertising typically only forecast minutes into the future, tasks in e-commerce can require predictions up to a year into the future. The further the forecast horizon, the more important it is to take account of uncertainty in both the learning algorithm and the representation of the predictions. I will discuss which learning frameworks are best suited for the various scenarios, that is, short-term predictions with little noise vs. long-term predictions with lots of noise, and present some ideas to combine representation learning with probabilistic methods. In the second half of the talk, I will give an overview of the applications of machine learning at Amazon ranging from demand forecasting, machine translation to automation of computer vision tasks and robotics. I will also discuss the importance of tools for data scientist and share learnings on bringing machine learning algorithms into products.",2017,Web Search and Data Mining,Fields of study: online machine learningstabilityinductive transfermulti task learningerror driven learningactive learningalgorithmic learning theorycomputational learning theoryinstance based learningworld wide webinformation retrievaldata miningartificial intelligencemachine learningcomputer science
Location Influence in Location-based Social Networks,Muhammad Aamir Saleem (Aalborg University)Rohit Kumar (Université libre de Bruxelles)Toon Calders (Université libre de Bruxelles)Xike Xie (University of Science and Technology of China)Torben Bach Pedersen (Aalborg University),"2503703461,2571316870,2064105222,2605700846,2019462106","Location-based social networks (LBSN) are social networks complemented with location data such as geo-tagged activity data of its users. In this paper, we study how users of a LBSN are navigating between locations and based on this information we select the most influential locations. In contrast to existing works on influence maximization, we are not per se interested in selecting the users with the largest set of friends or the set of locations visited by the most users; instead, we introduce a notion of location influence that captures the ability of a set of locations to reach out geographically. We provide an exact on-line algorithm and a more memory-efficient but approximate variant based on the HyperLogLog sketch to maintain a data structure called Influence Oracle that allows to efficiently find a top-k set of influential locations. Experiments show that our algorithms are efficient and scalable and that our new location influence notion favors diverse sets of locations with a large geographical spread.",2017,Web Search and Data Mining,Fields of study: world wide webdata miningmachine learning
How Relevant is the Irrelevant Data: Leveraging the Tagging Data for a Learning-to-Rank Model,Noor Ifada (Queensland University of Technology)Richi Nayak (Queensland University of Technology),"1404719639,2144864747","For the task of tag-based item recommendations, the underlying tensor model faces several challenges such as high data sparsity and inferring latent factors effectively. To overcome the inherent sparsity issue of tensor models, we propose the graded-relevance interpretation scheme that leverages the tagging data effectively. Unlike the existing schemes, the graded-relevance scheme interprets the tagging data richly, differentiates the non-observed tagging data insightfully, and annotates each entry as one of the ""relevant"", ""likely relevant"", ""irrelevant"", or ""indecisive"" labels. To infer the latent factors of tensor models correctly to produce the high quality recommendation, we develop a novel learning-to-rank method, Go-Rank, that optimizes Graded Average Precision (GAP). Evaluating the proposed method on real-world datasets, we show that the proposed interpretation scheme produces a denser tensor model by revealing ""relevant"" entries from the previously assumed ""irrelevant"" entries. Optimizing GAP as the ranking metric, the quality of the recommendations generated by Go-Rank is found superior against the benchmarking methods.",2016,Web Search and Data Mining,Fields of study: information retrievaldata miningmachine learningcomputer science
"Topics, Tasks & Beyond: Learning Representations for Personalization",Rishabh Mehrotra (University College London),2257322374,"Accurate understanding of a user's interests, preferences and behaviours is possibly one of the most critical research challenges faced while developing personalized systems for behavior targeting and information access. We intend to develop comprehensive latent variable models for web search personalization which jointly models user's topical interests along with user's click based relevance preferences while at the same time taking into account user's intended search tasks along with information about other similar users. We further augment this model by incorporating topic-level relevance parameters, which, to the best of our knowledge, is the first attempt at modeling result ranking preferences at the topic level. Additionally, we intend to explore the possibility of modeling users in terms of the search tasks they perform thereby coupling users' topical interests with their search task behavior to learn user representations. Finally, we wish to evaluate the proposition of extending user representations to hierarchical structures as an alternative to existing flat representations. The evaluation of these alternative approaches for user modeling is based on their performance on a variety of tasks such as collaborative query recommendations, user cohort modeling and search result personalization. This proposal provides the motivation to pursue these research directions, summarizes key research problems being targeted, glances through potential ways of tackling these research challenges and highlights some initial results obtained.",2015,Web Search and Data Mining,Fields of study: personalizationuser modelingknowledge managementmultimediaworld wide webdata miningmachine learningcomputer science
Modeling Navigation in Information Networks,Dimitar Dimitrov (Leibniz Association),2236542687,"Navigation in an information space is a natural way to explore and discover its content. Information systems on the Web like digital encyclopedias (e.g., Wikipedia) are interested in providing good navigational support to their users. To that end, navigation models can be useful for estimating the general navigability of an information space and for understanding how users interact with it. Such models can also be applied to identify problems faced by the users during navigation and to improve user interfaces. Studying navigation on the Web is a challenging task that has a long tradition in our scientific community. Based on large studies, researchers have made significant steps towards understanding navigational user behavior on the Web identifying general usage patterns, regularities, and strategies users apply during navigation. The seminal information foraging theory has been developed suggesting that people follow links by constantly estimating their quality in terms of information value and cost associated with obtaining that value by interacting with the environment. Furthermore, models describing the network structure of the Web like the bow tie model, and the small world models have been introduced. These models contributed valuable insights towards characterizing the underlying network topology on which the users operate and the extent to which it allows efficient navigation. In the context of information networks, researchers have successfully modeled user navigation resorting to Markov chains and to decentralized search. With respect to the users' navigational behavior and their click activities to traverse a link, researchers have found a valuable source of information in the log files of Web servers. Click data has also been collected by letting humans play navigational games on Wikipedia. With this data, researchers tested different navigational hypotheses; for example, (i) if humans tend to navigate between semantically similar articles, (ii) if they experience a trade-off between following links leading towards semantically similar articles and following links leading towards possibly well-connected articles. For navigation with a particular target in mind, users are found to be greedy with respect to the next click if they are confident to be on the right path, whereas they tend to explore the information network at random if they feel insecure or lost and have no intuition about the next click. Although these research lines have advanced our understanding of navigational user behavior in information networks, for the goal of the proposed thesis-modeling navigation-related work does not address and cover the following questions: (i) What is the relationship between the user's awareness regarding the structure and the topology of the information network and the efficiency of navigation, i.e., modeled as decentralized search and (ii) How do users interact with the content to explore and discover it, i.e., are there some specific links that are especially appealing and what are their characteristics? My research focuses on modeling navigation in an information space represented as an information network. Regarding the first question, I introduce and apply partially informed decentralized search to model the extent to which a user is exposed to the network structure of the information space and can make informed decisions about her next step towards exploring the content [1]. I test different hypotheses regarding the type and the amount of network structural information used to model navigation. My results show that only a small amount of knowledge about the network structure is sufficient for efficient navigation. For the second question, I study large-scale click data from the English version of Wikipedia. I observe a focus of the users' attention towards specific links. With this part of the proposal, I want to shed light on a different aspect of navigation and concentrate on the question why some links are more successful than others. In particular, I study the relationship between the link properties and the link popularity as measured by transitional click data. To that end, I formulate navigational hypotheses based on different link features, i.e., network features, semantic features and visual features [2, 3]. The plausibility of these hypotheses is then tested using a Markov chain-based Bayesian hypothesis testing framework. Results suggest that Wikipedia users tend to select links located at the top of the page. Furthermore, users are tempted to select links leading towards the periphery of the Wikipedia network. To conclude, I believe that the won insights may have impact on system design decisions, i.e, existing guidelines for Wikipedia contributors can be adapted to better reflect the usage of the system.",2017,Web Search and Data Mining,Fields of study: turn by turn navigationbrandnavigationworld wide webinformation retrievaldata miningmachine learningsimulationcomputer science
Utilizing Knowledge Graphs in Text-centric Information Retrieval,Laura Dietz (University of New Hampshire)Alexander Kotov (Wayne State University)Edgar Meij (Bloomberg L.P.),"2343535024,2123127453,2160283388","The past decade has witnessed the emergence of several publicly available and proprietary knowledge graphs (KGs). The increasing depth and breadth of content in KGs makes them not only rich sources of structured knowledge by themselves but also valuable resources for search systems. A surge of recent developments in entity linking and retrieval methods gave rise to a new line of research that aims at utilizing KGs for text-centric retrieval applications, making this an ideal time to pause and report current findings to the community, summarizing successful approaches, and soliciting new ideas. This tutorial is the first to disseminate the progress in this emerging field to researchers and practitioners. All tutorial resources are available online at http://github.com/laura-dietz/tutorial-utilizing-kg",2017,Web Search and Data Mining,Fields of study: entity linkingdocument retrievaldata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Anticipating Information Needs Based on Check-in Activity,Jan R. Benetka (Norwegian University of Science and Technology)Krisztian Balog (University of Stavanger)Kjetil Nørvåg (Norwegian University of Science and Technology),"2584748880,2100338238,202808005","In this work we address the development of a smart personal assistant that is capable of anticipating a user's information needs based on a novel type of context: the person's activity inferred from her check-in records on a location-based social network. Our main contribution is a method that translates a check-in activity into an information need, which is in turn addressed with an appropriate information card. This task is challenging because of the large number of possible activities and related information needs, which need to be addressed in a mobile dashboard that is limited in size. Our approach considers each possible activity that might follow after the last (and already finished) activity, and selects the top information cards such that they maximize the likelihood of satisfying the user's information needs for all possible future scenarios. The proposed models also incorporate knowledge about the temporal dynamics of information needs. Using a combination of historical check-in data and manual assessments collected via crowdsourcing, we show experimentally the effectiveness of our approach.",2017,Web Search and Data Mining,Fields of study: information mappinginformation needsworld wide webinformation retrievaldata miningdatabasemachine learningcomputer science
Click Through Rate Prediction for Local Search Results,Fidel Cacheda (University of A Coruña)Nicola Barbieri (Yahoo!)Roi Blanco (University of A Coruña),"135441323,2155070167,2128286424","With the ubiquity of internet access and location services provided by smartphone devices, the volume of queries issued by users to find products and services that are located near them is rapidly increasing. Local search engines help users in this task by matching queries with a predefined geographical connotation (""local queries"") against a database of local business listings. Local search differs from traditional web-search because to correctly capture users' click behavior, the estimation of relevance between query and candidate results must be integrated with geographical signals, such as distance. The intuition is that users prefer businesses that are physically closer to them. However, this notion of closeness is likely to depend upon other factors, like the category of the business, the quality of the service provided, the density of businesses in the area of interest, etc. In this paper we perform an extensive analysis of online users' behavior and investigate the problem of estimating the click-through rate on local search (LCTR) by exploiting the combination of standard retrieval methods with a rich collection of geo and business-dependent features. We validate our approach on a large log collected from a real-world local search service. Our evaluation shows that the non-linear combination of business information, geo-local and textual relevance features leads to a significant improvements over state of the art alternative approaches based on a combination of relevance, distance and business reputation.",2017,Web Search and Data Mining,Fields of study: distanceworld wide webinformation retrievaldata miningmachine learningcomputer science
Workshop on semantic personalized information management (SPIM'13),"Till Plumbaum (Technical University of Berlin)Ernesto William De Luca (Technical University of Berlin)Aldo Gangemi (Sapienza University of Rome)Michael Hausenblas (National University of Ireland, Galway)","364026266,2207200232,2498947824,331421492","The SPIM workshop focuses especially on people that are working on the social or semantic Web, machine learning, user modeling, recommender systems, information retrieval, semantic interaction, or their combination. The goal is to bring together researchers and practitioners to initiating discussions on the different requirements and challenges coming with the social and semantic Web for personalized information retrieval systems. The workshop aims at improving the exchange of ideas between the different research communities and practitioners involved in the research on semantic personalized information management.",2013,Web Search and Data Mining,Fields of study: semantic web stacksemantic computingsocial semantic websemantic analyticssemantic gridsemantic technologysemantic integrationpersonalizationsemantic websemantic searchontologyinformation managementknowledge managementworld wide webinformation retrievalcomputer science
Feature Generation and Selection on the Heterogeneous Graph for Music Recommendation,Chun Guo (Indiana University Bloomington),2713225127,-,2016,Web Search and Data Mining,Fields of study: feature selectioninformation retrievalpattern recognitionmachine learningcomputer science
Probabilistic Social Sequential Model for Tour Recommendation,Vineeth Rakesh (Wayne State University)Niranjan Jadhav (Wayne State University)Alexander Kotov (Wayne State University)Chandan K. Reddy (Virginia Tech),"2153695164,2584830837,2123127453,2100435683","The pervasive growth of location-based services such as Foursquare and Yelp has enabled researchers to incorpo- rate better personalization into recommendation models by leveraging the geo-temporal breadcrumbs left by a plethora of travelers. In this paper, we explore Travel path recommendation, which is one of the applications of intelligent urban navigation that aims in recommending sequence of point of interest (POIs) to tourists. Currently, travelers rely on a tedious and time-consuming process of searching the web, browsing through websites such as Trip Advisor, and reading travel blogs to compile an itinerary. On the other hand, people who do not plan ahead of their trip find it extremely difficult to do this in real-time since there are no automated systems that can provide personalized itinerary for travelers. To tackle this problem, we propose a tour recommendation model that uses a probabilistic generative framework to incorporate user's categorical preference, influence from their social circle, the dynamic travel transitions (or patterns) and the popularity of venues to recommend sequence of POIs for tourists. Through comprehensive experiments over a rich dataset of travel patterns from Foursquare, we show that our model is capable of outperforming the state-of-the-art probabilistic tour recommendation model by providing contextual and meaningful recommendation for travelers.",2017,Web Search and Data Mining,Fields of study: geolocationtopic modelsocial mediarecommender systeminternet privacyworld wide webinformation retrievaldata miningmachine learningcomputer science
Mining Actionable Insights from Social Networksat WSDM 2017,Faezeh Ensan (Ferdowsi University of Mashhad)Zeinab Noorian (Ryerson University)Ebrahim Bagheri (Ryerson University),"344693850,2598211725,756122464","The first international workshop on Mining Actionable Insights from Social Networks (MAISoN'17) is to be held on February 10, 2017; co-located with the Tenth ACM International Web Search and Data Mining (WSDM) Conference in Cambridge, UK. MAISoN'17 aims at bringing together researchers and participants from different disciplines such as computer science, big data mining, machine learning, social network analysis and other related areas in order to identify challenging problems and share ideas, algorithms, and technologies for mining actionable insight from social network data. We organized a workshop program that includes the presentation of eight peer-reviewed papers and keynote talks, which foster discussions around state-of-the-art in social network mining and will hopefully lead to future collaborations and exchanges.",2017,Web Search and Data Mining,Fields of study: predictive analyticssocial network analysissocial networkweb miningdata scienceworld wide websocial sciencedata miningcomputer science
Data design for personalization: current challenges and emerging opportunities,Elizabeth F. Churchill (eBay)Atish Das Sarma (eBay),"730947879,2266878914","There are several definitions of personalization but one that relates specifically to internet technologies is the following: Personalization technology enables the dynamic insertion, customization or suggestion of content in any format that is relevant to the individual user, based on the user's implicit behavior and preferences, and explicitly given details. Personalization is central to most Internet experiences. Personalization is a data-driven process, whether the data are explicitly gathered (e.g., by asking people to fill out forms) or implicitly (e.g. through analysis of behavioral data). It is clear that designing for effective personalization poses interesting engineering and computer science challenges. However, personalization is also a user experience issue. We believe that encouraging dialogue and collaboration between data mining experts, content providers, and user-focused researchers will offer gains in the area of personalization for search and for other domains. This is increasingly the case as devices enable more forms of data to be gathered, are always on/connected and are always with users. This workshop brings researchers interested in the area of personalization to share their research, explore possibilities for collaboration, and work on defining an agenda for Data Design for Personalization.",2014,Web Search and Data Mining,Fields of study: personalizationknowledge managementmultimediaworld wide webdata miningcomputer science
Proceedings of the fourth ACM international conference on Web search and data mining,Irwin King (Chinese Academy of Sciences)Wolfgang Nejdl (Huawei)Hang Li (Google),"2635268426,2612914866,2641158309","Welcome to the Fourth ACM International Conference on Web Search and Data Mining (WSDM 2011) held on February 9-12, 2011, in Hong Kong. As the premier ACM conference in the field, WSDM 2011 offers a highly competitive forum for reporting the latest developments in websearch, social search and data mining. We are pleased to present the proceedings of the conference as its published record. Although it is only in its fourth year, WSDM has already witnessed significant growth. We received a record 372 submissions, representing a 22% increase compared to WSDM 2010. 19 Senior PC members and 134 PC members conducted reviews to the submissions. The conference accepted 83 papers (22.3% acceptance rate). Among these, 32 papers were selected for oral and poster presentations and 51 papers were selected for poster only presentations. The authors of submitted papers were from 35 countries and regions, authors of accepted papers are from 13 countries and regions. The quality of accepted papers is very high, making WSDM a first tier conference in computer science.",2011,Web Search and Data Mining,Fields of study: operations researchworld wide webcomputer science
Document Retrieval Model Through Semantic Linking,Faezeh Ensan (Ferdowsi University of Mashhad)Ebrahim Bagheri (Ryerson University),"344693850,756122464","This paper addresses the task of document retrieval based on the degree of document relatedness to the meanings of a query by presenting a semantic-enabled language model. Our model relies on the use of semantic linking systems for forming a graph representation of documents and queries, where nodes represent concepts extracted from documents and edges represent semantic relatedness between concepts. Based on this graph, our model adopts a probabilistic reasoning model for calculating the conditional probability of a query concept given values assigned to document concepts. We present an integration framework for interpolating other retrieval systems with the presented model in this paper. Our empirical experiments on a number of TREC collections show that the semantic retrieval has a synergetic impact on the results obtained through state of the art keyword-based approaches, and the consideration of semantic information obtained from entity linking on queries and documents can complement and enhance the performance of other retrieval models.",2017,Web Search and Data Mining,Fields of study: divergence from randomness modelsemantic web stacksemantic compressionsemantic computingconcept searchsemantic gridsemantic technologyexplicit semantic analysisprobabilistic latent semantic analysissemantic similaritysemantic searchdocument clusteringnatural language processinginformation retrievaldata miningcomputer science
User Modeling in Large Social Networks,Yuxiao Dong (University of Notre Dame),2157080782,"This proposal aims to harness the power of data, social, and network sciences to model user behavior in social networks. Specifically, we focus on individual users and investigate the interplay between their behavior and subsequently emergent social phenomena. Work in this proposal unveils the significant social strategies that are used by people to satisfy their social needs. We apply computational methods to address user modeling problems, including demographic inference, link recommendation, and social impact prediction. The proposed research work can be translated into applications in large social systems, such as mobile communication, online social media, and academic collaboration.",2016,Web Search and Data Mining,Fields of study: media lab europe s social robotssocial heuristicssocial learningsocial networkcomputational sociologysocial computingsocial dynamicsknowledge managementhuman computer interactionworld wide websocial sciencedata miningcomputer science
Quantifying and Bursting the Online Filter Bubble,Kiran Garimella (Aalto University),1979823234,"In this thesis, we develop methods to (i) detect and quantify the existence of filter bubbles in social media, (ii) monitor their evolution over time, and finally, (iii) devise methods to overcome the effects caused by filter bubbles. We are the first to propose an end-to-end system that solves the problem of filter bubbles completely algorithmically. We build on top of existing studies and ideas from social science with principles from graph theory to design algorithms which are language independent, domain agnostic and scalable to large number of users.",2017,Web Search and Data Mining,Fields of study: social mediapolarizationworld wide webtelecommunicationssimulationcomputer science
Is Mail The Next Frontier In Search And Data Mining,Yoelle Maarek (Yahoo!),262608878,"The nature of Web mail traffic has significantly evolved in the last two decades, and consequently the behavior of Web mail users has also changed. For instance a recent study conducted by Yahoo Labs showed that today 90% of Web mail traffic is machine-generated. This partly explains why email traffic continues to grow even if a significant amount of personal communications has moved towards social media. Most users today are receiving in their inbox important invoices, receipts, and travel itineraries, together with non-malicious junk mail such as hotel newsletters or shopping promotions that could safely ignore. This is one of the reasons that a majority of messages remain unread, and many are deleted without being read. In that sense, Web mail has become quite similar to traditional snail mail. In spite of this drastic change in nature, many mail features remain unchanged. While 70% of mail users do not define even a single folder, folders are still predominant in the left trail of many Web mail clients. Mail search results are still mostly ranked by date, which makes the retrieving of older messages extremely challenging. This is even more painful to users, as unlike in Web search, they will know when a relevant previously read message has not been returned. In this talk, I present the results of multiple large-scale studies that have been conducted at Yahoo Labs in the last few years. I highlight the inherent challenges associated with such studies, especially around privacy concerns. I will discuss the new nature of consumer Web mail, which is dominated by machine-generated messages of highly heterogeneous forms and value. I will show how the change has not been fully recognized yet by my most email clients. As an example, why should there still be a reply option associated with a message coming from a ""do-not-reply@"" address?. I will introduce some approaches for large-scale mail mining specifically tailored to machine-generated email. I will conclude by discussing possible applications and research directions.",2016,Web Search and Data Mining,Fields of study: internet privacyworld wide webdata mining
The Information Life of Social Networks,Lada A. Adamic (Facebook),2716260478,"Vast amounts of information are propagated in online social networks such as Facebook. This talk will describe several studies characterizing how information diffuses over social ties, from the growth of individual cascades to the predictability of their eventual size. It will also characterize the diffusion of specific kinds of information, including rumors, memes, and social movements.",2015,Web Search and Data Mining,Fields of study: social networkartificial intelligencecomputer science
Predicting Online Purchase Conversion for Retargeting,Jinyoung Yeo (Pohang University of Science and Technology)Sungchul Kim (Adobe Systems)Eunyee Koh (Adobe Systems)Seung-won Hwang (Yonsei University)Nedim Lipka (Adobe Systems),"2232531623,2338919860,2649183222,2168667670,2307649016","Generally 2% of shoppers make a purchase on the first visit to an online store while the other 98% enjoys only window-shopping. To bring people back to the store and close the deal, ""retargeting"" has been a vital online advertising strategy that leads to ""conversion"" of window-shoppers into buyers. As such retargeting is more effective as a focused tool, in this paper, we study the problem of identifying a conversion rate for a given product and its current customers, which is an important analytics metric for retargeting process. Compared to existing approaches using either of customer- or product-level conversion pattern, we propose a joint modeling of both level patterns based on the well-studied buying decision process. To evaluate the effectiveness of our method, we perform extensive experiments on the simulated dataset generated based on a set of real-world web logs. The evaluation results show that conversion predictions by our approach are consistently more accurate and robust than those by existing baselines in dynamic market environment.",2017,Web Search and Data Mining,Fields of study: conversion marketinge commerceworld wide webdata miningcomputer science
Extracting Search Query Patterns via the Pairwise Coupled Topic Model,Takuya Konishi (National Institute of Informatics)Takuya Ohwa (National Institute of Informatics)Sumio Fujita (Yahoo!)Kazushi Ikeda (Nara Institute of Science and Technology)Kohei Hayashi (National Institute of Informatics),"2432122319,2155813952,2098450502,2132901609,2602971880","A fundamental yet new challenge in information retrieval is the identification of patterns behind search queries. For example, the query ""NY restaurant"" and ""boston hotel"" shares the common pattern ""LOCATION SERVICE"". However, because of the diversity of real queries, existing approaches require data preprocessing by humans or specifying the target query domains, which hinders their applicability. We propose a probabilistic topic model that assumes that each term (e.g., ""NY"") has a topic (LOCATION). The key idea is that we consider topic co-occurrence in a query rather than a topic sequence, which significantly reduces computational cost yet enables us to acquire coherent topics without the preprocessing. Using two real query datasets, we demonstrate that the obtained topics are intelligible by humans, and are highly accurate in keyword prediction and query generation tasks.",2016,Web Search and Data Mining,Fields of study: rankingsargableboolean conjunctive queryweb search queryweb query classificationtopic modelspatial queryquery expansionquery optimizationquery languagedata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
Learning Sensitive Combinations of A/B Test Metrics,Eugene Kharitonov (Yandex)Alexey Drutsa (Yandex)Pavel Serdyukov (Yandex),"2115606974,2229408502,2130450538","Online search evaluation, and A/B testing in particular, is an irreplaceable tool for modern search engines. Typically, online experiments last for several days or weeks and require a considerable portion of the search traffic. This restricts their usefulness and applicability. To alleviate the need for large sample sizes in A/B experiments, several approaches were proposed. Primarily, these approaches are based on increasing the sensitivity (informally, the ability to detect changes with less observations) of the evaluation metrics. Such sensitivity improvements are achieved by applying variance reduction methods, e.g. stratification and control covariates. However, the ability to learn sensitive metric combinations that (a) agree with the ground-truth metric, and (b) are more sensitive, was not explored in the A/B testing scenario. In this work, we aim to close this gap. We formulate the problem of finding a sensitive metric combination as a data-driven machine learning problem and propose two intuitive optimization approaches to address it. Next, we perform an extensive experimental study of our proposed approaches. In our experiments, we use a dataset of 118 A/B tests performed by Yandex and study eight state-of-the-art ground-truth user engagement metrics, including Sessions per User and Absence Time. Our results suggest that a considerable sensitivity improvements over the ground-truth metrics can be achieved by using our proposed approaches.",2017,Web Search and Data Mining,Fields of study: data miningmachine learningsimulation
Nonlinear Laplacian for Digraphs and its Applications to Network Analysis,Yuichi Yoshida (National Institute of Informatics),2115019593,"In this work, we introduce a new Markov operator associated with a digraph, which we refer to as a nonlinear Laplacian. Unlike previous Laplacians for digraphs, the nonlinear Laplacian does not rely on the stationary distribution of the random walk process and is well defined on digraphs that are not strongly connected. We show that the nonlinear Laplacian has nontrivial eigenvalues and give a Cheeger-like inequality, which relates the conductance of a digraph and the smallest non-zero eigenvalue of its nonlinear Laplacian. Finally, we apply the nonlinear Laplacian to the analysis of real-world networks and obtain encouraging results.",2016,Web Search and Data Mining,Fields of study: spectral graph theorylaplacian matrixmathematical optimizationcomputer science
Social Incentive Optimization in Online Social Networks,Guangde Chen (LinkedIn)Bee-Chung Chen (LinkedIn)Deepak Agarwal (LinkedIn),"2594440170,2152441490,2116605949","Most online social networks provide a mechanism for users to broadcast messages to their personalized network through actions like shares, likes and tweets. Receiving positive feedback from the network such as likes, comments and retweets in response to such actions can provide a strong incentive for users to broadcast more often in the future. We call such feedback by the network, that influences a user to perform certain desirable future actions, social incentives. For example, after a user shares an article to her social network, receiving positive feedback such as a ''like'' from a friend can potentially encourage her to continue sharing more regularly. Typically, for every user's visit to an online social network site, good messages need to be ranked and selected by a recommender system from a large set of candidate messages (broadcasted by the user's network). In this paper, we propose a novel recommendation problem: How should we recommend messages to users to incentivize neighbors in their personal network to perform desirable actions in the future with high likelihood, without significantly hurting overall engagement for the entire system? For instance, messages could be content shared by neighbors. The goal in this case would be to encourage more content shares in the future. We call this problem social incentive optimization and study an instance of it for LinkedIn's news feed. We observe that a user who receives positive social feedback from neighbors has a higher likelihood of broadcasting more frequently. Using this observation, we develop a novel recommendation framework that incentivize users to broadcast more often, without significantly hurting overall feed engagement. We demonstrate the effectiveness of our approach through causal analysis on retrospective data and online A/B experiments.",2017,Web Search and Data Mining,Fields of study: social networkconstrained optimizationworld wide webdata miningmachine learning
"Mining Groups Stability in Ubiquitous and Social Environments: Communities, Classes and Clusters",Mark Kibanov (University of Kassel),1917062723,"Ubiquitous Computing is an emerging research area of computer science. Similarly, social network analysis and mining became very important in the last years. We aim to combine these two research areas to explore the nature of processes happening around users. The presented research focuses on exploring and analyzing different groups of persons or entities (communities, clusters and classes), their stability and semantics. An example of ubiquitous social data are social networks captured during scientific conferences using face-to-face RFID proximity tags. Another example of ubiquitous data is crowd-generated environmental sensor data. In this paper we generalize various problems connected to these and further datasets and consider them as a task for measuring group stability. Group stability can be used to improve state-of-the-art methods to analyze data. We also aim to improve the performance of different data mining algorithms, eg. by better handling of data with a skewed density distribution. We describe significant results some experiments that show how the presented approach can be applied and discuss the planned experiments.",2015,Web Search and Data Mining,Fields of study: physical computingdata scienceworld wide webdata miningcomputer science
Multi-Column Convolutional Neural Networks with Causality-Attention for Why-Question Answering,Jong-Hoon Oh (National Institute of Information and Communications Technology)Kentaro Torisawa (National Institute of Information and Communications Technology)Canasai Kruengkrai (National Institute of Information and Communications Technology)Ryu Iida (National Institute of Information and Communications Technology)Julien Kloetzer (National Institute of Information and Communications Technology),"2146659124,250133260,2192528682,2483154518,1689173617","Why-question answering (why-QA) is a task to retrieve answers (or answer passages) to why-questions (e.g., ""why are tsunamis generated?"") from a text archive. Several previously proposed methods for why-QA improved their performance by automatically recognizing causalities that are expressed with such explicit cues as ""because"" in answer passages and using the recognized causalities as a clue for finding proper answers. However, in answer passages, causalities might be implicitly expressed, (i.e., without any explicit cues): ""An earthquake suddenly displaced sea water and a tsunami was generated."" The previous works did not deal with such implicitly expressed causalities and failed to find proper answers that included the causalities. We improve why-QA based on the following two ideas. First, implicitly expressed causalities in one text might be expressed in other texts with explicit cues. If we can automatically recognize such explicitly expressed causalities from a text archive and use them to complement the implicitly expressed causalities in an answer passage, we can improve why-QA. Second, the causes of similar events tend to be described with a similar set of words (e.g., ""seismic energy"" and ""tectonic plates"" for ""the Great East Japan Earthquake"" and ""the 1906 San Francisco Earthquake""). As such, even if we cannot find in a text archive any explicitly expressed cause of an event (e.g., ""the Great East Japan Earthquake"") expressed in a question (e.g., ""Why did the Great East Japan earthquake happen?""), we might be able to identify its implicitly expressed causes with a set of words (e.g., ""tectonic plates"") that appear in the explicitly expressed cause of a similar event (e.g., ""the 1906 San Francisco Earthquake""). We implemented these two ideas in our multi-column convolutional neural networks with a novel attention mechanism, which we call causality attention. Through experiments on Japanese why-QA, we confirmed that our proposed method outperformed the state-of-the-art systems.",2017,Web Search and Data Mining,Fields of study: causalityconvolutional neural networkquestion answeringnatural language processingworld wide webdata miningartificial intelligencemachine learningcomputer science
Towards Modelling Language Innovation Acceptance in Online Social Networks,Daniel Kershaw (Lancaster University)Matthew Rowe (Lancaster University)Patrick K. Stacey (Loughborough University),"1861106821,2290134306,2134890474","Language change and innovation is constant in online and offline communication, and has led to new words entering people's lexicon and even entering modern day dictionaries, with recent additions of 'e-cig' and 'vape'. However the manual work required to identify these 'innovations' is both time consuming and subjective. In this work we demonstrate how such innovations in language can be identified across two different OSN's (Online Social Networks) through the operationalisation of known language acceptance models that incorporate relatively simple statistical tests. From grounding our work in language theory, we identified three statistical tests that can be applied - variation in; frequency, form and meaning. Each show different success rates across the two networks (Geo-bound Twitter sample and a sample of Reddit). These tests were also applied to different community levels within the two networks allowing for different innovations to be identified across different community structures over the two networks, for instance: identifying regional variation across Twitter, and variation across groupings of Subreddits, where identified example innovations included 'casualidad' and 'cym'.",2016,Web Search and Data Mining,Fields of study: natural language processingworld wide websocial sciencedata miningmachine learningcomputer science
Sponsored search auctions,Riccardo Colini-Baldeschi (Sapienza University of Rome),138651742,"Sponsored search auctions are used to allocate ad slots to advertisers. The standard mechanism for sponsored search auctions is the Generalized-Second-Price (GSP) auction. Even if GSP seems to be established, a lot of open problems remain in the area and many significant researches have been done in the recent years. My research proposal is focusing in some specific aspects of the sponsored search auctions like revenue maximization and the design of mechanisms that obtain some form of social efficiency. In this paper we start from a brief history of the sponsored search auctions and then we present the formal model. In the last two sections I will introduce the obtained results and some open problems.",2013,Web Search and Data Mining,Fields of study: algorithmic game theorymechanism designcomputer science
Modeling Air Travel Choice Behavior with Mixed Kernel Density Estimations,Zhenni Feng (Shanghai Jiao Tong University)Yanmin Zhu (Shanghai Jiao Tong University)Jian Cao (Shanghai Jiao Tong University),"2658634789,2130173690,2693487168","Understanding air travel choice behavior of air passengers is of great significance for various purposes such as travel demand prediction and trip recommendation. Existing approaches based on surveys can only provide aggregate level air travel choice behavior of passengers and they fail to provide comprehensive information for personalized services. In this paper we focus on modeling individual level air travel choice behavior of passengers, which is valuable for recommendations and personalized services. We employ a probabilistic model to represent individual level air travel choice behavior based on a large dataset of historical booking records, leveraging several key factors, such as takeoff time, arrival time, elapsed time between reservation and takeoff, price, and seat class. However, each passenger has only a limited number of historical booking records, causing a serious data sparsity problem. To this end, we propose a mixed kernel density estimation (mix-KDE) approach for each passenger with a mixture model that combines probabilistic estimation of both regularity of the individual himself and social conformity of similar passengers. The proposed model is trained and evaluated via the expectation-maximization (EM) algorithm with a huge dataset of booking records of over 10 million air passengers from a popular online travel agency in China. Experimental results demonstrate that our mix-KDE approach outperforms the Gaussian mixture model (GMM) and the simple kernel density estimation in the presence of the sparsity issue.",2017,Web Search and Data Mining,Fields of study: data miningsimulation
Investigation of User Search Behavior While Facing Heterogeneous Search Services,Xin Li (Tsinghua University)Yiqun Liu (Tsinghua University)Rongjie Cai (Tsinghua University)Shaoping Ma (Tsinghua University),"2682567659,2111097927,2583099020,2109195263","With Web users' search tasks becoming increasingly complex, a single information source cannot necessarily satisfy their information needs. Searchers may rely on heterogeneous sources to complete their tasks, such as search engines, Community Question Answering (CQA), encyclopedia sites, and crowdsourcing platforms. Previous works focus on interaction behaviors with federated search results, including how to compose a federated Web search result page and what factors affect users' interaction behavior on aggregated search interfaces. However, little is known about which factors are crucial in determining users' search outcomes while facing multiple heterogeneous search services. In this paper, we design a lab-based user study to analyze what explicit and implicit factors affect search outcomes (information gain and user satisfaction) when users have access to heterogeneous information sources. In the study, each participant can access three different kinds of search services: a general search engine (Bing), a general CQA portal (Baidu Knows), and a high-quality CQA portal (Zhihu). Using questionnaires and interaction log data, we extract explicit and implicit signals to analyze how users' search outcomes are correlated with their behaviors on different information sources. Experimental results indicate that users' search experiences on CQA portals (such as users' perceived usefulness and number of result clicks) positively affect search outcome (information gain), while search satisfaction is significantly correlated with some other factors such as users' familiarity, interest and difficulty of the task. Besides, users' search satisfaction can be more accurately predicted by the implicit factors than search outcomes.",2017,Web Search and Data Mining,Fields of study: search analyticssearch enginesemantic searchmultimediaworld wide webinformation retrievaldata miningcomputer science
Exploratory search with semantic transformations using collaborative knowledge bases,Yegin Genc (Stevens Institute of Technology),2123806240,"Sometimes we search for simple facts. Other times we search for relationships between concepts. While existing information retrieval systems work well for simple searches, they are less satisfying for complex inquiries because of the ill-structured nature of many searches and the cognitive load involved in the search process. Search can be improved by leveraging the network of concepts that are maintained by collaborative knowledge bases such as Wikipedia. By treating exploratory search inquires as networks of concepts -- and then mapping documents to these concepts, exploratory search performance can be improved. This method is applied to an exploratory search task: given a journal abstract, abstracts are ranked based their relevancy to the seed abstract. The results show comparable relevancy scores to state of the art techniques while at the same time providing better diversity.",2014,Web Search and Data Mining,Fields of study: brandsemantic searchdata scienceworld wide webinformation retrievaldata miningmachine learningcomputer science
New Probabilistic Models for Recommender Systems with Rich Contextual and Content Information,Eliezer de Souza da Silva (Norwegian University of Science and Technology),2697790534,"This project is focused on the design of probabilistic models for recommender systems and collaborative ltering by extending and creating new models to include rich contextual and content information (content, user social network, location, time, user intent, etc), and developing scalable approximate inference algorithms for these models. The working hypothesis is that big data analytics combined with probabilistic modelling, through automatically mining of various data sources and combining di erent latent factors explaining the user interaction with the items, can be used to better infer the user behaviour and generate improved recommendations. Fundamentally we are interested in the following questions: 1) Does additional contextual information improve the quality of recommender systems? 2) What factors (features, model, methods) are relevant in the design of personalized systems? 3) What is the relation between the social network structure, the user model and the information need of the user? How does the social context interferes with user preferences? How the evolution of the social network structure can explain changes in the user preference model? 4) Does the choice of approximate inference method have a signi cant impact on the quality of the system (quality- efficiency trade-offs)? To address some of this questions we started by proposing a model (Figure 1) based on Poisson factorization models [2], combining a social factorization model [1] and a topic based factorization [3]. The main idea is to combine content latent factor (topic, tags, etc) and trust between users (trust weight in a social graph) in a way that both sources of information have additive e ects in the observed ratings. In the case of Poisson models, this additive constraint will induce non-negative latent factors to be more sparse and avoid overfitting (in comparison the Gausian based models [2]. The main objective at this point is to compare models that incorporated both source of information (content and social networks). The next steps will include empirical validation. Concluding, we are interested in the interplay between large scale data mining and probabilistic modeling in the design of recommender systems. One initial approach we are pursuing is to model content and social network feature in a Poisson latent variable model. Our main objective in the future is the development of methods with competitive computational complexity to perform inference using het- erogeneous data in dynamical probabilistic models, as well as exploring the scalability limits of the models we propose.",2017,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer science
Semantic Matching in APP Search,Juchao Zhuo (Tencent)Zeqian Huang (Tencent)Yunfeng Liu (Tencent)Zhanhui Kang (Tencent)Xun Cao (Tencent)Mingzhi Li (Tencent)Long Jin (Tencent),"2296036571,2421359397,2234802897,2227302744,2230086856,2223251845,2298303156","Past years, with the growth of smart-phones and applications, APP market has become an important mobile internet portal. As an important function in application market, APP search gains lots of attentions.However, mismatch between queries and APP is the most critical problem in APP search because of less text within term matching search engine. In this talk, we describe a semantic matching architecture in APP search--which mining topics and tags in big data. It enriches query and APP representations with topics and tags to achieve semantic matching in search. Some challenge must be considered: 1) How to extract tag-APP relationship from large web text. 2) How to use machine learning technologies to process de-noising and computing confidence. 3) How to hybrid ranking apps retrieved by different matching method. These will be introduced in some of our related works and as examples to describe how semantic matching is used in Tencent MyApp, an application market which serving hundreds of millions of users.",2015,Web Search and Data Mining,Fields of study: topic modelsemantic searchworld wide webinformation retrievaldata miningmachine learningcomputer science
Welcome from the program chairs,Carlos Castillo (Qatar Computing Research Institute)Donald Metzler (Google),"2479708560,2682520147",-,2014,Web Search and Data Mining,-
Search by multiple examples,Mingzhu Zhu (New Jersey Institute of Technology)Yi-Fang Brook Wu (New Jersey Institute of Technology),"2665295803,2711644088","It is often difficult for users to adopt keywords to express their information needs. Search-By-Multiple-Examples (SBME), a promising method for overcoming this problem, allows users to specify their information needs as a set of relevant documents rather than as a set of keywords. Most of the studies on SBME adopt the Positive Unlabeled learning (PU learning) techniques by treating the users' provided examples (denote as query examples) as positive set and the entire data collection as unlabeled set. However, it is inefficient to treat the entire data collection as unlabeled set, as its size can be huge. In addition, the query examples are treated as being relevant to a single topic, but it is often the case that they can be relevant to multiple topics. As the query examples are much fewer than the unlabeled data, the system performance may downgrade dramatically because of the class imbalance problem. What's more, the experiments conducted in these studies have not taken into account the settings in online search, which are very different from the controlled experiments scenario. This proposed research seeks to explore how to improve SBME by exploring: (1) how to predict user' information needs by modeling the content of the documents using probabilistic topic models; (2) how to deal with the class imbalance problem by reducing the size of the unlabeled data and adopting machine learning techniques. We will also conduct extensive experiments to better evaluate SBME using different sizes of query examples to simulate users' information needs.",2014,Web Search and Data Mining,Fields of study: transductionworld wide webinformation retrievaldata miningmachine learningcomputer science
Temporal Formation and Evolution of Online Communities,Hossein Fani (University of New Brunswick),2229693317,"Researchers have already studied the identification of online communities and the possible impact or influence relationships from several perspectives. For instance, communities of users that are formed based on shared relationships and topological similarities, or communities that consist of users that share similar content. However, little work has been done on detection of communities that simultaneously share topical and temporal similarities. Furthermore, these studies have not explored the causation relationship between the communities. Causation provides systematic explanation as to why communities are formed and helps to predict future communities. This proposal will address two main research questions: i) how can communities that share topical and temporal similarities be identified, and ii) how can causation relation between different online communities be detected and modelled. We model users' behaviour towards topics of interest through multivariate time series to identify like-minded communities. Further, we employ Granger's concept of causality to infer causation between detected communities from corresponding users' time series. Granger causality is the prominent approach in time series modelling and rests on a firm statistical foundation. We assess the proposed community detection methods through comparison with the state of the art and verify the causal model through its prediction accuracy.",2016,Web Search and Data Mining,Fields of study: causalitydata sciencedata mining
Computational advertising: leveraging user interaction & contextual factors for improved ad relevance & targeting,"Kushal S. Dave (International Institute of Information Technology, Hyderabad)",2123673961,"Computational advertising refers to finding the most relevant ads matching a particular context on the web. The core problem attacked in computational advertising CA is of the match making between the ads and the context. My research work aims at leveraging various user interaction, ad and advertiser related information and contextual information for improving the relevance, ranking and targeting of ads. The research work focuses on the identification of various factors that contribute in retrieving and ranking the most relevant set of ads that match best with the context. Specifically, information associated with the user, publisher and advertiser is leveraged for this purpose.",2012,Web Search and Data Mining,Fields of study: viral marketingcontextual advertisingonline advertisingworld wide webinformation retrievaldata miningcomputer science
The 2nd workshop on Vertical Search Relevance at WSDM 2015,Dawei Yin (Yahoo!)Chih-Chieh Hung (Rakuten)Rui Li (Yahoo!)Yi Chang (Yahoo!),"2170531144,2607118546,2696828198,2168000538","As the web information exponentially grows and the needs of users become more specific, traditional general web search engines are not able to perfectly satisfy the nowadays user requirement. Vertical search engines have emerged in various domains, which more focus on specific segments of online content, including local, shopping, medical information, travel search, etc. Vertical search engines start attracting more attention while relevance ranking in different vertical search engines is becoming the key technology. In addition, vertical search results are often slotted into general Web search results. Hence, designing effective ranking functions for vertical search has become practically important to improve users' experience in both web search and vertical search. The workshop bring together researchers from IR, ML, NLP, and other areas of computer and information science, who are working on or interested in this area. It provides a forum for the researchers to identify the issues and the challenges, to share their latest research results, to express a diverse range of opinions about this topic, and to discuss future directions.",2015,Web Search and Data Mining,Fields of study: search analyticsrankingsearch enginesemantic searchworld wide webinformation retrievaldata miningstatisticscomputer science
Query Expansion Using Pseudo Relevance Feedback on Wikipedia,Andisheh KeykhahF Ensan (University of New Brunswick)Ebrahim Bagheri (Ryerson University),"2342343737,344693850,756122464",-,2016,Web Search and Data Mining,Fields of study: query expansionnatural language processingworld wide webinformation retrievalcomputer science
Integration of large scale knowledge bases using probabilistic graphical models,Arnab Kumar Dutta (University of Mannheim),2161075844,"Over the recent past, information extraction (IE) systems such as Nell and ReVerb have attained much success in creating large knowledge resources with minimal supervision. But, these resources in general, lack schema information and contain facts with high degree of ambiguity which are often difficult to interpret. Whereas, Wikipedia-based IE projects like DBpedia and Yago are structured, have disambiguated facts with unique identifiers and maintain a well-defined schema. In this work, we propose a probabilistic method to integrate these two types of IE projects where the structured knowledge bases benefit from the wide coverage of the semi-supervised IE projects and the latter benefits from the schema information of the former.",2014,Web Search and Data Mining,Fields of study: data integrationdata scienceknowledge managementinformation retrievaldata miningmachine learningcomputer science
TargetAd2016: 2nd International Workshop on Ad Targeting at Scale,Mihajlo Grbovic (Yahoo!)Nemanja Djuric (Yahoo!)Vladan Radosavljevic (Yahoo!),"2000240052,2128657275,1981991050","The 2nd International Workshop on Ad Targeting at Scale will be held in San Francisco, California, USA on February 22nd, 2016, co-located with the 9th ACM International Conference on Web Search and Data Mining (WSDM). The main objective of the workshop is to address the challenges of ad targeting in web-scale settings. The workshop brings together interdisciplinary researchers in computational advertising, recommender systems, personalization, and related areas, to share, exchange, learn, and develop preliminary results, new concepts, ideas, principles, and methodologies on applying data mining technologies to ad targeting. We have constructed an exciting program of eight refereed papers and several invited talks that will help us better understand the future of ad targeting.",2016,Web Search and Data Mining,Fields of study: operations researchworld wide webdata mining
Affective Computing of Image Emotion Perceptions,Sicheng Zhao (Harbin Institute of Technology),2666009726,-,2016,Web Search and Data Mining,Fields of study: supervised learningmultimediacomputer visionmachine learningcomputer science
Harnessing the Power of Data Science through Research,Andrew Blake (The Turing Institute),2584987779,"The Alan Turing Institute is the UK's newly-created national centre for data science, headquartered at the British Library in the heart of London's vibrant Knowledge Quarter. Our vision is to become a world leader in data science research and innovation. This lecture will take a whistle-stop tour through the Institute's scientific and innovation programme. It tackles challenges of social and economic importance, from engineering to finance, from health and well-being to cloud computing and smart cities. The Institute aims to make unique contributions, focussing on work that is complementary to what can be done in universities. In particular, we aim to act as a national hub, attracting a diversity of talent, interest and influence. We emphasise engineering and the ability to build high quality prototypes. We encompass, in one connected physical space, a sweep of disciplines from pure mathematics, through statistics and machine learning, to social science.",2017,Web Search and Data Mining,Fields of study: recurrent neural networkdeep learningdata scienceoperations researchworld wide websocial sciencedata miningmachine learningcomputer science
Modeling Source Code to Support Retrieval-Based Applications,Venkatesh Vinayakarao (Indraprastha Institute of Information Technology),2229336357,"Advances in text retrieval do not apply directly to source code retrieval because of the difference in characteristics of source code when compared to text. Recently, researchers have proposed specialized indexing and querying techniques that are based on structural representations and semantics of source code. Current tools and techniques heavily depend on user defined terms in source code to leverage text retrieval techniques. Further, they have limitations in handling partial programs, platform independence and index-time processing. We focus on building reusable models of source code for the purposes of indexing and querying.",2017,Web Search and Data Mining,Fields of study: kpi driven code analysisinternal documentationcodebasecode reviewstatic program analysiscode generationsource codetheoretical computer scienceworld wide webinformation retrievaldata miningdatabaseprogramming languagecomputer science
Mining Medical Causality for Diagnosis Assistance,Sendong Zhao (Harbin Institute of Technology),2107290083,"In the medical context, causal knowledge usually refers to causal relations between diseases and symptoms, living habits and diseases, symptoms which get better and therapy, drugs and side-effects, etc [3]. All these causal relations are usually in medical literature, forum and clinical cases and compose the core part of medical diagnosis. Therefore, mining these causal knowledge to predict disease and recommend therapy is of great value for assisting patients and professionals. The task of mining these causal knowledge for diagnosis assistance can be decomposed into four constitutes: (1) mining medical causality from text; (2) medical treatment effectiveness measurement; (3) disease prediction and (4) explicable medical treatment recommendation. However, these tasks have never been systemically studied before. For my PhD thesis, I plan to formally define the problem of mining medical domain causality for diagnosis assistance and propose methods to solve this problem. 1. Ming these textual causalities can be very useful for discovering new knowledge and making decisions. Many studies have been done for causal extraction from the text [1, 4, 5]. However, all these studies are based on pattern or causal triggers, which greatly limit their power to extract causality and rarely consider the frequency of co-occurrence and contextual semantic features. Besides, none of them take the transitivity rules of causality leading to reject those causalities which can be easily get by simple inference. Therefore, we formally define the task of mining causality via frequency of event co-occurrence, semantic distance between event pairs and transitivity rules of causality, and present a factor graph to combine these three resources for causality mining. 2. Treatment effectiveness analysis is usually taken as a subset of causal analysis on observational data. For such real observational data, PSM and RCM are two dominant methods. On one hand, it is usually difficult for PSM to find the matched cases due to the sparsity of symptom. On the other hand, we should check every possible (symptom, treatment) pair by exploiting RCM, leading to make the characteristic of exploding up, especially when we want to check the causal relation between a combination of symptoms and a combination of drugs. Besides, the larger number of symptom or treatment in the combination the less number of patient case retrieved, which lead to the lack of statistical significance. Specifically, patients tend to take tens of herbs as the treatment each time in Traditional Chinese Medicine (TCM). Therefore, how to evaluate the effectiveness of herbs separately and jointly is really a big challenge. This is also a very fundamental research topic supporting many downstream applications. 3. Both hospitals and on-line forums have accumulated sheer amount of records, such as clinical text data and online diagnosis Q&A pairs. The availability of such data in large volume enables automatic disease prediction. There are some papers on disease prediction with electronic health record (EHR) [2], but the research on disease prediction with raw symptoms is still necessary and challenging. Therefore, we propose a general new idea of using the rich contextual information of diseases and symptoms to bridge the gap of disease candidates and symptoms, and detach it from the specific way of implementing the idea using network embedding. 4. Recommendation in medical domain is usually a decision-making issue, which requires the ability of explaining ""why"". The ability of explaining ""why"" are basically from two paths. Consider the recommendation suggest you eat more vegetables. You probably do not believe it if there is nothing attached. But if the recommendation gives the literally reasons why eating more vegetables is good you might like to take this suggestion. Consider another scenario, if the recommendation gives you the data of the contrast which show that people who eat more vegetables are healthier than those eat less, it is certain that you also want to take this recommendation. Based on these two intuitions, we present a recommendation model based on proofs which are either literally reasons or difference from contrast. This work was supported by the 973 program (No. 2014CB340503) and the NSFC (No. 61133012 and No. 61472107).",2017,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningartificial intelligencemachine learningstatisticscomputer science
Mining Complaints to Improve a Product: a Study about Problem Phrase Extraction from User Reviews,Elena Tutubalina (Kazan Federal University),2180427792,"The rapidly growing availability of user reviews has become an important resource for companies to detect customer dissatisfaction from textual opinions. Much research in opinion mining focuses on extracting customers' opinions from products' reviews and predicting their sentiment orientation or ratings with the aim of helping other users to make a decision on whether to buy a product. However, there have been few recent studies conducted on business-related opinion tasks to extract more refined opinions about a product's quality problems or technical failures. The focus of this study is the extraction of problem phrases, mentioned in user reviews about products. We explore main opinion mining tasks to determine whether given text from reviews contains a mention of a problem. We formulate research questions and propose knowledge-based methods and probabilistic models to classify users' phrases and extract latent problem indicators, aspects and related sentiments from online reviews.",2016,Web Search and Data Mining,Fields of study: sentiment analysisdata scienceworld wide webinformation retrievaldata miningcomputer science
Chronological Scientific Information Recommendation via Supervised Dynamic Topic Modeling,Zhuoren Jiang (Dalian Maritime University),2639760218,"Scientific information recommendation is crucial to assist scholars for their researches. Citation recommendation is an important field of scientific recommendation. Traditional approaches ignore the chronological nature of the citation recommendation task. In this study, I propose the ""Chronological Citation Recommendation,"" which assumes initial user information need could shift while they are looking for the papers in different time slices. Specifically, I employed a supervised dynamic topic model to characterize the content ""time-varying"" dynamics and constructed a novel heterogeneous graph that contains dynamic topic-based information, time-decay citation information and word-based information. I applied different meta-paths for different ranking hypotheses, which carried different types of information for citation recommendation in different time slices along with information need shifting. I plan to generate the final ""Chronological Citation Recommendation"" rankings by feature integration using Learning to Rank. ""Chronological Citation Recommendation"" will recommend time-series ranking lists based on initial user textual information need. Preliminary experiments on the ACM corpus show that chronological citation recommendation will significantly improve the citation recommendation performance.",2015,Web Search and Data Mining,Fields of study: data scienceworld wide webinformation retrievaldata miningcomputer science
Boosting Search with Deep Understanding of Contents and Users,Kaihua Zhu (Baidu),2230163657,"Recent years have witnessed dramatic changes in how people interact with search engines. Search engines are expected to be more intelligent in understanding users' intention and fulfilling users' needs with direct answers rather than raw information. Furthermore, search engines are expected to be equipped with recommendation and dialogue capabilities, making the interaction with users more natural and smoother. In this talk, I will introduce Baidu's work on how to make some of them come true through the deep understanding of users, queries and web pages, and discuss challenges behind these technologies.",2015,Web Search and Data Mining,Fields of study: multimediaworld wide webinformation retrievaldata miningcomputer science
Global Optimization for Display Ad,Rong Ji,2227075942,"Online display advertisement has been examined by numerous studies. Most online display ad systems take the greedy approach, namely they display, for each user, the set of ads that match best with the user's interests. One shortcoming of the greedy approach is that it does not take into account the budget limitation of each advertiser. As a result, we often observed that some ads are popular and match with the interests of millions of users; but due to the budget restriction, these ads can only be presented by a limited times, leading to a suboptimal performance. To make our point clear, let's consider a simple case where we only have two advertisers (i.e. A and B), and two users (i.e. a and b). We assume that both advertisers have only a budget of one display. We further assume that user a is interested in both ads even though he is more interested in ad A, while user b is only interested in ad A. Now, if we take the greedy approach, we will always present ad A to user a; as a result, if user a comes before user b, we will have no appropriate ad to be displayed for user b. On the other hand, if we can take into account the budget limitation of both advertisers, a better approach is to present ad B to user a and ad A to user b. This simple example motivates us to develop the global optimization approach for online display advertisement that explicitly take into account the budget limitation of advertisers when deciding the ad presentation for individual users. The key idea of the proposed approach is to compute a user-ad assignment matrix that maximizes the number of clicks under the constraint of ad budgets from individual advertisers. The main computational challenge is the size of variable to be optimized: since the number of users and advertisements involved in our system are 1 billion and ten thousands, respectively, we need to estimate a matrix of billions times ten thousands. We address this challenge by converting the original optimization problem into its dual problem, in which the number of variables is reduced to only ten thousands. A distributed computing algorithm, based on the Nesterov's method and map-reduce framework, was developed to efficiently solve the related optimization problem. We have observed that, the proposed algorithm significantly improves the effectiveness of ad presentation compared to the greedy algorithm.",2015,Web Search and Data Mining,Fields of study: world wide webdata miningmachine learningsimulationcomputer science
The secret life of social links,Hilary Mason,2638886410,"The social web is a messy place! At bitly, we see hundreds of millions of shares and clicks per day--clicks that contain all sorts of wonderful content from lolcats to spacecraft launches. I'll discuss our philosophy, tools, and techniques for looking at the data, and new research opportunities that weren't possible before.",2012,Web Search and Data Mining,Fields of study: social webinternet privacyworld wide webcomputer science
