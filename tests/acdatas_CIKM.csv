Information Diffusion at Workplace,Jiawei Zhang (University of Illinois at Chicago);Philip S. Yu (University of Illinois at Chicago);Yuanhua Lv (Microsoft);Qianyi Zhan (Nanjing University);,"2305185572,2125104194,2132538679,2442559174","People nowadays need to spend a large amount of time on their work everyday and workplace has become an important social occasion for effective communication and information exchange among employees. Besides traditional online contacts (e.g., face-to-face meetings and telephone calls), to facilitate the communication and cooperation among employees, a new type of online social networks has been launched inside the firewalls of many companies, which are named as the ""enterprise social networks"" (ESNs). In this paper, we want to study the information diffusion among employees at workplace via both online ESNs and online contacts. This is formally defined as the IDE (Information Diffusion in Enterprise) problem. Several challenges need to be addressed in solving the IDE problem: (1) diffusion channel extraction from online ESN and online contacts; (2) effective aggregation of the information delivered via different diffusion channels; and (3) communication channel weighting and selection. A novel information diffusion model, Muse (Multi-source Multi-channel Multi-topic diffUsion SElection), is introduced in this paper to resolve these challenges. Extensive experiments conducted on real-world ESN and organizational chart dataset demonstrate the outstanding performance of Muse in addressing the IDE problem.",2016,Conference on Information and Knowledge Management,knowledge management;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Data-Driven Contextual Valence Shifter Quantification for Multi-Theme Sentiment Analysis,Hongkun Yu (University of Illinois at Urbana–Champaign);Jingbo Shang (University of Illinois at Urbana–Champaign);Meichun Hsu (HP Labs);Malu Castellanos (HP Labs);Jiawei Han (University of Illinois at Urbana–Champaign);,"2636540397,2223914299,2164671343,2148997595,2121939561","Users often write reviews on different themes involving linguistic structures with complex sentiments. The sentiment polarity of a word can be different across themes. Moreover, contextual valence shifters may change sentiment polarity depending on the contexts that they appear in. Both challenges cannot be modeled effectively and explicitly in traditional sentiment analysis. Studying both phenomena requires multi-theme sentiment analysis at the word level, which is very interesting but significantly more challenging than overall polarity classification. To simultaneously resolve the multi-theme and sentiment shifting problems, we propose a data-driven framework to enable both capabilities: (1) polarity predictions of the same word in reviews of different themes, and (2) discovery and quantification of contextual valence shifters. The framework formulates multi-theme sentiment by factorizing the review sentiments with theme/word embeddings and then derives the shifter effect learning problem as a logistic regression. The improvement of sentiment polarity classification accuracy demonstrates not only the importance of multi-theme and sentiment shifting, but also effectiveness of our framework. Human evaluations and case studies further show the success of multi-theme word sentiment predictions and automatic effect quantification of contextual valence shifters.",2016,Conference on Information and Knowledge Management,sentiment analysis;natural language processing;computer science;
FacetGist: Collective Extraction of Document Facets in Large Technical Corpora,Tarique Siddiqui (University of Illinois at Urbana–Champaign);Xiang Ren (University of Illinois at Urbana–Champaign);Aditya G. Parameswaran (University of Illinois at Urbana–Champaign);Jiawei Han 0001 (University of Illinois at Urbana–Champaign);,"2508159517,2721154984,2077695977,2121939561","Given the large volume of technical documents available, it is crucial to automatically organize and categorize these documents to be able to understand and extract value from them. Towards this end, we introduce a new research problem called Facet Extraction. Given a collection of technical documents, the goal of Facet Extraction is to automatically label each document with a set of concepts for the key facets (e.g., application, technique, evaluation metrics, and dataset) that people may be interested in. Facet Extraction has numerous applications, including document summarization, literature search, patent search and business intelligence. The major challenge in performing Facet Extraction arises from multiple sources: concept extraction, concept to facet matching, and facet disambiguation. To tackle these challenges, we develop FacetGist, a framework for facet extraction. Facet Extraction involves constructing a graph-based heterogeneous network to capture information available across multiple local sentence-level features, as well as global context features. We then formulate a joint optimization problem, and propose an efficient algorithm for graph-based label propagation to estimate the facet of each concept mention. Experimental results on technical corpora from two domains demonstrate that Facet Extraction can lead to an improvement of over 25% in both precision and recall over competing schemes.",2016,Conference on Information and Knowledge Management,data science;information retrieval;data mining;database;computer science;
A Deep Relevance Matching Model for Ad-hoc Retrieval,Jiafeng Guo (Chinese Academy of Sciences);Yixing Fan (Chinese Academy of Sciences);Qingyao Ai (University of Massachusetts Amherst);W. Bruce Croft (University of Massachusetts Amherst);,"2581340266,2230500535,2223502885,2127889770","In recent years, deep neural networks have led to exciting breakthroughs in speech recognition, computer vision, and natural language processing (NLP) tasks. However, there have been few positive results of deep models on ad-hoc retrieval tasks. This is partially due to the fact that many important characteristics of the ad-hoc retrieval task have not been well addressed in deep models yet. Typically, the ad-hoc retrieval task is formalized as a matching problem between two pieces of text in existing work using deep models, and treated equivalent to many NLP tasks such as paraphrase identification, question answering and automatic conversation. However, we argue that the ad-hoc retrieval task is mainly about relevance matching while most NLP matching tasks concern semantic matching, and there are some fundamental differences between these two matching tasks. Successful relevance matching requires proper handling of the exact matching signals, query term importance, and diverse matching requirements. In this paper, we propose a novel deep relevance matching model (DRMM) for ad-hoc retrieval. Specifically, our model employs a joint deep architecture at the query term level for relevance matching. By using matching histogram mapping, a feed forward matching network, and a term gating network, we can effectively deal with the three relevance matching factors mentioned above. Experimental results on two representative benchmark collections show that our model can significantly outperform some well-known retrieval models as well as state-of-the-art deep matching models.",2016,Conference on Information and Knowledge Management,optimal matching;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;computer science;
Relational Database Schema Design for Uncertain Data,Sebastian Link (University of Auckland);Henri Prade (Centre national de la recherche scientifique);,"2095647292,2082615088","We investigate the impact of uncertainty on relational data\-base schema design. Uncertainty is modeled qualitatively by assigning to tuples a degree of possibility with which they occur, and assigning to functional dependencies a degree of certainty which says to which tuples they apply. A design theory is developed for possibilistic functional dependencies, including efficient axiomatic and algorithmic characterizations of their implication problem. Naturally, the possibility degrees of tuples result in a scale of different degrees of data redundancy. Scaled versions of the classical syntactic Boyce-Codd and Third Normal Forms are established and semantically justified in terms of avoiding data redundancy of different degrees. Classical decomposition and synthesis techniques are scaled as well. Therefore, possibilistic functional dependencies do not just enable designers to control the levels of data integrity and losslessness targeted but also to balance the classical trade-off between query and update efficiency. Extensive experiments confirm the efficiency of our framework and provide original insight into relational schema design.",2016,Conference on Information and Knowledge Management,superkey;data redundancy;boyce codd normal form;third normal form;axiom;possibility theory;data mining;database;algorithm;computer science;
Pseudo-Relevance Feedback Based on Matrix Factorization,Hamed Zamani (University of Massachusetts Amherst);Javid Dadashkarimi (University of Tehran);Azadeh Shakery (University of Tehran);W. Bruce Croft (University of Massachusetts Amherst);,"2143068131,273790870,2048088267,2127889770","In information retrieval, pseudo-relevance feedback (PRF) refers to a strategy for updating the query model using the top retrieved documents. PRF has been proven to be highly effective in improving the retrieval performance. In this paper, we look at the PRF task as a recommendation problem: the goal is to recommend a number of terms for a given query along with weights, such that the final weights of terms in the updated query model better reflect the terms' contributions in the query. To do so, we propose RFMF, a PRF framework based on matrix factorization which is a state-of-the-art technique in collaborative recommender systems. Our purpose is to predict the weight of terms that have not appeared in the query and matrix factorization techniques are used to predict these weights. In RFMF, we first create a matrix whose elements are computed using a weight function that shows how much a term discriminates the query or the top retrieved documents from the collection. Then, we re-estimate the created matrix using a matrix factorization technique. Finally, the query model is updated using the re-estimated matrix. RFMF is a general framework that can be employed with any retrieval model. In this paper, we implement this framework for two widely used document retrieval frameworks: language modeling and the vector space model. Extensive experiments over several TREC collections demonstrate that the RFMF framework significantly outperforms competitive baselines. These results indicate the potential of using other recommendation techniques in this task.",2016,Conference on Information and Knowledge Management,ranking;sargable;document term matrix;web query classification;query expansion;query optimization;matrix decomposition;language model;theoretical computer science;information retrieval;data mining;database;computer science;
Updating an Existing Social Graph Snapshot via a Limited API,Norases Vesdapunt (Stanford University);Hector Garcia-Molina (Stanford University);,"945412796,237419955","We study the problem of graph tracking with limited information. In this paper, we focus on updating a social graph snapshot. Say we have an existing partial snapshot, G 1 , of the social graph stored at some system. Over time G 1 becomes out of date. We want to update G 1 through a public API to the actual graph, restricted by the number of API calls allowed. Periodically recrawling every node in the snapshot is prohibitively expensive. We propose a scheme where we exploit indegrees and outdegrees to discover changes to the actual graph. When there is ambiguity, we probe the graph and verify edges. We propose a novel strategy designed for limited information that can be adapted to different levels of staleness. We evaluate our strategy against recrawling on real datasets and show that it saves an order of magnitude of API calls while introducing minimal errors.",2016,Conference on Information and Knowledge Management,graph database;snapshot;crawling;graph;social network;world wide web;distributed computing;data mining;database;machine learning;computer science;
Attribute-based Crowd Entity Resolution,Asif R. Khan (Stanford University);Hector Garcia-Molina (Stanford University);,"2138700960,237419955","We study the problem of using the crowd to perform entity resolution (ER) on a set of records. For many types of records, especially those involving images, such a task can be difficult for machines, but relatively easy for humans. Typical crowd-based ER approaches ask workers for pairwise judgments between records, which quickly becomes prohibitively expensive even for moderate numbers of records. In this paper, we reduce the cost of pairwise crowd ER approaches by soliciting the crowd for attribute labels on records, and then asking for pairwise judgments only between records with similar sets of attribute labels. However, due to errors induced by crowd-based attribute labeling, a naive attribute-based approach becomes extremely inaccurate even with few attributes. To combat these errors, we use error mitigation strategies which allow us to control the accuracy of our results while maintaining significant cost reductions. We develop a probabilistic model which allows us to determine the optimal, lowest-cost combination of error mitigation strategies needed to achieve a minimum desired accuracy. We test our approach with actual crowdworkers on a dataset of celebrity images, and find that our results yield crowd ER strategies which achieve high accuracy yet are significantly lower cost than pairwise-only approaches.",2016,Conference on Information and Knowledge Management,crowdsourcing;data deduplication;name resolution;record linkage;internet privacy;computer security;data mining;database;computer science;
Personalized Search: Potential and Pitfalls,Susan T. Dumais (Microsoft);,676500258,"Traditionally search engines have returned the same results to everyone who asks the same question. However, using a single ranking for everyone in every context at every point in time limits how well a search engine can do in providing relevant information. In this talk I present a framework to quantify the ""potential for personalization"" which we use to characterize the extent to which different people have different intents for the same query. I describe several examples of how we represent and use different kinds of contextual features to improve search quality for individuals and groups. Finally, I conclude by highlighting important challenges in developing personalized systems at Web scale including privacy, transparency, serendipity, and evaluation.",2016,Conference on Information and Knowledge Management,search analytics;user modeling;search engine;world wide web;information retrieval;data mining;database;machine learning;computer science;
Active Zero-Shot Learning,Sihong Xie (Lehigh University);Shaoxiong Wang (Tsinghua University);Philip S. Yu (University of Illinois at Chicago);,"2106011892,2331314855,2125104194","In multi-label classification in the big data age, the number of classes can be in thousands, and obtaining sufficient training data for each class is infeasible. Zero-shot learning aims at predicting a large number of unseen classes using only labeled data from a small set of classes and external knowledge about class relations. However, previous zero-shot learning models passively accept labeled data collected beforehand, relinquishing the opportunity to select the proper set of classes to inquire labeled data and optimize the performance of unseen class prediction. To resolve this issue, we propose an active class selection strategy to intelligently query labeled data for a parsimonious set of informative classes. We demonstrate two desirable probabilistic properties of the proposed method that can facilitate unseen classes prediction. Experiments on 4 text datasets demonstrate that the active zero-shot learning algorithm is superior to a wide spectrum of baselines. We indicate promising future directions at the end of this paper.",2016,Conference on Information and Knowledge Management,semi supervised learning;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
"PIN-TRUST: Fast Trust Propagation Exploiting Positive, Implicit, and Negative Information",Min-Hee Jang (Hanyang University);Christos Faloutsos (Carnegie Mellon University);Sang-Wook Kim (Hanyang University);U Kang (Seoul National University);Jiwoon Ha (Hanyang University);,"2502740687,2198983026,2114304489,2426051778,2102264230","Given ""who-trusts/distrusts-whom"" information, how can we propagate the trust and distrust? With the appearance of fraudsters in social network sites, the importance of trust prediction has increased. Most such methods use only explicit and implicit trust information (e.g., if Smith likes several of Johnson's reviews, then Smith implicitly trusts Johnson), but they do not consider distrust. In this paper, we propose PIN -TRUST, a novel method to handle all three types of interaction information: explicit trust, implicit trust, and explicit distrust. The novelties of our method are the following: (a) it is carefully designed, to take into account positive, implicit, and negative information, (b) it is scalable (i.e., linear on the input size), (c) most importantly, it is effective and accurate. Our extensive experiments with a real dataset, Epinions.com data, of 100K nodes and 1M edges, confirm that PIN-TRUST is scalable and outperforms existing methods in terms of prediction accuracy, achieving up to 50.4 percentage relative improvement.",2016,Conference on Information and Knowledge Management,belief propagation;data mining;artificial intelligence;machine learning;computer science;
Multi-source Hierarchical Prediction Consolidation,Chenwei Zhang (University of Illinois at Chicago);Sihong Xie (Lehigh University);Yaliang Li (University at Buffalo);Jing Gao (University at Buffalo);Wei Fan (Baidu);Philip S. Yu (University of Illinois at Chicago);,"2558611428,2106011892,2116094297,2096731881,2422054197,2125104194","In big data applications such as healthcare data mining, due to privacy concerns, it is necessary to collect predictions from multiple information sources for the same instance, with raw features being discarded or withheld when aggregating multiple predictions. Besides, crowd-sourced labels need to be aggregated to estimate the ground truth of the data. Due to the imperfection caused by predictive models or human crowdsourcing workers, noisy and conflicting information is ubiquitous and inevitable. Although state-of-the-art aggregation methods have been proposed to handle label spaces with flat structures, as the label space is becoming more and more complicated, aggregation under a label hierarchical structure becomes necessary but has been largely ignored. These label hierarchies can be quite informative as they are usually created by domain experts to make sense of highly complex label correlations such as protein functionality interactions or disease relationships. We propose a novel multi-source hierarchical prediction consolidation method to effectively exploits the complicated hierarchical label structures to resolve the noisy and conflicting information that inherently originates from multiple imperfect sources. We formulate the problem as an optimization problem with a closed-form solution. The consolidation result is inferred in a totally unsupervised, iterative fashion. Experimental results on both synthetic and real-world data sets show the effectiveness of the proposed method over existing alternatives.",2016,Conference on Information and Knowledge Management,crowdsourcing;ensembl;hierarchy;unsupervised learning;data science;data mining;database;machine learning;computer science;
Efficient Hidden Trajectory Reconstruction from Sparse Data,Ning Yang (Sichuan University);Philip S. Yu (University of Illinois at Chicago);,"2283784084,2125104194","In this paper, we investigate the problem of reconstructing hidden trajectories from a collective of separate spatial-temporal points without ID information, given the number of hidden trajectories. The challenge is three-fold: lack of meaningful features, data sparsity, and missing trajectory links. We propose a novel approach called Hidden Trajectory Reconstruction (HTR). From an information-theoretic perspective, we devise five novel temporal features and combine them into an Latent Spatial-Temporal Feature Vector (LSTFV) to characterize the dynamics of a single spatial-temporal point. The proposed features have the potential of distinguishing spatial-temporal points between trajectories. To overcome the data sparsity, we assemble the LSTFVs to a sparse Temporal Feature Tensor (TF-Tensor) and propose an algorithm called Parallel Iterative Collaborative Approximation of Sparse Tensor (PICAST). PICAST approximates the TF-Tensor by decomposing it into a tensor product of a low-rank core identity tensor and three dense factor matrices with a divide-and-conquer strategy. To achieve a dense approximate tensor with good accuracy and efficiency, PICAST minimizes a sparsity-measure and fuses an additional matrix of static geographical region features. To recover the missing trajectory links, we propose a mapping, Cross-Temporal Connectivity Preserving Transformation (CTCPT), to map the LSTFVs of the separate spatial-temporal points to an intrinsic space called Cross-Temporal Connectivity Preserving Space (CTCPS). CTCPT uses Cross-Temporal Connectivity (CTC) to evaluate whether two spatial-temporal points belong to the same trajectory and if they do, how strong the connectivity between them is. Due to the CTCPT, the hidden trajectories can be reconstructed from clusters generated in CTCPS by a clustering algorithm. At last, the extensive experiments conducted on synthetic datasets and real datasets verify the effectiveness and efficiency of our algorithms.",2016,Conference on Information and Knowledge Management,pattern recognition;machine learning;mathematical optimization;
Online Adaptive Topic Focused Tweet Acquisition,"Mehdi Sadri (University of California, Irvine);Sharad Mehrotra (University of California, Irvine);Yaming Yu (University of California, Irvine);","2560028920,2201039448,2714953384","Twitter provides a public streaming API that is strictly limited, making it difficult to simultaneously achieve good coverage and relevance when monitoring tweets for a specific topic of interest. In this paper, we address the tweet acquisition challenge to enhance monitoring of tweets based on the client/application needs in an online adaptive manner such that the quality and quantity of the results improves over time. We propose a Tweet Acquisition System (TAS), that iteratively selects phrases to track based on an explore-exploit strategy. Our experimental studies show that TAS significantly improves recall of relevant tweets and the performance improves when the topics are more specific.",2016,Conference on Information and Knowledge Management,data pre processing;data quality;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Multiple Queries as Bandit Arms,Cheng Li (University of Michigan);Paul Resnick (University of Michigan);Qiaozhu Mei (University of Michigan);,"2674810995,2020459140,2166036605","Existing retrieval systems rely on a single active query to pull documents from the index. Relevance feedback may be used to iteratively refine the query, but only one query is active at a time. If the user's information need has multiple aspects, the query must represent the union of these aspects. We consider a new paradigm of retrieval where multiple queries are kept ``active'' simultaneously. In the presence of rate limits, the active queries take turns accessing the index to retrieve another ``page'' of results. Turns are assigned by a multi-armed bandit based on user feedback. This allows the system to explore which queries return more relevant results and to exploit the best ones. In empirical tests, query pools outperform solo, combined queries. Significant improvement is observed both when the subtopic queries are known in advance and when the queries are generated in a user-interactive process.",2016,Conference on Information and Knowledge Management,ranking;range query;sargable;web search query;web query classification;spatial query;query expansion;query optimization;world wide web;information retrieval;data mining;database;machine learning;computer science;
Urban Traffic Prediction through the Second Use of Inexpensive Big Data from Buildings,Zimu Zheng (Hong Kong Polytechnic University);Dan Wang (Hong Kong Polytechnic University);Jian Pei (Simon Fraser University);Yi Yuan (Tencent);Cheng Fan (Hong Kong Polytechnic University);Fu Xiao (Hong Kong Polytechnic University);,"2535397510,2479868935,2126330539,2310236008,2443837793,2726568569","Traffic prediction, particularly in urban regions, is an important application of tremendous practical value. In this paper, we report a novel and interesting case study of urban traffic prediction in Central, Hong Kong, one of the densest urban areas in the world. The novelty of our study is that we make good second use of inexpensive big data collected from the Hong Kong International Commerce Centre (ICC), a 118-story building in Hong Kong where more than 10,000 people work. As building environment data are much cheaper to obtain than traffic data, we demonstrate that it is highly effective to estimate building occupancy information using building environment data, and then to further use the information on occupancy to provide traffic predictions in the proximate area. Scientifically, we investigate how and to what extent building data can complement traffic data in predicting traffic. In general, this study sheds new light on the development of accurate data mining applications through the second use of inexpensive big data.",2016,Conference on Information and Knowledge Management,computer science;
Luhn Revisited: Significant Words Language Models,Mostafa Dehghani (University of Amsterdam);Hosein Azarbonyad (University of Amsterdam);Jaap Kamps (University of Amsterdam);Djoerd Hiemstra (University of Twente);Maarten Marx (University of Amsterdam);,"2112331270,145866791,2088944921,2125867230,2195082027","Users tend to articulate their complex information needs in only a few keywords, making underspecified statements of request the main bottleneck for retrieval effectiveness. Taking advantage of feedback information is one of the best ways to enrich the query representation, but can also lead to loss of query focus and harm performance in particular when the initial query retrieves only little relevant information when overfitting to accidental features of the particular observed feedback documents. Inspired by the early work of Luhn [23], we propose significant words language models of feedback documents that capture all, and only, the significant shared terms from feedback documents. We adjust the weights of common terms that are already well explained by the document collection as well as the weight of rare terms that are only explained by specific feedback documents, which eventually results in having only the significant terms left in the feedback model. Our main contributions are the following. First, we present significant words language models as the effective models capturing the essential terms and their probabilities. Second, we apply the resulting models to the relevance feedback task, and see a better performance over the state-of-the-art methods. Third, we see that the estimation method is remarkably robust making the models in- sensitive to noisy non-relevant terms in feedback documents. Our general observation is that the significant words language models more accurately capture relevance by excluding general terms and feedback document specific terms.",2016,Conference on Information and Knowledge Management,natural language processing;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
An Adaptive Framework for Multistream Classification,Swarup Chandra (University of Texas at Dallas);Ahsanul Haque (University of Texas at Dallas);Latifur Khan (University of Texas at Dallas);Charu C. Aggarwal (IBM);,"2307411638,2132111568,2155983610,2146335907","A typical data stream classification involves predicting label of data instances generated from a non-stationary process. Studies in the past decade have focused on this problem setting to address various challenges such as concept drift and concept evolution. Most techniques assume availability of class labels associated with unlabeled data instances, soon after label prediction, for further training and drift detection. Moreover, training and test data distributions are assumed to be similar. These assumptions are not always true in practice. For instance, a semi-supervised setting that aims to utilize only a fraction of labels may induce bias during data selection. Consequently, the resulting data distribution of training and test instances may differ. In this paper, we present a novel stream classification problem setting involving two independent non-stationary data generating processes, relaxing the above assumptions. A source stream continuously generates labeled data instances whose distribution is biased compared to that of a target stream which generates unlabeled data instances from the same domain. The problem, we call Multistream Classification, is to predict the class labels of data instances in the target stream, while utilizing labels available on the source stream. Since concept drift can occur asynchronously on these two streams, we design an adaptive framework that uses a technique for supervised concept drift detection in the biased source stream, and unsupervised concept drift detection in the target stream. A weighted ensemble of classifiers is updated after each drift detection on either streams, while utilizing a bias correction mechanism that leverage source information to predict labels of target instances whenever necessary. We empirically evaluate the multistream classifier's performance on both real-world and synthetic datasets, while comparing with various baseline methods and its variants.",2016,Conference on Information and Knowledge Management,concept drift;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;
aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model,Liu Yang (University of Massachusetts Amherst);Qingyao Ai (University of Massachusetts Amherst);Jiafeng Guo (Chinese Academy of Sciences);W. Bruce Croft (University of Massachusetts Amherst);,"2654709152,2223502885,2581340266,2127889770","As an alternative to question answering methods based on feature engineering, deep learning approaches such as convolutional neural networks (CNNs) and Long Short-Term Memory Models (LSTMs) have recently been proposed for semantic matching of questions and answers. To achieve good results, however, these models have been combined with additional features such as word overlap or BM25 scores. Without this combination, these models perform significantly worse than methods based on linguistic feature engineering. In this paper, we propose an attention based neural matching model for ranking short answer text. We adopt value-shared weighting scheme instead of position-shared weighting scheme for combining different matching signals and incorporate question term importance learning using question attention network. Using the popular benchmark TREC QA data, we show that the relatively simple aNMM model can significantly outperform other neural network models that have been used for the question answering task, and is competitive with models that are combined with additional features. When aNMM is combined with additional features, it outperforms all baselines.",2016,Conference on Information and Knowledge Management,deep learning;question answering;natural language processing;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;computer science;
LogMine: Fast Pattern Recognition for Log Analytics,Hossein Hamooni (University of New Mexico);Biplob Debnath (NEC);Jianwu Xu (NEC);Hui Zhang (NEC);Guofei Jiang (NEC);Abdullah Mueen (University of New Mexico);,"308734036,2125605224,2493951869,2588683129,2168090285,2083987245","Modern engineering incorporates smart technologies in all aspects of our lives. Smart technologies are generating terabytes of log messages every day to report their status. It is crucial to analyze these log messages and present usable information (e.g. patterns) to administrators, so that they can manage and monitor these technologies. Patterns minimally represent large groups of log messages and enable the administrators to do further analysis, such as anomaly detection and event prediction. Although patterns exist commonly in automated log messages, recognizing them in massive set of log messages from heterogeneous sources without any prior information is a significant undertaking. We propose a method, named LogMine, that extracts high quality patterns for a given set of log messages. Our method is fast, memory efficient, accurate, and scalable. LogMine is implemented in map-reduce framework for distributed platforms to process millions of log messages in seconds. LogMine is a robust method that works for heterogeneous log messages generated in a wide variety of systems. Our method exploits algorithmic techniques to minimize the computational overhead based on the fact that log messages are always automatically generated. We evaluate the performance of LogMine on massive sets of log messages generated in industrial applications. LogMine has successfully generated patterns which are as good as the patterns generated by exact and unscalable method, while achieving a 500× speedup. Finally, we describe three applications of the patterns generated by LogMine in monitoring large scale industrial systems.",2016,Conference on Information and Knowledge Management,theoretical computer science;world wide web;data mining;database;computer science;
Vandalism Detection in Wikidata,Stefan Heindorf (University of Paderborn);Martin Potthast (Weimar Institute);Benno Stein (Weimar Institute);Gregor Engels (University of Paderborn);,"2229693617,1678657404,2134393620,2136680303","Wikidata is the new, large-scale knowledge base of the Wikimedia Foundation. Its knowledge is increasingly used within Wikipedia itself and various other kinds of information systems, imposing high demands on its integrity. Wikidata can be edited by anyone and, unfortunately, it frequently gets vandalized, exposing all information systems using it to the risk of spreading vandalized and falsified information. In this paper, we present a new machine learning-based approach to detect vandalism in Wikidata. We propose a set of 47 features that exploit both content and context information, and we report on 4 classifiers of increasing effectiveness tailored to this learning task. Our approach is evaluated on the recently published Wikidata Vandalism Corpus WDVC-2015 and it achieves an area under curve value of the receiver operating characteristic, ROC-AUC, of 0.991. It significantly outperforms the state of the art represented by the rule-based Wikidata Abuse Filter (0.865 ROC-AUC) and a prototypical vandalism detector recently introduced by Wikimedia within the Objective Revision Evaluation Service (0.859 ROC-AUC).",2016,Conference on Information and Knowledge Management,trustworthy computing;data quality;knowledge base;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Linked Document Embedding for Classification,Suhang Wang (Arizona State University);Jiliang Tang (Michigan State University);Charu C. Aggarwal (IBM);Huan Liu (Arizona State University);,"2122735199,2147392410,2146335907,2122391114","Word and document embedding algorithms such as Skip-gram and Paragraph Vector have been proven to help various text analysis tasks such as document classification, document clustering and information retrieval. The vast majority of these algorithms are designed to work with independent and identically distributed documents. However, in many real-world applications, documents are inherently linked. For example, web documents such as blogs and online news often have hyperlinks to other web documents, and scientific articles usually cite other articles. Linked documents present new challenges to traditional document embedding algorithms. In addition, most existing document embedding algorithms are unsupervised and their learned representations may not be optimal for classification when labeling information is available. In this paper, we study the problem of linked document embedding for classification and propose a linked document embedding framework LDE, which combines link and label information with content information to learn document representations for classification. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the importance of link and label information in the proposed framework LDE.",2016,Conference on Information and Knowledge Management,well formed document;linked data;document clustering;world wide web;information retrieval;data mining;database;computer science;
Social Recommendation with Strong and Weak Ties,Xin Wang (Zhejiang University);Wei Lu (University of British Columbia);Martin Ester (Simon Fraser University);Can Wang (Zhejiang University);Chun Chen (Zhejiang University);,"2720655070,2707307837,2067196623,2595543912,2151411149","With the explosive growth of online social networks, it is now well understood that social information is highly helpful to recommender systems. Social recommendation methods are capable of battling the critical cold-start issue, and thus can greatly improve prediction accuracy. The main intuition is that through trust and influence, users are more likely to develop affinity toward items consumed by their social ties. Despite considerable work in social recommendation, little attention has been paid to the important distinctions between strong and weak ties, two well-documented notions in social sciences. In this work, we study the effects of distinguishing strong and weak ties in social recommendation. We use neighbourhood overlap to approximate tie strength and extend the popular Bayesian Personalized Ranking (BPR) model to incorporate the distinction of strong and weak ties. We present an EM-based algorithm that simultaneously classifies strong and weak ties in a social network w.r.t. optimal recommendation accuracy and learns latent feature vectors for all users and all items. We conduct extensive empirical evaluation on four real-world datasets and demonstrate that our proposed method significantly outperforms state-of-the-art pairwise ranking methods in a variety of accuracy metrics.",2016,Conference on Information and Knowledge Management,recommender system;world wide web;data mining;artificial intelligence;machine learning;computer science;
Ensemble Learned Vaccination Uptake Prediction using Web Search Queries,Niels Dalum Hansen (University of Copenhagen);Christina Lioma (University of Copenhagen);Kåre Mølbak (Statens Serum Institut);,"2119294069,1619376036,277372617","We present a method that uses ensemble learning to combine clinical and web-mined time-series data in order to predict future vaccination uptake. The clinical data is official vaccination registries, and the web data is query frequencies collected from Google Trends. Experiments with official vaccine records show that our method predicts vaccination uptake effectively (4.7 Root Mean Squared Error). Whereas performance is best when combining clinical and web data, using solely web data yields comparative performance. To our knowledge, this is the first study to predict vaccination uptake using web data (with and without clinical data).",2016,Conference on Information and Knowledge Management,ensemble learning;data science;world wide web;data mining;machine learning;computer science;
OrientStream: A Framework for Dynamic Resource Allocation in Distributed Data Stream Management Systems,Chunkai Wang (Renmin University of China);Xiaofeng Meng (Renmin University of China);Qi Guo (Chinese Academy of Sciences);Zujian Weng (Renmin University of China);Chen Yang (Renmin University of China);,"2557937698,2134422024,2664956444,2535308214,2135903778","Distributed data stream management systems (DDSMS) are usually composed of upper layer relational query systems (RQS) and lower layer stream processing systems (SPS). When users submit new queries to RQS, a query planner needs to be converted into a directed acyclic graph (DAG) consisting of tasks which are running on SPS. Based on different query requests and data stream properties, SPS need to configure different deployments strategies. However, how to dynamically predict deployment configurations of SPS to ensure the processing throughput and low resource usage is a great challenge. This article presents OrientStream, a framework for dynamic resource allocation in DDSMS using incremental machine learning techniques. By introducing the data-level, query plan-level, operator-level and cluster-level's four-level feature extraction mechanism, we firstly use the different query workloads as training sets to predict the resource usage of DDSMS and then select the optimal resource configuration from candidate settings based on the current query requests and stream properties. Finally, we validate our approach on the open source SPS--Storm. Experiments show that OrientStream can reduce CPU usage of 8%-15% and memory usage of 38%-48% respectively.",2016,Conference on Information and Knowledge Management,query optimization;world wide web;information retrieval;data mining;database;real time computing;computer science;
Semantic Matching by Non-Linear Word Transportation for Information Retrieval,Jiafeng Guo (Chinese Academy of Sciences);Yixing Fan (Chinese Academy of Sciences);Qingyao Ai (University of Massachusetts Amherst);W. Bruce Croft (University of Massachusetts Amherst);,"2581340266,2230500535,2223502885,2127889770","A common limitation of many information retrieval (IR) models is that relevance scores are solely based on exact (i.e., syntactic) matching of words in queries and documents under the simple Bag-of-Words (BoW) representation. This not only leads to the well-known vocabulary mismatch problem, but also does not allow semantically related words to contribute to the relevance score. Recent advances in word embedding have shown that semantic representations for words can be efficiently learned by distributional models. A natural generalization is then to represent both queries and documents as Bag-of-Word-Embeddings (BoWE), which provides a better foundation for semantic matching than BoW. Based on this representation, we introduce a novel retrieval model by viewing the matching between queries and documents as a non-linear word transportation (NWT) problem. With this formulation, we define the capacity and profit of a transportation model designed for the IR task. We show that this transportation problem can be efficiently solved via pruning and indexing strategies. Experimental results on several representative benchmark datasets show that our model can outperform many state-of-the-art retrieval models as well as recently introduced word embedding-based models. We also conducted extensive experiments to analyze the effect of different settings on our semantic matching model.",2016,Conference on Information and Knowledge Management,visual word;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;computer science;
Making Sense of Entities and Quantities in Web Tables,Yusra Ibrahim (Max Planck Society);Mirek Riedewald (Northeastern University);Gerhard Weikum (Max Planck Society);,"2114972620,2128393815,514836396","HTML tables and spreadsheets on the Internet or in enterprise intranets often contain valuable information, but are created ad-hoc. As a result, they usually lack systematic names for column headers and clear vocabulary for cell values. This limits the re-use of such tables and creates a huge heterogeneity problem when comparing or aggregating multiple tables. This paper aims to overcome this problem by automatically canonicalizing header names and cell values onto concepts, classes, entities and uniquely represented quantities registered in a knowledge base. To this end, we devise a probabilistic graphical model that captures coherence dependencies between cells in tables and candidate items in the space of concepts, entities and quantities. We give specific consideration to quantities which are mapped into a ""measure, value, unit"" triple over a taxonomy of physical (e.g. power consumption), monetary (e.g. revenue), temporal (e.g. date) and dimensionless (e.g. counts) measures. Our experiments with Web tables from diverse domains demonstrate the viability of our method and its benefits over baselines.",2016,Conference on Information and Knowledge Management,table;information extraction;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Iterative Search using Query Aspects,Manmeet Singh (University of Massachusetts Amherst);W. Bruce Croft (University of Massachusetts Amherst);,"2535242910,2127889770","Pseudo-relevance feedback (PRF) via query expansion has proven to be effective in many information retrieval tasks. In most existing work, the top-ranked documents from an initial search are assumed to be relevant and used for feedback. There are some drawbacks to this approach. One limitation is that there might be other relevant documents which were not retrieved or considered for the the feedback process. Another issue is one or more of the top retrieved documents may be non-relevant, which can introduce noise into the feedback mechanism. Term-level diversification, on the other hand, uses an effective technique for identifying terms associated with query aspects or subtopics. We propose a new iterative feedback method that combines PRF with aspect generation to improve feedback effectiveness. In our experiments, we discovered a new property of convergence of feedback terms that was incorporated into the PRF process. We show that the resulting method significantly outperforms the baseline relevance model.",2016,Conference on Information and Knowledge Management,theoretical computer science;information retrieval;data mining;computer science;
Credibility Assessment of Textual Claims on the Web,Kashyap Popat (Max Planck Society);Subhabrata Mukherjee (Max Planck Society);Jannik Strötgen (Max Planck Society);Gerhard Weikum (Max Planck Society);,"2551091452,2301124665,1484506931,514836396","There is an increasing amount of false claims in news, social media, and other web sources. While prior work on truth discovery has focused on the case of checking factual statements, this paper addresses the novel task of assessing the credibility of arbitrary claims made in natural-language text - in an open-domain setting without any assumptions about the structure of the claim, or the community where it is made. Our solution is based on automatically finding sources in news and social media, and feeding these into a distantly supervised classifier for assessing the credibility of a claim (i.e., true or fake). For inference, our method leverages the joint interaction between the language of articles about the claim and the reliability of the underlying web sources. Experiments with claims from the popular website snopes.com and from reported cases of Wikipedia hoaxes demonstrate the viability of our methods and their superior accuracy over various baselines.",2016,Conference on Information and Knowledge Management,text mining;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Using Prerequisites to Extract Concept Maps fromTextbooks,Shuting Wang (Pennsylvania State University);Alexander G. Ororbia (Pennsylvania State University);Zhaohui Wu (Pennsylvania State University);Kyle Williams (Pennsylvania State University);Chen Liang (Pennsylvania State University);Bart Pursel (Pennsylvania State University);C. Lee Giles (Pennsylvania State University);,"2229790191,2265490809,2708527874,2124644202,2194926722,1967864241,2124749556","We present a framework for constructing a specific type of knowledge graph, a concept map from textbooks. Using Wikipedia, we derive prerequisite relations among these concepts. A traditional approach for concept map extraction consists of two sub-problems: key concept extraction and concept relationship identification. Previous work for the most part had considered these two sub-problems independently. We propose a framework that jointly optimizes these sub-problems and investigates methods that identify concept relationships. Experiments on concept maps that are manually extracted in six educational areas (computer networks, macroeconomics, precalculus, databases, physics, and geometry) show that our model outperforms supervised learning baselines that solve the two sub-problems separately. Moreover, we observe that incorporating textbook information helps with concept map extraction.",2016,Conference on Information and Knowledge Management,concept map;knowledge management;data mining;database;artificial intelligence;machine learning;computer science;
FeatureMiner: A Tool for Interactive Feature Selection,Kewei Cheng (Arizona State University);Jundong Li (Arizona State University);Huan Liu (Arizona State University);,"2563279133,2149809093,2122391114","The recent popularity of big data has brought immense quantities of high-dimensional data, which presents challenges to traditional data mining tasks due to curse of dimensionality. Feature selection has shown to be effective to prepare these high dimensional data for a variety of learning tasks. To provide easy access to feature selection algorithms, we provide an interactive feature selection tool FeatureMiner based on our recently released feature selection repository scikit-feature. FeatureMiner eases the process of performing feature selection for practitioners by providing an interactive user interface. Meanwhile, it also gives users some practical guidance in finding a suitable feature selection algorithm among many given a specific dataset. In this demonstration, we show (1) How to conduct data preprocessing after loading a dataset; (2) How to apply feature selection algorithms; (3) How to choose a suitable algorithm by visualized performance evaluation.",2016,Conference on Information and Knowledge Management,feature;feature selection;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Recommendations For Streaming Data,Karthik Subbian (University of Minnesota);Charu C. Aggarwal (IBM);Kshiteesh Hegde (University of Minnesota);,"2230469306,2146335907,2532037742","Recommender systems have become increasingly popular in recent years because of the broader popularity of many web-enabled electronic commerce applications. However, most recommender systems today are designed in the context of an offline setting. The online setting is, however, much more challenging because the existing methods do not work very effectively for very large-scale systems. In many applications, it is desirable to provide real-time recommendations in large-scale scenarios. The main problem in applying streaming algorithms for recommendations is that the in-core storage space for memory-resident operations is quite limited. In this paper, we present a probabilistic neighborhood-based algorithm for performing recommendations in real-time. We present experimental results, which show the effectiveness of our approach in comparison to state-of-the-art methods.",2016,Conference on Information and Knowledge Management,data stream mining;multimedia;world wide web;data mining;database;machine learning;computer science;
Generalizing Translation Models in the Probabilistic Relevance Framework,Navid Rekabsaz (Vienna University of Technology);Mihai Lupu (Vienna University of Technology);Allan Hanbury (Vienna University of Technology);Guido Zuccon (Queensland University of Technology);,"321652401,2010059705,2168901591,1551779932","A recurring question in information retrieval is whether term associations can be properly integrated in traditional information retrieval models while preserving their robustness and effectiveness. In this paper, we revisit a wide spectrum of existing models (Pivoted Document Normalization, BM25, BM25 Verboseness Aware, Multi-Aspect TF, and Language Modelling) by introducing a generalisation of the idea of the translation model. This generalisation is a de facto transformation of the translation models from Language Modelling to the probabilistic models. In doing so, we observe a potential limitation of these generalised translation models: they only affect the term frequency based components of all the models, ignoring changes in document and collection statistics. We correct this limitation by extending the translation models with the 15 statistics of term associations and provide extensive experimental results to demonstrate the benefit of the newly proposed methods. Additionally, we compare the translation models with query expansion methods based on the same term association resources, as well as based on Pseudo-Relevance Feedback (PRF). We observe that translation models always outperform the first, but provide complementary information with the second, such that by using PRF and our translation models together we observe results better than the current state of the art.",2016,Conference on Information and Knowledge Management,dynamic and formal equivalence;natural language processing;information retrieval;data mining;database;machine learning;statistics;
Where Did You Go: Personalized Annotation of Mobility Records,Fei Wu (Pennsylvania State University);Zhenhui Li (Pennsylvania State University);,"2281645832,2098136913","Recent advances in positioning technology have generated massive volume of human mobility data. At the same time, large amount of spatial context data are available and provide us with rich context information. Combining the mobility data with surrounding spatial context enables us to understand the semantics of the mobility records, e.g., what is a user doing at a location, e.g., dining at a restaurant or attending a football game). In this paper, we aim to answer this question by annotating the mobility records with surrounding venues that were actually visited by the user. The problem is non-trivial due to high ambiguity of surrounding contexts. Unlike existing methods that annotate each location record independently, we propose to use all historical mobility records to capture user preferences, which results in more accurate annotations. Our method does not assume the availability to any training data on user preference because of the difficulties to obtain such data in the real-world setting. Instead, we design a Markov random field model to find the best annotations that maximize the consistency of annotated venues. Through extensive experiments on real datasets, we demonstrate that our method significantly outperforms the baseline methods.",2016,Conference on Information and Knowledge Management,social network;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Hashtag Recommendation for Enterprise Applications,Dhruv Mahajan (Microsoft);Vishwajit Kolathur (Microsoft);Chetan Bansal (Microsoft);Suresh Parthasarathy (Microsoft);Sundararajan Sellamanickam (Microsoft);S. Sathiya Keerthi (Microsoft);Johannes Gehrke (Microsoft);,"2515560682,2533605055,2483521389,2532316185,2306535536,2649115054,2083845045","Hashtags have been popularly used in several social cum consumer network settings such as Twitter and Facebook. In this paper, we consider the problem of recommending hashtags for enterprise applications. These applications include emails (e.g., Outlook), enterprise social networks (e.g., Yammer) and special interest group email lists. This problem arises in an organization setting and hashtags are enterprise domain specific. One important aspect of our recommendation system is that we recommend hashtags for Inline hashtag scenario where recommendations change as the user inserts hashtags while typing the message. This involves working with partial content information. Besides this, we consider the conventional Post } hashtagging scenario where hashtags are recommended for the full message. We also consider an important (sub)scenario, viz., Auto-complete where hashtags are recommended with user provided partial information such as sub-string present in the hashtag. Auto-complete can be used with both Inline and Post scenarios. To the best of our knowledge, Inline , Auto-complete hashtag recommendations and hashtagging in enterprise applications have not been studied before. We propose to learn a joint model that uses features of three types, namely, temporal, structural and content. Our learning formulation handles all the hashtagging scenarios naturally. Comprehensive experimental study on five datasets of user email accounts collected by running an Outlook plugin (a key requirement for large scale industrial deployment), one dataset of special interest group email list and one enterprise social network data set shows that the proposed method performs significantly better than the state of the art methods used in consumer applications such as Twitter. The primary reason is that different feature types play dominant role in different scenarios and datasets. Since the joint model makes use of all feature types effectively, it performs better in almost all scenarios and datasets.",2016,Conference on Information and Knowledge Management,knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Cross-lingual Text Classification via Model Translation with Limited Dictionaries,Ruochen Xu (Carnegie Mellon University);Yiming Yang (Carnegie Mellon University);Hanxiao Liu (Carnegie Mellon University);Andrew Hsi (Carnegie Mellon University);,"2532904197,2159253281,2167236151,2560183732","Cross-lingual text classification (CLTC) refers to the task of classifying documents in different languages into the same taxonomy of categories. An open challenge in CLTC is to classify documents for the languages where labeled training data are not available. Existing approaches rely on the availability of either high-quality machine translation of documents (to the languages where massively training data are available), or rich bilingual dictionaries for effective translation of trained classification models (to the languages where labeled training data are lacking). This paper studies the CLTC challenge under the assumption that neither condition is met. That is, we focus on the problem of translating classification models with highly incomplete bilingual dictionaries. Specifically, we propose two new approaches that combines unsupervised word embedding in different languages, supervised mapping of embedded words across languages, and probabilistic translation of classification models. The approaches show significant performance improvement in CLTC on a benchmark corpus of Reuters news stories (RCV1/RCV2) in English, Spanish, German, French and Chinese and an internal dataset in Uzbek, compared to representative baseline methods using conventional bilingual dictionaries or highly incomplete ones.",2016,Conference on Information and Knowledge Management,transfer of learning;natural language processing;speech recognition;information retrieval;data mining;pattern recognition;computer science;
Characterizing Diseases from Unstructured Text: A Vocabulary Driven Word2vec Approach,Saurav Ghosh (Virginia Tech);Prithwish Chakraborty (Virginia Tech);Emily Cohn (Boston Children's Hospital);John S. Brownstein (Harvard University);Naren Ramakrishnan (Virginia Tech);,"2132509985,2121182072,2112193954,1915684033,2199255697","Traditional disease surveillance can be augmented with a wide variety of real-time sources such as, news and social media. However, these sources are in general unstructured and, construction of surveillance tools such as taxonomical correlations and trace mapping involves considerable human supervision. In this paper, we motivate a disease vocabulary driven word2vec model (Dis2Vec) to model diseases and constituent attributes as word embeddings from the HealthMap news corpus. We use these word embeddings to automatically create disease taxonomies and evaluate our model against corresponding human annotated taxonomies. We compare our model accuracies against several state-of-the art word2vec methods. Our results demonstrate that Dis2Vec outperforms traditional distributed vector representations in its ability to faithfully capture taxonomical attributes across different class of diseases such as endemic, emerging and rare.",2016,Conference on Information and Knowledge Management,natural language processing;data mining;machine learning;computer science;
Truth Discovery via Exploiting Implications from Multi-Source Data,Xianzhi Wang (University of New South Wales);Quan Z. Sheng (University of Adelaide);Lina Yao (University of New South Wales);Xue Li (University of Queensland);Xiu Susie Fang (University of Adelaide);Xiaofei Xu (Harbin Institute of Technology);Boualem Benatallah (University of New South Wales);,"2706456112,1740996049,2223456168,2239470812,2147043350,2130531517,2038216534","Data veracity is a grand challenge for various tasks on the Web. Since the web data sources are inherently unreliable and may provide conflicting information about the same real-world entities, truth discovery is emerging as a countermeasure of resolving the conflicts by discovering the truth, which conforms to the reality, from the multi-source data. A major challenge related to truth discovery is that different data items may have varying numbers of true values (or multi-truth), which counters the assumption of existing truth discovery methods that each data item should have exactly one true value. In this paper, we address this challenge by exploiting and leveraging the implications from multi-source data. In particular, we exploit three types of implications, namely the implicit negative claims, the distribution of positive/negative claims, and the co-occurrence of values in sources' claims, to facilitate multi-truth discovery. We propose a probabilistic approach with improvement measures that incorporate the three implications in all stages of truth discovery process. In particular, incorporating the negative claims enables multi-truth discovery, considering the distribution of positive/negative claims relieves truth discovery from the impact of sources' behavioral features in the specific datasets, and considering values' co-occurrence relationship compensates the information lost from evaluating each value in the same claims individually. Experimental results on three real-world datasets demonstrate the effectiveness of our approach.",2016,Conference on Information and Knowledge Management,statistical model;data science;information retrieval;data mining;statistics;computer science;
The Rich and the Poor: A Markov Decision Process Approach to Optimizing Taxi Driver Revenue Efficiency,Huigui Rong (Hunan University);Xun Zhou (University of Iowa);Chang Yang (Hunan University);M. Zubair Shafiq (University of Iowa);Alex X. Liu (Michigan State University);,"2674319802,2690456736,2694296392,2027770059,2138817356","Taxi services play an important role in the public transportation system of large cities. Improving taxi business efficiency is an important societal problem since it could improve the income of the drivers and reduce gas emissions and fuel consumption. The recent research on seeking strategies may not be optimal for the overall revenue over an extended period of time as they ignored the important impact of passengers' destinations on future passenger seeking. To address these issues, this paper investigates how to increase the revenue efficiency (revenue per unit time) of taxi drivers, and models the passenger seeking process as a Markov Decision Process (MDP). For each one-hour time slot, we learn a different set of parameters for the MDP from data and find the best move for a vacant taxi to maximize the total revenue in that time slot. A case study and several experimental evaluations on a real dataset from a major city in China show that our proposed approach improves the revenue efficiency of inexperienced drivers by up to 15% and outperforms a baseline method in all the time slots.",2016,Conference on Information and Knowledge Management,revenue model;markov decision process;simulation;computer science;
Generative Feature Language Models for Mining Implicit Features from Customer Reviews,Shubhra Kanti Karmaker Santu (University of Illinois at Urbana–Champaign);Parikshit Sondhi (Walmart Labs);Cheng Xiang Zhai (University of Illinois at Urbana–Champaign);,"2560334051,2662237313,2152766206","Online customer reviews are very useful for both helping consumers make buying decisions on products or services and providing business intelligence. However, it is a challenge for people to manually digest all the opinions buried in large amounts of review data, raising the need for automatic opinion summarization and analysis. One fundamental challenge in automatic opinion summarization and analysis is to mine implicit features, i.e., recognizing the features implicitly mentioned (referred to) in a review sentence. Existing approaches require many ad hoc manual parameter tuning, and are thus hard to optimize or generalize; their evaluation has only been done with Chinese review data. In this paper, we propose a new approach based on generative feature language models that can mine the implicit features more effectively through unsupervised statistical learning. The parameters are optimized automatically using an Expectation-Maximization algorithm. We also created eight new data sets to facilitate evaluation of this task in English. Experimental results show that our proposed approach is very effective for assigning features to sentences that do not explicitly mention the features, and outperforms the existing algorithms by a large margin.",2016,Conference on Information and Knowledge Management,language model;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
ESPRESSO: Explaining Relationships between Entity Sets,Stephan Seufert (Max Planck Society);Klaus Berberich (Max Planck Society);Srikanta J. Bedathur (IBM);Sarath Kumar Kondreddi (Max Planck Society);Patrick Ernst (Max Planck Society);Gerhard Weikum (Max Planck Society);,"2115632026,2064029816,1218200837,331953617,2106695673,514836396","Analyzing and explaining relationships between entities in a knowledge graph is a fundamental problem with many applications. Prior work has been limited to extracting the most informative subgraph connecting two entities of interest. This paper extends and generalizes the state of the art by considering the relationships between two sets of entities given at query time. Our method, coined ESPRESSO, explains the connection between these sets in terms of a small number of relatedness cores: dense sub-graphs that have strong relations with both query sets. The intuition for this model is that the cores correspond to key events in which entities from both sets play a major role. For example, to explain the relationships between US politicians and European politicians, our method identifies events like the PRISM scandal and the Syrian Civil War as relatedness cores. Computing cores of bounded size is NP-hard. This paper presents efficient approximation algorithms. Our experiments with real-life knowledge graphs demonstrate the practical viability of our approach and, through user studies, the superior output quality compared to state-of-the-art baselines.",2016,Conference on Information and Knowledge Management,social network;data mining;database;artificial intelligence;machine learning;algorithm;
The Role of Relevance in Sponsored Search,Luca Maria Aiello (Bell Labs);Ioannis Arapakis (Yahoo!);Ricardo A. Baeza-Yates (Yahoo!);Xiao Bai 0002 (Yahoo!);Nicola Barbieri (Yahoo!);Amin Mantrach (Yahoo!);Fabrizio Silvestri (Facebook);,"2677626719,2091815359,528588921,2104717575,2155070167,2027707398,2134079936","Sponsored search aims at retrieving the advertisements that in the one hand meet users' intent reflected in their search queries, and in the other hand attract user clicks to generate revenue. Advertisements are typically ranked based on their expected revenue that is computed as the product between their predicted probability of being clicked (i.e., namely clickability) and their advertiser provided bid. The relevance of an advertisement to a user query is implicitly captured by the predicted clickability of the advertisement, assuming that relevant advertisements are more likely to attract user clicks. However, this approach easily biases the ranking toward advertisements having rich click history. This may incorrectly lead to showing irrelevant advertisements whose clickability is not accurately predicted due to lack of click history. Another side effect consists of never giving a chance to new advertisements that may be highly relevant to be printed due to their lack of click history. To address this problem, we explicitly measure the relevance between an advertisement and a query without relying on the advertisement's click history, and present different ways of leveraging this relevance to improve user search experience without reducing search engine revenue. Specifically, we propose a machine learning approach that solely relies on text-based features to measure the relevance between an advertisement and a query. We discuss how the introduced relevance can be used in four important use cases: pre-filtering of irrelevant advertisements, recovering advertisements with little history, improving clickability prediction, and re-ranking of the advertisements on the final search result page. Offine experiments using large-scale query logs and online A/B tests demonstrate the superiority of the proposed click-oblivious relevance model and the important roles that relevance plays in sponsored search.",2016,Conference on Information and Knowledge Management,organic search;world wide web;information retrieval;data mining;computer science;
Mobile App Retrieval for Social Media Users via Inference of Implicit Intent in Social Media Text,Dae Hoon Park (Yahoo!);Yi Fang (Santa Clara University);Mengwen Liu (Drexel University);Cheng Xiang Zhai (University of Illinois at Urbana–Champaign);,"2103089955,2158128598,2130457613,2152766206","People often implicitly or explicitly express their needs in social media in the form of ""user status text"". Such text can be very useful for service providers and product manufacturers to proactively provide relevant services or products that satisfy people's immediate needs. In this paper, we study how to infer a user's intent based on the user's ""status text"" and retrieve relevant mobile apps that may satisfy the user's needs. We address this problem by framing it as a new entity retrieval task where the query is a user's status text and the entities to be retrieved are mobile apps. We first propose a novel approach that generates a new representation for each query. Our key idea is to leverage social media to build parallel corpora that contain implicit intention text and the corresponding explicit intention text. Specifically, we model various user intentions in social media text using topic models, and we predict user intention in a query that contains implicit intention. Then, we retrieve relevant mobile apps with the predicted user intention. We evaluate the mobile app retrieval task using a new data set we create. Experiment results indicate that the proposed model is effective and outperforms the state-of-the-art retrieval models.",2016,Conference on Information and Knowledge Management,internet privacy;multimedia;world wide web;information retrieval;data mining;database;computer science;
Combining Powers of Two Predictors in Optimizing Real-Time Bidding Strategy under Constrained Budget,Chi-Chun Lin (National Taiwan University);Kun-Ta Chuang (National Cheng Kung University);Wush Chi-Hsuan Wu (National Taiwan University);Ming-Syan Chen (National Taiwan University);,"2536781376,2124692862,2103160970,2122365371","We address the bidding strategy design problem faced by a Demand-Side Platform (DSP) in Real-Time Bidding (RTB) advertising. A RTB campaign consists of various parameters and usually a predefined budget. Under the budget constraint of a campaign, designing an optimal strategy for bidding on each impression to acquire as many clicks as possible is a main job of a DSP. State-of-the-art bidding algorithms rely on a single predictor, namely the clickthrough rate (CTR) predictor, to calculate the bidding value for each impression. This provides reasonable performance if the predictor has appropriate accuracy in predicting the probability of user clicking. However when the predictor gives only moderate accuracy, classical algorithms fail to capture optimal results. We improve the situation by accomplishing an additional winning price predictor in the bidding process. In this paper, a method combining powers of two prediction models is proposed, and experiments with real world RTB datasets from benchmarking the new algorithm with a classic CTR-only method are presented. The proposed algorithm performs better with regard to both number of clicks achieved and effective cost per click in many different settings of budget constraints.",2016,Conference on Information and Knowledge Management,real time bidding;simulation;
Building Industry-specific Knowledge Bases,Shivakumar Vaithyanathan (IBM);,2231410880,"Building industry-specific knowledge bases relies heavily on collecting and representing domain knowledge over time. Domain knowledge includes: (1) the logical schema, constraints and domain vocabulary of the application, (2) the models and algorithms to populate instances of that schema, and (3) the data necessary to build and maintain those models and algorithms. In IBM Watson we are using an ontology-driven approach for the creation and consumption of industry-specific knowledge bases. The creation of such knowledge bases involves well known building blocks: natural language processing, entity resolution, data transformation, etc. It is critical that the models and algorithms that implement these building blocks be transparent and optimizable for efficient execution. In this talk, I will describe the design of domain-specific languages (DSL) with specialized constructs that serve as target languages for learning these models and algorithms, and the generation of training data for scaling up the learning.",2016,Conference on Information and Knowledge Management,random walk;knowledge extraction;theoretical computer science;natural language processing;world wide web;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Influence Maximization for Complementary Goods: Why Parties Fail to Cooperate?,Han-Ching Ou (National Taiwan University);Chung-Kuang Chou (National Taiwan University);Ming-Syan Chen (National Taiwan University);,"2676756609,2151728411,2122365371","We consider the problem where companies provide different types of products and want to promote their products through viral marketing simultaneously. Most previous works assume products are purely competitive. Different from them, our work considers that each product has a pairwise relationship which can be from strongly competitive to strongly complementary to each other's product. The problem is to maximize the spread size with the presence of different opponents with different relationships on the network. We propose Interacting Influence Maximization (IIM) game to model such problems by extending the model of the Competitive Influence Maximization (CIM) game studied by previous works, which considers purely competitive relationship. As for the theoretical approach, we prove that the Nash equilibrium of highly complementary products of different companies may still be very inefficient due to the selfishness of companies. We do so by introducing a well-known concept in game theory, called Price of Stability (PoS) of the extensive-form game. We prove that in any k selfish players symmetric complementary IIM game, the overall spread of the products can be reduced to as less as 1/ k of the optimal spread. Since companies may fail to cooperate with one another, we propose different competitive objective functions that companies may consider and deal with separately. We propose a scalable strategy for maximizing influence differences, called TOPBOSS that is guaranteed to beat the first player in a single-round two-player second-move game. In the experiment, we first propose a learning method to learn the ILT model, which we propose for IIM game, from both synthetic and real data to validate the effectiveness of ILT. We then exhibit that the performance of several heuristic strategies in the traditional influence maximization problem can be improved by acquiring the knowledge of the existence of competitive/complementary products in the network. Finally, we compare the TOPBOSS with different heuristic algorithms in real data and demonstrate the merits of TOPBOSS.",2016,Conference on Information and Knowledge Management,non cooperative game;repeated game;diffusion;game theory;data mining;artificial intelligence;machine learning;simulation;
Supervised Robust Discrete Multimodal Hashing for Cross-Media Retrieval,Ting-Kun Yan (Shandong University);Xin-Shun Xu (Shandong University);Shanqing Guo (Shandong University);Zi Huang (University of Queensland);Xiao-Lin Wang (Shandong University);,"2538592094,2692499107,2714044890,2671729316,2106514957","Recently, multimodal hashing techniques have received considerable attention due to their low storage cost and fast query speed for multimodal data retrieval. Many methods have been proposed; however, there are still some problems that need to be further considered. For example, some of these methods just use a similarity matrix for learning hash functions which will discard some useful information contained in original data; some of them relax binary constraints or separate the process of learning hash functions and binary codes into two independent stages to bypass the obstacle of handling the discrete constraints on binary codes for optimization, which may generate large quantization error; some of them are not robust to noise. All these problems may degrade the performance of a model. To consider these problems, in this paper, we propose a novel supervised hashing framework for cross-modal retrieval, i.e., Supervised Robust Discrete Multimodal Hashing (SRDMH). Specifically, SRDMH tries to make final binary codes preserve label information as same as that in original data so that it can leverage more label information to supervise the binary codes learning. In addition, it learns hashing functions and binary codes directly instead of relaxing the binary constraints so as to avoid large quantization error problem. Moreover, to make it robust and easy to solve, we further integrate a flexible l 2, p loss with nonlinear kernel embedding and an intermediate presentation of each instance. Finally, an alternating algorithm is proposed to solve the optimization problem in SRDMH. Extensive experiments are conducted on three benchmark data sets. The results demonstrate that the proposed method (SRDMH) outperforms or is comparable to several state-of-the-art methods for cross-modal retrieval task.",2016,Conference on Information and Knowledge Management,hopscotch hashing;k independent hashing;2 choice hashing;feature hashing;locality preserving hashing;double hashing;dynamic perfect hashing;open addressing;universal hashing;locality sensitive hashing;hash function;hash table;theoretical computer science;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;computer science;
A Fatigue Strength Predictor for Steels Using Ensemble Data Mining: Steel Fatigue Strength Predictor,Ankit Agrawal (Northwestern University);Alok N. Choudhary (Northwestern University);,"2160807299,2147783234","Fatigue strength is one of the most important mechanical properties of steel. High cost and time for fatigue testing, and potentially disastrous consequences of fatigue failures motivates the development of predictive models for this property. We have developed advanced data-driven ensemble predictive models for this purpose with an extremely high cross-validated accuracy of >98\%, and have deployed these models in a user-friendly online web-tool, which can make very fast predictions of fatigue strength for a given steel represented by its composition and processing information. Such a tool with fast and accurate models is expected to be a very useful resource for the materials science researchers and practitioners to assist in their search for new and improved quality steels. The web-tool is available at http://info.eecs.northwestern.edu/SteelFatigueStrengthPredictor",2016,Conference on Information and Knowledge Management,materials informatics;fatigue limit;ensemble learning;supervised learning;machine learning;simulation;computer science;
User Response Learning for Directly Optimizing Campaign Performance in Display Advertising,Kan Ren (Shanghai Jiao Tong University);Weinan Zhang (Shanghai Jiao Tong University);Yifei Rong;Haifeng Zhang (Peking University);Yong Yu (Shanghai Jiao Tong University);Jun Wang (University College London);,"2277084468,2527611484,2343807655,2575368951,2119244895,2557836567","Learning and predicting user responses, such as clicks and conversions, are crucial for many Internet-based businesses including web search, e-commerce, and online advertising. Typically, a user response model is established by optimizing the prediction accuracy, e.g., minimizing the error between the prediction and the ground truth user response. However, in many practical cases, predicting user responses is only part of a rather larger predictive or optimization task, where on one hand, the accuracy of a user response prediction determines the final (expected) utility to be optimized, but on the other hand, its learning may also be influenced from the follow-up stochastic process. It is, thus, of great interest to optimize the entire process as a whole rather than treat them independently or sequentially. In this paper, we take real-time display advertising as an example, where the predicted user's ad click-through rate (CTR) is employed to calculate a bid for an ad impression in the second price auction. We reformulate a common logistic regression CTR model by putting it back into its subsequent bidding context: rather than minimizing the prediction error, the model parameters are learned directly by optimizing campaign profit. The gradient update resulted from our formulations naturally fine-tunes the cases where the market competition is high, leading to a more cost-effective bidding. Our experiments demonstrate that, while maintaining comparable CTR prediction accuracy, our proposed user response learning leads to campaign profit gains as much as 78.2% for offline test and 25.5% for online A/B test over strong baselines.",2016,Conference on Information and Knowledge Management,real time bidding;world wide web;data mining;database;artificial intelligence;machine learning;simulation;
Empowering Truth Discovery with Multi-Truth Prediction,Xianzhi Wang (University of New South Wales);Quan Z. Sheng (University of Adelaide);Lina Yao (University of New South Wales);Xue Li (University of Queensland);Xiu Susie Fang (University of Adelaide);Xiaofei Xu (Harbin Institute of Technology);Boualem Benatallah (University of New South Wales);,"2706456112,1740996049,2223456168,2239470812,2147043350,2130531517,2038216534","Truth discovery is the problem of detecting true values from the conflicting data provided by multiple sources on the same data items. Since sources' reliability is unknown a priori , a truth discovery method usually estimates sources' reliability along with the truth discovery process. A major limitation of existing truth discovery methods is that they commonly assume exactly one true value on each data item and therefore cannot deal with the more general case that a data item may have multiple true values (or multi-truth ). Since the number of true values may vary from data item to data item, this requires truth discovery methods being able to detect varying numbers of truth values from the multi-source data. In this paper, we propose a multi-truth discovery approach, which addresses the above challenges by providing a generic framework for enhancing existing truth discovery methods. In particular, we redeem the numbers of true values as an important clue for facilitating multi-truth discovery. We present the procedure and components of our approach, and propose three models, namely the byproduct model, the joint model, and the synthesis model to implement our approach. We further propose two extensions to enhance our approach, by leveraging the implications of similar numerical values and values' co-occurrence information in sources' claims to improve the truth discovery accuracy. Experimental studies on real-world datasets demonstrate the effectiveness of our approach.",2016,Conference on Information and Knowledge Management,single version of the truth;data science;data mining;artificial intelligence;computer science;
Paired Restricted Boltzmann Machine for Linked Data,Suhang Wang (Arizona State University);Jiliang Tang (Michigan State University);Fred Morstatter (Arizona State University);Huan Liu (Arizona State University);,"2122735199,2147392410,107712532,2122391114","Restricted Boltzmann Machines (RBMs) are widely adopted unsupervised representation learning methods and have powered many data mining tasks such as collaborative filtering and document representation. Recently, linked data that contains both attribute and link information has become ubiquitous in various domains. For example, social media data is inherently linked via social relations and web data is networked via hyperlinks. It is evident from recent work that link information can enhance a number of real-world applications such as clustering and recommendations. Therefore, link information has the potential to advance RBMs for better representation learning. However, the majority of existing RBMs have been designed for independent and identically distributed data and are unequipped for linked data. In this paper, we aim to design a new type of Restricted Boltzmann Machines that takes advantage of linked data. In particular, we propose a paired Restricted Boltzmann Machine (pRBM), which is able to leverage the attribute and link information of linked data for representation learning. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework pRBM.",2016,Conference on Information and Knowledge Management,restricted boltzmann machine;linked data;theoretical computer science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Forecasting Seasonal Time Series Using Weighted Gradient RBF Network based Autoregressive Model,Wenjie Ruan (University of Adelaide);Quan Z. Sheng (University of Adelaide);Peipei Xu (University of Electronic Science and Technology of China);Nguyen Khoi Tran (University of Adelaide);Nickolas J.G. Falkner (University of Adelaide);Xue Li (University of Queensland);Wei Emma Zhang (University of Adelaide);,"2148844920,1740996049,2532541266,2343944561,2309817396,2239470812,2104649335","How to accurately forecast seasonal time series is very important for many business area such as marketing decision, planning production and profit estimation. In this paper, we propose a weighted gradient Radial Basis Function Network based AutoRegressive (WGRBF-AR) model for modeling and predicting the nonlinear and non-stationary seasonal time series. This WGRBF-AR model is a synthesis of the weighted gradient RBF network and the functional-coefficient autoregressive (FAR) model through using the WGRBF networks to approximate varying coefficients of FAR model. It not only takes the advantages of the FAR model in nonlinear dynamics description but also inherits the capability of the WGRBF network to deal with non-stationarity. We test our model using ten-years retail sales data on five different commodity in US. The results demonstrate that the proposed WGRBF-AR model can achieve competitive prediction accuracy compared with the state-of-the-art.",2016,Conference on Information and Knowledge Management,nonlinear autoregressive exogenous model;autoregressive integrated moving average;star model;prediction;time series;artificial neural network;data mining;machine learning;statistics;computer science;
Studying the Dark Triad of Personality through Twitter Behavior,Daniel Preotiuc-Pietro (University of Pennsylvania);Jordan Carpenter (University of Pennsylvania);Salvatore Giorgi (University of Pennsylvania);Lyle H. Ungar (University of Pennsylvania);,"2656145732,2103594197,2593249665,2147282416","Research into the darker traits of human nature is growing in interest especially in the context of increased social media usage. This allows users to express themselves to a wider online audience. We study the extent to which the standard model of dark personality -- the dark triad -- consisting of narcissism, psychopathy and Machiavellianism, is related to observable Twitter behavior such as platform usage, posted text and profile image choice. Our results show that we can map various behaviors to psychological theory and study new aspects related to social media usage. Finally, we build a machine learning algorithm that predicts the dark triad of personality in out-of-sample users with reliable accuracy.",2016,Conference on Information and Knowledge Management,dark triad;social media;personality;multimedia;computer science;
When Sensor Meets Tensor: Filling Missing Sensor Values Through a Tensor Approach,Wenjie Ruan (University of Adelaide);Peipei Xu (University of Electronic Science and Technology of China);Quan Z. Sheng (University of Adelaide);Nguyen Khoi Tran (University of Adelaide);Nickolas J.G. Falkner (University of Adelaide);Xue Li (University of Queensland);Wei Emma Zhang (University of Adelaide);,"2148844920,2532541266,1740996049,2343944561,2309817396,2239470812,2104649335","In the era of the Internet of Things, enormous number of sensors have been deployed in different locations, generating massive time-series sensory data with geo-tags. However, such sensory readings are easily missing due to various reasons such as the hardware malfunction, connection errors, and data corruption. This paper focuses on this challenge--how to accurately yet efficiently recover the missing values for corrupted time-series sensor data with geo-stamps. In this paper, we formulate the time-series sensor data as a 3-order tensor that naturally preserves sensors' temporal and spatial dependencies. Then we exploit its low-rank and sparse-noise structures by drawing upon recent advances in Robust Principal Component Analysis (RPCA) and tensor completion theory. The main novelty of this paper lies in that, we design a highly efficient optimization method that combines the alternating direction method of multipliers and accelerated proximal gradient to recover the data tensor. Besides testing our method using the synthetic data, we also design a real-world testbed by passive RFID (RadioFrequency IDentification) sensors. The results demonstrate the effectiveness and accuracy of our approach.",2016,Conference on Information and Knowledge Management,radio frequency identification;tensor;data mining;artificial intelligence;machine learning;computer science;
Noise-Contrastive Estimation for Answer Selection with Deep Neural Networks,"Jinfeng Rao (University of Maryland, College Park);Hua He (University of Maryland, College Park);Jimmy J. Lin (University of Waterloo);","2159906317,2282970130,2163619555","We study answer selection for question answering, in which given a question and a set of candidate answer sentences, the goal is to identify the subset that contains the answer. Unlike previous work which treats this task as a straightforward pointwise classification problem, we model this problem as a ranking task and propose a pairwise ranking approach that can directly exploit existing pointwise neural network models as base components. We extend the Noise-Contrastive Estimation approach with a triplet ranking loss function to exploit interactions in triplet inputs over the question paired with positive and negative examples. Experiments on TrecQA and WikiQA datasets show that our approach achieves state-of-the-art effectiveness without the need for external knowledge sources or feature engineering.",2016,Conference on Information and Knowledge Management,learning to rank;question answering;natural language processing;information retrieval;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
Learning to Extract Conditional Knowledge for Question Answering using Dialogue,Pengwei Wang (South China University of Technology);Lei Ji (Microsoft);Jun Yan (Microsoft);Lianwen Jin (South China University of Technology);Wei-Ying Ma (Microsoft);,"2501582042,2106100428,2150635322,2719437060,2134693834","Knowledge based question answering (KBQA) has attracted much attention from both academia and industry in the field of Artificial Intelligence. However, many existing knowledge bases (KBs) are built by static triples. It is hard to answer user questions with different conditions, which will lead to significant answer variances in questions with similar intent. In this work, we propose to extract conditional knowledge base (CKB) from user question-answer pairs for answering user questions with different conditions through dialogue. Given a subject, we first learn user question patterns and conditions. Then we propose an embedding based co-clustering algorithm to simultaneously group the patterns and conditions by leveraging the answers as supervisor information. After that, we extract the answers to questions conditioned on both question pattern clusters and condition clusters as a CKB. As a result, when users ask a question without clearly specifying the conditions, we use dialogues in natural language to chat with users for question specification and answer retrieval. Experiments on real question answering (QA) data show that the dialogue model using automatically extracted CKB can more accurately answer user questions and significantly improve user satisfaction for questions with missing conditions.",2016,Conference on Information and Knowledge Management,question answering;knowledge management;information retrieval;data mining;database;computer science;
Document Filtering for Long-tail Entities,Ridho Reinanda (University of Amsterdam);Edgar Meij (Bloomberg L.P.);Maarten de Rijke (University of Amsterdam);,"2253770876,2160283388,401833296","Filtering relevant documents with respect to entities is an essential task in the context of knowledge base construction and maintenance. It entails processing a time-ordered stream of documents that might be relevant to an entity in order to select only those that contain vital information. State-of-the-art approaches to document filtering for popular entities are entity-dependent: they rely on and are also trained on the specifics of differentiating features for each specific entity. Moreover, these approaches tend to use so-called extrinsic information such as Wikipedia page views and related entities which is typically only available only for popular head entities. Entity-dependent approaches based on such signals are therefore ill-suited as filtering methods for long-tail entities. In this paper we propose a document filtering method for long-tail entities that is entity-independent and thus also generalizes to unseen or rarely seen entities. It is based on intrinsic features, i.e., features that are derived from the documents in which the entities are mentioned. We propose a set of features that capture informativeness, entity-saliency, and timeliness. In particular, we introduce features based on entity aspect similarities, relation patterns, and temporal expressions and combine these with standard features for document filtering. Experiments following the TREC KBA 2014 setup on a publicly available dataset show that our model is able to improve the filtering performance for long-tail entities over several baselines. Results of applying the model to unseen entities are promising, indicating that the model is able to learn the general characteristics of a vital document. The overall performance across all entities---i.e., not just long-tail entities---improves upon the state-of-the-art without depending on any entity-specific training data.",2016,Conference on Information and Knowledge Management,weak entity;semantic search;world wide web;information retrieval;data mining;computer science;
XKnowSearch!: Exploiting Knowledge Bases for Entity-based Cross-lingual Information Retrieval,Lei Zhang (Karlsruhe Institute of Technology);Michael Färber (Karlsruhe Institute of Technology);Achim Rettinger (Karlsruhe Institute of Technology);,"2633760533,2234226910,2050175453","In recent years, the amount of entities in large knowledge bases available on the Web has been increasing rapidly, making it possible to propose new ways of intelligent information access. Within the context of globalization, there is a clear need for techniques and systems that can enable multilingual and cross-lingual information access. In this paper, we present XKnowSearch!, a novel entity-based system for multilingual and cross-lingual information retrieval, which supports keyword search and also allows users to influence the search process according to their search intents. By leveraging the multilingual knowledge base on the Web, keyword queries and documents can be represented in their semantic forms, which can facilitate query disambiguation and expansion, and can also overcome the language barrier between queries and documents in different languages.",2016,Conference on Information and Knowledge Management,natural language processing;information retrieval;data mining;computer science;
Improving Entity Ranking for Keyword Queries,John Foley (University of Massachusetts Amherst);Brendan O'Connor (University of Massachusetts Amherst);James Allan (University of Massachusetts Amherst);,"2250569144,2604885170,2097030689","Knowledge bases about entities are an important part of modern information retrieval systems. A strong ranking of entities can be used to enhance query understanding and document retrieval or can be presented as another vertical to the user. Given a keyword query, our task is to provide a ranking of the entities present in the collection of interest. We are particularly interested in approaches to this problem that generalize to different knowledge bases and different collections. In the past, this kind of problem has been explored in the enterprise domain through Expert Search. Recently, a dataset was introduced for entity ranking from news and web queries from more general TREC collections. Approaches from prior work leverage a wide variety of lexical resources: e.g., natural language processing and relations in the knowledge base. We address the question of whether we can achieve competitive performance with minimal linguistic resources. We propose a set of features that do not require index-time entity linking, and demonstrate competitive performance on the new dataset. As this paper is the first non-introductory work to leverage this new dataset, we also find and correct certain aspects of the benchmark. To support a fair evaluation, we collect 38% more judgments and contribute annotator agreement information.",2016,Conference on Information and Knowledge Management,ranking;natural language processing;world wide web;information retrieval;data mining;database;computer science;
CyberRank: Knowledge Elicitation for Risk Assessment of Database Security,Hagit Grushka - Cohen (Ben-Gurion University of the Negev);Oded Sofer (IBM);Ofer Biller (IBM);Bracha Shapira (Ben-Gurion University of the Negev);Lior Rokach (Ben-Gurion University of the Negev);,"2619722740,2533787673,2558574783,1966632966,1979308116","Security systems for databases produce numerous alerts about anomalous activities and policy rule violations. Prioritizing these alerts will help security personnel focus their efforts on the most urgent alerts. Currently, this is done manually by security experts that rank the alerts or define static risk scoring rules. Existing solutions are expensive, consume valuable expert time, and do not dynamically adapt to changes in policy. Adopting a learning approach for ranking alerts is complex due to the efforts required by security experts to initially train such a model. The more features used, the more accurate the model is likely to be, but this will require the collection of a greater amount of user feedback and prolong the calibration process. In this paper, we propose CyberRank, a novel algorithm for automatic preference elicitation that is effective for situations with limited experts' time and outperforms other algorithms for initial training of the system. We generate synthetic examples and annotate them using a model produced by Analytic Hierarchical Processing (AHP) to bootstrap a preference learning algorithm. We evaluate different approaches with a new dataset of expert ranked pairs of database transactions, in terms of their risk to the organization. We evaluated using manual risk assessments of transaction pairs, CyberRank outperforms all other methods for cold start scenario with error reduction of 20%.",2016,Conference on Information and Knowledge Management,cold start;ranking;risk assessment;data science;world wide web;computer security;data mining;database;machine learning;statistics;computer science;
CrowdSelect: Increasing Accuracy of Crowdsourcing Tasks through Behavior Prediction and User Selection,Chenxi Qiu (Pennsylvania State University);Anna Cinzia Squicciarini (Pennsylvania State University);Barbara Carminati (University of Insubria);James Caverlee (Texas A&M University);Dev Rishi Khare (Pennsylvania State University);,"2533784963,2310372355,103678462,2028974103,2533742645","Crowdsourcing allows many people to complete tasks of various difficulty with minimal recruitment and administration costs. However, the lack of participant accountability may entice people to complete as many tasks as possible without fully engaging in them, jeopardizing the quality of responses. In this paper, we present a dynamic and time efficient solution to the task assignment problem in crowdsourcing platforms. Our proposed approach, CrowdSelect, offers a theoretically proven algorithm to assign workers to tasks in a cost efficient manner, while ensuring high accuracy of the overall task. In contrast to existing works, our approach makes minimal assumptions on the probability of error for workers, and completely removes the assumptions that such probability is known apriori and that it remains consistent over time. Through experiments over real Amazon Mechanical Turk traces and synthetic data, we find that CrowdSelect has a significant gain in term of accuracy compared to state-of-the-art algorithms, and can provide a 17.5\% gain in answers' accuracy compared to previous methods, even when there are over 50\% malicious workers.",2016,Conference on Information and Knowledge Management,crowdsourcing;data science;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Tag-Aware Personalized Recommendation Using a Deep-Semantic Similarity Model with Negative Sampling,Zhenghua Xu (University of Oxford);Cheng Chen (Beijing University of Posts and Telecommunications);Thomas Lukasiewicz (University of Oxford);Yishu Miao (University of Oxford);Xiangwu Meng (Beijing University of Posts and Telecommunications);,"2122531473,2444673349,297530023,2149004533,2678243629","With the rapid growth of social tagging systems, many efforts have been put on tag-aware personalized recommendation. However, due to uncontrolled vocabularies, social tags are usually redundant, sparse, and ambiguous. In this paper, we propose a deep neural network approach to solve this problem by mapping both the tag-based user and item profiles to an abstract deep feature space, where the deep-semantic similarities between users and their target items (resp., irrelevant items) are maximized (resp., minimized). Due to huge numbers of online items, the training of this model is usually computationally expensive in the real-world context. Therefore, we introduce negative sampling, which significantly increases the model's training efficiency (109.6 times quicker) and ensures the scalability in practice. Experimental results show that our model can significantly outperform the state-of-the-art baselines in tag-aware personalized recommendation: e.g., its mean reciprocal rank is between 5.7 and 16.5 times better than the baselines.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Survival Analysis based Framework for Early Prediction of Student Dropouts,Sattar Ameri (Wayne State University);Mahtab Jahanbani Fard (Wayne State University);Ratna Babu Chinnam (Wayne State University);Chandan K. Reddy (Virginia Tech);,"2500174339,2486966105,2129052378,2100435683","Retention of students at colleges and universities has been a concern among educators for many decades. The consequences of student attrition are significant for students, academic staffs and the universities. Thus, increasing student retention is a long term goal of any academic institution. The most vulnerable students are the freshman, who are at the highest risk of dropping out at the beginning of their study. Therefore, the early identification of {\emph{``at-risk''}} students is a crucial task that needs to be effectively addressed. In this paper, we develop a survival analysis framework for early prediction of student dropout using Cox proportional hazards regression model (Cox). We also applied time-dependent Cox (TD-Cox), which captures time-varying factors and can leverage those information to provide more accurate prediction of student dropout. For this prediction task, our model utilizes different groups of variables such as demographic, family background, financial, high school information, college enrollment and semester-wise credits. The proposed framework has the ability to address the challenge of predicting dropout students as well as the semester that the dropout will occur. This study enables us to perform proactive interventions in a prioritized manner where limited academic resources are available. This is critical in the student retention problem because not only correctly classifying whether a student is going to dropout is important but also when this is going to happen is crucial for a focused intervention. We evaluate our method on real student data collected at Wayne State University. Results show that the proposed Cox-based framework can predict the student dropouts and semester of dropout with high accuracy and precision compared to the other state-of-the-art methods.",2016,Conference on Information and Knowledge Management,survival analysis;regression;biological classification;data science;simulation;statistics;
Finding News Citations for Wikipedia,Besnik Fetahu (Leibniz University of Hanover);Katja Markert (Heidelberg University);Wolfgang Nejdl (Leibniz University of Hanover);Avishek Anand (Leibniz University of Hanover);,"2086402540,2565055383,2228144965,2576154677","An important editing policy in Wikipedia is to provide citations for added statements in Wikipedia pages, where statements can be arbitrary pieces of text, ranging from a sentence to a paragraph. In many cases citations are either outdated or missing altogether. In this work we address the problem of finding and updating news citations for statements in entity pages. We propose a two-stage supervised approach for this problem. In the first step, we construct a classifier to find out whether statements need a news citation or other kinds of citations (web, book, journal, etc.). In the second step, we develop a news citation algorithm for Wikipedia statements, which recommends appropriate citations from a given news collection. Apart from IR techniques that use the statement to query the news collection, we also formalize three properties of an appropriate citation, namely: (i) the citation should entail the Wikipedia statement, (ii) the statement should be central to the citation, and (iii) the citation should be from an authoritative source. We perform an extensive evaluation of both steps, using 20 million articles from a real-world news collection. Our results are quite promising, and show that we can perform this task with high precision and at scale.",2016,Conference on Information and Knowledge Management,brand;world wide web;information retrieval;data mining;computer science;
Regularizing Structured Classifier with Conditional Probabilistic Constraints for Semi-supervised Learning,"Vincent Wenchen Zheng (Agency for Science, Technology and Research);Kevin Chen-Chuan Chang (University of Illinois at Urbana–Champaign);","2084826970,2096749051","Constraints have been shown as an effective way to incorporate unlabeled data for semi-supervised structured classification. We recognize that, constraints are often conditional and probabilistic; moreover, a constraint can have its condition depend on either just observations (which we call x-type constraint) or even hidden variables (which we call y-type constraint). We wish to design a constraint formulation that can flexibly model the constraint probability for both x-type and y-type constraints, and later use it to regularize general structured classifiers for semi-supervision. Surprisingly, none of the existing models have such a constraint formulation. Thus in this paper, we propose a new conditional probabilistic formulation for modeling both x-type and y-type constraints. We also recognize the inference complication for y-type constraint, and propose a systematic selective evaluation approach to efficiently realize the constraints. Finally, we evaluate our model in three applications, including named entity recognition, part-of-speech tagging and entity information extraction, with totally nine data sets. We show that our model is generally more accurate and efficient than the state-of-the-art baselines. Our code and data are available at https://bitbucket.org/vwz/cikm2016-cpf/.",2016,Conference on Information and Knowledge Management,hybrid algorithm;constraint learning;binary constraint;constraint graph;constraint logic programming;constraint programming;constraint satisfaction;constraint;data mining;pattern recognition;machine learning;computer science;
User Modeling on Twitter with WordNet Synsets and DBpedia Concepts for Personalized Recommendations,"Guangyuan Piao (National University of Ireland, Galway);John G. Breslin (National University of Ireland, Galway);","2480903714,1967266261","User modeling of individual users on the Social Web platforms such as Twitter plays a significant role in providing personalized recommendations and filtering interesting information from social streams. Recently, researchers proposed the use of concepts (e.g., DBpedia entities) for representing user interests instead of word-based approaches, since Knowledge Bases such as DBpedia provide cross-domain background knowledge about concepts, and thus can be used for extending user interest profiles. Even so, not all concepts can be covered by a Knowledge Base, especially in the case of microblogging platforms such as Twitter where new concepts/topics emerge everyday. In this short paper, instead of using concepts alone, we propose using synsets from WordNet and concepts from DBpedia for representing user interests. We evaluate our proposed user modeling strategies by comparing them with other bag-of-concepts approaches. The results show that using synsets and concepts together for representing user interests improves the quality of user modeling significantly in the context of link recommendations on Twitter.",2016,Conference on Information and Knowledge Management,personalization;user modeling;recommender system;knowledge management;world wide web;data mining;machine learning;computer science;
Regularising Factorised Models for Venue Recommendation using Friends and their Comments,Jarana Manotumruksa (University of Glasgow);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"2232580914,2148910894,336997814","Venue recommendation is an important capability of Location-Based Social Networks such as Yelp and Foursquare. Matrix Factorisation (MF) is a collaborative filtering-based approach that can effectively recommend venues that are relevant to the users' preferences, by training upon either implicit or explicit feedbacks (e.g. check-ins or venue ratings) that these users express about venues. However, MF suffers in that users may only have rated very few venues. To alleviate this problem, recent literature have leveraged additional sources of evidence, e.g. using users' social friendships to reduce the complexity of - or regularise - the MF model, or identifying similar venues based on their comments. This paper argues for a combined regularisation model, where the venues suggested for a user are influenced by friends with similar tastes (as defined by their comments). We propose a MF regularisation technique that seamlessly incorporates both social network information and textual comments, by exploiting word embeddings to estimate a semantic similarity of friends based on their explicit textual feedback, to regularise the complexity of the factorised model. Experiments on a large existing dataset demonstrate that our proposed regularisation model is promising, and can enhance the prediction accuracy of several state-of-the-art matrix factorisation-based approaches.",2016,Conference on Information and Knowledge Management,world wide web;data mining;artificial intelligence;machine learning;
A Comparative Study of Query-biased and Non-redundant Snippets for Structured Search on Mobile Devices,Nikita V. Spirin (University of Illinois at Urbana–Champaign);Alexander S. Kotov (Wayne State University);Karrie G. Karahalios (University of Illinois at Urbana–Champaign);Vassil Mladenov (University of Illinois at Urbana–Champaign);Pavel A. Izhutov (Stanford University);,"2145605135,2123127453,244853069,2537842409,2224212804","To investigate what kind of snippets are better suited for structured search on mobile devices, we built an experimental mobile search application and conducted a task-oriented interactive user study with 36 participants. Four different versions of a search engine result page (SERP) were compared by varying the snippet type (query-biased vs. non-redundant) and the snippet length (two vs. four lines per result). We adopted a within-subjects experiment design and made each participant do four realistic search tasks using different versions of the application. During the study sessions, we collected search logs, ""think-aloud"" comments, and post-task surveys. Each session was finalized with an interview. We found that with non-redundant snippets the participants were able to complete the tasks faster and find more relevant results. Most participants preferred non-redundant snippets and wanted to see more information about each result on the SERP for any snippet type. Yet, the participants felt that the version with query-biased snippets was easier to use. We conclude with a set of practical design recommendations.",2016,Conference on Information and Knowledge Management,mobile search;internet privacy;world wide web;information retrieval;database;computer science;
Distributed Deep Learning for Question Answering,Minwei Feng (IBM);Bing Xiang (IBM);Bowen Zhou (IBM);,"2651107085,2168100440,2142227750","This paper is an empirical study of the distributed deep learning for question answering subtasks: answer selection and question classification. Comparison studies of SGD, MSGD, ADADELTA, ADAGRAD, ADAM/ADAMAX, RMSPROP, DOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental results show that the distributed framework based on the message passing interface can accelerate the convergence speed at a sublinear scale. This paper demonstrates the importance of distributed training. For example, with 48 workers, a 24x speedup is achievable for the answer selection task and running time is decreased from 138.2 hours to 5.81 hours, which will increase the productivity significantly.",2016,Conference on Information and Knowledge Management,deep learning;question answering;information retrieval;data mining;machine learning;computer science;
FIN10K: A Web-based Information System for Financial Report Analysis and Visualization,Yu-Wen Liu (National Chengchi University);Liang-Chih Liu (National Chiao Tung University);Chuan-Ju Wang (Academia Sinica);Ming-Feng Tsai (National Chengchi University);,"2534150353,2567247129,2116246611,2166008087","In this demonstration, we present FIN10K, a web-based information system that facilitates the analysis of textual information in financial reports. The proposed system has three main components: (1) a 10-K Corpus, including an inverted index of financial reports on Form 10-K, several numerical finance measures, and pre-trained word embeddings; (2) an information retrieval system; and (3) two data visualizations of the analyzed results. The system can be of great help in revealing valuable insights within large amounts of textual information. The system is now online available at http: //clip.csie.org/10K/.",2016,Conference on Information and Knowledge Management,data visualization;text mining;world wide web;information retrieval;data mining;database;statistics;computer science;
"On Backup Battery Data in Base Stations of Mobile Networks: Measurement, Analysis, and Optimization",Xiaoyi Fan (Simon Fraser University);Feng Wang (University of Mississippi);Jiangchuan Liu (Simon Fraser University);,"2319326083,2620719578,2099242182","Base stations have been massively deployed nowadays to afford the explosive demand to infrastructure-based mobile networking services, including both cellular networks and commercial WiFi access points. To maintain high service availability, backup battery groups are usually installed on base stations and serve as the only power source during power outages, which can be prevalent in rural areas or during severe weather conditions such as hurricanes or snow storms. Therefore, being able to understand and predict the battery group working condition is of immense technical and commercial importance as the first step towards a cost-effective battery maintenance on minimizing service interruptions. In this paper, we conduct a systematical analysis on a real world dataset collected from the battery groups installed on the base stations of China Mobile, with totally 1,550,032,984 records from July 28th, 2014 to February 17th, 2016. We find that the working condition degradation of a battery group may be accelerated under various situations and can cause premature failures on batteries in the group, which can hardly be captured by nowadays maintenance procedure and easily lead to a power-outage-triggered service interruption to a base station. To this end, we propose BatPro, a battery profiling framework, to precisely extract the features that cause the working condition degradation of the battery group. We formulate the prediction models for both battery voltage and lifetime and develop a series of solutions to yield accurate outputs. By real world trace-driven evaluations, we demonstrate that our BatPro approach can precisely predict the battery voltage and lifetime with the RMS error less than 0.01 v.",2016,Conference on Information and Knowledge Management,world wide web;telecommunications;simulation;
Query Expansion Using Word Embeddings,Saar Kuzi (Technion – Israel Institute of Technology);Anna Shtok (Technion – Israel Institute of Technology);Oren Kurland (Technion – Israel Institute of Technology);,"2521070045,1260992435,2250933759","We present a suite of query expansion methods that are based on word embeddings. Using Word2Vec's CBOW embedding approach, applied over the entire corpus on which search is performed, we select terms that are semantically related to the query. Our methods either use the terms to expand the original query or integrate them with the effective pseudo-feedback-based relevance model. In the former case, retrieval performance is significantly better than that of using only the query, and in the latter case the performance is significantly better than that of the relevance model.",2016,Conference on Information and Knowledge Management,sargable;ranking;boolean conjunctive query;web query classification;query expansion;query optimization;query language;natural language processing;information retrieval;database;computer science;
LICON: A Linear Weighting Scheme for the Contribution ofInput Variables in Deep Artificial Neural Networks,Gjergji Kasneci (Max Planck Society);Thomas Gottron (University of Mainz);,"42507994,223387194","In recent years artificial neural networks have become the method of choice for many pattern recognition tasks. Despite their overwhelming success, a rigorous and easy to interpret mathematical explanation of the influence of input variables on a output produced by a neural network is still missing. We propose a generic framework as well as a concrete method for quantifying the influence of individual input signals on the output computed by a deep neural network. Inspired by the variable weighting scheme in the log-linear combination of variables in logistic regression, the proposed method provides linear models for specific observations of the input variables. This linear model locally approximates the behaviour of the neural network and can be used to quantify the influence of input variables in a principled way. We demonstrate the effectiveness of the proposed method in experiments on various synthetic and real-world datasets.",2016,Conference on Information and Knowledge Management,time delay neural network;artificial neural network;artificial intelligence;machine learning;statistics;computer science;
Probabilistic Approaches to Controversy Detection,Myungha Jang (University of Massachusetts Amherst);John Foley (University of Massachusetts Amherst);Shiri Dori-Hacohen (University of Massachusetts Amherst);James Allan (University of Massachusetts Amherst);,"2508638950,2250569144,687633372,2097030689","Recently, the problem of automated controversy detection has attracted a lot of interest in the information retrieval community. Existing approaches to this problem have set forth a number of detection algorithms, but there has been little effort to model the probability of controversy in a document directly. In this paper, we propose a probabilistic framework to detect controversy on the web, and investigate two models. We first recast a state-of-the-art controversy detection algorithm into a model in our framework. Based on insights from social science research, we also introduce a language modeling approach to this problem. We evaluate different methods of creating controversy language models based on a diverse set of public datasets including Wikipedia, Web and News corpora. Our automatically derived language models show a significant relative improvement of 18% in AUC over prior work,and 23% over two manually curated lexicons.",2016,Conference on Information and Knowledge Management,critical literacy;language model;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Leveraging the Implicit Structure within Social Media for Emergent Rumor Detection,Justin Sampson (Arizona State University);Fred Morstatter (Arizona State University);Liang Wu (Arizona State University);Huan Liu (Arizona State University);,"2231480384,107712532,2666048107,2122391114","The automatic and early detection of rumors is of paramount importance as the spread of information with questionable veracity can have devastating consequences. This became starkly apparent when, in early 2013, a compromised Associated Press account issued a tweet claiming that there had been an explosion at the White House. This tweet resulted in a significant drop for the Dow Jones Industrial Average. Most existing work in rumor detection leverages conversation statistics and propagation patterns, however, such patterns tend to emerge slowly requiring a conversation to have a significant number of interactions in order to become eligible for classification. In this work, we propose a method for classifying conversations within their formative stages as well as improving accuracy within mature conversations through the discovery of implicit linkages between conversation fragments. In our experiments, we show that current state-of-the-art rumor classification methods can leverage implicit links to significantly improve the ability to properly classify emergent conversations when very little conversation data is available. Adopting this technique allows rumor detection methods to continue to provide a high degree of classification accuracy on emergent conversations with as few as a single tweet. This improvement virtually eliminates the delay of conversation growth inherent in current rumor classification methods while significantly increasing the number of conversations considered viable for classification.",2016,Conference on Information and Knowledge Management,social media;world wide web;artificial intelligence;computer science;
Pagination versus Scrolling in Mobile Web Search,Jaewon Kim (Australian National University);Paul Thomas (Microsoft);Ramesh Sankaranarayana (Australian National University);Tom Gedeon (Australian National University);Hwan-Jin Yoon (Australian National University);,"2235242638,2721559101,317343192,2052936527,2159953223","Vertical scrolling is the standard method of exploring search results pages. For touch-enabled mobile devices that are not equipped with a mouse or keyboard, we adopt other methods of controlling the viewport with the aim of investigating user interaction. From the intuition that people are used to reading books by turning pages horizontally, we conducted a user experiment to investigate the effects of horizontal and vertical control types ( pagination versus scrolling ) on a touch-enabled mobile phone. Our findings suggest that participants using pagination were more likely to find relevant documents, especially those over the fold; spent more time attending to relevant results; and were faster to click while spending less time on the search result pages overall. We also found that the main reason for the difference in search speed is the time taken for the scroll itself. We conclude that search engines need to provide different viewport controls to allow better search experiences on touch-enabled mobile devices.",2016,Conference on Information and Knowledge Management,mobile device;human computer interaction;multimedia;world wide web;computer science;
Evaluating Document Retrieval Methods for Resource Selection in Clustered P2P IR,Rami Suleiman Alkhawaldeh (University of Glasgow);Joemon M. Jose (University of Glasgow);Deepak P (Queen's University Belfast);,"2475945334,2167481407,2428233840","Resource Selection (or Query Routing) is an important step in P2P IR. Though analogous to document retrieval in the sense of choosing a relevant subset of resources, resource selection methods have evolved independently from those for document retrieval. Among the reasons for such divergence is that document retrieval targets scenarios where underlying resources are semantically homogeneous, whereas peers would manage diverse content. We observe that semantic heterogeneity is mitigated in the clustered 2-tier P2P IR architecture resource selection layer by way of usage of clustering, and posit that this necessitates a re-look at the applicability of document retrieval methods for resource selection within such a framework. This paper empirically benchmarks document retrieval models against the state-of-the-art resource selection models for the problem of resource selection in the clustered P2P IR architecture, using classical IR evaluation metrics. Our benchmarking study illustrates that document retrieval models significantly outperform other methods for the task of resource selection in the clustered P2P IR architecture. This indicates that clustered P2P IR framework can exploit advancements in document retrieval methods to deliver corresponding improvements in resource selection, indicating potential convergence of these fields for the clustered P2P IR architecture.",2016,Conference on Information and Knowledge Management,evaluation;document clustering;world wide web;information retrieval;data mining;database;computer science;
Towards Representation Independent Similarity Search Over Graph Databases,Yodsawalai Chodpathumwan (University of Illinois at Urbana–Champaign);Amirhossein Aleyasen (University of Illinois at Urbana–Champaign);Arash Termehchy (Oregon State University);Yizhou Sun (Northeastern University);,"33543605,138084862,146765738,2131539564","Finding similar entities is a fundamental problem in graph data analysis. Similarity search algorithms usually leverage the structural properties of the database to quantify the degree of similarity between entities. However, the same information can be represented in different structures and the structural properties observed over particular representations may not hold for the alternatives. These algorithms are effective on some representations and ineffective on others. We define the property of representation independence for similarity search algorithms as their robustness against transformations that modify the structure of databases but preserve the information content. We introduce a widespread group of such transformations called relationship reorganizing . We propose an algorithm called R-PathSim, which is provably robust under relationship reorganizing. Our empirical results show that current algorithms except R-PathSim are highly sensitive to the data representation and R-PathSim is as efficient and effective as other algorithms.",2016,Conference on Information and Knowledge Management,theoretical computer science;data mining;machine learning;
Distilling Word Embeddings: An Encoding Approach,Lili Mou (Peking University);Ran Jia (Peking University);Yan Xu (Peking University);Ge Li (Peking University);Lu Zhang (Peking University);Zhi Jin (Peking University);,"2163770800,2300066876,2615566346,2107721211,2103091586,2155874124","Distilling knowledge from a well-trained cumbersome network to a small one has recently become a new research topic, as lightweight neural networks with high performance are particularly in need in various resource-restricted systems. This paper addresses the problem of distilling word embeddings for NLP tasks. We propose an encoding approach to distill task-specific knowledge from a set of high-dimensional embeddings, so that we can reduce model complexity by a large margin as well as retain high accuracy, achieving a good compromise between efficiency and performance. Experiments reveal the phenomenon that distilling knowledge from cumbersome embeddings is better than directly training neural networks with small embeddings.",2016,Conference on Information and Knowledge Management,artificial neural network;theoretical computer science;natural language processing;machine learning;computer science;
Precision-Oriented Query Facet Extraction,Weize Kong (University of Massachusetts Amherst);James Allan (University of Massachusetts Amherst);,"2167771460,2097030689","Faceted search has been used successfully for many vertical applications such as e-commerce and digital libraries. However, it remains challenging to extend faceted search to the open-domain web due to the large and heterogeneous nature of the web. Recent work proposed an alternative solution that extracts facets for queries from their web search results, but neglected the precision-oriented perspective of the task -- users are likely to care more about precision of presented facets than recall. We improve query facet extraction performance under a precision-oriented scenario from two perspectives. First, we propose an empirical utility maximization approach to learn a probabilistic model by maximizing the expected performance measure instead of likelihood as used in previous approaches. We show that the empirical utility maximization approach can significantly improve over the previous approach under the precision-oriented scenario. Second, instead of showing facets for all queries, we propose a selective method that predicts the extraction performance for each query and selectively shows facets for some of them. We show the selective method can significantly improve the average performance with fair coverage over the whole query set.",2016,Conference on Information and Knowledge Management,web query classification;query expansion;query optimization;data science;data mining;database;machine learning;computer science;
Learning Graph-based POI Embedding for Location-based Recommendation,Min Xie (Chinese Academy of Sciences);Hongzhi Yin (University of Queensland);Hao Wang (Chinese Academy of Sciences);Fanjiang Xu (Chinese Academy of Sciences);Weitong Chen (University of Queensland);Sen Wang (Griffith University);,"2707245646,2145818752,2594397125,2107126444,2659708717,2632687329","With the rapid prevalence of smart mobile devices and the dramatic proliferation of location-based social networks (LBSNs), location-based recommendation has become an important means to help people discover attractive and interesting points of interest (POIs). However, the extreme sparsity of user-POI matrix and cold-start issue create severe challenges, causing CF-based methods to degrade significantly in their recommendation performance. Moreover, location-based recommendation requires spatiotemporal context awareness and dynamic tracking of the user's latest preferences in a real-time manner. To address these challenges, we stand on recent advances in embedding learning techniques and propose a generic graph-based embedding model, called GE, in this paper. GE jointly captures the sequential effect, geographical influence, temporal cyclic effect and semantic effect in a unified way by embedding the four corresponding relational graphs (POI-POI, POI-Region, POI-Time and POI-Word)into a shared low dimensional space. Then, to support the real-time recommendation, we develop a novel time-decay method to dynamically compute the user's latest preferences based on the embedding of his/her checked-in POIs learnt in the latent space. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets, and the experimental results show its superiority over other competitors, especially in recommending cold-start POIs. Besides, we study the contribution of each factor to improve location-based recommendation and find that both sequential effect and temporal cyclic effect play more important roles than geographical influence and semantic effect.",2016,Conference on Information and Knowledge Management,cold start;graph embedding;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Learning Points and Routes to Recommend Trajectories,Dawei Chen (Australian National University);Cheng Soon Ong (Australian National University);Lexing Xie (Australian National University);,"2538635890,2444503237,2100918400","The problem of recommending tours to travellers is an important and broadly studied area. Suggested solutions include various approaches of points-of-interest (POI) recommendation and route planning. We consider the task of recommending a sequence of POIs, that simultaneously uses information about POIs and routes. Our approach unifies the treatment of various sources of information by representing them as features in machine learning algorithms, enabling us to learn from past behaviour. Information about POIs are used to learn a POI ranking model that accounts for the start and end points of tours. Data about previous trajectories are used for learning transition patterns between POIs that enable us to recommend probable routes. In addition, a probabilistic model is proposed to combine the results of POI ranking and the POI to POI transitions. We propose a new F 1 score on pairs of POIs that capture the order of visits. Empirical results show that our approach improves on recent methods, and demonstrate that combining points and routes enables better trajectory recommendations.",2016,Conference on Information and Knowledge Management,planning;learning to rank;data mining;artificial intelligence;machine learning;computer science;
Optimizing Ad Allocation in Social Advertising,Shaojie Tang (University of Texas at Dallas);Jing Yuan (University of Texas at Dallas);,"2627137476,2510269384","Social advertising (or social promotion) is an effective approach that produces a significant cascade of adoption through influence in the online social networks. The goal of this work is to optimize the ad allocation from the platform's perspective. On the one hand, the platform would like to maximize revenue earned from each advertiser by exposing their ads to as many people as possible, on the other hand, the platform wants to reduce free-riding to ensure the truthfulness of the advertiser. To this end, we introduce a utility function that can access the above tradeoff. Based on this utility function, we define and study two social advertising problems: budgeted social advertising problem and unconstrained social advertising problem. In the first problem, we aim at selecting a set of seeds for each advertiser that maximizes the utility while setting budget constraints on the attention cost; in the second problem, we propose to optimize a linear combination of the utility and attention costs. We prove that both problems are NP-hard, and then develop constant factor approximation algorithms for both problems.",2016,Conference on Information and Knowledge Management,submodular set function;matroid;approximation algorithm;mathematical optimization;mathematics;
Targeted Influence Maximization in Social Networks,Chonggang Song (National University of Singapore);Wynne Hsu (National University of Singapore);Mong Li Lee (National University of Singapore);,"2225645568,2123778117,2159408573","Influence maximization (IM) problem asks for a set of k nodes in a given graph G , such that it can reach the largest expected number of remaining nodes in G . Existing methods have either considered that the influence be targeted to meet certain deadline constraint, or be restricted to specific geographical region. However, if an event organizer wants to disseminate some event information on a social platform, s/he would want to select a set of users who can influence the most number of people within the neighborhood of the event location, and this influence should occur before the event takes place. Considering the location and deadline independently may lead to a less than optimal set of users. In this paper, we formalize the problem targeted influence maximization in social networks. We adopt a login model where each user is associated with a login probability and he can be influenced by his neighbors only when he is online. We develop a sampling based algorithm that returns a (1-1/ e -e)-approximate solution, as well as an efficient heuristic algorithm that focuses on nodes close to the target location. Experiments on real-world social network datasets demonstrate the effectiveness and efficiency of our proposed method.",2016,Conference on Information and Knowledge Management,world wide web;data mining;artificial intelligence;machine learning;computer science;
BigNet 2016: First Workshop on Big Network Analytics,Jie Tang (Tsinghua University);Keke Cai (IBM);Zhong Su (IBM);Hanghang Tong (Arizona State University);Michalis Vazirgiannis (École Polytechnique);Yang Yang (Zhejiang University);,"2158012360,2137653166,2305826094,2667261544,1914497179,2629229856","The first ACM international workshop on big network analytics is held in Indianapolis, Indiana, USA on October 24, 2016 and co-located with the ACM 25th Conference on Information and Knowledge Management (CIKM). The main objective of the workshop is to provide a forum for presenting the most recent advances in mining big networks to unearth rich knowledge. It is related to information retrieval, Web mining, social network analysis, and computational advertising. The anticipated outcome includes a fruitful discussion about the emerging challenges in this field, the development of novel theories for mining big networks, and motivating the interesting applications. The broader anticipated outcome includes: fostering future research directions, publishing high quality papers, attracting new researchers to this field, and concrete solutions to the existing problems.",2016,Conference on Information and Knowledge Management,data science;operations research;world wide web;information retrieval;data mining;database;computer science;
Cutty: Aggregate Sharing for User-Defined Windows,Paris Carbone (Royal Institute of Technology);Jonas Traub (Technical University of Berlin);Asterios Katsifodimos (Technical University of Berlin);Seif Haridi (Royal Institute of Technology);Volker Markl (Technical University of Berlin);,"2562695421,2406730525,2225061756,678106963,2682056020","Aggregation queries on data streams are evaluated over evolving and often overlapping logical views called windows. While the aggregation of periodic windows were extensively studied in the past through the use of aggregate sharing techniques such as Panes and Pairs, little to no work has been put in optimizing the aggregation of very common, non-periodic windows. Typical examples of non-periodic windows are punctuations and sessions which can implement complex business logic and are often expressed as user-defined operators on platforms such as Google Dataflow or Apache Storm. The aggregation of such non-periodic or user-defined windows either falls back to expensive, best-effort aggregate sharing methods, or is not optimized at all. In this paper we present a technique to perform efficient aggregate sharing for data stream windows, which are declared as user-defined functions (UDFs) and can contain arbitrary business logic. To this end, we first introduce the concept of User-Defined Windows (UDWs), a simple, UDF-based programming abstraction that allows users to programmatically define custom windows. We then define semantics for UDWs, based on which we design Cutty, a low-cost aggregate sharing technique. Cutty improves and outperforms the state of the art for aggregate sharing on single and multiple queries. Moreover, it enables aggregate sharing for a broad class of non-periodic UDWs. We implemented our techniques on Apache Flink, an open source stream processing system, and performed experiments demonstrating orders of magnitude of reduction in aggregation costs compared to the state of the art.",2016,Conference on Information and Knowledge Management,user defined function;programming paradigm;functional programming;world wide web;data mining;database;programming language;computer science;
Data Summarization with Social Contexts,Hao Zhuang (École Polytechnique Fédérale de Lausanne);Rameez Rahman (École Polytechnique Fédérale de Lausanne);Xia Hu (Texas A&M University);Tian Guo (École Polytechnique Fédérale de Lausanne);Pan Hui (Hong Kong University of Science and Technology);Karl Aberer (École Polytechnique Fédérale de Lausanne);,"2126438575,2699281871,2161448330,2166312522,2100555659,150096297","While social data is being widely used in various applications such as sentiment analysis and trend prediction, its sheer size also presents great challenges for storing, sharing and processing such data. These challenges can be addressed by data summarization which transforms the original dataset into a smaller, yet still useful, subset. Existing methods find such subsets with objective functions based on data properties such as representativeness or informativeness but do not exploit social contexts, which are distinct characteristics of social data. Further, till date very little work has focused on topic preserving data summarization, despite the abundant work on topic modeling. This is a challenging task for two reasons. First, since topic model is based on latent variables, existing methods are not well-suited to capture latent topics. Second, it is difficult to find such social contexts that provide valuable information for building effective topic-preserving summarization model. To tackle these challenges, in this paper, we focus on exploiting social contexts to summarize social data while preserving topics in the original dataset. We take Twitter data as a case study. Through analyzing Twitter data, we discover two social contexts which are important for topic generation and dissemination, namely (i) CrowdExp topic score that captures the influence of both the crowd and the expert users in Twitter and (ii) Retweet topic score that captures the influence of Twitter users' actions. We conduct extensive experiments on two real-world Twitter datasets using two applications. The experimental results show that, by leveraging social contexts, our proposed solution can enhance topic-preserving data summarization and improve application performance by up to 18%.",2016,Conference on Information and Knowledge Management,topic model;social environment;multi document summarization;automatic summarization;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Toward Data-Driven Education: CIKM-2016 Keynote,Rakesh Agrawal (Microsoft);,2537924216,"A program of study can be viewed as a knowledge graph consisting of learning units and relationships between them. Such a knowledge graph provides the core data structure for organizing and navigating learning experiences. We address three issues in this talk. First, how can we synthesize the knowledge graph, given a set of concepts to be covered in the study program. Next, how can we use data mining to identify and correct deficiencies in a knowledge graph. Finally, how can we use data mining to form study groups with the goal of maximizing overall learning. We conclude by pointing out some open research problems.",2016,Conference on Information and Knowledge Management,knowledge extraction;data science;natural language processing;knowledge management;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
EnerQuery: Energy-Aware Query Processing,Amine Roukh (University of Mostaganem);Ladjel Bellatreche (University of Poitiers);Carlos Ordonez (University of Houston);,"2162505081,158375695,2165938062","Energy consumption is increasingly more important in large-scale query processing. This problem requires revisiting traditional query processing in actual DBMSs to identify the potential of energy saving, and to study the trade-offs between energy consumption and performance. In this paper, we propose EnerQuery , a tool built on top of a traditional DBMS to capitalize the efforts invested in building energy-aware query optimizers, which have the lion's share in energy consumption. Energy consumption is estimated on all query plan steps and integrated into a mathematical linear cost model used to select the best query plans. To increase end users' energy awareness, EnerQuery features a diagnostic GUI to visualize energy consumption per step and its savings when tuning key parameters during query execution.",2016,Conference on Information and Knowledge Management,sargable;online aggregation;web query classification;view;query by example;query expansion;query optimization;database design;efficient energy use;world wide web;information retrieval;data mining;database;computer science;
Topological Graph Sketching for Incremental and Scalable Analytics,Bortik Bandyopadhyay (Ohio State University);David Fuhry (Ohio State University);Aniket Chakrabarti (Ohio State University);Srinivasan Parthasarathy (Ohio State University);,"2509701196,2398106800,2098684641,2106796124","We propose a novel, scalable, and principled graph sketching technique based on minwise hashing of local neighborhood. For an n-node graph with e -edges ( e >> n ), we incrementally maintain in real-time a minwise neighbor sampled subgraph using k hash functions in O ( n x k ) memory, limit being user-configurable by the parameter k . Symmetrization and similarity based techniques can recover from these data structures a significant portion of the original graph. We present theoretical analysis of the minwise sampling strategy and also derive unbiased estimators for important graph properties such as triangle count and neighborhood overlap. We perform an extensive empirical evaluation of our graph sketch and it's derivatives on a wide variety of real-world graph data sets drawn from different application domains using important large network analysis algorithms: local and global clustering coefficient, PageRank, and local graph sparsification. With bounded memory, the quality of results using the sketch representation is competitive against baselines which use the full graph, and the computational performance is often better. Our framework is flexible and configurable to be leveraged by numerous other graph analytics algorithms, potentially reducing the information mining time on large streamed graphs for a variety of applications.",2016,Conference on Information and Knowledge Management,factor critical graph;distance hereditary graph;strength of a graph;voltage graph;complement graph;graph bandwidth;graph power;null graph;clique width;graph property;graph;theoretical computer science;data mining;database;machine learning;
Query Answering Efficiency in Expert Networks Under Decentralized Search,"Liang Ma (IBM);Mudhakar Srivatsa (IBM);Derya Cansever;Xifeng Yan (University of California, Santa Barbara);Sue Kase (United States Army Research Laboratory);Michelle Vanni (United States Army Research Laboratory);","2135210208,1449758934,2678809740,2116657824,1553375982,2106593583","Expert networks are formed by a group of expert-profes\-sionals with different specialties to collaboratively resolve specific queries. In such networks, when a query reaches an expert who does not have sufficient expertise, this query needs to be routed to other experts for further processing until it is completely solved; therefore, query answering efficiency is sensitive to the underlying query routing mechanism being used. Among all possible query routing mechanisms, decentralized search, operating purely on each expert's local information without any knowledge of network global structure, represents the most basic and scalable routing mechanism. However, there is still a lack of fundamental understanding of the efficiency of decentralized search in expert networks. In this regard, we investigate decentralized search by quantifying its performance under a variety of network settings. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O (log n ) and O (log 2 n ) hops, n : total number of experts in the network). Based on such theoretical foundation, we then study how the unique properties of decentralized search in expert networks is related to the anecdotal small-world phenomenon. To the best of our knowledge, this is the first work studying fundamental behaviors of decentralized search in expert networks. The developed performance bounds, confirmed by real datasets, can assist in predicting network performance and designing complex expert networks.",2016,Conference on Information and Knowledge Management,web query classification;query expansion;query optimization;world wide web;information retrieval;data mining;database;machine learning;computer science;
Incremental Mining of High Utility Sequential Patterns in Incremental Databases,Jun-Zhe Wang (National Chiao Tung University);Jiun-Long Huang (National Chiao Tung University);,"2110273631,2148510829","High utility sequential pattern (HUSP) mining is an emerging topic in pattern mining, and only a few algorithms have been proposed to address it. In practice, most sequence databases usually grow over time, and it is inefficient for existing algorithms to mine HUSPs from scratch when databases grow with a small portion of updates. In view of this, we propose the IncUSP-Miner algorithm to mine HUSPs incrementally. Specifically, to avoid redundant computations, we propose a tighter upper bound of the utility of a sequence, called TSU, and then design a novel data structure, called the candidate pattern tree, to maintain the sequences whose TSU values are greater than or equal to the minimum utility threshold. Accordingly, to avoid keeping a huge amount of utility information for each sequence, a set of auxiliary utility information is designed to be stored in each tree node. Moreover, for those nodes whose utilities have to be updated, a strategy is also proposed to reduce the amount of computation, thereby improving the mining efficiency. Experimental results on three real datasets show that IncUSP-Miner is able to efficiently mine HUSPs incrementally.",2016,Conference on Information and Knowledge Management,data science;data mining;database;algorithm;computer science;
Efficient Algorithms for the Two Locus Problem in Genome-Wide Association Study: Algorithms for the Two Locus Problem,Sanguthevar Rajasekaran (University of Connecticut);Subrata Saha (University of Connecticut);,"2171202298,2304603059","Advances made in sequencing technology have resulted in the sequencing of thousands of genomes. Novel analysis tools are needed to process these data and extract useful information. Such tools could aid in personalized medicine. As an example, we could identify the causes for a disease by comparing the genomes of people who have the disease and those who do not have this disease. Given that human variability happens due to single nucleotide polymorphisms (SNPs), we could focus our attention on these SNPs. Investigations that try to understand human variability using SNPs fall under genome-wide association study (GWAS). A crucial step in GWAS is the identification of the correlation between genotypes (SNPs) and phenotypes (i.e., characteristics such as the presence of a disease). This step can be modeled as the k -locus problem (where k is any integer). A number of algorithms have been proposed in the literature for this problem when k = 2. In this paper we present an algorithm for solving the 2-locus problem that is up to two orders of magnitude faster than the previous best known algorithms.",2016,Conference on Information and Knowledge Management,genome wide association study;bioinformatics;
"Agents, Simulated Users and Humans: An Analysis of Performance and Behaviour",David Maxwell (University of Glasgow);Leif Azzopardi (University of Strathclyde);,"2465962233,2163026013","Most of the current models that are used to simulate users in Interactive Information Retrieval (IIR) lack realism and agency. Such models generally make decisions in a stochastic manner, without recourse to the actual information encountered or the underlying information need. In this paper, we develop a more sophisticated model of the user that includes their cognitive state within the simulation. The cognitive state maintains data about what the simulated user knows, has done and has seen, along with representations of what it considers attractive and relevant. Decisions to inspect or judge are then made based upon the simulated user's current state, rather than stochastically. In the context of ad-hoc topic retrieval, we evaluate the quality of the simulated users and agents by comparing their behaviour and performance against 48 human subjects under the same conditions, topics, time constraints, costs and search engine. Our findings show that while naive configurations of simulated users and agents substantially outperform our human subjects, their search behaviour is notably different from actual searchers. However, more sophisticated search agents can be tuned to act more like actual searchers providing greater realism. This innovation advances the state of the art in simulation, from simulated users towards autonomous agents. It provides a much needed step forward enabling the creation of more realistic simulations, while also motivating the development of more advanced cognitive agents and tools to help support and augment human searchers. Future work will focus not only on the pragmatics of tuning and training such agents for topic retrieval, but will also look at developing agents for other tasks and contexts such as collaborative search and slow search.",2016,Conference on Information and Knowledge Management,cognitive models of information retrieval;autonomous agent;user modeling;software agent;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Robust Contextual Outlier Detection: Where Context Meets Sparsity,Jiongqian Liang (Ohio State University);Srinivasan Parthasarathy (Ohio State University);,"2238545870,2106796124","Outlier detection is a fundamental data science task with applications ranging from data cleaning to network security. Recently, a new class of outlier detection algorithms has emerged, called contextual outlier detection , and has shown improved performance when studying anomalous behavior in a specific context. However, as we point out in this article, such approaches have limited applicability in situations where the context is sparse (i.e., lacking a suitable frame of reference). Moreover, approaches developed to date do not scale to large datasets. To address these problems, here we propose a novel and robust approach alternative to the state-of-the-art called RObust Contextual Outlier Detection ( ROCOD ). We utilize a local and global behavioral model based on the relevant contexts, which is then integrated in a natural and robust fashion. We run ROCOD on both synthetic and real-world datasets and demonstrate that it outperforms other competitive baselines on the axes of efficacy and efficiency. We also drill down and perform a fine-grained analysis to shed light on the rationale for the performance gains of ROCOD and reveal its effectiveness when handling objects with sparse contexts.",2016,Conference on Information and Knowledge Management,anomaly detection;data mining;pattern recognition;machine learning;computer science;
Mining Shopping Patterns for Divergent Urban Regions by Incorporating Mobility Data,Tianran Hu (University of Rochester);Ruihua Song (Microsoft);Yingzi Wang (University of Science and Technology of China);Xing Xie (Microsoft);Jiebo Luo (University of Rochester);,"2100714073,2163477531,2714836703,2125800575,2059910451","What people buy is an important aspect or view of lifestyles. Studying people's shopping patterns in different urban regions can not only provide valuable information for various commercial opportunities, but also enable a better understanding about urban infrastructure and urban lifestyle. In this paper, we aim to predict citywide shopping patterns. This is a challenging task due to the sparsity of the available data -- over 60% of the city regions are unknown for their shopping records. To address this problem, we incorporate another important view of human lifestyles, namely mobility patterns. With information on ""where people go"", we infer ""what people buy"". Moreover, to model the relations between regions, we exploit spatial interactions in our method. To that end, Collective Matrix Factorization (CMF) with an interaction regularization model is applied to fuse the data from multiple views or sources. Our experimental results have shown that our model outperforms the baseline methods on two standard metrics. Our prediction results on multiple shopping patterns reveal the divergent demands in different urban regions, and thus reflect key functional characteristics of a city. Furthermore, we are able to extract the connection between the two views of lifestyles, and achieve a better or novel understanding of urban lifestyles.",2016,Conference on Information and Knowledge Management,simulation;
DTMBIO 2016: The Tenth International Workshop on Data and Text Mining in Biomedical Informatics,Sangwoo Kim (Yonsei University);Jake Y. Chen (University of Alabama at Birmingham);Vincenzo Cutello (University of Catania);Doheon Lee (KAIST);,"2303845809,2708071001,2131798677,2151057430","Started in 2006 as a specialized workshop in the field of text mining applied to biomedical informatics, DTMBIO (ACM international workshop on Data and Text Mining in Biomedical Informatics) has been held annually in conjunction with one of the largest data management conferences, CIKM, bringing together researchers working on computer science and bioinformatics area. The purpose of DTMBIO is to foster discussions regarding the state-of-the-art applications of data and text mining on biomedical research problems. DTMBIO 2016 will help scientists navigate emerging trends and opportunities in the evolving area of informatics related techniques and problems in the context of biomedical research.",2016,Conference on Information and Knowledge Management,engineering informatics;materials informatics;informatics;biomedical text mining;text mining;data science;information retrieval;data mining;computer science;
A Unified Index for Spatio-Temporal Keyword Queries,Tuan-Anh Hoang-Vu (New York University);Huy T. Vo (City College of New York);Juliana Freire (New York University);,"2228875287,2055039322,2116519607","From tweets to urban data sets, there has been an explosion in the volume of textual data that is associated with both temporal and spatial components. Efficiently evaluating queries over these data is challenging. Previous approaches have focused on the spatial aspect. Some used separate indices for space and text, thus incurring the overhead of storing separate indices and joining their results. Others proposed a combined index that either inserts terms into a spatial structure or adds a spatial structure to an inverted index. These benefit queries with highly-selective constraints that match the primary index structure but have limited effectiveness and pruning power otherwise. We propose a new indexing strategy that uniformly handles text, space and time in a single structure, and is thus able to efficiently evaluate queries that combine keywords with spatial and temporal constraints. We present a detailed experimental evaluation using real data sets which shows that not only our index attains substantially lower query processing times, but it can also be constructed in a fraction of the time required by state-of-the-art approaches.",2016,Conference on Information and Knowledge Management,spatial query;spatial database;k d tree;information retrieval;data mining;database;computer science;
Multi-Dueling Bandits and Their Application to Online Ranker Evaluation,Brian Brost (University of Copenhagen);Yevgeny Seldin (University of Copenhagen);Ingemar J. Cox (University College London);Christina Lioma (University of Copenhagen);,"2504127794,2513281567,2707492096,1619376036","Online ranker evaluation focuses on the challenge of efficiently determining, from implicit user feedback, which ranker out of a finite set of rankers is the best. It can be modeled by dueling bandits , a mathematical model for online learning under limited feedback from pairwise comparisons. Comparisons of pairs of rankers is performed by interleaving their result sets and examining which documents users click on. The dueling bandits model addresses the key issue of which pair of rankers to compare at each iteration. Methods for simultaneously comparing more than two rankers have recently been developed. However, the question of which rankers to compare at each iteration was left open. We address this question by proposing a generalization of the dueling bandits model that uses simultaneous comparisons of an unrestricted number of rankers. We evaluate our algorithm on standard large-scale online ranker evaluation datasets. Our experimentals show that the algorithm yields orders of magnitude gains in performance compared to state-of-the-art dueling bandit algorithms.",2016,Conference on Information and Knowledge Management,machine learning;simulation;algorithm;computer science;
LambdaFM: Learning Optimal Ranking with Factorization Machines Using Lambda Surrogates,Fajie Yuan (University of Glasgow);Guibing Guo (Northeastern University);Joemon M. Jose (University of Glasgow);Long Chen (University of Glasgow);Haitao Yu (University of Tsukuba);Weinan Zhang (Shanghai Jiao Tong University);,"2342748603,2723506860,2167481407,2342807686,2344089676,2694510272","State-of-the-art item recommendation algorithms, which apply Factorization Machines (FM) as a scoring function and pairwise ranking loss as a trainer (PRFM for short), have been recently investigated for the implicit feedback based context-aware recommendation problem (IFCAR). However, good recommenders particularly emphasize on the accuracy near the top of the ranked list, and typical pairwise loss functions might not match well with such a requirement. In this paper, we demonstrate, both theoretically and empirically, PRFM models usually lead to non-optimal item recommendation results due to such a mismatch. Inspired by the success of LambdaRank, we introduce Lambda Factorization Machines (LambdaFM), which is particularly intended for optimizing ranking performance for IFCAR. We also point out that the original lambda function suffers from the issue of expensive computational complexity in such settings due to a large amount of unobserved feedback. Hence, instead of directly adopting the original lambda strategy, we create three effective lambda surrogates by conducting a theoretical analysis for lambda from the top-N optimization perspective. Further, we prove that the proposed lambda surrogates are generic and applicable to a large set of pairwise ranking loss functions. Experimental results demonstrate LambdaFM significantly outperforms state-of-the-art algorithms on three real-world datasets in terms of four standard ranking measures.",2016,Conference on Information and Knowledge Management,theoretical computer science;world wide web;information retrieval;data mining;database;machine learning;statistics;
PARC: Privacy-Aware Data Cleaning,Dejun Huang (McMaster University);Dhruv Gairola (McMaster University);Yu Huang (McMaster University);Zheng Zheng (McMaster University);Fei Chiang (McMaster University);,"2575165173,2060800546,2704759256,2535947540,2106014425","Poor data quality has become a persistent challenge for organizations as data continues to grow in complexity and size. Existing data cleaning solutions focus on identifying repairs to the data to minimize either a cost function or the number of updates. These techniques, however, fail to consider underlying data privacy requirements that exist in many real data sets containing sensitive and personal information. In this demonstration, we present PARC, a Privacy-AwaRe data Cleaning system that corrects data inconsistencies w.r.t. a set of FDs, and limits the disclosure of sensitive values during the cleaning process. The system core contains modules that evaluate three key metrics during the repair search, and solves a multi-objective optimization problem to identify repairs that balance the privacy vs. utility tradeoff. This demonstration will enable users to understand: (1) the characteristics of a privacy-preserving data repair; (2) how to customize data cleaning and data privacy requirements using two real datasets; and (3) the distinctions among the repair recommendations via visualization summaries.",2016,Conference on Information and Knowledge Management,data quality;world wide web;computer security;data mining;database;computer science;
CyberSafety 2016: The First International Workshop on Computational Methods in CyberSafety,Shivakant Mishra (University of Colorado Boulder);Qin Lv (University of Colorado Boulder);Richard Han (University of Colorado Boulder);Jeremy Blackburn (Telefónica);,"2110219690,2154485217,2128661168,2131250283","The theme of cybersafety is an important emerging research topic on the Internet that manifests itself daily as users navigate the Web and networked applications. Examples of cybersafety issues include cyberbullying, cyberthreats, recruiting minors via Internet services for nefarious purposes, using deceptive means to dupe vulnerable populations, exhibiting misbehaving behaviors such as using profanity or flashing in online video chats, and many others. These issues have a direct negative impact on the social, psychological and in some cases physical well-being of the end users. An important characteristic of these issues is that they fall in a grey legal area, where perpetrators may claim freedom of speech or rights to free expression despite causing harm. The main goal of this inaugural workshop on cybersafety is to bring together the researchers and practitioners from academia, industry, government and research labs working in the area of cybersafety to discuss the unique challenges in addressing various cybersafety issues and to share experiences, solutions, tools, and techniques. The focus is on the detection, prevention and mitigation of various cybersafety issues, as well as education and promoting safe practices. Topics of interest include but are not limited to the following: Cyberbullying in social media, Cyberthreats, coercion, and undue social pressure, Misbehaving users in online video chat services, Trolls in chat rooms, discussion boards and other social media, Deception to shape opinion, such as spinning, Deceptive techniques targeted at vulnerable populations such as the elderly and K-12 minors, Bad actors in social media, Online exposure of inappropriate material to minors, Education and promoting safe practices, and Remedies for preventing or thwarting cybersafety issues.",2016,Conference on Information and Knowledge Management,world wide web;computer security;data mining;artificial intelligence;
Understanding Mobile Searcher Attention with Rich Ad Formats,Dmitry Lagun (Google);Donal McMahon;Vidhya Navalpakkam (Google);,"2281438794,2666305200,322804077","Mobile Search experiences have evolved significantly from a few blue links that require users to click. Recent search and ad units surface instant information to the user in a variety of visually rich formats that include images, horizontal swipes, and vertical scrolls. These innovative experiences call for new metrics and models to better understand searcher behavior on mobile phones. In this paper, we study how the presence of ads and their formats impacts searcher's gaze and satisfaction. We systematically vary presentation format of the sponsored result, while controlling for other factors, such as position and quality of organic results. We experiment with several configurations of text ad and rich ad formats. Our findings indicate that showing rich ad formats improve search experience, by drawing more attention to the information-rich ad and allowing users to interact to view more offers, which increases user satisfaction with search. In addition, we extend prior work by comparing the performance of various models to infer user's gaze from viewport data. Our models improve accuracy of existing viewport-based gaze inference methods by 30% in Pearson's correlation. Together, our findings show that viewport data can be used for fast, accurate and scalable measurement of user attention on a per-element basis, for both ads as well as organic search results.",2016,Conference on Information and Knowledge Management,eye tracking;multimedia;world wide web;information retrieval;data mining;database;simulation;computer science;
Uncovering Fake Likers in Online Social Networks,Prudhvi Ratna Badri Satya (Utah State University);Kyumin Lee (Utah State University);Dongwon Lee (Pennsylvania State University);Thanh Tran (Utah State University);Jason (Jiasheng) Zhang (Pennsylvania State University);,"2532776669,2222273857,2141172858,2478449116,2720943136","As the commercial implications of Likes in online social networks multiply, the number of fake Likes also increase rapidly. To maintain a healthy ecosystem, however, it is critically important to prevent and detect such fake Likes . Toward this goal, in this paper, we investigate the problem of detecting the so-called "" fake likers "" who frequently make fake Likes for illegitimate reasons. To uncover fake Likes in online social networks, we: (1) first collect a substantial number of profiles of both fake and legitimate Likers using linkage and honeypot approaches, (2) analyze the characteristics of both types of Likers , (3) identify effective features exploiting the learned characteristics and apply them in supervised learning models, and (4) thoroughly evaluate their performances against three baseline methods and under two attack models. Our experimental results show that our proposed methods with effective features significantly outperformed baseline methods, with accuracy = 0.871, false positive rate = 0.1, and false negative rate = 0.14.",2016,Conference on Information and Knowledge Management,internet privacy;computer security;
Measuring Metrics,Pavel Dmitriev (Microsoft);Xian Wu (Microsoft);,"2700607695,2534222794","You get what you measure, and you can't manage what you don't measure. Metrics are a powerful tool used in organizations to set goals, decide which new products and features should be released to customers, which new tests and experiments should be conducted, and how resources should be allocated. To a large extent, metrics drive the direction of an organization, and getting metrics 'right' is one of the most important and difficult problems an organization needs to solve. However, creating good metrics that capture long-term company goals is difficult. They try to capture abstract concepts such as success, delight, loyalty, engagement, life-time value , etc. How can one determine that a metric is a good one? Or, that one metric is better than another? In other words, how do we measure the quality of metrics? Can the evaluation process be automated so that anyone with an idea of a new metric can quickly evaluate it? In this paper we describe the metric evaluation system deployed at Bing, where we have been working on designing and improving metrics for over five years. We believe that by applying a data driven approach to metric evaluation we have been able to substantially improve our metrics and, as a result, ship better features and improve search experience for Bing's users.",2016,Conference on Information and Knowledge Management,measurement;management science;data mining;simulation;statistics;computer science;
Approximating Graph Pattern Queries Using Views,Jia Li (Beihang University);Yang Cao (University of Edinburgh);Xudong Liu (Beihang University);,"2343137359,2688685186,2706241310","This paper studies approximation of graph pattern queries using views. Given a pattern query Q and a set V of views, we propose to find a pair of queries Q u and Q l , referred to as the upper and lower approximations of Q w.r.t. V, such that (a) for any data graph G, answers to (part of) Q in G are contained in Q u (G) and contain Q l (G); and (b) both Q u and Q l can be answered by using views in V. We consider pattern queries based on both graph simulation and subgraph isomorphism. We study fundamental problems about approximation using views. Given Q and V, (1) we study whether there exist upper and lower approximations of Q w.r.t. V. (2) How to find approximations that are closest to Q w.r.t. V if exist? (3) How to answer upper and lower approximations using views in V? We give characterizations of the problems, study their complexity and approximation-hardness, and develop algorithms with provable bounds. Using real-life datasets, we verify the effectiveness and efficiency of approximating simulation and subgraph queries using views.",2016,Conference on Information and Knowledge Management,view;pattern matching;theoretical computer science;computer science;
Uncovering the Spatio-Temporal Dynamics of Memes in the Presence of Incomplete Information,Hancheng Ge (Texas A&M University);James Caverlee (Texas A&M University);Nan Zhang (Fudan University);Anna Cinzia Squicciarini (Pennsylvania State University);,"2166293409,2028974103,2607513995,2310372355","Modeling, understanding, and predicting the spatio-temporal dynamics of online memes are important tasks, with ramifications on location-based services, social media search, targeted advertising and content delivery networks. However, the raw data revealing these dynamics are often incomplete and error-prone; for example, API limitations and data sampling policies can lead to an incomplete (and often biased) perspective on these dynamics. Hence, in this paper, we investigate new methods for uncovering the full (underlying) distribution through a novel spatio-temporal dynamics recovery framework which models the latent relationships among locations, memes, and times. By integrating these hidden relationships into a tensor-based recovery framework -- called AirCP -- we find that high-quality models of meme spread can be built with access to only a fraction of the full data. Experimental results on both synthetic and real-world Twitter hashtag data demonstrate the promising performance of the proposed framework: an average improvement of over 27% in recovering the spatio-temporal dynamics of hashtags versus five state-of-the-art alternatives.",2016,Conference on Information and Knowledge Management,data science;data mining;artificial intelligence;machine learning;computer science;
Semi-supervised Multi-Label Topic Models for Document Classification and Sentence Labeling,Hossein Soleimani (Pennsylvania State University);David J. Miller (Pennsylvania State University);,"2513791302,2276725173","Extracting parts of a text document relevant to a class label is a critical information retrieval task. We propose a semi-supervised multi-label topic model for jointly achieving document and sentence-level class inferences. Under our model, each sentence is associated with only a subset of the document's labels (including possibly none of them), with the label set of the document the union of the labels of all of its sentences. For training, we use both labeled documents, and, typically, a larger set of unlabeled documents. Our model, in a semisupervised fashion, discovers the topics present, learns associations between topics and class labels, predicts labels for new (or unlabeled) documents, and determines label associations for each sentence in every document. For learning, our model does not require any ground-truth labels on sentences. We develop a Hamiltonian Monte Carlo based algorithm for efficiently sampling from the joint label distribution over all sentences, a very high-dimensional discrete space. Our experiments show that our approach outperforms several benchmark methods with respect to both document and sentence-level classification, as well as test set log-likelihood. All code for replicating our experiments is available from https://github.com/hsoleimani/MLTM.",2016,Conference on Information and Knowledge Management,topic model;semi supervised learning;information retrieval;data mining;pattern recognition;machine learning;computer science;
"Thymeflow, A Personal Knowledge Base with Spatio-temporal Data",David Montoya;Thomas Pellissier Tanon (École normale supérieure de Lyon);Serge Abiteboul (French Institute for Research in Computer Science and Automation);Fabian M. Suchanek (Télécom ParisTech);,"2287456233,2567170960,172400696,2681494453","The typical Internet user has data spread over several devices and across several online systems. We demonstrate an open-source system for integrating user's data from different sources into a single Knowledge Base. Our system integrates data of different kinds into a coherent whole, starting with email messages, calendar, contacts, and location history. It is able to detect event periods in the user's location data and align them with calendar events. We will demonstrate how to query the system within and across different dimensions, and perform analytics over emails, events, and locations.",2016,Conference on Information and Knowledge Management,personally identifiable information;data integration;world wide web;information retrieval;data mining;database;computer science;
"Incorporating Clicks, Attention and Satisfaction into a Search Engine Result Page Evaluation Model",Aleksandr Chuklin (Google);Maarten de Rijke (University of Amsterdam);,"113447990,401833296","Modern search engine result pages often provide immediate value to users and organize information in such a way that it is easy to navigate. The core ranking function contributes to this and so do result snippets, smart organization of result blocks and extensive use of one-box answers or side panels. While they are useful to the user and help search engines to stand out, such features present two big challenges for evaluation. First, the presence of such elements on a search engine result page (SERP) may lead to the absence of clicks, which is, however, not related to dissatisfaction, so-called 'good abandonments.' Second, the non-linear layout and visual difference of SERP items may lead to non-trivial patterns of user attention, which is not captured by existing evaluation metrics. In this paper we propose a model of user behavior on a SERP that jointly captures click behavior, user attention and satisfaction, the CAS model, and demonstrate that it gives more accurate predictions of user actions and self-reported satisfaction than existing models based on clicks alone. We use the CAS model to build a novel evaluation metric that can be applied to non-linear SERP layouts and that can account for the utility that users obtain directly on a SERP. We demonstrate that this metric shows better agreement with user-reported satisfaction than conventional evaluation metrics.",2016,Conference on Information and Knowledge Management,computer user satisfaction;evaluation;multimedia;world wide web;information retrieval;machine learning;simulation;
Semi-Supervision Dramatically Improves Time Series Clustering under Dynamic Time Warping,"Hoang Anh Dau (University of California, Riverside);Nurjahan Begum (University of California, Riverside);Eamonn J. Keogh (University of California, Riverside);","2712909183,2157373250,2170070822","The research community seems to have converged in agreement that for time series classification problems, Dynamic Time Warping (DTW)-based nearest-neighbor classifiers are exceptionally hard to beat. Obtaining the best performance from DTW requires setting its only parameter, the warping window width (w). This is typically set by cross validation in the training stage. However, for clustering, by definition we do not have access to such labeled data. This issue seems to have been largely ignored in the literature, with many practitioners simply assuming that ""the larger the better"" for the value of w, and using as large a value of w as computational resources permit. In this work we show that this is a naive approach which in most circumstances produces inferior clusterings. To address this problem, we introduce a novel semi-supervised technique that allows us to set the best value of w. Unlike virtually all other semi-supervised techniques, our ideas are completely independent of the clustering algorithm used, and can be utilized to improve time series clustering under partitional, hierarchical, spectral or density-based clustering. Our approach requires very little human intervention; moreover, we show that in many cases, true human annotation efforts can be replaced with automatically-generated ""pseudo"" supervision information. We demonstrate our technique by testing with more than one hundred publicly available datasets.",2016,Conference on Information and Knowledge Management,dynamic time warping;time series;semi supervised learning;world wide web;speech recognition;data mining;database;artificial intelligence;machine learning;computer science;
SoLSCSum: A Linked Sentence-Comment Dataset for Social Context Summarization,Minh-Tien Nguyen (Japan Advanced Institute of Science and Technology);Chien-Xuan Tran (Japan Advanced Institute of Science and Technology);Duc-Vu Tran (Japan Advanced Institute of Science and Technology);Minh-Le Nguyen (Japan Advanced Institute of Science and Technology);,"2159619789,2533470407,2532509306,2506028131","This paper presents a dataset named SoLSCSum for social context summarization. The dataset includes 157 open-domain articles along with their comments collected from Yahoo News. The articles and their comments were manually annotated by two annotators to extract standard summaries. The inter-annotator agreement is 74.5% and Cohen's Kappa is 0.5845. To illustrate the potential use of our dataset, a learning to rank model was trained by using a set of local and cross features. Experimental results demonstrate that: (1) our model trained by Ranking SVM obtains significant improvements from 5.5% to 14.8% of ROUGE-1 over state-of-the-art baselines in document summarization and (2) our dataset can be used to train summary methods such as SVM.",2016,Conference on Information and Knowledge Management,data set;learning to rank;multi document summarization;automatic summarization;data science;information retrieval;data mining;machine learning;computer science;
The Fourth International Workshop on Social Web for Disaster Management (SWDM 2016),Carlos Castillo (Yahoo!);Fernando Diaz (Microsoft);Yu Ru Lin (University of Pittsburgh);Jie Yin (Commonwealth Scientific and Industrial Research Organisation);,"2125169605,2159093489,2155397203,2150861151","The proliferation of social media platforms together with the wide adoption of smartphone devices has transformed how we communicate and share news. During large-scale emergencies, such as natural disasters or armed attacks, victims, responders, and volunteers increasingly use social media to post situation updates and to request and offer help. The use of social media for emergency and disaster response has been a prominent application of information and knowledge management techniques in recent years. There are a number of challenges associated with near real-time processing of vast volumes of information in a way that makes sense for people directly affected, for volunteer organizations, and for official emergency response agencies. As massive amount of messages posted by users are transformed into semi-structured records via information extraction and natural language processing techniques, there is a growing need for developing advanced techniques to aggregate this large-scale data to gain an understanding of the ``big picture'' of an emergency, and to detect and predict how a disaster could develop. This workshop seeks to provide a platform for the exchange of ideas, identification of important problems, and discovery of possible synergies. It will enable interesting discussions and encouraged collaboration between various disciplines, and information and knowledge management approaches is the core of this workshop.",2016,Conference on Information and Knowledge Management,emergency management;world wide web;computer security;data mining;database;artificial intelligence;computer science;
Reenactment for Read-Committed Snapshot Isolation,Bahareh Sadat Arab (Illinois Institute of Technology);Dieter Gawlick (Oracle Corporation);Vasudha Krishnaswamy (Oracle Corporation);Venkatesh Radhakrishnan (LinkedIn);Boris Glavic (Illinois Institute of Technology);,"2120138823,345041231,2286957374,2145279478,1263411180","Provenance for transactional updates is critical for many applications such as auditing and debugging of transactions. Recently, we have introduced MV-semirings, an extension of the semiring provenance model that supports updates and transactions. Furthermore, we have proposed reenactment, a declarative form of replay with provenance capture, as an efficient and non-invasive method for computing this type of provenance. However, this approach is limited to the snapshot isolation (SI) concurrency control protocol while many real world applications apply the read committed version of snapshot isolation (RC-SI) to improve performance at the cost of consistency. We present non trivial extensions of the model and reenactment approach to be able to compute provenance of RC-SI transactions efficiently. In addition, we develop techniques for applying reenactment across multiple RC-SI transactions. Our experiments demonstrate that our implementation in the GProM system supports efficient re-construction and querying of provenance.",2016,Conference on Information and Knowledge Management,database transaction;distributed computing;database;real time computing;computer science;
A Filtering-based Clustering Algorithm for Improving Spatio-temporal Kriging Interpolation Accuracy,Qiao Kang (Northwestern University);Wei-keng Liao (Northwestern University);Ankit Agrawal (Northwestern University);Alok N. Choudhary (Northwestern University);,"2566385901,2161046949,2160807299,2147783234","Geostatistical interpolation is the process that uses existing data and statistical models as inputs to predict data in unobserved spatio-temporal contexts as output. Kriging is a well-known geostatistical interpolation method that minimizes mean square error of prediction. The result interpolated by Kriging is accurate when consistency of statistical properties in data is assumed. However, without this assumption, Kriging interpolation has poor accuracy. To address this problem, this paper presents a new filtering-based clustering algorithm that partitions data into clusters such that the interpolation error within each cluster is significantly reduced, which in turn improves the overall accuracy. Comparisons to traditional Kriging are made with two real-world datasets using two error criteria: normalized mean square error(NMSE) and χ 2 test statistics for normalized deviation measurement. Our method has reduced NMSE by more than 50% for both datasets over traditional Kriging. Moreover, χ 2 tests have also shown significant improvements of our approach over traditional Kriging.",2016,Conference on Information and Knowledge Management,nearest neighbor interpolation;variogram;kriging;mathematical optimization;statistics;
Fully Dynamic Shortest-Path Distance Query Acceleration on Massive Networks,Takanori Hayashi (University of Tokyo);Takuya Akiba (University of Tokyo);Ken-ichi Kawarabayashi (National Institute of Informatics);,"2146187038,2149787982,563105935","The distance between vertices is one of the most fundamental measures for representing relations between them, and it is the basis of other classic measures of vertices, such as similarity, centrality, and influence. The 2-hop labeling methods are known as the fastest exact point-to-point distance algorithms on million-scale networks. However, they cannot handle billion-scale networks because of the large space requirement and long preprocessing time. In this paper, we present the first algorithm that can process exact distance queries on fully dynamic billion-scale networks besides trivial non-indexing algorithms, which combines an online bidirectional breadth-first search (BFS) and an offline indexing method for handling billion-scale networks in memory. First, we accelerate bidirectional BFSs by using heuristics that exploit the small-world property of complex networks. Then, we construct bit-parallel shortest-path trees to maintain sets of shortest paths passing through high-degree vertices of networks in compact form, the information of which enables us to avoid visiting vertices with high degrees during bidirectional BFSs. Thus, the searches achieve considerable speedup. In addition, our index size reduction technique enables us to handle billion-scale networks in memory. Furthermore, we introduce dynamic update procedures of our data structure to handle fully dynamic networks. We evaluated the performance of the proposed method on real-world networks. In particular, on large-scale social networks with over 1B edges, the proposed method enables us to answer distance queries in around 1 ms, on average.",2016,Conference on Information and Knowledge Management,distance;shortest path problem;graph;theoretical computer science;distributed computing;data mining;database;machine learning;
Discovering Temporal Purchase Patterns with Different Responses to Promotions,Ling Luo (University of Sydney);Bin Li (Commonwealth Scientific and Industrial Research Organisation);Irena Koprinska (University of Sydney);Shlomo Berkovsky (Commonwealth Scientific and Industrial Research Organisation);Fang Chen (Commonwealth Scientific and Industrial Research Organisation);,"2503285057,2646749737,276917286,86410884,2559371593","The supermarkets often use sales promotions to attract customers and create brand loyalty. They would often like to know if their promotions are effective for various customers, so that better timing and more suitable rate can be planned in the future. Given a transaction data set collected by an Australian national supermarket chain, in this paper we conduct a case study aimed at discovering customers' long-term purchase patterns, which may be induced by preference changes, as well as short-term purchase patterns, which may be induced by promotions. Since purchase events of individual customers may be too sparse to model, we propose to discover a number of latent purchase patterns from the data. The latent purchase patterns are modeled via a mixture of non-homogeneous Poisson processes where each Poisson intensity function is composed by long-term and short-term components. Through the case study, 1) we validate that our model can accurately estimate the occurrences of purchase events; 2) we discover easy-to-interpret long-term gradual changes and short-term periodic changes in different customer groups; 3) we identify the customers who are receptive to promotions through the correlation between behavior patterns and the promotions, which is particularly worthwhile for target marketing.",2016,Conference on Information and Knowledge Management,inhomogeneous poisson process;market segmentation;
"One Query, Many Clicks: Analysis of Queries with Multiple Clicks by the Same User",Elad Kravi (Technion – Israel Institute of Technology);Ido Guy (Ben-Gurion University of the Negev);Avihai Mejer (Yahoo!);David Carmel (Yahoo!);Yoelle Maarek (Yahoo!);Dan Pelleg (Yahoo!);Gilad Tsur (Yahoo!);,"171165695,2669811300,2050677669,2088014474,262608878,1551887306,2008753247","In this paper, we study multi-click queries - queries for which more than one click is performed by the same user within the same query session. Such queries may reflect a more complex information need, which leads the user to examine a variety of results. We present a comprehensive analysis that reveals unique characteristics of multi-click queries, in terms of their syntax, lexical domains, contextual properties, and returned search results page. We also show that a basic classifier for predicting multi-click queries can reach an accuracy of 75% over a balanced dataset. We discuss the implications of our findings for the design of Web search tools.",2016,Conference on Information and Knowledge Management,range query;queries per second;web search query;web query classification;spatial query;query language;world wide web;information retrieval;database;computer science;
Probabilistic Knowledge Graph Construction: Compositional and Incremental Approaches,Dongwoo Kim (Australian National University);Lexing Xie (Australian National University);Cheng Soon Ong (Australian National University);,"2170939500,2100918400,2444503237","Knowledge graph construction consists of two tasks: extracting information from external resources (knowledge population) and inferring missing information through a statistical analysis on the extracted information (knowledge completion). In many cases, insufficient external resources in the knowledge population hinder the subsequent statistical inference. The gap between these two processes can be reduced by an incremental population approach. We propose a new probabilistic knowledge graph factorisation method that benefits from the path structure of existing knowledge (e.g. syllogism) and enables a common modelling approach to be used for both incremental population and knowledge completion tasks. More specifically, the probabilistic formulation allows us to develop an incremental population algorithm that trades off exploitation-exploration. Experiments on three benchmark datasets show that the balanced exploitation-exploration helps the incremental population, and the additional path structure helps to predict missing information in knowledge completion.",2016,Conference on Information and Knowledge Management,thompson sampling;active learning;knowledge extraction;knowledge based systems;data mining;pattern recognition;machine learning;computer science;
Inferring Traffic Incident Start Time with Loop Sensor Data,Mingxuan Yue (University of Southern California);Liyue Fan (University of Southern California);Cyrus Shahabi (University of Southern California);,"2538561614,2109596318,240820708","Traffic incidents and their impacts have been largely studied to improve road safety and to reduce incurred life and economic losses. However, the inaccuracy of incident data collected from transportation agencies, especially the start time, poses a great challenge to traffic incident research. We present INFIT, a system that infers the incident start time utilizing traffic data collected by loop sensors. The core of INFIT is IIG, our newly developed inference algorithm. The key idea is that IIG considers the traffic speed at multiple upstream locations, to mitigate the randomness in traffic data and to distinguish among multiple impact factors. INFIT includes an interactive interface with real-world incident datasets. We demonstrate INFIT with three exploratory use cases and show the usefulness of our inference algorithms.",2016,Conference on Information and Knowledge Management,computer security;data mining;simulation;
The Healing Power of Poison: Helpful Non-relevant Documents in Feedback,Mostafa Dehghani (University of Amsterdam);Samira Abnar (University of Amsterdam);Jaap Kamps (University of Amsterdam);,"2112331270,2561900238,2088944921","The use of feedback information is an effective approach to address the vocabulary gap between a user's query and the relevant documents. It has been shown that some relevant documents act like ""poison pills,"" i.e. they hurt the performance of feedback systems despite the fact that they are relevant. In this paper, we study the positive counterpart of this by investigating the helpfulness of nonrelevant documents in feedback. In general, we find that although documents that are explicitly judged as non-relevant are normally assumed to be poisonous for feedback systems, sometimes considering high-scored non-relevant documents as a positive feedback helps to improve the performance of retrieval. In our experimental data, we observe a considerable fraction of non-relevant documents in higher ranked positions of the initial retrieval run, for most of the topics. Hence, by ignoring the potential value of non-relevant documents, we may loose a lot of useful information. We investigate the potential contribution of non-relevant documents using existing state-of-the-art feedback methods. Our main findings are the following. First, we find that some of the nonrelevant documents are exclusively helpful, they improve retrieval on their own, and others are complementary helpful, they lead to further improvement when added to a set of relevant documents. Second, we discover that, on average, exclusively helpful non-relevant documents have a higher contribution to the performance improvement, compared to the complementary ones. Third, we show that non-relevant documents in topics with poor average precision in the initial retrieval are more likely to help in the feedback.",2016,Conference on Information and Knowledge Management,ranking;multimedia;world wide web;information retrieval;data mining;database;computer science;
Efficient Orthogonal Non-negative Matrix Factorization over Stiefel Manifold,Wei Emma Zhang (University of Adelaide);Mingkui Tan (South China University of Technology);Quan Z. Sheng (University of Adelaide);Lina Yao (University of New South Wales);Qingfeng Shi (University of Adelaide);,"2104649335,2636993221,1740996049,2223456168,2551146181","Orthogonal Non-negative Matrix Factorization (ONMF) approximates a data matrix X by the product of two lower dimensional factor matrices: X -- UV T , with one of them orthogonal. ONMF has been widely applied for clustering, but it often suffers from high computational cost due to the orthogonality constraint. In this paper, we propose a method, called Nonlinear Riemannian Conjugate Gradient ONMF (NRCG-ONMF), which updates U and V alternatively and preserves the orthogonality of U while achieving fast convergence speed. Specifically, in order to update U , we develop a Nonlinear Riemannian Conjugate Gradient (NRCG) method on the Stiefel manifold using Barzilai-Borwein (BB) step size. For updating V , we use a closed-form solution under non-negativity constraint. Extensive experiments on both synthetic and real-world data sets show consistent superiority of our method over other approaches in terms of orthogonality preservation, convergence speed and clustering performance.",2016,Conference on Information and Knowledge Management,stiefel manifold;cluster analysis;machine learning;mathematical optimization;computer science;
Learning to Account for Good Abandonment in Search Success Metrics,Madian Khabsa (Microsoft);Aidan C. Crook (Microsoft);Ahmed Hassan Awadallah (Microsoft);Imed Zitouni (Microsoft);Tasos Anastasakos (Microsoft);Kyle Williams (Pennsylvania State University);,"296516693,2317344110,2094223786,2507515815,2305284634,2124644202","Abandonment in web search has been widely used as a proxy to measure user satisfaction. Initially it was considered a signal of dissatisfaction, however with search engines moving towards providing answer-like results, a new category of abandonment was introduced and referred to as Good Abandonment. Predicting good abandonment is a hard problem and it was the subject of several previous studies. All those studies have focused, though, on predicting good abandonment in offline settings using manually labeled data. Thus, it remained a challenge how to have an online metric that accounts for good abandonment. In this work we describe how a search success metric can be augmented to account for good abandonment sessions using a machine learned metric that depends on user's viewport information. We use real user traffic from millions of users to evaluate the proposed metric in an A/B experiment. We show that taking good abandonment into consideration has a significant effect on the overall performance of the online metric.",2016,Conference on Information and Knowledge Management,data mining;simulation;computer science;
A Study of Realtime Summarization Metrics,Matthew Ekstrand-Abueg (Northeastern University);Richard McCreadie (University of Glasgow);Virgil Pavlu (Northeastern University);Fernando Diaz (Microsoft);,"36859887,2078704756,2579520042,2159093489","Unexpected news events, such as natural disasters or other human tragedies, create a large volume of dynamic text data from official news media as well as less formal social media. Automatic real-time text summarization has become an important tool for quickly transforming this overabundance of text into clear, useful information for end-users including affected individuals, crisis responders, and interested third parties. Despite the importance of real-time summarization systems, their evaluation is not well understood as classic methods for text summarization are inappropriate for real-time and streaming conditions. The TREC 2013-2015 Temporal Summarization (TREC-TS) track was one of the first evaluation campaigns to tackle the challenges of real-time summarization evaluation, introducing new metrics, ground-truth generation methodology and dataset. In this paper, we present a study of TREC-TS track evaluation methodology, with the aim of documenting its design, analyzing its effectiveness, as well as identifying improvements and best practices for the evaluation of temporal summarization systems.",2016,Conference on Information and Knowledge Management,metrics;text graph;multi document summarization;automatic summarization;world wide web;information retrieval;data mining;computer science;
Influence-Aware Truth Discovery,Hengtong Zhang (University at Buffalo);Qi Li (University at Buffalo);Fenglong Ma (University at Buffalo);Houping Xiao (University at Buffalo);Yaliang Li (University at Buffalo);Jing Gao (University at Buffalo);Lu Su (University at Buffalo);,"2578315135,2261907930,2227076362,2303863390,2116094297,2096731881,2148733542","In the age of big data, information for the same entity can be obtained from different sources, which is inevitably conflicting. Therefore, aggregation methods are needed to identify the trustworthy information from such conflicting data. Truth discovery, which improves the aggregation results by estimating source trustworthiness and discovering truths simultaneously, has become an emerging field. Most truth discovery methods assume that sources make their claims independently, which may not be true in practice. As a matter of fact, influences among sources are ubiquitous and the claims made by one source may be influenced by others. Although there is some work that considers source correlation, those methods are designed to handle categorical claims, which is not general enough to represent the complicated real world applications. To tackle these challenges in truth discovery, we propose an unsupervised probabilistic model named IATD. The model takes source correlations as prior for influence derivation. To model influences among sources, we introduce ""claim trustworthiness"", which fuses the trustworthiness of the source which provides the claim and the trustworthiness of its influencers. Besides, the proposed model can handle different data types using different distributions in the probabilistic model. Experiments on real-world datasets show that IATD model can improve the aggregation performance compared with the state-of-the-art truth discovery approaches. The properties of IATD model are further illustrated using simulated datasets.",2016,Conference on Information and Knowledge Management,statistical model;unsupervised learning;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
TEAMOPT: Interactive Team Optimization in Big Networks,Liangyue Li (Arizona State University);Hanghang Tong (Arizona State University);Nan Cao (New York University Shanghai);Kate Ehrlich (IBM);Yu Ru Lin (University of Pittsburgh);Norbou Buchler (United States Army Research Laboratory);,"2144246580,2676574370,2719470804,2638086191,2155397203,2141367847","The science of team science is a rapidly emerging research field that studies strategies to understand and enhance the process and outcomes of collaborative, team-based research. An interesting research question we address in this work is how to maintain and optimize the team performance should certain changes happen to the team. In particular, we take the network approach to understanding the teams and consider optimizing the teams with several operations (e.g., replacement, expansion, shrinkage). We develop TEAMOPT, a system to assist users in optimizing the team performance interactively to support the changes to a team. TEAMOPT takes as input a large network of individuals (e.g., co-author network of researchers) and is able to assist users in assembling a team with specific requirements and optimizing the team in response to the changes made to the team. It is effective in finding the best candidates, and interactive with users' feedback in the loop. The system is developed using HTML5, JavaScript, D3.js (front-end) and Python CGI (back-end). A prototype system is already deployed. We will invite the audience to experiment with our TEAMOPT in terms of its effectiveness, efficiency and applicability to various scenarios.",2016,Conference on Information and Knowledge Management,graph kernel;team software process;management science;knowledge management;world wide web;data mining;machine learning;simulation;computer science;
A Probabilistic Fusion Framework,Yael Anava (Technion – Israel Institute of Technology);Anna Shtok (Technion – Israel Institute of Technology);Oren Kurland (Technion – Israel Institute of Technology);Ella Rabinovich (IBM);,"2344507439,1260992435,2250933759,2111118720","There are numerous methods for fusing document lists retrieved from the same corpus in response to a query. Many of these methods are based on seemingly unrelated techniques and heuristics. Herein we present a probabilistic framework for the fusion task. The framework provides a formal basis for deriving and explaining many fusion approaches and the connections between them. Instantiating the framework using various estimates yields novel fusion methods, some of which significantly outperform state-of-the-art approaches.",2016,Conference on Information and Knowledge Management,fusion;natural language processing;speech recognition;computer science;
Quark-X : An Efficient Top-K Processing Framework for RDF Quad Stores,Jyoti Leeka (Indraprastha Institute of Information Technology);Srikanta Bedathur (IBM);Debajyoti Bera (Indraprastha Institute of Information Technology);Medha Atre (Rensselaer Polytechnic Institute);,"2222170485,1218200837,2110685873,2067729839","There is a growing trend towards enriching the RDF content from its classical Subject-Predicate-Object triple form to an annotated representation which can model richer relationships such as including fact provenance, fact confidence, higher-order relationships and so on. One of the recommended ways to achieve this is to use reification and represent it as N-Quads ""or simply quads "" where an additional identifier is associated with the entire RDF statement which can then be used to add further annotations. A typical use of such annotations is to have quantifiable confidence values to be attached to facts. In such settings, it is important to support efficient top- k queries, typically over user-defined ranking functions containing sentence level confidence values in addition to other quantifiable values in the database. In this paper, we present Quark-X , an RDF-store and SPARQL processing system for reified RDF data represented in the form of quads. This paper presents the overall architecture of our system -- illustrating the modifications which need to be made to a native quad store for it to process top- k queries. In Quark-X, we propose indexing and query processing techniques for making top- k querying efficient. In addition, we present the results of a comprehensive empirical evaluation of our system over Yago2S and DBpedia datasets. Our performance study shows that the proposed method achieves one to two order of magnitude speed-up over baseline solutions.",2016,Conference on Information and Knowledge Management,rdf xml;rdf schema;sparql;rdf;world wide web;information retrieval;data mining;database;computer science;
Time-aware Multi-Viewpoint Summarization of Multilingual Social Text Streams,Zhaochun Ren (University of Amsterdam);Oana Inel (VU University Amsterdam);Lora Aroyo (VU University Amsterdam);Maarten de Rijke (University of Amsterdam);,"2158267603,2034761998,2063472714,401833296","A viewpoint is a triple consisting of an entity, a topic related to this entity and sentiment towards this topic. In time-aware multi-viewpoint summarization one monitors viewpoints for a running topic and selects a small set of informative documents. In this paper, we focus on time-aware multi-viewpoint summarization of multilingual social text streams. Viewpoint drift, ambiguous entities and multilingual text make this a challenging task. Our approach includes three core ingredients: dynamic viewpoint modeling, cross-language viewpoint alignment, and, finally, multi-viewpoint summarization. Specifically, we propose a dynamic latent factor model to explicitly characterize a set of viewpoints through which entities, topics and sentiment labels during a time interval are derived jointly; we connect viewpoints in different languages by using an entity-based semantic similarity measure; and we employ an update viewpoint summarization strategy to generate a time-aware summary to reflect viewpoints. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed method for time-aware multi-viewpoint summarization of multilingual social text streams.",2016,Conference on Information and Knowledge Management,topic model;multi document summarization;automatic summarization;natural language processing;information retrieval;data mining;machine learning;computer science;
An Experimental Comparison of Iterative MapReduce Frameworks,Haejoon Lee (KAIST);Minseo Kang (KAIST);Sun-Bum Youn;Jae-Gil Lee (KAIST);YongChul Kwon (Microsoft);,"2619023560,2498088530,2718164200,2134045017,2611915557","MapReduce has become a dominant framework in big data analysis, and thus there have been significant efforts to implement various data analysis algorithms in MapReduce. Many data analysis algorithms are inherently iterative , repeating the same set of tasks until a convergence. To efficiently support iterative algorithms at scale, a few variants of Hadoop and new platforms have been proposed and actively developed in both academia and industry. Representative systems include HaLoop, iMapReduce, Twister, and Spark. In this paper, we experimentally compare Hadoop and the aforementioned systems using various workloads and metrics. The five systems are compared through four iterative algorithms---PageRank, recursive query, k -means, and logistic regression---on 50 Amazon EC2 machines (200 cores in total). We thoroughly explore the effectiveness of their new caching, communication, and scheduling mechanisms in support of iterative computation. Our evaluation also shows the performance depending on data skewness and memory residency. Overall, we believe that our evaluation and interpretation will be useful for designing a new framework or improving the existing ones.",2016,Conference on Information and Knowledge Management,spark;benchmark;theoretical computer science;world wide web;data mining;database;machine learning;computer science;
Top-N Recommendation on Graphs,Zhao Kang (Southern Illinois University Carbondale);Chong Peng (Southern Illinois University Carbondale);Ming Yang (Southern Illinois University Carbondale);Qiang Cheng (Southern Illinois University Carbondale);,"2162933773,2104710458,2501691373,2102340508","Recommender systems play an increasingly important role in online applications to help users find what they need or prefer. Collaborative filtering algorithms that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. To alleviate this problem, this paper proposes a simple recommendation algorithm that fully exploits the similarity information among users and items and intrinsic structural information of the user-item matrix. The proposed method constructs a new representation which preserves affinity and structure information in the user-item rating matrix and then performs recommendation task. To capture proximity information about users and items, two graphs are constructed. Manifold learning idea is used to constrain the new representation to be smooth on these graphs, so as to enforce users and item proximities. Our model is formulated as a convex optimization problem, for which we need to solve the well known Sylvester equation only. We carry out extensive empirical evaluations on six benchmark datasets to show the effectiveness of this approach.",2016,Conference on Information and Knowledge Management,collaborative filtering;theoretical computer science;world wide web;information retrieval;data mining;machine learning;computer science;
Learning Latent Vector Spaces for Product Search,Christophe Van Gysel (University of Amsterdam);Maarten de Rijke (University of Amsterdam);Evangelos Kanoulas (University of Amsterdam);,"2275890166,401833296,2627690640","We introduce a novel latent vector space model that jointly learns the latent representations of words, e-commerce products and a mapping between the two without the need for explicit annotations. The power of the model lies in its ability to directly model the discriminative relation between products and a particular word. We compare our method to existing latent vector space models (LSI, LDA and word2vec) and evaluate it as a feature in a learning to rank setting. Our latent vector space model achieves its enhanced performance as it learns better product representations. Furthermore, the mapping from words to products and the representations of words benefit directly from the errors propagated back from the product representations during parameter estimation. We provide an in-depth analysis of the performance of our model and analyze the structure of the learned representations.",2016,Conference on Information and Knowledge Management,probabilistic latent semantic analysis;feature learning;natural language processing;pattern recognition;machine learning;computer science;
Adaptive Distributional Extensions to DFR Ranking,Casper Petersen (University of Copenhagen);Jakob Grue Simonsen (University of Copenhagen);Kalervo Jarvelin (University of Tampere);Christina Lioma (University of Copenhagen);,"2159821708,2153084707,54234561,1619376036","Divergence From Randomness (DFR) ranking models assume that informative terms are distributed in a corpus differently than non-informative terms. Different statistical models (e.g. Poisson, geometric) are used to model the distribution of non-informative terms, producing different DFR models. An informative term is then detected by measuring the divergence of its distribution from the distribution of non-informative terms. However, there is little empirical evidence that the distributions of non-informative terms used in DFR actually fit current datasets. Practically this risks providing a poor separation between informative and non-informative terms, thus compromising the discriminative power of the ranking model. We present a novel extension to DFR, which first detects the best-fitting distribution of non-informative terms in a collection, and then adapts the ranking computation to this best-fitting distribution. We call this model Adaptive Distributional Ranking (ADR) because it adapts the ranking to the statistics of the specific dataset being processed each time. Experiments on TREC data show ADR to outperform DFR models (and their extensions) and be comparable in performance to a query likelihood language model (LM).",2016,Conference on Information and Knowledge Management,data mining;pattern recognition;statistics;computer science;
Location-aware Friend Recommendation in Event-based Social Networks: A Bayesian Latent Factor Approach,Yao Lu (Chinese Academy of Sciences);Zhi Qiao (IBM);Chuan Zhou (Chinese Academy of Sciences);Yue Hu (Chinese Academy of Sciences);Li Guo (Chinese Academy of Sciences);,"2679696260,2132354067,2224226654,2698996319,2122010476","In this paper we study the friend recommendation problem in event-based social networks (EBSNs). Effective friend recommendation is of benefit to EBSNs, since it can promote user interaction and accelerate information diffusion for promoted events. Different from usual friend recommendations, the aim of making friends in EBSNs is to better participate offline events and enhance user experience. Meanwhile friend recommendation in EBSNs encounters three types of data, i.e. geographical information, implicate user rating, and user behavior. These differences imply that existing friend recommendation approaches are not adequate any more for EBSNs. Under this background, in this paper we propose a Bayesian latent factor model, which can jointly formulate above three types of data, for friend recommendation with better event promotion and user experience. Results on real-world datasets show the efficacy of our approach.",2016,Conference on Information and Knowledge Management,world wide web;data mining;
Medical Question Answering for Clinical Decision Support,Travis R. Goodwin (University of Texas at Dallas);Sanda M. Harabagiu (University of Texas at Dallas);,"2140595925,2345927361","The goal of modern Clinical Decision Support (CDS) systems is to provide physicians with information relevant to their management of patient care. When faced with a medical case, a physician asks questions about the diagnosis, the tests, or treatments that should be administered. Recently, the TREC-CDS track has addressed this challenge by evaluating results of retrieving relevant scientific articles where the answers of medical questions in support of CDS can be found. Although retrieving relevant medical articles instead of identifying the answers was believed to be an easier task, state-of-the-art results are not yet sufficiently promising. In this paper, we present a novel framework for answering medical questions in the spirit of TREC-CDS by first discovering the answer and then selecting and ranking scientific articles that contain the answer. Answer discovery is the result of probabilistic inference which operates on a probabilistic knowledge graph, automatically generated by processing the medical language of large collections of electronic medical records (EMRs). The probabilistic inference of answers combines knowledge from medical practice (EMRs) with knowledge from medical research (scientific articles). It also takes into account the medical knowledge automatically discerned from the medical case description. We show that this novel form of medical question answering (Q/A) produces very promising results in (a) identifying accurately the answers and (b) it improves medical article ranking by 40\%.",2016,Conference on Information and Knowledge Management,medical algorithm;question answering;data science;information retrieval;data mining;computer science;
BICP: Block-Incremental CP Decomposition with Update Sensitive Refinement,Shengyu Huang (Arizona State University);K. Selçuk Candan (Arizona State University);Maria Luisa Sapino (University of Turin);,"2310006983,674992784,351919550","With many applications relying on multi-dimensional datasets for decision making, tensors (or multi-dimensional arrays) are emerging as a popular data representation to support diverse types of data, such as sensor streams and social networks. Consequently, tensor decomposition forms the basis for many data analysis and knowledge discovery tasks, from clustering, trend detection, anomaly detection, to correlation analysis. In applications where data evolves over time and the tensor-based analysis results need to be continuously maintained, re-computation of the whole tensor decomposition with each update will cause high computational costs and incur large memory overheads. In this paper, we propose a two-phase block-incremental CP-based tensor decomposition technique, BICP, that efficiently and effectively maintains tensor decomposition results in the presence of dynamically evolving tensor data. In its first phase, instead of repeatedly conducting ALS on each sub-tensor, BICP only revises the decompositions of the tensors that contain updated data. Moreover, when updates are relatively small with respect to the block size, BICP relies on a incremental factor tracking to avoid re-decomposition the updated sub-tensor. In its second phase, BICP limits the block-centric refinement process to only those blocks that are critical given the update. Experiment results show that the proposed method significantly reduces the execution time while assuring high accuracy.",2016,Conference on Information and Knowledge Management,tensor;theoretical computer science;data mining;machine learning;computer science;
City-Scale Localization with Telco Big Data,Fangzhou Zhu (Soochow University);Chen Luo (Soochow University);Mingxuan Yuan (Huawei);Yijian Zhu;Zhengqing Zhang;Tao Gu (RMIT University);Ke Deng (RMIT University);Weixiong Rao (Tongji University);Jia Zeng (Huawei);,"2224806228,2461039878,2305706855,2646407971,2572661588,2680421693,2688213377,2666993148,2692706699","It is still challenging in telecommunication (telco) industry to accurately locate mobile devices (MDs) at city-scale using the measurement report (MR) data, which measure parameters of radio signal strengths when MDs connect with base stations (BSs) in telco networks for making/receiving calls or mobile broadband (MBB) services. In this paper, we find that the widely-used location based services (LBSs) have accumulated lots of over-the-top (OTT) global positioning system (GPS) data in telco networks, which can be automatically used as training labels for learning accurate MR-based positioning systems. Benefiting from these telco big data, we deploy a context-aware coarse-to-fine regression (CCR) model in Spark/Hadoop-based telco big data platform for city-scale localization of MDs with two novel contributions. First, we design map-matching and interpolation algorithms to encode contextual information of road networks. Second, we build a two-layer regression model to capture coarse-to-fine contextual features in a short time window for improved localization performance. In our experiments, we collect 10 8 GPS-associated MR records in the centroid of Shanghai city with 12 x 11 square kilometers for 30 days, and measure four important properties of real-world MR data related to localization errors: stability, sensitivity, uncertainty and missing values. The proposed CCR works well under different properties of MR data and achieves a mean error of 110 m and a median error of $80m$, outperforming the state-of-art range-based and fingerprinting localization methods.",2016,Conference on Information and Knowledge Management,internationalization and localization;regression analysis;ubiquitous computing;world wide web;computer security;data mining;database;artificial intelligence;computer science;
Scalability of Continuous Active Learning for Reliable High-Recall Text Classification,Gordon V. Cormack (University of Waterloo);Maura R. Grossman (University of Waterloo);,"2100357054,2120519955","For finite document collections, continuous active learning ('CAL') has been observed to achieve high recall with high probability, at a labeling cost asymptotically proportional to the number of relevant documents. As the size of the collection increases, the number of relevant documents typically increases as well, thereby limiting the applicability of CAL to low-prevalence high-stakes classes, such as evidence in legal proceedings, or security threats, where human effort proportional to the number of relevant documents is justified. We present a scalable version of CAL ('S-CAL') that requires O (log N ) labeling effort and O ( N log N ) computational effort---where N is the number of unlabeled training examples---to construct a classifier whose effectiveness for a given labeling cost compares favorably with previously reported methods. At the same time, S-CAL offers calibrated estimates of class prevalence, recall, and precision, facilitating both threshold setting and determination of the adequacy of the classifier.",2016,Conference on Information and Knowledge Management,tar;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
ACM DAVA'16: 2nd International Workshop on DAta mining meets Visual Analytics at Big Data Era,Lei Shi (Chinese Academy of Sciences);Hanghang Tong (Arizona State University);Chaoli Wang (University of Notre Dame);Leman Akoglu (Stony Brook University);,"2581263356,2667261544,2716592189,2288278917","The theme of this workshop is to bridge data mining and visual analytics for information and knowledge management. The topics include, but not limited to, the following: Big data mining and visual analytics, theory and foundations -- Knowledge discovery with data mining and visual analytics technologies -- Fusion, mining and visualization of rich and heterogeneous data source -- Security and privacy issues in data mining and visual analytics systems -- Information, social and biological graph mining and visualization -- Novel methods on visualization-oriented data mining -- Visual representations and interaction techniques of data mining results -- Data management and knowledge representation including scalable data representations -- Mathematical foundations and algorithms in data mining to allow interactive visual analysis -- Analytical reasoning including the human analytic, knowledge discovery, perception, and collaborative visual analytics -- Evaluation methods for data mining algorithms and visual analytics systems -- Applications of visual analytics and data mining techniques, including but not limited to applications in science, engineering, public safety, commerce, etc. The DAVA'16 workshop includes 3 invited keynote talks, 2 paper sessions and some posters. Authors of accepted oral papers give 20-minute presentation on their papers. Three keynote speakers from both data mining and visualization give invited talks in this workshop (40-minute each). The DAVA'16 organization committee selects one paper of the highest quality to receive the DAVA'16 best paper award and a cash award of $300. An extended version of the selected papers will be recommended to Chinese of Journal Electronics (SCI-indexed) or International Journal of Software and Informatics (IJSI) as a special issue on visual analytics.",2016,Conference on Information and Knowledge Management,software analytics;web analytics;semantic analytics;analytics;cultural analytics;business analytics;visual analytics;web mining;text mining;business intelligence;data science;world wide web;information retrieval;data mining;database;computer science;
Optimizing Nugget Annotations with Active Learning,Gaurav Baruah (University of Waterloo);Haotian Zhang (University of Waterloo);Rakesh Guttikonda (University of Waterloo);Jimmy J. Lin (University of Waterloo);Mark D. Smucker (University of Waterloo);Olga Vechtomova (University of Waterloo);,"2222791787,2716993343,2398653796,2163619555,1959697873,109440833","Nugget-based evaluations, such as those deployed in the TREC Temporal Summarization and Question Answering tracks, require human assessors to determine whether a nugget is present in a given piece of text. This process, known as nugget annotation, is labor-intensive. In this paper, we present two active learning techniques that prioritize the sequence in which candidate nugget/sentence pairs are presented to an assessor, based on the likelihood that the sentence contains a nugget. Our approach builds on the recognition that nugget annotation is similar to high-recall retrieval, and we adapt proven existing solutions. Simulation experiments with four existing TREC test collections show that our techniques yield far more matches for a given level of effort than baselines that are typically deployed in previous nugget-based evaluations.",2016,Conference on Information and Knowledge Management,question answering;information retrieval;data mining;database;pattern recognition;computer science;
Collaborative Social Group Influence for Event Recommendation,"Li Gao (Chinese Academy of Sciences);Jia Wu (University of Technology, Sydney);Zhi Qiao (IBM);Chuan Zhou (Chinese Academy of Sciences);Hong Yang (MathWorks);Yue Hu (Chinese Academy of Sciences);","2687426452,2151584597,2132354067,2224226654,2615632406,2698996319","In event-based social networks, such as Meetup, social groups refer to self-organized communities that consist of users who share the same interests. In many real-world scenarios, users usually have social group preference and join interested social groups to attend events. It is therefore necessary to consider the influence of social groups to improve the event recommendation performance; however, existing event recommendation models generally consider users' individual preferences and neglect the influence of social groups. To this end, we propose a new Bayesian latent factor model SogBmf that combines social group influence and individual preference for event recommendation. Experiments on real-world data sets demonstrate the effectiveness of the proposed method.",2016,Conference on Information and Knowledge Management,world wide web;computer science;
A Distributed Graph Algorithm for Discovering Unique Behavioral Groups from Large-Scale Telco Data,"Qirong Ho (Agency for Science, Technology and Research);Wenqing Lin (Qatar Computing Research Institute);Eran Shaham (Agency for Science, Technology and Research);Shonali Krishnaswamy (Agency for Science, Technology and Research);Jingxuan Wang;Isabel Choo Zhongyan;Amy She-Nash (Commonwealth Bank);","2680888243,2637843321,2158094253,2722391233,2534485586,2536655407,2536591844","It is critical for a large telecommunications company such as Singtel to truly understand the behavior and preference of its customers, in order to win their loyalty in a highly fragmented and competitive market. In this paper we propose a novel graph edge-clustering algorithm (DGEC) that can discover unique behavioral groups, from rich usage data sets (such as CDRs and beyond). A behavioral group is a set of nodes that share similar edge properties reflecting customer behavior, but are not necessarily connected to each other and therefore different from the usual notion of graph communities. DGEC is an optimization-based model that uses the stochastic proximal gradient method, implemented as a distributed algorithm that scales to tens of millions of nodes and edges. The performance of DGEC is satisfactory for deployment, with an execution time of 2.4 hours over a graph of 5 million nodes and 27 million edges in a 8-machine environment (32 cores and 64GB memory per machine). We evaluate the behavioral groups discovered by DGEC by combining other information such as demographics and customer profiles, and demonstrate that these behavioral groups are objective, consistent and insightful. DGEC has now been deployed in production, and also shows promising potential to extract new usage behavioral features from other data sources such as web browsing, app usage and TV consumption.",2016,Conference on Information and Knowledge Management,graph;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Sentiment Domain Adaptation with Multi-Level Contextual Sentiment Knowledge,Fangzhao Wu (Tsinghua University);Sixing Wu (Tsinghua University);Yongfeng Huang (Tsinghua University);Songfang Huang (IBM);Yong Qin (IBM);,"2142281011,2538435370,2707325663,2649974384,2683655728","Sentiment domain adaptation is widely studied to tackle the domain-dependence problem in sentiment analysis field. Existing domain adaptation methods usually train a sentiment classifier in a source domain and adapt it to the target domain using transfer learning techniques. However, when the sentiment feature distributions of the source and target domains are significantly different, the adaptation performance will heavily decline. In this paper, we propose a new sentiment domain adaptation approach by adapting the sentiment knowledge in general-purpose sentiment lexicons to a specific domain. Since the general sentiment words of general-purpose sentiment lexicons usually convey consistent sentiments in different domains, they have better generalization performance than the sentiment classifier trained in a source domain. In addition, we propose to extract various kinds of contextual sentiment knowledge from massive unlabeled samples in target domain and formulate them as sentiment relations among sentiment expressions. It can propagate the sentiment information in general sentiment words to massive domain-specific sentiment expressions. Besides, we propose a unified framework to incorporate these different kinds of sentiment knowledge and learn an accurate domain-specific sentiment classifier for target domain. Moreover, we propose an efficient optimization algorithm to solve the model of our approach. Extensive experiments on benchmark datasets validate the effectiveness and efficiency of our approach.",2016,Conference on Information and Knowledge Management,sentiment analysis;natural language processing;data mining;pattern recognition;computer science;
Computing and Summarizing the Negative Skycube,Nicolas Hanusse (University of Bordeaux);Patrick Kamnang Wanko (University of Bordeaux);Sofian Maabout (University of Bordeaux);,"205862891,2529663074,20381947","Given a table T with a set of dimensions D , the skycube of T is the union of all skylines obtained by considering each of the subsets of D (subspaces). The number of these skylines is exponential w.r.t D . To make the skycube practically useful, two lines of research have been pursued so far: the first one aims to propose efficient algorithms for computing it and the second one considers either that the skycube is too large to be computed in a reasonable time or it requires too much memory space to be stored. They therefore propose skycube summarization techniques to reduce time and space consumption. Intuitively, previous efforts have been devoted to compute or summarize the following information: ``for every tuple t , list the skylines where t belongs to"". In this paper, we consider the complementary statement, i.e., ``for every tuple t , list the skylines where t does not belong to "". This is what we call the negative skycube . Despite the apparent equivalence between these two statements, our analysis and extensive experiments show that these two points of views do not lead to the same behavior of the related algorithms. More specifically, our proposal shows that (i) the negative summary can be obtained much faster than state of the art techniques for positive summaries, (ii) in general, it consumes less space, (iii) skyline queries evaluation using this summary are much faster, (iv) the positive skycube can be obtained much more rapidly than state of the art algorithms, and (v) it can be used for a larger class of queries, namely k -domination skylines.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
BIGtensor: Mining Billion-Scale Tensor Made Easy,Namyong Park (Seoul National University);Byungsoo Jeon (Seoul National University);Jungwoo Lee (Seoul National University);U Kang (Seoul National University);,"2118226915,2275868139,2653259750,2426051778","Many real-world data are naturally represented as tensors, or multi-dimensional arrays. Tensor decomposition is an important tool to analyze tensors for various applications such as latent concept discovery, trend analysis, clustering, and anomaly detection. However, existing tools for tensor analysis do not scale well for billion-scale tensors or offer limited functionalities. In this paper, we propose BIGtensor, a large-scale tensor mining library that tackles both of the above problems. Carefully designed for scalability, BIGtensor decomposes at least 100× larger tensors than the current state of the art. Furthermore, BIGtensor provides a variety of distributed tensor operations and tensor generation methods. We demonstrate how BIGtensor can help users discover hidden concepts and analyze trends from large-scale tensors that are hard to be processed by existing tensor tools.",2016,Conference on Information and Knowledge Management,tensor product network;tensor;tensor;machine learning;computer science;
Feature Driven and Point Process Approaches for Popularity Prediction,Swapnil Mishra (Australian National University);Marian-Andrei Rizoiu (Australian National University);Lexing Xie (Australian National University);,"2615983930,297821025,2100918400","Predicting popularity, or the total volume of information outbreaks, is an important subproblem for understanding collective behavior in networks. Each of the two main types of recent approaches to the problem, feature-driven and generative models, have desired qualities and clear limitations. This paper bridges the gap between these solutions with a new hybrid approach and a new performance benchmark. We model each social cascade with a marked Hawkes self-exciting point process, and estimate the content virality, memory decay, and user influence. We then learn a predictive layer for popularity prediction using a collection of cascade history. To our surprise, Hawkes process with a predictive overlay outperform recent feature-driven and generative approaches on existing tweet data [44] and a new public benchmark on news tweets. We also found that a basic set of user features and event time summary statistics performs competitively in both classification and regression tasks, and that adding point process information to the feature set further improves predictions. From these observations, we argue that future work on popularity prediction should compare across feature-driven and generative modeling approaches in both classification and regression tasks.",2016,Conference on Information and Knowledge Management,social media;data science;world wide web;data mining;machine learning;statistics;computer science;
Estimating Time Models for News Article Excerpts,Arunav Mishra (Max Planck Society);Klaus Berberich (Max Planck Society);,"2193995480,2064029816","It is often difficult to ground text to precise time intervals due to the inherent uncertainty arising from either missing or multiple expressions at year, month, and day time granularities. We address the problem of estimating an excerpt-time model capturing the temporal scope of a given news article excerpt as a probability distribution over chronons. For this, we propose a semi-supervised distribution propagation framework that leverages redundancy in the data to improve the quality of estimated time models. Our method generates an event graph with excerpts as nodes and models various inter-excerpt relations as edges. It then propagates empirical excerpt-time models estimated for temporally annotated excerpts, to those that are strongly related but miss annotations. In our experiments, we first generate a test query set by randomly sampling 100 Wikipedia events as queries. For each query, making use of a standard text retrieval model, we then obtain top-10 documents with an average of 150 excerpts. From these, each temporally annotated excerpt is considered as gold standard. The evaluation measures are first computed for each gold standard excerpt for a single query, by comparing the estimated model with our method to the empirical model from the original expressions. Final scores are reported by averaging over all the test queries. Experiments on the English Gigaword corpus show that our method estimates significantly better time models than several baselines taken from the literature.",2016,Conference on Information and Knowledge Management,data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
PowerWalk: Scalable Personalized PageRank via Random Walks with Vertex-Centric Decomposition,Qin Liu (The Chinese University of Hong Kong);Zhenguo Li (Huawei);John C. S. Lui (The Chinese University of Hong Kong);Jiefeng Cheng (Huawei);,"2723691361,2142886067,2045404162,2718574469","Most methods for Personalized PageRank (PPR) precompute and store all accurate PPR vectors, and at query time, return the ones of interest directly. However, the storage and computation of all accurate PPR vectors can be prohibitive for large graphs, especially in caching them in memory for real-time online querying. In this paper, we propose a distributed framework that strikes a better balance between offline indexing and online querying . The offline indexing attains a fingerprint of the PPR vector of each vertex by performing billions of ``short'' random walks in parallel across a cluster of machines. We prove that our indexing method has an exponential convergence, achieving the same precision with previous methods using a much smaller number of random walks. At query time, the new PPR vector is composed by a linear combination of related fingerprints, in a highly efficient vertex-centric decomposition manner. Interestingly, the resulting PPR vector is much more accurate than its offline counterpart because it actually uses more random walks in its estimation . More importantly, we show that such decomposition for a batch of queries can be very efficiently processed using a shared decomposition. Our implementation, PowerWalk , takes advantage of advanced distributed graph engines and it outperforms the state-of-the-art algorithms by orders of magnitude. Particularly, it responses to tens of thousands of queries on graphs with billions of edges in just a few seconds.",2016,Conference on Information and Knowledge Management,random walk;theoretical computer science;world wide web;distributed computing;data mining;statistics;computer science;
Discovering Entities with Just a Little Help from You,Jaspreet Singh;Johannes Hoffart (Max Planck Society);Avishek Anand (Max Planck Society);,"2340217318,1019296130,2127850459","Linking entities like people, organizations, books, music groups and their songs in text to knowledge bases (KBs) is a fundamental task for many downstream search and mining applications. Achieving high disambiguation accuracy crucially depends on a rich and holistic representation of the entities in the KB. For popular entities, such a representation can be easily mined from Wikipedia, and many current entity disambiguation and linking methods make use of this fact. However, Wikipedia does not contain long-tail entities that only few people are interested in, and also at times lags behind until newly emerging entities are added. For such entities, mining a suitable representation in a fully automated fashion is very difficult, resulting in poor linking accuracy. What can automatically be mined, though, is a high-quality representation given the context of a new entity occurring in any text. Due to the lack of knowledge about the entity, no method can retrieve these occurrences automatically with high precision, resulting in a chicken-egg problem. To address this, our approach automatically generates candidate occurrences of entities, prompting the user for feedback to decide if the occurrence refers to the actual entity in question. This feedback gradually improves the knowledge and allows our methods to provide better candidate suggestions to keep the user engaged. We propose novel human-in-the-loop retrieval methods for generating candidates based on gradient interleaving of diversification and textual relevance approaches. We conducted extensive experiments on the FACC dataset, showing that our approaches convincingly outperform carefully selected baselines in both intrinsic and extrinsic measures while keeping users engaged.",2016,Conference on Information and Knowledge Management,weak entity;entity linking;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Scalable Local-Recoding Anonymization using Locality Sensitive Hashing for Big Data Privacy Preservation,"Xuyun Zhang (University of Auckland);Christopher Leckie (University of Melbourne);Wanchun Dou (Nanjing University);Jinjun Chen (University of Technology, Sydney);Ramamohanarao Kotagiri (University of Melbourne);Zoran Salcic (University of Auckland);","2704436268,2111831791,2155983813,2170756005,1995540086,268055191","While cloud computing has become an attractive platform for supporting data intensive applications, a major obstacle to the adoption of cloud computing in sectors such as health and defense is the privacy risk associated with releasing datasets to third-parties in the cloud for analysis. A widely-adopted technique for data privacy preservation is to anonymize data via local recoding. However, most existing local-recoding techniques are either serial or distributed without directly optimizing scalability, thus rendering them unsuitable for big data applications. In this paper, we propose a highly scalable approach to local-recoding anonymization in cloud computing, based on Locality Sensitive Hashing (LSH). Specifically, a novel semantic distance metric is presented for use with LSH to measure the similarity between two data records. Then, LSH with the MinHash function family can be employed to divide datasets into multiple partitions for use with MapReduce to parallelize computation while preserving similarity. By using our efficient LSH-based scheme, we can anonymize each partition through the use of a recursive agglomerative $k$-member clustering algorithm. Extensive experiments on real-life datasets show that our approach significantly improves the scalability and time-efficiency of local-recoding anonymization by orders of magnitude over existing approaches.",2016,Conference on Information and Knowledge Management,cloud computing;big data;internet privacy;world wide web;data mining;database;computer science;
Hybrid Indexing for Versioned Document Search with Cluster-based Retrieval,"Xin Jin (University of California, Santa Barbara);Daniel Agun (University of California, Santa Barbara);Tao Yang (University of California, Santa Barbara);Qinghao Wu (University of California, Santa Barbara);Yifan Shen (University of California, Santa Barbara);Susen Zhao (University of California, Santa Barbara);","2525850132,2224413333,2584189575,2558493035,2263943090,2535403789",The previous two-phase method for searching versioned documents seeks a cost tradeoff by using non-positional information to rank document versions first. The second phase then re-ranks top document versions using positional information with fragment-based index compression. This paper proposes an alternative approach that uses cluster-based retrieval to quickly narrow the search scope guided by version representatives at Phase 1 and develops a hybrid index structure with adaptive runtime data traversal to speed up Phase 2 search. The hybrid scheme exploits the advantages of forward index and inverted index based on the term characteristics to minimize the time in extracting positional and other feature information during runtime search. This paper compares several indexing and data traversal options with different time and space tradeoffs and describes evaluation results to demonstrate their effectiveness. The experiment results show that the proposed scheme can be up-to about 4x as fast as the previous work on solid state drives while retaining good relevance.,2016,Conference on Information and Knowledge Management,inverted index;world wide web;information retrieval;data mining;database;computer science;
DDTA 2016: The Workshop on Data-Driven Talent Acquisition,Yi Fang (Santa Clara University);Maarten de Rijke (University of Amsterdam);Huangming Xie (LinkedIn);,"2158128598,401833296,2562536844","Expertise search is a well-established field in information retrieval. In recent years, the increasing availability of data enables accumulation of evidence of talent and expertise from a wide range of domains. The availability of big data significantly benefits employers and recruiters. By analyzing the massive amounts of structured and unstructured data, organizations may be able to find the exact skill sets and talent they need to grow their business. The aim of this workshop is to provide a forum for industry and academia to discuss the recent progress in talent search and management, and how the use of big data and data-driven decision making can advance talent acquisition and human resource management.",2016,Conference on Information and Knowledge Management,human resource management;management science;knowledge management;data mining;
Forecasting Geo-sensor Data with Participatory Sensing Based on Dropout Neural Network,"Jyun-Yu Jiang (University of California, Los Angeles);Cheng-Te Li (National Cheng Kung University);","2288553189,2139086518","Nowadays, geosensor data, such as air quality and traffic flow, have become more and more essential in people's daily life. However, installing geosensors or hiring volunteers at every location and every time is so expensive. Some organizations may have only few facilities or limited budget to sense these data. Moreover, people usually tend to know the forecast instead of ongoing observations, but the number of sensors (or volunteers) will be a hurdle to make precise prediction. In this paper, we propose a novel concept to forecast geosensor data with participatory sensing. Given a limited number of sensors or volunteers, participatory sensing assumes each of them can observe and collect data at different locations and at different time. By aggregating these sparse data observations in the past time, we propose a neural network based approach to forecast the future geosensor data in any location of an urban area. The extensive experiments have been conducted with large-scale datasets of the air quality in three cities and the traffic of bike sharing systems in two cities. Experimental results show that our predictive model can precisely forecast the air quality and the bike rentle traffic as geosensor data.",2016,Conference on Information and Knowledge Management,operations research;world wide web;data mining;artificial intelligence;simulation;
Effective and Efficient Spectral Clustering on Text and Link Data,"Zhiqiang Xu (Agency for Science, Technology and Research);Yiping Ke (Nanyang Technological University);","2720365357,2712540053","Clustering text and link data, as an important task in text and link analysis, aims at finding communities of linked documents by leveraging the information from both domains. Due to its improved performance over the single domain counterpart, it has attracted increasing attention from practitioners in recent years. Despite its popularity, all existing algorithms on clustering text and link data overlook the existence of domain-specific distinctions and thus result in unsatisfactory clustering quality. In this paper, we address this limitation by explicitly modeling the domain-specific distinctions in the clustering process. Specifically, we extend the idea of consensus and domain-specific subspace decomposition from flat data to graph data. Such a modeling, when coupled with a regularization to further sharpen the information distinction, makes the consensus information between text and link more accurate for clustering with both domains. The final model is cast into the spectral clustering model by imposing the subspace orthogonality. To eschew the costly eigen-decomposition required for spectral clustering and further speed-up the optimization, we take advantage of the data sparsity and the low dimensionality of subspaces, and deploy a constraint-preserving gradient method to efficiently solve the model. The experimental study on three real datasets shows that our algorithm consistently and significantly outperforms the state-of-the-art relevant algorithms in terms of both quality and efficiency.",2016,Conference on Information and Knowledge Management,flame clustering;brown clustering;canopy clustering algorithm;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;spectral clustering;fuzzy clustering;clustering high dimensional data;cluster analysis;efficiency;consensus clustering;biclustering;conceptual clustering;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;statistics;computer science;
Content-Agnostic Malware Detection in Heterogeneous Malicious Distribution Graph,Ibrahim M. Alabdulmohsin (King Abdullah University of Science and Technology);Yufei Han (Symantec);Yun Shen (Symantec);Xiangliang Zhang (King Abdullah University of Science and Technology);,"717680490,2636219526,2686816837,2129841492","Malware detection has been widely studied by analysing either file dropping relationships or characteristics of the file distribution network. This paper, for the first time, studies a global heterogeneous malware delivery graph fusing file dropping relationship and the topology of the file distribution network. The integration offers a unique ability of structuring the end-to-end distribution relationship. However, it brings large heterogeneous graphs to analysis. In our study, an average daily generated graph has more than 4 million edges and 2.7 million nodes that differ in type, such as IPs, URLs, and files. We propose a novel Bayesian label propagation model to unify the multi-source information, including content-agnostic features of different node types and topological information of the heterogeneous network. Our approach does not need to examine the source codes nor inspect the dynamic behaviours of a binary. Instead, it estimates the maliciousness of a given file through a semi-supervised label propagation procedure, which has a linear time complexity w.r.t. the number of nodes and edges. The evaluation on 567 million real-world download events validates that our proposed approach efficiently detects malware with a high accuracy.",2016,Conference on Information and Knowledge Management,bayesian inference;semi supervised learning;internet privacy;world wide web;data mining;database;machine learning;statistics;computer science;
A Framework for Task-specific Short Document Expansion,Ramakrishna B. Bairi (Indian Institute of Technology Bombay);Raghavendra Udupa (Microsoft);Ganesh Ramakrishnan (Indian Institute of Technology Bombay);,"1416699208,2147340292,2113956430","Collections that contain a large number of short texts are becoming increasingly common ( eg. , tweets, reviews, etc ). Analytical tasks (such as classification, clustering, etc. ) involving short texts could be challenging due to the lack of context and owing to their sparseness. An often encountered problem is low accuracy on the task. A standard technique used in the handling of short texts is expanding them before subjecting them to the task. However, existing works on short text expansion suffer from certain limitations: (i) they depend on domain knowledge to expand the text; (ii) they employ task-specific heuristics; and (iii) the expansion procedure is tightly coupled to the task. This makes it hard to adapt a procedure, designed for one task, into another. We present an expansion technique -- TIDE ( T ask-spec I fic short D ocument E xpansion) -- that can be applied on several Machine Learning, NLP and Information Retrieval tasks on short texts (such as short text classification, clustering, entity disambiguation, and the like) without using task specific heuristics and domain-specific knowledge for expansion. At the same time, our technique is capable of learning to expand short texts in a task-specific way. That is, the same technique that is applied to expand a short text in two different tasks is able to learn to produce different expansions depending upon what expansion benefits the task's performance. To speed up the learning process, we also introduce a technique called block learning . Our experiments with classification and clustering tasks show that our framework improves upon several baselines according to the standard evaluation metrics which includes the accuracy and normalized mutual information (NMI).",2016,Conference on Information and Knowledge Management,natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Using Machine Learning to Improve the Email Experience,Marc Najork (Google);,2477457921,"Email is an essential communication medium for billions of people, with most users relying on web-based email services. Two recent trends are changing the email experience: smartphones have become the primary tool for accessing online services including email, and machine learning has come of age. Smartphones have a number of compelling properties (they are location-aware, usually with us, and allow us to record and share photos and videos), but they also have a few limitations, notably limited screen size and small and tedious virtual keyboards. Over the past few years, Google researchers and engineers have leveraged machine learning to ameliorate these weaknesses, and in the process created novel experiences. In this talk, I will give three examples of machine learning improving the email experience. The first example describes how we are improving email search. Displaying the most relevant results as the query is being typed is particularly useful on smartphones due to the aforementioned limitations. Combining hand-crafted and machine-learned rankers is powerful, but training learned rankers requires a relevance-labeled training set. User privacy prohibits us from employing raters to produce relevance labels. Instead, we leverage implicit feedback (namely clicks) provided by the users themselves. Using click logs as training data in a learning-to-rank setting is intriguing, since there is a vast and continuous supply of fresh training data. However, the click stream is biased towards queries that receive more clicks -- e.g. queries for which we already return the best result in the top-ranked position. I will summarize our work on neutralizing that bias. The second example describes how we extract key information from appointment and reservation emails and surface it at the appropriate time as a reminder on the user's smartphone. Our basic approach is to learn the templates that were used to generate these emails, use these templates to extract key information such as places, dates and times, store the extracted records in a personal information store, and surface them at the right time, taking contextual information such as estimated transit time into account. The third example describes Smart Reply, a system that offers a set of three short responses to those incoming emails for which a short response is appropriate, allowing users to respond quickly with just a few taps, without typing or involving voice-to-text transcription. The basic approach is to learn a model of likely short responses to original emails from the corpus, and then to apply the model whenever a new message arrives. Other considerations include offering a set of responses that are all appropriate and yet diverse, and triggering only when sufficiently confident that each responses is of high quality and appropriate.",2016,Conference on Information and Knowledge Management,html email;ranking;information extraction;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
On Transductive Classification in Heterogeneous Information Networks,Xiang Li (University of Hong Kong);Ben Kao (University of Hong Kong);Yudian Zheng (University of Hong Kong);Zhipeng Huang (University of Hong Kong);,"2644215135,1911907851,2105493843,2511877038","A heterogeneous information network (HIN) is used to model objects of different types and their relationships. Objects are often associated with properties such as labels. In many applications, such as curated knowledge bases for which object labels are manually given, only a small fraction of the objects are labeled. Studies have shown that transductive classification is an effective way to classify and to deduce labels of objects, and a number of transductive classifiers have been put forward to classify objects in an HIN. We study the performance of a few representative transductive classification algorithms on HINs. We identify two fundamental properties, namely, cohesiveness and connectedness , of an HIN that greatly influence the effectiveness of transductive classifiers. We define metrics that measure the two properties. Through experiments, we show that the two properties serve as very effective indicators that predict the accuracy of transductive classifiers. Based on cohesiveness and connectedness we derive (1) a black-box tester that evaluates whether transductive classifiers should be applied for a given classification task and (2) an active learning algorithm that identifies the objects in an HIN whose labels should be sought in order to improve classification accuracy.",2016,Conference on Information and Knowledge Management,transduction;knowledge base;data mining;pattern recognition;machine learning;computer science;
APAM : Adaptive Eager-Lazy Hybrid Evaluation of Event Patterns for Low Latency,Ilyeop Yi (KAIST);Jae-Gil Lee (KAIST);Kyu-Young Whang (KAIST);,"2408627296,2134045017,1933211966","Event pattern detection refers to identifying combinations of events matched to a user-specified query event pattern from a real-time event stream. Latency is an important measure of the performance of an event pattern detection system. Existing methods can be classified into the eager evaluation method and the lazy evaluation method depending on when each event arrival is evaluated. These methods have advantages and disadvantages in terms of latency depending on the event arrival rate. In this paper, we propose a hybrid eager-lazy evaluation method that combines the advantages of both methods. For each event type, the hybrid method, which we call APAM ( Adaptive Partitioning-And-Merging ), determines which method to use: eager or lazy. We also propose a formal cost model to estimate the latency and propose a method of finding the optimal partition based on the cost model. Finally, we show through experiments that our method can improve the latency by up to 361.48 times over the eager evaluation method and 27.94 times over the lazy evaluation method using a synthetic data set.",2016,Conference on Information and Knowledge Management,complex event processing;hybrid;latency;theoretical computer science;parallel computing;database;real time computing;computer science;
Multi-View Time Series Classification: A Discriminative Bilinear Projection Approach,Sheng Li (Northeastern University);Yaliang Li (University at Buffalo);Yun Fu (Northeastern University);,"2618462548,2116094297,2123131494","By virtue of the increasingly large amount of various sensors, information about the same object can be collected from multiple views. These mutually enriched information can help many real-world applications, such as daily activity recognition in which both video cameras and on-body sensors are continuously collecting information. Such multivariate time series (m.t.s.) data from multiple views can lead to a significant improvement of classification tasks. However, the existing methods for time series data classification only focus on single-view data, and the benefits of mutual-support multiple views are not taken into account. In light of this challenge, we propose a novel approach, named Multi-view Discriminative Bilinear Projections (MDBP), for extracting discriminative features from multi-view m.t.s. data. First, MDBP keeps the original temporal structure of m.t.s. data, and projects m.t.s. from different views onto a shared latent subspace. Second, MDBP incorporates discriminative information by minimizing the within-class separability and maximizing the between-class separability of m.t.s. in the shared latent subspace. Moreover, a Laplacian regularization term is designed to preserve the temporal smoothness within m.t.s.. Extensive experiments on two real-world datasets demonstrate the effectiveness of our approach. Compared to the state-of-the-art multi-view learning and m.t.s. classification methods, our approach greatly improves the classification accuracy due to the full exploration of multi-view streaming data. Moreover, by using a feature fusion strategy, our approach further improves the classification accuracy by at least 10%.",2016,Conference on Information and Knowledge Management,data mining;pattern recognition;machine learning;
Off the Beaten Path: Let's Replace Term-Based Retrieval with k-NN Search,Leonid Boytsov (Carnegie Mellon University);David Novak (Masaryk University);Yury Malkov;Eric Nyberg (Carnegie Mellon University);,"253157154,2312116117,2652869245,2074756409","Retrieval pipelines commonly rely on a term-based search to obtain candidate records, which are subsequently re-ranked. Some candidates are missed by this approach, e.g., due to a vocabulary mismatch. We address this issue by replacing the term-based search with a generic k -NN retrieval algorithm, where a similarity function can take into account subtle term associations. While an exact brute-force k -NN search using this similarity function is slow, we demonstrate that an approximate algorithm can be nearly two orders of magnitude faster at the expense of only a small loss in accuracy. A retrieval pipeline using an approximate k -NN search can be more effective and efficient than the term-based pipeline. This opens up new possibilities for designing effective retrieval pipelines. Our software (including data-generating code) and derivative data based on the Stack Overflow collection is available online.",2016,Conference on Information and Knowledge Management,theoretical computer science;world wide web;information retrieval;data mining;machine learning;computer science;
Answering Twitter Questions: a Model for Recommending Answerers through Social Collaboration,Laure Soulier (University of Paris);Lynda Tamine (University of Toulouse);Gia-Hung Nguyen (United Parcel Service);,"1986048695,62726460,2471116620","In this paper, we specifically consider the challenging task of solving a question posted on Twitter. The latter generally remains unanswered and most of the replies, if any, are only from members of the questioner's neighborhood. As outlined in previous work related to community Q&A, we believe that question-answering is a collaborative process and that the relevant answer to a question post is an aggregation of answer nuggets posted by a group of relevant users. Thus, the problem of identifying the relevant answer turns into the problem of identifying the right group of users who would provide useful answers and would possibly be willing to collaborate together in the long-term. Accordingly, we present a novel method, called CRAQ, that is built on the collaboration paradigm and formulated as a group entropy optimization problem. To optimize the quality of the group, an information gain measure is used to select the most likely ``informative"" users according to topical and collaboration likelihood predictive features. Crowd-based experiments performed on two crisis-related Twitter datasets demonstrate the effectiveness of our collaborative-based answering approach.",2016,Conference on Information and Knowledge Management,knowledge management;world wide web;information retrieval;data mining;computer science;
ConHub: A Metadata Management System for Docker Containers,Chris Xing Tian (National University of Singapore);Aditya Pan (Amity University);Yong Chiang Tay (National University of Singapore);,"2506894745,2503702942,2110494393","For many years now, enterprises and cloud providers have been using virtualization to run their workloads. Until recently, this means running an application in a virtual machine (hardware virtualization). However, virtual machines are increasingly replaced by containers (operating system virtualization), as evidenced by the rapid rise of Docker. A containerized software environment can generate a large amount of metadata. If properly managed, these metadata can greatly facilitate the management of containers themselves. This demonstration introduces ConHub, a PostgreSQL-based container metadata management system. Visitors will see that (1) ConHub has a language CQL that supports Docker commands; (2) it has a user-friendly interface for querying and visualizing container relationships; and (3) they can use CQL to formulate sophisticated queries to facilitate container management.",2016,Conference on Information and Knowledge Management,full virtualization;metadata repository;relational database;world wide web;operating system;data mining;database;computer science;
Query-Biased Partitioning for Selective Search,Zhuyun Dai (Carnegie Mellon University);Chenyan Xiong (Carnegie Mellon University);Jamie Callan (Carnegie Mellon University);,"2398480995,2226924701,2148123616","Selective search is a cluster-based distributed retrieval architecture that reduces computational costs by partitioning a corpus into topical shards , and selectively searching them. Prior research formed topical shards by clustering the corpus based on the documents' contents. This content-based partitioning strategy reveals common topics in a corpus. However, the topic distribution produced by clustering may not match the distribution of topics in search traffic, which may reduce the effectiveness of selective search. This paper presents a query-biased partitioning strategy that aligns document partitions with topics from query logs . It focuses on two parts of the partitioning process: clustering initialization and document similarity calculation. A query-driven clustering initialization algorithm uses topics from query logs to form cluster seeds. A query-biased similarity metric favors terms that are important in query logs. Both methods boost retrieval effectiveness, reduce variance, and produce a more balanced distribution of shard sizes.",2016,Conference on Information and Knowledge Management,information retrieval;data mining;database;machine learning;computer science;
The Solitude of Relevant Documents in the Pool,Aldo Lipani (Vienna University of Technology);Mihai Lupu (Vienna University of Technology);Evangelos Kanoulas (University of Amsterdam);Allan Hanbury (Vienna University of Technology);,"1518226153,2010059705,2627690640,2168901591","Pool bias is a well understood problem of test-collection based benchmarking in information retrieval. The pooling method itself is designed to identify all relevant documents. In practice, 'all' translates to `as many as possible given some budgetary constraints' and the problem persists, albeit mitigated. Recently, methods to address this pool bias for previously created test collections have been proposed, for the evaluation measure precision at cut-off (P@n). Analyzing previous methods, we make the empirical observation that the distribution of the probability of providing new relevant documents to the pool, over the runs, is log-normal (when the pooling strategy is fixed depth at cut-off). We use this observation to calculate a prior probability of providing new relevant documents, which we then use in a pool bias estimator that improves upon previous estimates of precision at cut-off. Through extensive experimental results, covering 15 test collections, we show that the proposed bias correction method is the new state of the art, providing the closest estimates yet when compared to the original pool.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;computer science;
Q+Tree: An Efficient Quad Tree based Data Indexing for Parallelizing Dynamic and Reverse Skylines,Md. Saiful Islam 0003 (La Trobe University);Chengfei Liu (Swinburne University of Technology);J. Wenny Rahayu (La Trobe University);Tarique Anwar (Swinburne University of Technology);,"2684735252,2144108974,2096900180,2125769409","Skyline queries play an important role in multi-criteria decision making applications of many areas. Given a dataset of objects, a skyline query retrieves data objects that are not dominated by any other data object in the dataset. Unlike standard skyline queries where the different aspects of data objects are compared directly, dynamic and reverse skyline queries adhere to the around-by semantics, which is realized by comparing the relative distances of the data objects w.r.t. a given query. Though, there are a number of works on parallelizing the standard skyline queries, only a few works are devoted to the parallel computation of dynamic and reverse skyline queries. This paper presents an efficient quad-tree based data indexing scheme, called Q+Tree, for parallelizing the computations of the dynamic and reverse skyline queries. We compare the performance of Q+Tree with an existing quad-tree based indexing scheme. We also present several optimization heuristics to improve the performance of both of the indexing schemes further. Experimentation with both real and synthetic datasets verifies the efficiency of the proposed indexing scheme and optimization heuristics.",2016,Conference on Information and Knowledge Management,quadtree;load balancing;theoretical computer science;data mining;database;computer science;
"A Self-Learning and Online Algorithm for Time Series Anomaly Detection, with Application in CPU Manufacturing",Xing Wang (George Mason University);Jessica Lin (George Mason University);Nital Patel (Intel);Martin Braun (Intel);,"2309573071,2100950507,2194658547,2506864248","The problem of anomaly detection in time series has received a lot of attention in the past two decades. However, existing techniques cannot locate where the anomalies are within anomalous time series, or they require users to provide the length of potential anomalies. To address these limitations, we propose a self-learning online anomaly detection algorithm that automatically identifies anomalous time series, as well as the exact locations where the anomalies occur in the detected time series. We evaluate our approach on several real datasets, including two CPU manufacturing data from Intel. We demonstrate that our approach can successfully detect the correct anomalies without requiring any prior knowledge about the data.",2016,Conference on Information and Knowledge Management,time series;anomaly detection;data mining;real time computing;machine learning;statistics;computer science;
ZEST: A Hybrid Model on Predicting Passenger Demand for Chauffeured Car Service,Hua Wei (Beihang University);Yuandong Wang (Beihang University);Tianyu Wo (Beihang University);Yaxiao Liu (Tsinghua University);Jie Xu (Beihang University);,"2666839791,2566165873,2687457955,2688561202,2667666958","Chauffeured car service based on mobile applications like Uber or Didi suffers from supply-demand disequilibrium, which can be alleviated by proper prediction on the distribution of passenger demand. In this paper, we propose a Z ero-Grid E nsemble S patio T emporal model ( ZEST ) to predict passenger demand with four predictors: a temporal predictor and a spatial predictor to model the influences of local and spatial factors separately, an ensemble predictor to combine the results of former two predictors comprehensively and a Zero-Grid predictor to predict zero demand areas specifically since any cruising within these areas costs extra waste on energy and time of driver. We demonstrate the performance of ZEST on actual operational data from ride-hailing applications with more than 6 million order records and 500 million GPS points. Experimental results indicate our model outperforms 5 other baseline models by over 10% both in MAE and sMAPE on the three-month datasets.",2016,Conference on Information and Knowledge Management,simulation;
A Preference Approach to Reputation in Sponsored Search,Aritra Ghosh (Microsoft);Dinesh Gaurav (Microsoft);Rahul Agrawal (Microsoft);,"2538060625,2565840240,2546543800","Determining reputation of an advertiser in sponsored search is a recent important problem with direct impact on revenue for web publishers and relevance of ads. Individual performance of advertisers is usually expressed through observed click through rate, which depends on advertiser reputation, ad relevance and position. However, advertiser reputation has not been explicitly modeled in click prediction literature. Using traditional approaches in web page popularity for organic search in this context is not reasonable as the notion of link-structure in web is not directly applicable to sponsored search. In this study, we motivate and propose a pairwise preference relation model to study the advertiser reputation problem. Pairwise comparisons of advertisers give information over and above the information available in their individual historical performances. We relate the notion of preference among the advertisers to the spectral properties of the preference graph. We provide empirical evidence of the existence of reputation bias in click behavior. Consequently, we experiment with this signal to improve click prediction.",2016,Conference on Information and Knowledge Management,world wide web;data mining;computer science;
OptMark: A Toolkit for Benchmarking Query Optimizers,Zhan Li (Brandeis University);Olga Papaemmanouil (Brandeis University);Mitch Cherniack (Brandeis University);,"2338064268,166316913,2003519162","Query optimizers have long been considered as among the most complex components of a database engine, while the assessment of an optimizer's quality remains a challenging task. Indeed, existing performance benchmarks for database engines (like TPC benchmarks) produce a performance assessment of the query runtime system rather than its query optimizer. To address this challenge, this paper introduces OptMark , a toolkit for evaluating the quality of a query optimizer. OptMark is designed to offer a number of desirable properties. First, it decouples the quality of an optimizer from the quality of its underlying execution engine. Second it evaluates independently both the effectiveness of an optimizer (i.e., quality of the chosen plans) and its efficiency (i.e., optimization time). OptMark includes also a generic benchmarking toolkit that is minimum invasive to the DBMS that wishes to use it. Any DBMS can provide a system-specific implementation of a simple API that allows OptMark to run and generate benchmark scores for the specific system. This paper discusses the metrics we propose for evaluating an optimizer's quality, the benchmark's design and the toolkit's API and functionality. We have implemented OptMark on the open-source MySQL engine as well as two commercial database systems. Using these implementations we are able to assess the quality of the optimizers on these three systems based on the TPC-DS benchmark queries.",2016,Conference on Information and Knowledge Management,sargable;query optimization;benchmarking;world wide web;data mining;database;computer science;
Reuse-based Optimization for Pig Latin,Jesús Camacho-Rodríguez (University of Paris-Sud);Dario Colazzo (Paris Dauphine University);Melanie Herschel (University of Stuttgart);Ioana Manolescu (French Institute for Research in Computer Science and Automation);Soudip Roy Chowdhury;,"2017015447,113461303,2158630827,740816581,2698690435","Pig Latin is a popular language which is widely used for parallel processing of massive data sets. Currently, subexpressions occurring repeatedly in Pig Latin scripts are executed as many times as they appear, and the current Pig Latin optimizer does not identify reuse opportunities. We present a novel optimization approach aiming at identifying and reusing repeated subexpressions in Pig Latin scripts. Our optimization algorithm, named PigReuse, identifies subexpression merging opportunities, selects the best ones to execute based on a cost function, and reuses their results as needed in order to compute exactly the same output as the original scripts. Our experiments demonstrate the effectiveness of our approach.",2016,Conference on Information and Knowledge Management,big data;linear programming;theoretical computer science;data mining;database;artificial intelligence;machine learning;simulation;computer science;
A Density-Based Approach to the Retrieval of Top-K Spatial Textual Clusters,Dingming Wu (Shenzhen University);Christian Søndergaard Jensen (Aalborg University);,"2118818107,2159644763","Spatial keyword queries retrieve spatial textual objects that are near a query location and are relevant to query keywords. The paper defines the top- k spatial textual clusters ( k -STC) query that returns the top- k clusters that are located close to a given query location, contain relevant objects with regard to given query keywords, and have an object density that exceeds a given threshold. This query aims to support users who wish to explore nearby regions with many relevant objects. To compute this query, the paper proposes a basic and an advanced algorithm that rely on on-line density-based clustering. An empirical study offers insight into the performance properties of the proposed algorithms.",2016,Conference on Information and Knowledge Management,sargable;rdf query language;boolean conjunctive query;spark;web search query;web query classification;spatial query;query expansion;query optimization;benchmark;query language;information retrieval;data mining;database;computer science;
Clustering Speed in Multi-lane Traffic Networks,Bing Zhang (Northwestern University);Goce Trajcevski (Northwestern University);Feiying Liu (Northwestern University);,"2311374292,98612900,2560180177","We address the problem of efficient spatio-temporal clustering of speed data in road segments with multiple lanes. We postulate that the navigation/route plans typically reported by different providers as a single-value need not be accurate in multi-lane networks. Our methodology generates lane-aware distribution of speed from GPS data and agglomerates the basic space and time units into larger clusters. Thus, we achieve a compact description of speed variations which can be subsequently used for more accurate trips planning. We provide experiments that demonstrate the benefits of our proposed approaches.",2016,Conference on Information and Knowledge Management,trajectory;simulation;
Improving Search Results with Prior Similar Queries,Yashar Moshfeghi (University of Glasgow);Kristiyan Velinov (University of Glasgow);Peter Triantafillou (University of Glasgow);,"92283206,2534961708,318333653","This paper describes a novel approach to re-ranking search engine result pages (SERP): Its fundamental principle is to re-rank results to a given query, based on exploiting evidence gathered from past similar search queries. Our approach is inspired by collaborative filtering, with the main challenge being to find the set of similar queries, while also taking efficiency into account. In particular, our approach aims to address this challenge by proposing a combination of a similarity graph and a locality sensitive hashing scheme. We construct a set of features from our similarity graph and build a prediction model using the Hoeffding decision tree algorithm. We have evaluated the effectiveness of our model in terms of P@1, MAP@10, and nDCG@10, using the Yandex Data Challenge data set. We have compared the performance of our model against two baselines, namely, the Yandex initial ranking and the decision tree model learnt on the same set of features when extracted based on query repetition (i.e. excluding the evidence of similar queries in our approach). Our results reveal that the proposed approach consistently and (statistically) significantly outperforms both baselines.",2016,Conference on Information and Knowledge Management,collaborative filtering;graph;world wide web;information retrieval;data mining;database;machine learning;computer science;
Digesting Multilingual Reader Comments via Latent Discussion Topics with Commonality and Specificity,Bei Shi (The Chinese University of Hong Kong);Wai Lam (The Chinese University of Hong Kong);Lidong Bing (Carnegie Mellon University);Yinqing Xu (The Chinese University of Hong Kong);,"2250712956,2119595446,2160800796,2156201790","Many news websites from different regions in the world allow readers to write comments in their own languages about an event. Digesting such enormous amount of comments in different languages is difficult. One elegant way to digest and organize these comments is to detect latent discussion topics with the consideration of language attributes. Some discussion topics are common topics shared between languages whereas some topics are specifically dominated by a particular language. To tackle this task of discovering discussion topics that exhibit commonality or specificity from news reader comments written in different languages, we propose a new model called TDCS based on graphical models, which can cope with the language gap and detect language-common and language-specific latent discussion topics simultaneously. Our TDCS model also exploits comment-oriented clues via a scalable Dirichlet Multinomial Regression method. To learn the model parameters, we develop an inference method which alternates between EM and Gibbs sampling. Experimental results show that our proposed TDCS model can provide an effective way to digest multilingual news reader comments.",2016,Conference on Information and Knowledge Management,natural language processing;world wide web;speech recognition;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Graph Topic Scan Statistic for Spatial Event Detection,"Yu Liu (University of Hong Kong);Baojian Zhou (University at Albany, SUNY);Feng Chen (University at Albany, SUNY);David W. Cheung (University of Hong Kong);","2533001184,2657541502,2658979844,1979772396","Spatial event detection is an important and challenging problem. Unlike traditional event detection that focuses on the timing of global urgent event, the task of spatial event detection is to detect the spatial regions (e.g. clusters of neighboring cities) where urgent events occur. In this paper, we focus on the problem of spatial event detection using textual information in social media. We observe that, when a spatial event occurs, the topics relevant to the event are often discussed more coherently in cities near the event location than those far away. In order to capture this pattern, we propose a new method called Graph Topic Scan Statistic (Graph-TSS) that corresponds to a generalized log-likelihood ratio test based on topic modeling. We first demonstrate that the detection of spatial event regions under Graph-TSS is NP-hard due to a reduction from classical node-weighted prize-collecting Steiner tree problem (NW-PCST). We then design an efficient algorithm that approximately maximizes the graph topic scan statistic over spatial regions of arbitrary form. As a case study, we consider three applications using Twitter data, including Argentina civil unrest event detection, Chile earthquake detection, and United States influenza disease outbreak detection. Empirical evidence demonstrates that the proposed Graph-TSS performs superior over state-of-the-art methods on both running time and accuracy.",2016,Conference on Information and Knowledge Management,topic model;data mining;pattern recognition;machine learning;statistics;computer science;
Improving Personalized Trip Recommendation by Avoiding Crowds,Xiaoting Wang (University of Melbourne);Christopher Leckie (University of Melbourne);Jeffrey Chan (RMIT University);Kwan Hui Lim (University of Melbourne);Tharshan Vaithianathan (University of Melbourne);,"2306464015,2111831791,2408228308,2080969542,1903149906","There has been a growing interest in recommending trips for tourists using location-based social networks. The challenge of trip recommendation not only lies in searching for relevant points-of-interest (POIs) to form a personalized trip, but also selecting the best time of day to visit the POIs. Popular POIs can be too crowded during peak times, resulting in long queues and delays. In this work, we propose the Personalized Crowd-aware Trip Recommendation (PersCT) algorithm to recommend personalized trips that also avoid the most crowded times of the POIs. We model the problem as an extension of the Orienteering Problem with multiple constraints. We extract user interests by collaborative filtering and we propose an extension of the Ant Colony Optimisation algorithm to merge user interests with POI popularity and crowdedness data to recommend trips. We evaluate our algorithm using foot traffic information obtained from a real-life pedestrian sensor dataset and user travel histories extracted from a Flickr photo dataset. We show that our algorithm out-performs several benchmarks in achieving a balance between conflicting objectives by satisfying user interests while reducing the crowdedness of the trips.",2016,Conference on Information and Knowledge Management,world wide web;data mining;simulation;
Bus Routes Design and Optimization via Taxi Data Analytics,"Seong Ping Chuah (Agency for Science, Technology and Research);Huayu Wu (Agency for Science, Technology and Research);Yu Lu (Agency for Science, Technology and Research);Liang Yu (Agency for Science, Technology and Research);Stephane Bressan (National University of Singapore);","2534616701,2704714878,2671388445,2682291251,2159446685","Public bus services are often planned in the context of urban planning. For a city with efficient and extensive network of public transportation system like Singapore, enhancing the existing coverage of bus service to meet the dynamic mobility needs of the population requires data mining approach. Specifically, frequent taxi rides between two locations at a period of time may suggest possible poor coverage of public transport service, if not lacking of the public transport service. In this paper, we describe a proof of concept effort to discover this weakness and its improvement in public transportation system via mining of taxi ride dataset. We cluster taxi rides dataset to determine some popular taxi rides in Singapore. From the clustered taxi rides, we filter and select only the clusters whose commuting via existing public transport are tortuous if not unreachable door-to-door. Based on the discovered travel pattern, we propose new bus routes that serve the passengers of these clusters. We formulate the bus planning problem as an optimization of directed cycle graph, and present it's preliminary solution and results. We showcase our idea in the case of Singapore.",2016,Conference on Information and Knowledge Management,cluster analysis;computer security;machine learning;simulation;computer science;
Hierarchical and Dynamic k -Path Covers,Takuya Akiba (University of Tokyo);Yosuke Yano (University of Tokyo);Naoto Mizuno (University of Tokyo);,"2149787982,2366236231,2125072240","A metric-independent data structure for spatial networks called k-all-path cover ( k -APC) has recently been proposed. It involves a set of vertices that covers all paths of size k , and is a general indexing technique that can accelerate various path-related processes on spatial networks, such as route planning and path subsampling to name a few. Although it is a promising tool, it currently has drawbacks pertaining to its construction and maintenance. First, k -APCs, especially for large values of k , are computationally too expensive. Second, an important factor related to quality is ignored by a prevalent construction algorithm. Third, an existing algorithm only focuses on static networks. To address these issues, we propose novel k -APC construction and maintenance algorithms. Our algorithms recursively construct the layers of APCs, which we call the k-all-path cover hierarchy , by using vertex cover heuristics. This allows us to extract k -APCs for various values of k from the hierarchy. We also devise an algorithm to maintain k -APC hierarchies on dynamic networks. Our experiments showed that our construction algorithm can yield high solution quality, and has a short running time for large values of k . They also verified that our dynamic algorithm can handle an edge weight change within 40 ms.",2016,Conference on Information and Knowledge Management,search engine indexing;graph;theoretical computer science;world wide web;data mining;database;artificial intelligence;machine learning;algorithm;computer science;
Global and Local Influence-based Social Recommendation,"Qinzhe Zhang (University of Technology, Sydney);Jia Wu (University of Technology, Sydney);Hong Yang (MathWorks);Weixue Lu (Chinese Academy of Sciences);Guodong Long (University of Technology, Sydney);Chengqi Zhang (University of Technology, Sydney);","2491414791,2151584597,2615632406,2642977947,2140909072,2166080598","Social recommendation has been widely studied in recent years. Existing social recommendation models use various explicit pieces of social information as regularization terms in recommendation, for instance, social links are considered as new constraints. However, social influence, an implicit source of information in social networks, is seldomly considered, even though it often drives recommendations in social networks. In this paper, we introduce a new global and local influence-based social recommendation model. Based on the observation that user purchase behaviour is influenced by both global influential nodes and the local influential nodes of the user, we formulate the global and local influence as an regularization terms, and incorporate them into a matrix factorization-based recommendation model. Experimental results on large data sets demonstrate the performance of the proposed method.",2016,Conference on Information and Knowledge Management,world wide web;data mining;
Automatic Generation and Validation of Road Maps from GPS Trajectory Data Sets,Hengfeng Li (University of Melbourne);Lars Kulik (University of Melbourne);Kotagiri Ramamohanarao (University of Melbourne);,"2224550669,1899350157,123309386","With the popularity of mobile GPS devices such as on-board navigation systems and smart phones, users can contribute their GPS trajectory data for creating geo-volunteered road maps. However, the quality of these road maps cannot be guaranteed due to the lack of expertise among contributing users. Therefore, important challenges are (i) to automatically generate accurate roads from GPS traces and (ii) to validate the correctness of existing road maps. To address these challenges, we propose a novel Spatial-Linear Clustering (SLC) technique to infer road segments from GPS traces. In our algorithm, we propose the use of spatial-linear clusters to appropriately represent the linear nature of GPS points collected from the same road segment. Through inferring road segments our algorithm can detect missing roads and checking the correctness of existing road network. For our evaluation, we conduct extensive experiments that compare our method to the state-of-the-art methods on two real data sets. The experimental results show that the F1 score of our algorithm is on average 10.7% higher than the best state-of-the-art method.",2016,Conference on Information and Knowledge Management,data mining;simulation;
Geotagging Named Entities in News and Online Documents,Jiangwei Yu Rafiei (University of Alberta);Davood Rafiei (University of Alberta);,"2532947903,272765103","News sources generate constant streams of text with many references to real world entities; understanding the content from such sources often requires effectively detecting the geographic foci of the entities. We study the problem of associating geography to named entities in online documents. More specifically, given a named entity and a page (or a set of pages) where the entity is mentioned, the problem being studied is how the geographic focus of the name can be resolved at a location granularity (e.g. city or country), assuming that the name has a geographic focus. We further study dispersion, and show that the dispersion of a name can be estimated with a good accuracy, allowing a geo-centre to be detected at an exact dispersion level. Two key features of our approach are: (i) minimal assumption is made on the structure of the mentions hence the approach can be applied to a diverse and heterogeneous set of web pages, and (ii) the approach is unsupervised, leveraging shallow English linguistic features and the large volume of location data in public domain. We evaluate our methods under different task settings and with different categories of named entities. Our evaluation reveals that the geo-centre of a name can be estimated with a good accuracy based on some simple statistics of the mentions, and that the accuracy of the estimation varies with the categories of the names.",2016,Conference on Information and Knowledge Management,geotagging;web mining;content analysis;world wide web;information retrieval;data mining;database;computer science;
Tag2Word: Using Tags to Generate Words for Content Based Tag Recommendation,Yong Wu (Nanjing University);Yuan Yao (Nanjing University);Feng Xu (Nanjing University);Hanghang Tong (Arizona State University);Jian Lu (Nanjing University);,"2697153965,2617797049,2720220320,2667261544,2639471847","Tag recommendation is helpful for the categorization and searching of online content. Existing tag recommendation methods can be divided into collaborative filtering methods and content based methods. In this paper, we put our focus on the content based tag recommendation due to its wider applicability. Our key observation is the tag-content co-occurrence, i.e., many tags have appeared multiple times in the corresponding content. Based on this observation, we propose a generative model (Tag2Word), where we generate the words based on the tag-word distribution as well as the tag itself. Experimental evaluations on real data sets demonstrate that the proposed method outperforms several existing methods in terms of recommendation accuracy, while enjoying linear scalability.",2016,Conference on Information and Knowledge Management,generative model;world wide web;information retrieval;data mining;machine learning;computer science;
Querying Minimal Steiner Maximum-Connected Subgraphs in Large Graphs,Jiafeng Hu (University of Hong Kong);Xiaowei Wu (University of Hong Kong);Reynold Cheng (University of Hong Kong);Siqiang Luo (University of Hong Kong);Yixiang Fang (University of Hong Kong);,"2550217635,2118871531,2138267588,2120933249,2277390951","Given a graph G and a set Q of query nodes, we examine the Steiner Maximum-Connected Subgraph (SMCS). The SMCS, or G's induced subgraph that contains Q with the largest connectivity, can be useful for customer prediction, product promotion, and team assembling. Despite its importance, the SMCS problem has only been recently studied. Existing solutions evaluate the maximum SMCS, whose number of nodes is the largest among all the SMCSs of Q. However, the maximum SMCS, which may contain a lot of nodes, can be difficult to interpret. In this paper, we investigate the minimal SMCS, which is the minimal subgraph of G with the maximum connectivity containing Q. The minimal SMCS contains much fewer nodes than its maximum counterpart, and is thus easier to be understood. However, the minimal SMCS can be costly to evaluate. We thus propose efficient Expand-Refine algorithms, as well as their approximate versions with accuracy guarantees. Extensive experiments on six large real graph datasets validate the effectiveness and efficiency of our approaches.",2016,Conference on Information and Knowledge Management,mathematical optimization;
Crowdsourcing-based Urban Anomaly Prediction System for Smart Cities,Chao Huang (University of Notre Dame);Xian Wu (University of Notre Dame);Dong Wang (University of Notre Dame);,"2723474616,2646522146,2651092694","Crowdsourcing has become an emerging data collection paradigm for smart city applications. A new category of crowdsourcing-based urban anomaly reporting systems have been developed to enable pervasive and real-time reporting of anomalies in cities (e.g., noise, illegal use of public facilities, urban infrastructure malfunctions). An interesting challenge in these applications is how to accurately predict an anomaly in a given region of the city before it happens. Prior works have made significant progress in anomaly detection. However, they can only detect anomalies after they happen, which may lead to significant information delay and lack of preparedness to handle the anomalies in an efficient way. In this paper, we develop a Crowdsourcing-based Urban Anomaly Prediction Scheme (CUAPS) to accurately predict the anomalies of a city by exploring both spatial and temporal information embedded in the crowdsourcing data. We evaluated the performance of our scheme and compared it to the state-of-the-art baselines using four real-world datasets collected from 311 service in the city of New York. The results showed that our scheme can predict different categories of anomalies in a city more accurately than the baselines.",2016,Conference on Information and Knowledge Management,crowdsourcing;bayesian inference;data science;computer security;data mining;statistics;computer science;
FolkTrails: Interpreting Navigation Behavior in a Social Tagging System,Thomas Niebler (University of Würzburg);Martin Becker (University of Würzburg);Daniel Zoller (University of Würzburg);Stephan Doerfel (University of Kassel);Andreas Hotho (University of Würzburg);,"301749610,2343475332,2139750634,2006480174,20543882","Social tagging systems have established themselves as a quick and easy way to organize information by annotating resources with tags. In recent work, user behavior in social tagging systems was studied, that is, how users assign tags, and consume content. However, it is still unclear how users make use of the navigation options they are given. Understanding their behavior and differences in behavior of different user groups is an important step towards assessing the effectiveness of a navigational concept and improving it to better suit the users' needs. In this work, we investigate navigation trails in the popular scholarly social tagging system BibSonomy from six years of log data. We discuss dynamic browsing behavior of the general user population and show that different navigational subgroups exhibit different navigational traits. Furthermore, we provide strong evidence that the semantic nature of the underlying folksonomy is an essential factor for explaining navigation.",2016,Conference on Information and Knowledge Management,semantic similarity;multimedia;world wide web;information retrieval;computer science;
TweetSift: Tweet Topic Classification Based on Entity Knowledge Base and Topic Enhanced Word Embedding,Quanzhi Li (Thomson Reuters);Sameena Shah (Thomson Reuters);Xiaomo Liu (Thomson Reuters);Armineh Nourbakhsh (Thomson Reuters);Rui Fang (Thomson Reuters);,"2261932186,2114545764,2490351473,2232518488,2427571942","Classifying tweets into topic categories is necessary and important for many applications, since tweets are about a variety of topics and users are only interested in certain topical areas. Many tweet classification approaches fail to achieve high accuracy due to data sparseness issue. Tweet, as a special type of short text, in additional to its text, also has other metadata that can be used to enrich its context, such as user name, mention, hashtag and embedded link. In this demonstration, we present TweetSift, an efficient and effective real time tweet topic classifier. TweetSift exploits external tweet-specific entity knowledge to provide more topical context for a tweet, and integrates them with topic enhanced word embeddings for topic classification. The demonstration will show how TweetSift works and how it is incorporated with our social media event detection system.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;computer science;
eGraphSearch: Effective Keyword Search in Graphs,Mehdi Kargar (University of Windsor);Lukasz Golab (University of Waterloo);Jaroslaw Szlichta (University of Ontario Institute of Technology);,"2126665663,2618045780,2308200152","In a node-labeled graph, keyword search finds subtrees of the graph whose nodes contain all of the query keywords. This provides a way to query graph databases that neither requires mastery of a query language such as SPARQL, nor a deep knowledge of the database schema. We demonstrate eGraphSearch, a new system for effective keyword search in graph databases. Previous work ranks answer trees using combinations of structural and content-based metrics, such as path length between keywords or relevance of the labels in the answer tree to the query keywords. However, different nodes in the graph might have different importance, which affects the utility of the answer. In the proposed system, we implemented two new ways to rank keyword search results over graphs: the first one takes node importance into account while the second one is a bi-objective optimization of edge weights and node importance. In the demonstration, participants will execute keyword queries against several popular graph datasets.",2016,Conference on Information and Knowledge Management,keyword density;graph operations;graph database;web search query;graph;null model;information retrieval;data mining;database;computer science;
Constructing Reliable Gradient Exploration for Online Learning to Rank,Tong Zhao (The Chinese University of Hong Kong);Irwin King (The Chinese University of Hong Kong);,"2689099768,2121363826","With the rapid development of information retrieval (IR) systems, online learning to rank (OLR) approaches, which allow retrieval systems to automatically learn best parameters from user interactions, have attracted great research interests in recent years. In OLR, the algorithms usually need to explore some uncertain retrieval results for updating current parameters meanwhile guaranteeing to produce quality retrieval results by exploiting what have already been learned, and the final retrieval results is an interleaved list from both exploratory and exploitative results. However, existing OLR algorithms perform exploration based on either only one stochastic direction or multiple randomly selected stochastic directions, which always involve large variance and uncertainty into the exploration, and may further harm the retrieval quality. Moreover, little historical exploration knowledge is considered when conducting current exploration. In this paper, we propose two OLR algorithms that improve the reliability of the exploration by constructing robust exploratory directions. First, we describe a Dual-Point Dueling Bandit Gradient Descent (DP-DBGD) approach with a Contextual Interleaving (CI) method. In particular, the exploration of DP-DBGD is carefully conducted via two opposite stochastic directions and the proposed CI method constructs a qualified interleaved retrieval result list by taking historical explorations into account. Second, we introduce a Multi-Point Deterministic Gradient Descent (MP-DGD) method that constructs a set of deterministic standard unit basis vectors for exploration. In MP-DGD , each basis direction will be explored and the parameter updating is performed by walking along the combination of exploratory winners from the basis vectors. We conduct experiments on several datasets and show that both DP-DBGD and MP-DGD improve the online learning to rank performance over 10% compared with baseline methods.",2016,Conference on Information and Knowledge Management,learning to rank;data mining;artificial intelligence;machine learning;statistics;computer science;
Separating-Plane Factorization Models: Scalable Recommendation from One-Class Implicit Feedback,Haolan Chen (University of Alberta);Di Niu (University of Alberta);Kunfeng Lai (Tencent);Yu Xu (Tencent);Masoud Ardakani (University of Alberta);,"2206242337,2665607791,2562390450,2534212139,2160500562","We study the video recommendation problem based on a large amount of user viewing logs instead of explicit ratings. As viewing records are implicitly suggest user preferences, existing matrix factorization methods fail to generate discriminative recommendations based on such one-class positive samples. We propose a scalable approach called separating-plane matrix factorization (SPMF) to make effective recommendations based on positive implicit feedback, with a learning complexity that is comparable to traditional matrix factorization. With extensive offline evaluation in Tencent Data Warehouse (TDW) based on a large amount of data, we show that our approach outperforms a wide range of state-of-the-art methods. We also deployed our system in the QQ Browser App of Tencent and performed online A/B testing with real users. Results suggest that our approach increased the video click through rate by $23% over implicit-feedback collaborative filtering (IFCF), a scheme available in Apache Spark's MLlib.",2016,Conference on Information and Knowledge Management,collaborative filtering;matrix decomposition;big data;multimedia;world wide web;information retrieval;data mining;database;machine learning;computer science;
PairFac: Event Analytics through Discriminant Tensor Factorization,Xidao Wen (University of Pittsburgh);Yu-Ru Lin (University of Pittsburgh);Konstantinos Pelechrinis (University of Pittsburgh);,"2700783907,2155397203,155875377","The study of disaster events and their impact in the urban space has been traditionally conducted through manual collections and analysis of surveys, questionnaires and authority documents. While there have been increasingly rich troves of human behavioral data related to the events of interest, the ability to obtain hindsight following a disaster event has not been scaled up. In this paper, we propose a novel approach for analyzing events called PairFac. PairFac utilizes discriminant tensor analysis to automatically discover the impact of a major event from rich human behavioral data. Our method aims to (i) uncover the persistent patterns across multiple interrelated aspects of urban behavior (e.g., when, where and what citizens do in a city) and at the same time (ii) identify the salient changes following a potentially impactful event. We show the effectiveness of PairFac in comparison with previous methods through extensive experiments. We also demonstrate the advantages of our approach through case studies with real-world traffic sensor data and social media streams surrounding the 2015 terrorist attacks in Paris. Our work has both methodological contributions in studying the impact of an external stimulus on a system as well as practical implications in the area of disaster event analysis and assessment.",2016,Conference on Information and Knowledge Management,data science;world wide web;data mining;database;artificial intelligence;machine learning;simulation;
Deep Match between Geology Reports and Well Logs Using Spatial Information,Bin Tong (Hitachi);Martin Klinkigt (Hitachi);Makoto Iwayama (Hitachi);Yoshiyuki Kobayashi (Hitachi);Anshuman Sahu (Hitachi);Ravigopal Vennelakanti (Hitachi);,"2648970340,2559885959,26120161,2440167581,2560453588,2483337582","In the shale oil & gas industry, operators are looking toward big data and new analytics tools and techniques to optimize operations and reduce cost. Formation evaluation is one of the most crucial steps before the fracturing operation. To assist engineers in understanding the subsurface and in turn make optimal operations, we focus on learning semantic relations between geology reports and well logs, which are collected during down-hole drilling. The challenges are how to represent the features of the geology reports and the well logs collected at measured depths and how to effectively embed them into a common feature space. We propose both linear and nonlinear (artificial neural network) models to achieve such an embedding. Extensive validations are conducted on public well data of North Dakota in the United States. We empirically discover that both geology reports and well logs follow a neighborhood property measured by geological distance. We show that this spatial information is highly effective in both the linear and nonlinear models and our nonlinear model with the spatial information performs the best among the state-of-the-art methods.",2016,Conference on Information and Knowledge Management,well logging;artificial neural network;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Derivative Delay Embedding: Online Modeling of Streaming Time Series,Zhifei Zhang (University of Tennessee);Yang Song (University of Tennessee);Wei Wang (University of Tennessee);Hairong Qi (University of Tennessee);,"2645487903,2607542581,2619447935,2131491696","The staggering amount of streaming time series coming from the real world calls for more efficient and effective online modeling solution. For time series modeling, most existing works make some unrealistic assumptions such as the input data is of fixed length or well aligned, which requires extra effort on segmentation or normalization of the raw streaming data. Although some literature claim their approaches to be invariant to data length and misalignment, they are too time-consuming to model a streaming time series in an online manner. We propose a novel and more practical online modeling and classification scheme, DDE-MGM, which does not make any assumptions on the time series while maintaining high efficiency and state-of-the-art performance. The derivative delay embedding (DDE) is developed to incrementally transform time series to the embedding space, where the intrinsic characteristics of data is preserved as recursive patterns regardless of the stream length and misalignment. Then, a non-parametric Markov geographic model (MGM) is proposed to both model and classify the pattern in an online manner. Experimental results demonstrate the effectiveness and superior classification accuracy of the proposed DDE-MGM in an online setting as compared to the state-of-the-art.",2016,Conference on Information and Knowledge Management,real time computing;machine learning;simulation;statistics;computer science;
Robust Spectral Ensemble Clustering,Zhiqiang Tao (Northeastern University);Hongfu Liu (Northeastern University);Sheng Li (Northeastern University);Yun Fu (Northeastern University);,"2536319506,2108071053,2618462548,2123131494","Ensemble Clustering (EC) aims to integrate multiple Basic Partitions (BPs) of the same dataset into a consensus one. It could be transformed as a graph partition problem on the co-association matrix derived from BPs. However, existing EC methods usually directly use the co-association matrix, yet without considering various noises ( e.g. , the disagreement between different BPs or outliers) that may exist in it. These noises can impair the cluster structure of a co-association matrix and thus degrade the final clustering performance. In this paper, we propose a novel Robust Spectral Ensemble Clustering (RSEC) approach to address this challenge. First, RSEC learns a robust representation for the co-association matrix through low-rank constraint, which reveals the cluster structure of a co-association matrix and captures various noises in it. Second, RSEC finds the consensus partition by conducting spectral clustering. These two steps are iteratively performed in a unified optimization framework. Most importantly, during our optimization process, we utilize consensus partition to iteratively enhance the block-diagonal structure of the learned representation to further assist the clustering process. Experiments on numerous real-world datasets demonstrate the effectiveness of our method compared with the state-of-the-art. Moreover, several impact factors that may affect the clustering performance of our approach are also explored extensively.",2016,Conference on Information and Knowledge Management,k medians clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;
Routing an Autonomous Taxi with Reinforcement Learning,"Miyoung Han (Télécom ParisTech);Pierre Senellart (Télécom ParisTech);Stéphane Bressan (National University of Singapore);Huayu Wu (Agency for Science, Technology and Research);","2505726045,2039937633,2159446685,2153968863","Singapore's vision of a Smart Nation encompasses the development of effective and efficient means of transportation. The government's target is to leverage new technologies to create services for a demand-driven intelligent transportation model including personal vehicles, public transport, and taxis. Singapore's government is strongly encouraging and supporting research and development of technologies for autonomous vehicles in general and autonomous taxis in particular. The design and implementation of intelligent routing algorithms is one of the keys to the deployment of autonomous taxis. In this paper we demonstrate that a reinforcement learning algorithm of the Q-learning family, based on a customized exploration and exploitation strategy, is able to learn optimal actions for the routing autonomous taxis in a real scenario at the scale of the city of Singapore with pick-up and drop-off events for a fleet of one thousand taxis.",2016,Conference on Information and Knowledge Management,exploration;machine learning;simulation;computer science;
A Theoretical Framework on the Ideal Number of Classifiers for Online Ensembles in Data Streams,Hamed R. Bonab (Bilkent University);Fazli Can (Bilkent University);,"2536742310,2135311499","A priori determining the ideal number of component classifiers of an ensemble is an important problem. The volume and velocity of big data streams make this even more crucial in terms of prediction accuracies and resource requirements. There is a limited number of studies addressing this problem for batch mode and none for online environments. Our theoretical framework shows that using the same number of independent component classifiers as class labels gives the highest accuracy. We prove the existence of an ideal number of classifiers for an ensemble, using the weighted majority voting aggregation rule. In our experiments, we use two state-of-the-art online ensemble classifiers with six synthetic and six real-world data streams. The violation of providing independent component classifiers for our theoretical framework makes determining the exact ideal number of classifiers nearly impossible. We suggest upper bounds for the number of classifiers that gives the highest accuracy. An important implication of our study is that comparing online ensemble classifiers should be done based on these ideal values, since comparing based on a fixed number of classifiers can be misleading.",2016,Conference on Information and Knowledge Management,cascading classifiers;random subspace method;data mining;pattern recognition;machine learning;
Learning to Rank System Configurations,Romain Deveaud (University of Toulouse);Josiane Mothe (University of Toulouse);Jian-Yun Nia (Université de Montréal);,"314381667,2141333472,2546595331","Information Retrieval (IR) systems heavily rely on a large number of parameters, such as the retrieval model or various query expansion parameters, whose values greatly influence the overall retrieval effectiveness. However, setting all these parameters individually can often be a tedious task, since they can all affect one another, while also vary for different queries. We propose to tackle this problem by dealing with entire system configurations (i.e. a set of parameters representing an IR system) instead of single parameters, and to apply state-of-the-art Learning to Rank techniques to select the most appropriate configuration for a given query. The experiments we conducted on two TREC AdHoc collections show that this approach is feasible and significantly outperforms the traditional way to configure a system, as well as the top performing systems of the TREC tracks. We also show an analysis on the impact of different features on the model's learning capability.",2016,Conference on Information and Knowledge Management,query expansion;learning to rank;world wide web;information retrieval;data mining;
On the Effectiveness of Query Weighting for Adapting Rank Learners to New Unlabelled Collections,Pengfei Li (RMIT University);Mark Sanderson (RMIT University);Mark James Carman (Monash University);Falk Scholer (RMIT University);,"2692161514,2704667184,2123487663,1970689224","Query-level instance weighting is a technique for unsupervised transfer ranking, which aims to train a ranker on a source collection so that it also performs effectively on a target collection, even if no judgement information exists for the latter. Past work has shown that this approach can be used to significantly improve effectiveness; in this work, the approach is re-examined on a wide set of publicly available L2R test collections with more advanced learning to rank algorithms. Different query-level weighting strategies are examined against two transfer ranking frameworks: AdaRank and a new weighted LambdaMART algorithm. Our experimental results show that the effectiveness of different weighting strategies, including those shown in past work, vary under different transferring environments. In particular, (i) Kullback-Leibler based density-ratio estimation tends to outperform a classification-based approach and (ii) aggregating document-level weights into query-level weights is likely superior to direct estimation using a query-level representation. The Nemenyi statistical test, applied across multiple datasets, indicates that most weighting transfer learning methods do not significantly outperform baselines, although there is potential for the further development of such techniques.",2016,Conference on Information and Knowledge Management,learning to rank;information retrieval;data mining;pattern recognition;machine learning;
Group-Aware Weighted Bipartite B-Matching,Cheng Chen (University of Victoria);Sean Chester (Norwegian University of Science and Technology);Venkatesh Srinivasan (University of Victoria);Kui Wu (University of Victoria);Alex Thomo (University of Victoria);,"2561786263,2167628457,2125078017,2149089207,83612842","The weighted bipartite B-matching (WBM) problem models a host of data management applications, ranging from recommender systems to Internet advertising and e-commerce. Many of these applications, however, demand versatile assignment constraints, which WBM is weak at modelling. In this paper, we investigate powerful generalisations of WBM. We first show that a recent proposal for conflict-aware WBM by Chen et al. is hard to approximate by reducing their problem from Maximum Weight Independent Set. We then propose two related problems, collectively called group-aware WBM. For the first problem, which constrains the degree of groups of vertices, we show that a linear programming formulation produces a Totally Unimodular (TU) matrix and is thus polynomial-time solvable. Nonetheless, we also give a simple greedy algorithm subject to a 2-extendible system that scales to higher workloads. For the second problem, which instead limits the budget of groups of vertices, we prove its NP-hardness but again give a greedy algorithm with an approximation guarantee. Our experimental evaluation reveals that the greedy algorithms vastly outperform their theoretical guarantees and scale to bipartite graphs with more than eleven million edges.",2016,Conference on Information and Knowledge Management,bipartite graph;linear programming;machine learning;mathematical optimization;
Learning to Rewrite Queries,Yunlong He (Yahoo!);Jiliang Tang (Michigan State University);Hua Ouyang (Yahoo!);Changsung Kang (Yahoo!);Dawei Yin (Yahoo!);,"2442566723,2147392410,2489973799,2158414383,2170531144,2168000538","It is widely known that there exists a semantic gap between web documents and user queries and bridging this gap is crucial to advance information retrieval systems. The task of query rewriting, aiming to alter a given query to a rewrite query that can close the gap and improve information retrieval performance, has attracted increasing attention in recent years. However, the majority of existing query rewriters are not designed to boost search performance and consequently their rewrite queries could be sub-optimal. In this paper, we propose a learning to rewrite framework that consists of a candidate generating phase and a candidate ranking phase. The candidate generating phase provides us the flexibility to reuse most of existing query rewriters; while the candidate ranking phase allows us to explicitly optimize search relevance. Experimental results on a commercial search engine demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the important components of the proposed framework.",2016,Conference on Information and Knowledge Management,ranking;rewrite engine;web search query;web query classification;query expansion;
Ensemble of Anchor Adapters for Transfer Learning,Fuzhen Zhuang (Chinese Academy of Sciences);Ping Luo (Chinese Academy of Sciences);Sinno Jialin Pan (Nanyang Technological University);Hui Xiong (Rutgers–Newark);Qing He (Chinese Academy of Sciences);,"2050314250,2291210646,2120836466,2153710278,2167314737","In the past decade, there have been a large number of transfer learning algorithms proposed for various real-world applications. However, most of them are vulnerable to negative transfer since their performance is even worse than traditional supervised models. Aiming at more robust transfer learning models, we propose an ENsemble framework of anCHOR adapters (ENCHOR for short), in which an anchor adapter adapts the features of instances based on their similarities to a specific anchor (i.e., a selected instance). Specifically, the more similar to the anchor instance, the higher degree of the original feature of an instance remains unchanged in the adapted representation, and vice versa. This adapted representation for the data actually expresses the local structure around the corresponding anchor, and then any transfer learning method can be applied to this adapted representation for a prediction model, which focuses more on the neighborhood of the anchor. Next, based on multiple anchors, multiple anchor adapters can be built and combined into an ensemble for final output. Additionally, we develop an effective measure to select the anchors for ensemble building to achieve further performance improvement. Extensive experiments on hundreds of text classification tasks are conducted to demonstrate the effectiveness of ENCHOR. The results show that: when traditional supervised models perform poorly, ENCHOR (based on only 8 selected anchors) achieves $6%-13%$ increase in terms of average accuracy compared with the state-of-the-art methods, and it greatly alleviates negative transfer.",2016,Conference on Information and Knowledge Management,transfer of learning;data mining;artificial intelligence;machine learning;computer science;
CIKM 2016 general chairs' welcome,Snehasis Mukhopadhyay (Indiana University);Cheng Xiang Zhai;,"2548524061,2700105088",-,2016,Conference on Information and Knowledge Management,-
Bayesian Non-Exhaustive Classification A Case Study: Online Name Disambiguation using Temporal Record Streams,Baichuan Zhang (Indiana University – Purdue University Indianapolis);Murat Dundar (Indiana University – Purdue University Indianapolis);Mohammad Al Hasan (Indiana University – Purdue University Indianapolis);,"2103681637,2104557900,2430381672","The name entity disambiguation task aims to partition the records of multiple real-life persons so that each partition contains records pertaining to a unique person. Most of the existing solutions for this task operate in a batch mode, where all records to be disambiguated are initially available to the algorithm. However, more realistic settings require that the name disambiguation task be performed in an online fashion, in addition to, being able to identify records of new ambiguous entities having no preexisting records. In this work, we propose a Bayesian non-exhaustive classification framework for solving online name disambiguation task. Our proposed method uses a Dirichlet process prior with a Normal x Normal x Inverse Wishart data model which enables identification of new ambiguous entities who have no records in the training data. For online classification, we use one sweep Gibbs sampler which is very efficient and effective. As a case study we consider bibliographic data in a temporal stream format and disambiguate authors by partitioning their papers into homogeneous groups. Our experimental results demonstrate that the proposed method is better than existing methods for performing online name disambiguation task.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;pattern recognition;machine learning;statistics;computer science;
Extracting Skill Endorsements from Personal Communication Data,Darshan M. Shankaralingappa (Aalto University);Gianmarco De Fransicsi Morales (Qatar Computing Research Institute);Aristides Gionis (Aalto University);,"2538817857,2535579375,737311942","People are increasingly communicating and collaborating via digital platforms, such as email and messaging applications. Data exchanged on these digital communication platforms can be a treasure trove of information on people who participate in the discussions: who they are collaborating with, what they are working on, what their expertise is, and so on. Yet, personal communication data is very rarely analyzed due to the sensitivity of the information it contains. In this paper, we mine personal communication data with the goal of generating skill endorsements of the type ""person A endorses person B on skill X."" To address privacy concerns, we consider that each person has access only to their own data (i.e., conversations with their peers). By using our method, they can generate endorsements for their peers, which they can inspect and opt to publish. To identify meaningful skills we use a knowledge base created from the StackExchange Q&A forum. We study two different approaches, one based on building a skill graph, and one based on information retrieval techniques. We find that the latter approach outperforms the graph-based algorithms when tested on a dataset of user profiles from StackOverflow. We also conduct a user study on email data from nine volunteers, and we find that the information retrieval-based approach achieves a MAP@10 score of 0.617.",2016,Conference on Information and Knowledge Management,multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Modeling Customer Engagement from Partial Observations,Jelena Stojanovic (Temple University);Djordje Gligorijevic (Temple University);Zoran Obradovic (Temple University);,"2503405498,2401352849,2029694244","It is of high interest for a company to identify customers expected to bring the largest profit in the upcoming period. Knowing as much as possible about each customer is crucial for such predictions. However, their demographic data, preferences, and other information that might be useful for building loyalty programs is often missing. Additionally, modeling relations among different customers as a network can be beneficial for predictions at an individual level, as similar customers tend to have similar purchasing patterns. We address this problem by proposing a robust framework for structured regression on deficient data in evolving networks with a supervised representation learning based on neural features embedding. The new method is compared to several unstructured and structured alternatives for predicting customer behavior (e.g. purchasing frequency and customer ticket) on user networks generated from customer databases of two companies from different industries. The obtained results show 4% to 130% improvement in accuracy over alternatives when all customer information is known. Additionally, the robustness of our method is demonstrated when up to 80% of demographic information was missing where it was up to several folds more accurate as compared to alternatives that are either ignoring cases with missing values or learn their feature representation in an unsupervised manner.",2016,Conference on Information and Knowledge Management,customer intelligence;voice of the customer;structured prediction;feature learning;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Analyzing Data Relevance and Access Patterns of Live Production Database Systems,Martin Boissier (Hasso Plattner Institute);Carsten Alexander Meyer (Hasso Plattner Institute);Timo Djürken (Hasso Plattner Institute);Jan Lindemann (Hasso Plattner Institute);Kathrin Mao (Hasso Plattner Institute);Pascal Reinhardt (Hasso Plattner Institute);Tim Specht (Hasso Plattner Institute);Tim Zimmermann (Hasso Plattner Institute);Matthias Uflacker (Hasso Plattner Institute);,"2096063145,2403291897,2521372112,2222173604,2535635563,2537494205,2534500209,2535982695,2008573489","Access to real-world database systems and their workloads is an invaluable source of information for database researchers. However, usually such full access is not possible due to tracing overheads, data protection, or legal reasons. In this paper, we present a tool set to analyze and compare synthetic and real-world database workloads, their characteristics, and access patterns. This tool set processes SQL workload traces and collects fine-grained access information without requiring direct read access to the production system. To gain insights into large real-world systems, we traced a live production enterprise system of a Global 2000 company and compare it with the synthetic benchmarks TPC-C and TPC-E.",2016,Conference on Information and Knowledge Management,production system;world wide web;data mining;database;artificial intelligence;computer science;
Efficient Processing of Location-Aware Group Preference Queries,Miao Li (Northeastern University);Lisi Chen (Hong Kong Baptist University);Gao Cong (Nanyang Technological University);Yu Gu (Northeastern University);Ge Yu (Northeastern University);,"2243963891,2106043476,2295915604,2306501471,2168806630","With the proliferation of geo-positioning techniques that enable users to acquire their geographical positions, there has been increasing popularity of online location-based services. This development has generated a large volume of points of interest labeled with category features (e.g., hotel, resort, stores, stations, and tourist attractions). It gives prominence to various types of spatial-keyword queries, which are employed to provide fundamental querying functionality for location-based services. We study the Location-aware Group Preference ( LGP ) query that aims to find a destination place for a group of users. The group of users want to go to a place labeled with a specified category feature (e.g., hotel) together, and each of them has a location and a set of additional preferences. It is expected that the result place of the query belongs to the specified category feature, and it is close to places satisfying the preferences of each user. We develop a novel framework for answering the LGP query, which can be used to compute both exact query result and approximate result with a proven approximation ratio. The efficiency and efficacy of the proposed algorithms for answering the LGP query are verified by extensive experiments on two real datasets.",2016,Conference on Information and Knowledge Management,web query classification;group;query optimization;query language;location;world wide web;information retrieval;data mining;database;computer science;
When is the Time Ripe for Natural Language Processing for Patent Passage Retrieval,Linda Andersson (Vienna University of Technology);Mihai Lupu (Vienna University of Technology);João R. M. Palotti (Vienna University of Technology);Allan Hanbury (Vienna University of Technology);Andreas Rauber (Vienna University of Technology);,"2157745092,2010059705,2197643117,2168901591,2057632188","Patent text is a mixture of legal terms and domain specific terms. In technical English text, a multi-word unit method is often deployed as a word formation strategy in order to expand the working vocabulary, i.e. introducing a new concept without the invention of an entirely new word. In this paper we explore query generation using natural language processing technologies in order to capture domain specific concepts represented as multi-word units. In this paper we examine a range of query generation methods using both linguistic and statistical information. We also propose a new method to identify domain specific terms from other more general phrases. We apply a machine learning approach using domain knowledge and corpus linguistic information in order to learn domain specific terms in relation to phrases' Termhood values. The experiments are conducted on the English part of the CLEF-IP 2013 test collection. The outcome of the experiments shows that the favoured method in terms of PRES and recall is when a language model is used and search terms are extracted with a part-of-speech tagger and a noun phrase chunker. With our proposed methods we improve each evaluation metric significantly compared to the existing state-of-the-art for the CLEP-IP 2013 test collection: for PRES@100 by 26% (0.544 from 0.433), for recall@100 by 17% (0.631 from 0.540) and on document MAP by 57% (0.300 from 0.191).",2016,Conference on Information and Knowledge Management,information extraction;text mining;natural language processing;speech recognition;information retrieval;data mining;database;computer science;
Memory-Optimized Distributed Graph Processing through Novel Compression Techniques,Panagiotis Liakos (National and Kapodistrian University of Athens);Katia Papakonstantinopoulou (National and Kapodistrian University of Athens);Alex Delis (National and Kapodistrian University of Athens);,"2169631048,115028611,1977083973","A multitude of contemporary applications now involve graph data whose size continuously grows and this trend shows no signs of subsiding. This has caused the emergence of many distributed graph processing systems including Pregel and Apache Giraph . However, the unprecedented scale now reached by real-world graphs hardens the task of graph processing even in distributed environments and the current memory usage patterns rapidly become a primary concern for such contemporary graph processing systems. We seek to address this challenge by exploiting empirically-observed properties demonstrated by graphs that are generated by human activity. In this paper, we propose three space-efficient adjacency list representations that can be applied to any distributed graph processing system. Our suggested compact representations reduce respective memory requirements for accommodating the graph elements up to 5 times if compared with state-of-the-art methods. At the same time, our memory-optimized methods retain the efficiency of uncompressed structures and enable the execution of algorithms for large scale graphs in settings where contemporary alternative structures fail due to memory errors.",2016,Conference on Information and Knowledge Management,graph database;theoretical computer science;natural language processing;world wide web;distributed computing;data mining;database;artificial intelligence;machine learning;computer science;
Framing Mobile Information Needs: An Investigation of Hierarchical Query Sequence Structure,Shuguang Han (University of Pittsburgh);Xing Yi (Yahoo!);Zhen Yue (Yahoo!);Zhigeng Geng (Yahoo!);Alyssa Glass (Yahoo!);,"2104672739,2578647779,2168476731,2327790307,2694585302","When using search engines, people often issue multiple related queries to accomplish a complex search task. A simple query-task structure may not fully capture the complexity of query relations since people may divide a task into multiple subtasks. As a result, this paper applies a three-level hierarchical structure with query, goal and mission - a mission includes several goals, and a goal consists of multiple queries. Particularly, we focus on analyzing query-goal-mission structure for mobile web search because of its increasing popularity and lack of investigation in the literature. This study has three main contributions: (1) we study the query-goal-mission structure for mobile web search, which was not studied before. (2) We identify several differences between mobile and desktop search patterns in terms of goal/mission length, duration and interleaving. (3) We demonstrate that the query-goal-mission structure can be applied to design better user satisfaction metrics. Specifically, goal-based search success rate and mission-based abandonment rate are better aligned with users' long-term engagement than query and session based metrics.",2016,Conference on Information and Knowledge Management,mobile search;web search query;web query classification;query expansion;search engine;world wide web;information retrieval;data mining;database;computer science;
Online Adaptive Passive-Aggressive Methods for Non-Negative Matrix Factorization and Its Applications,"Chenghao Liu (Zhejiang University);Steven C.H. Hoi (Singapore Management University);Peilin Zhao (Agency for Science, Technology and Research);Jianling Sun (Zhejiang University);Ee-Peng Lim (Singapore Management University);","2416298036,108406206,2096910461,2142885270,2130308643","This paper aims to investigate efficient and scalable machine learning algorithms for resolving Non-negative Matrix Factorization (NMF), which is important for many real-world applications, particularly for collaborative filtering and recommender systems. Unlike traditional batch learning methods, a recently proposed online learning technique named ""NN-PA"" tackles NMF by applying the popular Passive-Aggressive (PA) online learning, and found promising results. Despite its simplicity and high efficiency, NN-PA falls short in at least two critical limitations: (i) it only exploits the first-order information and thus may converge slowly especially at the beginning of online learning tasks; (ii) it is sensitive to some key parameters which are often difficult to be tuned manually, particularly in a practical online learning system. In this work, we present a novel family of online Adaptive Passive-Aggressive (APA) learning algorithms for NMF, named ""NN-APA"", which overcomes two critical limitations of NN-PA by (i) exploiting second-order information to enhance PA in making more informative updates at each iteration; and (ii) achieving the parameter auto-selection by exploring the idea of online learning with expert advice in deciding the optimal combination of the key parameters in NMF. We theoretically analyze the regret bounds of the proposed method and show its advantage over the state-of-the-art NN-PA method, and further validate the efficacy and scalability of the proposed technique through an extensive set of experiments on a variety of large-scale real recommender systems datasets.",2016,Conference on Information and Knowledge Management,online machine learning;non negative matrix factorization;adaptive behavior;regularization;active learning;semi supervised learning;theoretical computer science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Learning Hidden Features for Contextual Bandits,Huazheng Wang (University of Virginia);Qingyun Wu (University of Virginia);Hongning Wang (University of Virginia);,"2556947837,2479883750,2157880984","Contextual bandit algorithms provide principled online learning solutions to find optimal trade-offs between exploration and exploitation with companion side-information. Most contextual bandit algorithms simply assume the learner would have access to the entire set of features, which govern the generation of payoffs from a user to an item. However, in practice it is challenging to exhaust all relevant features ahead of time, and oftentimes due to privacy or sampling constraints many factors are unobservable to the algorithm. Failing to model such hidden factors leads a system to make constantly suboptimal predictions. In this paper, we propose to learn the hidden features for contextual bandit algorithms. Hidden features are explicitly introduced in our reward generation assumption, in addition to the observable contextual features. A scalable bandit algorithm is achieved via coordinate descent, in which closed form solutions exist at each iteration for both hidden features and bandit parameters. Most importantly, we rigorously prove that the developed contextual bandit algorithm achieves a sublinear upper regret bound with high probability, and a linear regret is inevitable if one fails to model such hidden features. Extensive experimentation on both simulations and large-scale real-world datasets verified the advantages of the proposed algorithm compared with several state-of-the-art contextual bandit algorithms and existing ad-hoc combinations between bandit algorithms and matrix factorization methods.",2016,Conference on Information and Knowledge Management,multi armed bandit;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
Who are My Familiar Strangers?: Revealing Hidden Friend Relations and Common Interests from Smart Card Data,Fusang Zhang (Chinese Academy of Sciences);Beihong Jin (Chinese Academy of Sciences);Tingjian Ge (University of Massachusetts Lowell);Qiang Ji (Chinese Academy of Sciences);Yanling Cui (Chinese Academy of Sciences);,"2133208957,2028690333,2185270649,2667641705,2550426555","The newly emerging location-based social networks (LBSN) such as Tinder and Momo extends social interaction from friends to strangers, providing novel experiences of making new friends. Familiar strangers refer to the strangers who meet frequently in daily life and may share common interests; thus they may be good candidates for friend recommendation. In this paper, we study the problem of discovering familiar strangers, specifically, public transportation trip companions, and their common interests. We collect 5.7 million transaction records of smart cards from about 3.02 million people in the city of Beijing, China. We first analyze this dataset and reveal the temporal and spatial characteristics of passenger encounter behaviors. Then we propose a stability metric to measure hidden friend relations. This metric facilitates us to employ community detection techniques to capture the communities of trip companions. Further, we infer common interests of each community using a topic model, i.e., LDA4HFC (Latent Dirichlet Allocation for Hidden Friend Communities) model. Such topics for communities help to understand how hidden friend clusters are formed. We evaluate our method using large-scale and real-world datasets, consisting of two-week smart card records and 901,855 Point of Interests (POIs) in Beijing. The results show that our method outperforms three baseline methods with higher recommendation accuracy. Moreover, our case study demonstrates that the discovered topics interpret the communities very well.",2016,Conference on Information and Knowledge Management,topic model;internet privacy;world wide web;data mining;machine learning;computer science;
Ease the Process of Machine Learning with Dataflow,Tianyou Guo (Chinese Academy of Sciences);Jun Xu (Chinese Academy of Sciences);Xiaohui Yan (Chinese Academy of Sciences);Jianpeng Hou (Chinese Academy of Sciences);Ping Li (Chinese Academy of Sciences);Zhaohui Li (Chinese Academy of Sciences);Jiafeng Guo (Chinese Academy of Sciences);Xueqi Cheng (Chinese Academy of Sciences);,"2560493900,2598177019,2223462478,2671932931,2697740518,2712824936,2581340266,2129598186","Machine learning algorithms have become the key components in many big data applications. However, the full potential of machine learning is still far from been realized because using machine learning algorithms is hard, especially on distributed platforms such as Hadoop and Spark. The key barriers come from not only the implementation of the algorithms themselves, but also the processing for applying them to real applications which often involve multiple steps and different algorithms. In this demo we present a general-purpose dataflow-based system for easing the process of applying machine learning algorithms to real world tasks. In the system, a learning task is formulated as a directed acyclic graph (DAG) in which each node represents an operation (e.g., a machine learning algorithm), and each edge represents the flow of the data from one node to its descendants. Graphical user interface is implemented for making users to create, configure, submit, and monitor a task in a drag-and-drop manner. Advantages of the system include 1) lowering the barriers of defining and executing machine learning tasks; 2) sharing and re-using the implementations of the algorithms, the task dataflow DAGs, and the (intermediate) experimental results; 3) seamlessly integrating the stand-alone algorithms as well as the distributed algorithms in one task. The system has been deployed as a machine learning service and can be access from the Internet.",2016,Conference on Information and Knowledge Management,event driven finite state machine;online machine learning;stability;inductive transfer;multi task learning;dataflow;robot learning;directed acyclic graph;active learning;algorithmic learning theory;computational learning theory;instance based learning;theoretical computer science;natural language processing;world wide web;distributed computing;data mining;database;real time computing;artificial intelligence;machine learning;computer science;
A Non-Parametric Topic Model for Short Texts Incorporating Word Coherence Knowledge,Yuhao Zhang (Chinese Academy of Sciences);Wenji Mao (Chinese Academy of Sciences);Daniel Dajun Zeng (Chinese Academy of Sciences);,"2108076037,2164388523,2705278694","Mining topics in short texts (e.g. tweets, instant messages) can help people grasp essential information and understand key contents, and is widely used in many applications related to social media and text analysis. The sparsity and noise of short texts often restrict the performance of traditional topic models like LDA. Recently proposed Biterm Topic Model (BTM) which models word co-occurrence patterns directly, is revealed effective for topic detection in short texts. However, BTM has two main drawbacks. It needs to manually specify topic number, which is difficult to accurately determine when facing new corpora. Besides, BTM assumes that two words in same term should belong to the same topic, which is often too strong as it does not differentiate two types of words (i.e. general words and topical words). To tackle these problems, in this paper, we propose a non-parametric topic model npCTM with the above distinction. Our model incorporates the Chinese restaurant process (CRP) into the BTM model to determine topic number automatically. Our model also distinguishes general words from topical words by jointly considering the distribution of these two word types for each word as well as word coherence information as prior knowledge. We carry out experimental studies on real-world twitter dataset. The results demonstrate the effectiveness of our method to discover coherent topics compared with the baseline methods.",2016,Conference on Information and Knowledge Management,topic model;text mining;natural language processing;world wide web;speech recognition;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Graph-Based Multi-Modality Learning for Clinical Decision Support,Ziwei Zheng (Peking University);Xiaojun Wan (Peking University);,"2477465545,2146508076","The task of clinical decision support (CDS) involves retrieval and ranking of medical journal articles for medical records of diagnosis, test or treatment. Previous studies on this task are based on bag-of-words representations of document texts and general retrieval models. In this paper, we propose to use the paragraph vector technique to learn the latent semantic representation of texts and treat the latent semantic representations and the original bag-of-words representations as two different modalities. We then propose to use the graph-based multi-modality learning algorithm for document re-ranking. Experimental results on two TREC-CDS benchmark datasets demonstrate the excellent performance of our proposed approach.",2016,Conference on Information and Knowledge Management,clinical decision support system;natural language processing;information retrieval;data mining;database;machine learning;computer science;
ASNets: A Benchmark Dataset of Aligned Social Networks for Cross-Platform User Modeling,Xuezhi Cao (Shanghai Jiao Tong University);Yong Yu (Shanghai Jiao Tong University);,"2663311502,2119244895","Aligning heterogeneous online social networks is a highly beneficial task proposed in recent years. It targets at automatically aligning accounts from multiple networks by whether they are held by the same natural person. Aligning the networks can improve personalized services by cross-platform user modeling, and is the prerequisite for cross-network analysis. However, there is currently no public benchmark dataset available due to its recency. As performances of this task depend highly on the dataset, experiments using different private datasets are not directly comparable. Therefore, in this paper we propose ASNets, a benchmark dataset with two sets of aligned social networks. With this dataset, we can now properly evaluate different approaches and compare them fairly. The two sets of aligned networks have 328,224 and 141,614 aligned users respectively, covering multilingual usage (Chinese and English) and various types of social networks including general purposed networks, review sites and microblogging sites. We describe the collecting methodology and statistics in details, and evaluate several state-of-the-art network aligning approaches. Beside introducing the dataset, we further propose several potential research directions that benefit from ASNets.",2016,Conference on Information and Knowledge Management,user modeling;data science;world wide web;data mining;database;machine learning;computer science;
Scalability and Total Recall with Fast CoveringLSH,Ninh Pham (IT University of Copenhagen);Rasmus Pagh (IT University of Copenhagen);,"2162985535,1864519460","Locality-sensitive hashing (LSH) has emerged as the dominant algorithmic technique for similarity search with strong performance guarantees in high-dimensional spaces. A drawback of traditional LSH schemes is that they may have false negatives , i.e., the recall is less than 100%. This limits the applicability of LSH in settings requiring precise performance guarantees. Building on the recent theoretical ""CoveringLSH"" construction that eliminates false negatives, we propose a fast and practical covering LSH scheme for Hamming space called Fast CoveringLSH (fcLSH) . Inheriting the design benefits of CoveringLSH our method avoids false negatives and always reports all near neighbors. Compared to CoveringLSH we achieve an asymptotic improvement to the hash function computation time from O ( dL ) to O ( d + ( L log L ), where d is the dimensionality of data and L is the number of hash tables. Our experiments on synthetic and real-world data sets demonstrate that fcLSH is comparable (and often superior) to traditional hashing-based approaches for search radius up to 20 in high-dimensional Hamming space.",2016,Conference on Information and Knowledge Management,locality sensitive hashing;theoretical computer science;data mining;database;algorithm;
KB-Enabled Query Recommendation for Long-Tail Queries,Zhipeng Huang (University of Hong Kong);Bogdan Cautis (Huawei);Reynold Cheng (University of Hong Kong);Yudian Zheng (University of Hong Kong);,"2511877038,2560089064,2138267588,2105493843","In recent years, query recommendation algorithms have been designed to provide related queries for search engine users. Most of these solutions, which perform extensive analysis of users' search history (or query logs ), are largely insufficient for long-tail queries that rarely appear in query logs. To handle such queries, we study a new solution, which makes use of a knowledge base (or KB), such as YAGO and Freebase. A KB is a rich information source that describes how real-world entities are connected. We extract entities from a query, and use these entities to explore new ones in the KB. Those discovered entities are then used to suggest new queries to the user. As shown in our experiments, our approach provides better recommendation results for long-tail queries than existing solutions.",2016,Conference on Information and Knowledge Management,sargable;range query;rdf query language;web search query;web query classification;spatial query;query expansion;query optimization;query language;knowledge base;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
DI-DAP: An Efficient Disaster Information Delivery and Analysis Platform in Disaster Management,Tao Li (Florida International University);Wubai Zhou (Florida International University);Chunqiu Zeng (Florida International University);Qing Wang (Florida International University);Qifeng Zhou (Xiamen University);Dingding Wang (Florida Atlantic University);Jia Xu (Nanjing University of Posts and Telecommunications);Yue Huang (Nanjing University of Posts and Telecommunications);Wentao Wang (Florida International University);Minjing Zhang (Florida International University);Steven Luis (Florida International University);Shu-Ching Chen (Florida International University);Naphtali Rishe (Florida International University);,"2472069284,2227176090,2155150411,2564420227,2680994159,2097650207,2702868401,2508143780,2492850689,2536690633,2145639965,2118447230,2019309144","In disaster management, people are interested in the development and the evolution of the disasters. If they intend to track the information of the disaster, they will be overwhelmed by the large number of disaster-related documents, microblogs, and news, etc. To support disaster management and minimize the loss during the disaster, it is necessary to efficiently and effectively collect, deliver, summarize, and analyze the disaster information, letting people in affected area quickly gain an overview of the disaster situation and improve their situational awareness. To present an integrated solution to address the information explosion problem during the disaster period, we designed and implemented DI-DAP, an efficient and effective disaster information delivery and analysis platform. DI-DAP is an information centric information platform aiming to provide convenient, interactive, and timely disaster information to the users in need. It is composed of three separated but complementary services: Disaster Vertical Search Engine , Disaster Storyline Generation , and Geo-Spatial Data Analysis Portal . These services provide a specific set of functionalities to enable users to consume highly summarized information and allow them to conduct ad-hoc geospatial information retrieval tasks. To support these services, DI-DAP adopts FIU-Miner , a fast, integrated, and user-friendly data analysis platform, which encapsulated all the computation and analysis workflow as well-defined tasks. Moreover, to enable ad-hoc geospatial information retrieval, an advanced query language MapQL is used and the query template engine is integrated. DI-DAP is designed and implemented as a disaster management tool and is currently been exercised as the disaster information platform by more than 100 companies and institutions in South Florida area.",2016,Conference on Information and Knowledge Management,emergency management;disaster recovery;world wide web;computer security;data mining;database;
Collective Classification via Discriminative Matrix Factorization on Sparsely Labeled Networks,"Daokun Zhang (University of Technology, Sydney);Jie Yin (Commonwealth Scientific and Industrial Research Organisation);Xingquan Zhu (Florida Atlantic University);Chengqi Zhang (University of Technology, Sydney);","2140738150,2150861151,2618356905,2166080598","We address the problem of classifying sparsely labeled networks, where labeled nodes in the network are extremely scarce. Existing algorithms, such as collective classification, have been shown to be effective for jointly deriving labels of related nodes, by exploiting class label dependencies among neighboring nodes. However, when the underlying network is sparsely labeled, most nodes have too few or even no connections to labeled nodes. This makes it very difficult to leverage supervised knowledge from labeled nodes to accurately estimate label dependencies, thereby largely degrading the classification accuracy. In this paper, we propose a novel discriminative matrix factorization (DMF) based algorithm that effectively learns a latent network representation by exploiting topological paths between labeled and unlabeled nodes, in addition to nodes' content information. The main idea is to use matrix factorization to obtain a compact representation of the network that fully encodes nodes' content information and network structure, and unleash discriminative power inferred from labeled nodes to directly benefit collective classification. To achieve this, we formulate a new matrix factorization objective function that integrates network representation learning with an empirical loss minimization for classifying node labels. An efficient optimization algorithm based on conjugate gradient methods is proposed to solve the new objective function. Experimental results on real-world networks show that DMF yields superior performance gain over the state-of-the-art baselines on sparsely labeled networks.",2016,Conference on Information and Knowledge Management,matrix decomposition;theoretical computer science;pattern recognition;machine learning;
Digesting News Reader Comments via Fine-Grained Associations with Event Facets and News Contents,Bei Shi (The Chinese University of Hong Kong);Wai Lam (The Chinese University of Hong Kong);,"2250712956,2119595446","News articles from different sources reporting the same event are often associated with an enormous amount of reader comments resulting in difficulty in digesting the comments manually. Some of these comments, despite coming from different sources, discuss about a certain facet of the event. On the other hand, some comments discuss on the specific topic of the corresponding news article. We propose a framework that can digest reader comments automatically via fine-grained associations with event facets and news. We propose an unsupervised model called DRC, based on collective matrix factorization and develop a multiplicative-update method to infer the parameters. Experimental results show that our proposed DRC model can provide an effective way to digest news reader comments.",2016,Conference on Information and Knowledge Management,matrix decomposition;world wide web;speech recognition;artificial intelligence;computer science;
Efficient Batch Processing for Multiple Keyword Queries on Graph Data,"Lu Chen (Swinburne University of Technology);Chengfei Liu (Swinburne University of Technology);Xiaochun Yang (Northeastern University);Bin Wang (Northeastern University);Jianxin Li (University of Western Australia);Rui Zhou (Victoria University, Australia);","2435341048,2144108974,2109336725,2643561327,2608401020,2109556250","Recently, answering keyword queries on graph data has drawn a great deal of attention from database communities. However, most graph keyword search solutions proposed so far primarily focus on a single query setting. We observe that for a popular keyword query system, the number of keyword queries received could be substantially large even in a short time interval, and the chance that these queries share common keywords is quite high. Therefore, answering keyword queries in batches would significantly enhance the performance of the system. Motivated by this, this paper studies efficient batch processing for multiple keyword queries on graph data. Realized that finding both the optimal query plan for multiple queries and the optimal query plan for a single keyword query on graph data are computationally hard, we first propose two heuristic approaches which target maximizing keyword overlap and give preferences for processing keywords with short sizes. Then we devise a cardinality based cost estimation model that takes both graph data statistics and search semantics into account. Based on the model, we design an A* based algorithm to find the global optimal execution plan for multiple queries. We evaluate the proposed model and algorithms on two real datasets and the experimental results demonstrate their efficacy.",2016,Conference on Information and Knowledge Management,keyword density;graph database;spatial query;batch processing;graph;information retrieval;data mining;database;computer science;
TGraph: A Temporal Graph Data Management System,Haixing Huang (Beihang University);Jinghe Song (Beihang University);Xuelian Lin (Beihang University);Shuai Ma (Beihang University);Jinpeng Huai (Beihang University);,"2531948039,2535595969,2640741533,2119375424,1966937424","Temporal graphs are a class of graphs whose nodes and edges, together with the associated properties, continuously change over time. Recently, systems have been developed to support snapshot queries over temporal graphs. However, these systems barely support aggregate time range queries. Moreover, these systems cannot guarantee ACID transactions, an important feature for data management systems as long as concurrent processing is involved. To solve these issues, we design and develop TGraph, a temporal graph data management system, that assures the ACID transaction feature, and supports fast temporal graph queries.",2016,Conference on Information and Knowledge Management,graph operations;clique width;graph database;graph;null model;data management;theoretical computer science;data mining;database;computer science;
A Multiple Instance Learning Framework for Identifying Key Sentences and Detecting Events,Wei Wang (Virginia Tech);Yue Ning (Virginia Tech);Huzefa Rangwala (George Mason University);Naren Ramakrishnan (Virginia Tech);,"2529750488,2493066754,2096698710,2199255697","State-of-the-art event encoding approaches rely on sentence or phrase level labeling, which are both time consuming and infeasible to extend to large scale text corpora and emerging domains. Using a multiple instance learning approach, we take advantage of the fact that while labels at the sentence level are difficult to obtain, they are relatively easy to gather at the document level. This enables us to view the problems of event detection and extraction in a unified manner. Using distributed representations of text, we develop a multiple instance formulation that simultaneously classifies news articles and extracts sentences indicative of events without any engineered features. We evaluate our model in its ability to detect news articles about civil unrest events (from Spanish text) across ten Latin American countries and identify the key sentences pertaining to these events. Our model, trained without annotated sentence labels, yields performance that is competitive with selected state-of-the-art models for event detection and sentence identification. Additionally, qualitative experimental results show that the extracted event-related sentences are informative and enhance various downstream applications such as article summarization, visualization, and event encoding.",2016,Conference on Information and Knowledge Management,angular mil;deep learning;information extraction;natural language processing;world wide web;speech recognition;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Discriminative View Learning for Single View Co-Training,Joseph St.Amand (University of Kansas);Jun Huan (University of Kansas);,"2413471006,2139058963","Co-training, a popular semi-supervised learning technique, is severely limited as it applicable only to datasets which have a natural division of the feature space into two or more distinct views. In this paper, we investigate techniques to apply co-training to single-view data sets. We develop a view learning technique which takes a single view dataset and learns multiple views. These learned views balance the available discriminatory information in the dataset, while still meeting Blum's co-training criteria. In addition, we constrain the views such that pairs of learned view embedding functions exhibit sparsity in a complementary pattern, which aid in increasing diversity. Finally, we demonstrate the efficacy of our approach via experimental means on several real-world datasets from different domains.",2016,Conference on Information and Knowledge Management,semi supervised learning;data mining;pattern recognition;machine learning;computer science;
Predicting Importance of Historical Persons using Wikipedia,Adam Jatowt (Kyoto University);Daisuke Kawai (Kyoto University);Katsumi Tanaka (Kyoto University);,"13250842,2621635348,2100196114","Wikipedia contains a lot of contemporary as well as history-related information, and given its vast coverage and richness, it can be used to rank entities in a variety of different ways. In this work, we are interested in utilizing Wikipedia for judging historical person's importance. Based on the two well-known lists of the most important people in the last millennium, we look closely into factors that determine significance of historical persons. We predict person's importance using six classifiers equipped with features derived from link structure, visit logs and article content.",2016,Conference on Information and Knowledge Management,brand;multimedia;world wide web;data mining;
Incorporate Group Information to Enhance Network Embedding,Jifan Chen (Fudan University);Qi Zhang (Fudan University);Xuanjing Huang (Fudan University);,"2228647164,2484821979,2161482855","The problem of representing large-scale networks with low-dimensional vectors has received considerable attention in recent years. Except the networks that include only vertices and edges, a variety of networks contain information about groups or communities. For example, on Facebook, in addition to users and the follower-followee relations between them, users can also create and join groups. However, previous studies have rarely utilized this valuable information to generate embeddings of vertices. In this paper, we investigate a novel method for learning the network embeddings with valuable group information for large-scale networks. The proposed methods take both the inner structures of the groups and the information across groups into consideration. Experimental results demonstrate that the embeddings generated by the proposed methods significantly outperform state-of-the-art network embedding methods on two different scale real-world network",2016,Conference on Information and Knowledge Management,theoretical computer science;
Webpage Depth-level Dwell Time Prediction,Chong Wang (New Jersey Institute of Technology);Achir Kalra (New Jersey Institute of Technology);Cristian Borcea (New Jersey Institute of Technology);Yi Chen (New Jersey Institute of Technology);,"2436599651,2109915864,2123637163,2620155405","The amount of time spent by users at specific page depths within webpages, called dwell time, can be used by web publishers to decide where to place online ads and what type of ads to place at different depths within a webpage. This paper presents a model to predict the dwell time for a given ""user, webpage, depth"" triplet based on historic data collected by publishers. Dwell time prediction is difficult due to user behavior variability and data sparsity. We adopt the Factorization Machines model because it is able to capture the interaction between users and webpages, overcome the data sparsity issue, and provide flexibility to add auxiliary information such as the visible area of a user's browser. Experimental results using data from a large web publisher demonstrate that our model outperforms deterministic and regression-based comparison models.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
aptMTVL: Nailing Interactions in Multi-Task Multi-View Multi-Label Learning using Adaptive-basis Multilinear Factor Analyzers,Xiaoli Li (University of Kansas);Jun Huan (University of Kansas);,"2672212736,2139058963","We investigate a new direction of multi-task multi-view learning where we have data sets with multiple tasks, multiple views and multiple labels. We call this problem a multi-task multi-view multi-label learning problem or MTVL learning for short. There is a wide application of MTVL leaning where examples include Internet of Things, brain science, and document classification. In designing effective MTVL learning algorithms, we hypothesize that a key component is to ""disentangle"" interactions among tasks, views, and labels, or the U task-view-label interactions . For that purpose we have developed an adaptive-basis multilinear analyzers(aptMLFA) that utilizes a loading tensor to modulate interactions among multiple latent factors. With aptMLFA we designed a new MTVL learning algorithm, aptMTVL, and evaluated its performance on 3 real-world data sets. The experimental results demonstrated the effectiveness of our proposed method as compared to the state-of-the-art MTVL learning algorithm.",2016,Conference on Information and Knowledge Management,stability;multi task learning;generalization error;active learning;semi supervised learning;instance based learning;unsupervised learning;theoretical computer science;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
Why Did You Cover That Song?: Modeling N-th Order Derivative Creation with Content Popularity,Kosetsu Tsukuda (National Institute of Advanced Industrial Science and Technology);Masahiro Hamasaki (National Institute of Advanced Industrial Science and Technology);Masataka Goto (National Institute of Advanced Industrial Science and Technology);,"2515680162,2153063948,2140422315","Many amateur creators now create derivative works and put them on the web. Although there are several factors that inspire the creation of derivative works, such factors cannot usually be observed on the web. In this paper, we propose a model for inferring latent factors from sequences of derivative work posting events. We assume a sequence to be a stochastic process incorporating the following three factors: (1) the original work's attractiveness, (2) the original work's popularity, and (3) the derivative work's popularity. To characterize content popularity, we use content ranking data and incorporate rank-biased popularity based on the creators' browsing behavior. Our main contributions are three-fold: (1) to the best of our knowledge, this is the first study modeling derivative creation activity, (2) by using a real-world dataset of music-related derivative work creation to evaluate our model, we showed the effectiveness of adopting all three factors to model derivative creation activity and onsidering creators' browsing behavior, and (3) we carried out qualitative experiments and showed that our model is useful in analyzing derivative creation activity in terms of category characteristics, temporal development of factors that trigger derivative work posting events, etc.",2016,Conference on Information and Knowledge Management,user generated content;latent variable model;multimedia;world wide web;data mining;artificial intelligence;machine learning;statistics;computer science;
Network-Efficient Distributed Word2vec Training System for Large Vocabularies,Erik Ordentlich (Yahoo!);Lee Yang (Yahoo!);Andy Feng (Yahoo!);Peter Cnudde (Yahoo!);Mihajlo Grbovic (Yahoo!);Nemanja Djuric (Aiken Technical College);Vladan Radosavljevic (Aiken Technical College);Gavin Owens (Yahoo!);,"2338049117,2163978776,2645179532,2628521124,2000240052,2128657275,1981991050,2464886585","Word2vec is a popular family of algorithms for unsupervised training of dense vector representations of words on large text corpuses. The resulting vectors have been shown to capture semantic relationships among their corresponding words, and have shown promise in reducing a number of natural language processing (NLP) tasks to mathematical operations on these vectors. While heretofore applications of word2vec have centered around vocabularies with a few million words, wherein the vocabulary is the set of words for which vectors are simultaneously trained, novel applications are emerging in areas outside of NLP with vocabularies comprising several 100 million words. Existing word2vec training systems are impractical for training such large vocabularies as they either require that the vectors of all vocabulary words be stored in the memory of a single server or suffer unacceptable training latency due to massive network data transfer. In this paper, we present a novel distributed, parallel training system that enables unprecedented practical training of vectors for vocabularies with several 100 million words on a shared cluster of commodity servers, using far less network traffic than the existing solutions. We evaluate the proposed system on a benchmark data set, showing that the quality of vectors does not degrade relative to non-distributed training. Finally, for several quarters, the system has been deployed for the purpose of matching queries to ads in Gemini, the sponsored search advertising platform at Yahoo, resulting in significant improvement of business metrics.",2016,Conference on Information and Knowledge Management,spark;theoretical computer science;natural language processing;world wide web;data mining;artificial intelligence;machine learning;programming language;computer science;
Understanding Sparse Topical Structure of Short Text via Stochastic Variational-Gibbs Inference,Tianyi Lin (The Chinese University of Hong Kong);Siyuan Zhang (The Chinese University of Hong Kong);Hong Cheng (The Chinese University of Hong Kong);,"2654068848,2640499744,2161754280","With the soaring popularity of online social media like Twitter, analyzing short text has emerged as an increasingly important task which is challenging to classical topic models, as topic sparsity exists in short text. Topic sparsity refers to the observation that individual document usually concentrates on several salient topics, which may be rare in entire corpus. Understanding this sparse topical structure of short text has been recognized as the key ingredient for mining user-generated Web content and social medium, which are featured in the form of extremely short posts and discussions. However, the existing sparsity-enhanced topic models all assume over-complicated generative process, which severely limits their scalability and makes them unable to automatically infer the number of topics from data. In this paper, we propose a probabilistic Bayesian topic model, namely Sparse Dirichlet mixture Topic Model (SparseDTM), based on Indian Buffet Process (IBP) prior, and infer our model on the large text corpora through a novel inference procedure called stochastic variational-Gibbs inference. Unlike prior work, the proposed approach is able to achieve exact sparse topical structure of large short text collections, and automatically identify the number of topics with a good balance between completeness and homogeneity of topic coherence. Experiments on different genres of large text corpora demonstrate that our approach outperforms various existing sparse topic models. The improvement is significant on large-scale collections of short text.",2016,Conference on Information and Knowledge Management,topic model;data science;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
CRISP: Consensus Regularized Selection based Prediction,Ping Wang (Virginia Tech);Karthik K. Padthe (Wayne State University);Bhanukiran Vinzamuri (Wayne State University);Chandan K. Reddy (Virginia Tech);,"2654931033,2538008682,23137369,2100435683","Integrating regularization methods with standard loss functions such as the least squares, hinge loss, etc., within a regression framework has become a popular choice for researchers to learn predictive models with lower variance and better generalization ability. Regularizers also aid in building interpretable models with high-dimensional data which makes them very appealing. It is observed that each regularizer is uniquely formulated in order to capture data-specific properties such as correlation, structured sparsity and temporal smoothness. The problem of obtaining a consensus among such diverse regularizers while learning a predictive model is extremely important in order to determine the optimal regularizer for the problem. The advantage of such an approach is that it preserves the simplicity of the final model learned by selecting a single candidate model which is not the case with ensemble methods as they use multiple candidate models for prediction. This is called the consensus regularization problem which has not received much attention in the literature due to the inherent difficulty associated with learning and selecting a model from an integrated regularization framework. To solve this problem, in this paper, we propose a method to generate a committee of non-convex regularized linear regression models, and use a consensus criterion to determine the optimal model for prediction. Each corresponding non-convex optimization problem in the committee is solved efficiently using the cyclic-coordinate descent algorithm with the generalized thresholding operator. Our Consensus RegularIzation Selection based Prediction (CRISP) model is evaluated on electronic health records (EHRs) obtained from a large hospital for the congestive heart failure readmission prediction problem. We also evaluate our model on high-dimensional synthetic datasets to assess its performance. The results indicate that CRISP outperforms several state-of-the-art methods such as additive, interactions-based and other competing non-convex regularized linear regression methods.",2016,Conference on Information and Knowledge Management,regularization;regression;data mining;artificial intelligence;machine learning;mathematical optimization;statistics;computer science;
Word Vector Compositionality based Relevance Feedback using Kernel Density Estimation,Dwaipayan Roy (Indian Statistical Institute);Debasis Ganguly (Dublin City University);Mandar Mitra (Indian Statistical Institute);Gareth J.F. Jones (Dublin City University);,"2162652759,2021801927,2104374829,2253680186","A limitation of standard information retrieval (IR) models is that the notion of term composionality is restricted to pre-defined phrases and term proximity. Standard text based IR models provide no easy way of representing semantic relations between terms that are not necessarily phrases, such as the equivalence relationship between `osteoporosis' and the terms `bone' and `decay'. To alleviate this limitation, we introduce a relevance feedback (RF) method which makes use of word embedded vectors. We leverage the fact that the vector addition of word embeddings leads to a semantic composition of the corresponding terms, e.g. addition of the vectors for `bone' and `decay' yields a vector that is likely to be close to the vector for the word `osteoporosis'. Our proposed RF model enables incorporation of semantic relations by exploiting term compositionality with embedded word vectors. We develop our model for RF as a generalization of the relevance model (RLM). Our experiments demonstrate that our word embedding based RF model significantly outperforms the RLM model on standard TREC test collections, namely the TREC 6,7,8 and Robust ad-hoc and the TREC 9 and 10 WT10G test collections.",2016,Conference on Information and Knowledge Management,kernel density estimation;natural language processing;speech recognition;information retrieval;machine learning;statistics;computer science;
Cost-Effective Stream Join Algorithm on Cloud System,"Junhua Fang (East China Normal University);Rong Zhang (East China Normal University);Xiaotong Wang (East China Normal University);Tom Z.J. Fu (Agency for Science, Technology and Research);Zhenjie Zhang (Agency for Science, Technology and Research);Aoying Zhou (East China Normal University);","2635493675,2423758776,2519080653,2083891144,2658385593,2111470091","Matrix-based scheme (Join-Matrix) can prefectly support distributed stream joins, especially for arbitrary join predicates, because it guarantees any tuples from two streams to meet with each other. However,the dynamics and unpredictability features of stream require quick actions on scheme changing. Otherwise, they may lead to degradation of system throughputs and increament of processing latency with the waste of system resources, such as CPUs and Memories. Since Join-Matrix model has the fixed processing architecture with replicated data, these kinds of adverseness will be magnified. Therefore, it is urgent to find a solution that preserves advantages of Join-Matrix model and promises a good usage to computation resources when it meets scheme changing. In this paper, we propose a cost-effective stream join algorithm, which ensures the adaptability of Join-Matrix but with lower resources consumption. Specifically, a varietal matrix generation algorithm is proposed to generate an irregular matrix scheme for assigning the minimal number of tasks; a lightweight migration algorithm is designed to ensure state migration at a low cost; a complete load balance process framework is described to guarantee the correctness during the scheme changing. We conduct extensive experiments to compare our method with baseline systems on both benchmarks and real-workloads, and explain the results in detail.",2016,Conference on Information and Knowledge Management,world wide web;parallel computing;distributed computing;data mining;database;real time computing;computer science;
Where are You Tweeting?: A Context and User Movement Based Approach,Zhi Liu (University of North Texas);Yan Huang (University of North Texas);,"2669665289,2130510374","Geotagged tweets allow one to extract geo-information-trend, search local events, and identify natural disasters. In this paper, we propose a Hidden-Markov-based model to integrate tweet contents and user movements for geotagging. A language model is obtained for different locations from training datasets and movements of users among cities are analyzed. Home cities of users are considered in modeling the patterns of user movements. Evaluation on a large Twitter dataset shows that our method can significantly improve geotagging accuracy by 55% for home cities and 2% for other non-home cities as well as reduce error distances by orders of magnitude compared with pure text-based methods.",2016,Conference on Information and Knowledge Management,geotagging;hidden markov model;internet privacy;world wide web;data mining;machine learning;computer science;
Retweet Prediction with Attention-based Deep Neural Network,Qi Zhang (Fudan University);Yeyun Gong (Fudan University);Jindou Wu (Fudan University);Haoran Huang (Fudan University);Xuanjing Huang (Fudan University);,"2484821979,2104159869,2533434835,2590160806,2161482855","On Twitter-like social media sites, the re-posting statuses or tweets of other users are usually considered to be the key mechanism for spreading information. How to predict whether a tweet will be retweeted by a user has received increasing attention in recent years. Previous methods studied the problem using various linguistic features, personal information of users, and many other manually constructed features to achieve the task. Usually, feature engineering is a laborious task, we require to obtain the external sources and they are difficult or not always available. Recently, deep learning methods have been used in the industry and research community for their ability to learn optimal features automatically and in many tasks, deep learning methods can achieve state-of-the art performance, such as natural language processing, computer vision, image classification and so on. In this work, we proposed a novel attention-based deep neural network to incorporate contextual and social information for this task. We used embeddings to represent the user, the user's attention interests, the author and tweet respectively. To train and evaluate the proposed methods, we also constructed a large dataset collected from Twitter. Experimental results showed that the proposed method could achieve better results than the previous state-of-the-art methods.",2016,Conference on Information and Knowledge Management,natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Query Variations and their Effect on Comparing Information Retrieval Systems,Guido Zuccon (Queensland University of Technology);João R. M. Palotti (Vienna University of Technology);Allan Hanbury (Vienna University of Technology);,"1551779932,2197643117,2168901591","We explore the implications of using query variations for evaluating information retrieval systems and how these variations should be exploited to compare system effectiveness. Current evaluation approaches consider the availability of a set of topics (information needs), and only one expression of each topic in the form of a query is used for evaluation and system comparison. While there is strong evidence that considering query variations better models the usage of retrieval systems and accounts for the important user aspect of user variability, it is unclear how to best exploit query variations for evaluating and comparing information retrieval systems. We propose a framework for evaluating retrieval systems that explicitly takes into account query variations. The framework considers both the system mean effectiveness and its variance over query variations and topics, as opposed to current approaches that only consider the mean across topics or perform a topic-focused analysis of variance across systems. Furthermore, the framework extends current evaluation practice by encoding: (1) user tolerance to effectiveness variations, (2) the popularity of different query variations, and (3) the relative importance of individual topics. These extensions and our findings make information retrieval comparisons more aligned with user behaviour.",2016,Conference on Information and Knowledge Management,ranking;web query classification;query expansion;query optimization;modern portfolio theory;theoretical computer science;world wide web;information retrieval;data mining;database;computer science;
Collective Traffic Prediction with Partially Observed Traffic History using Location-Based Social Media,Xinyue Liu (Worcester Polytechnic Institute);Xiangnan Kong (Worcester Polytechnic Institute);Yanhua Li (Worcester Polytechnic Institute);,"2687326342,2204127537,2160296268","Traffic prediction has become an important and active research topic in the last decade. Existing solutions mainly focus on exploiting the past and current traffic data, collected from various kinds of sensors, such as loop detectors, GPS devices, etc . In real-world road systems, only a small fraction of the road segments are deployed with sensors. For all the other road segments without sensors or historical traffic data, previous methods may no longer work. In this paper, we propose to use location-based social media, which captures a much larger area of the road systems than deployed sensors, to predict the traffic conditions. A simple but effective method called CTP is proposed to incorporate location-based social media semantics into the learning process. CTP also exploits complex dependencies among different regions to improve the prediction performances through collective inference. Empirical studies using traffic data and tweets collected in Los Angeles area demonstrate the effectiveness of CTP.",2016,Conference on Information and Knowledge Management,floating car data;social media;world wide web;computer security;data mining;database;artificial intelligence;simulation;computer science;
Scarce Feature Topic Mining for Video Recommendation,Wei Lu (Hong Kong Polytechnic University);Fu-lai Chung (Hong Kong Polytechnic University);Kunfeng Lai (Tencent);,"2654481479,2469582652,2562390450","Recommendation for user generated content sites has gained significant attention nowadays. To satisfy the niche tastes of users, product recommendation poses more challenges due to the data sparsity issue. This work is motivated by a real world online video recommendation problem, where the click records database suffers from sparseness of video inventory and video tags. Targeting the long tail phenomena of user behavior and sparsity of item features, we propose a personalized compound recommendation framework for online video recommendation called Dirichlet mixture probit model for information scarcity (DPIS). Assuming that each record is generated from a representation of user preferences, DPIS is a probit classifier utilizing record topical clustering on the user part for recommendation. As demonstrated by the real-world application, the proposed DPIS achieves better performance than traditional methods.",2016,Conference on Information and Knowledge Management,topic model;bayesian probability;recommender system;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Beyond Clustering: Sub-DAG Discovery for Categorising Documents,Ramakrishna B. Bairi (Indian Institute of Technology Bombay);Mark James Carman (Monash University);Ganesh Ramakrishnan (Indian Institute of Technology Bombay);,"1416699208,2123487663,2113956430","We study the problem of generating DAG-structured category hierarchies over a given set of documents associated with ""importance"" scores. Example application includes automatically generating Wikipedia disambiguation pages for a set of articles having click counts associated with them. Unlike previous works, which focus on clustering the set of documents using the category hierarchy as features, we directly pose the problem as that of finding a DAG structured generative mode that has maximum likelihood of generating the observed ""importance"" scores for each document where documents are modeled as the leaf nodes in the DAG structure. Desirable properties of the categories in the inferred DAG-structured hierarchy include document coverage and category relevance, each of which, we show, is naturally modeled by our generative model. We propose two different algorithms for estimating the model parameters. One by modeling the DAG as a Bayesian Network and estimating its parameters via Gibbs Sampling; and the other by estimating the path probabilities using the Expectation Maximization algorithm. We empirically evaluate our method on the problem of automatically generating Wikipedia disambiguation pages using human generated clusterings as the ground truth. We find that our framework improves upon the baselines according to the F1 score and Entropy that are used as standard metrics to evaluate the hierarchical clustering.",2016,Conference on Information and Knowledge Management,topic model;gibbs sampling;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Efficient Estimation of Triangles in Very Large Graphs,Roohollah Etemadi (University of Windsor);Jianguo Lu (University of Windsor);Yung H. Tsin (University of Windsor);,"2532838606,2698412956,671910775","The number of triangles in a graph is an important metric for understanding the graph. It is also directly related to the clustering coefficient of a graph, which is one of the most important indicator for social networks. Counting the number of triangles is computationally expensive for very large graphs. Hence, estimation is necessary for large graphs, particularly for graphs that are hidden behind searchable interfaces where the graphs in their entirety are not available. For instance, user networks in Twitter and Facebook are not available for third parties to explore their properties directly. This paper proposes a new method to estimate the number of triangles based on random edge sampling. It improves the traditional random edge sampling by probing the edges that have a higher probability of forming triangles. The method outperforms the traditional method consistently, and can be better by orders of magnitude when the graph is very large. The result is demonstrated on 20 graphs, including the largest graphs we can find. More importantly, we proved the improvement ratio, and verified our result on all the datasets. The analytical results are achieved by simplifying the variances of the estimators based on the assumption that the graph is very large. We believe that such big data assumption can lead to interesting results not only in triangle estimation, but also in other sampling problems.",2016,Conference on Information and Knowledge Management,partial k tree;indifference graph;forbidden graph characterization;1 planar graph;graph operations;comparability graph;random regular graph;critical graph;graph product;dense graph;modular decomposition;pathwidth;chordal graph;clustering coefficient;null model;random graph;estimation;statistics;
Effective Document Labeling with Very Few Seed Words: A Topic Model Approach,Chenliang Li (Wuhan University);Jian Xing (Wuhan University);Aixin Sun (Nanyang Technological University);Zongyang Ma (Nanyang Technological University);,"2133949981,2560009206,2124989948,2111067505","Developing text classifiers often requires a large number of labeled documents as training examples. However, manually labeling documents is costly and time-consuming. Recently, a few methods have been proposed to label documents by using a small set of relevant keywords for each category, known as dataless text classification . In this paper, we propose a S eed-Guided T opic M odel (named STM ) for the dataless text classification task. Given a collection of unlabeled documents, and for each category a small set of seed words that are relevant to the semantic meaning of the category, the STM predicts the category labels of the documents through topic influence. STM models two kinds of topics: category-topics and general-topics . Each category-topic is associated with one specific category, representing its semantic meaning. The general-topics capture the global semantic information underlying the whole document collection. STM assumes that each document is associated with a single category-topic and a mixture of general-topics. A novelty of the model is that STM learns the topics by exploiting the explicit word co-occurrence patterns between the seed words and regular words ( i.e. , non-seed words) in the document collection. A document is then labeled, or classified, based on its posterior category-topic assignment. Experiments on two widely used datasets show that STM consistently outperforms the state-of-the-art dataless text classifiers. In some tasks, STM can also achieve comparable or even better classification accuracy than the state-of-the-art supervised learning solutions. Our experimental results further show that STM is insensitive to the tuning parameters. Stable performance with little variation can be achieved in a broad range of parameter settings, making it a desired choice for real applications.",2016,Conference on Information and Knowledge Management,topic model;text mining;natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
Approximate Aggregates in Oracle 12C,Hong Su (Oracle Corporation);Mohamed Zaït (Oracle Corporation);Vladimir Barrière (Oracle Corporation);Joseph Torres (Oracle Corporation);Andre Cavalheiro Menck (Oracle Corporation);,"2656928419,2617495618,2533928397,2561192129,2284061201","New generation of analytic applications emerged to process data generated from non conventional sources. The challenge for the traditional database systems is that the data sets are very large and keep increasing at a very high rate while the application users have higher performance expectations. The most straightforward response to this challenge is to deploy larger hardware configurations making the solution very expensive and not acceptable for most cases. Alternative solutions fall into two categories: reduce the data set using sampling techniques or reduce the computational complexity of expensive database operations by using alternative algorithms. Alternative algorithms considered in this paper are approximate aggregates that perform a lot better at the cost of reduced and tolerable accuracy. In Oracle 12C we introduced approximate aggregates of expensive aggregate functions that are very common in analytic applications, that is, approximate count distinct and approximate percentile. The performance is improved in two ways. First, the approximate aggregates use bounded memory, often eliminating the need to use temporary storage which results in significant performance improvement over the exact aggregates. Second, we provide materialized view support that allows users to store pre-computed results of approximate aggregates. These results can be rolled up to answer queries on different dimensions (such rollup is not possible for exact aggregates).",2016,Conference on Information and Knowledge Management,theoretical computer science;data mining;database;machine learning;statistics;computer science;
Annotating Points of Interest with Geo-tagged Tweets,Kaiqi Zhao (Nanyang Technological University);Gao Cong (Nanyang Technological University);Aixin Sun (Nanyang Technological University);,"2134782497,2295915604,2124989948","Microblogging services like Twitter contain abundant of user generated content covering a wide range of topics. Many of the tweets can be associated to real-world entities for providing additional information for the latter. In this paper, we aim to associate tweets that are semantically related to real-world locations or Points of Interest (POIs). Tweets contain dynamic and real-time information while POIs contain relatively static information. The tweets associated with POIs provide complementary information for many applications like opinion mining and POI recommendation; the associated POIs can also be used as POI tags in Twitter. We define the research problem of annotating POIs with tweets and propose a novel supervised Bayesian Model (sBM). The model takes into account the textual, spatial features and user behaviors together with the supervised information of whether a tweet is POI-related. It is able to capture user interests in latent regions for the prediction of whether a tweet is POI-related and the association between the tweet and its most semantically related POI. On tweets and POIs collected for two cities (New York City and Singapore), we demonstrate the effectiveness of our models against baseline methods.",2016,Conference on Information and Knowledge Management,bayesian inference;regression;internet privacy;world wide web;data mining;statistics;
Automatical Storyline Generation with Help from Twitter,Ting Hua (Virginia Tech);Xuchao Zhang (Virginia Tech);Wei Wang (Virginia Tech);Chang-Tien Lu (Virginia Tech);Naren Ramakrishnan (Virginia Tech);,"2106233920,2558542419,2529750488,2112878203,2199255697","Storyline detection aims to connect seemly irrelevant single documents into meaningful chains, which provides opportunities for understanding how events evolve over time and what triggers such evolutions. Most previous work generated the storylines through unsupervised methods that can hardly reveal underlying factors driving the evolution process. This paper introduces a Bayesian model to generate storylines from massive documents and infer the corresponding hidden relations and topics. In addition, our model is the first attempt that utilizes Twitter data as human input to ``supervise'' the generation of storylines. Through extensive experiments, we demonstrate our proposed model can achieve significant improvement over baseline methods and can be used to discover interesting patterns for real world cases.",2016,Conference on Information and Knowledge Management,topic model;world wide web;data mining;machine learning;simulation;computer science;
Approximate Discovery of Functional Dependencies for Large Datasets,Tobias Bleifuß (Hasso Plattner Institute);Susanne Bülow (Hasso Plattner Institute);Johannes Frohnhofen (Hasso Plattner Institute);Julian Risch (Hasso Plattner Institute);Georg Wiese (Hasso Plattner Institute);Sebastian Kruse (Hasso Plattner Institute);Thorsten Papenbrock (Hasso Plattner Institute);Felix Naumann (Hasso Plattner Institute);,"2533241308,2169977169,267332255,2371457721,2559759695,2257309457,2167331809,2099727678","Functional dependencies (FDs) are an important prerequisite for various data management tasks, such as schema normalization, query optimization, and data cleansing. However, automatic FD discovery entails an exponentially growing search and solution space, so that even today's fastest FD discovery algorithms are limited to small datasets only, due to long runtimes and high memory consumptions. To overcome this situation, we propose an approximate discovery strategy that sacrifices possibly little result correctness in return for large performance improvements. In particular, we introduce AID-FD, an algorithm that approximately discovers FDs within runtimes up to orders of magnitude faster than state-of-the-art FD discovery algorithms. We evaluate and compare our performance results with a focus on scalability in runtime and memory, and with measures for completeness, correctness, and minimality.",2016,Conference on Information and Knowledge Management,functional dependency;data mining;database;machine learning;algorithm;computer science;
QART: A Tool for Quality Assurance in Real-Time in Contact Centers,Ragunathan Mariappan (Xerox);Balaji Peddamuthu (Xerox);Preethi R Raajaratnam (Xerox);Sandipan Dandapat (Xerox);Neeta Pande (Xerox);Shourya Roy (Xerox);,"2534539633,2538352206,1451487607,2560306702,2664605342,2146613775","In this paper, we describe an automatic real-time quality assurance system QA RT (pronounced cart) for contact center chats. QA RT performs multi-faceted analysis on dialogue utterances, as they happen, using sophisticated statistical and rule-based natural language processing (NLP) techniques. It covers various aspects inspired by today's Quality Assurance and Customer Satisfaction Scoring(C-Sat) practices as well as introduces novel components such as incremental dialogue summarization capability. QA RT front-end is an interactive dashboard providing views of ongoing dialogues at different granularity, enabling contact center supervisors to monitor and take corrective actions as needed. It is developed on state of the art stream computing platform Apache Spark Streaming with HBase datastore and Python Flask front end.",2016,Conference on Information and Knowledge Management,consumer behaviour;multimedia;world wide web;data mining;database;artificial intelligence;simulation;
A Probabilistic Multi-Touch Attribution Model for Online Advertising,"Wendi Ji (East China Normal University);Xiaoling Wang (East China Normal University);Dell Zhang (Birkbeck, University of London);","2703211390,2128137243,2158284782","It is an important problem in computational advertising to study the effects of different advertising channels upon user conversions, as advertisers can use the discoveries to plan or optimize advertising campaigns. In this paper, we propose a novel Probabilistic Multi-Touch Attribution (PMTA) model which takes into account not only which ads have been viewed or clicked by the user but also when each such interaction occurred. Borrowing the techniques from survival analysis, we use the Weibull distribution to describe the observed conversion delay and use the hazard rate of conversion to measure the influence of an ad exposure. It has been shown by extensive experiments on a large real-world dataset that our proposed model is superior to state-of-the-art methods in both conversion prediction and attribution analysis. Furthermore, a surprising research finding obtained from this dataset is that search ads are often not the root cause of final conversions but just the consequence of previously viewed ads.",2016,Conference on Information and Knowledge Management,survival analysis;world wide web;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
PISA: An Index for Aggregating Big Time Series Data,Xiangdong Huang (Tsinghua University);Jianmin Wang 0001 (Tsinghua University);Raymond K. Wong (University of New South Wales);Jinrui Zhang (Tsinghua University);Chen Wang (Tsinghua University);,"2115303606,2310637432,2290077475,2560384152,2645754196","Aggregation operation plays an important role in time series database management. As the amount of data increases, current solutions such as summary table and MapReduce-based methods struggle to respond to such queries with low latency. Other approaches such as segment tree based methods have a poor insertion performance when the data size exceeds the available memory. This paper proposes a new segment tree based index called PISA, which has fast insertion performance and low latency for aggregation queries. PISA uses a forest to overcome the performance disadvantages of insertions in traditional segment trees. By defining two kinds of tags, namely code number and serial number, we propose an algorithm to accelerate queries by avoiding reading unnecessary data on disk. The index is stored on disk and only takes a few hundred bytes of memory for billions of data points. PISA can be easily implemented on both traditional databases and NoSQL systems, examples including MySQL and Cassandra. It handles aggregation queries within milliseconds on a commodity server for a time range that may contain tens of billions of data points.",2016,Conference on Information and Knowledge Management,temporal database;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Structural Clustering of Machine-Generated Mail,Noa Avigdor-Elgrabli (Yahoo!);Mark Cwalinski (Yahoo!);Dotan Di Castro (Yahoo!);Iftah Gamzu (Yahoo!);Irena Grabovitch-Zuyev (Yahoo!);Liane Lewin-Eytan (Yahoo!);Yoelle Maarek (Yahoo!);,"2275537854,2536979520,2163216773,328684630,2560573581,2022197843,262608878","Several recent studies have presented different approaches for clustering and classifying machine-generated mail based on email headers. We propose to expand these approaches by considering email message bodies. We argue that our approach can help increase coverage and precision in several tasks, and is especially critical for mail extraction. We remind that mail extraction supports a variety of mail mining applications such as ad re-targeting, mail search, and mail summarization. We introduce new structural clustering methods that leverage the HTML structure that is common to messages generated by a same mass-sender script. We discuss how such structural clustering can be conducted at different levels of granularity, using either strict or flexible matching constraints, depending on the use cases. We present large scale experiments carried over real Yahoo mail traffic. For our first use case of automatic mail extraction, we describe novel flexible-matching clustering methods that meet the key requirements of high intra-cluster similarity, adequate clusters size, and relatively small overall number of clusters. We identify the precise level of flexibility that is needed in order to achieve extremely high extraction precision (close to 100%), while producing relatively small number of clusters. For our second use case, namely, mail classification, we show that strict structural matching is more adequate, achieving precision and recall rates between 85%-90%, while converging to a stable classification after a short learning cycle. This represents an increase of 10%-20% compared to the sender-based method described in previous work, when run over the same period length. Our work has been deployed in production in Yahoo mail backend.",2016,Conference on Information and Knowledge Management,internet privacy;world wide web;information retrieval;data mining;database;machine learning;computer science;
Detecting and Ranking Conceptual Links between Texts Using a Knowledge Base,"Martin Tutek (Faculty of Electrical Engineering and Computing, University of Zagreb);Goran Glavas (Faculty of Electrical Engineering and Computing, University of Zagreb);Jan Šnajder (Faculty of Electrical Engineering and Computing, University of Zagreb);Natasa Milić-Frayling (University of Nottingham);Bojana Dalbelo Basic (Faculty of Electrical Engineering and Computing, University of Zagreb);","2474316052,1664107684,2051582866,2561408884,1779508249","Recent research has explored the use of Knowledge Bases (KBs) to represent documents as subgraphs of a KB concept graph and define metrics to characterize semantic relatedness of documents in terms of properties of the document concept graphs. However, none of the studies so far have examined to what degree such metrics capture a user-perceived relatedness of documents. Considering the users' explanations of how pairs of documents are related, the aim is to identify concepts in a KB graph that express the same notion of document relatedness. Our algorithm generates paths through the KB graph that originate from the terms in two documents. KB concepts where these paths intersect capture the semantic relatedness of the two starting terms and therefore the two documents. We consider how such intersecting concepts relate to the concepts in the users' explanations. The higher the users' concepts appear in the ranked list of intersecting concepts, the better the method in capturing the users' notion of document relatedness. Our experiments show that our approach outperforms a simpler graph method that uses properties of the concept nodes alone.",2016,Conference on Information and Knowledge Management,semantic similarity;content analysis;theoretical computer science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Balanced Supervised Non-Negative Matrix Factorization for Childhood Leukaemia Patients,"Ali Braytee (University of Technology, Sydney);Daniel R. Catchpoole (Boston Children's Hospital);Paul J. Kennedy (University of Technology, Sydney);Wei Liu (University of Technology, Sydney);","409707907,1166170919,2100247246,2172864801","Supervised feature extraction methods have received considerable attention in the data mining community due to their capability to improve the classification performance of the unsupervised dimensionality reduction methods. With increasing dimensionality, several methods based on supervised feature extraction are proposed to achieve a feature ranking especially on microarray gene expression data. This paper proposes a method with twofold objectives: it implements a balanced supervised non-negative matrix factorization (BSNMF) to handle the class imbalance problem in supervised non-negative matrix factorization techniques. Furthermore, it proposes an accurate gene ranking method based on our proposed BSNMF for microarray gene expression datasets. To the best of our knowledge, this is the first work to handle the class imbalance problem in supervised feature extraction methods. This work is part of a Human Genome project at The Children's Hospital at Westmead (TB-CHW), Australia. Our experiments indicate that the factorized components using supervised feature extraction approach have more classification capability than the unsupervised one, but it drastically fails at the presence of class imbalance problem. Our proposed method outperforms the state-of-the-art methods and shows promise in overcoming this concern.",2016,Conference on Information and Knowledge Management,gene centered view of evolution;non negative matrix factorization;data mining;pattern recognition;machine learning;computer science;
Near Real-time Geolocation Prediction in Twitter Streams via Matrix Factorization Based Regression,Nghia Duong-Trung (University of Hildesheim);Nicolas Schilling (University of Hildesheim);Lars Schmidt-Thieme (University of Hildesheim);,"2395141778,2019736652,78243962","Previous research on content-based geolocation in general has developed prediction methods via conducting pre-partitioning and applying classification methods. The input of these methods is the concatenation of individual tweets during a period of time. But unfortunately, these methods have some drawbacks. They discard the natural real-values properties of latitude and longitude as well as fail to capture geolocation in near real-time. In this work, we develop a novel generative content-based regression model via a matrix factorization technique to tackle the near real-time geolocation prediction problem. With this model, we aim to address a couple of un-answered questions. First, we prove that near real-time geolocation prediction can be accomplished if we leave out the concatenation. Second, we account the real-values properties of physical coordinates within a regression solution. We apply our model on Twitter datasets as an example to prove the effectiveness and generality. Our experimental results show that the proposed model, in the best scenario, outperforms a set of state-of-the-art regression models including Support Vector Machines and Factorization Machines by a reduction of the median localization error up to 79%.",2016,Conference on Information and Knowledge Management,geolocation;matrix decomposition;regression;world wide web;data mining;machine learning;simulation;computer science;
Towards Time-Discounted Influence Maximization,Arijit Khan (Nanyang Technological University);,2164403858,"The classical influence maximization (IM) problem in social networks does not distinguish between whether a campaign gets viral in a week or in a year. From the practical standpoint, however, campaigns for a new technology or an upcoming movie must be spread as quickly as possible, otherwise they will be obsolete. To this end, we formulate and investigate the novel problem of maximizing the time-discounted influence spread in a social network, that is, the campaigner is interested in both ""when"" and ""how likely"" a user would be influenced. In particular, we assume that the campaigner has a utility function which monotonically decreases with the time required for a user to get influenced, since the activation of the seed nodes. The problem that we solve in this paper is to maximize the expected aggregated value of this utility function over all network users. This is a novel and relevant problem that, surprisingly, has not been studied before. Time-discounted influence maximization (TDIM), being a generalization of the classical IM, still remains NP-hard. However, our main contribution is to prove the sub-modularity of the objective function for any monotonically decreasing function of time, under a variety of influence cascading models, e.g., the independent cascade, linear threshold, and maximum influence arborescence models, thereby designing approximate algorithms with theoretical performance guarantees. We also illustrate that the existing optimization techniques (e.g., CELF) for influence maximization are more efficient over TDIM. Our experimental results demonstrate the effectiveness of our solutions over several baselines including the classical influence maximization algorithms.",2016,Conference on Information and Knowledge Management,social network;data mining;artificial intelligence;machine learning;simulation;mathematical optimization;statistics;
Active Content-Based Crowdsourcing Task Selection,"Piyush Bansal (International Institute of Information Technology, Hyderabad);Carsten Eickhoff (ETH Zurich);Thomas Hofmann (ETH Zurich);","2136097516,1992666041,2703362482","Crowdsourcing has long established itself as a viable alternative to corpus annotation by domain experts for tasks such as document relevance assessment. The crowdsourcing process traditionally relies on high degrees of label redundancy in order to mitigate the detrimental effects of individually noisy worker submissions. Such redundancy comes at the cost of increased label volume, and, subsequently, monetary requirements. In practice, especially as the size of datasets increases, this is undesirable. In this paper, we focus on an alternate method that exploits document information instead, to infer relevance labels for unjudged documents. We present an active learning scheme for document selection that aims at maximising the overall relevance label prediction accuracy, for a given budget of available relevance judgements by exploiting system-wide estimates of label variance and mutual information. Our experiments are based on TREC 2011 Crowdsourcing Track data and show that our method is able to achieve state-of-the-art performance while requiring 17% - 25% less budget.",2016,Conference on Information and Knowledge Management,crowdsourcing;active learning;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
From Recommendation to Profile Inference (Rec2PI): A Value-added Service to Wi-Fi Data Mining,Cheng Chen (University of Victoria);Fang Dong (University of Victoria);Kui Wu (University of Victoria);Venkatesh Srinivasan (University of Victoria);Alex Thomo (University of Victoria);,"2561786263,2425817321,2149089207,2125078017,83612842","Portable smart devices have become prevalent and are used for ubiquitous access to the Internet in our daily life. Taking advantage of this trend, brick-and-mortar retailers have been increasingly deploying free Wi-Fi hotspots to provide easy Internet access for their customers. This opens the opportunity for retailers to collect customer information and perform data mining to improve the quality of their service. In this paper, we propose a novel value-added service to Wi-Fi data mining, Rec2PI, which can infer users' preference profiles based on recommendations pushed by third-party apps. Such profiles can be used to improve users' online experience and enable a brick-and-mortar retailer to participate in the global advertising business. Since the goal and technical difficulties of Rec2PI significantly differ from those of traditional recommender systems, we present a general framework of Rec2PI to illustrate its process. To tackle the technical challenges in profile inference, we propose novel algorithms built using copulas, a statistical tool suitable for capturing complex dependence structure beyond the scope of linear dependence. In the context of rating-based recommendations, we evaluate the proposed algorithms using an open dataset and a real-world recommender system. The evaluation results show that Rec2PI creates consistent and accurate inference results.",2016,Conference on Information and Knowledge Management,world wide web;data mining;database;
Joint Collaborative Ranking with Social Relationships in Top-N Recommendation,Dimitrios Rafailidis (Aristotle University of Thessaloniki);Fabio Crestani (University of Southern Indiana);,"2104576903,2558677592","With the advent of learning to rank methods, relevant studies showed that Collaborative Ranking (CR) models can produce accurate ranked lists in the top-N recommendation problem. However, in practice several real-world problems decrease their ranking performance, such as the sparsity and cold-start problems, which often occur in recommendation systems for inactive or new users. In this study, to account for the fact that the selections of social friends can improve the recommendation accuracy, we propose a joint CR model based on the users' social relationships. We propose two different CR strategies based on the notions of Social Reverse Height and Social Height, which consider how well the relevant and irrelevant items of users and their social friends have been ranked at the top of the list, respectively. We focus on the top of the list mainly because users see the top-N recommendations in real-world applications, and not the whole ranked list. Furthermore, we formulate a joint objective function to consider both CR strategies, and propose an alternating minimization algorithm to learn our joint CR model. Our experiments on benchmark datasets show that our proposed joint CR model outperforms other state-of-the-art models that either consider social relationships or focus on the ranking performance at the top of the list.",2016,Conference on Information and Knowledge Management,learning to rank;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Learning to Rank Non-Factoid Answers: Comment Selection in Web Forums,Kateryna Tymoshenko (University of Trento);Daniele Bonadiman (University of Trento);Alessandro Moschitti (Qatar Computing Research Institute);,"2652651832,2468808117,48142092","Recent initiatives in IR community have shown the importance of going beyond factoid Question Answering (QA) in order to design useful real-world applications. Questions asking for descriptions or explanations are much more difficult to be solved, e.g., the machine learning models cannot focus on specific answer words or their lexical type. Thus, researchers have started to explore powerful methods for feature engineering. Two of the most promising methods are convolution tree kernels (CTKs) and convolutional neural networks (CNNs) as they have been shown to obtain high performance in the task of answer sentence selection in factoid QA. In this paper, we design state-of-the-art models for non-factoid QA also carried out on noisy data. In particular, we study and compare models for comment selection in a community QA (cQA) scenario, where the majority of questions regard descriptions or explanations. To deal with such complex task, we incorporate relational information holding between questions and comments as well as domain-specific features into both convolutional models above. Our experiments on a cQA corpus show that both CTK and CNN achieve the state of the art, also according to a direct comparison with the results obtained by the best systems of the SemEval cQA challenge.",2016,Conference on Information and Knowledge Management,kernel method;question answering;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
SemiNMF-PCA framework for Sparse Data Co-clustering,Kais Allab (University of Paris);Lazhar Labiod (University of Paris);Mohamed Nadif (University of Paris);,"2477615743,2479513158,2682351797","Several studies have demonstrated the importance of co-clustering which aims to cluster simultaneously the sets of objects and features. The co-clustering is often more effective than one-side clustering, especially when considering sparse high dimensional data. In this paper, we propose a novel way to consider the co-clustering and the reduction of the dimension simultaneously. Our approach takes advantage of the mutual reinforcement between Principal Component Analysis (PCA) which provides a low-dimensional representation of data and Semi-Nonnegative Matrix Factorization (SemiNMF) that learns this low-dimensional representation and lends itself to a co-clustering interpretation. In other words, the proposed framework aims to find an optimal subspace of multi-dimensional variables for effectively identifying a partition of the set of objects. We show that by doing so, our model is able to learn low-dimensional representations that are better suited for co-clustering, outperforming not only spectral methods, but also co-clustering graph-regularized-based methods.",2016,Conference on Information and Knowledge Management,dimensionality reduction;matrix decomposition;biclustering;data mining;pattern recognition;machine learning;computer science;
Scaling Factorization Machines with Parameter Server,Erheng Zhong (Baidu);Yue Shi (Yahoo!);Nathan Liu (Google);Suju Rajan (Yahoo!);,"2560321765,2714713288,2560430539,2229133469","Factorization Machines (FM) have been recognized as an effective learning paradigm for incorporating complex relations to improve item recommendation in recommender systems. However, one open issue of FM lies in its factorized representation (latent factors) for each feature in the observed feature space, a characteristic often resulting in a large parameter space. Therefore, training FM (in other words, learning a large number of parameters in FM) is a computationally expensive task. Our work targets to improve the scalability of FM by building it in a distributed environment. We propose a new system framework that integrates Parameter Server (PS) with the Map/Reduce (MR) framework. In addition to the data parallelism achieved via MR, our framework particularly benefits from PS for model parallelism, a critical characteristic for learning with a large number of parameters in FM. We further address two specific challenges in our system, namely, communication cost and parameter update collision. Through both offline and online experiments on recommendation tasks, we demonstrate that the proposed system framework succeeds in scaling up FM for very large datasets, while it also maintains competitive performance on recommendation quality compared to alternative baselines.",2016,Conference on Information and Knowledge Management,collaborative filtering;theoretical computer science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Qualitative Cleaning of Uncertain Data,Henning Koehler (Massey University);Sebastian Link (University of Auckland);,"1987773696,2095647292","We propose a new view on data cleaning: Not data itself but the degrees of uncertainty attributed to data are dirty. Applying possibility theory, tuples are assigned degrees of possibility with which they occur, and constraints are assigned degrees of certainty that say to which tuples they apply. Classical data cleaning modifies some minimal set of tuples. Instead, we marginally reduce their degrees of possibility. This reduction leads to a new qualitative version of the vertex cover problem. Qualitative vertex cover can be mapped to a linear-weighted constraint satisfaction problem. However, any off-the-shelf solver cannot solve the problem more efficiently than classical vertex cover. Instead, we utilize the degrees of possibility and certainty to develop a dedicated algorithm that is fixed parameter tractable in the size of the qualitative vertex cover. Experiments show that our algorithm is faster than solvers for the classical vertex cover problem by several orders of magnitude, and performance improves with higher numbers of uncertainty degrees.",2016,Conference on Information and Knowledge Management,edge cover;feedback vertex set;vertex cover;possibility theory;artificial intelligence;machine learning;algorithm;computer science;
Towards the Effective Linking of Social Media Contents to Products in E-Commerce Catalogs,Henry S. Vieira (Federal University of Amazonas);Altigran Soares da Silva (Federal University of Amazonas);Pável Calado (INESC-ID);Marco Cristo (Federal University of Amazonas);Edleno Silva de Moura (Federal University of Amazonas);,"2484389818,2155740526,2038722768,2567321649,2121054036","Online social media has become an essential part of our life. This media is often characterized by its diverse content, which is produced by ordinary users. The potential to easily express ideas and opinions has made social media a source of valuable information on a variety of topics. In particular, information containing comments about consumer products has become prevalent. Here, we are interested in linking products mentioned in unstructured user-generated content, namely open discussion forums, to their respective entities in consumer product catalogs. Among the issues associated with this task, ambiguity is a particularly hard problem, as users typically refer to the same product using many different forms and different products may share the same form. We argue that this problem can be effectively solved using a set of evidences that can be easily extracted from social media content and product descriptions. To achieve this, we show which features should be used, how they can be extracted, and then how to combine them through machine learning techniques. Experiments in three different product categories and two different datasets demonstrate that all the sources of evidence here proposed are important, while contextual information is fundamental to achieve higher levels of precision. In fact, our method, although straightforward, was able to achieve an average improvement of 0.17 in precision and 0.13 in F1, when compared to the current state-of-the-art solution.",2016,Conference on Information and Knowledge Management,social media;text mining;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Privacy-Preserving Reachability Query Services for Massive Networks,Jiaxin Jiang (Hong Kong Baptist University);Peipei Yi (Hong Kong Baptist University);Byron Choi (Hong Kong Baptist University);Zhiwei Zhang (Hong Kong Baptist University);Xiaohui Yu (Shandong University);,"2685063421,2163842591,2117040297,2307175532,2097734689","This paper studies privacy-preserving reachability query services under the paradigm of data outsourcing. Specifically, graph data have been outsourced to a third-party service provider ( SP ), query clients submit their queries to the ( SP ), and the ( SP ) returns the query answers to the clients. However, the ( SP ) may not always be trustworthy. Hence, this paper investigates protecting the structural information of the graph data and the query answers from the ( SP ). Existing techniques are either insecure or not scalable. This paper proposes a privacy-preserving labeling, called ppTopo. To our knowledge, ppTopo is the first work that can produce reachability index on massive networks and is secure against known plaintext attacks (KPA). Specifically, we propose a scalable index construction algorithm by employing the idea of topological folding, recently proposed by Cheng et al. We propose a novel asymmetric scalar product encryption in modulo 3 (ASPE3). It allows us to encrypt the index labels and transforms the queries into scalar products of encrypted labels. We perform an experimental study of the proposed technique on the SNAP networks. Compared with the existing methods, our results show that our technique is capable of producing the encrypted indexes at least 5 times faster for massive networks and the client's decryption time is 2-3 times smaller for most graphs.",2016,Conference on Information and Knowledge Management,graph database;query language;theoretical computer science;world wide web;information retrieval;data mining;database;computer science;
A Neural Network Approach to Quote Recommendation in Writings,Jiwei Tan (Peking University);Xiaojun Wan (Peking University);Jianguo Xiao (Peking University);,"2143668223,2146508076,2131977055","Quote is a language phenomenon of transcribing the saying of someone else. Proper usage of quote can usually make the statement more elegant and convincing. However, the ability of quote usage is usually limited by the amount of quotes one remembers or knows. Quote recommendation is a task of exploiting abundant quote repositories to help people make better use of quotes while writing. The task is different from conventional recommendation tasks due to the characteristic of quote. A pilot study has explored this task by using a learning to rank framework and manually designed features. However, it is still hard to model the meaning of a quote, which is an interesting and challenging problem. In this paper, we propose a neural network approach based on LSTMs to the quote recommendation task. We directly learn the distributed meaning representations for the contexts and the quotes, and then measure the relevance based on the meaning representations. In particular, we try to represent the words in quotes with specific embeddings, according to the contexts, topics and even author preferences of the quotes. Experimental results on a large dataset show that our proposed approach achieves the state-of-the-art performance and it outperforms several strong baselines.",2016,Conference on Information and Knowledge Management,long short term memory;deep learning;world wide web;data mining;artificial intelligence;machine learning;computer science;
Inspiration or Preparation?: Explaining Creativity in Scientific Enterprise,Xinyang Zhang (Lehigh University);Dashun Wang (Northwestern University);Ting Wang (Lehigh University);,"2533497801,2098143673,2568094062","Human creativity is the ultimate driving force behind scientific progress. While the building blocks of innovations are often embodied in existing knowledge, it is creativity that blends seemingly disparate ideas. Existing studies have made striding advances in quantifying creativity of scientific publications by investigating their citation relationships. Yet, little is known hitherto about the underlying mechanisms governing scientific creative processes, largely due to that a paper's references, at best, only partially reflect its authors' actual information consumption. This work represents an initial step towards fine-grained understanding of creative processes in scientific enterprise. In specific, using two web-scale longitudinal datasets (120.1 million papers and 53.5 billion web requests spanning 4 years), we directly contrast authors' information consumption behaviors against their knowledge products. We find that, of 59.0% papers across all scientific fields, 25.7% of their creativity can be readily explained by information consumed by their authors. Further, by leveraging these findings, we develop a predictive framework that accurately identifies the most critical knowledge to fostering target scientific innovations. We believe that our framework is of fundamental importance to the study of scientific creativity. It promotes strategies to stimulate and potentially automate creative processes, and provides insights towards more effective designs of information recommendation platforms.",2016,Conference on Information and Knowledge Management,creativity technique;management science;knowledge management;world wide web;social science;artificial intelligence;sociology;computer science;
On Structural Health Monitoring Using Tensor Analysis and Support Vector Machine with Artificial Negative Data,"Prasad Cheema (Commonwealth Scientific and Industrial Research Organisation);Nguyen Lu Dang Khoa (Commonwealth Scientific and Industrial Research Organisation);Mehrisadat Makki Alamdari (Commonwealth Scientific and Industrial Research Organisation);Wei Liu (University of Technology, Sydney);Yang Wang (Commonwealth Scientific and Industrial Research Organisation);Fang Chen (Commonwealth Scientific and Industrial Research Organisation);Peter Runcie (Commonwealth Scientific and Industrial Research Organisation);","2558108086,2046895292,2079446620,2172864801,2629024335,2559371593,2035030998","Structural health monitoring is a condition-based technology to monitor infrastructure using sensing systems. Since we usually only have data associated with the healthy state of a structure, one-class approaches are more practical. However, tuning the parameters for one-class techniques (like one-class Support Vector Machines) still remains a relatively open and difficult problem. Moreover, in structural health monitoring, data are usually multi-way, highly redundant and correlated, which a matrix-based two-way approach cannot capture all these relationships and correlations together. Tensor analysis allows us to analyse the multi-way vibration data at the same time. In our approach, we propose the use of tensor learning and support vector machines with artificial negative data generated by density estimation techniques for damage detection, localization and estimation in a one-class manner. The artificial negative data can help tuning SVM parameters and calibrating probabilistic outputs, which is not possible to do with one-class SVM. The proposed method shows promising results using data from laboratory-based structures and also with data collected from the Sydney Harbour Bridge, one of the most iconic structures in Australia. The method works better than the one-class approach and the approach without using tensor analysis.",2016,Conference on Information and Knowledge Management,tensor;density estimation;support vector machine;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
Tracking the Evolution of Congestion in Dynamic Urban Road Networks,Tarique Anwar (Swinburne University of Technology);Chengfei Liu (Swinburne University of Technology);Hai L. Vu (Swinburne University of Technology);Md. Saiful Islam (Swinburne University of Technology);,"2125769409,2144108974,2275185045,2429334933","The congestion scenario on a road network is often represented by a set of differently congested partitions having homogeneous level of congestion inside. Due to the changing traffic, these partitions evolve with time. In this paper, we propose a two-layer method to incrementally update the differently congested partitions from those at the previous time point in an efficient manner, and thus track their evolution. The physical layer performs low-level computations to incrementally update a set of small-sized road network building blocks, and the logical layer provides an interface to query the physical layer about the congested partitions. At each time point, the unstable road segments are identified and moved to their most suitable building blocks. Our experimental results on different datasets show that the proposed method is much efficient than the existing re-partitioning methods without significant sacrifice in accuracy.",2016,Conference on Information and Knowledge Management,simulation;
Growing Graphs from Hyperedge Replacement Graph Grammars,Salvador Aguiñaga (University of Notre Dame);Rodrigo Palacios (California State University);David Chiang (University of Notre Dame);Tim Weninger (University of Notre Dame);,"2084141825,2560357051,2297564775,2037649753","Discovering the underlying structures present in large real world graphs is a fundamental scientific problem. In this paper we show that a graph's clique tree can be used to extract a hyperedge replacement grammar. If we store an ordering from the extraction process, the extracted graph grammar is guaranteed to generate an isomorphic copy of the original graph. Or, a stochastic application of the graph grammar rules can be used to quickly create random graphs. In experiments on large real world networks, we show that random graphs, generated from extracted graph grammars, exhibit a wide range of properties that are very similar to the original graphs. In addition to graph properties like degree or eigenvector centrality, what a graph ``looks like'' ultimately depends on small details in local graph substructures that are difficult to define at a global level. We show that our generative graph model is able to preserve these local substructures when generating new graphs and performs well on new and difficult tests of model robustness.",2016,Conference on Information and Knowledge Management,distance hereditary graph;simplex graph;voltage graph;complement graph;forbidden graph characterization;coxeter graph;vertex transitive graph;butterfly graph;comparability graph;universal graph;block graph;null graph;graph product;clique width;graph property;outerplanar graph;symmetric graph;cubic graph;line graph;graph;discrete mathematics;combinatorics;machine learning;mathematics;
Multiple Infection Sources Identification with Provable Guarantees,Hung T. Nguyen (Virginia Commonwealth University);Preetam Ghosh (Virginia Commonwealth University);Michael L. Mayo (Engineer Research and Development Center);Thang N. Dinh (Virginia Commonwealth University);,"2696605192,2123638769,2106067942,1982323184","Given an aftermath of a cascade in the network, i.e. a set V I of ""infected"" nodes after an epidemic outbreak or a propagation of rumors/worms/viruses, how can we infer the sources of the cascade? Answering this challenging question is critical for computer forensic, vulnerability analysis, and risk management. Despite recent interest towards this problem, most of existing works focus only on single source detection or simple network topologies, e.g. trees or grids. In this paper, we propose a new approach to identify infection sources by searching for a seed set S that minimizes the symmetric difference between the cascade from S and V I , the given set of infected nodes. Our major result is an approximation algorithm, called SISI, to identify infection sources without the prior knowledge on the number of source nodes . SISI, to our best knowledge, is the first algorithm with provable guarantee for the problem in general graphs. It returns a 2/((1-e) 2 Δ-approximate solution with high probability, where Δ denotes the maximum number of nodes in V I that may infect a single node in the network. Our experiments on real-world networks show the superiority of our approach and SISI in detecting true source(s), boosting the F1-measure from few percents, for the state-of-the-art NETSLEUTH, to approximately 50%.",2016,Conference on Information and Knowledge Management,approximation algorithm;theoretical computer science;combinatorics;world wide web;machine learning;algorithm;computer science;mathematics;
Selective Cluster-Based Document Retrieval,Or Levi (Technion – Israel Institute of Technology);Fiana Raiber (Technion – Israel Institute of Technology);Oren Kurland (Technion – Israel Institute of Technology);Ido Guy (Yahoo!);,"2539331141,347751262,2250933759,2675969824","We address the long standing challenge of selective cluster-based retrieval ; namely, deciding on a per-query basis whether to apply cluster-based document retrieval or standard document retrieval. To address this classification task, we propose a few sets of features based on those utilized by the cluster-based ranker, query-performance predictors, and properties of the clustering structure. Empirical evaluation shows that our method outperforms state-of-the-art retrieval approaches, including cluster-based, query expansion, and term proximity methods.",2016,Conference on Information and Knowledge Management,term discrimination;human computer information retrieval;query expansion;vector space model;relevance;document clustering;document retrieval;information retrieval;data mining;database;computer science;
MIST: Missing Person Intelligence Synthesis Toolkit,Elham Shaabani (Arizona State University);Hamidreza Alvari (Arizona State University);Paulo Shakarian (Arizona State University);J. E. Kelly Snyder;,"2070833751,2565122393,102302551,2484549282","Each day, approximately 500 missing persons cases occur that go unsolved/unresolved in the United States. The non-profit organization known as the Find Me Group (FMG), led by former law enforcement professionals, is dedicated to solving or resolving these cases. This paper introduces the Missing Person Intelligence Synthesis Toolkit (MIST) which leverages a data-driven variant of geospatial abductive inference. This system takes search locations provided by a group of experts and rank-orders them based on the probability assigned to areas based on the prior performance of the experts taken as a group. We evaluate our approach compared to the current practices employed by the Find Me Group and found it significantly reduces the search area - leading to a reduction of 31 square miles over 24 cases we examined in our experiments. Currently, we are using MIST to aid the Find Me Group in an active missing person case.",2016,Conference on Information and Knowledge Management,abductive reasoning;operations research;data mining;artificial intelligence;machine learning;statistics;computer science;
Sequential Query Expansion using Concept Graph,Saeid Balaneshin-kordan (Wayne State University);Alexander Kotov (Wayne State University);,"2483446533,2123127453","Manually and automatically constructed concept graphs (or semantic networks), in which the nodes correspond to words or phrases and the typed edges designate semantic relationships between words and phrases, have been previously shown to be rich sources of effective latent concepts for query expansion. However, finding good expansion concepts for a given query in large and dense concept graphs is a challenging problem, since the number of candidate concepts that are related to query terms and phrases and need to be examined increases exponentially with the distance from the original query concepts. In this paper, we propose a two-stage feature-based method for sequential selection of the most effective concepts for query expansion from a concept graph. In the first stage, the proposed method weighs the concepts according to different types of computationally inexpensive features, including collection and concept graph statistics. In the second stage, a sequential concept selection algorithm utilizing more expensive features is applied to find the most effective expansion concepts at different distances from the original query concepts. Experiments on TREC datasets of different type indicate that the proposed method achieves significant improvement in retrieval accuracy over state-of-the-art methods for query expansion using concept graphs.",2016,Conference on Information and Knowledge Management,sargable;rdf query language;boolean conjunctive query;web search query;web query classification;query expansion;query optimization;semantic network;query language;information retrieval;data mining;database;pattern recognition;computer science;
Personalized Semantic Word Vectors,Javid Ebrahimi (University of Oregon);Dejing Dou (University of Oregon);,"2309072058,2040419331","Distributed word representations are able to capture syntactic and semantic regularities in text. In this paper, we present a word representation scheme that incorporates authorship information. While maintaining similarity among related words in the induced distributed space, our word vectors can be effectively used for some text classification tasks too. We build on a log-bilinear document model (lbDm), which extracts document features, and word vectors based on word co-occurrence counts. First, we propose a log-bilinear author model (lbAm), which contains an additional author matrix. We show that by directly learning author feature vectors, as opposed to document vectors, we can learn better word representations for the authorship attribution task. Furthermore, authorship information has been found to be useful for sentiment classification. We enrich the author model with a sentiment tensor, and demonstrate the effectiveness of this hybrid model (lbHm) through our experiments on a movie review-classification dataset.",2016,Conference on Information and Knowledge Management,word lists by frequency;natural language processing;speech recognition;information retrieval;computer science;
Learning to Re-Rank Questions in Community Question Answering Using Advanced Features,Giovanni Da San Martino (Khalifa University);Alberto Barrón Cedeño (Khalifa University);Salvatore Romeo (Khalifa University);Antonio Uva (University of Trento);Alessandro Moschitti (Khalifa University);,"2150053968,2613499377,2460589072,2476492215,48142092","We study the impact of different types of features for question ranking in community Question Answering: bag-of-words models (BoW), syntactic tree kernels (TKs) and rank features. It should be noted that structural kernels have never been applied to the question reranking task, i.e., question to question similarity, where they have to model paraphrase relations. Additionally, the informal text, typically present in forums, poses new challenges to the use of TKs. We compare our learning to rank (L2R) algorithms against a strong baseline given by the Google rank (GR). The results show that (i) our shallow structures used in TKs are robust enough to noisy data and (ii) improving GR requires effective BoW features and TKs along with an accurate model of GR features in the used L2R algorithm.",2016,Conference on Information and Knowledge Management,learning to rank;natural language processing;information retrieval;data mining;machine learning;computer science;
"""Shall I Be Your Chat Companion?"": Towards an Online Human-Computer Conversation System",Rui Yan (Peking University);Yiping Song (Peking University);Xiangyang Zhou (Baidu);Hua Wu (Baidu);,"2109109241,2686548685,2558220530,2696646157","To establish an automatic conversation system between human and computer is regarded as one of the most hardcore problems in computer science. It requires interdisciplinary techniques in information retrieval, natural language processing, and data management, etc. The challenges lie in how to respond like a human, and to maintain a relevant, meaningful, and continuous conversation. The arrival of big data era reveals the feasibility to create such a system empowered by data-driven approaches. We can now organize the conversational data as a chat companion. In this paper, we introduce a chat companion system, which is a practical conversation system between human and computer as a real application. Given the human utterances as queries, our proposed system will respond with corresponding replies retrieved and highly ranked from a massive conversational data repository. Note that 'practical' here indicates effectiveness and efficiency : both issues are important for a real-time system based on a massive data repository. We have two scenarios of single-turn and multi-turn conversations. In our system, we have a base ranking without conversational context information (for single-turn) and a context-aware ranking (for multi-turn). Both rankings can be conducted either by a shallow learning or deep learning paradigm. We combine these two rankings together in optimization. In the experimental setups, we investigate the performance between effectiveness and efficiency for the proposed methods, and we also compare against a series of baselines to demonstrate the advantage of the proposed framework in terms of p@1, MAP, and nDCG. We present a new angle to launch a practical online conversation system between human and computer.",2016,Conference on Information and Knowledge Management,big data;natural language processing;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Leveraging Multiple GPUs and CPUs for Graphlet Counting in Large Networks,Ryan A. Rossi (PARC);Rong Zhou (PARC);,"2060818872,2170103657","Massively parallel architectures such as the GPU are becoming increasingly important due to the recent proliferation of data. In this paper, we propose a key class of hybrid parallel graphlet algorithms that leverages multiple CPUs and GPUs simultaneously for computing k-vertex induced subgraph statistics (called graphlets). In addition to the hybrid multi-core CPU-GPU framework, we also investigate single GPU methods (using multiple cores) and multi-GPU methods that leverage all available GPUs simultaneously for computing induced subgraph statistics. Both methods leverage GPU devices only, whereas the hybrid multi-core CPU-GPU framework leverages all available multi-core CPUs and multiple GPUs for computing graphlets in large networks. Compared to recent approaches, our methods are orders of magnitude faster, while also more cost effective enjoying superior performance per capita and per watt. In particular, the methods are up to 300 times faster than a recent state-of-the-art method. To the best of our knowledge, this is the first work to leverage multiple CPUs and GPUs simultaneously for computing induced subgraph statistics.",2016,Conference on Information and Knowledge Management,general purpose computing on graphics processing units;symmetric multiprocessor system;parallel algorithm;feature learning;theoretical computer science;parallel computing;machine learning;computer science;
Memory-based Recommendations of Entities for Web Search Users,Ignacio Fernández-Tobías (Autonomous University of Madrid);Roi Blanco (University of A Coruña);,"155911543,2128286424","Modern search engines have evolved from mere document retrieval systems to platforms that assist the users in discovering new information. In this context, entity recommendation systems exploit query log data to proactively provide the users with suggestions of entities (people, movies, places, etc.) from knowledge bases that are relevant for their current information need. Previous works consider the problem of ranking facts and entities related to the user's current query, or focus on specific recommendation domains requiring supervised selection and extraction of features from knowledge bases. In this paper we propose a set of domain-agnostic methods based on nearest neighbors collaborative filtering that exploit query log data to generate entity suggestions, taking into account the user's full search session. Our experimental results on a large dataset from a commercial search engine show that the proposed methods are able to compute relevant entity recommendations outperforming a number of baselines. Finally, we perform an analysis on a cross-domain scenario using different entity types, and conclude that even if knowing the right target domain is important for providing effective recommendations, some inter-domain user interactions are helpful for the task at hand.",2016,Conference on Information and Knowledge Management,web search query;recommender system;world wide web;information retrieval;data mining;database;machine learning;computer science;
Incorporating Risk-Sensitiveness into Feature Selection for Learning to Rank,Daniel Xavier De Sousa (Universidade Federal de Minas Gerais);Sérgio Daniel Canuto (Universidade Federal de Minas Gerais);Thierson Couto Rosa (Universidade Federal de Goiás);Wellington Santos Martins (Universidade Federal de Goiás);Marcos André Gonçalves (Universidade Federal de Minas Gerais);,"2475654474,2027273974,2481158883,2140379218,2115586749","Learning to Rank (L2R) is currently an essential task in basically all types of information systems given the huge and ever increasing amount of data made available. While many solutions have been proposed to improve L2R functions, relatively little attention has been paid to the task of improving the quality of the feature space. L2R strategies usually rely on dense feature representations, which contain noisy or redundant features, increasing the cost of the learning process, without any benefits. Although feature selection (FS) strategies can be applied to reduce dimensionality and noise, side effects of such procedures have been neglected, such as the risk of getting very poor predictions in a few (but important) queries. In this paper we propose multi-objective FS strategies that optimize both aspects at the same time: ranking performance and risk-sensitive evaluation. For this, we approximate the Pareto-optimal set for multi-objective optimization in a new and original application to L2R. Our contributions include novel FS methods for L2R which optimize multiple, potentially conflicting, criteria. In particular, one of the objectives (risk-sensitive evaluation) has never been optimized in the context of FS for L2R before. Our experimental evaluation shows that our proposed methods select features that are more effective (ranking performance) and low-risk than those selected by other state-of-the-art FS methods.",2016,Conference on Information and Knowledge Management,learning to rank;feature selection;data mining;pattern recognition;machine learning;computer science;
"LDA Revisited: Entropy, Prior and Convergence",Jianwei Zhang (Soochow University);Jia Zeng (Huawei);Mingxuan Yuan (Huawei);Weixiong Rao (Tongji University);Jianfeng Yan (Soochow University);,"2699765691,2692706699,2305706855,2666993148,2667538916","Inference algorithms of latent Dirichlet allocation (LDA), either for small or big data, can be broadly categorized into expectation-maximization (EM), variational Bayes (VB) and collapsed Gibbs sampling (GS). Looking for a unified understanding of these different inference algorithms is currently an important open problem. In this paper, we revisit these three algorithms from the entropy perspective, and show that EM can achieve the best predictive perplexity (a standard performance metric for LDA accuracy) by minimizing directly the cross entropy between the observed word distribution and LDA's predictive distribution. Moreover, EM can change the entropy of LDA's predictive distribution through tuning priors of LDA, such as the Dirichlet hyperparameters and the number of topics, to minimize the cross entropy with the observed word distribution. Finally, we propose the adaptive EM (AEM) algorithm that converges faster and more accurate than the current state-of-the-art SparseLDA [20] and AliasLDA [12] from small to big data and LDA models. The core idea is that the number of active topics, measured by the residuals between E-steps at successive iterations, decreases significantly, leading to the amortized σ(1) time complexity in terms of the number of topics. The open source code of AEM is available at GitHub.",2016,Conference on Information and Knowledge Management,latent dirichlet allocation;entropy;convergence;big data;data mining;pattern recognition;machine learning;statistics;computer science;
A Personal Perspective and Retrospective on Web Search Technology,Andrei Z. Broder (Google);,2720205684,"This talk is a review of some Web research and predictions that I co-authored over the last two decades: both what turned out gratifyingly right and what turned out embarrassingly wrong. Topics will include near-duplicates, the Web graph, query intent, inverted indices efficiency, and others. While this seems a completely idiosyncratic collection there are in fact concealed connections that offer good clues to the big question: what will happen next?",2016,Conference on Information and Knowledge Management,data science;world wide web;data mining;database;artificial intelligence;computer science;
Large-Scale Analysis of Viewing Behavior: Towards Measuring Satisfaction with Mobile Proactive Systems,Qi Guo (Google);Yang Song (Google);,"2571368294,2674437208","Recently, proactive systems such as Google Now and Microsoft Cortana have become increasingly popular in reforming the way users access information on mobile devices. In these systems, relevant content is presented to users based on their context without a query in the form of information cards that do not require a click to satisfy the users. As a result, prior approaches based on clicks cannot provide reliable measurements of user satisfaction with such systems. It is also unclear how much of the previous findings regarding good abandonment with reactive Web searches can be applied to these proactive systems due to the intrinsic difference in user intent, the greater variety of content types and their presentations. In this paper, we present the first large-scale analysis of viewing behavior based on the viewport (the visible fraction of a Web page) of the mobile devices, towards measuring user satisfaction with the information cards of the mobile proactive systems. In particular, we identified and analyzed a variety of factors that may influence the viewing behavior, including biases from ranking positions, the types and attributes of the information cards, and the touch interactions with the mobile devices. We show that by modeling the various factors we can better measure user satisfaction with the mobile proactive systems, enabling stronger statistical power in large-scale online A/B testing.",2016,Conference on Information and Knowledge Management,computer user satisfaction;mobile search;internet privacy;multimedia;world wide web;data mining;database;computer science;
Adaptive Evolutionary Filtering in Real-Time Twitter Stream,Feifan Fan (Peking University);Yansong Feng (Peking University);Lili Yao (Peking University);Dongyan Zhao (Peking University);,"2156639595,2142380681,2657546595,2156639542","With the explosive growth of microblogging service, Twitter has become a leading platform consisting of real-time world wide information. Users tend to explore breaking news or general topics in Twitter according to their interests. However, the explosive amount of incoming tweets leads users to information overload. Therefore, filtering interesting tweets based on users' interest profiles from real-time stream can be helpful for users to easily access the relevant and key information hidden among the tweets. On the other hand, real-time twitter stream contains enormous amount of noisy and redundant tweets. Hence, the filtering process should consider previously pushed interesting tweets to provide users with diverse tweets. What's more, different from traditional document summarization methods which focus on static dataset, the twitter stream is dynamic, fast-arriving and large-scale, which means we have to decide whether to filter the coming tweet for users from the real-time stream as early as possible. In this paper, we propose a novel adaptive evolutionary filtering framework to push interesting tweets for users from real-time twitter stream. First, we propose an adaptive evolutionary filtering algorithm to filter interesting tweets from the twitter stream with respect to user interest profiles. And then we utilize the maximal marginal relevance model in fixed time window to estimate the relevance and diversity of potential tweets. Besides, to overcome the enormous number of redundant tweets and characterize the diversity of potential tweets, we propose a hierarchical tweet representation learning model (HTM) to learn the tweet representations dynamically over time. Experiments on large scale real-time twitter stream datasets demonstrate the efficiency and effectiveness of our framework.",2016,Conference on Information and Knowledge Management,timeline;internet privacy;world wide web;data mining;computer science;
Online Food Recipe Title Semantics: Combining Nutrient Facts and Topics,Tomasz Kusmierczyk (Norwegian University of Science and Technology);Kjetil Nørvåg (Norwegian University of Science and Technology);,"189438138,202808005","Dietary pattern analysis is an important research area, and recently the availability of rich resources in food-focused social networks has enabled new opportunities in that field. However, there is a little understanding of how online textual content is related to actual health factors, e.g., nutritional values. To contribute to this lack of knowledge, we present a novel approach to mine and model online food content by combining text topics with related nutrient facts. Our empirical analysis reveals a strong correlation between them and our experiments show the extent to which it is possible to predict nutrient facts from meal name.",2016,Conference on Information and Knowledge Management,data science;multimedia;data mining;computer science;
GiraphAsync: Supporting Online and Offline Graph Processing via Adaptive Asynchronous Message Processing,Yuqiong Liu (Peking University);Chang Zhou (Peking University);Jun Gao (Peking University);Zhiguo Fan (Alibaba Group);,"2538590606,2714489094,2671498316,2568442928","It is highly desired for existing distributed graph processing systems to support both offline analytics and online queries adaptively. Existing offline graph analytics systems are mostly based on synchronous model. Although achieving high throughput, they suffer relatively high latency in answering simple queries due to synchronization overhead and slow convergence. On the other hand, online graph query systems adopting asynchronous model can response at any time, while incur overwhelmed messages and network packets, making them unable to meet the high throughput demand of offline analytics. In this work, we propose an adaptive asynchronous message processing (AAMP) method, which improves the efficiency of network communication while maintains low latency, to efficiently support offline analytics and online queries in one graph processing framework. We then design GiraphAsync, an implementation of AAMP on top of Apache Giraph, and evaluate it using several representative offline analytics and online queries on large graph datasets. Experimental results show that GiraphAsync gains an up to 10X improvement over synchronous model systems for graph analytics, while performs as well as specialized systems for online graph queries.",2016,Conference on Information and Knowledge Management,theoretical computer science;world wide web;distributed computing;database;real time computing;computer science;
Compression-Based Selective Sampling for Learning to Rank,Rodrigo M. Silva (Universidade Federal de Minas Gerais);Guilherme de Castro Mendes Gomes (Universidade Federal de Minas Gerais);Mário S. Alvim (Universidade Federal de Minas Gerais);Marcos André Gonçalves (Universidade Federal de Minas Gerais);,"2308259767,2503112593,2563512265,2115586749","Learning to rank (L2R) algorithms use a labeled training set to generate a ranking model that can be later used to rank new query results. These training sets are very costly and laborious to produce, requiring human annotators to assess the relevance or order of the documents in relation to a query. Active learning (AL) algorithms are able to reduce the labeling effort by actively sampling an unlabeled set and choosing data instances that maximize the effectiveness of a learning function. But AL methods require constant supervision, as documents have to be labeled at each round of the process. In this paper, we propose that certain characteristics of unlabeled L2R datasets allow for an unsupervised, compression-based selection process to be used to create small and yet highly informative and effective initial sets that can later be labeled and used to bootstrap a L2R system. We implement our ideas through a novel unsupervised selective sampling method, which we call Cover, that has several advantages over AL methods tailored to L2R. First, it does not need an initial labeled seed set and can select documents from scratch. Second, selected documents do not need to be labeled as the iterations of the method progress since it is unsupervised (i.e., no learning model needs to be updated). Thus, an arbitrarily sized training set can be selected without human intervention depending on the available budget. Third, the method is efficient and can be run on unlabeled collections containing millions of query-document instances. We run various experiments with two important L2R benchmarking collections to show that the proposed method allows for the creation of small, yet very effective training sets. It achieves full training-like performance with less than 10% of the original sets selected, outperforming the baselines in both effectiveness and scalability.",2016,Conference on Information and Knowledge Management,active learning;compression;learning to rank;semi supervised learning;unsupervised learning;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
GStreamMiner: A GPU-accelerated Data Stream Mining Framework,Chandima HewaNadungodage (Indiana University – Purdue University Indianapolis);Yuni Xia (Indiana University – Purdue University Indianapolis);John Jaehwan Lee (Indiana University – Purdue University Indianapolis);,"2491573301,2334154954,2294192703","Due to the continuous, unbounded, and dynamic characteristics of the streaming data, mining data streams becomes a very challenging task. When analyzing online data streams, it is necessary to produce accurate results in a very short amount of time. The parallel processing power of Graphics Processing Units (GPUs) can be used to accelerate the processing and produce results in a timely manner. In this paper, we present GStreamMiner, a GPU-accelerated data stream mining framework and demonstrate its application using outlier detection over continuous streaming data as a case study. The demo software provides a visual interface which is continuously get updated with new results as the data stream progresses. It also facilitates the users to compare the performance of the GPU and CPU versions of the outlier detection algorithm.",2016,Conference on Information and Knowledge Management,data stream clustering;data stream mining;data mining;database;real time computing;machine learning;computer science;
CGMOS: Certainty Guided Minority OverSampling,Xi Zhang (Illinois Institute of Technology);Di Ma (Illinois Institute of Technology);Lin Gan (Illinois Institute of Technology);Shanshan Jiang (Illinois Institute of Technology);Gady Agam (Illinois Institute of Technology);,"2579590718,2049181642,2181311955,2494896903,1991374343","Handling imbalanced datasets is a challenging problem that if not treated correctly results in reduced classification performance. Imbalanced datasets are commonly handled using minority oversampling, whereas the SMOTE algorithm is a successful oversampling algorithm with numerous extensions. SMOTE extensions do not have a theoretical guarantee during training to work better than SMOTE and in many instances their performance is data dependent. In this paper we propose a novel extension to the SMOTE algorithm with a theoretical guarantee for improved classification performance. The proposed approach considers the classification performance of both the majority and minority classes. In the proposed approach CGMOS (Certainty Guided Minority OverSampling) new data points are added by considering certainty changes in the dataset. The paper provides a proof that the proposed algorithm is guaranteed to work better than SMOTE for training data. Further, experimental results on 30 real-world datasets show that CGMOS works better than existing algorithms when using 6 different classifiers.",2016,Conference on Information and Knowledge Management,oversampling;synthetic data;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
A Context-aware Collaborative Filtering Approach for Urban Black Holes Detection,Li Jin (Tsinghua University);Zhuonan Feng (Tsinghua University);Ling Feng (Tsinghua University);,"2661467644,2115372578,2130302844","Urban black hole, as a traffic anomaly, has caused lots of catastrophic accidents in many big cities nowadays. Traditional methods only depend on the single source data (e.g., taxi trajectories) to design blackhole detection algorithm from one point of view, which is rather incomplete to describe the regional crowd flow. In this paper, we model the urban black holes in each region of New York City (NYC) at different time intervals with a 3-dimensional tensor by fusing cross-domain data sources. Supplementing the missing entries of the tensor through a context-aware tensor decomposition approach, we leverage the knowledge from geographical features, 311 complaint features and human mobility features to recover the blackhole situation throughout NYC. The information can facilitate local residents and officials' decision making. We evaluate our model with five datasets related to NYC, diagnosing the urban black holes that cannot be identified (or earlier than those detected) by a single dataset. Experimental results demonstrate the advantages beyond four baseline methods.",2016,Conference on Information and Knowledge Management,computer security;data mining;simulation;
PRO: Preference-Aware Recurring Query Optimization,Zhongfang Zhuang (Worcester Polytechnic Institute);Chuan Lei (NEC);Elke A. Rundensteiner (Worcester Polytechnic Institute);Mohamed Y. Eltabakh (Worcester Polytechnic Institute);,"2276855656,2109712595,2709761886,2034638176","While recurring queries over evolving data are the bedrock of the analytical applications, resources demanded to process a large amount of data for each recurring execution can be a fatal bottleneck in cost-sensitive cloud computing environments. It is thus imperative to design a system responsive to users' preferences regarding how resources should be utilized. In this work, we propose PRO, a preference-aware recurring query processing system that optimizes recurring query executions complying with user preferences. First, we show that finding an optimal is an NP-complete problem due to the cost interdependencies between consecutive executions. We propose an execution relation graph (ERG) model that effectively incorporates these dependencies between executions. This model enables us to transform our problem into a well-known graph problem. We then design a graph-based approach (called PRO-OPT) leveraging dynamic programming and pruning techniques with pseudo-polynomial complexity. Our experiments confirm that PRO consistently outperforms state-of-the-art solutions by 9 fold in processing time under a rich variety of circumstances on the Wikipedia datasets.",2016,Conference on Information and Knowledge Management,world wide web;data mining;database;real time computing;machine learning;computer science;
Detecting Promotion Campaigns in Query Auto Completion,Yuli Liu (Tsinghua University);Yiqun Liu (Tsinghua University);Ke Zhou (Yahoo!);Min Zhang (Tsinghua University);Shaoping Ma (Tsinghua University);Yue Yin (Samsung);Hengliang Luo (Samsung);,"2560296559,2111097927,2308026972,2526008467,2109195263,2537799577,2337737746","Query Auto Completion (QAC) aims to provide possible suggestions to Web search users from the moment they start entering a query, which is thought to reduce their physical and cognitive efforts in query formulation. However, the QAC has been misused by malicious users, being transformed into a new form of promotion campaign. These malicious users attack the search engines to replace legitimate auto-completion candidate suggestions with manipulated contents. Through this way, they provide a new malicious advertising service to promote their customers' products or services in QAC. To our best knowledge, we are among the first to investigate this new type of Promotion Campaign in QAC (PCQ). Firstly, we look into the causes of PCQ based on practical commercial search query logs. We found that various queries containing certain promotion intents are submitted multiple times to search engines to promote their rankings in QAC. Secondly, an effective promotion query detection framework is proposed by promotion intent propagation on query-user bipartite graph, which takes into account the behavioral characteristics of promotion campaigns. Finally, we extend the query detection framework to promotion target detection to identify the consistent promotion target which is the inherent goal of the promotion campaign. Large-scale manual annotations on practical data set convey both the effectiveness of our proposed algorithm, and an in-depth understanding of PCQ.",2016,Conference on Information and Knowledge Management,web query classification;query expansion;internet privacy;world wide web;information retrieval;data mining;database;
Efficient Computation of Importance Based Communities in Web-Scale Networks Using a Single Machine,Shu Chen (University of Victoria);Ran Wei (University of Victoria);Diana Popova (University of Victoria);Alex Thomo (University of Victoria);,"2579430419,2534295792,2062753966,83612842","Finding decompositions of a graph into a family of communities is crucial to understanding its underlying structure. Algorithms for finding communities in networks often rely only on structural information and search for cohesive subsets of nodes. In practice however, we would like to find communities that are not only cohesive, but also influential or important. In order to capture such communities, Li, Qin, Yu, and Mao introduced a novel community model called ""k-influential community"" based on the concept of $k$-core, with numerical values representing ""influence"" assigned to the nodes. They formulate the problem of finding the top-r most important communities as finding r connected k-core subgraphs ordered by the lower-bound of their importance. In this paper, our goal is to scale-up the computation of top-r, k-core communities to web-scale graphs of tens of billions of edges. We feature several fast new algorithms for this problem. With our implementations, we show that we can efficiently handle massive networks using a single consumer-level machine within a reasonable amount of time.",2016,Conference on Information and Knowledge Management,theoretical computer science;world wide web;data mining;database;artificial intelligence;machine learning;
Predicting Popularity of Twitter Accounts through the Discovery of Link-Propagating Early Adopters,Daichi Imamori (Kyoto University);Keishi Tajima (Kyoto University);,"2533403732,2172053298","In this paper, we propose a method of ranking recently created Twitter accounts according to their prospective popularity. Early detection of new promising accounts is useful for trend prediction, viral marketing, user recommendation, and so on. New accounts are, however, difficult to evaluate because they have not yet established the reputation they deserve, and we cannot apply existing link-based or other popularity-based account evaluation methods. Our method first finds early adopters, i.e., users who often find new good information sources earlier than others. Our method then regards new accounts followed by good early adopters as promising, even if they do not have many followers now. In order to find good early adopters, we estimate the frequency of link propagation from each account, i.e., how many times the follow links from the account have been copied by its followers. If the frequency is high, the account must be a good early adopter who often find good information sources earlier than its followers. We develop a method of inferring which links are created by copying which links. One important advantage of our method is that our method only uses information that can be easily obtained only by crawling neighbors of the target accounts in the current Twitter graph. We evaluated our method by an experiment on Twitter data. We chose then-new accounts from an old snapshot of Twitter, compute their ranking by our method, and compare it with the ranking based on the number of followers the accounts currently have. The result shows that our method produces better rankings than various baseline methods, especially for very new accounts that have only a few followers.",2016,Conference on Information and Knowledge Management,power graph analysis;microblogging;internet privacy;combinatorics;world wide web;data mining;machine learning;computer science;
A Model-Free Approach to Infer the Diffusion Network from Event Cascade,Yu Rong;Qiankun Zhu;Hong Cheng;,"2647636356,2543896483,2716132289","Information diffusion through various types of networks, such as social networks and media networks, is a very common phenomenon on the Internet nowadays. In many scenarios, we can track only the time when the information reaches a node. However, the source infecting this node is usually unobserved. Inferring the underlying diffusion network based on cascade data (observed sequence of infected nodes with timestamp) without additional information is an essential and challenging task in information diffusion. Many studies have focused on constructing complex models to infer the underlying diffusion network in a parametric way. However, the diffusion process in the real world is very complex and hard to be captured by a parametric model. Even worse, inferring the parameters of a complex model is impractical under a large data volume. Different from previous works focusing on building models, we propose to interpret the diffusion process from the cascade data directly in a non-parametric way, and design a novel and efficient algorithm named Non-Parametric Distributional Clustering (NPDC). Our algorithm infers the diffusion network according to the statistical difference of the infection time intervals between nodes connected with diffusion edges versus those with no diffusion edges. NPDC is a model-free approach since we do not define any transmission models between nodes in advance. We conduct experiments on synthetic data sets and two large real-world data sets with millions of cascades. Our algorithm achieves substantially higher accuracy of network inference and is orders of magnitude faster compared with the state-of-the-art solutions.",2016,Conference on Information and Knowledge Management,nonparametric statistics;cluster analysis;data mining;artificial intelligence;machine learning;statistics;computer science;
RAP: Scalable RPCA for Low-rank Matrix Recovery,Chong Peng (Southern Illinois University Carbondale);Zhao Kang (Southern Illinois University Carbondale);Ming Yang (Southern Illinois University Carbondale);Qiang Cheng (Southern Illinois University Carbondale);,"2104710458,2162933773,2501691373,2102340508","Recovering low-rank matrices is a problem common in many applications of data mining and machine learning, such as matrix completion and image denoising. Robust Principal Component Analysis (RPCA) has emerged for handling such kinds of problems; however, the existing RPCA approaches are usually computationally expensive, due to the fact that they need to obtain the singular value decomposition (SVD) of large matrices. In this paper, we propose a novel RPCA approach that eliminates the need for SVD of large matrices. Scalable algorithms are designed for several variants of our approach, which are crucial for real world applications on large scale data. Extensive experimental results confirm the effectiveness of our approach both quantitatively and visually.",2016,Conference on Information and Knowledge Management,anomaly detection;pattern recognition;machine learning;mathematical optimization;computer science;
Link Prediction in Heterogeneous Social Networks,Sumit Negi (Indian Institute of Technology Delhi);Santanu Chaudhury (Indian Institute of Technology Delhi);,"2560532887,2133550925","A heterogeneous social network is characterized by multiple link types which makes the task of link prediction in such networks more involved. In the last few years collective link prediction methods have been proposed for the problem of link prediction in heterogeneous networks. These methods capture the correlation between different types of links and utilize this information in the link prediction task. In this paper we pose the problem of link prediction in heterogeneous networks as a multi-task, metric learning (MTML) problem. For each link-type (relation) we learn a corresponding distance measure, which utilizes both network and node features. These link-type specific distance measures are learnt in a coupled fashion by employing the Multi-Task Structure Preserving Metric Learning (MT-SPML) setup. We further extend the MT-SPML method to account for task correlations, robustness to non-informative features and non-stationary degree distribution across networks. Experiments on the Flickr and DBLP network demonstrates the effectiveness of our proposed approach vis-a-vis competitive baselines.",2016,Conference on Information and Knowledge Management,heterogeneous network;data mining;artificial intelligence;machine learning;computer science;
Reuters Tracer: A Large Scale System of Detecting & Verifying Real-Time News Events from Twitter,Xiaomo Liu (Thomson Reuters);Quanzhi Li (Thomson Reuters);Armineh Nourbakhsh (Thomson Reuters);Rui Fang (Thomson Reuters);Merine Thomas (Thomson Reuters);Kajsa Anderson (Thomson Reuters);Russ Kociuba (Thomson Reuters);Mark Vedder (Thomson Reuters);Steven Pomerville (Thomson Reuters);Ramdev Wudali (Thomson Reuters);Robert Martin (Thomson Reuters);John Duprey (Thomson Reuters);Arun Vachher (Thomson Reuters);William Keenan (Thomson Reuters);Sameena Shah (Thomson Reuters);,"2490351473,2261932186,2232518488,2427571942,2302122939,2534786805,2537325736,2537331614,2399762215,2285868361,2486007319,2242360227,2282673536,2166626089,2114545764","News professionals are facing the challenge of discovering news from more diverse and unreliable information in the age of social media. More and more news events break on social media first and are picked up by news media subsequently. The recent Brussels attack is such an example. At Reuters, a global news agency, we have observed the necessity of providing a more effective tool that can help our journalists to quickly discover news on social media, verify them and then inform the public. In this paper, we describe Reuters Tracer , a system for sifting through all noise to detect news events on Twitter and assessing their veracity. We disclose the architecture of our system and discuss the various design strategies that facilitate the implementation of machine learning models for noise filtering and event detection. These techniques have been implemented at large scale and successfully discovered breaking news faster than traditional journalism",2016,Conference on Information and Knowledge Management,filter;internet privacy;world wide web;data mining;computer science;
Explaining Sentiment Spikes in Twitter,Anastasia Giachanou (University of Lugano);Ida Mele (University of Lugano);Fabio Crestani (University of Lugano);,"314978886,1999225486,2303795236","Tracking public opinion in social media provides important information to enterprises or governments during a decision making process. In addition, identifying and extracting the causes of sentiment spikes allows interested parties to redesign and adjust strategies with the aim to attract more positive sentiments. In this paper, we focus on the problem of tracking sentiment towards different entities, detecting sentiment spikes and on the problem of extracting and ranking the causes of a sentiment spike. Our approach combines LDA topic model with Relative Entropy. The former is used for extracting the topics discussed in the time window before the sentiment spike. The latter allows to rank the detected topics based on their contribution to the sentiment spike.",2016,Conference on Information and Knowledge Management,sentiment analysis;data science;world wide web;data mining;
Error Link Detection and Correction in Wikipedia,Chengyu Wang (East China Normal University);Rong Zhang (East China Normal University);Xiaofeng He (East China Normal University);Aoying Zhou (East China Normal University);,"2655171548,2423758776,2005481251,2111470091","The hyperlink structure of Wikipedia forms a rich semantic network connecting entities and concepts, enabling it as a valuable source for knowledge harvesting. Wikipedia, as crowd-sourced data, faces various data quality issues which significantly impacts knowledge systems depending on it as the information source. One such issue occurs when an anchor text in a Wikipage links to a wrong Wikipage, causing the error link problem. While much of previous work has focused on leveraging Wikipedia for entity linking, little has been done to detect error links. In this paper, we address the error link problem, and propose algorithms to detect and correct error links. We introduce an efficient method to generate candidate error links based on iterative ranking in an Anchor Text Semantic Network . This greatly reduces the problem space. A more accurate pairwise learning model was used to detect error links from the reduced candidate error link set, while suggesting correct links in the same time. This approach is effective when data sparsity is a challenging issue. The experiments on both English and Chinese Wikipedia illustrate the effectiveness of our approach. We also provide a preliminary analysis on possible causes of error links in English and Chinese Wikipedia.",2016,Conference on Information and Knowledge Management,brand;world wide web;information retrieval;data mining;database;machine learning;computer science;
Efficient Distributed Regular Path Queries on RDF Graphs Using Partial Evaluation,Xin Wang (Tianjin University);Junhu Wang (Griffith University);Xiaowang Zhang (Tianjin University);,"2618815364,2115281420,2097808557","We propose an efficient distributed method for answering regular path queries (RPQs) on large-scale RDF graphs using partial evaluation. In local computation, we devise a dynamic programming approach to evaluate local and partial answers of an RPQ on each computing site in parallel. In the assembly phase, an automata-based algorithm is proposed to assemble the partial answers of the RPQ into the final results. The experiments on benchmark RDF graphs show that our method outperforms the state-of-the-art message passing methods by up to an order of magnitude.",2016,Conference on Information and Knowledge Management,blank node;partial evaluation;theoretical computer science;distributed computing;data mining;database;programming language;computer science;
A Self-Organizing Map for Identifying InfluentialCommunities in Speech-based Networks,Sameen Mansha (Information Technology University);Faisal Kamiran (Information Technology University);Asim Karim (Lahore University of Management Sciences);Aizaz Anwar (Information Technology University);,"2045047531,2072234693,2206695298,2530141259","Low-literate people are unable to use many mainstream social networks due to their text-based interfaces even though they constitute a major portion of the world population. Specialized speech-based networks (SBNs) are more accessible to low-literate users through their simple speech-based interfaces. While SBNs have the potential for providing value-adding services to a large segment of society they have been hampered by the need to operate in low-income segments on low budgets. The knowledge of influential users and communities in such networks can help in optimizing their operations. In this paper, we present a self-organizing map (SOM) for discovering and visualizing influential communities of users in SBNs. We demonstrate how a friendship graph is formed from call data records and present a method for estimating influences between users. Subsequently, we develop a SOM to cluster users based on their influence, thus identifying community-level influences and their roles in information propagation. We test our approach on Polly, a SBN developed for job ads dissemination among low-literate users. For comparison, we identify influential users with the benchmark greedy algorithm and relate them to the discovered communities. The results show that influential users are concentrated in influential communities and community-level information propagation provides a ready summary of influential users.",2016,Conference on Information and Knowledge Management,self organizing map;multimedia;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Plackett-Luce Regression Mixture Model for Heterogeneous Rankings,Maksim Tkachenko (Singapore Management University);Hady Wirawan Lauw (Singapore Management University);,"1974642809,2024254804","Learning to rank is an important problem in many scenarios, such as information retrieval, natural language processing, recommender systems, etc. The objective is to learn a function that ranks a number of instances based on their features. In the vast majority of the learning to rank literature, there is an implicit assumption that the population of ranking instances are homogeneous, and thus can be modeled by a single central ranking function. In this work, we are concerned with learning to rank for a heterogeneous population, which may consist of a number of sub-populations, each of which may rank objects differently. Because these sub-populations are not known in advance, and are effectively latent, the problem turns into simultaneously learning both a set of ranking functions, as well as the latent assignment of instances to functions. To address this problem in a joint manner, we develop a probabilistic graphical model called Plackett-Luce Regression Mixture or PLRM model, and describe its inference via Expectation-Maximization algorithm. Comprehensive experiments on publicly-available real-life datasets showcase the effectiveness of PLRM, as opposed to a pipelined approach of clustering followed by learning to rank, as well as approaches that assume a single ranking function for a heterogeneous population.",2016,Conference on Information and Knowledge Management,rank;ranking svm;graphical model;mixture model;learning to rank;data mining;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Model-Based Oversampling for Imbalanced Sequence Classification,Zhichen Gong (University of Science and Technology of China);Huanhuan Chen (University of Science and Technology of China);,"2535590666,2162722686","Sequence classification is critical in the data mining communities. It becomes more challenging when the class distribution is imbalanced, which occurs in many real-world applications. Oversampling algorithms try to re-balance the skewed class by generating synthetic data for minority classes, but most of existing oversampling approaches could not consider the temporal structure of sequences, or handle multivariate and long sequences. To address these problems, this paper proposes a novel oversampling algorithm based on the 'generative' models of sequences. In particular, a recurrent neural network was employed to learn the generative mechanics for sequences as representations for the corresponding sequences. These generative models are then utilized to form a kernel to capture the similarity between different sequences. Finally, oversampling is performed in the kernel feature space to generate synthetic data. The proposed approach can handle highly imbalanced sequential data and is robust to noise. The competitiveness of the proposed approach is demonstrated by experiments on both synthetic data and benchmark data, including univariate and multivariate sequences.",2016,Conference on Information and Knowledge Management,oversampling;data mining;pattern recognition;machine learning;computer science;
Understanding Stability of Noisy Networks through Centrality Measures and Local Connections,Vladimir Ufimtsev (University of Nebraska Omaha);Soumya Sarkar (Indian Institute of Technology Kharagpur);Animesh Mukherjee (Indian Institute of Technology Kharagpur);Sanjukta Bhowmick (University of Nebraska Omaha);,"2084851264,2559023834,2134540012,2137502878","Networks created from real-world data contain some inaccuracies or noise, manifested as small changes in the network structure. An important question is whether these small changes can signficantly affect the analysis results. In this paper, we study the effect of noise in changing ranks of the high centrality vertices . We compare, using the Jaccard Index (JI), how many of the top-k high centrality nodes from the original network are also part of the top- k ranked nodes from the noisy network. We deem a network as stable if the JI value is high. We observe two features that affect the stability. First, the stability is dependent on the number of top-ranked vertices considered . When the vertices are ordered according to their centrality values, they group into clusters. Perturbations to the network can change the relative ranking within the cluster, but vertices rarely move from one cluster to another. Second, the stability is dependent on the local connections of the high ranking vertices . The network is highly stable if the high ranking vertices are connected to each other. Our findings show that the stability of a network is affected by the local properties of high centrality vertices, rather than the global properties of the entire network. Based on these local properties we can identify the stability of a network, without explicitly applying a noise model.",2016,Conference on Information and Knowledge Management,alpha centrality;random walk closeness centrality;katz centrality;centrality;betweenness centrality;network theory;noise;stability;combinatorics;machine learning;statistics;mathematics;
Supervised Feature Selection by Preserving Class Correlation,Jun Wang (Nankai University);Jinmao Wei (Nankai University);Zhenglu Yang (Nankai University);,"2661950261,2648431935,2628251071","Feature selection is an effective technique for dimension reduction, which assesses the importance of features and constructs an optimal feature subspace suitable for recognition task. Two recognition scenarios, i.e., single-label learning and multi-label learning, pose different challenges for feature selection. For the single-label task, how to accurately measure and reduce feature redundancy is crucial. For the multi-label task, how to effectively exploit class correlation information during selection is critical. However, both issues cannot be simultaneously resolved by any existing selection methods. In this paper, we propose effective supervised feature selection techniques to address the problems. The original class correlation information in the reduced feature space is preserved, and meanwhile the feature redundancy for classification is alleviated. To the best of our knowledge, this study is the first attempt to accomplish both recognition tasks in a unified framework. Comprehensive experimental evaluations on artificial, single-label, and multi-label data sets demonstrate the effectiveness of the new approach.",2016,Conference on Information and Knowledge Management,minimum redundancy feature selection;multi task learning;feature;dimensionality reduction;feature vector;feature;feature extraction;k nearest neighbors algorithm;feature learning;feature selection;data mining;pattern recognition;machine learning;computer science;
"PEQ: An Explainable, Specification-based, Aspect-oriented Product Comparator for E-commerce",Abhishek Sikchi (Indian Institute of Technology Kharagpur);Pawan Goyal (Indian Institute of Technology Kharagpur);Samik Datta;,"2534629711,2556932677,2642686320","While purchasing a product, consumers often rely on specifications as well as online reviews of the product for decision-making. While comparing, one often has in mind a specific aspect or a set of aspects which are of interest to them. Previous work has used comparative sentences, where two entities are compared directly in a single sentence by the review author, towards the comparison task. In this paper, we extend the existing model by incorporating the feature specifications of the products, which are easily available, and learn the importance to be associated with each of them. To test the validity of these product ranking measures, we comprehensively test it on a digital camera dataset from Amazon.com and the results show good empirical outperformance over the state-of-the-art baselines.",2016,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Optimizing Update Frequencies for Decaying Information,Simon Razniewski (Free University of Bozen-Bolzano);,314715041,"Many kinds of information, e.g., addresses, crawls of webpages, or academic affiliations, are prone to becoming outdated over time. Therefore, if data quality shall be maintained over time, often periodical refreshing is done. As refreshing data usually has a cost, for instance computation time, network bandwidth or human work time, a problem is to find the right update frequency depending on the benefit gained from the information and on the speed with which the information is expected to get outdated. This is especially important since often entities exhibit a different speed of getting outdated, e.g., addresses of students change more frequently than addresses of retirees, or news portals change more frequently than homepages. Consequently, there is no uniform best update frequency for all entities. Previous work on data freshness has investigated how to best distribute a fixed number of updates among entities, in order to maximize average freshness. For businesses that are able to adapt their resources, another question is to determine the number of updates that optimizes the income derived from the data. In this paper we present a model for describing the relationship between update frequency and income derived from data, present solutions for calculating the optimal update frequency for two common classes of functions for describing decay behaviour, and validate the benefits of our framework.",2016,Conference on Information and Knowledge Management,data quality;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Axiomatic Result Re-Ranking,Matthias Hagen (Weimar Institute);Michael Völske (Weimar Institute);Steve Göring (Weimar Institute);Benno Stein (Weimar Institute);,"2097926291,300255710,2533378553,2134393620","We consider the problem of re-ranking the top- k documents returned by a retrieval system given some search query. This setting is common to learning-to-rank scenarios, and it is often solved with machine learning and feature weighting based on user preferences such as clicks, dwell times, etc. In this paper, we combine the learning-to-rank paradigm with the recent developments on axioms for information retrieval. In particular, we suggest to re-rank the top- k documents of a retrieval system using carefully chosen axiom combinations. In recent years, research on axioms for information retrieval has focused on identifying reasonable constraints that retrieval systems should fulfill. Researchers have analyzed a wide range of standard retrieval models for conformance to the proposed axioms and, at times, suggested certain adjustments to the models. We take up this axiomatic view---but, instead of adjusting the retrieval models themselves, we suggest the following innovation: to adopt the learning-to-rank idea and to re-rank the top- k results directly using promising axiom combinations. This way, we can turn every reasonable basic retrieval model into an axiom-based retrieval model. In large-scale experiments on the ClueWeb corpora, we identify promising axiom combinations for a variety of retrieval models. Our experiments show that for most of these models our axiom-based re-ranking significantly improves the original retrieval performance.",2016,Conference on Information and Knowledge Management,divergence from randomness model;learning to rank;information retrieval;data mining;machine learning;computer science;
Improving Advertisement Recommendation by Enriching User Browser Cookie Attributes,Liang Wang (Yahoo!);Kuang-chih Lee (Yahoo!);Quan Lu (Yahoo!);,"2533912099,2223869048,2685429739","User attributes including online behavior history and demographic information are the keys to decide whether a user is the right audience for an advertisement. When a user visits a website, the website generally plugs a browser cookie string (`bcookie' for short). The bcookie is then used as an identifier to collect the user's online behavior, as well as the joint key to link user profile attributes, such as demographic information and browsing history. However, the same users can have different bcookies across different browsers and devices. Moreover, bcookies can expire after some period, be cleared by browsers or users. This situation of bcookie discounting typically introduces both performance and delivery problems in online advertising since advertisers are hard to find the most receptive audiences based on the user profile information. In this paper, we try to tackle this problem by using an `assistant identifier' to find the linkage between different bcookies. For most of the Internet company, in addition to the bcookie information, there are always other identifiers such as IP address, user agent, OS type and version, etc. , stored in the serving log data. Therefore, we propose an unified framework to link different bcookies from the same users according to those assistant identifiers. Specifically, our proposed method first constructs a bipartite graph with linkages between the assistant identifiers and the bcookies. Next all attributes associated with each bcookie are propagated along the graph using the state-of-the-art random walk model. Offline comparative experimental studies are conducted to confirm that by enriching the bcookie attributes we can recover 20% more online users whose bcookie information is lost, which is greatly helpful to delivery more budget spending with a little loss in precision of predicting converted users. On-product evaluation further confirms the effectiveness of the proposed method.",2016,Conference on Information and Knowledge Management,unique user;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Quantifying Query Ambiguity with Topic Distributions,Yuki Yano (Yahoo!);Yukihiro Tagami (Yahoo!);Akira Tajima (Yahoo!);,"2559655806,2112635383,2159701148","Query ambiguity is a useful metric for search engines to understand users' intents. Existing methods quantify query ambiguity by calculating an entropy of clicks. These methods assign each click to a one-hot vector corresponding to some mutually exclusive groups. However, they cannot incorporate non-obvious structures such as similarity among documents. In this paper, we propose a new approach for quantifying query ambiguity using topic distributions. We show that it is a natural extension of an existing entropy-based method. Further, we use our approach to achieve topic-based extensions of major existing entropy-based methods. Through an evaluation using e-commerce search logs combined with human judgments, our approach successfully extended existing entropy-based methods and improved the quality of query ambiguity measurements.",2016,Conference on Information and Knowledge Management,web query classification;query expansion;query optimization;information retrieval;data mining;pattern recognition;
Anomalies in the Peer-review System: A Case Study of the Journal of High Energy Physics,Sandipan Sikdar (Indian Institute of Technology Kharagpur);Matteo Marsili (International Centre for Theoretical Physics);Niloy Ganguly (Indian Institute of Technology Kharagpur);Animesh Mukherjee (Indian Institute of Technology Kharagpur);,"2126195243,2103281278,2097625090,2134540012","Peer-review system has long been relied upon for bringing quality research to the notice of the scientific community and also preventing flawed research from entering into the literature. The need for the peer-review system has often been debated as in numerous cases it has failed in its task and in most of these cases editors and the reviewers were thought to be responsible for not being able to correctly judge the quality of the work. This raises a question ""Can the peer-review system be improved?"" Since editors and reviewers are the most important pillars of a reviewing system, we in this work, attempt to address a related question - given the editing/reviewing history of the editors or reviewers ""can we identify the under-performing ones?"", with citations received by the edited/reviewed papers being used as proxy for quantifying performance. We term such reviewers and editors as anomalous and we believe identifying and removing them shall improve the performance of the peer-review system. Using a massive dataset of Journal of High Energy Physics (JHEP) consisting of 29 k papers submitted between 1997 and 2015 with 95 editors and 4035 reviewers and their review history, we identify several factors which point to anomalous behavior of referees and editors. In fact the anomalous editors and reviewers account for 26.8% and 14.5% of the total editors and reviewers respectively and for most of these anomalous reviewers the performance degrades alarmingly over time.",2016,Conference on Information and Knowledge Management,editing;data science;operations research;computer science;
Scalable Spectral k-Support Norm Regularization for Robust Low Rank Subspace Learning,Yiu-ming Cheung (Hong Kong Baptist University);Jian Lou (Hong Kong Baptist University);,"2161219483,2293969661","As a fundamental tool in the fields of data mining and computer vision, robust low rank subspace learning is to recover a low rank matrix under gross corruptions that are often modeled by another sparse matrix. Within this learning, we investigate the spectral k-support norm, a more appealing convex relaxation than the popular nuclear norm, as a low rank penalty in this paper. Despite the better recovering performance, the spectral k-support norm entails the model difficult to be optimized efficiently, which severely limits its scalability from the practical perspective. Therefore, this paper proposes a scalable and efficient algorithm which considers the dual objective of the original problem that can take advantage of the more computational efficient linear oracle of the spectral k-support norm to be evaluated. Further, by studying the sub-gradient of the loss of the dual objective, a line-search strategy is adopted in the algorithm to enable it to adapt to the Holder smoothness. Experiments on various tasks demonstrate the superior prediction performance and computation efficiency of the proposed algorithm.",2016,Conference on Information and Knowledge Management,machine learning;mathematical optimization;
Data Locality in Graph Engines: Implications and Preliminary Experimental Results,Yong-Yeon Jo (Hanyang University);Jiwon Hong (Hanyang University);Myung-Hwan Jang (Hanyang University);Jae-Geun Bang (Hanyang University);Sang-Wook Kim (Hanyang University);,"1979337330,2118697064,2538622392,2303631338,2114304489","The size of graphs has dramatically increased. Graph engines for a single machine have been emerged to process these graphs efficiently. However, existing engines have overlooked a data locality which is an imperative factor to improve the performance of these engines in the previous literature. In this paper, we show the importance of data locality with graph algorithms by running on graph engines based on a single machine.",2016,Conference on Information and Knowledge Management,graph database;theoretical computer science;distributed computing;machine learning;computer science;
Where to Place Your Next Restaurant?: Optimal Restaurant Placement via Leveraging User-Generated Reviews,Feng Wang (Hong Kong Baptist University);Li Chen (Hong Kong Baptist University);Weike Pan (Shenzhen University);,"2674724863,2444561585,2557864391",-,2016,Conference on Information and Knowledge Management,-
Effective Spelling Correction for Eye-based Typing using domain-specific Information about Error Distribution,"Raíza Hanada (Institute of Mathematical Sciences, Chennai);Maria da Graça Campos Pimentel (Institute of Mathematical Sciences, Chennai);Marco Cristo (Federal University of Amazonas);Fernando Anglada Lores (Federal University of Amazonas);","2562511164,2442877379,2567321649,2567033073","Spelling correction methods, widely used and researched, usually assume a low error probability and a small number of errors per word. These assumptions do not hold in very noisy input scenarios such as eye-based typing systems. In particular for eye typing, insertion errors are much more common than in traditional input systems, due to specific sources of noise such as the eye tracker device, particular user behaviors, and intrinsic characteristics of eye movements. The large number of common errors in such a scenario makes the use of traditional approaches unfeasible. Moreover, the lack of a large corpus of errors makes it hard to adopt probabilistic approaches based on information extracted from real world data. We address these problems by combining estimates extracted from general error corpora with domain-specific knowledge about eye-based input. Further, by relaxing restrictions on edit distance specifically related to insertion errors, we propose an algorithm that is able to find dictionary word candidates in an attainable time. We show that our method achieves good results to rank the correct word, given the input stream and similar space and time restrictions, when compared to the state-of-the-art baselines.",2016,Conference on Information and Knowledge Management,noisy channel model;minimum message length;natural language processing;speech recognition;data mining;database;artificial intelligence;machine learning;statistics;algorithm;computer science;
Exploiting Cluster-based Meta Paths for Link Prediction in Signed Networks,Jiangfeng Zeng (Huazhong University of Science and Technology);Ke Zhou (Huazhong University of Science and Technology);Xiao Ma (Huazhong University of Science and Technology);Fuhao Zou (Huazhong University of Science and Technology);Hua Wang (Huazhong University of Science and Technology);,"2478601218,2155787637,2438657433,2690726639,2660519072","Many online social networks can be described by signed networks, where positive links signify friendships, trust and like; while negative links indicate enmity, distrust and dislike. Predicting the sign of the links in these networks has attracted a great deal of attentions in the areas of friendship recommendation and trust relationship prediction. Existing methods for sign prediction tend to rely on path-based features which are somehow limited to the sparsity problem of the network. In order to solve this issue, in this paper, we introduce a novel sign prediction model by exploiting cluster-based meta paths, which can take advantage of both local and global information of the input networks. First, cluster-based meta paths based features are constructed by incorporating the newly generated clusters through hierarchically clustering the input networks. Then, the logistic regression classifier is employed to train the model and predict the hidden signs of the links. Extensive experiments on Epinions and Slashdot datasets demonstrate the efficiency of our proposed method in terms of Accuracy and Coverage.",2016,Conference on Information and Knowledge Management,data mining;artificial intelligence;machine learning;
Attractiveness versus Competition: Towards an Unified Model for User Visitation,Thanh-Nam Doan (Singapore Management University);Ee-Peng Lim (Singapore Management University);,"2225839162,2130308643","Modeling user check-in behavior provides useful insights about venues as well as the users visiting them. These insights can be used in urban planning and recommender system applications. Unlike previous works that focus on modeling distance effect on user's choice of check-in venues, this paper studies check-in behaviors affected by two venue-related factors, namely, area attractiveness and neighborhood competitiveness . The former refers to the ability of an area with multiple venues to collectively attract check-ins from users, while the latter represents the ability of a venue to compete with its neighbors in the same area for check-ins. We first embark on a data science study to ascertain the two factors using two Foursquare datasets gathered from users and venues in Singapore and Jakarta, two major cities in Asia. We then propose the VAN model incorporating user-venue distance, area attractiveness and neighborhood competitiveness factors. The results from real datasets show that VAN model outperforms the various baselines in two tasks: home location prediction and check-in prediction.",2016,Conference on Information and Knowledge Management,simulation;
Tracking Virality and Susceptibility in Social Media,Tuan Anh Hoang;Ee-Peng Lim (Singapore Management University);,"2649630928,2130308643","In social media, the magnitude of information propagation hinges on the virality and susceptibility of users spreading and receiving the information respectively, as well as the virality of information items. These users' and items' behavioral factors evolve dynamically at the same time interacting with one another. Previous works however measure the factors statically and independently in a restricted case: each user has only a single adoption on each item, and/or users' exposure to items are observable. In this work, we investigate the inter-relationship among the factors and users' multiple adoptions on items to propose both new static and temporal models for measuring the factors without requiring user - item exposure. These models are designed to cope with even more realistic propagation scenarios where an item may be propagated many times from the same user(s) to the same other user(s). We further propose an incremental model for measuring the factors in large data streams. We evaluated the proposed models and existing models through extensive experiments on a large Twitter dataset covering information propagation in one month. The experiments show that our proposed models can effectively mine the behavioral factors and outperform the existing ones in a propagation prediction task. The incremental model is shown more than 10 times faster than the temporal model, while still obtains very similar results.",2016,Conference on Information and Knowledge Management,world wide web;data mining;database;machine learning;simulation;computer science;
Skipping Word: A Character-Sequential Representation based Framework for Question Answering,Lingxun Meng;Yan Li;Mengyi Liu;Peng Shu;,"2722234220,2674663181,2674232503,2532811333","Recent works using artificial neural networks based on word distributed representation greatly boost the performance of various natural language learning tasks, especially question answering. Though, they also carry along with some attendant problems, such as corpus selection for embedding learning, dictionary transformation for different learning tasks, etc. In this paper, we propose to straightforwardly model sentences by means of character sequences, and then utilize convolutional neural networks to integrate character embedding learning together with point-wise answer selection training. Compared with deep models pre-trained on word embedding (WE) strategy, our character-sequential representation (CSR) based method shows a much simpler procedure and more stable performance across different benchmarks. Extensive experiments on two benchmark answer selection datasets exhibit the competitive performance compared with the state-of-the-art methods.",2016,Conference on Information and Knowledge Management,deep learning;natural language processing;pattern recognition;artificial intelligence;machine learning;programming language;computer science;
To Click or Not To Click: Automatic Selection of Beautiful Thumbnails from Videos,Yale Song (Yahoo!);Miriam Redi (Yahoo!);Jordi Vallmitjana (Yahoo!);Alejandro Jaimes (Yahoo!);,"2311096721,2264204246,2231612383,2193615068","Thumbnails play such an important role in online videos. As the most representative snapshot, they capture the essence of a video and provide the first impression to the viewers; ultimately, a great thumbnail makes a video more attractive to click and watch. We present an automatic thumbnail selection system that exploits two important characteristics commonly associated with meaningful and attractive thumbnails: high relevance to video content and superior visual aesthetic quality. Our system selects attractive thumbnails by analyzing various visual quality and aesthetic metrics of video frames, and performs a clustering analysis to determine the relevance to video content, thus making the resulting thumbnails more representative of the video. On the task of predicting thumbnails chosen by professional video editors, we demonstrate the effectiveness of our system against six baseline methods, using a real-world dataset of 1,118 videos collected from Yahoo Screen. In addition, we study what makes a frame a good thumbnail by analyzing the statistical relationship between thumbnail frames and non-thumbnail frames in terms of various image quality features. Our study suggests that the selection of a good thumbnail is highly correlated with objective visual quality metrics, such as the frame texture and sharpness, implying the possibility of building an automatic thumbnail selection system based on visual aesthetics.",2016,Conference on Information and Knowledge Management,thumbnail;multimedia;world wide web;computer vision;computer science;
DePP: A System for Detecting Pages to Protect in Wikipedia,Kelsey Suyehira (Boise State University);Francesca Spezzano (Boise State University);,"2610324969,2203751546","Wikipedia is based on the idea that anyone can make edits to the website in order to create reliable and crowd-sourced content. Yet with the cover of internet anonymity, some users make changes to the website that do not align with Wikipedia's intended uses. For this reason, Wikipedia allows for some pages of the website to become protected, where only certain users can make revisions to the page. This allows administrators to protect pages from vandalism, libel, and edit wars. However, with over five million pages on Wikipedia, it is impossible for administrators to monitor all pages and manually enforce page protection. In this paper we consider for the first time the problem of deciding whether a page should be protected or not in a collaborative environment such as Wikipedia. We formulate the problem as a binary classification task and propose a novel set of features to decide which pages to protect based on (i) users page revision behavior and (ii) page categories. We tested our system, called DePP, on a new dataset we built consisting of 13.6K pages (half protected and half unprotected) and 1.9M edits. Experimental results show that DePP reaches 93.24% classification accuracy and significantly improves over baselines.",2016,Conference on Information and Knowledge Management,brand;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Deola: A System for Linking Author Entities in Web Document with DBLP,Yinan Liu (Nankai University);Wei Shen (Nankai University);Xiaojie Yuan (Nankai University);,"2532453420,2667078396,2717062936","In this paper, we present Deola, an Online system for Author Entity Linking with DBLP. Unlike most existing entity linking systems which focus on linking entities with Wikipedia and depend largely on the special features associated with Wikipedia (e.g., Wikipedia articles), Deola links author names appearing in the web document which belongs to the domain of computer science with their corresponding entities existing in the DBLP network. This task is helpful for the enrichment of the DBLP network and the understanding of the domain-specific document. This task is challenging due to name ambiguity and limited knowledge existing in DBLP. Given a fragment of domain-specific web document belonging to the domain of computer science, Deola can return the mapping entity in DBLP for each author name appearing in the input document.",2016,Conference on Information and Knowledge Management,entity linking;world wide web;information retrieval;data mining;computer science;
"Hashtag Recommendation Based on Topic Enhanced Embedding, Tweet Entity Data and Learning to Rank",Quanzhi Li (Thomson Reuters);Sameena Shah (Thomson Reuters);Armineh Nourbakhsh (Thomson Reuters);Xiaomo Liu (Thomson Reuters);Rui Fang (Thomson Reuters);,"2261932186,2114545764,2232518488,2490351473,2427571942","In this paper, we present a new approach of recommending hashtags for tweets. It uses Learning to Rank algorithm to incorporate features built from topic enhanced word embeddings, tweet entity data, hashtag frequency, hashtag temporal data and tweet URL domain information. The experiments using millions of tweets and hashtags show that the proposed approach outperforms the three baseline methods -- the LDA topic, the tf.idf based and the general word embedding approaches.",2016,Conference on Information and Knowledge Management,social media;learning to rank;world wide web;information retrieval;data mining;machine learning;computer science;
A Nonparametric Model for Event Discovery in the Geospatial-Temporal Space,Jinjin Guo (University of Macau);Zhiguo Gong (University of Macau);,"2560753094,2159588081","The availability of geographical and temporal tagged documents enables many location and time based mining tasks. Event discovery is one of such tasks, which is to identify interesting happenings in the geographical and temporal space. In recent years, several techniques have been proposed. However, no existing work has provided a nonparametric algorithm for detecting events in the joint space crossing geographical and temporal dimensions. Furthermore, though some prior works proposed to capture the periodicities of topics in their solutions, some restrictions on the temporal patterns are often placed and they usually ignore the spatial patterns of the topics. To break through such limitations, in this paper we propose a novel nonparametric model to identify events in the geographical and temporal space, where any recurrent patterns of events can be automatically captured. In our approach, parameters are automatically determined by exploiting a Dirichlet Process. To reduce the influence from noisy terms in the detection, we distinguish its event role from its background role using a Bernoulli model in the solution. Experimental results on three real world datasets show the proposed algorithm outperforms previous state-of-the-art approaches.",2016,Conference on Information and Knowledge Management,data mining;machine learning;statistics;
Large-scale Robust Online Matching and Its Application in E-commerce,Rong Jin (Alibaba Group);,2690114951,"This talk will be focused on large-scale matching problem that aims to find the optimal assignment of tasks to different agents under linear constraints. Large-scale matching has found numerous applications in e-commerce. An well known example is budget aware online advertisement. A common practice in online advertisement is to find, for each opportunity or user, the advertisements that fit best with his/her interests. The main shortcoming with this greedy approach is that it did not take into account the budget limits set by advertisers. Our studies, as well as others, have shown that by carefully taking into budget limits of individual advertisers, we could significantly improve the performance of the advertisement system. Despite of rich literature, two important issues are often overlooked in the previous studies of matching/assignment problem. The first issues arises from the fact that most quantities used by optimization are estimated based on historical data and therefore are likely to be inaccurate and unreliable. The second challenge is how to perform online matching as in many e-commerce problems, tasks are created in an online fashion and algorithm has to make assignment decision immediately when every task emerges. We refer to these two issues as challenges of ""robust matching"" and ""online matching"". To address the first challenge, I will introduce two different techniques for robust matching. The first approach is based on the theory of robust optimization that takes into account the uncertainties of estimated quantities when performing optimization. The second approach is based on the theory of two-sided matching whose result only depends on the partial preference of estimated quantities. To deal with the challenge of online matching, I will discuss two online optimization techniques, one based on theory of primal-dual online optimization and one based on minimizing dynamic regret under long term constraints. We verify the effectiveness of all these approaches by applying them to real-world projects developed in Alibaba.",2016,Conference on Information and Knowledge Management,assignment problem;robust optimization;data mining;artificial intelligence;machine learning;mathematical optimization;computer science;
Modeling and Predicting Popularity Dynamics via an Influence-based Self-Excited Hawkes Process,Peng Bao (Beijing Jiaotong University);,2537627875,"Modeling and predicting the popularity dynamics of individual user generated items on online social networks has important implications in a wide range of areas. The challenge of this problem comes from the inequality of the popularity of content and the numerous complex factors. Existing works mainly focus on exploring relevant factors for prediction and fitting the time series of popularity dynamics into certain class of functions, while ignoring the underlying arrival process of attentions. Also, the exogenous effect of user activity variation on the platform has been neglected. In this paper, we propose a probabilistic model using an influence-based self-excited Hawkes process (ISEHP) to characterize the process through which individual microblogs gain their popularity. This model explicitly captures three ingredients: the intrinsic attractiveness of a microblog with exponential time decay, the user-specific triggering effect of each forwardings based on the endogenous influence among users, and the exogenous effect from the platform. We validate the ISEHP model by applying it on Sina Weibo, the most popular microblogging network in China. Experimental results demonstrate that our proposed model consistently outperforms existing prediction models.",2016,Conference on Information and Knowledge Management,microblogging;data science;world wide web;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
Duer: Intelligent Personal Assistant,Haifeng Wang (Baidu);,2653458542,"Intelligent personal assistant is widely recognized as a more natural and efficient way of human-computer interaction, which has attracted extensive interests from both academia and industry. In this talk, I describe Duer, Baidu's intelligent personal assistant. In particular, I would like to focus on the following three features. Firstly, Duer comprehensively understands people's requirements via multiple channels, including not only explicit utterances, but also user models and rich contexts. Duer's user models are learnt from users' interaction history, and the rich contexts consist of temporal and geographical information, as well as the foregoing dialogues. Secondly, Duer meets diverse requirements with a range of instruments, such as chatting, information provision, reminder service, etc. These instruments are implemented based on mining the big data of web pages, applications, and user logs, which are then seamlessly integrated in the dialogue flow. Thirdly, Duer features multi-modal interaction, which allows people to interact with it by means of texts, speech, and images. We believe the above features will enable Duer to become a better and distinguished intelligent assistant for each of you.",2016,Conference on Information and Knowledge Management,human computer interaction;multimedia;world wide web;data mining;database;artificial intelligence;computer science;
Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval,Krisztian Balog (University of Stavanger);Jeffrey Dalton (Google);Antoine Doucet (University of La Rochelle);Yusra Ibrahim (Max Planck Society);,"2100338238,2222608611,2152615820,2114972620","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our great pleasure to welcome you to the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR'15), held at CIKM 2015 in Melbourne, Australia, on October 23, 2015. The amount of structured content published on the Web has been growing rapidly, making it possible to address increasingly complex information access tasks. Recent years have witnessed the emergence of large-scale human-curated knowledge bases as well as a growing array of techniques that identify or extract information automatically from unstructured and semi-structured sources. The ESAIR workshop series aims to advance the general research agenda on the problem of creating and exploiting semantic annotations. The eighth edition of ESAIR, with a renewed group of organizers, sets its focus on applications. We dedicate a special ""Annotations in Action"" track to demonstrations that showcase innovative prototype systems, in addition to the regular research and position paper contributions. The call for papers attracted a total of 19 submissions, out of which 10 were accepted. The final program includes 4 regular, 2 position, and 3 demo papers (one contribution was withdrawn). In addition, the workshop programme features invited talks by Maarten de Rijke (University of Amsterdam) and Matthew Kelcey (Google, Inc.). The workshop is intended to be highly interactive to encourage group discussion and active collaboration among attendees. A final discussion session wraps up the event with the objective to identify and formulate specific action items for future research and development. Following the tradition of earlier ESAIR editions, a social event is organized for further, more informal discussions among workshop participants and other CIKM attendees.",2015,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking,Leif Azzopardi (University of Glasgow);Jeremy Pickens (FX Palo Alto Laboratory);Tetsuya Sakai (Waseda University);Laure Soulier (University of Toulouse);Lynda Tamine (University of Toulouse);,"2163026013,2168651388,2655523027,1986048695,62726460","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our great pleasure to welcome you to the ECol 2015 Workshop on the Evaluation on Collaborative Information Seeking and Retrieval in conjunction with CIKM 2015. These last years and particularly since 2005, CIS and CIR have became emerging topics that have been addressed in several IR and IS conferences including CIKM and SIGIR conferences. While the potential of collaboration has been highlighted with respect to individual settings, other challenges remain and need to be thoroughly explored. Despite most of experimental evaluations have been done with the objective of highlighting the synergic effect of the proposed contributions, there is an important need for the future to discuss about what should be evaluated in terms of collaboration aspects (e.g. cognitive effort, mutual beneficial goal satisfaction, collective relevance...). Moreover, it does not exist standard framework as proposed in ad-hoc information retrieval through the evaluation campaign, as those proposed by TREC, INEX, CLEF... Previous related workshops (e.g. CIR at CIKM 2011, CIS at CSCW 2010-2013 and CIB at GROUP 2009) and special issues on ""Collaborative Information Seeking"" (IPM IEEE, 2014) gathered researchers exploring theoretical frameworks and applications focusing on CIS/CIR. More particularly, these workshops and special issues allowed opening relevant research directions dealing mainly with the modeling of collaborative search behavior, the design of appropriate collaborative search interfaces, and the formalization of retrieval models. However, the major issue of evaluation in CIS/CIR is still underexplored, and the understanding of how well the current evaluation protocols and metrics capture the dimension of collaboration still remains poor. Therefore, the mission of this workshop is to discuss the impact of collaboration features on evaluation as well as evaluation metrics and protocols. Finally, our goal is to open new directions in the CIS/CIR field. Our workshop would both interest and benefit from researchers with a complementary expertise that would cover all the aspects dealing with the evaluation in CIS and CIR. The call for papers attracted submissions from Asia, Australia, Europe, and the United States. We also encourage attendees to attend the keynote. This insightful talk can and will guide us to a better understanding of the future: Social and Collaborative Information Seeking: State of the Union, Chirag Shah (School of Communication and Information, Rutgers University, USA).",2015,Conference on Information and Knowledge Management,operations research;world wide web;information retrieval;data mining;database;artificial intelligence;simulation;computer science;
Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems,Davood Rafiei (University of Alberta);Katsumi Tanaka (Kyoto University);,"272765103,2100196114","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our great pleasure to welcome everyone to the 2015 ACM Workshop on Novel Web Search Interfaces and Systems (NWSearch'15) in Melbourne, Australia. The workshop started out of the need for a venue to discuss the latest research and development in the area of novel Web search interfaces. Given the diversity of the topics involved and the fact that the topic of the workshop overlaps with the areas of information retrieval, user interfaces, Web search and maybe databases, our goal has been to gather researchers and practitioners in those diverse fields to tackle and discuss the problems of common interest as they relate to the topic of this workshop. The call for papers attracted 6 submissions from Australia, China, Czech Republic, Greece, and United States. Each submission was reviewed by at least three members of the program committee. Based on those reviews, four submissions were selected to be included in the program. We are also pleased to have two insightful keynotes by leading researchers in our field. These talks set the tone and directions for possible future work in the area. Still Haven't Found What I'm Looking For: Suggestions for Next Generation Search User Interfaces, Marti Hearst, UC Berkeley Hands and eyes free search, Mark Sanderson, RMIT University",2015,Conference on Information and Knowledge Management,operations research;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP,Il-Yeol Song (Drexel University);Carlos Garcia-Alvarado (University of Houston);Carlos Ordonez (University of Houston);,"2148782644,2016997139,2165938062","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our great pleasure to welcome you to the 18th ACM International Workshop on Data Warehousing and OLAP -- DOLAP 2015. The DOLAP workshop continues its tradition of being the premier forum where both researchers and practitioners in data warehousing and On-Line Analytical Processing (OLAP) share their findings in theoretical foundations, current methodologies, new trends and practical experiences. The mission of the DOLAP workshop is to identify and explore new directions for future research and development, as well as emerging application domains in the areas of data warehousing and OLAP. In recent years, research in these areas have addressed many topics, ranging from conceptual-level and methodological issues, which help designers to build effective decision-support applications, to physical-level and query processing issues, aiming at increasing the performance of these applications in order to deal with vast amounts of data. However, the successful use of data warehousing and OLAP technologies within organizations brings up new requirements and research opportunities, in particular to cope with non-traditional application domains, such as text, biological, imaging, and spatio-temporal applications. The call for papers attracted 31 submissions, from 19 different countries and 6 continents. After careful review and discussion, the program committee accepted 8 full papers and 4 short papers, for a competitive acceptance rate of 26% for full papers and about 39% overall. In addition, some papers received up to four reviews and a summary of the discussion. The accepted papers cover a wide variety of topics, including conceptual modeling, multidimensional design, query processing, energy consumption optimization, join algorithms, metadata management, ETL. Papers are grouped into four sessions covering data warehouse design, database modeling, query processing, and text processing. This year we also have a peer-reviewed invited paper talk from the DBMS community on Big Data Design for revisiting database design in the context of new big data wave. The author also gives a vision of major challenges.",2015,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Proceedings of the 2015 Workshop on Large-Scale and Distributed System for Information Retrieval,Ismail Sengor Altingovde (Middle East Technical University);B. Barla Cambazoglu (Yahoo!);Nicola Tonellotto (Istituto di Scienza e Tecnologie dell'Informazione);,"686977125,2044137649,1923078747","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference The LSDS-IR workshop series aims to attract researchers from the industry and academia to present and discuss problems, ideas, and recent research results related to the performance of large-scale and distributed information retrieval systems. The workshop plays an important role in the information retrieval community as a venue where early work addressing the workshop's topics are discussed and matured. The LSDS-IR'15 workshop continues the efforts of the following workshops organized in the past: P2PIR (collocated with SIGIR'05, CIKM'06, and CIKM'07), HDIR (collocated with SIGIR'08), and LSDS-IR (collocated with SIGIR'07, CIKM'08, SIGIR'09, SIGIR'10, CIKM'11, WSDM'13, WSDM'14). As in the previous years, the workshop provides space for researchers to discuss the scalability and efficiency issues in largescale and distributed information retrieval systems and to define new directions for the field. This year's LSDS-IR workshop has attracted five submissions from Europe (Sweden, Germany, Russia), Asia (India), and South America (Chile). Three of these submissions were accepted for presentation as long papers, and one submission was accepted for presentation as short paper. The workshop program also includes the following two invited talks: ""Large-Scale Real-Time Data Management for Engagement and Monetization"", Simon Jonassen (Cxense), ""Count or Not to Count: Counting Challenges for Big Spatial Data Analytics"", Egemen Tanin (University of Melbourne).",2015,Conference on Information and Knowledge Management,operations research;world wide web;data mining;computer science;
Visualization Oriented Spatiotemporal Urban Data Management and Retrieval,Jonathan Liono (RMIT University);Flora Dilys Salim (RMIT University);Irwan Fario Subastian (RMIT University);,"2223527159,2145588295,2223801459","Urban planners and policy makers often rely on data visualization and spatial data mapping tools to perceive the overall urban trends. The accumulation of historical and real-time urban data from many government and private organizations provides the opportunity for an integrated visual analytic platform. Data management and retrieval for geospatial visualization, correlations, and analysis of multiple data dimensions over a map constitute some of the main challenges when dealing with the heterogeneity of urban data from a variety of sources. In this paper, spatiotemporal aggregation strategies and approaches to accelerate the retrieval of spatial data are presented. The methods are tested on visualizing multivariate urban datasets from two cities in Australia that are aggregated from heterogeneous federated urban data providers. The aggregated spatial or temporal features can be visualized as a choropleth heatmap or extrusion on map. Dynamic spatial window query in our visual analytics tool allows extraction of flat geometry objects optimized through materialized views from a database. Given the robust and scalable orchestration of geometries retrieval, this enables urban planners to perform interactive and dynamic multidimensional visual exploration over a map.",2015,Conference on Information and Knowledge Management,spatiotemporal database;geospatial analysis;data science;information retrieval;computer vision;data mining;computer science;
Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications,Nikolaos Aletras (University College London);Jey Han Lau (King's College London);Timothy Baldwin (University of Melbourne);Mark Stevenson (University of Sheffield);,"93365683,2095936123,2436269535,2131647180","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference The main objective of the workshop is to bring together researchers who are interested in applications of topic models and improving their output. Our goal is to create a broad platform for researchers to share ideas that could improve the usability and interpretation of topic models. We hope this workshop will promote topic model applications in other research areas, making their use more effective. We received a total of 12 paper submissions from around the world, which were subject to a rigorous peer review process by an international program committee. A total of 8 papers were accepted for publication and appear in the workshop proceedings. In keeping with the theme of ""Post-processing and Applications"", there was strong representation of topic model applications among the accepted papers.",2015,Conference on Information and Knowledge Management,operations research;data mining;computer science;
Proceedings of the ACM First International Workshop on Understanding the City with Urban Informatics,Yashar Moshfeghi (University of Glasgow);Iadh Ounis (University of Glasgow);Craig Macdonald (University of Glasgow);Joemon M. Jose (University of Glasgow);Peter Triantafillou (University of Glasgow);Mark Livingston (University of Glasgow);Piyushimita Thakuriah (University of Glasgow);,"92283206,336997814,2148910894,2167481407,318333653,2134037074,2047364655","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our great pleasure to welcome you to the 1st Workshop on Understanding the City with Urban Informatics -- UCUI'15. This workshop aims to provide a multidisciplinary forum which brings together researchers in Big Data (BD), Information Retrieval (IR), Data Mining, and Urban Studies, to explore novel solutions to the numerous theoretical, practical and ethical challenges arising in this context. These include difficulties in collecting city data, creating data management infrastructures, and providing new effective and efficient information access techniques, to as many users as possible in the context of a smart city. Our call has attracted nine papers. The program committee, which is formed of 14 experienced researchers, accepted six papers for presentation in the workshop, i.e. three technical papers, and three position papers. These papers represent the ideas and opinions of the authors who are trying to stimulate debate. In addition, two keynotes helped us frame the problem, and create a common understanding of the challenges. Finally, as part of the workshop, we introduced our newly published datasets relating to the iMCD project of the University of Glasgow's Urban Big Data Centre and participants to our Urban Informatics Data Challenge presented their works.",2015,Conference on Information and Knowledge Management,operations research;world wide web;data mining;computer science;
Proceedings of the 8th Workshop on Ph.D. Workshop in Information and Knowledge Management,Mouna Kacimi (Free University of Bozen-Bolzano);Nicoleta Preda (French Institute for Research in Computer Science and Automation);Maya Ramanath (Indian Institute of Technology Delhi);,"2629444457,1989473477,2061296320","The publication date is one day earlier then the EST date to provide the proceedings to attendees in Australian on the first day of the conference It is our pleasure to host PIKM, the PhD workshop in Information and Knowledge Management, in conjunction with the ACM CIKM 2015 conference in Melbourne, Australia. PIKM has been a mpopular event in CIKM since its inception in 2007. This is the 8th time PIKM is being held and has attracted participants from all over the world. PIKM provides PhD students an opportunity to present their dissertation proposals and/or early doctoral research worldwide and get recognition for their work. It gives them valuable feedback at a relatively early stage from experts in their field in academia and industry. This helps them assess their work with respect to its novelty, technical contributions and real-world applications. Moreover, PIKM also presents a panorama of upcoming doctoral work to established researchers in information and knowledge management. It gives them an idea of the interesting topics that attract fresh doctorates. It could help them tap this potential at an early stage through summer internships, research collaborations and more. There have been 16 submissions to PIKM2015 of which 5 have been accepted as full papers. A significant highlight of PIKM 2015 includes both poster and oral presentations for all accepted papers to increase visibility and interaction. Another distinguished aspect this year is a career development session consisting of a mentoring presentation, from an experienced researcher, which emphasizes the importance of seeking opportunities and developing the needed skills to be successful after the PhD. We encourage participants to attend the keynote and invited talks. These valuable and insightful talks can help PhD students in their career: Keynote: ""Why Researchers are Managers"", Dr. Gerard de Melo (Tsinghua University, China) Invited talk in the career development session: ""Beyond The Thesis: Completing A Successful PhD"", Prof. Justin Zobel (University of Melbourne, Australia) The PIKM 2015 team includes Program Committee members from 11 countries spanning 4 continents. These comprise a good balance of industry and academia. We thank the reviewers for providing quick and useful feedback to the students amidst their busy schedule of work. In recent years, PIKM has been giving a best reviewer award in order to honor the exceptional contributions of a PC member, analogous to the best paper award that provides recognition to outstanding PhD student research. This year, the best paper award goes to Shady Elbassuoni from the American University of Beirut, Lebanon. We sincerely applaud him for his time and effort in providing excellent and detailed reviews. The best paper award will be announced during the PIKM workshop at the CIKM conference. Both these awards consist of ACM certificates.",2015,Conference on Information and Knowledge Management,operations research;world wide web;data mining;artificial intelligence;computer science;
Short Text Similarity with Word Embeddings,Tom Kenter (University of Amsterdam);Maarten de Rijke (University of Amsterdam);,"2060822933,401833296","Determining semantic similarity between texts is important in many tasks in information retrieval such as search, query suggestion, automatic summarization and image finding. Many approaches have been suggested, based on lexical matching, handcrafted patterns, syntactic parse trees, external sources of structured semantic knowledge and distributional semantics. However, lexical features, like string matching, do not capture semantic similarity beyond a trivial level. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains. Lastly, approaches depending on parse trees are restricted to syntactically well-formed texts, typically of one sentence in length. We investigate whether determining short text similarity is possible using only semantic features---where by semantic we mean, pertaining to a representation of meaning---rather than relying on similarity in lexical or syntactic representations. We use word embeddings, vector representations of terms, computed from unlabelled data, that represent terms in a semantic space in which proximity of vectors can be interpreted as semantic similarity. We propose to go from word-level to text-level semantics by combining insights from methods based on external sources of semantic knowledge with word embeddings. A novel feature of our approach is that an arbitrary number of word embedding sets can be incorporated. We derive multiple types of meta-features from the comparison of the word vectors for short text pairs, and from the vector means of their respective word embeddings. The features representing labelled short text pairs are used to train a supervised learning algorithm. We use the trained model at testing time to predict the semantic similarity of new, unlabelled pairs of short texts We show on a publicly available evaluation set commonly used for the task of semantic similarity that our method outperforms baseline methods that work under the same conditions.",2015,Conference on Information and Knowledge Management,dishin;semeval;semantic property;explicit semantic analysis;semantic similarity;natural language processing;information retrieval;pattern recognition;computer science;
Semantic Path based Personalized Recommendation on Weighted Heterogeneous Information Networks,Chuan Shi (Beijing University of Posts and Telecommunications);Zhiqiang Zhang (Beijing University of Posts and Telecommunications);Ping Luo (Chinese Academy of Sciences);Philip S. Yu (University of Illinois at Chicago);Yading Yue (Tencent);Bin Wu (Beijing University of Posts and Telecommunications);,"2252461150,2444486561,2291210646,2125104194,2228925929,2464938123","Recently heterogeneous information network (HIN) analysis has attracted a lot of attention, and many data mining tasks have been exploited on HIN. As an important data mining task, recommender system includes a lot of object types (e.g., users, movies, actors, and interest groups in movie recommendation) and the rich relations among object types, which naturally constitute a HIN. The comprehensive information integration and rich semantic information of HIN make it promising to generate better recommendations. However, conventional HINs do not consider the attribute values on links, and the widely used meta path in HIN may fail to accurately capture semantic relations among objects, due to the existence of rating scores (usually ranging from 1 to 5) between users and items in recommender system. In this paper, we are the first to propose the weighted HIN and weighted meta path concepts to subtly depict the path semantics through distinguishing different link attribute values. Furthermore, we propose a semantic path based personalized recommendation method SemRec to predict the rating scores of users on items. Through setting meta paths, SemRec not only flexibly integrates heterogeneous information but also obtains prioritized and personalized weights representing user preferences on paths. Experiments on two real datasets illustrate that SemRec achieves better recommendation performance through flexibly integrating information with the help of weighted meta paths.",2015,Conference on Information and Knowledge Management,similarity;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Struggling and Success in Web Search,Daan Odijk (University of Amsterdam);Ryen W. White (Microsoft);Ahmed Hassan Awadallah (Microsoft);Susan T. Dumais (Microsoft);,"1988427373,2096583854,2094223786,676500258","Web searchers sometimes struggle to find relevant information. Struggling leads to frustrating and dissatisfying search experiences, even if searchers ultimately meet their search objectives. Better understanding of search tasks where people struggle is important in improving search systems. We address this important issue using a mixed methods study using large-scale logs, crowd-sourced labeling, and predictive modeling. We analyze anonymized search logs from the Microsoft Bing Web search engine to characterize aspects of struggling searches and better explain the relationship between struggling and search success. To broaden our understanding of the struggling process beyond the behavioral signals in log data, we develop and utilize a crowd-sourced labeling methodology. We collect third-party judgments about why searchers appear to struggle and, if appropriate, where in the search task it became clear to the judges that searches would succeed (i.e., the pivotal query). We use our findings to propose ways in which systems can help searchers reduce struggling. Key components of such support are algorithms that accurately predict the nature of future actions and their anticipated impact on search outcomes. Our findings have implications for the design of search systems that help searchers struggle less and succeed more.",2015,Conference on Information and Knowledge Management,world wide web;data mining;simulation;computer science;
GraRep: Learning Graph Representations with Global Structural Information,Shaosheng Cao (Xidian University);Wei Lu (Singapore University of Technology and Design);Qiongkai Xu (IBM);,"2467350679,2599884673,2227099082","In this paper, we present {GraRep}, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. as well as the skip-gram model with negative sampling of Mikolov et al . We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks.",2015,Conference on Information and Knowledge Management,theoretical computer science;natural language processing;data mining;artificial intelligence;machine learning;computer science;
PlateClick: Bootstrapping Food Preferences Through an Adaptive Visual Interface,Longqi Yang (Cornell University);Yin Cui (Cornell University);Fan Zhang (Cornell University);John P. Pollak (Cornell University);Serge J. Belongie (Cornell University);Deborah Estrin (Cornell University);,"2229171165,2100166040,2675641844,2124210957,305618809,2127250160","Food preference learning is an important component of wellness applications and restaurant recommender systems as it provides personalized information for effective food targeting and suggestions. However, existing systems require some form of food journaling to create a historical record of an individual's meal selections. In addition, current interfaces for food or restaurant preference elicitation rely extensively on text-based descriptions and rating methods, which can impose high cognitive load, thereby hampering wide adoption. In this paper, we propose PlateClick , a novel system that bootstraps food preference using a simple, visual quiz-based user interface. We leverage a pairwise comparison approach with only visual content. Using over 10,028 recipes collected from Yummly, we design a deep convolutional neural network (CNN) to learn the similarity distance metric between food images. Our model is shown to outperform state-of-the-art CNN by 4 times in terms of mean Average Precision. We explore a novel online learning framework that is suitable for learning users' preferences across a large scale dataset based on a small number of interactions (≤ 15). Our online learning approach balances exploitation-exploration and takes advantage of food similarities using preference-propagation in locally connected graphs. We evaluated our system in a field study of 227 anonymous users. The results demonstrate that our method outperforms other baselines by a significant margin, and the learning process can be completed in less than one minute. In summary, PlateClick provides a light-weight, immersive user experience for efficient food preference elicitation.",2015,Conference on Information and Knowledge Management,preference learning;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Enterprise Social Link Recommendation,Jiawei Zhang (University of Illinois at Chicago);Yuanhua Lv (Microsoft);Philip S. Yu (University of Illinois at Chicago);,"2305185572,2132538679,2125104194","Many companies have started to use Enterprise Social Networks (ESNs), such as Yammer, to facilitate collaboration and communication amongst their employees in the business context. Social link recommendation, which finds and suggests whom one wants to connect with in a company, is crucial for ESNs to promote their usages. Although link recommendation has been studied extensively in external social networks (e.g., Facebook and Twitter), it has not been addressed in ESNs. In this paper, we study this novel problem. Social link recommendation in ESNs is significantly different from that in external social networks, and also has unique challenges: (1) people usually socialize differently in enterprise than in their personal life, but users' social behaviors in enterprise have not been well explored, and (2) there is important business information available in ESNs under the enterprise context, e.g., a company?s organizational chart, but how to exploit it for link recommendation is still an open problem. To this end, we mine not only the social graph and user-generated content in ESNs, but also the company's organizational chart, to model enterprise user social behaviors. We develop a supervised link recommendation algorithm using a large scale enterprise social network based on Yammer (with over 100k users), which shows that the proposed techniques perform effectively. Moreover, we find that both the social graph and the organizational chart are complementary to each other for link recommendation in ESNs.",2015,Conference on Information and Knowledge Management,data;knowledge management;world wide web;data mining;computer science;
A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion,Alessandro Sordoni (Université de Montréal);Yoshua Bengio (Université de Montréal);Hossein Vahabi (Yahoo!);Christina Lioma (University of Copenhagen);Jakob Grue Simonsen (University of Copenhagen);Jian-Yun Nie (Université de Montréal);,"65685553,161269817,2190435107,1619376036,2153084707,2620303841","Users may strive to formulate an adequate textual query for their information need. Search engines assist the users by presenting query suggestions. To preserve the original search intent, suggestions should be context-aware and account for the previous queries issued by the user. Achieving context awareness is challenging due to data sparsity. We present a novel hierarchical recurrent encoder-decoder architecture that makes possible to account for sequences of previous queries of arbitrary lengths. As a result, our suggestions are sensitive to the order of queries in the context while avoiding data sparsity. Additionally, our model can suggest for rare, or long-tail, queries. The produced suggestions are synthetic and are sampled one word at a time, using computationally cheap decoding techniques. This is in contrast to current synthetic suggestion models relying upon machine learning pipelines and hand-engineered feature sets. Results show that our model outperforms existing context-aware approaches in a next query prediction setting. In addition to query suggestion, our architecture is general enough to be used in a variety of other applications.",2015,Conference on Information and Knowledge Management,web query classification;spatial query;query expansion;query optimization;recurrent neural network;query language;data mining;artificial intelligence;machine learning;computer science;
Knowlywood: Mining Activity Knowledge From Hollywood Narratives,Niket Tandon (Max Planck Society);Gerard de Melo (Tsinghua University);Abir De (Indian Institute of Technology Kharagpur);Gerhard Weikum (Max Planck Society);,"1990453627,2134233121,2100683166,514836396","Despite the success of large knowledge bases, one kind of knowledge that has not received attention so far is that of human activities. An example of such an activity is proposing to someone (to get married). For the computer, knowing that this involves two adults, often but not necessarily a woman and a man, that it often takes place in some romantic location, that it typically involves flowers or jewelry, and that it is usually followed by kissing, is a valuable asset for tasks like natural language dialog, scene understanding, or video search. This corresponds to the challenging task of acquiring semantic frames that capture human activities, their participating agents, and their typical spatio-temporal contexts. This paper presents a novel approach that taps into movie scripts and other narrative texts. We develop a pipeline for semantic parsing and knowledge distillation, to systematically compile semantically refined activity frames. The resulting knowledge base contains hundreds of thousands of activity frames, mined from about two million scenes of movies, TV series, and novels. A manual assessment study, with extensive sampling and statistical significance tests, shows that the frames and their attribute values have an accuracy of at least 80 percent. We also demonstrate the usefulness of activity knowledge by the extrinsic use case of movie scene search.",2015,Conference on Information and Knowledge Management,natural language processing;multimedia;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
An Integrated Bayesian Approach for Effective Multi-Truth Discovery,Xianzhi Wang (University of Adelaide);Quan Z. Sheng (University of Adelaide);Xiu Susie Fang (University of Adelaide);Lina Yao (University of Adelaide);Xiaofei Xu (Harbin Institute of Technology);Xue Li (University of Queensland);,"2113587557,1740996049,2147043350,2223456168,2130531517,2239470812","Truth-finding is the fundamental technique for corroborating reports from multiple sources in both data integration and collective intelligent applications. Traditional truth-finding methods assume a single true value for each data item and therefore cannot deal will multiple true values (i.e., the multi-truth-finding problem). So far, the existing approaches handle the multi-truth-finding problem in the same way as the single-truth-finding problems. Unfortunately, the multi-truth-finding problem has its unique features, such as the involvement of sets of values in claims, different implications of inter-value mutual exclusion, and larger source profiles. Considering these features could provide new opportunities for obtaining more accurate truth-finding results. Based on this insight, we propose an integrated Bayesian approach to the multi-truth-finding problem, by taking these features into account. To improve the truth-finding efficiency, we reformulate the multi-truth-finding problem model based on the mappings between sources and (sets of) values. New mutual exclusive relations are defined to reflect the possible co-existence of multiple true values. A finer-grained copy detection method is also proposed to deal with sources with large profiles. The experimental results on three real-world datasets show the effectiveness of our approach.",2015,Conference on Information and Knowledge Management,bayesian inference;measurement;data mining;machine learning;statistics;computer science;
Classification with Active Learning and Meta-Paths in Heterogeneous Information Networks,Chang Wan (University of Hong Kong);Xiang Li (University of Hong Kong);Ben Kao (University of Hong Kong);Xiao Yu (University of Illinois at Urbana–Champaign);Quanquan Gu (University of Illinois at Urbana–Champaign);David Wai-Lok Cheung (University of Hong Kong);Jiawei Han 0001 (University of Illinois at Urbana–Champaign);,"2374628970,2644215135,1911907851,2160715520,2167348148,1979772396,2121939561",A heterogeneous information network (HIN) is used to model objects of different types and their relationships. Meta-paths are sequences of object types. They are used to represent complex relationships between objects beyond what links in a homogeneous network capture. We study the problem of classifying objects in an HIN. We propose class-level meta-paths and study how they can be used to (1) build more accurate classifiers and (2) improve active learning in identifying objects for which training labels should be obtained. We show that class-level meta-paths and object classification exhibit interesting synergy. Our experimental results show that the use of class-level meta-paths results in very effective active learning and good classification performance in HINs.,2015,Conference on Information and Knowledge Management,one class classification;active learning;biological classification;data mining;pattern recognition;machine learning;computer science;
Joint Modeling of User Check-in Behaviors for Point-of-Interest Recommendation,Hongzhi Yin (University of Queensland);Xiaofang Zhou (University of Queensland);Yingxia Shao (Peking University);Hao Wang 0005 (Chinese Academy of Sciences);Shazia Wasim Sadiq (University of Queensland);,"2145818752,2128990482,2122925794,2594397125,2122552307","Point-of-Interest (POI) recommendation has become an important means to help people discover attractive and interesting locations, especially when users travel out of town. However, extreme sparsity of user-POI matrix creates a severe challenge. To cope with this challenge, a growing line of research has exploited the temporal effect, geographical-social influence, content effect and word-of-mouth effect. However, current research lacks an integrated analysis of the joint effect of the above factors to deal with the issue of data-sparsity, especially in the out-of-town recommendation scenario which has been ignored by most existing work. In light of the above, we propose a joint probabilistic generative model to mimic user check-in behaviors in a process of decision making, which strategically integrates the above factors to effectively overcome the data sparsity, especially for out-of-town users. To demonstrate the applicability and flexibility of our model, we investigate how it supports two recommendation scenarios in a unified way, i.e., home-town recommendation and out-of-town recommendation. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets in terms of both recommendation effectiveness and efficiency, and the experimental results show its superiority over other competitors.",2015,Conference on Information and Knowledge Management,location based service;recommender system;world wide web;data mining;artificial intelligence;machine learning;simulation;computer science;
Extracting Situational Information from Microblogs during Disaster Events: a Classification-Summarization Approach,"Koustav Rudra (Indian Institute of Technology Kharagpur);Subham Ghosh (Indian Institute of Technology Kharagpur);Niloy Ganguly (Indian Institute of Technology Kharagpur);Pawan Goyal (Indian Institute of Technology Kharagpur);Saptarshi Ghosh (Indian Institute of Engineering Science and Technology, Shibpur);","2001992693,2608047588,2097625090,2556932677,2160207668","Microblogging sites like Twitter have become important sources of real-time information during disaster events. A significant amount of valuable situational information is available in these sites; however, this information is immersed among hundreds of thousands of tweets, mostly containing sentiments and opinion of the masses, that are posted during such events. To effectively utilize microblogging sites during disaster events, it is necessary to (i) extract the situational information from among the large amounts of sentiment and opinion, and (ii) summarize the situational information, to help decision-making processes when time is critical. In this paper, we develop a novel framework which first classifies tweets to extract situational information, and then summarizes the information. The proposed framework takes into consideration the typicalities pertaining to disaster events where (i) the same tweet often contains a mixture of situational and non-situational information, and (ii) certain numerical information, such as number of casualties, vary rapidly with time, and thus achieves superior performance compared to state-of-the-art tweet summarization approaches.",2015,Conference on Information and Knowledge Management,biological classification;automatic summarization;internet privacy;natural language processing;world wide web;information retrieval;data mining;computer science;
Detect Rumors Using Time Series of Social Context Information on Microblogging Websites,Jing Ma (Beijing University of Posts and Telecommunications);Wei Gao (Qatar Computing Research Institute);Zhongyu Wei (University of Texas at Dallas);Yueming Lu (Beijing University of Posts and Telecommunications);Kam Fai Wong (The Chinese University of Hong Kong);,"2650270329,2421005930,2153343683,2704433482,2189748902","Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time. In this study, we propose a novel approach to capture the temporal characteristics of these features based on the time series of rumor's lifecycle, for which time series modeling technique is applied to incorporate various social context information. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast.",2015,Conference on Information and Knowledge Management,social environment;time series;internet privacy;world wide web;statistics;computer science;
EsdRank: Connecting Query and Documents through External Semi-Structured Data,Chenyan Xiong (Carnegie Mellon University);Jamie Callan (Carnegie Mellon University);,"2226924701,2148123616","This paper presents EsdRank, a new technique for improving ranking using external semi-structured data such as controlled vocabularies and knowledge bases. EsdRank treats vocabularies, terms and entities from external data, as objects connecting query and documents. Evidence used to link query to objects, and to rank documents are incorporated as features between query-object and object-document correspondingly. A latent listwise learning to rank algorithm, Latent-ListMLE, models the objects as latent space between query and documents, and learns how to handle all evidence in a unified procedure from document relevance judgments. EsdRank is tested in two scenarios: Using a knowledge base for web search, and using a controlled vocabulary for medical search. Experiments on TREC Web Track and OHSUMED data show significant improvements over state-of-the-art baselines.",2015,Conference on Information and Knowledge Management,ranking;free base;web search query;semi structured data;ranking;controlled vocabulary;learning to rank;knowledge base;natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
Pooled Evaluation Over Query Variations: Users are as Diverse as Systems,Alistair Moffat (University of Melbourne);Falk Scholer (RMIT University);Paul Thomas (Commonwealth Scientific and Industrial Research Organisation);Peter Bailey (Microsoft);,"2155888323,1970689224,2229341583,2295915320","Evaluation of information retrieval systems with test collections makes use of a suite of fixed resources: a document corpus; a set of topics; and associated judgments of the relevance of each document to each topic. With large modern collections, exhaustive judging is not feasible. Therefore an approach called pooling is typically used where, for example, the documents to be judged can be determined by taking the union of all documents returned in the top positions of the answer lists returned by a range of systems. Conventionally, pooling uses system variations to provide diverse documents to be judged for a topic; different user queries are not considered. We explore the ramifications of user query variability on pooling, and demonstrate that conventional test collections do not cover this source of variation. The effect of user query variation on the size of the judging pool is just as strong as the effect of retrieval system variation. We conclude that user query variation should be incorporated early in test collection construction, and cannot be considered effectively post hoc.",2015,Conference on Information and Knowledge Management,ranking;world wide web;information retrieval;data mining;database;computer science;
Towards Multi-level Provenance Reconstruction of Information Diffusion on Social Media,Tom De Nies (Ghent University);Io Taxidou (University of Freiburg);Anastasia Dimou (Ghent University);Ruben Verborgh (Ghent University);Peter M. Fischer (University of Freiburg);Erik Mannens (Ghent University);Rik Van de Walle (Ghent University);,"305430315,47752373,1967857329,329670953,2571461549,1978788732,2004763151","In order to assess the trustworthiness of information on social media, a consumer needs to understand where this information comes from, and which processes were involved in its creation. The entities, agents and activities involved in the creation of a piece of information are referred to as its provenance, which was standardized by W3C PROV. However, current social media APIs cannot always capture the full lineage of every message, leaving the consumer with incomplete or missing provenance, which is crucial for judging the trust it carries. Therefore in this paper, we propose an approach to reconstruct the provenance of messages on social media on multiple levels. To obtain a fine-grained level of provenance, we use an approach from prior work to reconstruct information cascades with high certainty, and map them to PROV using the PROV-SAID extension for social media. To obtain a coarse-grained level of provenance, we adapt our similarity-based, fuzzy provenance reconstruction approach -- previously applied on news. We illustrate the power of the combination by providing the reconstructed provenance of a limited social media dataset gathered during the 2012 Olympics, for which we were able to reconstruct a significant amount of previously unidentified connections.",2015,Conference on Information and Knowledge Management,social media;cluster analysis;internet privacy;world wide web;data mining;database;machine learning;computer science;
Real-time Rumor Debunking on Twitter,Xiaomo Liu (Thomson Reuters);Armineh Nourbakhsh (Thomson Reuters);Quanzhi Li (Thomson Reuters);Rui Fang (Thomson Reuters);Sameena Shah (Thomson Reuters);,"2490351473,2232518488,2261932186,2427571942,2114545764","In this paper, we propose the first real time rumor debunking algorithm for Twitter. We use cues from 'wisdom of the crowds', that is, the aggregate 'common sense' and investigative journalism of Twitter users. We concentrate on identification of a rumor as an event that may comprise of one or more conflicting microblogs. We continue monitoring the rumor event and generate real time updates dynamically based on any additional information received. We show using real streaming data that it is possible, using our approach, to debunk rumors accurately and efficiently, often much faster than manual verification by professionals.",2015,Conference on Information and Knowledge Management,social computing;internet privacy;computer science;
L2Knng: Fast Exact K-Nearest Neighbor Graph Construction with L2-Norm Pruning,David C. Anastasiu (University of Minnesota);George Karypis (University of Minnesota);,"2118655246,219814910","The k -nearest neighbor graph is often used as a building block in information retrieval, clustering, online advertising, and recommender systems algorithms. The complexity of constructing the exact k-nearest neighbor graph is quadratic on the number of objects that are compared, and most existing methods solve the problem approximately. We present L2Knng, an efficient algorithm that finds the exact cosine similarity k -nearest neighbor graph for a set of sparse high-dimensional objects. Our algorithm quickly builds an approximate solution to the problem, identifying many of the most similar neighbors, and then uses theoretic bounds on the similarity of two vectors, based on the L 2 -norm of part of the vectors, to find each object's exact k -neighborhood. We perform an extensive evaluation of our algorithm, comparing against both exact and approximate baselines, and demonstrate the efficiency of our method across a variety of real-world datasets and neighborhood sizes. Our approximate and exact L2Knng variants compute the k -nearest neighbor graph up to an order of magnitude faster than their respective baselines.",2015,Conference on Information and Knowledge Management,nearest neighbor chain algorithm;best bin first;complement graph;graph bandwidth;theta graph;large margin nearest neighbor;nearest neighbor graph;vector space model;nearest neighbor search;pattern recognition;machine learning;computer science;
Interactive User Group Analysis,Behrooz Omidvar-Tehrani (Centre national de la recherche scientifique);Sihem Amer-Yahia (Centre national de la recherche scientifique);Alexandre Termier (University of Rennes);,"299395660,19633248,2558242110","User data is becoming increasingly available in multiple domains ranging from phone usage traces to data on the social Web. The analysis of user data is appealing to scientists who work on population studies, recommendations, and large-scale data analytics. We argue for the need for an interactive analysis to understand the multiple facets of user data and address different analytics scenarios. Since user data is often sparse and noisy, we propose to produce labeled groups that describe users with common properties and develop IUGA, an interactive framework based on group discovery primitives to explore the user space. At each step of IUGA, an analyst visualizes group members and may take an action on the group (add/remove members) and choose an operation (exploit/explore) to discover more groups and hence more users. Each discovery operation results in k most relevant and diverse groups . We formulate group exploitation and exploration as optimization problems and devise greedy algorithms to enable efficient group discovery. Finally, we design a principled validation methodology and run extensive experiments that validate the effectiveness of IUGA on large datasets for different user space analysis scenarios.",2015,Conference on Information and Knowledge Management,data science;world wide web;data mining;database;computer science;
Rank by Time or by Relevance?: Revisiting Email Search,David Carmel (Yahoo!);Guy Halawi (Yahoo!);Liane Lewin-Eytan (Yahoo!);Yoelle Maarek (Yahoo!);Ariel Raviv (Yahoo!);,"2088014474,259131073,2022197843,262608878,2227119167","With Web mail services offering larger and larger storage capacity, most users do not feel the need to systematically delete messages anymore and inboxes keep growing. It is quite surprising that in spite of the huge progress of relevance ranking in Web Search, mail search results are still typically ranked by date. This can probably be explained by the fact that users demand perfect recall in order to ""re-find"" a previously seen message, and would not trust relevance ranking. Yet mail search is still considered a difficult and frustrating task, especially when trying to locate older messages. In this paper, we study the current search traffic of Yahoo mail , a major Web commercial mail service, and discuss the limitations of ranking search results by date. We argue that this sort-by-date paradigm needs to be revisited in order to account for the specific structure and nature of mail messages, as well as the high-recall needs of users. We describe a two-phase ranking approach, in which the first phase is geared towards maximizing recall and the second phase follows a learning-to-rank approach that considers a rich set of mail-specific features to maintain precision. We present our results obtained on real mail search query traffic, for three different datasets, via manual as well as automatic evaluation. We demonstrate that the default time-driven ranking can be significantly improved in terms of both recall and precision, by taking into consideration time recency and textual similarity to the query, as well as mail-specific signals such as users' actions.",2015,Conference on Information and Knowledge Management,ranking;ranking;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Differentially Private Histogram Publication for Dynamic Datasets: an Adaptive Sampling Approach,"Haoran Li (Emory University);Li Xiong (Emory University);Xiaoqian Jiang (University of California, San Diego);Jinfei Liu (Emory University);","2099815881,1969262224,2132814769,2280101196","Differential privacy has recently become a de facto standard for private statistical data release. Many algorithms have been proposed to generate differentially private histograms or synthetic data. However, most of them focus on ""one-time"" release of a static dataset and do not adequately address the increasing need of releasing series of dynamic datasets in real time. A straightforward application of existing histogram methods on each snapshot of such dynamic datasets will incur high accumulated error due to the composibility of differential privacy and correlations or overlapping users between the snapshots. In this paper, we address the problem of releasing series of dynamic datasets in real time with differential privacy, using a novel adaptive distance-based sampling approach. Our first method, DSFT, uses a fixed distance threshold and releases a differentially private histogram only when the current snapshot is sufficiently different from the previous one, i.e., with a distance greater than a predefined threshold. Our second method, DSAT, further improves DSFT and uses a dynamic threshold adaptively adjusted by a feedback control mechanism to capture the data dynamics. Extensive experiments on real and synthetic datasets demonstrate that our approach achieves better utility than baseline methods and existing state-of-the-art methods.",2015,Conference on Information and Knowledge Management,differential privacy;text mining;data science;world wide web;information retrieval;data mining;database;machine learning;statistics;computer science;
Personalized Trip Recommendation with POI Availability and Uncertain Traveling Time,Chenyi Zhang (Simon Fraser University);Hongwei Liang (Simon Fraser University);Ke Wang (Simon Fraser University);Jianling Sun (Zhejiang University);,"2617976177,2436323175,2626264286,2142885270","As location-based social network (LBSN) services become increasingly popular, trip recommendation that recommends a sequence of points of interest (POIs) to visit for a user emerges as one of many important applications of LBSNs. Personalized trip recommendation tailors to users' specific tastes by learning from past check-in behaviors of users and their peers. Finding the optimal trip that maximizes user's experiences for a given time budget constraint is an NP hard problem and previous solutions do not consider two practical and important constraints. One constraint is POI availability where a POI may be only available during a certain time window. Another constraint is uncertain traveling time where the traveling time between two POIs is uncertain. This work presents efficient solutions to personalized trip recommendation by incorporating these constraints to prune the search space. We evaluated the efficiency and effectiveness of our solutions on real life LBSN data sets.",2015,Conference on Information and Knowledge Management,recommender system;world wide web;data mining;database;machine learning;simulation;computer science;
Time Series Analysis of Nursing Notes for Mortality Prediction via a State Transition Topic Model,Yohan Jo (Carnegie Mellon University);Natasha Loghmanpour (Carnegie Mellon University);Carolyn Penstein Rosé (Carnegie Mellon University);,"2139737370,1865990560,2152131012","Accurate mortality prediction is an important task in intensive care units in order to channel prompt care to patients in the most critical condition and to reduce nurses' alarm fatigue. Nursing notes carry valuable information in this regard, but nothing has been reported about the effectiveness of temporal analysis of nursing notes in mortality prediction tasks. We propose a time series model that uncovers the temporal dynamics of patients' underlying states from nursing notes. The effectiveness of this information in mortality prediction is examined for mortality prediction for five different time spans ranging from one day to one year. Our experiments show that the model captures both patient states and their temporal dynamics that have a strong correlation with patient mortality. The results also show that incorporating temporal information improves performance in long-term mortality prediction, but has no significant effect in short-term prediction.",2015,Conference on Information and Knowledge Management,latent dirichlet allocation;hidden markov model;data science;data mining;machine learning;simulation;computer science;
Tumblr Blog Recommendation with Boosted Inductive Matrix Completion,Donghyuk Shin (University of Texas at Austin);Suleyman Cetintas (Yahoo!);Kuang-Chih Lee (Yahoo!);Inderjit S. Dhillon (University of Texas at Austin);,"2123430164,2050174705,2223869048,2033403132","Popular microblogging sites such as Tumblr have attracted hundreds of millions of users as a content sharing platform, where users can create rich content in the form of posts that are shared with other users who follow them. Due to the sheer amount of posts created on such services, an important task is to make quality recommendations of blogs for users to follow. Apart from traditional recommender system settings where the follower graph is the main data source, additional side-information of users and blogs such as user activity (e.g., like and reblog) and rich content (e.g., text and images) are also available to be exploited for enhanced recommendation performance. In this paper, we propose a novel boosted inductive matrix completion method (BIMC) for blog recommendation. BIMC is an additive low-rank model for user-blog preferences consisting of two components; one component captures the low-rank structure of follow relationships and the other captures the latent structure using side-information. Our model formulation combines the power of the recently proposed inductive matrix completion (IMC) model (for side-information) together with a standard matrix completion (MC) model (for low-rank structure). Furthermore, we utilize recently developed deep learning techniques to obtain semantically rich feature representations of text and images that are incorporated in BIMC. Experiments on a large-scale real-world dataset from Tumblr illustrate the effectiveness of the proposed BIMC method.",2015,Conference on Information and Knowledge Management,multimedia;world wide web;information retrieval;data mining;database;
Learning Entity Types from Query Logs via Graph-Based Modeling,Jingyuan Zhang (University of Illinois at Chicago);Luo Jie (Yahoo!);Altaf Rahman (Yahoo!);Sihong Xie (University of Illinois at Chicago);Yi Chang (Yahoo!);Philip S. Yu (University of Illinois at Chicago);,"2142129048,2095673574,2136125118,2106011892,2168000538,2125104194","Entities (e.g., person, movie or place) play an important role in real-world applications and learning entity types has attracted much attention in recent years. Most conventional automatic techniques use large corpora, such as news articles, to learn types of entities. However, such text corpora focus on general knowledge about entities in an objective way. Hence, it is difficult to satisfy those users with specific and personalized needs for an entity. Recent years have witnessed an explosive expansion in the mining of search query logs, which contain billions of entities. The word patterns and click-throughs in search logs are not found in text corpora, thus providing a complemental source for discovering entity types based on user behaviors. In this paper, we study the problem of learning entity types from search query logs and address the following challenges: (1) queries are short texts, and information related to entities is usually very sparse; (2) large amounts of irrelevant information exists in search logs, bringing noise in detecting entity types. In this paper, we first model query logs using a bipartite graph with entities and their auxiliary information, such as contextual words and clicked URLs. Then we propose a graph-based framework called ELP ( E nsemble framework based on L able P ropagation) to simultaneously learn the types of both entities and auxiliary signals. In ELP, two separate strategies are designed to fix the problems of sparsity and noise in query logs. Extensive empirical studies are conducted on real search logs to evaluate the effectiveness of the proposed ELP framework.",2015,Conference on Information and Knowledge Management,entity;graph;natural language processing;world wide web;information retrieval;data mining;database;computer science;
Efficient Computation of Trips with Friends and Families,Tanzima Hashem (Bangladesh University of Engineering and Technology);Sukarna Barua (Bangladesh University of Engineering and Technology);Mohammed Eunus Ali (Bangladesh University of Engineering and Technology);Lars Kulik (University of Melbourne);Egemen Tanin (University of Melbourne);,"2015929307,2115071381,2160137718,1899350157,66485931","A group of friends located at their working places may want to plan a trip to visit a shopping center, have dinner at a restaurant, watch a movie at a theater, and then finally return to their homes with the minimum total trip distance. For a group of spatially dispersed users a group trip planning (GTP) query returns points of interests (POIs) of different types such as a shopping center, a restaurant and a movie theater that minimize the aggregate trip distance for the group. The aggregate trip distance could be the sum or maximum of the trip distances of all users in the group, where the users travel from their source locations via the jointly visited POIs to their individual destinations. In this paper, we develop both optimal and approximation algorithms for GTP queries for both Euclidean space and road networks . Processing GTP queries in real time is a computational challenge as trips involve POIs of multiple types and computation of aggregate trip distances. We develop novel techniques to refine the POI search space for a GTP query based on geometric properties of ellipses, which in turn significantly reduces the number of aggregate trip distance computations. An extensive set of experiments on a real and synthetic datasets shows that our approach outperforms the most competitive approach on an average by three orders of magnitude in terms of processing time.",2015,Conference on Information and Knowledge Management,world wide web;data mining;database;simulation;
More Accurate Question Answering on Freebase,Hannah Bast (University of Freiburg);Elmar Haussmann (University of Freiburg);,"1884751247,2122394792","Real-world factoid or list questions often have a simple structure, yet are hard to match to facts in a given knowledge base due to high representational and linguistic variability. For example, to answer ""who is the ceo of apple"" on Freebase requires a match to an abstract ""leadership"" entity with three relations ""role"", ""organization"" and ""person"", and two other entities ""apple inc"" and ""managing director"". Recent years have seen a surge of research activity on learning-based solutions for this method. We further advance the state of the art by adopting learning-to-rank methodology and by fully addressing the inherent entity recognition problem, which was neglected in recent works. We evaluate our system, called Aqqu , on two standard benchmarks, Free917 and WebQuestions, improving the previous best result for each benchmark considerably. These two benchmarks exhibit quite different challenges, and many of the existing approaches were evaluated (and work well) only for one of them. We also consider efficiency aspects and take care that all questions can be answered interactively (that is, within a second). Materials for full reproducibility are available on our website: http://ad.informatik.uni-freiburg.de/publications.",2015,Conference on Information and Knowledge Management,free base;topic model;question answering;knowledge base;knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Learning to Represent Knowledge Graphs with Gaussian Embedding,Shizhu He (Chinese Academy of Sciences);Kang Liu (Chinese Academy of Sciences);Guoliang Ji (Chinese Academy of Sciences);Jun Zhao (Chinese Academy of Sciences);,"2126153884,2130404924,2718547011,2590483556","The representation of a knowledge graph ( KG ) in a latent space recently has attracted more and more attention. To this end, some proposed models (e.g., TransE) embed entities and relations of a KG into a "" point "" vector space by optimizing a global loss function which ensures the scores of positive triplets are higher than negative ones. We notice that these models always regard all entities and relations in a same manner and ignore their (un)certainties. In fact, different entities and relations may contain different certainties, which makes identical certainty insufficient for modeling. Therefore, this paper switches to density-based embedding and propose KG2E for explicitly modeling the certainty of entities and relations, which learn the representations of KGs in the space of multi-dimensional Gaussian distributions. Each entity/relation is represented by a Gaussian distribution, where the mean denotes its position and the covariance (currently with diagonal covariance) can properly represent its certainty. In addition, compared with the symmetric measures used in point-based methods, we employ the KL-divergence for scoring triplets, which is a natural asymmetry function for effectively modeling multiple types of relations. We have conducted extensive experiments on link prediction and triplet classification with multiple benchmark datasets (WordNet and Freebase). Our experimental results demonstrate that our method can effectively model the (un)certainties of entities and relations in a KG, and it significantly outperforms state-of-the-art methods (including TransH and TransR).",2015,Conference on Information and Knowledge Management,data mining;artificial intelligence;machine learning;statistics;
Forming Online Support Groups for Internet and Behavior Related Addictions,Chih Ya Shen (Academia Sinica);Hong Han Shuai (National Taiwan University);De Nian Yang (Academia Sinica);Yi Feng Lan (Tamkang University);Wang Chien Lee (Pennsylvania State University);Philip S. Yu (University of Illinois at Chicago);Ming Syan Chen (National Taiwan University);,"2122520210,2184003779,2096343151,2612257228,2143778659,2125104194,2122365371","While online social networks have become a part of many people's daily lives, Internet and social network addictions (ISNAs) have been noted recently. With increased patients in addictive Internet use, clinicians often form support groups to help patients. This has become a trend because groups organized around therapeutic goals can effectively enrich members with insight and guidance while holding everyone accountable along the way. With the emergence of online social network services, there is a trend to form support groups online with the aid of mental health professionals. Nevertheless, it becomes impractical for a psychiatrist to manually select the group members because she faces an enormous number of candidates, while the selection criteria are also complicated since they span both the social and symptom dimensions. To effectively address the need of mental healthcare professionals, this paper makes the first attempt to study a new problem, namely Member Selection for Online Support Group (MSSG). The problem aims to maximize the similarity of the symptoms of all selected members, while ensuring that any two members are unacquainted to each other. We prove that MSSG is NP-Hard and inapproximable within any ratio, and design a 3-approximation algorithm with a guaranteed error bound. We evaluate MSSG via a user study with 11 mental health professionals, and the results manifest that MSSG can effectively find support group members satisfying the member selection criteria. Experimental results on large-scale real datasets also demonstrate that our proposed algorithm outperforms other baselines in terms of solution quality and efficiency.",2015,Conference on Information and Knowledge Management,addiction;social network;approximation algorithm;world wide web;data mining;artificial intelligence;simulation;computer science;
Location and Time Aware Social Collaborative Retrieval for New Successive Point-of-Interest Recommendation,Wei Zhang (Tsinghua University);Jianyong Wang (Tsinghua University);,"2723820743,2105625159","In location-based social networks (LBSNs), new successive point-of-interest (POI) recommendation is a newly formulated task which tries to regard the POI a user currently visits as his POI-related query and recommend new POIs the user has not visited before. While carefully designed methods are proposed to solve this problem, they ignore the essence of the task which involves retrieval and recommendation problem simultaneously and fail to employ the social relations or temporal information adequately to improve the results. In order to solve this problem, we propose a new model called location and time aware social collaborative retrieval model (LTSCR), which has two distinct advantages: (1) it models the location, time, and social information simultaneously for the successive POI recommendation task; (2) it efficiently utilizes the merits of the collaborative retrieval model which leverages weighted approximately ranked pairwise (WARP) loss for achieving better top-n ranking results, just as the new successive POI recommendation task needs. We conducted some comprehensive experiments on publicly available datasets and demonstrate the power of the proposed method, with 46.6% growth in Precision@5 and 47.3% improvement in Recall@5 over the best previous method.",2015,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
Ad Hoc Monitoring of Vocabulary Shifts over Time,Tom Kenter (University of Amsterdam);Melvin Wevers (Utrecht University);Pim Huijnen (Utrecht University);Maarten de Rijke (University of Amsterdam);,"2060822933,2223742249,1565002861,401833296","Word meanings change over time. Detecting shifts in meaning for particular words has been the focus of much research recently. We address the complementary problem of monitoring shifts in vocabulary over time. That is, given a small seed set of words, we are interested in monitoring which terms are used over time to refer to the underlying concept denoted by the seed words. In this paper, we propose an algorithm for monitoring shifts in vocabulary over time, given a small set of seed terms. We use distributional semantic methods to infer a series of semantic spaces over time from a large body of time-stamped unstructured textual documents. We construct semantic networks of terms based on their representation in the semantic spaces and use graph-based measures to calculate saliency of terms. Based on the graph-based measures we produce ranked lists of terms that represent the concept underlying the initial seed terms over time as final output. As the task of monitoring shifting vocabularies over time for an ad hoc set of seed words is, to the best of our knowledge, a new one, we construct our own evaluation set. Our main contributions are the introduction of the task of ad hoc monitoring of vocabulary shifts over time, the description of an algorithm for tracking shifting vocabularies over time given a small set of seed words, and a systematic evaluation of results over a substantial period of time (over four decades). Additionally, we make our newly constructed evaluation set publicly available.",2015,Conference on Information and Knowledge Management,digital humanities;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
10 Bits of Surprise: Detecting Malicious Users with Minimum Information,Reza Zafarani (Syracuse University);Huan Liu (Arizona State University);,"2055981231,2122391114","Malicious users are a threat to many sites and defending against them demands innovative countermeasures. When malicious users join sites, they provide limited information about themselves. With this limited information, sites can find it difficult to distinguish between a malicious user and a normal user. In this study, we develop a methodology that identifies malicious users with limited information. As information provided by malicious users can vary, the proposed methodology utilizes minimum information to identify malicious users. It is shown that as little as 10 bits of information can help greatly in this challenging task. The experiments results verify that this methodology is effective in identifying malicious users in the realistic scenario of limited information availability.",2015,Conference on Information and Knowledge Management,behaviorism;internet privacy;world wide web;computer security;computer science;
Viewability Prediction for Online Display Ads,Chong Wang (New Jersey Institute of Technology);Achir Kalra (New Jersey Institute of Technology);Cristian Borcea (New Jersey Institute of Technology);Yi Chen (New Jersey Institute of Technology);,"2436599651,2109915864,2123637163,2620155405","As a massive industry, display advertising delivers advertisers' marketing messages to attract customers through graphic banners on webpages. Advertisers are charged by ad serving, where their ads are shown in web pages. However, recent studies show that about half of the ads were actually never seen by users because they do not scroll deep enough to bring the ads in-view. Thus, the ad pricing standards are shifting to a new model: ads are paid if they are in view, not just being served. To the best of our knowledge, this paper is the first to address the important problem of ad viewability prediction which can improve the performance of guaranteed ad delivery, real-time bidding, as well as recommender systems. We analyze a real-life dataset from a large publisher, identify a number of features that impact the scroll depth for a given user and a page, and propose a probabilistic latent class model that predicts the viewability of any given scroll depth for a user-page pair. The experiments demonstrate that our model outperforms comparison systems based on singular value decomposition and logistic regression, in terms of prediction quality and training time.",2015,Conference on Information and Knowledge Management,internet privacy;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Personalized Federated Search at LinkedIn,Dhruv Arya (LinkedIn);Viet Ha-Thuc (LinkedIn);Shakti Sinha (LinkedIn);,"2231240302,2310324677,2155323900","LinkedIn has grown to become a platform hosting diverse sources of information ranging from member profiles, jobs, professional groups, slideshows etc. Given the existence of multiple sources, when a member issues a query like ""software engineer"", the member could look for software engineer profiles, jobs or professional groups. To tackle this problem, we exploit a data-driven approach that extracts searcher intents from their profile data and recent activities at a large scale. The intents such as job seeking, hiring, content consuming are used to construct features to personalize federated search experience. We tested the approach on the LinkedIn homepage and A/B tests show significant improvements in member engagement. As of writing this paper, the approach powers all of federated search on LinkedIn homepage.",2015,Conference on Information and Knowledge Management,ranking;social network;world wide web;information retrieval;data mining;database;machine learning;computer science;
Assessing the Impact of Syntactic and Semantic Structures for Answer Passages Reranking,Kateryna Tymoshenko (University of Trento);Alessandro Moschitti (Qatar Computing Research Institute);,"2652651832,48142092","In this paper, we extensively study the use of syntactic and semantic structures obtained with shallow and deeper syntactic parsers in the answer passage reranking task. We propose several dependency-based structures enriched with Linked Open Data (LD) knowledge for representing pairs of questions and answer passages. We use such tree structures in learning to rank (L2R) algorithms based on tree kernel. The latter can represent questions and passages in a tree fragment space, where each substructure represents a powerful syntactic/semantic feature. Additionally since we define links between structures, tree kernels also generate relational features spanning question and passage structures. We derive very important findings, which can be useful to build state-of-the-art systems: (i) full syntactic dependencies can outperform shallow models also using external knowledge and (ii) the semantic information should be derived by effective and high-coverage resources, e.g., LD, and incorporated in syntactic structures to be effective. We demonstrate our findings by carrying out an extensive comparative experimentation on two different TREC QA corpora and one community question answer dataset, namely Answerbag. Our comparative analysis on well-defined answer selection benchmarks consistently demonstrates that our structural semantic models largely outperform the state of the art in passage reranking.",2015,Conference on Information and Knowledge Management,linked data;kernel method;learning to rank;question answering;natural language processing;information retrieval;data mining;database;machine learning;computer science;
Deriving Intensional Descriptions for Web Services,Maria Koutraki (Leibniz Association);Dan Vodislav (Conservatoire national des arts et métiers);Nicoleta Preda (French Institute for Research in Computer Science and Automation);,"2230575466,182606413,1989473477","Many data providers make their data available through Web service APIs. In order to unleash the potential of these sources for intelligent applications, the data has to be combined across different APIs. However, due to the heterogeneity of schemas, the integration of different APIs remains a mainly manual task to date. In this paper, we model an API method as a view with binding patterns over a global RDF schema. We present an algorithm that can automatically infer the view definition of a method in the global schema. We also show how to compute transformation functions that can transform API call results into this schema. The key idea of our approach is to exploit the intersection of API call results with a knowledge base and with other call results. Our experiments on more than 50 real Web services show that we can automatically infer the schema with a precision of 81%-100%.",2015,Conference on Information and Knowledge Management,information schema;star schema;view;web service;world wide web;information retrieval;data mining;database;computer science;
Unsupervised Streaming Feature Selection in Social Media,Jundong Li (Arizona State University);Xia Hu (Texas A&M University);Jiliang Tang (Yahoo!);Huan Liu (Arizona State University);,"2149809093,2161448330,2147392410,2122391114","The explosive growth of social media sites brings about massive amounts of high-dimensional data. Feature selection is effective in preparing high-dimensional data for data analytics. The characteristics of social media present novel challenges for feature selection. First, social media data is not fully structured and its features are usually not predefined, but are generated dynamically. For example, in Twitter, slang words (features) are created everyday and quickly become popular within a short period of time. It is hard to directly apply traditional batch-mode feature selection methods to find such features. Second, given the nature of social media, label information is costly to collect. It exacerbates the problem of feature selection without knowing feature relevance. On the other hand, opportunities are also unequivocally present with additional data sources; for example, link information is ubiquitous in social media and could be helpful in selecting relevant features. In this paper, we study a novel problem to conduct unsupervised streaming feature selection for social media data. We investigate how to exploit link information in streaming feature selection, resulting in a novel unsupervised streaming feature selection framework USFS. Experimental results on two real-world social media datasets show the effectiveness and efficiency of the proposed framework comparing with the state-of-the-art unsupervised feature selection algorithms.",2015,Conference on Information and Knowledge Management,feature;data mining;pattern recognition;machine learning;computer science;
Deep Collaborative Filtering via Marginalized Denoising Auto-encoder,Sheng Li (Northeastern University);Jaya Kawale (Adobe Systems);Yun Fu (Northeastern University);,"2618462548,2091655785,2123131494","Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.",2015,Conference on Information and Knowledge Management,probabilistic latent semantic analysis;collaborative filtering;matrix decomposition;deep learning;data science;data mining;pattern recognition;machine learning;computer science;
Query Relaxation across Heterogeneous Data Sources,Verena Kantere (University of Geneva);George Orfanoudakis (National Technical University of Athens);Anastasios Kementsietsidis (Google);Timos K. Sellis (RMIT University);,"1886388312,2228832098,2674980903,2696661525","The fundamental assumption for query rewriting in heterogeneous environments is that the mappings used for the rewriting are complete , i.e., every relation and attribute mentioned in the query is associated, through mappings, to relations and attributes in the schema of the source that the query is rewritten. In reality, it is rarely the case that such complete sets of mappings exist between sources, and the presence of partial mappings is the norm rather than the exception. So, practically, existing query answering algorithms fail to generate any rewriting in the majority of cases. The question is then whether we can somehow relax queries that cannot be rewritten as such (due to insufficient mappings), and whether we can identify the interesting query relaxations, given the mappings at hand. In this paper, we propose a technique to compute query relaxations of an input query that can be rewritten and evaluated in an environment of collaborating autonomous and heterogeneous data sources. We extend traditional techniques for query rewriting, and we propose both an exhaustive and an optimized heuristic algorithm to compute and evaluate these relaxations. Our technique works with input of any query similarity measure. The experimental study proves the effectiveness and efficiency of our technique.",2015,Conference on Information and Knowledge Management,sargable;ranking;range query;boolean conjunctive query;web query classification;spatial query;query by example;query expansion;range query;query optimization;query language;theoretical computer science;data mining;database;
Searching and Stopping: An Analysis of Stopping Rules and Strategies,David Maxwell (University of Glasgow);Leif Azzopardi (University of Glasgow);Kalervo Järvelin (University of Tampere);Heikki Keskustalo (University of Tampere);,"2465962233,2163026013,54234561,131578950","Searching naturally involves stopping points, both at a query level ( how far down the ranked list should I go? ) and at a session level ( how many queries should I issue? ). Understanding when searchers stop has been of much interest to the community because it is fundamental to how we evaluate search behaviour and performance. Research has shown that searchers find it difficult to formalise stopping criteria, and typically resort to their intuition of what is ""good enough"" . While various heuristics and stopping criteria have been proposed, little work has investigated how well they perform, and whether searchers actually conform to any of these rules. In this paper, we undertake the first large scale study of stopping rules, investigating how they influence overall session performance, and which rules best match actual stopping behaviour. Our work is focused on stopping at the query level in the context of ad-hoc topic retrieval, where searchers undertake search tasks within a fixed time period. We show that stopping strategies based upon the disgust or frustration point rules - both of which capture a searcher's tolerance to non-relevance - typically result in ( i ) the best overall performance, and ( ii ) provide the closest approximation to actual searcher behaviour, although a fixed depth approach also performs remarkably well. Findings from this study have implications regarding how we build measures, and how we conduct simulations of search behaviours.",2015,Conference on Information and Knowledge Management,evaluation;artificial intelligence;simulation;computer science;
Fast Distributed Correlation Discovery Over Streaming Time-Series Data,Tian Guo (École Polytechnique Fédérale de Lausanne);Saket Sathe (IBM);Karl Aberer (École Polytechnique Fédérale de Lausanne);,"2166312522,2478550524,150096297","The dramatic rise of time-series data in a variety of contexts, such as social networks, mobile sensing, data centre monitoring, etc., has fuelled interest in obtaining real-time insights from such data using distributed stream processing systems. One such extremely valuable insight is the discovery of correlations in real-time from large-scale time-series data. A key challenge in discovering correlations is that the number of time-series pairs that have to be analyzed grows quadratically in the number of time-series, giving rise to a quadratic increase in both computation cost and communication cost between the cluster nodes in a distributed environment. To tackle the challenge, we propose a framework called AEGIS. AEGIS exploits well-established statistical properties to dramatically prune the number of time-series pairs that have to be evaluated for detecting interesting correlations. Our extensive experimental evaluations on real and synthetic datasets establish the efficacy of AEGIS over baselines.",2015,Conference on Information and Knowledge Management,stream processing;time series;data science;theoretical computer science;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
ORec: An Opinion-Based Point-of-Interest Recommendation Framework,Jia-Dong Zhang (City University of Hong Kong);Chi-Yin Chow (City University of Hong Kong);Yu Zheng (Microsoft);,"2123840817,2152571782,2656731750","As location-based social networks (LBSNs) rapidly grow, it is a timely topic to study how to recommend users with interesting locations, known as points-of-interest (POIs). Most existing POI recommendation techniques only employ the check-in data of users in LBSNs to learn their preferences on POIs by assuming a user's check-in frequency to a POI explicitly reflects the level of her preference on the POI. However, in reality users usually visit POIs only once, so the users' check-ins may not be sufficient to derive their preferences using their check-in frequencies only. Actually, the preferences of users are exactly implied in their opinions in text-based tips commenting on POIs. In this paper, we propose an opinion-based POI recommendation framework called ORec to take full advantage of the user opinions on POIs expressed as tips. In ORec, there are two main challenges: (i) detecting the polarities of tips (positive, neutral or negative), and (ii) integrating them with check-in data including social links between users and geographical information of POIs. To address these two challenges, (1) we develop a supervised aspect-dependent approach to detect the polarity of a tip, and (2) we devise a method to fuse tip polarities with social links and geographical information into a unified POI recommendation framework. Finally, we conduct a comprehensive performance evaluation for ORec using two large-scale real data sets collected from Foursquare and Yelp. Experimental results show that ORec achieves significantly superior polarity detection and POI recommendation accuracy compared to other state-of-the-art polarity detection and POI recommendation techniques.",2015,Conference on Information and Knowledge Management,fusion;sentiment analysis;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Leveraging Joint Interactions for Credibility Analysis in News Communities,Subhabrata Mukherjee (Max Planck Society);Gerhard Weikum (Max Planck Society);,"2301124665,514836396","Media seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more. This paper presents a model to systematically analyze the different interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of ""citizen journalists"" in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized without losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities.",2015,Conference on Information and Knowledge Management,graphical model;world wide web;data mining;machine learning;computer science;
Balancing Novelty and Salience: Adaptive Learning to Rank Entities for Timeline Summarization of High-impact Events,Tuan A. Tran (Leibniz University of Hanover);Claudia Niederee (Leibniz University of Hanover);Nattiya Kanhabua (Leibniz University of Hanover);Ujwal Gadiraju (Leibniz University of Hanover);Avishek Anand (Max Planck Society);,"2336376938,1820140241,2278903833,2225811719,2127850459","Long-running, high-impact events such as the Boston Marathon bombing often develop through many stages and involve a large number of entities in their unfolding. Timeline summarization of an event by key sentences eases story digestion, but does not distinguish between what a user remembers and what she might want to re-check. In this work, we present a novel approach for timeline summarization of high-impact events, which uses entities instead of sentences for summarizing the event at each individual point in time. Such entity summaries can serve as both (1) important memory cues in a retrospective event consideration and (2) pointers for personalized event exploration. In order to automatically create such summaries, it is crucial to identify the ""right"" entities for inclusion. We propose to learn a ranking function for entities, with a dynamically adapted trade-off between the in-document salience of entities and the informativeness of entities across documents, i.e., the level of new information associated with an entity for a time point under consideration. Furthermore, for capturing collective attention for an entity we use an innovative soft labeling approach based on Wikipedia. Our experiments on a real large news datasets confirm the effectiveness of the proposed methods.",2015,Conference on Information and Knowledge Management,news;learning to rank;automatic summarization;world wide web;information retrieval;data mining;machine learning;computer science;
Approximate Truth Discovery via Problem Scale Reduction,Xianzhi Wang (University of Adelaide);Quan Z. Sheng (University of Adelaide);Xiu Susie Fang (University of Adelaide);Xue Li (University of Queensland);Xiaofei Xu (Harbin Institute of Technology);Lina Yao (University of Adelaide);,"2113587557,1740996049,2147043350,2239470812,2130531517,2223456168","Many real-world applications rely on multiple data sources to provide information on their interested items. Due to the noises and uncertainty in data, given a specific item, the information from different sources may conflict. To make reliable decisions based on these data, it is important to identify the trustworthy information by resolving these conflicts, i.e., the truth discovery problem. Current solutions to this problem detect the veracity of each value jointly with the reliability of each source for each data item. In this way, the efficiency of truth discovery is strictly confined by the problem scale, which in turn limits truth discovery algorithms from being applicable on a large scale. To address this issue, we propose an approximate truth discovery approach, which divides sources and values into groups according to a user-specified approximation criterion. The groups are then used for efficient inter-value influence computation to improve the accuracy. Our approach is applicable to most existing truth discovery algorithms. Experiments on real-world datasets show that our approach improves the efficiency compared to existing algorithms while achieving similar or even better accuracy. The scalability is further demonstrated by experiments on large synthetic datasets.",2015,Conference on Information and Knowledge Management,data science;theoretical computer science;information retrieval;data mining;database;machine learning;statistics;computer science;
Balancing Exploration and Exploitation: Empirical Parameterization of Exploratory Search Systems,Kumaripaba Ahukorala (University of Helsinki);Alan Medlar (University of Helsinki);Kalle Ilves (University of Helsinki);Dorota Glowacka (University of Helsinki);,"2223198503,1828258422,1929882918,2042460623","Exploratory searches are where a user has insufficient knowledge to define exact search criteria or does not otherwise know what they are looking for. Reinforcement learning techniques have demonstrated great potential for supporting exploratory search in information retrieval systems as they allow the system to trade-off exploration (presenting the user with alternatives topics) and exploitation (moving toward more specific topics). Users of such systems, however, often feel that the system is not responsive to user needs. This problem is not an inherent feature of such systems, but is caused by the exploration rate parameter being inappropriately tuned for a given system, dataset or user. We present a user study to analyze how different exploration rates affect search performance, user satisfaction, and the number of documents selected. We show that the tradeoff between exploration and exploitation can be modelled as a direct relationship between the exploration rate parameter from the reinforcement learning algorithm and the number of relevant documents returned to the user over the course of a search session. We define the optimal exploration/exploitation trade-off as where this relationship is maximised and show this point to be broadly concordant with user satisfaction and performance.",2015,Conference on Information and Knowledge Management,computer user satisfaction;user modeling;systems design;world wide web;data mining;machine learning;simulation;computer science;
On the Cost of Extracting Proximity Features for Term-Dependency Models,Xiaolu Lu (RMIT University);Alistair Moffat (University of Melbourne);J. Shane Culpepper (RMIT University);,"2231866520,2155888323,1944334593","Sophisticated ranking mechanisms make use of term dependency features in order to compute similarity scores for documents. These features often include exact phrase occurrences, and term proximity estimates. Both cases build on the intuition that if multiple query terms appear near each other, the document is more likely to be relevant to the query. In this paper we examine the processes used to compute these statistics. Two distinct input structures can be used -- inverted files and direct files. Inverted files must store the position offsets of the terms, while ""direct"" files represent each document as a sequence of preprocessed term identifiers. Based on these two input modalities, a number of algorithms can be used to compute proximity statistics. Until now, these algorithms have been described in terms of a single set of query terms. But similarity computations such as the Full Dependency Model compute proximity statistics for a collection of related term sets. We present a new approach in which such collections are processed holistically in time that is much less than would be the case if each subquery were to be evaluated independently. The benefits of the new method are demonstrated by a comprehensive experimental study.",2015,Conference on Information and Knowledge Management,efficiency;performance;measurement;world wide web;information retrieval;data mining;database;machine learning;computer science;
Automated News Suggestions for Populating Wikipedia Entity Pages,Besnik Fetahu (Leibniz University of Hanover);Katja Markert (Heidelberg University);Avishek Anand (Max Planck Society);,"2086402540,2565055383,2127850459","Wikipedia entity pages are a valuable source of information for direct consumption and for knowledge-base construction, update and maintenance. Facts in these entity pages are typically supported by references. Recent studies show that as much as 20% of the references are from online news sources. However, many entity pages are incomplete even if relevant information is already available in existing news articles. Even for the already present references, there is often a delay between the news article publication time and the reference time. In this work, we therefore look at Wikipedia through the lens of news and propose a novel news-article suggestion task to improve news coverage in Wikipedia, and reduce the lag of newsworthy references. Our work finds direct application, as a precursor, to Wikipedia page generation and knowledge-base acceleration tasks that rely on relevant and high quality input sources. We propose a two-stage supervised approach for suggesting news articles to entity pages for a given state of Wikipedia. First, we suggest news articles to Wikipedia entities (article-entity placement) relying on a rich set of features which take into account the salience and relative authority of entities, and the novelty of news articles to entity pages. Second, we determine the exact section in the entity page for the input article (article-section placement) guided by class-based section templates. We perform an extensive evaluation of our approach based on ground-truth data that is extracted from external references in Wikipedia. We achieve a high precision value of up to 93% in the article-entity suggestion stage and upto 84% for the article-section placement . Finally, we compare our approach against competitive baselines and show significant improvements.",2015,Conference on Information and Knowledge Management,entity linking;world wide web;information retrieval;data mining;database;computer science;
An Optimization Framework for Merging Multiple Result Lists,Chia-Jung Lee (University of Massachusetts Amherst);Qingyao Ai (University of Massachusetts Amherst);W. Bruce Croft (University of Massachusetts Amherst);Daniel Sheldon (University of Massachusetts Amherst);,"2166010901,2223502885,2127889770,2114707312","Developing effective methods for fusing multiple ranked lists of documents is crucial to many applications. Federated web search, for instance, has become a common practice where a query is issued to different verticals and a single ranked list of blended results is created. While federated search is regarded as collection fusion, data fusion techniques aim at improving search coverage and precision by combining multiple search runs on a single document collection. In this paper, we study in depth and extend a neural network-based approach, LambdaMerge, for merging results of ranked lists drawn from one (i.e., data fusion) or more (i.e., collection fusion) verticals. The proposed model considers the impact of the quality of documents, ranked lists and verticals for producing the final merged result in an optimization framework. We further investigate the potential of incorporating deep structures into the model with an aim of determining better combinations of different evidence. In the experiments on collection fusion and data fusion, the proposed approach significantly outperforms several standard baselines and state-of-the-art learning-based approaches.",2015,Conference on Information and Knowledge Management,sensor fusion;world wide web;information retrieval;data mining;database;computer science;
Social Spammer and Spam Message Co-Detection in Microblogging with Social Context Regularization,Fangzhao Wu (Tsinghua University);Jinyun Shu (Beijing University of Posts and Telecommunications);Yongfeng Huang (Tsinghua University);Zhigang Yuan (Tsinghua University);,"2142281011,2229560289,2707325663,2225891681","The popularity of microblogging platforms, such as Twitter, makes them important for information dissemination and sharing. However, they are also recognized as ideal places by spammers to conduct social spamming. Massive social spammers and spam messages heavily hurt the user experience and hinder the healthy development of microblogging systems. Thus, effectively detecting the social spammers and spam messages in microblogging is of great value. Existing studies mainly regard social spammer detection and spam message detection as two separate tasks. However, social spammers and spam messages have strong connections, since social spammers tend to post more spam messages and spam messages have high probabilities to be posted by social spammers. Combining social spammer detection with spam message detection has the potential to boost the performance of each task. In this paper, we propose a unified framework for social spammer and spam message co-detection in microblogging. Our framework utilizes the posting relations between users and messages to combine social spammer detection with spam message detection. In addition, we extract the social relations between users as well as the connections between messages, and incorporate them into our framework as regularization terms over the prediction results. Besides, we introduce an efficient optimization method to solve our framework. Extensive experiments on a real-world microblog dataset demonstrate that our framework can significantly and consistently improve the performance of both social spammer detection and spam message detection.",2015,Conference on Information and Knowledge Management,referer spam;forum spam;spambot;social spam;spamming;microblogging;social environment;internet privacy;world wide web;computer science;
Robust Subspace Clustering via Tighter Rank Approximation,Zhao Kang (Southern Illinois University Carbondale);Chong Peng (Southern Illinois University Carbondale);Qiang Cheng (Southern Illinois University Carbondale);,"2162933773,2104710458,2102340508","Matrix rank minimization problem is in general NP-hard. The nuclear norm is used to substitute the rank function in many recent studies. Nevertheless, the nuclear norm approximation adds all singular values together and the approximation error may depend heavily on the magnitudes of singular values. This might restrict its capability in dealing with many practical problems. In this paper, an arctangent function is used as a tighter approximation to the rank function. We use it on the challenging subspace clustering problem. For this nonconvex minimization problem, we develop an effective optimization procedure based on a type of augmented Lagrange multipliers (ALM) method. Extensive experiments on face clustering and motion segmentation show that the proposed method is effective for rank approximation.",2015,Conference on Information and Knowledge Management,correlation clustering;matrix norm;low rank approximation;discrete mathematics;combinatorics;mathematical optimization;mathematics;
Sampling Big Trajectory Data,Yanhua Li (Worcester Polytechnic Institute);Chi Yin Chow (City University of Hong Kong);Ke Deng (RMIT University);Mingxuan Yuan (Huawei);Jia Zeng (Soochow University);Jia Dong Zhang (City University of Hong Kong);Qiang Yang (Hong Kong University of Science and Technology);Zhi Li Zhang (University of Minnesota);,"2160296268,2152571782,2688213377,2305706855,2683497130,2123840817,2109031554,2164420873","The increasing prevalence of sensors and mobile devices has led to an explosive increase of the scale of spatio-temporal data in the form of trajectories. A trajectory aggregate query, as a fundamental functionality for measuring trajectory data, aims to retrieve the statistics of trajectories passing a user-specified spatio-temporal region. A large-scale spatio-temporal database with big disk-resident data takes very long time to produce exact answers to such queries. Hence, approximate query processing with a guaranteed error bound is a promising solution in many scenarios with stringent response-time requirements. In this paper, we study the problem of approximate query processing for trajectory aggregate queries. We show that it boils down to the distinct value estimation problem, which has been proven to be very hard with powerful negative results given that no index is built. By utilizing the well-established spatio-temporal index and introducing an inverted index to trajectory data, we are able to design random index sampling (RIS) algorithm to estimate the answers with a guaranteed error bound. To further improve system scalability, we extend RIS algorithm to concurrent random index sampling (CRIS) algorithm to process a number of trajectory aggregate queries arriving concurrently with overlapping spatio-temporal query regions. To demonstrate the efficacy and efficiency of our sampling and estimation methods, we applied them in a real large-scale user trajectory database collected from a cellular service provider in China. Our extensive evaluation results indicate that both RIS and CRIS outperform exhaustive search for single and concurrent trajectory aggregate queries by two orders of magnitude in terms of the query processing time, while preserving a relative error ratio lower than 10\%, with only 1% search cost of the exhaustive search method.",2015,Conference on Information and Knowledge Management,online aggregation;query optimization;sampling;theoretical computer science;world wide web;information retrieval;data mining;database;machine learning;statistics;computer science;
MAPer: A Multi-scale Adaptive Personalized Model for Temporal Human Behavior Prediction,Sarah Masud Preum (University of Virginia);John A. Stankovic (University of Virginia);Yanjun Qi (University of Virginia);,"2228136005,2030977062,2255911127","The primary objective of this research is to develop a simple and interpretable predictive framework to perform temporal modeling of individual user's behavior traits based on each person's past observed traits/behavior. Individual-level human behavior patterns are possibly influenced by various temporal features (e.g., lag, cycle) and vary across temporal scales (e.g., hour of the day, day of the week). Most of the existing forecasting models do not capture such multi-scale adaptive regularity of human behavior or lack interpretability due to relying on hidden variables. Hence, we build a multi-scale adaptive personalized (MAPer ) model that quantifies the effect of both lag and behavior cycle for predicting future behavior. MAper includes a novel basis vector to adaptively learn behavior patterns and capture the variation of lag and cycle across multi-scale temporal contexts. We also extend MAPer to capture the interaction among multiple behaviors to improve the prediction performance. We demonstrate the effectiveness of MAPer on four real datasets representing different behavior domains, including, habitual behavior collected from Twitter, need based behavior collected from search logs, and activities of daily living collected from a single resident and a multi-resident home. Experimental results indicate that MAPer significantly improves upon the state-of-the-art and baseline methods and at the same time is able to explain the temporal dynamics of individual-level human behavior.",2015,Conference on Information and Knowledge Management,time series;data mining;artificial intelligence;simulation;statistics;computer science;
Improving Latent Factor Models via Personalized Feature Projection for One Class Recommendation,"Tong Zhao (The Chinese University of Hong Kong);Julian J. McAuley (University of California, San Diego);Irwin King (The Chinese University of Hong Kong);","2689099768,2041520510,2121363826","Latent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users' and items' latent factors to be of the same size and use an inner product to represent a user's ""compatibility"" with an item. Intuitively, users' factors encode ""preferences"" while item factors encode ""properties"", so that the inner product encodes how well an item matches a user's preferences. However, a user's opinion of an item may be more complex, for example each dimension of each user's opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user's preference as a personalized projection of an item's properties so that the preference model can capture complex relationships between items' properties and users' preferences. Therefore, in this paper we propose a novel personalized feature projection method to model users' preferences over items. Specifically, for each user, we define a personalized projection matrix, which takes the place of user-specific factors from existing models. This matrix describes a mapping between items' factors and users' preferences in order to build personalized preference models for each user and item. The proposed personalized feature projection method is quite general and existing latent factor models, for example, can be cast as a special case. We present three objective functions to optimize predictions in the form of ranked lists of users' preferences over items, and demonstrate how each can be used to improve one-class recommendation performance. Experiments are conducted on four real-world datasets and our results show that our personalized feature projection method outperforms several state-of-the-art methods on various evaluation metrics.",2015,Conference on Information and Knowledge Management,collaborative filtering;world wide web;information retrieval;data mining;database;machine learning;computer science;
A Graph-based Recommendation across Heterogeneous Domains,Deqing Yang (Fudan University);Jingrui He (Arizona State University);Huazheng Qin (Fudan University);Yanghua Xiao (Fudan University);Wei Wang (Fudan University);,"2466629964,2685232604,2222106256,2131222654,2296847996","Given the users from a social network site, who have been tagged with a set of terms, how can we recommend the movies tagged with a completely different set of terms hosted by another website? Given the users from a website dedicated to Type I and Type II diabetes, how can we recommend the discussion threads from another website dedicated to gestational diabetes, where the keywords used in the two websites might be quite diverse? In other words, how can we recommend across heterogeneous domains characterized by barely overlapping feature sets? Despite the vast amount of existing work devoted to recommendation within homogeneous domains (e.g., with the same set of features), or collaborative filtering, emerging applications call for new techniques to address the problem of recommendation across heterogeneous domains, such as recommending movies hosted by one website to users from another website with barely overlapping tags. To this end, in this paper, we propose a graph-based approach for recommendation across heterogeneous domains. Specifically, for each domain, we use a bipartite graph to represent the relationships between its entities and features. Furthermore, to bridge the gap among multiple heterogeneous domains with barely overlapping sets of features, we propose to infer their semantic relatedness through concept-based interpretation distilled from online encyclopedias, e.g., Wikipedia and Baike. Finally, we propose an efficient propagation algorithm to obtain the similarity between entities from heterogeneous domains. Experimental results on both Weibo-Douban data set and Diabetes data set demonstrate the effectiveness and efficiency of our algorithm.",2015,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
MF-Tree: Matrix Factorization Tree for Large Multi-Class Learning,Lei Liu (Hewlett-Packard);Pang Ning Tan (Michigan State University);Xi Liu (Michigan State University);,"2434336243,2113230973,2667906179","Many big data applications require accurate classification of objects into one of possibly thousands or millions of categories. Such classification tasks are challenging due to issues such as class imbalance, high testing cost, and model interpretability problems. To overcome these challenges, we propose a novel hierarchical learning method known as MF-Tree to efficiently classify data sets with large number of classes while simultaneously inducing a taxonomy structure that captures relationships among the classes. Unlike many other existing hierarchical learning methods, our approach is designed to optimize a global objective function. We demonstrate the equivalence between our proposed regularized loss function and the Hilbert-Schmidt Independence Criterion (HSIC). The latter has a nice additive property, which allows us to decompose the multi-class learning problem into hierarchical binary classification tasks. To improve its training efficiency, an approximate algorithm for inducing MF-Tree is also proposed. We performed extensive experiments to compare MF-Tree against several state-of-the-art algorithms and showed both its effectiveness and efficiency when applied to real-world data sets.",2015,Conference on Information and Knowledge Management,one class classification;cluster analysis;biological classification;semi supervised learning;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Associative Classification with Statistically Significant Positive and Negative Rules,Jundong Li (University of Alberta);Osmar R. Zaïane (University of Alberta);,"2149809093,2308328903","Rule-based classifier has shown its popularity in building many decision support systems such as medical diagnosis and financial fraud detection. One major advantage is that the models are human understandable and can be edited. Associative classifiers, as an extension of rule-based classifiers, use association rules to associate attributes with class labels. A delicate issue of associative classifiers is the need for subtle thresholds: minimum support and minimum confidence. Without prior knowledge, it could be difficult to choose the proper thresholds, and the discovered rules within the support-confidence framework are not statistically significant, i.e., inclusion of noisy rules and exclusion of valuable rules. Besides, most associative classifiers proposed so far, are built with only positive association rules. Negative rules, however, are also able to provide valuable information to discriminate between classes. To solve the above mentioned problems, we propose a novel associative classifier which is built upon both positive and negative classification association rules that show statistically significant dependencies. Experimental results on real-world datasets show that our method achieves competitive or even better performance than well-known rule-based and associative classifiers in terms of both classification accuracy and computational efficiency.",2015,Conference on Information and Knowledge Management,statistical significance;data mining;pattern recognition;machine learning;statistics;
Unsupervised Feature Selection on Data Streams,Hao Huang (GE Global Research);Shinjae Yoo (Brookhaven National Laboratory);Shiva Prasad Kasiviswanathan (Samsung);,"2223610432,2132315744,239480343","Massive data streams are continuously being generated from sources such as social media, broadcast news, etc., and typically these datapoints lie in high-dimensional spaces (such as the vocabulary space of a language). Timely and accurate feature subset selection in these massive data streams has important applications in model interpretation, computational/storage cost reduction, and generalization enhancement. In this paper, we introduce a novel unsupervised feature selection approach on data streams that selects important features by making only one pass over the data while utilizing limited storage. The proposed algorithm uses ideas from matrix sketching to efficiently maintain a low-rank approximation of the observed data and applies regularized regression on this approximation to identify the important features. We theoretically prove that our algorithm is close to an expensive offline approach based on global singular value decompositions. The experimental results on a variety of text and image datasets demonstrate the excellent ability of our approach to identify important features even in presence of concept drifts and also its efficiency over other popular scalable feature selection algorithms.",2015,Conference on Information and Knowledge Management,streaming algorithm;feature selection;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;computer science;
Probabilistic Forecasts of Bike-Sharing Systems for Journey Planning,Nicolas Gast (French Institute for Research in Computer Science and Automation);Guillaume Massonnet (French Institute for Research in Computer Science and Automation);Daniel Reijsbergen (University of Edinburgh);Mirco Tribastone (IMT Institute for Advanced Studies Lucca);,"2716550952,2721378333,2014022278,2691688528","We study the problem of making forecasts about the future availability of bicycles in stations of a bike-sharing system (BSS). This is relevant in order to make recommendations guaranteeing that the probability that a user will be able to make a journey is sufficiently high. To do this we use probabilistic predictions obtained from a queuing theoretical time-inhomogeneous model of a BSS. The model is parametrized and successfully validated using historical data from the Velib' BSS of the City of Paris. We develop a critique of the standard root-mean-square-error (RMSE), commonly adopted in the bike-sharing research as an index of the prediction accuracy, because it does not account for the stochasticity inherent in the real system. Instead we introduce a new metric based on scoring rules. We evaluate the average score of our model against classical predictors used in the literature. We show that these are outperformed by our model for prediction horizons of up to a few hours. We also discuss that, in general, measuring the current number of available bikes is only relevant for prediction horizons of up to few hours.",2015,Conference on Information and Knowledge Management,operations research;world wide web;data mining;database;artificial intelligence;machine learning;simulation;statistics;
Search Result Diversification Based on Hierarchical Intents,Sha Hu (Renmin University of China);Zhicheng Dou (Renmin University of China);Xiaojie Wang (Renmin University of China);Tetsuya Sakai (Waseda University);Ji Rong Wen (Renmin University of China);,"2158724505,2330149811,2443414991,2655523027,2579522231","A large percentage of queries issued to search engines are broad or ambiguous. Search result diversification aims to solve this problem, by returning diverse results that can fulfill as many different information needs as possible. Most existing intent-aware search result diversification algorithms formulate user intents for a query as a flat list of subtopics. In this paper, we introduce a new hierarchical structure to represent user intents and propose two general hierarchical diversification models to leverage hierarchical intents. Experimental results show that our hierarchical diversification models outperform state-of-the-art diversification methods that use traditional flat subtopics.",2015,Conference on Information and Knowledge Management,data mining;
Ranking Entities for Web Queries Through Text and Knowledge,Michael Schuhmacher (University of Mannheim);Laura Dietz (University of Mannheim);Simone Paolo Ponzetto (University of Mannheim);,"2165387107,2343535024,2252270924","When humans explain complex topics, they naturally talk about involved entities, such as people, locations, or events. In this paper, we aim at automating this process by retrieving and ranking entities that are relevant to understand free-text web-style queries like Argentine British relations, which typically demand a set of heterogeneous entities with no specific target type like, for instance, Falklands_-War} or Margaret-_Thatcher, as answer. Standard approaches to entity retrieval rely purely on features from the knowledge base. We approach the problem from the opposite direction, namely by analyzing web documents that are found to be query-relevant. Our approach hinges on entity linking technology that identifies entity mentions and links them to a knowledge base like Wikipedia. We use a learning-to-rank approach and study different features that use documents, entity mentions, and knowledge base entities -- thus bridging document and entity retrieval. Since established benchmarks for this problem do not exist, we use TREC test collections for document ranking and collect custom relevance judgments for entities. Experiments on TREC Robust04 and TREC Web13/14 data show that: i) single entity features, like the frequency of occurrence within the top-ranke documents, or the query retrieval score against a knowledge base, perform generally well; ii) the best overall performance is achieved when combining different features that relate an entity to the query, its document mentions, and its knowledge base representation.",2015,Conference on Information and Knowledge Management,weak entity;entity;entity linking;information retrieval;data mining;database;computer science;
Query Auto-Completion for Rare Prefixes,Bhaskar Mitra (Microsoft);Nick Craswell (Microsoft);,"2229276239,2009495402","Query auto-completion (QAC) systems typically suggest queries that have previously been observed in search logs. Given a partial user query, the system looks up this query prefix against a precomputed set of candidates, then orders them using ranking signals such as popularity. Such systems can only recommend queries for prefixes that have been previously seen by the search engine with adequate frequency. They fail to recommend if the prefix is sufficiently rare such that it has no matches in the precomputed candidate set. We propose a design of a QAC system that can suggest completions for rare query prefixes. In particular, we describe a candidate generation approach using frequently observed query suffixes mined from historical search logs. We then describe a supervised model for ranking these synthetic suggestions alongside the traditional full-query candidates. We further explore ranking signals that are appropriate for both types of candidates based on n -gram statistics and a convolutional latent semantic model (CLSM). Within our supervised framework the new features demonstrate significant improvements in performance over the popularity-based baseline. The synthetic query suggestions complement the existing popularity-based approach, helping users formulate rare queries.",2015,Conference on Information and Knowledge Management,ranking;range query;sargable;web search query;web query classification;spatial query;query expansion;query optimization;query language;world wide web;information retrieval;data mining;database;machine learning;computer science;
HDRF: Stream-Based Partitioning for Power-Law Graphs,Fabio Petroni (Sapienza University of Rome);Leonardo Querzoni (Sapienza University of Rome);Khuzaima Daudjee (David R. Cheriton School of Computer Science);Shahin Kamali (David R. Cheriton School of Computer Science);Giorgio Iacoboni (Sapienza University of Rome);,"2040829290,2087835387,426341526,2147104284,2231298960","Balanced graph partitioning is a fundamental problem that is receiving growing attention with the emergence of distributed graph-computing (DGC) frameworks. In these frameworks, the partitioning strategy plays an important role since it drives the communication cost and the workload balance among computing nodes, thereby affecting system performance. However, existing solutions only partially exploit a key characteristic of natural graphs commonly found in the real-world: their highly skewed power-law degree distributions. In this paper, we propose High-Degree (are) Replicated First ( HDRF ), a novel streaming vertex-cut graph partitioning algorithm that effectively exploits skewed degree distributions by explicitly taking into account vertex degree in the placement decision. We analytically and experimentally evaluate HDRF on both synthetic and real-world graphs and show that it outperforms all existing algorithms in partitioning quality.",2015,Conference on Information and Knowledge Management,streaming algorithm;load balancing;graph partition;replication;theoretical computer science;distributed computing;database;real time computing;machine learning;computer science;
A Convolutional Click Prediction Model,Qiang Liu (Chinese Academy of Sciences);Feng Yu (Chinese Academy of Sciences);Shu Wu (Chinese Academy of Sciences);Liang Wang (Chinese Academy of Sciences);,"2698910997,2651542687,2122580694,2226151461","The explosion in online advertisement urges to better estimate the click prediction of ads. For click prediction on single ad impression, we have access to pairwise relevance among elements in an impression, but not to global interaction among key features of elements. Moreover, the existing method on sequential click prediction treats propagation unchangeable for different time intervals. In this work, we propose a novel model, Convolutional Click Prediction Model (CCPM), based on convolution neural network. CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression. Experiment results on two public large-scale datasets indicate that CCPM is effective on click prediction.",2015,Conference on Information and Knowledge Management,speech recognition;artificial intelligence;machine learning;computer science;
BiasWatch: A Lightweight System for Discovering and Tracking Topic-Sensitive Opinion Bias in Social Media,Haokai Lu (Texas A&M University);James Caverlee (Texas A&M University);Wei Niu (Texas A&M University);,"2305711674,2028974103,2232381592","We propose a lightweight system for (i) semi-automatically discovering and tracking bias themes associated with opposing sides of a topic; (ii) identifying strong partisans who drive the online discussion; and (iii) inferring the opinion bias of ""regular"" participants. By taking just two hand-picked seeds to characterize the topic-space (e.g., ""pro-choice"" and ""pro-life"") as weak labels , we develop an efficient optimization-based opinion bias propagation method over the social/information network. We show how this approach leads to a 20% accuracy improvement versus a next-best alternative for bias estimation, as well as uncovering the opinion leaders and evolving themes associated with these topics. We also demonstrate how the inferred opinion bias can be integrated into user recommendation, leading to a 26% improvement in precision.",2015,Conference on Information and Knowledge Management,social media;bias;world wide web;data mining;computer science;
Answering Questions with Complex Semantic Constraints on Open Knowledge Bases,Pengcheng Yin (University of Hong Kong);Nan Duan (Microsoft);Ben Kao (University of Hong Kong);Junwei Bao (Harbin Institute of Technology);Ming Zhou (Microsoft);,"2663988108,2148648456,1911907851,2234567019,2143584880","A knowledge-based question-answering system (KB-QA) is one that answers natural language questions with information stored in a large-scale knowledge base ( KB ). Existing KB-QA systems are either powered by curated KBs in which factual knowledge is encoded in entities and relations with well-structured schemas, or by open KBs , which contain assertions represented in the form of triples (e.g., subject; relation phrase; argument ). We show that both approaches fall short in answering questions with complex prepositional or adverbial constraints. We propose using n-tuple assertions, which are assertions with an arbitrary number of arguments, and n -tuple open KB (nOKB), which is an open knowledge base of n -tuple assertions. We present TAQA, a novel KB-QA system that is based on an nOKB and illustrate via experiments how TAQA can effectively answer complex questions with rich semantic constraints. Our work also results in a new open KB containing 120M n -tuple assertions and a collection of 300 labeled complex questions, which is made publicly available for further research.",2015,Conference on Information and Knowledge Management,question answering;knowledge base;natural language processing;world wide web;data mining;database;computer science;
TriRank: Review-aware Explainable Recommendation by Modeling Aspects,Xiangnan He (National University of Singapore);Tao Chen (National University of Singapore);Min-Yen Kan (National University of Singapore);Xiao Chen (Chinese Academy of Sciences);,"2155461083,2679931616,2146273806,2681354411","Most existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions.",2015,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
Co-clustering Document-term Matrices by Direct Maximization of Graph Modularity,Melissa Ailem (Paris Descartes University);François Role (Paris Descartes University);Mohamed Nadif (Paris Descartes University);,"2225297926,1992980393,21121672","We present Coclus, a novel diagonal co-clustering algorithm which is able to effectively co-cluster binary or contingency matrices by directly maximizing an adapted version of the modularity measure traditionally used for networks. While some effective co-clustering algorithms already exist that use network-related measures (normalized cut, modularity), they do so by using spectral relaxations of the discrete optimization problems. In contrast, Coclus allows to get even better co-clusters by directly maximizing modularity using an iterative alternating optimization procedure. Extensive comparative experiments performed on various document-term datasets demonstrate that our algorithm is very effective, stable and outperforms other co-clustering algorithms.",2015,Conference on Information and Knowledge Management,modularity;modularity;machine learning;mathematical optimization;computer science;
Partially Labeled Data Tuple Can Optimize Multivariate Performance Measures,Jim Jing-Yan Wang (King Abdullah University of Science and Technology);Xin Gao (King Abdullah University of Science and Technology);,"2293273053,2504554750","Multivariate performance measure optimization refers to learning predictive models such that a desired complex performance measure can be optimized over a training set, such as the F1 score. Up to now, all the existing multivariate performance measure optimization methods are limited to a completely labeled data tuple, i.e., the label tuple is complete. However, in real-world applications, sometimes it is difficult to obtain a complete label tuple. In this paper, we show that the multivariate performance measures can also be optimized by learning from partially labeled data tuple, when the label tuple is incomplete. We introduce a slack label tuple to represent the sought complete true label tuple, and learn it jointly with a hyper predictor, so that it can be consistent to the known labels, prediction results, and is smooth in the neighborhood. We develop an iterative learning algorithm to learn the slack label tuple and the hyper predictor. Its advantage over state-of-the-art multivariate performance measure optimization methods is shown by experiments on benchmark data sets.",2015,Conference on Information and Knowledge Management,data mining;machine learning;algorithm;
The Role of Query Sessions in Interpreting Compound Noun Phrases,Marius Pasca (Google);,1892622091,"The meaning of compound noun phrases can be approximated in the form of lexical interpretations extracted from text. The interpretations hint at the role that modifiers play relative to heads within the noun phrases. In a study examining the role of query sessions in explaining compound noun phrases, candidate interpretations of compound noun phrases are extracted from pairs of queries that belong to the same query session. Experimental results over multiple evaluation sets of noun phrases show a higher accuracy of the interpretations when extracted from query sessions rather than from individual queries.",2015,Conference on Information and Knowledge Management,specifier;noun phrase;noun;natural language processing;computer science;
Characterizing and Predicting Viral-and-Popular Video Content,David Vallet (NICTA);Shlomo Berkovsky (Commonwealth Scientific and Industrial Research Organisation);Sebastien Ardon (NICTA);Anirban Mahanti (NICTA);Mohamed Ali Kafaar (NICTA);,"2482052293,86410884,2590868965,2166267501,2223366520","The proliferation of online video content has triggered numerous works on its evolution and popularity, as well as on the effect of social sharing on content propagation. In this paper, we focus on the observable dependencies between the virality of video content on a micro-blogging social network (in this case, Twitter) and the popularity of such content on a video distribution service (YouTube). To this end, we collected and analysed a corpus of Twitter posts containing links to YouTube clips and the corresponding video meta-data from YouTube. Our analysis highlights the unique properties of content that is both popular and viral, which allows such content to attract high number of views on YouTube and achieve fast propagation on Twitter. With this in mind, we proceed to the predictions of popular-and-viral clips and propose a framework that can, with high degree of accuracy and low amount of training data, predict videos that are likely to be popular, viral, and both. The key contribution of our work is the focus on cross-system dynamics between YouTube and Twitter. We conjecture and validate that cross-system prediction of both popularity and virality of videos is feasible, and can be performed with a reasonably high degree of accuracy. One of our key findings is that YouTube features capturing user engagement, have strong virality prediction capabilities. This findings allows to solely rely on data extracted from a video sharing service to predict popularity and virality aspects of videos.",2015,Conference on Information and Knowledge Management,video;internet privacy;multimedia;world wide web;computer science;
Location-Based Influence Maximization in Social Networks,Tao Zhou (Southeast University);Jiuxin Cao (Southeast University);Bo Liu (Southeast University);Shuai Xu (Southeast University);Ziqing Zhu (Southeast University);Junzhou Luo (Southeast University);,"2716860880,2138849195,2496448393,2656403675,2148525374,2101356858","In this paper, we aim at the product promotion in O2O model and carry out the research of location-based influence maximization on the platform of LBSN. As offline consuming behavior exists under the O2O environment, the traditional online influence diffusion model could not describe the product acceptance accurately. Moreover, the existing researches of influence maximization tend to only concern on the online network of relationships but rarely take the offline part into consideration. This paper introduces the location property into the influence maximization to accord with the characteristic of O2O model. Firstly, we propose an improved influence diffusion model called TP Model which could accurately describe the process of accepting products under the O2O environment. Meanwhile, the definition of location-based influence maximization is presented. Then the user mobility pattern is analyzed and the calculation method of offline probability is designed. Considering the influence ability, a location-based influence maximization algorithm named TPH is proposed. Experiments prove TPH algorithm has general advantage. Finally, focusing on the performance of TPH algorithm under special circumstances, MR algorithm is designed as complement and experiments also verify its high effectiveness.",2015,Conference on Information and Knowledge Management,diffusion;social network;data mining;artificial intelligence;machine learning;simulation;
"Query Length, Retrievability Bias and Performance",Colin Wilkie (University of Glasgow);Leif Azzopardi (University of Glasgow);,"2098928293,2163026013","Past work has shown that longer queries tend to lead to better retrieval performance. However, this comes at the cost of increased user effort effort and additional system processing. In this paper, we examine whether there are benefits of longer queries beyond performance. We posit that increasing the query length will also lead to a reduction in the retrievability bias. Additionally, we speculate that to minimise retrievability bias as queries become longer, more length normalisation must be applied to account for the increase in the length of documents retrieved. To this end, we perform a retrievability analysis on two TREC collections using three standard retrieval models and various lengths of queries (one to five terms). From this investigation we find that increasing the length of queries reduces the overall retrievability bias but at a decreasing rate. Moreover, once the query length exceeds three terms the bias can begin to increase (and the performance can start to drop). We also observe that more document length normalisation is typically required as query length increases, in order to minimise bias. Finally, we show that there is a strong correlation between performance and retrieval bias. This work raises some interesting questions regarding query length and its affect on performance and bias. Further work will be directed towards examining longer and more verbose queries, including those generated via query expansion methods, to obtain a more comprehensive understanding of the relationship between query length, performance and retrievability bias.",2015,Conference on Information and Knowledge Management,retrievability;evaluation;performance;world wide web;information retrieval;data mining;computer science;
Toward Dual Roles of Users in Recommender Systems,Suhang Wang (Arizona State University);Jiliang Tang (Arizona State University);Huan Liu (Arizona State University);,"2122735199,2147392410,2122391114","Users usually play dual roles in real-world recommender systems. One is as a reviewer who writes reviews for items with rating scores, and the other is as a rater who rates the helpfulness scores of reviews. Traditional recommender systems mainly consider the reviewer role while not taking into account the rater role. However, the rater role allows users to express their opinions toward reviews about items; hence it may indirectly indicate their opinions about items, which could be complementary to the reviewer role. Since most real-world recommender systems provide convenient mechanisms for the rater role, recent studies show that typically there are much more helpfulness ratings from the rater role than item ratings from the reviewer role. Therefore, incorporating the rater role of users may have the potentials to mitigate the data sparsity and cold-start problems in traditional recommender systems. In this paper, we investigate how to exploit dual roles of users in recommender systems. In particular, we provide a principled way to exploit the rater role mathematically and propose a novel recommender system DualRec, which captures both the reviewer role and the rater role of users simultaneously for recommendation. Experimental results on two real world datasets demonstrate the effectiveness of the proposed framework, and further experiments are conducted to understand the importance of the rater role of users in recommendation.",2015,Conference on Information and Knowledge Management,cold start;collaborative filtering;multimedia;world wide web;machine learning;computer science;
Message Clustering based Matrix Factorization Model for Retweeting Behavior Prediction,Bo Jiang (Chinese Academy of Sciences);Jiguang Liang (Chinese Academy of Sciences);Ying Sha (Chinese Academy of Sciences);Lihong Wang (Chinese Academy of Sciences);,"2648956405,2688756401,2161320450,2562931221","Retweeting is an important mechanism for information diffusion in social networks. Through retweeting, message is reshared from one user to another user, forming large cascades of message forwarding. Most existing researches of predicting retweeting utilize user social relationships for modeling which leads to vast calculating amount. In this paper, we propose two message clustering based matrix factorization models for retweeting prediction. Unlike previous approaches, our models exploit the clustering relationships of messages instead of social relationships. Our models are quite general because we do not need any auxiliary information except for message content. Several experiments on real datasets show that our models are effective and outperform the state-of-the-art methods.",2015,Conference on Information and Knowledge Management,matrix decomposition;cluster analysis;theoretical computer science;data mining;machine learning;computer science;
Ranking Deep Web Text Collections for Scalable Information Extraction,Pablo Barrio (Columbia University);Luis Gravano (Columbia University);Chris Develder (Ghent University);,"2224102567,2251396636,2037926187","Information extraction (IE) systems discover structured information from natural language text, to enable much richer querying and data mining than possible directly over the unstructured text. Unfortunately, IE is generally a computationally expensive process, and hence improving its efficiency, so that it scales over large volumes of text, is of critical importance. State-of-the-art approaches for scaling the IE process focus on one text collection at a time. These approaches prioritize the extraction effort by learning keyword queries to identify the ""useful"" documents for the IE task at hand, namely, those that lead to the extraction of structured ""tuples."" These approaches, however, do not attempt to predict which text collections are useful for the IE task---and hence merit further processing---and which ones will not contribute any useful output---and hence should be ignored altogether, for efficiency. In this paper, we focus on an especially valuable family of text sources, the so-called deep web collections, whose (remote) contents are only accessible via querying. Specifically, we introduce and study techniques for ranking deep web collections for an IE task, to prioritize the extraction effort by focusing on collections with substantial numbers of useful documents for the task. We study both (adaptations of) state-of-the-art resource selection strategies for distributed information retrieval, and IE-specific approaches. Our extensive experimental evaluation over realistic deep web collections, and for several different IE tasks, shows the merits and limitations of the alternative families of approaches, and provides a roadmap for addressing this critically important building block for efficient, scalable information extraction.",2015,Conference on Information and Knowledge Management,scalability;efficiency;relationship extraction;information extraction;world wide web;information retrieval;data mining;database;computer science;
Implementing Query Completeness Reasoning,Werner Nutt (Free University of Bozen-Bolzano);Sergey Paramonov (Katholieke Universiteit Leuven);Ognjen Savkovic (Free University of Bozen-Bolzano);,"1905000215,2232029774,669351657","Data completeness is commonly regarded as one of the key aspects of data quality. With this paper we make two main contributions: (i) we develop techniques to reason about the completeness of a query answer over a partially complete database, taking into account constraints that hold over the database, and (ii) we implement them by an encoding into logic programming paradigms. As constraints we consider primary and foreign keys as well as finite domain constraints. In this way we can identify more situations in which a query is complete than was possible with previous work. For each combination of constraints, we establish characterizations of the completeness reasoning and we show how to translate them into logic programs. As a proof of concept we ran our encodings against test cases that capture characteristics of a real-world scenario.",2015,Conference on Information and Knowledge Management,answer set programming;logic programming;data quality;data mining;database;artificial intelligence;programming language;algorithm;computer science;
Identifying Top- k Structural Hole Spanners in Large-Scale Social Networks,Mojtaba Rezvani (Australian National University);Weifa Liang (Australian National University);Wenzheng Xu (Sichuan University);Chengfei Liu (Swinburne University of Technology);,"2409102697,2133400326,2131825046,2144108974","Recent studies have shown that in social networks, users who bridge different communities, known as structural hole spanners, have great potentials to acquire available resources from these communities and gain access to multiple sources of information flow. Structural hole spanners are crucial in many applications such as community detections, diffusion controls, and viral marketing. In spite of their importance, not much attention has been paid to them. Particularly, how to characterize the structural hole spanner properties and how to devise efficient yet scalable algorithms to find them are fundamental issues. In this paper, we formulate the problem as the top- k structural hole spanner problem. Specifically, we first provide a generic model to measure the quality of structural hole spanners, by exploring their properties, and show that the problem is NP-hard. We then devise efficient and scalable algorithms, by exploiting the bounded inverse closeness centralities of vertices and making use of articulation points of the network. We finally evaluate the performance of the proposed algorithms through extensive experiments on real and synthetic datasets, and validate the effectiveness of the proposed model. Our experimental results demonstrate that the proposed model can capture the characteristics of structural hole spanners accurately, and the proposed algorithms are very promising.",2015,Conference on Information and Knowledge Management,biconnected component;social network;machine learning;mathematical optimization;
Contextual Text Understanding in Distributional Semantic Space,Jianpeng Cheng (Microsoft);Zhongyuan Wang (Renmin University of China);Ji-Rong Wen (Renmin University of China);Jun Yan (Microsoft);Zheng Chen (Microsoft);,"2639351597,2585510981,2593770520,2150635322,2425877144","Representing discrete words in a continuous vector space turns out to be useful for natural language applications related to text understanding. Meanwhile, it poses extensive challenges, one of which is due to the polysemous nature of human language. A common solution (a.k.a word sense induction) is to separate each word into multiple senses and create a representation for each sense respectively. However, this approach is usually computationally expensive and prone to data sparsity, since each sense needs to be managed discriminatively. In this work, we propose a new framework for generating context-aware text representations without diving into the sense space. We model the concept space shared among senses, resulting in a framework that is efficient in both computation and storage. Specifically, the framework we propose is one that: i) projects both words and concepts into the same vector space; ii) obtains unambiguous word representations that not only preserve the uniqueness among words, but also reflect their context-appropriate meanings. We demonstrate the effectiveness of the framework in a number of tasks on text understanding, including word/phrase similarity measurements, paraphrase identification and question-answer relatedness classification.",2015,Conference on Information and Knowledge Management,semeval;computational linguistics;natural language processing;speech recognition;data mining;artificial intelligence;machine learning;computer science;
Experiments with a Venue-Centric Model for Personalisedand Time-Aware Venue Suggestion,Romain Deveaud (University of Avignon);M-Dyaa Albakour (University of Essex);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"314381667,209705036,2148910894,336997814","Location-based social networks (LBSNs), such as Foursquare, fostered the emergence of new tasks such as recommending venues a user might wish to visit. In the literature, recommending venues has typically been addressed using user-centric recommendation approaches relying on collaborative filtering techniques. Such approaches not only require many users with detailed profiles to be effective, but they also cannot recommend venues to users who are not actually members of the LBSN. In contrast, in this paper, we introduce a venue-centric yet personalised probabilistic approach that suggests personalised and popular venues for users to visit in the near future. In our approach, we probabilistically incorporate two components, a popularity component for predicting the popularity of a venue at a given point in time, as estimated from the attendance of the venue in the LBSN (i.e. number of check-ins), and a personalisation component for identifying its interestingness with respect to the estimated preferences of the user. The popularity of each venue is predicted using time series forecasting models that are trained on the recent attendance trends of the venue, while the users' interests are modelled from the entity pages that they like on Facebook. Using three major cities, we conduct a user study to evaluate the effectiveness of the two components of our approach in suggesting venues for different types of users at different times of the day. Our experimental results show that an approach that combines the popularity and personalisation components is able to consistently outperform the recommendation service of the leading Foursquare LBSN. We also find that combining popularity and personalisation is effective for both new visitors and residents, while former visitors prefer popular venues.",2015,Conference on Information and Knowledge Management,personalization;time series;multimedia;world wide web;data mining;statistics;
Inclusion Dependencies Reloaded,Henning Köhler (Massey University);Sebastian Link (University of Auckland);,"2686789357,2095647292","Inclusion dependencies form one of the most fundamental classes of integrity constraints. Their importance in classical data management is reinforced by modern applications such as data cleaning and profiling, entity resolution and schema matching. Surprisingly, the implication problem of inclusion dependencies has not been investigated in the context of SQL, the de-facto industry standard. Codd's relational model of data represents the idealized special case of SQL in which all attributes are declared NOT NULL. Driven by the SQL standard recommendation, we investigate inclusion dependencies and NOT NULL constraints under simple and partial semantics. Partial semantics is not natively supported by any SQL implementation but we show how classical results on the implication problem carry over into this context. Interestingly, simple semantics is natively supported by every SQL implementation, but we show that the implication problem is not finitely axiomatizable in this context. Resolving this conundrum we establish an optimal solution by identifying the desirable class of not-null inclusion dependencies (NNINDs) that subsumes simple and partial semantics as special cases, and whose associated implication problem has the same computational properties as inclusion dependencies in the relational model. That is, NNIND implication is 2-ary axiomatizable and PSPACE-complete to decide. Our proof techniques bring also forward a chase procedure for deciding NNIND implication, the NP-hard subclass of typed acyclic NNINDs, and the tractable subclasses of NNINDs whose arity is bounded.",2015,Conference on Information and Knowledge Management,dependency theory;null;sql;computational complexity theory;semantics;theoretical computer science;data mining;database;algorithm;computer science;
Improving Ranking Consistency for Web Search by Leveraging a Knowledge Base and Search Logs,Jyun-Yu Jiang (National Taiwan University);Jing Liu (Microsoft);Chin-Yew Lin (Microsoft);Pu-Jen Cheng (National Taiwan University);,"2230297831,2701242056,2159460278,2138985046","In this paper, we propose a new idea called ranking consistency in web search. Relevance ranking is one of the biggest problems in creating an effective web search system. Given some queries with similar search intents, conventional approaches typically only optimize ranking models by each query separately. Hence, there are inconsistent rankings in modern search engines. It is expected that the search results of different queries with similar search intents should preserve ranking consistency. The aim of this paper is to learn consistent rankings in search results for improving the relevance ranking in web search. We then propose a re-ranking model aiming to simultaneously improve relevance ranking and ranking consistency by leveraging knowledge bases and search logs. To the best of our knowledge, our work offers the first solution to improving relevance rankings with ranking consistency. Extensive experiments have been conducted using the Freebase knowledge base and the large-scale query-log of a commercial search engine. The experimental results show that our approach significantly improves relevance ranking and ranking consistency. Two user surveys on Amazon Mechanical Turk also show that users are sensitive and prefer the consistent ranking results generated by our model.",2015,Conference on Information and Knowledge Management,ranking;ranking svm;okapi bm25;world wide web;information retrieval;data mining;computer science;
Mining Coordinated Intent Representation for Entity Search and Recommendation,Huizhong Duan (Walmart Labs);Cheng Xiang Zhai (University of Illinois at Urbana–Champaign);,"2110991831,2152766206","We study the problem of learning query intent representation for an entity search task such as product retrieval, where a user would use a keyword query to retrieve entities based on their structured attribute value descriptions. Existing intent representation has been mostly based on the query space. These methods overlook the critical information from the entity space and the connection in between. Consequently, when such representation methods are used in intent mining from user engagement logs in entity search, they cannot fully discover the comprehensive knowledge of user preference, which is essential for improving the effectiveness of entity search and recommendation, as well as many applications such as business intelligence. To address this problem, we propose a novel Coordinated Intent Representation, where each user intent is represented collectively in both the query space and the entity space. Specifically, a coordinated intent representation consists of a language model to capture typical query terms used for search and a series of probabilistic distributions on entity attributes and attribute values to characterize the preferred features of entities for the corresponding intent. We propose a novel generative model to discover coordinated intent representations from the entity search logs. Evaluation in the domain of product search shows that the proposed model is effective for discovering meaningful coordinated shopping intents, and the discovered intent representation can be directly used for improving the accuracy of product search and recommendation.",2015,Conference on Information and Knowledge Management,semantic search;data science;information retrieval;data mining;database;computer science;
A Min-Max Optimization Framework For Online Graph Classification,"Peng Yang (Agency for Science, Technology and Research);Peilin Zhao (Agency for Science, Technology and Research);","2705151546,2096910461","Traditional online learning for graph node classification adapts graph regularization into ridge regression, which may not be suitable when data is adversarially generated. To solve this issue, we propose a more general min-max optimization framework for online graph node classification. The derived online algorithm can achieve a min-max regret compared with the optimal linear model found offline. However, this algorithm assumes that the label is provided for every node, while label is scare and labeling is usually either too time-consuming or expensive in real-world applications. To save labeling effort, we propose a novel confidence-based query approach to prioritize the informative labels. Our theoretical result shows that an online algorithm learning on these selected labels can achieve comparable mistake bound with the fully-supervised online counterpart. To take full advantage of these labels, we propose an aggressive algorithm, which can update the model even if no error occurs. Theoretical analysis shows that the mistake bound of the proposed method, thanks to the aggressive update trials, is better than conservative competitor in expectation. We finally empirically evaluate it on several real-world graph databases. Encouraging experimental results further demonstrate the effectiveness of our method.",2015,Conference on Information and Knowledge Management,sampling;theoretical computer science;world wide web;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Core-Sets For Canonical Correlation Analysis,Saurabh Paul (Rensselaer Polytechnic Institute);,2169921149,"Canonical Correlation Analysis (CCA) is a technique that finds how ""similar"" are the subspaces that are spanned by the columns of two different matrices A έℜ(of size m-x-n ) and B έℜ(of size m-x-l ). CCA measures similarity by means of the cosines of the so-called principal angles between the two subspaces. Those values are also known as canonical correlations of the matrix pair ( A,B ). In this work, we consider the over-constrained case where the number of rows is greater than the number of columns ( m > max( n,l )). We study the problem of constructing ""core-sets"" for CCA. A core-set is a subset of rows from A and the corresponding subset of rows from B - denoted by Â and B , respectively. A ""good"" core-set is a subset of rows such that the canonical correlations of the core-set ( Â , B ) are ""close"" to the canonical correlations of the original matrix pair ( A, B ). There is a natural tradeoff between the core-set size and the approximation accuracy of a core-set. We present two algorithms namely, single-set spectral sparsification and leverage-score sampling, which find core-sets with additive-error guarantees to canonical correlations.",2015,Conference on Information and Knowledge Management,canonical analysis;canonical correlation;dimensionality reduction;sampling;machine learning;statistics;computer science;
Node Immunization over Infectious Period,Chonggang Song (National University of Singapore);Wynne Hsu (National University of Singapore);Mong Li Lee (National University of Singapore);,"2225645568,2123778117,2159408573","Locating nodes to immunize in computer/social networks to control the spread of virus or rumors has become an important problem. In real world contagions, nodes may get infected by external sources when the propagation is underway. While most studies formalize the problem in a setting where contagion starts at one time point, we model a more realistic situation where there are likely to be many breakouts of contagions over a time window. We call this the node immunization over infectious period (NIIP) problem. We show that the NIIP problem is NP-hard and remains so even in directed acyclic graphs. We propose a NIIP algorithm to select $k$ nodes to immunize over a time period. Simulation is performed to estimate a good distribution of $k$ over the time period. For each time point, the NIIP algorithm will make decisions which nodes to immunize given the estimated value of $k$ for that time point. Experiments show that the proposed NIIP algorithm outperform the state-of-the-art algorithms in terms of both effectiveness and efficiency.",2015,Conference on Information and Knowledge Management,social network;telecommunications;simulation;
Social-Relational Topic Model for Social Networks,Weiyu Guo (Chinese Academy of Sciences);Shu Wu (Chinese Academy of Sciences);Liang Wang (Chinese Academy of Sciences);Tieniu Tan (Chinese Academy of Sciences);,"2125651078,2122580694,2226151461,2120394816","Social networking services, such as Twitter and Sina Weibo, have tremendous popularity in recent years. Mass of short texts and social links are aggregated into these service platforms. To realize personalized services on social network, topic inference from both short texts and social links plays more and more important role. Most conventional topic modeling methods focus on analyzing formal texts, e.g., papers, news and blogs, and usually assume that the links are only generated by topical factors. As a result, on social network, the learned topics of these methods are usually affected by topic-irrelevant links. Recently, a few approaches use artificial priors to recognize the links generated by the popularity factor in topic modeling. However, employing global priors, these methods can not well capture the distinct properties of each link and still suffer from the effect of topic-irrelevant links. To address the above limitations, we propose a novel Social-Relational Topic Model (SRTM), which can alleviate the effect of topic-irrelevant links by analyzing relational users' topics of each link. SRTM jointly models texts and social links for learning the topic distribution and topical influence of each user. The experimental results show that, our model outperforms the state-of-the-arts in topic modeling and social link prediction.",2015,Conference on Information and Knowledge Management,topic model;social network;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Efficient Computation of Polynomial Explanations of Why-Not Questions,Nicole Bidoit (French Institute for Research in Computer Science and Automation);Melanie Herschel (University of Stuttgart);Aikaterini Tzompanaki (French Institute for Research in Computer Science and Automation);,"33344769,2158630827,2226761697","Answering a Why-Not question consists in explaining why a query result does not contain some expected data, called missing answers. This paper focuses on processing Why-Not questions in a query-based approach that identifies the culprit query components. Our first contribution is a general definition of a Why-Not explanation by means of a polynomial. Intuitively, the polynomial provides all possible explanations to explore in order to recover the missing answers, together with an estimation of the number of recoverable answers. Moreover, this formalism allows us to represent Why-Not explanations in a unified way for extended relational models with probabilistic or bag semantics. We further present an algorithm to efficiently compute the polynomial for a given Why-Not question. An experimental evaluation demonstrates the practicality of the solution both in terms of efficiency and explanation quality, compared to existing algorithms.",2015,Conference on Information and Knowledge Management,theoretical computer science;data mining;database;machine learning;algorithm;
Semi-Automated Text Classification for Sensitivity Identification,Giacomo Berardi (Istituto di Scienza e Tecnologie dell'Informazione);Andrea Esuli (Istituto di Scienza e Tecnologie dell'Informazione);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);Fabrizio Sebastiani (Qatar Computing Research Institute);,"2162836066,97551770,2148910894,336997814,2130902957","Sensitive documents are those that cannot be made public, e.g., for personal or organizational privacy reasons. For instance, documents requested through Freedom of Information mechanisms must be manually reviewed for the presence of sensitive information before their actual release. Hence, tools that can assist human reviewers in spotting sensitive information are of great value to government organizations subject to Freedom of Information laws. We look at sensitivity identification in terms of semi-automated text classification (SATC), the task of ranking automatically classified documents so as to optimize the cost-effectiveness of human post-checking work. We use a recently proposed utility-theoretic approach to SATC that explicitly optimizes the chosen effectiveness function when ranking the documents by sensitivity; this is especially useful in our case, since sensitivity identification is a recall-oriented task, thus requiring the use of a recall-oriented evaluation measure such as F 2 . We show the validity of this approach by running experiments on a multi-label multi-class dataset of government documents manually annotated according to different types of sensitivity.",2015,Conference on Information and Knowledge Management,information sensitivity;world wide web;information retrieval;data mining;database;machine learning;computer science;
Modeling Individual-Level Infection Dynamics Using Social Network Information,Suppawong Tuarob (Pennsylvania State University);Conrad S. Tucker (Pennsylvania State University);Marcel Salathe (Pennsylvania State University);Nilam Ram (Pennsylvania State University);,"206342214,2099240893,2284353421,2041064628","Epidemic monitoring systems engaged in accurate discovery of infected individuals enable better understanding of the dynamics of epidemics and thus may promote effective disease mitigation or prevention. Currently, infection discovery systems require either physical participation of potential patients or provision of information from hospitals and health-care services. While social media has emerged as an increasingly important knowledge source that reflects multiple real world events, there is only a small literature examining how social media information can be incorporated into computational epidemic models. In this paper, we demonstrate how social media information can be incorporated into and improve upon traditional techniques used to model the dynamics of infectious diseases. Using flu infection histories and social network data collected from 264 students in a college community, we identify social network signals that can aid identification of infected individuals. Extending the traditional SIRS model, we introduce and illustrate the efficacy of an Online-Interaction-Aware Susceptible-Infected-Recovered-Susceptible (OIA-SIRS) model based on four social network signals for modeling infection dynamics. Empirical evaluations of our case study, flu infection within a college community, reveal that the OIA-SIRS model is more accurate than the traditional model, and also closely tracks the real-world infection rates as reported by CDC ILINet and Google Flu Trend.",2015,Conference on Information and Knowledge Management,social network;simulation;computer science;
Cross-Modal Similarity Learning: A Low Rank Bilinear Formulation,Cuicui Kang (Chinese Academy of Sciences);Shengcai Liao (Chinese Academy of Sciences);Yonghao He (Chinese Academy of Sciences);Jian Wang (Chinese Academy of Sciences);Wenjia Niu (Chinese Academy of Sciences);Shiming Xiang (Chinese Academy of Sciences);Chunhong Pan (Chinese Academy of Sciences);,"2097698347,2127548784,2125248606,2677245202,2135491977,1995762524,2114868839","The cross-media retrieval problem has received much attention in recent years due to the rapid increasing of multimedia data on the Internet. A new approach to the problem has been raised which intends to match features of different modalities directly. In this research, there are two critical issues: how to get rid of the heterogeneity between different modalities and how to match the cross-modal features of different dimensions. Recently metric learning methods show a good capability in learning a distance metric to explore the relationship between data points. However, the traditional metric learning algorithms only focus on single-modal features, which suffer difficulties in addressing the cross-modal features of different dimensions. In this paper, we propose a cross-modal similarity learning algorithm for the cross-modal feature matching. The proposed method takes a bilinear formulation, and with the nuclear-norm penalization, it achieves low-rank representation. Accordingly, the accelerated proximal gradient algorithm is successfully imported to find the optimal solution with a fast convergence rate O (1/ t 2 ). Experiments on three well known image-text cross-media retrieval databases show that the proposed method achieves the best performance compared to the state-of-the-art algorithms.",2015,Conference on Information and Knowledge Management,matrix norm;computer vision;pattern recognition;machine learning;mathematical optimization;algorithm;mathematics;
Learning Relative Similarity from Data Streams: Active Online Learning Approaches,"Shuji Hao (Nanyang Technological University);Peilin Zhao (Agency for Science, Technology and Research);Steven C.H. Hoi (Singapore Management University);Chunyan Miao (Nanyang Technological University);","2223900961,2096910461,108406206,2154137932","Relative similarity learning, as an important learning scheme for information retrieval, aims to learn a bi-linear similarity function from a collection of labeled instance-pairs, and the learned function would assign a high similarity value for a similar instance-pair and a low value for a dissimilar pair. Existing algorithms usually assume the labels of all the pairs in data streams are always made available for learning. However, this is not always realistic in practice since the number of possible pairs is quadratic to the number of instances in the database, and manually labeling the pairs could be very costly and time consuming. To overcome the limitation, we propose a novel framework of active online similarity learning. Specifically, we propose two new algorithms: (i)~PAAS: Passive-Aggressive Active Similarity learning; (ii)~CWAS: Confidence-Weighted Active Similarity learning, and we will prove their mistake bounds in theory. We have conducted extensive experiments on a variety of real-world data sets, and we find encouraging results that validate the empirical effectiveness of the proposed algorithms.",2015,Conference on Information and Knowledge Management,online machine learning;stability;preference learning;active learning;generalization error;competitive learning;active learning;algorithmic learning theory;learning classifier system;semi supervised learning;data stream mining;computational learning theory;instance based learning;unsupervised learning;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;computer science;
External Data Access And Indexing In AsterixDB,"Abdullah A. Alamoudi (University of California, Irvine);Raman Grover (University of California, Irvine);Michael J. Carey (University of California, Irvine);Vinayak R. Borkar (University of California, Irvine);","2230809072,2171821552,2157114695,1900516000","Traditional database systems offer rich query interfaces (SQL) and efficient query execution for data that they store. Recent years have seen the rise of Big Data analytics platforms offering query-based access to ""raw"" external data, e.g., file-resident data (often in HDFS). In this paper, we describe techniques to achieve the qualities offered by DBMSs when accessing external data. This work has been built into Apache AsterixDB, an open source Big Data Management System. We describe how we build distributed indexes over external data, partition external indexes, provide query consistency across access paths, and manage external indexes amidst concurrent activities. We compare the performance of this new AsterixDB capability to an external-only solution (Hive) and to its internally managed data and indexes.",2015,Conference on Information and Knowledge Management,search engine indexing;world wide web;information retrieval;data mining;database;computer science;
Comprehensible Models for Reconfiguring Enterprise Relational Databases to Avoid Incidents,Ioana Giurgiu (IBM);Mirela Botezatu (IBM);Dorothea Wiesmann (IBM);,"2203074430,2229656828,2048997920","Configuring enterprise database management systems is a notoriously hard problem. The combinatorial parameter space makes it intractable to run and observe the DBMS behavior in all scenarios. Thus, the database administrator has the difficult task of choosing DBMS configurations that potentially lead to critical incidents, thus hindering its availability or performance. We propose using machine learning to understand how configuring a DBMS can lead to such high risk incidents. We collect historical data from three IT environments that run both IBM DB2 and Oracle DBMS. Then, we implement several linear and non-linear multivariate models to identify and learn from high risk configurations. We analyze their performance, in terms of accuracy, cost, generalization and interpretability. Results show that high risk configurations can be identified with extremely high accuracy and that the database administrator can potentially benefit from the rules extracted to reconfigure in order to prevent incidents.",2015,Conference on Information and Knowledge Management,multivariate analysis;data science;world wide web;data mining;database;artificial intelligence;machine learning;statistics;computer science;
A Soft Computing Approach for Learning to Aggregate Rankings,Javier Alvaro Vargas Muñoz (State University of Campinas);Ricardo da Silva Torres (State University of Campinas);Marcos André Gonçalves (Universidade Federal de Minas Gerais);,"2227353741,2195225068,2115586749","This paper presents an approach to combine rank aggregation techniques using a soft computing technique -- Genetic Programming -- in order to improve the results in Information Retrieval tasks. Previous work shows that by combining rank aggregation techniques in an agglomerative way, it is possible to get better results than with individual methods. However, these works either combine only a small set of lists or are performed in a completely ad-hoc way. Therefore, given a set of ranked lists and a set of rank aggregation techniques, we propose to use a supervised genetic programming approach to search combinations of them that maximize effectiveness in large search spaces. Experimental results conducted using four datasets with different properties show that our proposed approach reaches top performance in most datasets. Moreover, this cross-dataset performance is not matched by any other baseline among the many we experiment with, some being the state-of-the-art in learning-to-rank and in the supervised rank aggregation tasks. We also show that our proposed framework is very efficient, flexible, and scalable.",2015,Conference on Information and Knowledge Management,genetic programming;soft computing;data mining;pattern recognition;machine learning;computer science;
Practical Aspects of Sensitivity in Online Experimentation with User Engagement Metrics,Alexey Drutsa (Yandex);Anna Ufliand (Yandex);Gleb Gusev (Yandex);,"2229408502,2230030394,2005728791","Online controlled experiments, e.g., A/B testing, is the state-of-the-art approach used by modern Internet companies to improve their services based on data-driven decisions. The most challenging problem is to define an appropriate online metric of user behavior, so-called Overall Evaluation Criterion (OEC), which is both interpretable and sensitive. A typical OEC consists of a key metric and an evaluation statistic. Sensitivity of an OEC to the treatment effect of an A/B test is measured by a statistical significance test. We introduce the notion of Overall Acceptance Criterion (OAC) that includes both the components of an OEC and a statistical significance test. While existing studies on A/B tests are mostly concentrated on the first component of an OAC, its key metric, we widely study the two latter ones by comparison of several statistics and several statistical tests with respect to user engagement metrics on hundreds of A/B experiments run on real users of Yandex. We discovered that the application of the state-of-the-art Student's t-tests to several main user engagement metrics may lead to an underestimation of the false-positive rate by an order of magnitude. We investigate both well-known and novel techniques to overcome this issue in practical settings. At last, we propose the entropy and the quantiles as novel OECs that reflect the diversity and extreme cases of user engagement.",2015,Conference on Information and Knowledge Management,p value;sensitivity;statistical significance;world wide web;data mining;database;artificial intelligence;machine learning;simulation;statistics;computer science;
Understanding the Impact of the Role Factor in Collaborative Information Retrieval,Lynda Tamine (University of Toulouse);Laure Soulier (University of Toulouse);,"62726460,1986048695","Collaborative information retrieval systems often rely on division of labor policies. Such policies allow work to be divided among collaborators with the aim of preventing redundancy and optimizing the synergic effects of collaboration. Most of the underlying methods achieve these goals by the means of explicit vs. implicit role-based mediation. In this paper, we investigate whether and how different factors, such as users' behavior, search strategies, and effectiveness, are related to role assignment within a collaborative exploratory search. Our main findings suggest that: (1) spontaneous and cohesive implicit roles might emerge during the collaborative search session implying users with no prior roles, and that these implicit roles favor the search precision, (2) role drift might occur alongside the search session performed by users with prior-assigned roles.",2015,Conference on Information and Knowledge Management,knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Finding Probabilistic k-Skyline Sets on Uncertain Data,Jinfei Liu (Emory University);Haoyu Zhang (Emory University);Li Xiong (Emory University);Haoran Li (Emory University);Jun Luo (Chinese Academy of Sciences);,"2280101196,2292024314,1969262224,2099815881,2705262446","Skyline is a set of points that are not dominated by any other point. Given uncertain objects, probabilistic skyline has been studied which computes objects with high probability of being skyline. While useful for selecting individual objects, it is not sufficient for scenarios where we wish to compute a subset of skyline objects, i.e., a skyline set. In this paper, we generalize the notion of probabilistic skyline to probabilistic k -skyline sets (P k -SkylineSets) which computes k -object sets with high probability of being skyline set. We present an efficient algorithm for computing probabilistic k -skyline sets. It uses two heuristic pruning strategies and a novel data structure based on the classic layered range tree to compute the skyline set probability for each instance set with a worst-case time bound. The experimental results on the real NBA dataset and the synthetic datasets show that P k -SkylineSets is interesting and useful, and our algorithms are efficient and scalable.",2015,Conference on Information and Knowledge Management,probabilistic logic;data mining;database;machine learning;
Multi-view Clustering via Structured Low-rank Representation,Dong Wang (Chinese Academy of Sciences);Qiyue Yin (Chinese Academy of Sciences);Ran He (Chinese Academy of Sciences);Liang Wang (Chinese Academy of Sciences);Tieniu Tan (Chinese Academy of Sciences);,"2721833140,2484020598,2169476276,2226151461,2120394816","In this paper, we present a novel solution to multi-view clustering through a structured low-rank representation. When assuming similar samples can be linearly reconstructed by each other, the resulting representational matrix reflects the cluster structure and should ideally be block diagonal. We first impose low-rank constraint on the representational matrix to encourage better grouping effect. Then representational matrices under different views are allowed to communicate with each other and share their mutual cluster structure information. We develop an effective algorithm inspired by iterative re-weighted least squares for solving our formulation. During the optimization process, the intermediate representational matrix from one view serves as a cluster structure constraint for that from another view. Such mutual structural constraint fine-tunes the cluster structures from both views and makes them more and more agreeable. Extensive empirical study manifests the superiority and efficacy of the proposed method.",2015,Conference on Information and Knowledge Management,data mining;artificial intelligence;machine learning;mathematical optimization;
Gradient-based Signatures for Efficient Similarity Search in Large-scale Multimedia Databases,Christian Beecks (RWTH Aachen University);Merih Seran Uysal (RWTH Aachen University);Judith Hermanns (RWTH Aachen University);Thomas Seidl (RWTH Aachen University);,"175699300,1976045200,2221996503,2140301036","With the continuous rise of multimedia, the question of how to access large-scale multimedia databases efficiently has become of crucial importance. Given a multimedia database comprising millions of multimedia objects, how to approximate the content-based properties of the corresponding feature representations in order to carry out similarity search efficiently and with high accuracy? In this paper, we propose the concept of gradient-based signatures in order to aggregate content-based features of multimedia objects by means of generative models. We provide theoretical insights into our approach including closed-form expressions for the computation of gradient-based signatures with respect to Gaussian mixture models and additionally investigate different binarization methods for gradient-based signatures in order to query databases comprising millions of multimedia objects with high accuracy in less than one second.",2015,Conference on Information and Knowledge Management,mixture model;theoretical computer science;information retrieval;data mining;database;machine learning;computer science;
The Influence of Pre-processing on the Estimation of Readability of Web Documents,João Rafael de Moura Palotti (Vienna University of Technology);Guido Zuccon (Queensland University of Technology);Allan Hanbury (Vienna University of Technology);,"2197643117,1551779932,2168901591","This paper investigates the effect that text pre-processing approaches have on the estimation of the readability of web pages. Readability has been highlighted as an important aspect of web search result personalisation in previous work. The most widely used text readability measures rely on surface level characteristics of text, such as the length of words and sentences. We demonstrate that different tools for extracting text from web pages lead to very different estimations of readability. This has an important implication for search engines because search result personalisation strategies that consider users reading ability may fail if incorrect text readability estimations are computed.",2015,Conference on Information and Knowledge Management,multimedia;world wide web;information retrieval;computer science;
Discovering Canonical Correlations between Topical and Topological Information in Document Networks,Yuan He (Tongji University);Cheng Wang (Tongji University);Changjun Jiang (Tongji University);,"2682831565,2614286577,2103290824","Document network is a kind of intriguing dataset which can provide both topical (textual content) and topological (relational link) information. A key point in viably modeling such datasets is to discover proper denominators beneath the two different types of data, text and link. Most previous work introduces the assumption that documents closely linked with each other share common latent topics. However, the heterophily (i.e., tendency to link to different others) of nodes is neglected, which is pervasive in social networks. In this paper, we simultaneously incorporate community detection and topic modeling in a unified framework, and appeal to Canonical Correlation Analysis (CCA) to capture the latent semantic correlations between the two heterogeneous latent factors, community and topic. Despite of the homophily (i.e., tendency to link to similar others) or heterophily, CCA can properly capture the inherent correlations which fit the dataset itself without any prior hypothesis. Logistic normal prior is also employed in modeling network to better capture the community correlations. We derive efficient inference and learning algorithms based on variational EM methods. The effectiveness of our proposed model is comprehensively verified on three different types of datasets which are namely hyperlinked networks of web pages, social networks of friends and coauthor networks of publications. Experimental results show that our approach achieves significant improvements on both topic modeling and community detection compared with the current state of the art. Meanwhile, our model is impressive in discovering correlations between extracted topics and communities.",2015,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Approximated Summarization of Data Provenance,Eleanor Ainy (Tel Aviv University);Pierre Bourhis (Centre national de la recherche scientifique);Susan B. Davidson (University of Pennsylvania);Daniel Deutch (Tel Aviv University);Tova Milo (Tel Aviv University);,"2232520687,2693376797,2659423383,2076066329,1983463915","Many modern applications involve collecting large amounts of data from multiple sources, and then aggregating and manipulating it in intricate ways. The complexity of such applications, combined with the size of the collected data, makes it difficult to understand how the resulting information was derived. Data provenance has proven helpful in this respect, however, maintaining and presenting the full and exact provenance information may be infeasible due to its size and complexity. We therefore introduce the notion of approximated summarized provenance , which provides a compact representation of the provenance at the possible cost of information loss. Based on this notion, we present a novel provenance summarization algorithm which, based on the semantics of the underlying data and the intended use of provenance, outputs a summary of the input provenance. Experiments measure the conciseness and accuracy of the resulting provenance summaries, and improvement in provenance usage time.",2015,Conference on Information and Knowledge Management,provisioning;world wide web;data mining;database;computer science;
Profession-Based Person Search in Microblogs: Using Seed Sets to Find Journalists,"Mossaab Bagdouri (University of Maryland, College Park);Douglas W. Oard (University of Maryland, College Park);","2046366089,7916806","We introduce the problem of searching for professionals in microblogging platforms. We describe a study of how a group of professional journalists with some common characteristics (e.g., works in a specific language, belongs to certain region, or specializes in a particular media) can be found. Starting from seed sets of different sizes, social network features and profile content features are used to find additional journalists. The results show that combining the social network features of the reciprocated mentions and a bidirectional friend/follower graph provides a signal stronger than either of them taken independently, that both social network and profile content features are useful, and that profile content features are able to find larger numbers of less prominent journalists. We apply our methods to find the Twitter accounts of British and Arab journalists.",2015,Conference on Information and Knowledge Management,microblogging;multimedia;world wide web;computer science;
Deep Semantic Frame-Based Deceptive Opinion Spam Analysis,Seongsoon Kim (Korea University);Hyeokyoon Chang (Korea University);Seongwoon Lee (Korea University);Minhwan Yu (Korea University);Jaewoo Kang (Korea University);,"2125591212,2231559704,2541169476,2223189705,2660424849","User-generated content is becoming increasingly valuable to both individuals and businesses due to its usefulness and influence in e-commerce markets. As consumers rely more on such information, posting deceptive opinions, which can be deliberately used for potential profit, is becoming more of an issue. Existing work on opinion spam detection focuses mainly on linguistic features such as n-grams, syntactic patterns, or LIWC. However, deep semantic analysis remains largely unstudied. In this paper, we propose a frame-based deep semantic analysis method for understanding rich characteristics of deceptive and truthful opinions written by various types of individuals including crowdsourcing workers, employees who have expert-level domain knowledge about local businesses, and online users who post on Yelp and TripAdvisor. Using our proposed semantic frame feature, we developed a classification model that outperforms the baseline model and achieves an accuracy of nearly 91%. Also, we performed qualitative analysis of deceptive and truthful review datasets and considered their semantic differences. Finally, we successfully found some interesting features that existing methods were unable to identify.",2015,Conference on Information and Knowledge Management,framenet;internet privacy;world wide web;data mining;computer science;
Context-Adaptive Matrix Factorization for Multi-Context Recommendation,Tong Man (Chinese Academy of Sciences);Huawei Shen (Chinese Academy of Sciences);Junming Huang (University of Electronic Science and Technology of China);Xueqi Cheng (Chinese Academy of Sciences);,"2223619349,2106143704,2172201243,2129598186","Data sparsity is a long-standing challenge for recommender systems based on collaborative filtering. A promising solution for this problem is multi-context recommendation, i.e., leveraging users' explicit or implicit feedback from multiple contexts. In multi-context recommendation, various types of interactions between entities (users and items) are combined to alleviate data sparsity of a single context in a collective manner. Two issues are crucial for multi-context recommendation: (1) How to differentiate context-specific factors from entity-intrinsic factors shared across contexts? (2) How to capture the salient phenomenon that some entities are insensitive to contexts while others are remarkably context-dependent? Previous methods either do not consider context-specific factors, or assume that a context imposes equal influence on different entities, limiting their capability of combating data sparsity problem by taking full advantage of multiple contexts. In this paper, we propose a context-adaptive matrix factorization method for multi-context recommendation by simultaneously modeling context-specific factors and entity-intrinsic factors in a unified model. We learn an entity-intrinsic latent factor for every entity, and a context-specific latent factor for every entity in each context. Meanwhile, using a context-entity mixture parameter matrix we explicitly model the extent to which each context imposes influence on each entity. Experiments on two real scenarios demonstrate that our method consistently outperforms previous multi-context recommendation methods on all different sparsity levels.Such a consistent performance promotion forms the unique superiority of our method, enabling it to be a reliable model for multi-context recommendation.",2015,Conference on Information and Knowledge Management,collaborative filtering;recommender system;world wide web;data mining;machine learning;computer science;
Robust Capped Norm Nonnegative Matrix Factorization: Capped Norm NMF,Hongchang Gao (University of Texas at Arlington);Feiping Nie (University of Texas at Arlington);Weidong Cai (University of Sydney);Heng Huang (University of Texas at Arlington);,"2169884944,2245267964,2098283194,2137533801","As an important matrix factorization model, Nonnegative Matrix Factorization (NMF) has been widely used in information retrieval and data mining research. Standard Nonnegative Matrix Factorization is known to use the Frobenius norm to calculate the residual, making it sensitive to noises and outliers. It is desirable to use robust NMF models for practical applications, in which usually there are many data outliers. It has been studied that the 2,1, or 1 -norm can be used for robust NMF formulations to deal with data outliers. However, these alternatives still suffer from the extreme data outliers. In this paper, we present a novel robust capped norm orthogonal Nonnegative Matrix Factorization model, which utilizes the capped norm for the objective to handle these extreme outliers. Meanwhile, we derive a new efficient optimization algorithm to solve the proposed non-convex non-smooth objective. Extensive experiments on both synthetic and real datasets show our proposed new robust NMF method consistently outperforms related approaches.",2015,Conference on Information and Knowledge Management,machine learning;mathematical optimization;
Topic Modeling in Semantic Space with Keywords,Xiaojia Pu (Nanjing University);Rong Jin (Michigan State University);Gangshan Wu (Nanjing University);Dingyi Han (Alibaba Group);Gui-Rong Xue (Alibaba Group);,"2674289103,2142724104,2677649643,2692420200,2636150798","A common and convenient approach for user to describe his information need is to provide a set of keywords. Therefore, the technique to understand the need becomes crucial. In this paper, for the information need about a topic or category, we propose a novel method called TDCS(Topic Distilling with Compressive Sensing) for explicit and accurate modeling the topic implied by several keywords. The task is transformed as a topic reconstruction problem in the semantic space with a reasonable intuition that the topic is sparse in the semantic space. The latent semantic space could be mined from documents via unsupervised methods, e.g. LSI. Compressive sensing is leveraged to obtain a sparse representation from only a few keywords. In order to make the distilled topic more robust, an iterative learning approach is adopted. The experiment results show the effectiveness of our method. Moreover, with only a few semantic concepts remained for the topic, our method is efficient for subsequent text mining tasks.",2015,Conference on Information and Knowledge Management,semantic computing;compressed sensing;text mining;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;computer science;
On Query-Update Independence for SPARQL,Nicola Guido (French Institute for Research in Computer Science and Automation);Pierre Genevès (Centre national de la recherche scientifique);Nabil Layaïda (French Institute for Research in Computer Science and Automation);Cécile Roisin (French Institute for Research in Computer Science and Automation);,"2677498900,262950646,200364188,231239453","This paper investigates techniques for detecting independence of SPARQL queries from updates. A query is independent of an update when the execution of the update does not affect the result of the query. Determining independence is especially useful in the context of huge RDF repositories, where it permits to avoid expensive yet useless re-evaluation of queries. While this problem has been intensively studied for fragments of relational calculus, very few works exist for the standard query language for the semantic web. We report on our investigations on how a notion of independence can be defined in the SPARQL context.",2015,Conference on Information and Knowledge Management,named graph;rdf query language;rdf schema;sparql;rdf;independence;analysis;information retrieval;data mining;database;statistics;computer science;
Who With Whom And How?: Extracting Large Social Networks Using Search Engines,Stefan Siersdorfer (Max Planck Society);Philipp Kemkes;Hanno Ackermann;Sergej Zerr (Leibniz University of Hanover);,"138385633,2039327560,2685357963,2165764572","Social network analysis is leveraged in a variety of applications such as identifying influential entities, detecting communities with special interests, and determining the flow of information and innovations. However, existing approaches for extracting social networks from unstructured Web content do not scale well and are only feasible for small graphs. In this paper, we introduce novel methodologies for query-based search engine mining, enabling efficient extraction of social networks from large amounts of Web data. To this end, we use patterns in phrase queries for retrieving entity connections, and employ a bootstrapping approach for iteratively expanding the pattern set. Our experimental evaluation in different domains demonstrates that our algorithms provide high quality results and allow for scalable and efficient construction of social graphs.",2015,Conference on Information and Knowledge Management,data science;world wide web;data mining;machine learning;computer science;
A Structured Query Model for the Deep Relational Web,Hasan M. Jamil (University of Idaho);Hosagrahar Visvesvaraya Jagadish (University of Michigan);,"2299872231,360112113","The deep web is very large and diverse and queries evaluated against the deep web can provide great value. While there have been attempts at accessing the data in the deep web, these are clever ""one-of'' systems and techniques. In this paper, we describe an ongoing research of a generic structured query model that can be used against the deep web. Using this query model, the contributions of a community of researchers can be combined freely, leading to a system that can be improved incrementally each time someone develops a specific novel technique to improve a particular operator.",2015,Conference on Information and Knowledge Management,web modeling;data web;web mapping;web search query;web query classification;name resolution;query expansion;query optimization;data integration;data model;deep web;world wide web;information retrieval;data mining;database;computer science;
Where You Go Reveals Who You Know: Analyzing Social Ties from Millions of Footprints,Hsun-Ping Hsieh (National Taiwan University);Rui Yan (Baidu);Cheng-Te Li (Academia Sinica);,"2109618838,2109109241,2139086518","This paper aims to investigate how the geographical footprints of users correlate to their social ties. While conventional wisdom told us that the more frequently two users co-locate in geography, the higher probability they are friends, we find that in real geo-social data, Gowalla and Meetup, almost all of the user pairs with friendships had never met geographically. In this sense, can we discover social ties among users purely using their geographical footprints even if they never met? To study this question, we develop a two-stage feature engineering framework. The first stage is to characterize the direct linkages between users through their spatial co-locations while the second is to capture the indirect linkages between them via a co-location graph. Experiments conducted on Gowalla check-in data and Meetup meeting events exhibit not only the superiority of our feature model, but also validate the predictability (with 70% accuracy) of detecting social ties solely from user footprints.",2015,Conference on Information and Knowledge Management,interpersonal ties;social network;world wide web;data mining;
Incomplete Multi-view Clustering via Subspace Learning,Qiyue Yin (Chinese Academy of Sciences);Shu Wu (Chinese Academy of Sciences);Liang Wang (Chinese Academy of Sciences);,"2484020598,2122580694,2226151461","Multi-view clustering, which explores complementary information between multiple distinct feature sets for better clustering, has a wide range of applications, e.g., knowledge management and information retrieval. Traditional multi-view clustering methods usually assume that all examples have complete feature sets. However, in real applications, it is often the case that some examples lose some feature sets, which results in incomplete multi-view data and notable performance degeneration. In this paper, a novel incomplete multi-view clustering method is therefore developed, which learns unified latent representations and projection matrices for the incomplete multi-view data. To approximate the high level scaled indicator matrix defined to represent class label matrix, the latent representations are expected to be non-negative and column orthogonal. Besides, since data are often with high dimensional and noisy features, the projection matrices are enforced to be sparse so as to select relevant features when learning the latent space. Furthermore, the inter-view and intra-view data structure is preserved to further enhance the clustering performance. To these ends, an objective is developed with efficient optimization strategy and convergence analysis. Extensive experiments demonstrate that our model performs better than the state-of-the-art multi-view clustering methods in various settings.",2015,Conference on Information and Knowledge Management,flame clustering;brown clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;cluster analysis;consensus clustering;biclustering;conceptual clustering;feature selection;data mining;pattern recognition;machine learning;statistics;computer science;
RoadRank: Traffic Diffusion and Influence Estimation in Dynamic Urban Road Networks,Tarique Anwar (Swinburne University of Technology);Chengfei Liu (Swinburne University of Technology);Hai L. Vu (Swinburne University of Technology);Md. Saiful Islam (Swinburne University of Technology);,"2125769409,2144108974,2275185045,2429334933","With the rapidly growing population in urban areas, these days the urban road networks are expanding at a faster rate. The frequent movement of people on them leads to traffic congestions. These congestions originate from some crowded road segments, and diffuse towards other parts of the urban road networks creating further congestions. This behavior of road networks motivates the need to understand the influence of individual road segments on others in terms of congestion. In this work, we propose RoadRank, an algorithm to compute the influence scores of each road segment in an urban road network, and rank them based on their overall influence. It is an incremental algorithm that keeps on updating the influence scores with time, by feeding with the latest traffic data at each time point. The method starts with constructing a directed graph called influence graph, which is then used to iteratively compute the influence scores using probabilistic diffusion theory. We show promising preliminary experimental results on real SCATS traffic data of Melbourne.",2015,Conference on Information and Knowledge Management,simulation;
Improving Event Detection by Automatically Assessing Validity of Event Occurrence in Text,Andrea Ceroni (Leibniz University of Hanover);Ujwal Kumar Gadiraju (Leibniz University of Hanover);Marco Fisichella (Leibniz University of Hanover);,"1994078628,2225811719,2606151018","Manually inspecting text to assess whether an event occurs in a document collection is an onerous and time consuming task. Although a manual inspection to discard the false events would increase the precision of automatically detected sets of events, it is not a scalable approach. In this paper, we automatize event validation, defined as the task of determining whether a given event occurs in a given document or corpus. The introduction of automatic event validation as a post-processing step of event detection can boost the precision of the detected event set, discarding false events and preserving the true ones. We propose a novel automatic method for event validation, which relies on a supervised model to predict the occurrence of events in a non-annotated corpus. The data for training the model is gathered by exploiting the crowdsourcing paradigm. Experiments on real-world events and documents show that our proposed method (i) outperforms the state-of-the-art event validation approach and (ii) increases the precision of event detection while preserving recall.",2015,Conference on Information and Knowledge Management,information retrieval;data mining;pattern recognition;computer science;
Exploiting Document Content for Efficient Aggregation of Crowdsourcing Votes,Martin Davtyan (ETH Zurich);Carsten Eickhoff (ETH Zurich);Thomas Hofmann (ETH Zurich);,"2650551430,1992666041,2703362482","The use of crowdsourcing for document relevance assessment has been found to be a viable alternative to corpus annotation by highly trained experts. The question of quality control is a recurring challenge that is often addressed by aggregating multiple individual assessments of the same topic-document pair from independent workers. In the past, such aggregation schemes have been weighted or filtered by estimates of worker reliability based on a multitude of behavioral features. In this paper, we propose an alternative approach by relying on document information. Inspired by the clustering hypothesis of information retrieval, we assume textually similar documents to show similar degrees of relevance towards a given topic. Following up on this intuition, we propagate crowd-generated relevance judgments to similar documents, effectively smoothing the distribution of relevance labels across the similarity space. Our experiments are based on TREC Crowdsourcing Track data and show that even simple aggregation methods utilizing document similarity information significantly improve over majority voting in terms of accuracy as well as cost efficiency.",2015,Conference on Information and Knowledge Management,crowdsourcing;relevance;data science;world wide web;information retrieval;data mining;computer science;
Detecting Check-worthy Factual Claims in Presidential Debates,Naeemul Hassan (University of Texas at Arlington);Chengkai Li (University of Texas at Arlington);Mark Tremayne (University of Texas at Arlington);,"2222345529,2145831560,1955149797","Public figures such as politicians make claims about ""facts"" all the time. Journalists and citizens spend a good amount of time checking the veracity of such claims. Toward automatic fact checking, we developed tools to find check-worthy factual claims from natural language sentences. Specifically, we prepared a U.S. presidential debate dataset and built classification models to distinguish check-worthy factual claims from non-factual claims and unimportant factual claims. We also identified the most-effective features based on their impact on the classification models' accuracy.",2015,Conference on Information and Knowledge Management,data mining;artificial intelligence;
Concept-Based Relevance Models for Medical and Semantic Information Retrieval,"Chunye Wang (University of California, Santa Cruz);Ramakrishna Akella (University of California, Santa Cruz);","2130558464,2713785902","Relevance models provide an important approach for estimating probabilities of words in the relevant class. However, the associated bag-of-words assumption breaks dependencies between words, especially between those within a phrase. If such dependencies could be preserved, it would permit matching the query terms with document terms having the same dependencies. Additionally, during the estimation of relevance, relevance models are unable to distinguish relevant and non-relevant information in a feedback document, and hence take the entire document into account, which potentially hurts the accuracy of estimation. In this paper, we define the notion of ""concept"", and design a concept-based information retrieval framework. Using this framework, we transform documents and queries from term space into concept space, and propose a concept-based relevance model for improved estimation of relevance. Our approach has three advantages. First, this approach only assumes independence between concepts, so is able to keep the strong dependencies between the words of a concept. Second, it unifies synonyms or different surface forms of a concept, leading to reduced dimensionality of the space, increased sample size of a concept, and consequently more accurate and reliable estimates of the relevance. Third, when knowledge bases are available, our approach enables the semantic analysis of query concepts, and thus identifies concepts related to the query, from which a more accurate distribution of relevance can be estimated. This work is aligned with semantic search methods. We apply our concept-based relevance model to information retrieval in the medical domain, where concepts are abundant and their variations are numerous. We compare with relevance models, BM25 with pseudo relevance feedback, and the state of the art conceptual language models, on several data collections. The proposed model demonstrates consistent and statistically significant improvements across collections, outperforming top benchmark conceptual language models by at least 9% and up to 20% on a number of metrics.",2015,Conference on Information and Knowledge Management,concept search;unified medical language system;concepts;relevance;relevance;semantic search;ontology;natural language processing;information retrieval;data mining;computer science;
Characterizing and Predicting Voice Query Reformulation,Ahmed Hassan Awadallah (Microsoft);Ranjitha Gurunath Kulkarni (Microsoft);Umut Ozertem (Microsoft);Rosie Jones (Microsoft);,"2094223786,2150529431,2304140494,2128530851","Voice interactions are becoming more prevalent as the usage of voice search and intelligent assistants gains more popularity. Users frequently reformulate their requests in hope of getting better results either because the system was unable to recognize what they said or because it was able to recognize it but was unable to return the desired response. Query reformulation has been extensively studied in the context of text input. Many of the characteristics studied in the context of text query reformulation are potentially useful for voice query reformulation. However, voice query reformulation has its unique characteristics in terms of the reasons that lead users to reformulating their queries and how they reformulate them. In this paper, we study the problem of voice query reformulation. We perform a large scale human annotation study to collect thousands of labeled instances of voice reformulation and non-reformulation query pairs. We use this data to compare and contrast characteristics of reformulation and non-reformulation queries over a large a number of dimensions. We then train classifiers to distinguish between reformulation and non-reformulation query pairs and to predict the rationale behind reformulation. We demonstrate through experiments with the human labeled data that our classifiers achieve good performance in both tasks.",2015,Conference on Information and Knowledge Management,natural language processing;speech recognition;
Dynamic Resource Management In a Massively Parallel Stream Processing Engine,Kasper Grud Skat Madsen (University of Southern Denmark);Yongluan Zhou (University of Southern Denmark);,"2601984327,2097638082","The emerging interest in Massively Parallel Stream Processing Engines (MPSPEs), which are able to process long-standing computations over data streams with ever-growing velocity at a large-scale cluster, calls for efficient dynamic resource management techniques to avoid any waste of resources and/or excessive processing latency. In this paper, we propose an approach to integrate dynamic resource management with passive fault-tolerance mechanisms in a MPSPE so that we can harvest the checkpoints prepared for failure recovery to enhance the efficiency of dynamic load migrations. To maximize the opportunity of reusing checkpoints for fast load migration, we formally define a checkpoint allocation problem and provide a pragmatic algorithm to solve it. We implement all the proposed techniques on top of Apache Storm, an open-source MPSPE, and conduct extensive experiments using a real dataset to examine various aspects of our techniques. The results show that our techniques can greatly improve the efficiency of dynamic resource reconfiguration without imposing significant overhead or latency to the normal job execution.",2015,Conference on Information and Knowledge Management,fault tolerance;elasticity;resource management;world wide web;parallel computing;distributed computing;database;real time computing;computer science;
Building Effective Query Classifiers: A Case Study in Self-harm Intent Detection,Ashiqur R. KhudaBukhsh (Carnegie Mellon University);Paul N. Bennett (Microsoft);Ryen W. White (Microsoft);,"2222165598,2137013502,2096583854","Query-based triggers play a crucial role in modern search systems, e.g., in deciding when to display direct answers on result pages. We address a common scenario in designing such triggers for real-world settings where positives are rare and search providers possess only a small seed set of positive examples to learn query classification models. We choose the critical domain of self-harm intent detection to demonstrate how such small seed sets can be expanded to create meaningful training data with a sizable fraction of positive examples. Our results show that with our method, substantially more positive queries can be found compared to plain random sampling. Additionally, we explored the effectiveness of traditional active learning approaches on classification performance and found that maximum uncertainty performs the best among several other techniques that we considered.",2015,Conference on Information and Knowledge Management,web query classification;query expansion;query optimization;active learning;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
A Probabilistic Framework for Temporal User Modeling on Microblogs,Jitao Sang (Chinese Academy of Sciences);Dongyuan Lu (Beijing Institute of Foreign Trade);Changsheng Xu (Chinese Academy of Sciences);,"2714208759,2309866710,2669895834","In social media, users have contributed enormous behavior data online which can be leveraged for user modeling and conduct personalized services. Temporal user modeling, which incorporates the timestamp of these behavior data and understands users' interest evolution, have attracted attention recently. With the recognition that user interests are vulnerable to transient events, many current temporal user modeling solutions propose to first identify the transient events and then consider the identified events into user behavior modeling. In this work, in the context of microblogs, we propose a unified probabilistic framework to simultaneously model the process of transient event detection and temporal user tweeting. The outputs of the framework include: (1) one long-term topic space spanning over general categories, (2) one short-term topic space for each time interval corresponding to the transient events, and (3) users' interest distributions over the long- and short-term topic spaces. Qualitative and quantitative experimental evaluation are conducted on a large-scale Twitter dataset, with more than 2 million users and 0.3 billion tweets. The promising results demonstrate the advantage of the proposed topic models.",2015,Conference on Information and Knowledge Management,topic model;microblogging;internet privacy;world wide web;data mining;machine learning;computer science;
Making Sense of Spatial Trajectories,Xiaofang Zhou (University of Queensland);Kai Zheng (University of Queensland);Hoyoung Jueng;Jiajie Xu (Soochow University);Shazia Sadiq (University of Queensland);,"2128990482,2150403146,2222086553,2124260618,2122552307","Spatial trajectory data is widely available today. Over a sustained period of time, trajectory data has been collected from numerous GPS devices, smartphones, sensors and social media applications. Daily increases of real-time trajectory data have also been phenomenal in recent years. More and more new applications have emerged to derive business values from both trajectory data warehouses and real-time trajectory data. Due to their very large volumes, their nature of streaming, their highly variable levels of data quality, as well as many possible links with other types of data, making sense of spatial trajectory data becomes one of the crucial areas for big data analytics. In this paper we will present a review of the extensive work in spatiotemporal data management and trajectory mining, and discuss new challenges and new opportunities in the context of new applications, focusing on recent advances in trajectory data management and trajectory mining from their foundations to high performance processing with modern computing infrastructure.",2015,Conference on Information and Knowledge Management,spatiotemporal database;data science;data mining;simulation;
Video Popularity Prediction by Sentiment Propagation via Implicit Network,Wanying Ding (Drexel University);Yue Shang (Drexel University);Lifan Guo (TCL Corporation);Xiaohua Hu (Drexel University);Rui Yan (Central China Normal University);Tingting He (Central China Normal University);,"2106552163,2669245976,2139179961,2207916209,2109109241,2204855006","Video popularity prediction plays a foundational role in many aspects of life, such as recommendation systems and investment consulting. Because of its technological and economic importance, this problem has been extensively studied for years. However, four constraints have limited most related works' usability. First, most feature oriented models are inadequate in the social media environment, because many videos are published with no specific content features, such as a strong cast or a famous script. Second, many studies assume that there is a linear correlation existing between view counts from early and later days, but this is not the case in every scenario. Third, numerous works just take view counts into consideration, but discount associated sentiments. Nevertheless, it is the public opinions that directly drive a video's final success/failure. Also, many related approaches rely on a network topology, but such topologies are unavailable in many situations. Here, we propose a Dual Sentimental Hawkes Process (DSHP) to cope with all the problems above. DSHP's innovations are reflected in three ways: (1) it breaks the ""Linear Correlation"" assumption, and implements Hawkes Process; (2) it reveals deeper factors that affect a video's popularity; and (3) it is topology free. We evaluate DSHP on four types of videos: Movies, TV Episodes, Music Videos, and Online News, and compare its performance against 6 widely used models, including Translation Model, Multiple Linear Regression, KNN Regression, ARMA, Reinforced Poisson Process, and Univariate Hawkes Process. Our model outperforms all of the others, which indicates a promising application prospect.",2015,Conference on Information and Knowledge Management,point process;natural language processing;world wide web;data mining;database;artificial intelligence;machine learning;simulation;statistics;computer science;
Large-scale Knowledge Base Completion: Inferring via Grounding Network Sampling over Selected Instances,Zhuoyu Wei (Chinese Academy of Sciences);Jun Zhao (Chinese Academy of Sciences);Kang Liu (Chinese Academy of Sciences);Zhenyu Qi (Chinese Academy of Sciences);Zhengya Sun (Chinese Academy of Sciences);Guanhua Tian (Chinese Academy of Sciences);,"2165683487,2590483556,2130404924,2712248413,2658967741,2670237053","Constructing large-scale knowledge bases has attracted much attention in recent years, for which Knowledge Base Completion (KBC) is a key technique. In general, inferring new facts in a large-scale knowledge base is not a trivial task. The large number of inferred candidate facts has resulted in the failure of the majority of previous approaches. Inference approaches can achieve high precision for formulas that are accurate, but they are required to infer candidate instances one by one, and extremely large candidate sets bog them down in expensive calculations. In contrast, the existing embedding-based methods can easily calculate similarity-based scores for each candidate instance as opposed to using inference, so they can handle large-scale data. However, this type of method does not consider explicit logical semantics and usually has unsatisfactory precision. To resolve the limitations of the above two types of methods, we propose an approach through Inferring via Grounding Network Sampling over Selected Instances. We first employ an embedding-based model to make the instance selection and generate much smaller candidate sets for subsequent fact inference, which not only narrows the candidate sets but also filters out part of the noise instances. Then, we only make inferences within these candidate sets by running a data-driven inference algorithm on the Markov Logic Network (MLN), which is called Inferring via Grounding Network Sampling (INS). In this process, we especially incorporate the similarity priori generated by embedding-based models into INS to promote the inference precision. The experimental results show that our approach improved Hits@1 from 32.911% to 71.692% on the FB15K dataset and achieved much better AP@n evaluations than state-of-the-art methods.",2015,Conference on Information and Knowledge Management,embedding;data mining;database;artificial intelligence;machine learning;statistics;algorithm;
TM 2015 -- Topic Models: Post-Processing and Applications Workshop,Nikolaos Aletras (University College London);Jey Han Lau (King's College London);Timothy Baldwin (University of Melbourne);Mark Stevenson (University of Sheffield);,"93365683,2095936123,2436269535,2131647180","The main objective of the workshop is to bring together researchers who are interested in applications of topic models and improving their output. Our goal is to create a broad platform for researchers to share ideas that could improve the usability and interpretation of topic models. We expect this will promote topic model applications in other research areas, making their use more effective.",2015,Conference on Information and Knowledge Management,topic model;data science;information retrieval;data mining;machine learning;computer science;
Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR'15),Krisztian Balog (University of Stavanger);Jeffrey Dalton (Google);Antoine Doucet (University of La Rochelle);Yusra Ibrahim (Max Planck Society);,"2100338238,2222608611,2152615820,2114972620","The amount of structured content published on the Web has been growing rapidly, making it possible to address increasingly complex information access tasks. Recent years have witnessed the emergence of large scale human-curated knowledge bases as well as a growing array of techniques that identify or extract information automatically from unstructured and semi-structured sources. The ESAIR workshop series aims to advance the general research agenda on the problem of creating and exploiting semantic annotations. The eighth edition of ESAIR sets its focus on applications. We dedicate a special ""annotations in action"" track to demonstrations that showcase innovative prototype systems, in addition to the regular research and position paper contributions. The workshop also features invited talks from leaders in the field. The desired outcome of ESAIR'15 is a roadmap and research agenda that guides academic efforts and aligns them with industrial directions and developments.",2015,Conference on Information and Knowledge Management,data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Efficient Incremental Evaluation of Succinct Regular Expressions,Henrik Björklund (Umeå University);Wim Martens (University of Bayreuth);Thomas Timm (University of Bayreuth);,"2497174757,1941908016,2228954004","Regular expressions are omnipresent in database applications. They form the structural core of schema languages for XML, they are a fundamental ingredient for navigational queries in graph databases, and are being considered in languages for upcoming technologies such as schema- and transformation languages for tabular data on the Web. In this paper we study the usage and effectiveness of the counting operator (or: limited repetition) in regular expressions. The counting operator is a popular extension which is part of the POSIX standard and therefore also present in regular expressions in grep, Java, Python, Perl, and Ruby. In a database context, expressions with counting appear in XML Schema and languages for querying graphs such as SPARQL 1.1 and Cypher. We first present a practical study that suggests that counters are extensively used in practice. We then investigate evaluation methods for such expressions and develop a new algorithm for efficient incremental evaluation. Finally, we conduct an extensive benchmark study that shows that exploiting counting operators can lead to speed-ups of several orders of magnitude in a wide range of settings: normal and incremental evaluation on synthetic and real expressions.",2015,Conference on Information and Knowledge Management,schema;xml;regular expression;theoretical computer science;world wide web;information retrieval;data mining;database;programming language;computer science;
Structured Sparse Regression for Recommender Systems,Mingjie Qian (University of Illinois at Urbana–Champaign);Liangjie Hong (Yahoo!);Yue Shi (Yahoo!);Suju Rajan (Yahoo!);,"2110740920,2152948077,2714713288,2229133469","Feature-based collaborative filtering models, such as state-of-the-art factorization machines and regression-based latent factor models, rarely consider features' structural information, ignoring the heterogeneity of inter-type and intra-type relationships. Naively treating all feature pairs equally would potentially deteriorate the overall recommendation performance. In addition, human prior knowledge and other hierarchical or graphical structures are often available for some features, e.g., the country-state-city hierarchy for geographic features and the topical taxonomy for article features. It is a challenge to utilize the prior knowledge to further boost performance of state-of-the-art models. In this paper we employ rich features from both user and item sides to enhance latent factors learnt from interaction data, uncovering hidden structures from features' relationships and learning sparse pairwise and tree structural connections among features. Our framework borrows the modeling strengh from both structural sparsity modeling and latent factor models. Experiments on a real-world large-scale recommendation data set demonstrated that the proposed model outperforms several strong state-of-the-art baselines.",2015,Conference on Information and Knowledge Management,sparse approximation;data mining;pattern recognition;machine learning;computer science;
A Cost-based Method for Location-Aware Publish/Subscribe Services,Minghe Yu (Tsinghua University);Guoliang Li (Tsinghua University);Jianhua Feng (Tsinghua University);,"2128233467,2171804313,1995232797","Location-based services have attracted significant attentions from both industry and academia, thanks to modern smartphones and mobile Internet. To provide users with gratifications, location-aware publish/subscribe has been recently proposed, which delivers spatio-textual messages of publishers to subscribers whose registered spatio-textual subscriptions are relevant to the messages. Since there could be large numbers of subscriptions, it is necessary to devise an efficient location-aware publish/subscribe system to enable instant message filtering. To this end, in this paper we propose two novel indexing structures, mbrtrie and PKQ . Using the indexes, we devise two filtering algorithms to support fast message filtering. We analyze the complexities of the two filtering algorithms and develop a cost-based model to judiciously select the best filtering algorithm for different scenarios. The experimental results show that our method achieves high performance and significantly outperforms the baseline approaches",2015,Conference on Information and Knowledge Management,internet privacy;world wide web;database;computer science;
Category-Driven Approach for Local Related Business Recommendations,Yonathan Perez (Stanford University);Michael Schueppert (Google);Matthew Lawlor (Google);Shaunak Kishore (Google);,"2224266352,2227686788,2588106213,2228444729","When users search online for a business, the search engine may present them with a list of related business recommendations. We address the problem of constructing a useful and diverse list of such recommendations that would include an optimal combination of substitutes and complements. Substitutes are similar potential alternatives to the searched business, whereas complements are local businesses that can offer a more comprehensive and better rounded experience for a user visiting the searched locality. In our problem setting, each business belongs to a category in an ontology of business categories . Two businesses are defined as substitutes of one another if they belong to the same category, and as complements if they are otherwise relevant to each other. We empirically demonstrate that the related business recommendation lists generated by Google's search engine are too homogeneous, and overemphasize substitutes. We then use various data sources such as crowdsourcing, mobile maps directions queries, and the existing Google's related business graph to mine association rules to determine to which extent do categories complement each other, and establish relevance between businesses, using both category-level and individual business-level information. We provide an algorithmic approach that incorporates these signals to produce a list of recommended businesses that balances pairwise business relevance with overall diversity of the list. Finally, we use human raters to evaluate our system, and show that it significantly improves on the current Google system in usefulness of the generated recommendation lists.",2015,Conference on Information and Knowledge Management,business rule;diversification;recommender system;ontology;knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Rank Consistency based Multi-View Learning: A Privacy-Preserving Approach,Han-Jia Ye (Nanjing University);De-Chuan Zhan (Nanjing University);Yuan Miao (Nanjing University);Yuan Jiang (Nanjing University);Zhi-Hua Zhou (Nanjing University);,"2226363573,2131836931,2224674931,2100145838,2286237009","Complex media objects are often described by multi-view feature groups collected from diverse domains or information channels. Multi-view learning, which attempts to exploit the relationship among multiple views to improve learning performance, has drawn extensive attention. It is noteworthy that in some real-world applications, features of different views may come from different private data repositories, and thus, it is desired to exploit view relationship with data privacy preserved simultaneously. Existing multi-view learning approaches such as subspace methods and pre-fusion methods are not applicable in this scenario because they need to access the whole features, whereas late-fusion approaches could not exploit information from other views to improve the individual view-specific learners. In this paper, we propose a novel multi-view learning framework which works in a hybrid fusion manner. Specifically, we convert predicted values of each view into an Accumulated Prediction Matrix (APM) with low-rank constraint enforced jointly by the multiple views. The joint low-rank constraint enables the view-specific learner to exploit other views to help improve the performance, without accessing the features of other views. Thus, the proposed RANC framework provides a privacy-preserving way for multi-view learning. Furthermore, we consider variants of solutions to achieve rank consistency and present corresponding methods for the optimization. Empirical investigations on real datasets show that the proposed method achieves state-of-the-art performance on various tasks.",2015,Conference on Information and Knowledge Management,data science;world wide web;data mining;database;machine learning;computer science;
Entity and Aspect Extraction for Organizing News Comments,Radityo Eko Prasojo (Free University of Bozen-Bolzano);Mouna Kacimi (Free University of Bozen-Bolzano);Werner Nutt (Free University of Bozen-Bolzano);,"2117170884,2629444457,1905000215","News websites give their users the opportunity to participate in discussions about published articles, by writing comments. Typically, these comments are unstructured making it hard to understand the flow of user discussions. Thus, there is a need for organizing comments to help users to (1) gain more insights about news topics, and (2) have an easy access to comments that trigger their interests. In this work, we address the above problem by organizing comments around the entities and the aspects they discuss. More specifically, we propose an approach for entity and aspect extraction from user comments through the following contributions. First, we extend traditional Named-Entity Recognition approaches, using coreference resolution and external knowledge bases, to detect more occurrences of entities in comments. Second, we exploit part-of-speech tag, dependency tag, and lexical databases to extract explicit and implicit aspects around discussed entities. Third, we evaluate our entity and aspect extraction approach, on manually annotated data, showing that it highly increases precision and recall compared to baseline approaches.",2015,Conference on Information and Knowledge Management,text mining;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Chronological Citation Recommendation with Information-Need Shifting,Zhuoren Jiang (Peking University);Xiaozhong Liu (Indiana University Bloomington);Liangcai Gao (Peking University);,"2308566457,2171587459,2120263473","As the volume of publications has increased dramatically, an urgent need has developed to assist researchers in locating high-quality, candidate-cited papers from a research repository. Traditional scholarly-recommendation approaches ignore the chronological nature of citation recommendations. In this study, we propose a novel method called ""Chronological Citation Recommendation"" which assumes initial user information needs could shift while users are searching for papers in different time slices. We model the information-need shifts with two-level modeling: dynamic time-related ranking feature construction and dynamic evolving feature weight training. In more detail, we employed a supervised document influence model to characterize the content ""time-varying"" dynamics and constructed a novel heterogeneous graph that encapsulates dynamic topic-based information, time-decay paper/topic citation information, and word-based information. We applied multiple meta-paths for different ranking hypotheses which carried different types of information for citation recommendation in various time slices, along with information-need shifting. We also used multiple learning-to-rank models to optimize the feature weights for different time slices to generate the final ""Chronological Citation Recommendation"" rankings. The use of Chronological Citation Recommendation suggests time-series ranking lists based on initial user textual information need and characterizes the information-need shifting. Experiments on the ACM corpus show that Chronological Citation Recommendation can significantly enhance citation recommendation performance.",2015,Conference on Information and Knowledge Management,learning to rank;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Clustering-based Active Learning on Sensor Type Classification in Buildings,Dezhi Hong (University of Virginia);Hongning Wang (University of Virginia);Kamin Whitehouse (University of Virginia);,"2310673635,2157880984,2001774235","Commercial and industrial buildings account for a considerable portion of all energy consumed in the U.S., and thus reducing this energy consumption is a national grand challenge. Based on the large deployment of sensors in modern commercial buildings, many organizations are applying data analytic solutions to the thousands of sensing and control points to detect wasteful and incorrect operations for energy savings. Scaling this approach is challenging, however, because the metadata about these sensing and control points is inconsistent between buildings, or even missing altogether. Moreover, normalizing the metadata requires significant integration effort. In this work, we demonstrate a first step towards an automatic metadata normalization solution that requires minimal human intervention. We propose a clustering-based active learning algorithm to differentiate sensors in buildings by type, e.g., temperature v.s. humidity. Our algorithm exploits data clustering structure and propagates labels to their nearby unlabeled neighbors to accelerate the learning process. We perform a comprehensive study on metadata collected from over 20 different sensor types and 2,500 sensor streams in three commercial buildings. Our approach is able to achieve more than 92% accuracy for type classification with much less labeled examples than baselines. As a proof-of-concept, we also demonstrate a typical analytic application enabled by the normalized metadata.",2015,Conference on Information and Knowledge Management,active learning;cluster analysis;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Heterogeneous Multi-task Semantic Feature Learning for Classification,Xin Jin (Chinese Academy of Sciences);Fuzhen Zhuang (Chinese Academy of Sciences);Sinno Jialin Pan (Nanyang Technological University);Changying Du (Chinese Academy of Sciences);Ping Luo (Chinese Academy of Sciences);Qing He (Chinese Academy of Sciences);,"2695402291,2050314250,2120836466,2116524837,2291210646,2167314737","Multi-task Learning (MTL) aims to learn multiple related tasks simultaneously instead of separately to improve generalization performance of each task. Most existing MTL methods assumed that the multiple tasks to be learned have the same feature representation. However, this assumption may not hold for many real-world applications. In this paper, we study the problem of MTL with heterogeneous features for each task. To address this problem, we first construct an integrated graph of a set of bipartite graphs to build a connection among different tasks. We then propose a multi-task nonnegative matrix factorization (MTNMF) method to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. Finally, based on the common semantic features and original heterogeneous features, we model the heterogenous MTL problem as a multi-task multi-view learning (MTMVL) problem. In this way, a number of existing MTMVL methods can be applied to solve the problem effectively. Extensive experiments on three real-world problems demonstrate the effectiveness of our proposed method.",2015,Conference on Information and Knowledge Management,multi task learning;theoretical computer science;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
Semi-Automated Exploration of Data Warehouses,Thibault Sellam (College of Western Idaho);Emmanuel Müller (Karlsruhe Institute of Technology);Martin L. Kersten (College of Western Idaho);,"690733822,2112493600,2117317669","Exploratory data analysis tries to discover novel dependencies and unexpected patterns in large databases. Traditionally, this process is manual and hypothesis-driven. However, analysts can come short of patience and imagination. In this paper, we introduce Claude, a hypothesis generator for data warehouses. Claude follows a 2-step approach: (1) It detects interesting views, by exploiting non-linear statistical dependencies between the dimensions and the measure. (2) To explain its findings, it detects local patterns in these views and describes them with SQL queries. Technically, we derive a model of interestingness from fundamental information theory. To exploit this model, we present aggressive approximations and heuristics, allowing Claude to be fast and more accurate than state-of-art view selection algorithms.",2015,Conference on Information and Knowledge Management,feature selection;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Organic or Organized?: Exploring URL Sharing Behavior,Cheng Cao (Texas A&M University);James Caverlee (Texas A&M University);Kyumin Lee (Utah State University);Hancheng Ge (Texas A&M University);Jinwook Chung (Utah State University);,"2100972142,2028974103,2222273857,2166293409,2487725797","URL sharing has become one of the most popular activities on many online social media platforms. Shared URLs are an avenue to interesting news articles, memes, photos, as well as low-quality content like spam, promotional ads, and phishing sites. While some URL sharing is organic, other sharing is strategically organized with a common purpose (e.g., aggressively promoting a website). In this paper, we investigate the individual-based and group-based user behavior of URL sharing in social media toward uncovering these organic versus organized user groups. Concretely, we pro- pose a four-phase approach to model, identify, characterize, and classify organic and organized groups who engage in URL sharing. The key motivating insights of this approach are (i) that patterns of individual-based behavioral signals embedded in URL posting activities can uncover groups whose members engage in similar behaviors; and (ii) that group-level behavioral signals can distinguish between organic and organized user groups. Through extensive experiments, we find that levels of organized behavior vary by URL type and that the proposed approach achieves good performance -- an F-measure of 0.836 and Area Under the Curve of 0.921.",2015,Conference on Information and Knowledge Management,url subscription architecture;semantic url;uniform resource locator;social media;internet privacy;multimedia;world wide web;computer science;
Building Representative Composite Items,VIncent Leroy (Centre national de la recherche scientifique);Sihem Amer-Yahia (Centre national de la recherche scientifique);Eric Gaussier (Centre national de la recherche scientifique);Hamid Mirisaee (Centre national de la recherche scientifique);,"2288706330,19633248,2663681485,2223317163","The problem of summarizing a large collection of homogeneous items has been addressed extensively in particular in the case of geo-tagged datasets (e.g. Flickr photos and tags). In our work, we study the problem of summarizing large collections of heterogeneous items. For example, a user planning to spend extended periods of time in a given city would be interested in seeing a map of that city with item summaries in different geographic areas, each containing a theater, a gym, a bakery, a few restaurants and a subway station. We propose to solve that problem by building representative Composite Items (CIs). To the best of our knowledge, this is the first work that addresses the problem of finding representative CIs for heterogeneous items. Our problem naturally arises when summarizing geo-tagged datasets but also in other datasets such as movie or music summarization. We formalize building representative CIs as an optimization problem and propose KFC, an extended fuzzy clustering algorithm to solve it. We show that KFC converges and run extensive experiments on a variety of real datasets that validate its effectiveness.",2015,Conference on Information and Knowledge Management,fuzzy clustering;automatic summarization;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Slow Search: Improving Information Retrieval Using Human Assistance,Jaime Teevan (Microsoft);,1982462162,"We live in a world where the pace of everything from communication to transportation is getting faster. In recent years a number of ""slow movements"" have emerged that advocate for reducing speed in exchange for increasing quality, including the slow food movement, slow parenting, slow travel, and even slow science. We propose the concept of ""slow search,"" where search engines use additional time to provide a higher quality search experience than is possible given conventional time constraints. While additional time can be used to identify relevant results within the existing search engine framework, it can also be used to create new search artifacts and enable previously unimaginable user experiences. This talk will focus on how search engines can make use of additional time to employ a resource that is inherently slow: other people. Using crowdsourcing and friendsourcing, it will highlight opportunities for search systems to support new search experiences with high quality result content that takes time to identify.",2015,Conference on Information and Knowledge Management,crowdsourcing;speed;search engine;multimedia;information retrieval;data mining;simulation;computer science;
Behavioral Dynamics from the SERP's Perspective: What are Failed SERPs and How to Fix Them?,Julia Kiseleva (Eindhoven University of Technology);Jaap Kamps (University of Amsterdam);Vadim Nikulin (Yandex);Nikita Makarov (Yandex);,"2165175320,2088944921,2224319808,2631366578","Web search is always in a state of flux: queries, their intent, and the most relevant content are changing over time, in predictable and unpredictable ways. Modern search technology has made great strides in keeping up to pace with these changes, but there remain cases of failure where the organic search results on the search engine result page (SERP) are outdated, and no relevant result is displayed. Failing SERPs due to temporal drift are one of the greatest frustrations of web searchers, leading to search abandonment or even search engine switch. Detecting failed SERPs timely and providing access to the desired out-of-SERP results has huge potential to improve user satisfaction. Our main findings are threefold: First, we refine the conceptual model of behavioral dynamics on the web by including the SERP and defining (un)successful SERPs in terms of observable behavior. Second, we analyse typical patterns of temporal change and propose models to predict query drift beyond the current SERP, and ways to adapt the SERP to include the desired results. Third, we conduct extensive experiments on real world search engine traffic demonstrating the viability of our approach. Our analysis of behavioral dynamics at the SERP level gives new insight in one of the primary causes of search failure due to temporal query intent drifts. Our overall conclusion is that the most detrimental cases in terms of (lack of) user satisfaction lead to the largest changes in information seeking behavior, and hence to observable changes in behavior we can exploit to detect failure, and moreover not only detect them but also resolve them.",2015,Conference on Information and Knowledge Management,concept drift;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Process-Driven Data Privacy,Weiyi Xia (Vanderbilt University);Murat Kantarcioglu (University of Texas at Dallas);Zhiyu Wan (Vanderbilt University);Raymond Heatherly (Vanderbilt University);Yevgeniy Vorobeychik (Vanderbilt University);Bradley Malin (Vanderbilt University);,"2121210855,332400322,2110339547,1982805049,2305697090,2145238237","The quantity of personal data gathered by service providers via our daily activities continues to grow at a rapid pace. The sharing, and the subsequent analysis of, such data can support a wide range of activities, but concerns around privacy often prompt an organization to transform the data to meet certain protection models (e.g., k -anonymity or e-differential privacy). These models, however, are based on simplistic adversarial frameworks, which can lead to both under- and over-protection. For instance, such models often assume that an adversary attacks a protected record exactly once. We introduce a principled approach to explicitly model the attack process as a series of steps. Specifically, we engineer a factored Markov decision process (FMDP) to optimally plan an attack from the adversary's perspective and assess the privacy risk accordingly. The FMDP captures the uncertainty in the adversary's belief (e.g., the number of identified individuals that match the de-identified data) and enables the analysis of various real world deterrence mechanisms beyond a traditional protection model, such as a penalty for committing an attack. We present an algorithm to solve the FMDP and illustrate its efficiency by simulating an attack on publicly accessible U.S. census records against a real identified resource of over 500,000 individuals in a voter registry. Our results demonstrate that while traditional privacy models commonly expect an adversary to attack exactly once per record, an optimal attack in our model may involve exploiting none, one, or more individuals in the pool of candidates, depending on context.",2015,Conference on Information and Knowledge Management,adversary model;privacy;planning;internet privacy;world wide web;computer security;data mining;database;artificial intelligence;machine learning;computer science;
GLUE: a Parameter-Tuning-Free Map Updating System,Hao Wu (Fudan University);Chuanchuan Tu (Fudan University);Weiwei Sun (Fudan University);Baihua Zheng (Singapore Management University);Hao Su (Fudan University);Wei Wang (Fudan University);,"2649278900,2223946539,2142659109,2200653933,2226699693,2296847996","Map data are widely used in mobile services, but most maps might not be complete. Updating the map automatically is an important problem because road networks are frequently changed with the development of the city. This paper studies the problem of recovering missing road segments via GPS trajectories, especially low sampled data. Our approach takes the GPS noise into consideration and proposes an effective self-adaptive algorithm. Besides, we propose theoretical models behind all the important parameters to enable self-adaptive parameter setting. To the best of our knowledge, this is the first work that addresses the parameter setting issue successfully to make sure our approach is free of parameter-tuning. In addition, we also propose a quantitative evaluation method for map updating problem. The result shows our algorithm has a much better performance than the existing approaches.",2015,Conference on Information and Knowledge Management,data mining;machine learning;
Where you Instagram?: Associating Your Instagram Photos with Points of Interest,"Xutao Li (Nanyang Technological University);Tuan-Anh Nguyen Pham (Nanyang Technological University);Gao Cong (Nanyang Technological University);Quan Yuan (Nanyang Technological University);Xiao-Li Li (Agency for Science, Technology and Research);Shonali Krishnaswamy (Agency for Science, Technology and Research);","2129143600,2228254159,2295915604,2163879794,2306607199,2722391233","Instagram, an online photo-sharing platform, has gained increasing popularity. It allows users to take photos, apply digital filters and share them with friends instantaneously by using mobile devices.Instagram provides users with the functionality to associate their photos with points of interest, and it thus becomes feasible to study the association between points of interest and Instagram photos. However, no previous work studies the association. In this paper, we propose to study the problem of mapping Instagram photos to points of interest. To understand the problem, we analyze Instagram datasets, and report our findings, which also characterize the challenges of the problem. To address the challenges, we propose to model the mapping problem as a ranking problem, and develop a method to learn a ranking function by exploiting the textual, visual and user information of photos. To maximize the prediction effectiveness for textual and visual information, and incorporate the users' visiting preferences, we propose three subobjectives for learning the parameters of the proposed ranking function. Experimental results on two sets of Instagram data show that the proposed method substantially outperforms existing methods that are adapted to handle the problem.",2015,Conference on Information and Knowledge Management,point of interest;ranking;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Who Will You,Yeyun Gong (Fudan University);Qi Zhang (Fudan University);Xuyang Sun (Fudan University);Xuanjing Huang (Fudan University);,"2104159869,2484821979,2494659118,2161482855","In Twitter-like social networking services, people can use the ""@"" symbol to mention other users in tweets and send them a message or link to their profiles. In recent years, social media services are rapidly growing with thousands of millions of users participating in them every day. When the ""@"" symbol is entered, there should be an automatic suggestion function which recommends a small list of candidates in order to help users to easily identify and input usernames. In this paper, we present our work on building a recommendation system for the mention function in microblogging services. The recommendation strategy we used takes into consideration not only content of the microblog but also histories of candidate users. To better handle these textual information, we propose a novel method that extends the translation-based model. Experimental results on the dataset we collected from a real world microblogging service demonstrate that the proposed method outperforms state-of-the-art approaches.",2015,Conference on Information and Knowledge Management,microblogging;internet privacy;multimedia;world wide web;information retrieval;data mining;database;computer science;
Protecting Your Children from Inappropriate Content in Mobile Apps: An Automatic Maturity Rating Framework,Bing Hu (Samsung);Bin Liu (Rutgers University);Neil Zhenqiang Gong (Iowa State University);Deguang Kong (Samsung);Hongxia Jin (Samsung);,"2100072381,2428181972,1984287476,2230864965,2707082889","Mobile applications (Apps) could expose children or adolescents to mature themes such as sexual content, violence and drug use, which results in an inappropriate security and privacy risk for them. Therefore, mobile platforms provide rating policies to label the maturity levels of Apps and the reasons why an App has a given maturity level, which enables parents to select maturity-appropriate Apps for their children. However, existing approaches to implement these maturity rating policies are either costly (because of expensive manually labeling) or inaccurate (because of no centralized controls). In this work, we aim to design and build a machine learning framework to automatically predict maturity levels for mobile Apps and the associated reasons with a high accuracy and a low cost. To this end, we take a multi-label classification approach to predict the mature contents in a given App and then label the maturity level according to a rating policy. Specifically, we extract novel features from App descriptions by leveraging deep learning technique to automatically capture the semantic similarity of pairwise words and adapt Support Vector Machine to capture label correlations with pearson correlation in a multi-label classification setting. Moreover, we evaluate our approach and various baseline methods using datasets that we collected from both App Store and Google Play. We demonstrate that, with only App descriptions, our approach already achieves 85% Precision for predicting mature contents and 79% Precision for predicting maturity levels, which substantially outperforms baseline methods.",2015,Conference on Information and Knowledge Management,pearson product moment correlation coefficient;deep learning;text mining;internet privacy;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Modeling Parameter Interactions in Ranking SVM,Yaogong Zhang (Nankai University);Jun Xu (Chinese Academy of Sciences);Yanyan Lan (Chinese Academy of Sciences);Jiafeng Guo (Chinese Academy of Sciences);Maoqiang Xie (Nankai University);Yalou Huang (Nankai University);Xueqi Cheng (Chinese Academy of Sciences);,"2110044780,2598177019,2154124860,2581340266,2698260482,2396374192,2129598186","Ranking SVM, which formalizes the problem of learning a ranking model as that of learning a binary SVM on preference pairs of documents, is a state-of-the-art ranking model in information retrieval. The dual form solution of Ranking SVM model can be written as a linear combination of the preference pairs, i.e., w = ∑( i,j ) α ij ( x i - x j ), where α ij denotes the Lagrange parameters associated with each pair ( i,j ). It is obvious that there exist significant interactions over the document pairs because two preference pairs could share a same document as their items. Thus it is natural to ask if there also exist interactions over the model parameters α ij , which we may leverage to propose better ranking model. This paper aims to answer the question. Firstly, we found that there exists a low-rank structure over the Ranking SVM model parameters α ij , which indicates that the interactions do exist. Then, based on the discovery, we made a modification on the original Ranking SVM model by explicitly applying a low-rank constraint to the parameters. Specifically, each parameter α i j is decomposed as a product of two low-dimensional vectors, i.e., α ij = v i , v j , where vectors v i and v j correspond to document i and j , respectively. The learning process, thus, becomes to optimize the modified dual form objective function with respect to the low-dimensional vectors. Experimental results on three LETOR datasets show that our method, referred to as Factorized Ranking SVM, can outperform state-of-the-art baselines including the conventional Ranking SVM.",2015,Conference on Information and Knowledge Management,ranking svm;data mining;pattern recognition;machine learning;computer science;
Profiling Pedestrian Distribution and Anomaly Detection in a Dynamic Environment,Minh Tuan Doan (University of Melbourne);Sutharshan Rajasegarar (University of Melbourne);Mahsa Salehi (University of Melbourne);Masud Moshtaghi (University of Melbourne);Christopher Leckie (University of Melbourne);,"2223150331,249221098,2408564922,1967642254,2111831791","Pedestrians movements have a major impact on the dynamics of cities and provide valuable guidance to city planners. In this paper we model the normal behaviours of pedestrian flows and detect anomalous events from pedestrian counting data of the City of Melbourne. Since the data spans an extended period, and pedestrian activities can change intermittently (e.g., activities in winter vs. summer), we applied an Ensemble Switching Model, which is a dynamic anomaly detection technique that can accommodate systems that switch between different states. The results are compared with those produced by a static clustering model (HyCARCE) and also cross-validated with known events. We found that the results from the Ensemble Switching Model are valid and more accurate than HyCARCE.",2015,Conference on Information and Knowledge Management,application software;anomaly detection;computer security;machine learning;simulation;computer science;
Gauging Correct Relative Rankings For Similarity Search,Weiren Yu (Imperial College London);Julie A. McCann (Imperial College London);,"2111026807,2146782186","One of the important tasks in link analysis is to quantify the similarity between two objects based on hyperlink structure. SimRank is an attractive similarity measure of this type. Existing work mainly focuses on absolute SimRank scores, and often harnesses an iterative paradigm to compute them. While these iterative scores converge to exact ones with the increasing number of iterations, it is still notoriously difficult to determine how well the relative orders of these iterative scores can be preserved for a given iteration. In this paper, we propose efficient ranking criteria that can secure correct relative orders of node-pairs with respect to SimRank scores when they are computed in an iterative fashion. Moreover, we show the superiority of our criteria in harvesting top-K SimRank scores and bucket orders from a full ranking list. Finally, viable empirical studies verify the usefulness of our techniques for SimRank top-K ranking and bucket ordering.",2015,Conference on Information and Knowledge Management,nearest neighbor search;world wide web;information retrieval;data mining;database;machine learning;statistics;computer science;
On Predicting Deletions of Microblog Posts,"Mossaab Bagdouri (University of Maryland, College Park);Douglas W. Oard (University of Maryland, College Park);","2046366089,7916806","Among the many classification tasks on Twitter content, predicting whether a tweet will be deleted has to date received relatively little attention. Deletions occur for a variety of reasons, which can make the classification task challenging. Moreover, deletion prediction might serve different goals, the characteristics of which should be reflected in the evaluation design. This paper addresses the problem of deletion prediction by analyzing the distribution of deleted tweets, presenting a new evaluation framework, exploring tweet-based and user-based features, and reporting prediction scores.",2015,Conference on Information and Knowledge Management,microblogging;prediction;internet privacy;world wide web;data mining;statistics;computer science;
Improving Label Quality in Crowdsourcing Using Noise Correction,Jing Zhang (Nanjing University of Science and Technology);Victor S. Sheng (University of Central Arkansas);Jian Wu (Soochow University);Xiaoqin Fu (University of Central Arkansas);Xindong Wu (Hefei University of Technology);,"2656342078,2010535889,2559930321,2224299252,2123651450","This paper proposes a novel framework that introduces noise correction techniques to further improve label quality after ground truth inference in crowdsourcing. In the framework, an adaptive voting noise correction algorithm (AVNC) is proposed to identify and correct the most likely noises with the help of estimated qualities of labelers provided by the ground truth inference. The experimental results on two real-world datasets show that (1) the framework can improve label quality regardless of inference algorithms, especially under the circumstance that each example has a few noisy labels; and (2) since the algorithm AVNC considers both the number of and the probability of potential noises, it outperforms a baseline noise correction algorithm.",2015,Conference on Information and Knowledge Management,crowdsourcing;data science;data mining;machine learning;computer science;
Know Your Onions: Understanding the User Experience with the Knowledge Module in Web Search,Ioannis Arapakis (Yahoo!);Luis A. Leiva (Polytechnic University of Valencia);Berkant Barla Cambazoglu (Yahoo!);,"2091815359,2133476366,2044137649","The increasing availability of large volumes of human-curated content is shifting web search towards a paradigm that introduces seamlessly more semantic information to search engine result pages. This trend has resulted in the design of a new element known as the knowledge module (KM) where certain facts about named entities, obtained from various knowledge bases, are shown to users. So far, little has been done to uncover the role that this module plays on user experience in web search and whether it is perceived by users as a useful aid for their search tasks. Our work is an early attempt to bridge this gap. To this end, we conducted a crowdsourcing study aimed at understanding the effect of the KM on users' search experience and its overall utility. In particular, our study is the first to provide insights about the noticeability and usefulness of the KM in web search, together with comprehensive analyses of usability and workload.",2015,Conference on Information and Knowledge Management,search analytics;web design;search engine;semantic search;web search engine;knowledge management;world wide web;information retrieval;data mining;database;computer science;
Lifespan-based Partitioning of Index Structures for Time-travel Text Search,Animesh Nandi (IBM);Suriya Subramanian (IBM);Sriram Lakshminarasimhan (IBM);Prasad M. Deshpande (IBM);Sriram Raghavan (IBM);,"2232379423,2228367386,1987828310,2304487933,2158818593","Time-travel text search over a temporally evolving document collection is useful in various applications. Supporting a wide range of query classes demanded by these applications require different index layouts optimized for their respective query access patterns. The problem we tackle is how to efficiently handle different query classes using the same index layout. Our approach is to use list intersections on single-attribute indexes of keywords and temporal attributes. Although joint predicate evaluation on single-attribute indexes is inefficient in general, we show that partitioning the index based on version lifespans coupled with exploiting the transaction-time ordering of record-identifiers, can significantly reduce the cost of list intersections. We empirically evaluate different index partitioning alternatives on top of open-source Lucene, and show that our approach is the only technique that can simultaneously support a wide range of query classes efficiently, have high indexing throughput in a real-time ingestion setting, and also have negligible extra storage costs.",2015,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
A Clustering-based Approach to Detect Probable Outcomes of Lawsuits,Daniel Lemes Gribel (Pontifical Catholic University of Rio de Janeiro);Maira Gatti de Bayser (IBM);Leonardo Guerreiro Azevedo (IBM);,"2642207494,2228643433,2324089062","The numerous lawsuits in progress or already judged by the Brazilian Supreme Court consists of a large amount of non-structured data. This leads to a large number of hidden or unknown information, since some relationships between lawsuits are not explicit in the available data; and contributes to generate non-intuitive influences between variables, which in addition increases the degree of uncertainty on judicial outcomes. This work proposes an approach to identify possible judgment outcomes that considers the use of similarity calculations and clustering mechanisms based on lawsuits patterns. The similarity problem was tackled by analysing metadata manually extracted from lawsuits; and this work also presents an approach to detect clusters and to compile past votes. From the results, it is possible to verify lawsuits most likely outcomes and to detect their degree of uncertainty.",2015,Conference on Information and Knowledge Management,similarity;prediction;cluster analysis;computer security;data mining;artificial intelligence;machine learning;statistics;computer science;
F1: Accelerating the Optimization of Aggregate Continuous Queries,Anatoli U. Shein (University of Pittsburgh);Panos K. Chrysanthis (University of Pittsburgh);Alexandros Labrinidis (University of Pittsburgh);,"2223913085,2030977514,119288298","Data Stream Management Systems performing on-line analytics rely on the efficient execution of large numbers of Aggregate Continuous Queries (ACQs). The state-of-the-art WeaveShare optimizer uses the Weavability concept in order to selectively combine ACQs for partial aggregation and produce high quality execution plans. However, WeaveShare does not scale well with the number of ACQs. In this paper we propose a novel closed formula, F 1, that accelerates Weavability calculations, and thus allows WeaveShare to achieve exceptional scalability in systems with heavy workloads. In general, F 1 can reduce the computation time of any technique that combines partial aggregations within composite slides of multiple ACQs . We theoretically analyze the Bit Set approach currently used by WeaveShare and show that F 1 is superior in both time and space complexities. We show that F 1 performs 10 62 times less operations compared to Bit Set to produce the same execution plan for the same input. We experimentally show that F 1 executes up to 60,000 times faster and can handle 1,000,000 ACQs in a setting where the limit for the current technique is 550.",2015,Conference on Information and Knowledge Management,data stream mining;data mining;database;real time computing;machine learning;computer science;
Large-Scale Question Answering with Joint Embedding and Proof Tree Decoding,Zhenghao Wang (Microsoft);Shengquan Yan (Microsoft);Huaming Wang (Microsoft);Xuedong Huang (Microsoft);,"2706217897,2578042296,2500320461,2153189671","Question answering (QA) over a large-scale knowledge base (KB) such as Freebase is an important natural language processing application. There are linguistically oriented semantic parsing techniques and machine learning motivated statistical methods. Both of these approaches face a key challenge on how to handle diverse ways natural questions can be expressed about predicates and entities in the KB. This paper is to investigate how to combine these two approaches. We frame the problem from a proof-theoretic perspective, and formulate it as a proof tree search problem that seamlessly unifies semantic parsing, logic reasoning, and answer ranking. We combine our word entity joint embedding learned from web-scale data with other surface-form features to further boost accuracy improvements. Our real-time system on the Freebase QA task achieved a very high F1 score (47.2) on the standard Stanford WebQuestions benchmark test data.",2015,Conference on Information and Knowledge Management,free base;question answering;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Private Analysis of Infinite Data Streams via Retroactive Grouping,Rui Chen (Samsung);Yilin Shen (Samsung);Hongxia Jin (Samsung);,"2675460166,2228306107,2707082889","With the rapid advances in hardware technology, data streams are being generated daily in large volumes, enabling a wide range of real-time analytical tasks. Yet data streams from many sources are inherently sensitive, and thus providing continuous privacy protection in data streams has been a growing demand. In this paper, we consider the problem of private analysis of infinite data streams under differential privacy. We propose a novel data stream sanitization framework that periodically releases histograms summarizing the event distributions over sliding windows to support diverse data analysis tasks. Our framework consists of two modules, a sampling-based change monitoring module and a continuous histogram publication module. The monitoring module features an adaptive Bernoulli sampling process to accurately track the evolution of a data stream. We for the first time conduct error analysis of sampling under differential privacy, which allows to select the best sampling rate. The publication module features three different publishing strategies, including a novel technique called retroactive grouping to enjoy reduced noise. We provide theoretical analysis of the utility, privacy and complexity of our framework. Extensive experiments over real datasets demonstrate that our solution substantially outperforms the state-of-the-art competitors.",2015,Conference on Information and Knowledge Management,differential privacy;world wide web;information retrieval;data mining;database;machine learning;computer science;
Learning Task Grouping using Supervised Task Space Partitioning in Lifelong Multitask Learning,Meenakshi Mishra (University of Kansas);Jun Huan (University of Kansas);,"2192999366,2139058963","Lifelong multitask learning is a multitask learning framework in which a learning agent faces the tasks that need to be learnt in an online manner. Lifelong multitask learning framework may be applied to a variety of applications such as image annotation, robotics, automated machines etc, and hence, may prove to be a highly promising direction for further investigation. However, the lifelong learning framework comes with its own baggage of challenges. The biggest challenge is the fact that the characteristics of the future tasks which might be encountered by the learning agents are entirely unknown. If all the tasks are assumed to be related, there may be a risk of training from unrelated task resulting in negative transfer of information. To overcome this problem, both batch and online multitask learning algorithms learn task relationships. However, due to the unknown nature of the future tasks, learning the task relationships is also difficult in lifelong multitask learning. In this paper, we propose learning functions to model the task relationships as it is computationally cheaper in an online setting. More specifically, we learn partition functions in the task space to divide the tasks into cluster. Our major contribution is to present a global formulation to learn both the task partitions and the parameters. We provide a supervised learning framework to estimate both the partition function and the model. The current method has been implemented and compared against other leading lifelong learning algorithms using several real world datasets, and we show that the current method has a superior performance.",2015,Conference on Information and Knowledge Management,challenge point framework;online machine learning;stability;preference learning;multi task learning;robot learning;lifelong learning;synchronous learning;active learning;error driven learning;feature learning;semi supervised learning;instance based learning;supervised learning;feature selection;unsupervised learning;artificial intelligence;machine learning;simulation;computer science;
Modelling the Usefulness of Document Collections for Query Expansion in Patient Search,Nut Limsopatham (University of Cambridge);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"2670406119,2148910894,336997814","Dealing with the medical terminology is a challenge when searching for patients based on the relevance of their medical records towards a given query. Existing work used query expansion (QE) to extract expansion terms from different document collections to improve query representation. However, the usefulness of particular document collections for QE was not measured and taken into account during retrieval. In this work, we investigate two automatic approaches that measure and leverage the usefulness of document collections when exploiting multiple document collections to improve query representation. These two approaches are based on resource selection and learning to rank techniques, respectively. We evaluate our approaches using the TREC Medical Records track's test collection. Our results show the potential of the proposed approaches, since they can effectively exploit 14 different document collections, including both domain-specific (e.g. MEDLINE abstracts) and generic (e.g. blogs and webpages) collections, and significantly outperform existing effective baselines, including the best systems participating at the TREC Medical Records track. Our analysis shows that the different collections are not equally useful for QE, while our two approaches can automatically weight the usefulness of expansion terms extracted from different document collections effectively.",2015,Conference on Information and Knowledge Management,query expansion;world wide web;information retrieval;data mining;database;computer science;
Defragging Subgraph Features for Graph Classification,"Haishuai Wang (University of Technology, Sydney);Peng Zhang (University of Technology, Sydney);Ivor W. Tsang (University of Technology, Sydney);Ling Chen (University of Technology, Sydney);Chengqi Zhang (University of Technology, Sydney);","2228729678,2120503182,2429802807,2691089318,2166080598","Graph classification is an important tool for analysing structured and semi-structured data, where subgraphs are commonly used as the feature representation. However, the number and size of subgraph features crucially depend on the threshold parameters of frequent subgraph mining algorithms. Any improper setting of the parameters will generate many trivial short-pattern subgraph fragments which dominate the feature space, distort graph classifiers and bury interesting long-pattern subgraphs. In this paper, we propose a new Subgraph Join Feature Selection ( SJFS ) algorithm. The SJFS algorithm, by forcing graph classifiers to join short-pattern subgraph fragments, can defrag trivial subgraph features and deliver long-pattern interesting subgraphs. Experimental results on both synthetic and real-world social network graph data demonstrate the performance of the proposed method.",2015,Conference on Information and Knowledge Management,factor critical graph;maximum common subgraph isomorphism problem;degeneracy;distance hereditary graph;rook s graph;induced subgraph isomorphism problem;forbidden graph characterization;graph power;graph factorization;butterfly graph;universal graph;reconstruction conjecture;cograph;claw free graph;planarity testing;color coding;subgraph isomorphism problem;line graph;connected component;feature selection;pattern recognition;machine learning;computer science;
Generalized Team Draft Interleaving,Eugene Kharitonov (Yandex);Craig Macdonald (University of Glasgow);Pavel Serdyukov (Yandex);Iadh Ounis (University of Glasgow);,"2115606974,2148910894,2130450538,336997814","Interleaving is an online evaluation method that compares two ranking functions by mixing their results and interpreting the users' click feedback. An important property of an interleaving method is its sensitivity, i.e. the ability to obtain reliable comparison outcomes with few user interactions. Several methods have been proposed so far to improve interleaving sensitivity, which can be roughly divided into two areas: (a) methods that optimize the credit assignment function (how the click feedback is interpreted), and (b) methods that achieve higher sensitivity by controlling the interleaving policy (how often a particular interleaved result page is shown). In this paper, we propose an interleaving framework that generalizes the previously studied interleaving methods in two aspects. First, it achieves a higher sensitivity by performing a joint data-driven optimization of the credit assignment function and the interleaving policy. Second, we formulate the framework to be general w.r.t. the search domain where the interleaving experiment is deployed, so that it can be applied in domains with grid-based presentation, such as image search. In order to simplify the optimization, we additionally introduce a stratified estimate of the experiment outcome. This stratification is also useful on its own, as it reduces the variance of the outcome and thus increases the interleaving sensitivity. We perform an extensive experimental study using large-scale document and image search datasets obtained from a commercial search engine. The experiments show that our proposed framework achieves marked improvements in sensitivity over effective baselines on both datasets.",2015,Conference on Information and Knowledge Management,interleaving;theoretical computer science;data mining;real time computing;computer science;
Modeling Infinite Topics on Social Behavior Data with Spatio-temporal Dependence,"Peng Wang (Chinese Academy of Sciences);Peng Zhang (University of Technology, Sydney);Chuan Zhou (Chinese Academy of Sciences);Zhao Li (Alibaba Group);Guo Li (Chinese Academy of Sciences);","2717480781,2120503182,2224226654,2337134791,2635593453","The problem of modeling topics on user behavior data in social networks has been widely studied in social marketing and social emotion analysis, where latent topic models are commonly used as the solutions. The user behavior data are highly related in time and space, which demands new latent topic models that consider both temporal and spatial distances. However, existing topic models either fail to model these two factors simultaneously, or cannot handle the high order dependence among user behaviors. In this paper we present a new nonparametric Bayesian model Time and Space Dependent Chinese Restaurant Processes (TSD-CRP for short). TSD-CRP can auto-select the number of topics and model high-order temporal and spatial dependence behind user behavior data. Empirical results on real-world data sets demonstrate the effectiveness of the proposed method.",2015,Conference on Information and Knowledge Management,topic model;social network;data science;data mining;machine learning;statistics;computer science;
Querying Temporal Drifts at Multiple Granularities,Sofia Kleisarchaki (Centre national de la recherche scientifique);Sihem Amer-Yahia (Centre national de la recherche scientifique);Ahlame Douzal-Chouakria;Vassilis Christophides (Open University of Catalonia);,"2226814701,19633248,2669081957,2478481250","There exists a large body of work on online drift detection with the goal of dynamically finding and maintaining changes in data streams. In this paper, we adopt a query-based approach to drift detection. Our approach relies on a drift index , a structure that captures drift at different time granularities and enables flexible drift queries. We formalize different drift queries that represent real-world scenarios and develop query evaluation algorithms that use different materializations of the drift index as well as strategies for online index maintenance. We describe a thorough study of the performance of our algorithms on real-world and synthetic datasets with varying change rates.",2015,Conference on Information and Knowledge Management,theoretical computer science;data mining;real time computing;
A Probabilistic Rating Auto-encoder for Personalized Recommender Systems,Huizhi Liang (University of Melbourne);Timothy Baldwin (University of Melbourne);,"2502174112,2436269535","User profiling is a key component of personalized recommender systems, and is used to generate user profiles that describe individual user interests and preferences. The increasing availability of big data is driving the urgent need for user profiling algorithms that are able to generate accurate user profiles from large-scale user behavior data. In this paper, we propose a probabilistic rating auto-encoder to perform unsupervised feature learning and generate latent user feature profiles from large-scale user rating data. Based on the generated user profiles, neighbourhood based collaborative filtering approaches have been adopted to make personalized rating predictions. The effectiveness of the proposed approach is demonstrated in experiments conducted on a real-world rating dataset from yelp.com.",2015,Conference on Information and Knowledge Management,autoencoder;user modeling;dimensionality reduction;recommender system;world wide web;information retrieval;data mining;database;machine learning;computer science;
Central Topic Model for Event-oriented Topics Mining in Microblog Stream,"Min Peng (Wuhan University);Jiahui Zhu (Wuhan University);Xuhui Li (Wuhan University);Jiajia Huang (Wuhan University);Hua Wang (Victoria University, Australia);Yanchun Zhang (Victoria University, Australia);","2636634401,2293365922,2664061689,2096326769,2306205450,2100438523","To date, data generates and arrives in the form of stream to propagate discussions of public events in microblog services. Discovering event-oriented topics from the stream will lead to a better understanding of the change of public concern. However, as the massive scale of the data stream, traditional static topic models, such as LDA, are no longer fit for topic detection and tracking tasks. In this paper, we propose a central topic model (CenTM), where a Multi-view Clustering algorithm with Two-phase Random Walk (MC-TRW) is devised to aggregate the LDA's latent topics into central topics. Furthermore, we leverage the aggregation of central topics alternately with MC-TRW and sequential topic inference to improve the scalability in the stream fashion, so as to derive the dynamic central topic model (DCenTM). Specifically, our model is able to uncover the intrinsic characteristics of the central topics and predict the trend of their intensity along a life cycle. Experimental results demonstrate that the proposed central topic model is event-oriented and of high generalization, it therefore can dispose the topic trend prediction effectively and precisely in massive data stream.",2015,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Mining Brokers in Dynamic Social Networks,Chonggang Song (National University of Singapore);Wynne Hsu (National University of Singapore);Mong Li Lee (National University of Singapore);,"2225645568,2123778117,2159408573","The theory of brokerage in sociology suggests if contacts between two parties are enabled through a third party, the latter occupies a strategic position of controlling information flows. Such individuals are called brokers and they play a key role in disseminating information. However, there is no systematic approach to identify brokers in online social networks. In this paper, we formally define the problem of detecting top-$k$ brokers given a social network and show that it is NP-hard. We develop a heuristic algorithm to find these brokers based on the weak tie theory. In order to handle the dynamic nature of online social networks, we design incremental algorithms: WeakTie-Local for unidirectional networks and WeakTie-Bi for bidirectional networks. We use two real world datasets, DBLP and Twitter, to evaluate the proposed methods. We also demonstrate how the detected brokers are useful in diffusing information across communities and propagating tweets to reach more distinct users.",2015,Conference on Information and Knowledge Management,social network analysis;world wide web;computer security;data mining;database;
What Is a Network Community?: A Novel Quality Function and Detection Algorithms,Atsushi Miyauchi (Tokyo Institute of Technology);Yasushi Kawase (Tokyo Institute of Technology);,"2152002755,2134091023","In this study, we introduce a novel quality function for a network community, which we refer to as the communitude . The communitude has a strong statistical background. Specifically, it measures the Z-score of a subset of vertices S with respect to the fraction of the number of edges within the subgraph induced by S. Due to the null model of a random graph used in the definition, our quality function focuses not only on the inside of the subgraph but also on the cut edges, unlike some quality functions for extracting dense subgraphs. To evaluate the detection ability of our quality function, we address the communitude maximization problem and its variants for realistic scenarios. For the problems, we propose a two-phase heuristic algorithm together with some modified versions. In the first phase, it repeatedly removes the vertex with the smallest degree, and then obtains the subgraph with maximum communitude over the iterations. In the second phase, the algorithm improves the obtained solution using a simple local search heuristic. This algorithm runs in linear time when the number of iterations is fixed to a constant; thus, it is applicable to massive graphs. Computational experiments using both synthetic graphs and real-world networks demonstrate the validity and reliability of the proposed quality function and algorithms.",2015,Conference on Information and Knowledge Management,induced subgraph isomorphism problem;community structure;machine learning;mathematical optimization;statistics;computer science;
Large-Scale Analysis of Dynamics of Choice Among Discrete Alternatives,Andrew Tomkins (Google);,2535415812,"The online world is rife with scenarios in which a user must select one from a finite set of alternatives: which movie to watch, which song to play, which camera to order, which website to visit. There is a long history of study of these types of questions in economics, machine learning, marketing, and psychology. However, historically the study of choice was limited to relatively modest data scales. Today, we have access to large-scale datasets providing insights into the choices of large populations of users faced with a wide variety of sets of alternatives. From such data, we are beginning to develop more detailed models of how users weigh alternatives and make selections. I'll begin this talk by covering basic models for choice, along with some standard assumptions made by these models. I'll then cover some more recent work on understanding choice in modern datasets. First, I'll discuss choice in a geographic setting, in which users make selections of restaurants. Features in this setting provide visibility into the actual time cost to travel to one alternative versus another. In addition to this real cost, we may also tease out the implications on likelihood as the set of alternatives at a particular distance becomes larger or smaller based on the local density of restaurants. The marginals of these factors provide poor quality compared to joint models suggested by choice theory. From choice of individual restaurants, I'll then move to a setting in which users consume items repeatedly: repeated purchases of a particular brand of product; repeated listens to a song; repeated visits to a favorite coffee shop; and so forth. I'll describe a simple but accurate model for this problem whose behavior moves between two regimes based on parameter choices: in one regime, users settle on particular favorites and maintain them over time; in another regime, even the most favored item will eventually be abandoned after finite reconsumptions. Finally, I'll move to a more complex scenario of sequential consumption of a range of items, and will show how the theory of discrete choice can be incorporated into the theory of markov processes, requiring a new algorithmic approach to learning the optimal solution. In all of these instances, the learned models include a per-item quality score that may be viewed as proportional to the residual likelihood of selecting the item after other factors in the choice slate have been accounted for. The work described in this talk is partly due to other researchers, and partly joint with various colleagues including Ashton Anderson, Ravi Kumar, Mohammad Mahdian, Bo Pang, Sergei Vassilvitskii and Erik Vee.",2015,Conference on Information and Knowledge Management,world wide web;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
Best First Over-Sampling for Multilabel Classification,Xusheng Ai (Soochow University);Jian Wu (Soochow University);Victor S. Sheng (University of Central Arkansas);Yufeng Yao (Soochow University);Pengpeng Zhao (Soochow University);Zhiming Cui (Soochow University);,"2430633428,2559930321,2010535889,2460457279,2138196587,2135549110","Learning from imbalanced multilabel data is a challenging task. It has attracted considerable attention recently. In this paper we propose a MultiLabel Best First Over-sampling (ML-BFO) to improve the performance of multilabel classification algorithms, based on imbalance minimization and Wilson's ENN rule. Our experimental results show that ML-BFO not only duplicates fewer samples but also reduces the imbalance level much more than two state-of-the-art multilabel sampling methods, i.e., an over-sampling method LP-ROS and an under-sampling method MLeNN. Besides, ML-BFO significantly improves the performance of multilabel classification algorithms, and performs much better than LP-ROS and MLeNN.",2015,Conference on Information and Knowledge Management,resampling;heuristic;data mining;pattern recognition;machine learning;statistics;computer science;
Exploiting Game Theoretic Analysis for Link Recommendation in Social Networks,Tong Zhao (The Chinese University of Hong Kong);H. Vicky Zhao (University of Alberta);Irwin King (The Chinese University of Hong Kong);,"2689099768,2656600412,2121363826","The popularity of Online Social Networks (OSNs) has attracted great research interests in different fields. In Economics, researchers use game theory to analyze the mechanism of network formation, which is called Network Formation Game. While in Computer Science, much effort has been done in building machine learning models to predict future or missing links. However, there are few works considering how to combine game theoretic analysis and machine learning models. Therefore, in this paper, we study the problem of Exploiting Game Theoretic Analysis for Link Recommendation in Social Networks. Our goal is to improve link recommendation accuracy via leveraging the power of Network Formation Games into machine learning models. We present two different approaches to solve this problem. First, we propose a three- phase method that straightforwardly combines game theoretic analysis with machine learning models. Second, we develop a unified model, BPRLGT , that incorporates Network Formation Game into a Bayesian ranking framework for link recommendation. Specifically, BPRLGT takes advantage of network topology and we design a game theoretic sampling approach to improve its training process. The experiments are conducted on four real world datasets and the results on all datasets demonstrate that both our proposed three-phase method and the unified ranking model outperform the baseline methods.",2015,Conference on Information and Knowledge Management,simulations and games in economics education;game complexity;algorithmic game theory;game theory;world wide web;data mining;artificial intelligence;machine learning;simulation;computer science;
Analyzing Document Intensive Business Processes using Ontology,Suman Roychoudhury (Tata Consultancy Services);Vinay Kulkarni (Tata Consultancy Services);Nikhil Bellarykar (Tata Consultancy Services);,"2310691329,2170707583,2222189569","Knowledge is manifested in an enterprise in various forms ranging from unstructured operational data, to structured information like programs, as well as relational data stored in databases to semi-structured information stored in XML files. This information embodies the core of an enterprise knowledge base and analyzing the knowledge base can result in intelligent decision making. In order to realize this goal we begin with representing and analyzing unstructured knowledge present in an enterprise. In particular, this paper presents a real life example of a document intensive business process (International Trade) and attempts to model and analyze the process in a formal way. Typically, the information contained in a document intensive business process is of operational nature and requires extensive manual verification, which is both time consuming and error prone. Therefore, this research aims to eliminate such exhaustive manual verification by constructing a knowledge base in the form of ontology and apply suitable rule based reasoners to automate the verification process.",2015,Conference on Information and Knowledge Management,open knowledge base connectivity;knowledge extraction;knowledge representation and reasoning;knowledge base;knowledge based systems;natural language processing;knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
UCUI'15: The 1st International Workshop on Understanding the City with Urban Informatics,Yashar Moshfeghi (University of Glasgow);Iadh Ounis (University of Glasgow);Craig Macdonald (University of Glasgow);Joemon M. Jose (University of Glasgow);Peter Triantafillou (University of Glasgow);Mark Livingston (University of Glasgow);Piyushimita Thakuriah (University of Glasgow);,"92283206,336997814,2148910894,2167481407,318333653,2134037074,2047364655","Urban Informatics aims to exploit the large quantities of information produced by modern cities in order to gain insights into how they function. These insights lay the foundation for improving the lives of citizens, by improving the efficacy and efficiency of public services, and satisfying complex information needs arising within this context. The goal of the workshop is to provide a multidisciplinary forum which brings together researchers in Big Data (BD), Information Retrieval (IR), Data Mining, and Urban Studies, to explore novel solutions to the numerous theoretical, practical and ethical challenges arising in this context. These include difficulties in collecting city data, creating data management infrastructures, and providing new effective and efficient information access techniques to as many users as possible in the context of a smart city. To foster the development of new BD and IR approaches in Urban Informatics, the workshop makes available a representative dataset of city data, including Internet-based visual (Flickr) and textual (Tweets and News) media collections. The workshop provides enormous opportunities for data scientists who wish to understand the complexities of working with city data, conduct innovative research within Urban Informatics, and build a long-term community in this emerging research area.",2015,Conference on Information and Knowledge Management,engineering informatics;materials informatics;informatics;big data;data science;world wide web;information retrieval;data mining;database;computer science;
ASEM: Mining Aspects and Sentiment of Events from Microblog,Ruhui Wang (Peking University);Weijing Huang (Peking University);Wei Chen (Peking University);Tengjiao Wang (Peking University);Kai Lei (Peking University);,"2228068865,2164339082,2619414614,2144373700,2262537035","Microblogs contain the most up-to-date and abundant opinion information on current events. Aspect-based opinion mining is a good way to get a comprehensive summarization of events. The most popular aspect based opinion mining models are used in the field of product and service. However, existing models are not suitable for event mining. In this paper we propose a novel probabilistic generative model (ASEM) to simultaneously discover aspects and the specified opinions. ASEM incorporate a sequence labeling model(CRF) into a generative topic model. Additionally, we adopt a set of features for separating aspects and sentiments. Moreover, we novelly present a continuously learning model. It can utilize the knowledge of one event to learn another, and get a better performance. We use five real world events to do experiment. The experimental results show that ASEM extracts aspects and sentiments well, and ASEM outperforms other state-of-art models and the intuitive two-step method.",2015,Conference on Information and Knowledge Management,topic model;data science;world wide web;data mining;machine learning;computer science;
Recommending Short-lived Dynamic Packages for Golf Booking Services,Robin Swezey;Young-joo Chung;,"2676204163,2610487806","We introduce an approach to recommending short-lived dynamic packages for golf booking services. Two challenges are addressed in this work. The first is the short life of the items, which puts the system in a state of a permanent cold start. The second is the uninformative nature of the package attributes, which makes clustering or figuring latent packages challenging. Although such settings are fairly pervasive, they have not been studied in traditional recommendation research, and there is thus a call for original approaches for recommender systems. In this paper, we introduce a hybrid method that leverages user analysis and its relation to the packages, as well as package pricing and environmental analysis, and traditional collaborative filtering. The proposed approach achieved appreciable improvement in precision compared with baselines",2015,Conference on Information and Knowledge Management,user analysis;cold start;field research;world wide web;data mining;database;artificial intelligence;simulation;computer science;
Identifying Top-k Consistent News-Casters on Twitter,Sahisnu Mazumder (Indian Institute of Technology Roorkee);Sameep Mehta (IBM);Dhaval Patel (Indian Institute of Technology Roorkee);,"2162085870,2121593309,2152020443","News-casters are Twitter users who periodically pick up interesting news from online news media and spread it to their followers' network. Existing works on Twitter user analysis have only analysed a pre-defined set of users for user modeling, influence analysis and news recommendation. The problem of identifying prominent , trustworthy and consistent news-casters is unaddressed so far. In this paper, we present a framework, NCFinder , to discover top- k consistent news-casters directly from Twitter. NCFinder uses news headlines published in online news sources to periodically collect authentic news-tweets and processes them to discover news-casters, news sources and news concepts. Next, NCFinder builds a tripartite graph among news-casters, news source and news concepts and employs HITS algorithm on it to score the news-casters on daily basis. The daily score profiles of the news-casters collected over a time-period are then used to infer top-$k$ consistent news-casters. We run NCFinder from 11th Nov. to 24th Nov., 2014 and discover top-100 consistent news-casters and their profile information.",2015,Conference on Information and Knowledge Management,news aggregator;news;internet privacy;world wide web;computer science;
ECol 2015: First international workshop on the Evaluation on Collaborative Information Seeking and Retrieval,Leif Azzopardi (University of Glasgow);Jeremy Pickens (FX Palo Alto Laboratory);Tetsuya Sakai (Waseda University);Laure Soulier (University of Toulouse);Lynda Tamine (University of Toulouse);,"2163026013,2168651388,2655523027,1986048695,62726460","Collaborative Information Seeking/Retrieval (CIS/CIR) has given rise to several challenges in terms of search behavior analysis, retrieval model formalization as well as interface design. However, the major issue of evaluation in CIS/CIR is still underexplored. The goal of this workshop is to investigate the evaluation challenges in CIS/CIR with the hope of building standardized evaluation frameworks, methodologies, and task specifications that would foster and grow the research area (in a collaborative fashion).",2015,Conference on Information and Knowledge Management,cognitive models of information retrieval;human computer information retrieval;relevance;evaluation;knowledge management;world wide web;information retrieval;data mining;computer science;
Extracting Interest Tags for Non-famous Users in Social Network,Wei He (Renmin University of China);Hongyan Liu (Tsinghua University);Jun He (Renmin University of China);Shu Tang (Renmin University of China);Xiaoyong Du (Renmin University of China);,"2705869466,2618347989,2292722654,2489670639,2160770667","Inferring interests of users in social network is important for many applications such as personalized search, recommender systems and online advertising. Most previous studies inferred users' interests based on text posted in social network, which is usually not related to their interests. In this paper, we propose a modified topic model, Bi-Labeled LDA with a term weighting scheme, to extract interest tags for users in social network. The proposed model utilize only users' relationship information without requirement for text information, and incorporates supervision into traditional LDA. Specifically, we introduce method to extract tags for non-famous user through their relationship with famous users in Twitter, and study why a non-famous user follows famous users simultaneously. Comparison with state-of-the-art methods on real dataset shows that our method is far more superior in terms of precision and recall of the extracted tag set, and also more applicable for many personalized applications. Besides, we find that a reasonable term weighting scheme can actually improve the performance further.",2015,Conference on Information and Knowledge Management,topic model;world wide web;information retrieval;data mining;database;machine learning;computer science;
ReverseCloak: Protecting Multi-level Location Privacy over Road Networks,Chao Li (University of Pittsburgh);Balaji Palanisamy (University of Pittsburgh);,"2224052144,2014838794","With advances in sensing and positioning technology, fueled by the ubiquitous deployment of wireless networks, location-aware computing has become a fundamental model for offering a wide range of life enhancing services. However, the ability to locate users and mobile objects opens doors for new threats - the intrusion of location privacy. Location anonymization refers to the process of perturbing the exact location of users as a cloaking region such that a user's location becomes indistinguishable from the location of a set of other users. A fundamental limitation of existing location anonymization techniques is that location information once perturbed to provide a certain anonymity level cannot be reversed to reduce anonymity or the degree of perturbation. This is especially a serious limiting factor in multi-level privacy-controlled scenarios where different users of the location information have different levels of access. This paper presents ReverseCloak, a new class of reversible location cloaking mechanisms that effectively support multi-level location privacy, allowing selective de-anonymization of the cloaking region to reduce the granularity of the perturbed location when suitable access credentials are provided. We evaluate the ReverseCloak techniques through extensive experiments on realistic road network traces generated by GTMobiSim. Our experiments show that the proposed techniques are efficient, scalable and provide the required level of privacy.",2015,Conference on Information and Knowledge Management,internet privacy;world wide web;computer security;
Top-k Reliable Edge Colors in Uncertain Graphs,Arijit Khan (ETH Zurich);Francesco Gullo (Yahoo!);Thomas Wohler (ETH Zurich);Francesco Bonchi (Yahoo!);,"2164403858,1979201319,2503012031,2176652147","We study the fundamental problem of finding the set of top- k edge colors that maximizes the reliability between a source node and a destination node in an uncertain and edge-colored graph. Our top- k reliable color set problem naturally arises in a variety of real-world applications including pathway finding in biological networks, topic-aware influence maximization, and team formation in social networks, among many others. In addition to the # P-completeness of the classical reliability finding problem between a source and a destination node over an uncertain graph, we prove that our problem is also NP-hard, and neither sub-modular, nor super-modular. To this end, we aim at designing effective and scalable solutions for the top- k reliable color set problem. We first introduce two baselines following the idea of repetitive inclusion of the next best edge colors, and we later develop a more efficient and effective algorithm that directly finds the highly-reliable paths while maintaining the budget on the number of edge-colors. An extensive empirical evaluation on various large-scale and real-world graph datasets illustrates that our proposed techniques are both scalable and highly accurate.",2015,Conference on Information and Knowledge Management,reliability;mathematical optimization;statistics;
Interruption-Sensitive Empty Result Feedback: Rethinking the Visual Query Feedback Paradigm for Semistructured Data,Sourav S. Bhowmick (Nanyang Technological University);Curtis E. Dyreson (Utah State University);Byron Choi (Hong Kong Baptist University);Min-Hwee Ang (Nanyang Technological University);,"2168903744,2103951309,2117040297,2229201773","The usability of visual querying schemes for tree and graph-structured data can be greatly enhanced by providing feedback during query construction, but feedback at inopportune times can hamper query construction. In this paper, we rethink the traditional way of providing feedback. We describe a novel vision of interruption-sensitive query feedback where relevant notifications are delivered quickly but at an appropriate moment when the mental workload of the user is low. Though we focus on one class of query feedback, namely empty result detection , where a user is notified when a partially constructed visual query yields an empty result, our new paradigm is applicable to other kinds of feedback. We present a framework called iSERF that bridges the classical database problem of empty-result detection with intelligent notification management from the domains of HCI and psychology. Instead of immediate notification, iSERF considers the structure of query formulation tasks and breakpoints when reasoning about when to notify the user. We present an HCI-inspired model to quantify the performance bounds that iSERF must abide by for checking for an empty result in order to ensure interruption-sensitive notification at optimal breakpoints. We implement this framework in the context of visual XML query formulation and highlight its effectiveness empirically.",2015,Conference on Information and Knowledge Management,sargable;rdf query language;web search query;web query classification;query expansion;query optimization;breakpoint;query language;xml;graph;world wide web;information retrieval;data mining;database;computer science;
Transductive Domain Adaptation with Affinity Learning,Le Shu (Temple University);Longin Jan Latecki (Temple University);,"2171431502,214878226","We study the problem of domain adaptation, which aims to adapt the classifiers trained on a labeled source domain to an unlabeled target domain. We propose a novel method to solve domain adaptation task in a transductive setting. The proposed method bridges the distribution gap between source domain and target domain through affinity learning. It exploits the existence of a subset of data points in target domain which distribute similarly to the data points in the source domain. These data points act as the bridge that facilitates the data similarities propagation across domains. We also propose to control the relative importance of intra- and inter-domain similarities to boost the similarity propagation. In our approach, we first construct the similarity matrix which encodes both the intra- and inter-domain similarities. We then learn the true similarities among data points in joint manifold using graph diffusion. We demonstrate that with improved similarities between source and target data, spectral embedding provides a better data representation, which boosts the prediction accuracy. The effectiveness of our method is validated on standard benchmark datasets for visual object recognition (multi-category).",2015,Conference on Information and Knowledge Management,data mining;pattern recognition;machine learning;computer science;
WaveCluster with Differential Privacy,Ling Chen (North Carolina State University);Ting Yu (Qatar Computing Research Institute);Rada Chirkova (North Carolina State University);,"2306064245,2663675160,1983031712","WaveCluster is an important family of grid-based clustering algorithms that are capable of finding clusters of arbitrary shapes. In this paper, we investigate techniques to perform WaveCluster while ensuring differential privacy.Our goal is to develop a general technique for achieving differential privacy on WaveCluster that accommodates different wavelet transforms. We show that straightforward techniques based on synthetic data generation and introduction of random noise when quantizing the data, though generally preserving the distribution of data, often introduce too much noise to preserve useful clusters. We then propose two optimized techniques, PrivTHR and PrivTHR em , which can significantly reduce data distortion during two key steps of WaveCluster: the quantization step and the significant grid identification step. We conduct extensive experiments based on four datasets that are particularly interesting in the context of clustering, and show that PrivTHR and PrivTHR em achieve high utility when privacy budgets are properly allocated, conforming to our theoretical analysis.",2015,Conference on Information and Knowledge Management,differential privacy;technical report;wavelet transform;cluster analysis;theoretical computer science;world wide web;computer security;data mining;database;machine learning;statistics;computer science;
Scalable Facility Location for Massive Graphs on Pregel-like Systems,Kiran Garimella (Aalto University);Gianmarco De Francisci Morales (Aalto University);Aristides Gionis (Aalto University);Mauro Sozio (Télécom ParisTech);,"1979823234,2153118160,737311942,2665718924","We propose a new scalable algorithm for the facility-location problem. We study the graph setting , where the cost of serving a client from a facility is represented by the shortest-path distance on a graph. This setting is applicable to various problems arising in the Web and social media, and allows to leverage the inherent sparsity of such graphs. To obtain truly scalable performance, we design a parallel algorithm that operates on clusters of shared-nothing machines. In particular, we target modern Pregel-like architectures, and we implement our algorithm on Apache Giraph. Our work builds upon previous results: a facility location algorithm for the PRAM model, a recent distance-sketching method for massive graphs, and a parallel algorithm to finding maximal independent sets. The main challenge is to adapt those building blocks to the distributed graph setting, while maintaining the approximation guarantee and limiting the amount of distributed communication. Extensive experimental results show that our algorithm scales gracefully to graphs with billions of edges, while, in terms of quality, being competitive with state-of-the-art sequential algorithms.",2015,Conference on Information and Knowledge Management,facility location problem;theoretical computer science;parallel computing;operating system;distributed computing;data mining;computer science;
Does Vertical Bring more Satisfaction?: Predicting Search Satisfaction in a Heterogeneous Environment,Ye Chen (Tsinghua University);Yiqun Liu (Tsinghua University);Ke Zhou (Yahoo!);Meng Wang (Hefei University of Technology);Min Zhang (Tsinghua University);Shaoping Ma (Tsinghua University);,"2305217790,2111097927,2308026972,2300598665,2526008467,2109195263","The study of search satisfaction is one of the prime concerns in search performance evaluation research. Most existing works on search satisfaction primarily rely on the hypothesis that all results on search engine result pages (SERPs) are homogeneous. However, a variety of heterogeneous vertical results such as videos, images and instant answers are aggregated into SERPs by search engines to improve the diversity and quality of search results. In this paper, we carry out a lab-based user study with specifically designed SERPs to determine how verticals with different qualities and presentation styles affect search satisfaction. Users' satisfaction feedback and external assessors' satisfaction annotations are both collected to make a comparison regarding the perception of search satisfaction. Mouse click-through / movement data and eye movement information are also collected such that we can investigate the influence of vertical results from the perspectives of both benefit and cost. Finally, a vertical-aware learning-based prediction method is proposed to predict search satisfaction on aggregated SERPs. To the best of our knowledge, this paper is the first to analyze the effect of verticals on search satisfaction. The results show that verticals with different qualities, presentation styles and positions have different effects on search satisfaction, among which Encyclopedia verticals, as well as Download verticals, will bring the largest improvement. Furthermore, our proposed vertical-aware prediction method outperforms state-of-the-art methods that are designed for search satisfaction prediction in homogeneous environment.",2015,Conference on Information and Knowledge Management,computer user satisfaction;prediction;multimedia;world wide web;data mining;simulation;statistics;
A Unified Posterior Regularized Topic Model with Maximum Margin for Learning-to-Rank,Shoaib Jameel (Cardiff University);Wai Lam (The Chinese University of Hong Kong);Steven Schockaert (Cardiff University);Lidong Bing (Carnegie Mellon University);,"2101481170,2119595446,2407586687,2160800796","While most methods for learning-to-rank documents only consider relevance scores as features, better results can often be obtained by taking into account the latent topic structure of the document collection. Existing approaches that consider latent topics follow a two-stage approach, in which topics are discovered in an unsupervised way, as usual, and then used as features for the learning-to-rank task. In contrast, we propose a learning-to-rank framework which integrates the supervised learning of a maximum margin classifier with the discovery of a suitable probabilistic topic model. In this way, the labelled data that is available for the learning-to-rank task can be exploited to identify the most appropriate topics. To this end, we use a unified constrained optimization framework, which can dynamically compute the latent topic similarity score between the query and the document. Our experimental results show a consistent improvement over the state-of-the-art learning-to-rank models.",2015,Conference on Information and Knowledge Management,dynamic topic model;topic model;latent dirichlet allocation;learning to rank;information retrieval;data mining;pattern recognition;machine learning;computer science;
A Study of Query Length Heuristics in Information Retrieval,Yuanhua Lv (Microsoft);,2132538679,"Query length has generally been regarded as a query-specific constant that does not affect document ranking. In this paper, we reveal that query length actually interacts with term frequency (TF) normalization, a key component of all effective retrieval models. Specifically, the longer the query is, the smaller the TF decay speed should be. In order to study the impact of query length, we present a desirable formal constraint to capture the heuristic of query length for retrieval. Our constraint analysis shows that current state-of-the-art retrieval functions, including BM25 and language models, fail to satisfy the constraint, and that, in order to solve this problem, the TF normalization component in a retrieval function should be adapted to query length. As an application, we develop a simple regression algorithm to adapt BM25 to query length, and demonstrate its effectiveness on several representative TREC collections.",2015,Conference on Information and Knowledge Management,ranking;sargable;boolean conjunctive query;web query classification;query expansion;query optimization;information retrieval;data mining;database;computer science;
Improving Collaborative Filtering via Hidden Structured Constraint,Qing Zhang (Peking University);Houfeng Wang (Peking University);,"2636887956,2717761748","Matrix factorization models, as one of the most powerful Collaborative Filtering approaches, have greatly advanced the recommendation tasks. However, few of them are able to explicitly consider structured constraint for modeling user interests. To solve this problem, we propose a novel matrix factorization model with adaptive graph regularization framework, which can automatically discover latent user communities jointly with learning latent user representations, to enhance the discriminative power for recommendation. Experiments on real-world datasets demonstrate the effectiveness of the proposed method.",2015,Conference on Information and Knowledge Management,collaborative filtering;data mining;pattern recognition;machine learning;computer science;
Towards Scale-out Capability on Social Graphs,Haichuan Shang (National Institute of Information and Communications Technology);Xiang Zhao (National University of Defense Technology);R. Uday Kiran (National Institute of Information and Communications Technology);Masaru Kitsuregawa (National Institute of Informatics);,"2320774486,2675323951,2721972879,2627529059","The development of cloud storage and computing has facilitated the rise of various big data applications. As a representative high performance computing (HPC) workload, graph processing is becoming a part of cloud computing. However, scalable computing on large graphs is still dominated by HPC solutions, which require high performance all-to-all collective operations over torus (or mesh) networking. Implementing those torus-based algorithms on commodity clusters, e.g., cloud computing infrastructures, can result in great latency due to inefficient communication. Moreover, designing a highly scalable system for large social graphs, is far from being trivial, as intrinsic features of social graphs, e.g., degree skewness and lacking of locality, often profoundly limit the extent of parallelism. To resolve the challenges, we explore the iceberg of developing a scalable system for processing large social graphs on commodity clusters. In particular, we focus on the scale-out capability of the system. We propose a novel separator-combiner based query processing engine which provides native load-balancing and very low communication overhead, such that increasinglylarger graphs can be simply addressed by adding more computing nodes to the cluster.The proposed system achieves remarkable scale-out capability in processing large social graphs with skew degree distributions, while providing many critical features for big data analytics, such as easy-to-use API, fault-tolerance and recovery. We implement the system as a portable and easily configurable library, and conduct comprehensive experimental studies to demonstrate its effectiveness and efficiency.",2015,Conference on Information and Knowledge Management,graph database;social network;performance;distributed database;theoretical computer science;world wide web;distributed computing;data mining;database;machine learning;simulation;computer science;
KSGM: Keynode-driven Scalable Graph Matching,Xilun Chen (Arizona State University);K. Selçuk Candan (Arizona State University);Maria Luisa Sapino (University of Turin);Paulo Shakarian (Arizona State University);,"2224976689,674992784,351919550,102302551","Understanding how a given pair of graphs align with each other (also known as the graph matching problem) is a critical task in many search, classification, and analysis applications. Unfortunately, the problem of maximum common subgraph isomorphism between two graphs is a well known NP-hard problem, rendering it impractical to search for exact graph alignments. While there are several heuristics, most of these analyze and encode global and local structural information for every node of the graph and then rank pairs of nodes across the two graphs based on their structural similarities. Moreover, many algorithms involve a post-processing (or refinement) step which aims to improve the initial matching accuracy. In this paper we note that the expensive refinement phase of graph matching algorithms is not practical in any application where scalability is critical. It is also impractical to seek structural similarity between all pairs of nodes. We argue that a more practical and scalable solution is to seek structural keynodes of the input graphs that can be used to limit the amount of time needed to search for alignments. Naturally, these keynodes need to be selected carefully to prevent any degradations in accuracy during the alignment process. Given this motivation, in this paper, we first present a structural keynode extraction (SKE) algorithm and then use structural keynodes obtained during off-line processing for keynode-driven scalable graph matching (KSGM). Experiments show that the proposed keynode-driven scalable graph matching algorithms produce alignments that are as accurate as (or better than) the state-of-the-art algorithms, with significantly faster online executions.",2015,Conference on Information and Knowledge Management,distance hereditary graph;complement graph;graph bandwidth;comparability graph;3 dimensional matching;null graph;critical graph;graph product;clique width;graph;null model;bipartite graph;matching;theoretical computer science;machine learning;computer science;
DeepCamera: A Unified Framework for Recognizing Places-of-Interest based on Deep ConvNets,Pai Peng (Zhejiang University);Hongxiang Chen (Zhejiang University);Lidan Shou (Zhejiang University);Ke Chen (Zhejiang University);Gang Chen (Zhejiang University);Chang Xu (Zhejiang University);,"2149470536,2283884976,2118321968,2279580101,2125776506,2724059614","In this work, we present a novel project called DeepCamera(DC) for recognizing places-of-interest(POI) with smartphones. Our framework is based on deep convolutional neural networks(ConvNets) which are currently state-of-the-art solutions to vision recognition tasks such as our mission. We propose a novel ConvNet by introducing a new layer called ""spatial layer"" which captures spatial knowledge from a geographic view. As a result, both spatial and visual knowledge contribute to generating a hybrid probability distribution over all possible POI candidates. Furthermore, we compress multiple trained deep ConvNets into one single shallow net called ""shNet"" which achieves competitive performance with ensemble methods. Our preliminary experiments conducted on real-world dataset have shown promising POI recognition results.",2015,Conference on Information and Knowledge Management,deep learning;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
A Network-Aware Approach for Searching As-You-Type in Social Media,Paul Lagrée (French Institute for Research in Computer Science and Automation);Bogdan Cautis (French Institute for Research in Computer Science and Automation);Hossein Vahabi (Yahoo!);,"2163442402,335134206,2190435107","We present in this paper a novel approach for as-you-type top- k keyword search over social media. We adopt a natural ""network-aware"" interpretation for information relevance, by which information produced by users who are closer to the seeker is considered more relevant. In practice, this query model poses new challenges for effectiveness and efficiency in online search, even when a complete query is given as input in one keystroke. This is mainly because it requires a joint exploration of the social space and classic IR indexes such as inverted lists. We describe a memory-efficient and incremental prefix-based retrieval algorithm, which also exhibits an anytime behavior, allowing to output the most likely answer within any chosen running-time limit. We evaluate it through extensive experiments for several applications and search scenarios, including searching for posts in micro-blogging (Twitter and Tumblr), as well as searching for businesses based on reviews in Yelp. They show that our solution is effective in answering real-time as-you-type searches over social media.",2015,Conference on Information and Knowledge Management,social network;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Improving Microblog Retrieval with Feedback Entity Model,Feifan Fan (Peking University);Runwei Qiang (Peking University);Chao Lv (Peking University);Jianwu Yang (Peking University);,"2156639595,2123660618,2138937154,2162807091","When searching over the microblogging, users prefer using queries including terms that represent some specific entities. Meanwhile, tweets, though limited within 140 characters, are often generated with one or more entities. Entities, as an important part of tweets, usually convey rich information for modeling relevance from new perspectives. In this paper, we propose a feedback entity model and integrate it into an adaptive language modeling framework in order to improve the retrieval performance. The feedback entity model is estimated with the latest entity-associated tweets based upon a regularized maximum likelihood criterion. More specifically, we assume that the entity-associated tweets are generated by a mixture model, which consists of the entity model, the domain-specific language model and the collection language model. Experimental results on two public Text Retrieval Conference (TREC) Twitter corpora demonstrate the significant superiority of our approach over the state-of-the-art baselines.",2015,Conference on Information and Knowledge Management,free base;language model;world wide web;information retrieval;data mining;computer science;
Probabilistic Non-negative Inconsistent-resolution Matrices Factorization,Masahiro Kohjima (Nippon Telegraph and Telephone);Tatsushi Matsubayashi (Nippon Telegraph and Telephone);Hiroshi Sawada (Nippon Telegraph and Telephone);,"2228706800,2171838580,2099875912","In this paper, we tackle with the problem of analyzing datasets with different resolution such as a pair of user's individual data and user group's data, for example ""userA visited shopA 5 times"" and ""users whose attributes are men purchased itemA 80 times in total"". In order to establish a basic approach to this problem, we focus on the simplified scenario and propose a new probabilistic model called probabilistic non-negative inconsistent-resolution matrices factorization (pNimf). pNimf is rigorously derived from the data generative process using latent high-resolution data which underlie low-resolution data. We conduct experiments on real purchase log data and confirm that the proposed model provides superior performance, and that the performance improves as the number of low-resolution data increases. These results imply that our way of modeling using latent high-resolution data can become the basic approach to the problem of analyzing dataset with different resolution.",2015,Conference on Information and Knowledge Management,non negative matrix factorization;theoretical computer science;data mining;database;machine learning;statistics;computer science;
Collaborative Prediction for Multi-entity Interaction With Hierarchical Representation,Qiang Liu (Chinese Academy of Sciences);Shu Wu (Chinese Academy of Sciences);Liang Wang (Chinese Academy of Sciences);,"2698910997,2122580694,2226151461","With the rapid growth of Internet applications, there are more and more entities in interaction scenarios, and thus collaborative prediction for multi-entity interaction is becoming a significant problem. The state-of-the-art methods, e.g., tensor factorization and factorization machine, predict multi-entity interaction based on calculating the similarity among all entities. However, these methods are usually not able to reveal the joint characteristics of entities in the interaction. Besides, some methods may succeed in one specific application, but they can not be extended effectively for other applications or interaction scenarios with more entities. In this work, we propose a Hierarchical Interaction Representation (HIR) model, which models the mutual action among different entities as a joint representation. We generate the interaction representation of two entities via tensor multiplication, which is preformed iteratively to construct a hierarchical structure among all entities. Moreover, we employ several hidden layers to reveal the underlying properties of this interaction and enhance the model performance. After generating final representation, the prediction can be calculated using a variety of machine learning methods according to different tasks (i.e., linear regression for regression tasks, pair-wise ranking for ranking tasks and logistic regression for classification tasks). Experimental results show that our proposed HIR model yields significant improvements over the competitive compared methods in four different application scenarios (i.e., general recommendation, context-aware recommendation, latent collaborative retrieval and click-through rate prediction).",2015,Conference on Information and Knowledge Management,data mining;pattern recognition;machine learning;computer science;
Collaborating between Local and Global Learning for Distributed Online Multiple Tasks,Xin Jin (Chinese Academy of Sciences);Ping Luo (Chinese Academy of Sciences);Fuzhen Zhuang (Chinese Academy of Sciences);Jia He (Chinese Academy of Sciences);Qing He (Chinese Academy of Sciences);,"2695402291,2291210646,2050314250,2145519872,2167314737","This paper studies the novel learning scenarios of Distributed Online Multi-tasks (DOM), where the learning individuals with continuously arriving data are distributed separately and meanwhile they need to learn individual models collaboratively. It has three characteristics: distributed learning, online learning and multi-task learning. It is motivated by the emerging applications of wearable devices, which aim to provide intelligent monitoring services, such as health emergency alarming and movement recognition. To the best of our knowledge, no previous work has been done for this kind of problems. Thus, in this paper a collaborative learning scheme is proposed for this problem. Specifically, it performs local learning and global learning alternately. First, each client performs online learning using the increasing data locally. Then, DOM switches to global learning on the server side when some condition is triggered by clients. Here, an asynchronous online multi-task learning method is proposed for global learning. In this step, only this client's model, which triggers the global learning, is updated with the support of the difficult local data instances and the other clients' models. The experiments from 4 applications show that the proposed method of global learning can improve local learning significantly. DOM framework is effective, since it can share knowledge among distributed tasks and obtain better models than learning them separately. It is also communication efficient, which only requires the clients send a small portion of raw data to the server.",2015,Conference on Information and Knowledge Management,online machine learning;stability;inductive transfer;multi task learning;robot learning;synchronous learning;competitive learning;error driven learning;active learning;proactive learning;instance based learning;knowledge management;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Crowdsourcing Pareto-Optimal Object Finding By Pairwise Comparisons,Abolfazl Asudeh (University of Texas at Arlington);Gensheng Zhang (University of Texas at Arlington);Naeemul Hassan (University of Texas at Arlington);Chengkai Li (University of Texas at Arlington);Gergely V. Zaruba (University of Texas at Arlington);,"1997286123,2130615231,2222345529,2145831560,149384553","This is the first study of crowdsourcing Pareto-optimal object finding over partial orders and by pairwise comparisons, which has applications in public opinion collection, group decision making, and information exploration. Departing from prior studies on crowdsourcing skyline and ranking queries, it considers the case where objects do not have explicit attributes and preference relations on objects are strict partial orders. The partial orders are derived by aggregating crowdsourcers' responses to pairwise comparison questions. The goal is to find all Pareto-optimal objects by the fewest possible questions. It employs an iterative question-selection framework. Guided by the principle of eagerly identifying non-Pareto optimal objects, the framework only chooses candidate questions which must satisfy three conditions. This design is both sufficient and efficient, as it is proven to find a short terminal question sequence. The framework is further steered by two ideas---macro-ordering and micro-ordering. By different micro-ordering heuristics, the framework is instantiated into several algorithms with varying power in pruning questions. Experiment results using both real crowdsourcing marketplace and simulations exhibited not only orders of magnitude reductions in questions when compared with a brute-force approach, but also close-to-optimal performance from the most efficient instantiation.",2015,Conference on Information and Knowledge Management,crowdsourcing;pairwise comparison;partially ordered set;data science;data mining;machine learning;statistics;computer science;
DifRec: A Social-Diffusion-Aware Recommender System,Hossein Vahabi (Yahoo!);Iordanis Koutsopoulos (Athens University of Economics and Business);Francesco Gullo (Yahoo!);Maria Halkidi (University of Piraeus);,"2190435107,436372673,1979201319,339332626","Recommender systems used in current online social platforms make recommendations by only considering how relevant an item is to a specific user but they ignore the fact that, thanks to mechanisms like sharing or re-posting across the underlying social network, an item recommended to a user i propagates through the network and can reach another user j without needing to be explicitly recommended to j too. Overlooking this fact may lead to an inefficient use of the limited recommendation slots. These slots can instead be exploited more profitably by avoiding unnecessary duplicates and recommending other equally relevant items. In this work we take a step towards rethinking recommender systems by exploiting the anticipated social-network information diffusion and withholding recommendation of items that are expected to reach a user through sharing/re-posting. We devise a novel recommender system, DifRec, by formulating the problem of maximizing the total user engagement as an allocation problem in a properly-defined neighborhoodness graph, i.e., a graph that models the conflicts of recommending an item to a user who will receive it anyway by social diffusion. We show that the problem is NP-hard and propose efficient heuristics to solve it. We assess the performance of our DifRec by involving real data from Tumblr platform. We obtain substantial improvements in overall user engagement (130%--190%) over the real recommender system embedded in Tumblr and over various existing recommender systems.",2015,Conference on Information and Knowledge Management,multimedia;world wide web;data mining;database;computer science;
A Data-Driven Approach to Distinguish Cyber-Attacks from Physical Faults in a Smart Grid,Adnan Anwar (University of New South Wales);Abdun Naser Mahmood (University of New South Wales);Zubair Shah (University of New South Wales);,"2110451004,2095913062,2609482565","Recently, there has been significant increase in interest on Smart Grid security. Researchers have proposed various techniques to detect cyber-attacks using sensor data. However, there has been little work to distinguish a cyber-attack from a power system physical fault. A serious operational failure in physical power grid may occur from the mitigation strategies if fault is wrongly classified as a cyber-attack or vice-versa. In this paper, we utilize a data-driven approach to accurately differentiate the physical faults from cyber-attacks. First, we create a realistic dataset by generating different types of faults and cyber-attacks on the IEEE 30 bus benchmark test system. With extensive experiments, we observe that most of the established supervised methods perform poorly for the classification of faults and cyber-attacks specially for the practical datasets. Hence, we provide a data-driven approach where labelled data are projected in a new low-dimensional subspace using Principal Component Analysis (PCA). Next, Sequential Minimal Optimization (SMO) based Support Vectors are trained using the new projection of the original dataset. With both simulated and practical datasets, we have observed that the proposed classification method outperforms other existing popular supervised classification approaches considering the cyber-attack and fault datasets.",2015,Conference on Information and Knowledge Management,smart grid;fault;anomaly;computer security;data mining;machine learning;computer science;
Sentiment Extraction by Leveraging Aspect-Opinion Association Structure,Li Zhao (Tsinghua University);Minlie Huang (Tsinghua University);Jiashen Sun (Samsung);Hengliang Luo (Samsung);Xiankai Yang (Beijing University of Posts and Telecommunications);Xiaoyan Zhu (Tsinghua University);,"2695429572,2162268045,2644886845,2337737746,2223279818,2147746173","Sentiment extraction aims to extract and group the task of extracting and grouping aspect and opinion words from online reviews. Previous works usually extract aspect and opinion words by leveraging association between a single pair of aspect and opinion word[5] [14] [9] [4][11], but the structure of aspect and opinion word clusters has not been fully exploited. In this paper, we investigate the aspect-opinion association structure , and propose a ""first clustering, then extracting"" unsupervised model to leverage properties of the structure for sentiment extraction. For the clustering purpose, we formalise a novel concept syntactic distribution consistency as soft constraint in the framework of posterior regularization; for the extraction purpose, we extract aspect and opinion words based on cluster-cluster association. In comparison to traditional word-word association, we show that cluster-cluster association is a much stronger signal to distinguish aspect (opinion) words from non-aspect (non-opinion) words. Extensive experiments demonstrate the effectiveness of the proposed approach and the advantages against state-of-the-art baselines.",2015,Conference on Information and Knowledge Management,sentiment analysis;data science;natural language processing;data mining;pattern recognition;computer science;
Weakly Supervised Natural Language Processing Framework for Abstractive Multi-Document Summarization: Weakly Supervised Abstractive Multi-Document Summarization,Peng Li (University of Texas at Arlington);Weidong Cai (University of Sydney);Heng Huang (University of Texas at Arlington);,"2432045502,2098283194,2137533801","In this paper, we propose a new weakly supervised abstractive news summarization framework using pattern based approaches. Our system first generates meaningful patterns from sentences. Then, in order to precisely cluster patterns, we propose a novel semisupervised pattern learning algorithm that leverages a hand-crafted list of topic-relevant keywords, which are the only weakly supervised information used by our framework to generate aspect-oriented summarization. After that, our system generates new patterns by fusing existing patterns and selecting top ranked new patterns via the recurrent neural network language model. Finally, we introduce a new pattern based surface realization algorithm to generate abstractive summaries. Automatic and manual evaluations demonstrate the effectiveness and advantages of our new methods. Code is available at: https://github.com/jerryli1981",2015,Conference on Information and Knowledge Management,recurrent neural network;automatic summarization;data mining;pattern recognition;machine learning;computer science;
Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model,Pavel Metrikov (Northeastern University);Virgil Pavlu (Northeastern University);Javed A. Aslam (Northeastern University);,"41409495,2579520042,1997938366","Existing approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors. A document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.",2015,Conference on Information and Knowledge Management,crowdsourcing;learning to rank;data science;information retrieval;data mining;machine learning;computer science;
NWSearch 2015: International Workshop on Novel Web Search Interfaces and Systems,Davood Rafiei (University of Alberta);Katsumi Tanaka (Kyoto University);,"272765103,2100196114","Held for the first time in conjunction with the ACM International Conference on Information and Knowledge Management (CIKM), NWSearch 2015 aims to bring together researchers, developers and practitioners who are interested in pushing the search boundary on the Web and exploring more novel forms of searches, interfaces, task formulations, and result organizations and presentations. In particular, the workshop seeks to identify some of the problems and challenges facing the development of such tools and interfaces and to flourish new ideas and findings that can shape or influence future research directions and developments. The workshop organizers solicited contributions that would fall within the large spectrum of human-computer interaction in one extreme and system production and development in the other extreme.",2015,Conference on Information and Knowledge Management,web modeling;web development;human computer interaction;world wide web;information retrieval;data mining;database;computer science;
Range Search on Uncertain Trajectories,"Liming Zhan (University of New South Wales);Ying Zhang (University of Technology, Sydney);Wenjie Zhang (University of New South Wales);Xiaoyang Wang (University of New South Wales);Xuemin Lin (University of New South Wales);","2165234013,2604265191,2232753573,2697402229,2125481875","The range search on trajectories is fundamental in a wide spectrum of applications such as environment monitoring and location based services. In practice, a large portion of spatio-temporal data in the above applications is generated with low sampling rate and the uncertainty arises between two subsequent observations of a moving object. To make sense of the uncertain trajectory data, it is critical to properly model the uncertainty of the trajectories and develop efficient range search algorithms on the new model. Assuming uncertain trajectories are modeled by the popular Markov Chains, in this paper we investigate the problem of range search on uncertain trajectories. In particular, we propose a general framework for range search on uncertain trajectories following the filtering-and-refinement paradigm where summaries of uncertain trajectories are constructed to facilitate the filtering process. Moreover, statistics based and partition based filtering techniques are developed to enhance the filtering capabilities. Comprehensive experiments demonstrate the effectiveness and efficiency of our new techniques.",2015,Conference on Information and Knowledge Management,data mining;simulation;mathematical optimization;
On Gapped Set Intersection Size Estimation,Chen Chen (University of New South Wales);Jianbin Qin (University of New South Wales);Wei Wang (University of New South Wales);,"2701039591,2693238642,2425880155","There exists considerable literature on estimating the cardinality of set intersection result. In this paper, we consider a generalized problem for integer sets where, given a gap parameter δ, two elements are deemed as matches if their numeric difference equals δ or is within δ. We call this problem the gapped set intersection size estimation ( GSISE/ ), and it can be used to model applications in database systems, data mining, and information retrieval. We first distinguish two subtypes of the estimation problem: the point gap estimation and range gap estimation. We propose optimized sketches to tackle the two problems efficiently and effectively with theoretical guarantees. We demonstrate the usage of our proposed techniques in mining top- K related keywords efficiently, by integrating with an inverted index. Finally, substantial experiments based on a large subset of the ClueWed09 dataset demonstrate the efficiency and effectiveness of the proposed methods.",2015,Conference on Information and Knowledge Management,search engine indexing;world wide web;data mining;machine learning;statistics;computer science;
Personalized Recommendation Meets Your Next Favorite,Qiang Song (Chinese Academy of Sciences);Jian Cheng (Chinese Academy of Sciences);Ting Yuan (Chinese Academy of Sciences);Hanqing Lu (Chinese Academy of Sciences);,"2708766351,2337615961,2720320996,2096321700","A comprehensive understanding of user's item selection behavior is not only essential to many scientific disciplines, but also has a profound business impact on online recommendation. Recent researches have discovered that user's favorites can be divided into 2 categories: long-term and short-term. User's item selection behavior is a mixed decision of her long and short-term favorites. In this paper, we propose a unified model, namely S tates T ransition p A ir-wise R anking Model (STAR), to address users' favorites mining for sequential-set recommendation. Our method utilizes a transition graph for collaborative filtering that accounts for mining user's short-term favorites, jointed with a generative topic model for expressing user's long-term favorites. Furthermore, a user's specific prior is introduced into our unified model for better modeling personalization. Technically, we develop a pair-wise ranking loss function for parameters learning. Empirically, we measure the effectiveness of our method using two real-world datasets and the results show that our method outperforms state-of-the-art methods.",2015,Conference on Information and Knowledge Management,recommender system;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
What Users Ask a Search Engine: Analyzing One Billion Russian Question Queries,Michael Völske (Weimar Institute);Pavel Braslavski (Ural Federal University);Matthias Hagen (Weimar Institute);Galina Lezina (Ural Federal University);Benno Stein (Weimar Institute);,"300255710,2025620057,2097926291,2111478572,2134393620","We analyze the question queries submitted to a large commercial web search engine to get insights about what people ask, and to better tailor the search results to the users' needs. Based on a dataset of about one billion question queries submitted during the year 2012, we investigate askers' querying behavior with the support of automatic query categorization. While the importance of question queries is likely to increase, at present they only make up 3-4% of the total search traffic. Since questions are such a small part of the query stream, and are more likely to be unique than shorter queries, click-through information is typically rather sparse. Thus, query categorization methods based on the categories of clicked web documents do not work well for questions. As an alternative, we propose a robust question query classification method that uses the labeled questions from a large community question answering platform (CQA) as a training set. The resulting classifier is then transferred to the web search questions. Even though questions on CQA platforms tend to be different to web search questions, our categorization method proves competitive with strong baselines with respect to classification accuracy. To show the scalability of our proposed method we apply the classifiers to about one billion question queries and discuss the trade-offs between performance and accuracy that different classification models offer.",2015,Conference on Information and Knowledge Management,web search query;web query classification;world wide web;information retrieval;data mining;database;computer science;
An Inference Approach to Basic Level of Categorization,Zhongyuan Wang (Renmin University of China);Haixun Wang (Facebook);Ji-Rong Wen (Renmin University of China);Yanghua Xiao (Fudan University);,"2674925434,2116756368,2593770520,2675838241","Humans understand the world by classifying objects into an appropriate level of categories. This process is often automatic and subconscious. Psychologists and linguists call it as Basic-level Categorization ( BLC ). BLC can benefit lots of applications such as knowledge panel, advertising and recommendation. However, how to quantify basic-level concepts is still an open problem. Recently, much work focuses on constructing knowledge bases or semantic networks from web scale text corpora, which makes it possible for the first time to analyze computational approaches for deriving BLC. In this paper, we introduce a method based on typicality and PMI for BLC. We compare it with a few existing measures such as NPMI and commute time to understand its essence, and conduct extensive experiments to show the effectiveness of our approach. We also give a real application example to show how BLC can help sponsored search.",2015,Conference on Information and Knowledge Management,conceptualization;semantic network;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Ordering Selection Operators Under Partial Ignorance,"Khaled H. Alyoubi (Birkbeck, University of London);Sven Helmer (Free University of Bozen-Bolzano);Peter T. Wood (Birkbeck, University of London);","2231032145,2147421714,2301950271","Optimising queries in real-world situations under imperfect conditions is still a problem that has not been fully solved. We consider finding the optimal order in which to execute a given set of selection operators under partial ignorance of their selectivities. The selectivities are modelled as intervals rather than exact values and we apply a concept from decision theory, the minimisation of the maximum regret, as a measure of optimality. The associated decision problem turns out to be NP-hard, which renders a brute-force approach to solving it impractical. Nevertheless, by investigating properties of the problem and identifying special cases which can be solved in polynomial time, we gain insight that we use to develop a novel heuristic for solving the general problem. We also evaluate minmax regret query optimisation experimentally, showing that it outperforms a currently employed strategy of optimisers that uses mean values for uncertain parameters.",2015,Conference on Information and Knowledge Management,decision theory;machine learning;mathematical optimization;statistics;
DOLAP 2015 Workshop Summary,Carlos Garcia-Alvarado (University of Houston);Carlos Ordonez (University of Houston);Il-Yeol Song (Drexel University);,"2016997139,2165938062,2148782644","The ACM DOLAP workshop presents research that bridges data warehousing, On-Line Analytical Processing (OLAP), and other large-scale data processing platforms. The program has four interesting sessions on data warehouse design, database modeling, query processing, and text processing, as well as an invited paper on Big Data Database Design.",2015,Conference on Information and Knowledge Management,online analytical processing;data science;data mining;database;computer science;
Identifying Attractive News Headlines for Social Media,Sawa Kourogi (Hosei University);Hiroyuki Fujishiro (Hosei University);Akisato Kimura (Nippon Telegraph and Telephone);Hitoshi Nishikawa (Tokyo Institute of Technology);,"2225660326,2222544764,2290295929,2233550808","In the past, leading newspaper companies and broadcasters were the sole distributors of news articles, and thus news consumers simply received news articles from those outlets at regular intervals. However, the growth of social media and smart devices led to a considerable change in this traditional relationship between news providers and consumers. Hundreds of thousands of news articles are now distributed on social media, and consumers can access those articles at any time via smart devices. This has meant that news providers are under pressure to find ways of engaging the attention of consumers. This paper provides a novel solution to this problem by identifying attractive headlines as a gateway to news articles. We first perform one of the first investigations of news headlines on a major viral medium. Using our investigation as a basis, we also propose a learning-to-rank method that suggests promising news headlines. Our experiments with 2,000 news articles demonstrate that our proposed method can accurately identify attractive news headlines from the candidates and reveals several promising factors of making news articles go viral.",2015,Conference on Information and Knowledge Management,news values;news media;social media;learning to rank;multimedia;world wide web;machine learning;computer science;
Enhanced Word Embeddings from a Hierarchical Neural Language Model,Xun Wang (Nippon Telegraph and Telephone);Katsuhoto Sudoh (Nippon Telegraph and Telephone);Masaaki Nagata (Nippon Telegraph and Telephone);,"2303064488,2230641072,2102463429","This paper proposes a neural language model to capture the interaction of text units of different levels, i.e.., documents, paragraphs, sentences, words in an hierarchical structure. At each paralleled level, the model incorporates Markov property while each higher-level unit hierarchically influences its containing units. Such an architecture enables the learned word embeddings to encode both global and local information. We evaluate the learned word embeddings and experiments demonstrate the effectiveness of our model.",2015,Conference on Information and Knowledge Management,hierarchical database model;artificial neural network;natural language processing;speech recognition;database;machine learning;computer science;
Approximate String Matching by End-Users using Active Learning,Lutz Büch (Heidelberg University);Artur Andrzejak (Heidelberg University);,"2479297565,215664075","Identifying approximately identical strings is key for many data cleaning and data integration processes, including similarity join and record matching. The accuracy of such tasks crucially depends on appropriate choices of string similarity measures and thresholds for the particular dataset. Manual selection of similarity measures and thresholds is infeasible. Other approaches rely on the existence of adequate historic ground-truth or massive manual effort. To address this problem, we propose an Active Learning algorithm which selects a best performing similarity measure in a given set while optimizing a decision threshold. Active Learning minimizes the number of user queries needed to arrive at an appropriate classifier. Queries require only the label match/no match , which end users can easily provide in their domain. Evaluation on well-known string matching benchmark data sets shows that our approach achieves highly accurate results with a small amount of manual labeling required.",2015,Conference on Information and Knowledge Management,string metric;data deduplication;approximate string matching;active learning;string searching algorithm;world wide web;data mining;database;pattern recognition;machine learning;computer science;
Update Summarization using Semi-Supervised Learning Based on Hellinger Distance,Dingding Wang (Florida Atlantic University);Sahar Sohangir (Florida Atlantic University);Tao Li (Florida International University);,"2097650207,2677802258,2472069284","Update summarization aims to generate brief summaries of recent documents to capture new information different from earlier documents. In this paper, we propose a new method to generate the sentence similarity graph using a novel similarity measure based on Helliger distance and apply semi-supervised learning on the sentence graph to select the sentences with maximum consistency and minimum redundancy to form the summaries. We use TAC 2011 data to evaluate our proposed method and compare it with existing baselines. The experimental results show the effectiveness of our proposed method.",2015,Conference on Information and Knowledge Management,hellinger distance;semi supervised learning;automatic summarization;information retrieval;data mining;pattern recognition;machine learning;statistics;computer science;
A Parallel GPU-Based Approach to Clustering Very Fast Data Streams,Pengtao Huang (Tsinghua University);Xiu Li (Tsinghua University);Bo Yuan (Tsinghua University);,"2225491498,2638322028,2293770898","Clustering data streams has become a hot topic in the era of big data. Driven by the ever increasing volume, velocity and variety of data, more efficient algorithms for clustering large-scale complex data streams are needed. In this paper, we present a parallel algorithm called PaStream, which is based on advanced Graphics Processing Unit (GPU) and follows the online-offline framework of CluStream. Our approach can achieve hundreds of times speedup on high-speed and high-dimensional data streams compared with CluStream. It can also discover clusters with arbitrary shapes and handle outliers properly. The efficiency and scalability of PaStream are demonstrated through comprehensive experiments on synthetic and standard benchmark datasets with various problem factors.",2015,Conference on Information and Knowledge Management,correlation clustering;data stream clustering;cure data clustering algorithm;cluster analysis;parallel computing;data mining;database;machine learning;computer science;
Atypical Queries in eCommerce,Neeraj Pradhan;Vinay Deolalikar (Hewlett-Packard);Kang Li;,"2231762276,2150307071,2501532190","Understanding how specific, ambiguous, or broad the intent of a search query is, across all users of the system, is important in improving search relevance in eCommerce. There is scant literature on such a structural characterization of queries in eCommerce. In this paper, we use query-click log data to address the problem of identifying ""atypical queries"": these are queries that are extremal in terms of specificity, ambiguity, or breadth of intent. We isolate three components of atypicality: geometric, statistical, and topological. We demonstrate, using query-click logs at Groupon, that certain combinations of these properties render a query atypical, and discuss how search analysts treat such queries differently. Our work is being used to improve search relevance at Groupon.",2015,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
A Real-Time Eye Tracking Based Query Expansion Approach via Latent Topic Modeling,Yongqiang Chen (Tianjin University);Peng Zhang (Tianjin University);Dawei Song (Tianjin University);Benyou Wang (Tianjin University);,"2492756770,2670383678,2113829419,2231501501","Formulating and reformulating reliable textual queries have been recognized as a challenging task in Information Retrieval (IR), even for experienced users. Most existing query expansion methods, especially those based on implicit relevance feedback, utilize the user's historical interaction data, such as clicks, scrolling and viewing time on documents, to derive a refined query model. It is further expected that the user's search experience would be largely improved if we could dig out user's latent query intention, in real-time, by capturing the user's current interaction at the term level directly. In this paper, we propose a real-time eye tracking based query expansion method, which is able to: (1) automatically capture the terms that the user is viewing by utilizing eye tracking techniques; (2) derive the user's latent intent based on the eye tracking terms and by using the Latent Dirichlet Allocation (LDA) approach. A systematic user study has been carried out and the experimental results demonstrate the effectiveness of our proposed methods.",2015,Conference on Information and Knowledge Management,ranking;query expansion;query optimization;eye tracking;world wide web;information retrieval;data mining;database;computer science;
Bottom-up Faceted Search: Creating Search Neighbourhoods with Datacube Cells,Mark Sifer (University of Wollongong);,2043105879,"Browsing a collection can start with a keyword search. A user visits a library, performs a keyword search to find a few books of interest; finding their location in the library. Then they go to these locations; the corresponding bookshelves, where they do not just retrieve the found books, but rather they start browsing the nearby books; the books which have a similar Dewey classification. This paper extends this approach to curated corpora that contain items or documents that have been classified in multiple dimensions (facets), where each dimension classification may be a hierarchy. In particular (i) a technique for determining near items based on OLAP datacube cells and (ii) user interfaces that support browsing of near items are presented.",2015,Conference on Information and Knowledge Management,online analytical processing;similarity;user interface;world wide web;information retrieval;data mining;database;computer science;
Towards Scalable and Complete Query Explanation with OWL 2 EL Ontologies,Zhe Wang (Griffith University);Mahsa Chitsaz (Griffith University);Kewen Wang (Griffith University);Jianfeng Du (Guangdong University of Foreign Studies);,"2714010287,2293627786,2141181964,2715239518","Ontology-mediated data access and management systems are rapidly emerging. Besides standard query answering, there is also a need for such systems to be coupled with explanation facilities, in particular to explain missing query answers (i.e. desired answers of a query which are not derivable from the given ontology and data). This support is highly demanded for debugging and maintenance of big data, and both theoretical results and algorithms proposed. However, existing query explanation algorithms either cannot scale over relative large data sets or are not guaranteed to compute all desired explanations. To the best of our knowledge, no existing algorithm can efficiently and completely explain conjunctive queries (CQs) w.r.t. ELH 1 ontologies. In this paper, we present a hybrid approach to achieve this. An implementation of the proposed query explanation algorithm has been developed using an off-the-shelf Prolog engine and a datalog engine. Finally, the system is evaluated over practical ontologies. Experimental results show that our system scales over large data sets.",2015,Conference on Information and Knowledge Management,sargable;rdf query language;boolean conjunctive query;web query classification;conjunctive query;abductive reasoning;query expansion;query optimization;description logic;query language;information retrieval;data mining;database;computer science;
Parallel Lazy Semi-Naive Bayes Strategies for Effective and Efficient Document Classification,Felipe Viegas (Universidade Federal de Minas Gerais);Marcos André Gonçalves (Universidade Federal de Minas Gerais);Wellington Martins (Universidade Federal de Goiás);Leonardo C. da Rocha (Universidade Federal de São João del-Rei);,"2430900927,2115586749,2140379218,2151239327","Automatic Document Classification (ADC) is the basis of many important applications such as spam filtering and content organization. Naive Bayes (NB) approaches are a widely used classification paradigm, due to their simplicity, efficiency, absence of parameters and effectiveness. However, they do not present competitive effectiveness when compared to other modern statistical learning methods, such as SVMs. This is related to some characteristics of real document collections, such as class imbalance, feature sparseness and strong relationships among attributes. In this paper, we investigate whether the relaxation of the NB feature independence assumption (aka, Semi-NB approaches) can improve its effectiveness in large text collections. We propose four new Lazy Semi-NB strategies that exploit different ideas for alleviating the NB independence assumption. By being lazy , our solutions focus only on the most important features to classify a given test document, overcoming some Semi-NB issues when applied to ADC such as bias towards larger classes and overfitting and/or lack of generalization of the models. We demonstrate that our Lazy Semi-NB proposals can produce superior effectiveness when compared to state-of-the-art ADC classifiers such as SVM and KNN. Moreover, to overcome some efficiency issues of combining Semi-NB and lazy strategies, we take advantage of current manycore GPU architectures and present a massively parallelized version of the Semi-NB approaches. Our experimental results show that speedups of up to 63.36 times can be obtained when compared to serial solutions, making our proposals very practical in real-situations.",2015,Conference on Information and Knowledge Management,natural language processing;world wide web;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
gSparsify: Graph Motif Based Sparsification for Graph Clustering,Peixiang Zhao (Florida State University);,2169163720,"Graph clustering is a fundamental problem that partitions vertices of a graph into clusters with an objective to optimize the intuitive notions of intra-cluster density and intercluster sparsity . In many real-world applications, however, the sheer sizes and inherent complexity of graphs may render existing graph clustering methods inefficient or incapable of yielding quality graph clusters. In this paper, we propose gSparsify, a graph sparsification method, to preferentially retain a small subset of edges from a graph which are more likely to be within clusters, while eliminating others with less or no structure correlation to clusters. The resultant simplified graph is succinct in size with core cluster structures well preserved, thus enabling faster graph clustering without a compromise to clustering quality. We consider a quantitative approach to modeling the evidence that edges within densely knitted clusters are frequently involved in small-size graph motifs, which are adopted as prime features to differentiate edges with varied cluster significance. Path-based indexes and path-join algorithms are further designed to compute graph-motif based cluster significance of edges for graph sparsification. We perform experimental studies in real-world graphs, and results demonstrate that gSparsify can bring significant speedup to existing graph clustering methods with an improvement to graph clustering quality.",2015,Conference on Information and Knowledge Management,factor critical graph;distance hereditary graph;simplex graph;strength of a graph;quartic graph;voltage graph;complement graph;graph bandwidth;multiple edges;graph power;butterfly graph;null graph;graph labeling;graph property;line graph;clustering coefficient;graph;directed graph;world wide web;machine learning;computer science;
Structural Constraints for Multipartite Entity Resolution with Markov Logic Network,Tengyuan Ye (Zhejiang University);Hady Wirawan Lauw (Singapore Management University);,"2225886386,2024254804","Multipartite entity resolution seeks to match entity mentions across several collections. An entity mention is presumed unique within a collection, and thus could match at most one entity mention in each of the other collections. In addition to domain-specific features considered in entity resolution, there are a number of domain-invariant structural contraints that apply in this scenario, including one-to-one assignment as well as cross-collection transitivity. We propose a principled solution to the multipartite entity resolution problem, building on the foundation of Markov Logic Network (MLN) that combines probabilistic graphical model and first-order logic. We describe how the domain-invariant structural constraints could be expressed appropriately in terms of Markov logic, flexibly allowing joint modeling with domain-specific features. Experiments on two real-life datasets, each spanning four collections, show the utility of this approach and validate the contributions of various MLN components.",2015,Conference on Information and Knowledge Management,name resolution;data mining;database;machine learning;algorithm;computer science;
Lingo: Linearized Grassmannian Optimization for Nuclear Norm Minimization,Qian Li (Chinese Academy of Sciences);Wenjia Niu (Chinese Academy of Sciences);Gang Li (Deakin University);Yanan Cao (Chinese Academy of Sciences);Jianlong Tan (Chinese Academy of Sciences);Li Guo (Chinese Academy of Sciences);,"2642754292,2135491977,2098057600,2117145066,2100810457,2122010476","As a popular heuristic to the matrix rank minimization problem, nuclear norm minimization attracts intensive research attentions. Matrix factorization based algorithms can reduce the expensive computation cost of SVD for nuclear norm minimization . However, most matrix factorization based algorithms fail to provide the theoretical guarantee for convergence caused by their non-unique factorizations. This paper proposes an efficient and accurate Linearized Grassmannian Optimization (Lingo) algorithm, which adopts matrix factorization and Grassmann manifold structure to alternatively minimize the subproblems. More specially, linearization strategy makes the auxiliary variables unnecessary and guarantees the close-form solution for low per-iteration complexity. Lingo then converts linearized objective function into a nuclear norm minimization over Grassmannian manifold , which could remedy the non-unique of solution for the low-rank matrix factorization. Extensive comparison experiments demonstrate the accuracy and efficiency of Lingo algorithm. The global convergence of Lingo is guaranteed with theoretical proof, which also verifies the effectiveness of Lingo.",2015,Conference on Information and Knowledge Management,matrix norm;grassmannian;mathematical optimization;
Efficient Sparse Matrix Multiplication on GPU for Large Social Network Analysis,Yong-Yeon Jo (Hanyang University);Sang-Wook Kim (Hanyang University);Duck-Ho Bae (Hanyang University);,"1979337330,2114304489,2125189814","As a number of social network services appear online recently, there have been many attempts to analyze social networks for extracting valuable information. Most existing methods first represent a social network as a quite sparse adjacency matrix, and then analyze it through matrix operations such as matrix multiplication. Due to the large scale and high complexity, efficient processing multiplications is an important issue in social network analysis. In this paper, we propose a GPU-based method for efficient sparse matrix multiplication through the parallel computing paradigm. The proposed method aims at balancing the amount of workload both at fine- and coarse-grained levels for maximizing the degree of parallelism in GPU. Through extensive experiments using synthetic and real-world datasets, we show that the proposed method outperforms previous methods by up to three orders-of-magnitude.",2015,Conference on Information and Knowledge Management,social network analysis;theoretical computer science;parallel computing;distributed computing;computer science;
An Optimization Framework for Propagation of Query-Document Features by Query Similarity Functions,Maxim Zhukovskiy (Yandex);Tsimafei Khatkevich (Yandex);Gleb Gusev (Yandex);Pavel Serdyukov (Yandex);,"2018740001,2223114616,2005728791,2130450538","It is well known that a great number of query--document features which significantly improve the quality of ranking for popular queries, however, do not provide any benefit for new or rare queries since there is typically not enough data associated with those queries that is required to reliably compute the values of those features. It is a common practice to propagate the values of such features from popular to tail queries, if the queries are similar according to some predefined query similarity functions. In this paper, we propose new algorithms that facilitate and increase the effectiveness of this propagation. Given a query similarity function and a query--document relevance feature, we introduce two different approaches (linear weighting approach and tree-based approach) to learn a function of values of the similarity function and values of the feature for the similar queries w.r.t. the given document. The propagated value of the feature equals the value of the obtained function for the given query--document pair.",2015,Conference on Information and Knowledge Management,range query;spatial query;information retrieval;data mining;pattern recognition;
An Optimal Online Algorithm For Retrieving Heavily Perturbed Statistical Databases In The Low-Dimensional Querying Model,Krzysztof Marcin Choromanski (Google);Afshin Rostamizadeh (Google);Umar Syed (Google);,"2030704647,2304993124,1985611198","We give the first O(1 over √ T )-error online algorithm for reconstructing noisy statistical databases, where T is the number of (online) sample queries received. The algorithm is optimal up to the poly (log( T )) factor in terms of the error and requires only O (log T ) memory. It aims to learn a hidden database-vector w * E in ℜ D in order to accurately answer a stream of queries regarding the hidden database, which arrive in an online fashion from some unknown distribution D . We assume the distribution D is defined on the neighborhood of a low-dimensional manifold. The presented algorithm runs in O(dD) -time per query, where d is the dimensionality of the query-space. Contrary to the classical setting, there is no separate training set that is used by the algorithm to learn the database --- the stream on which the algorithm will be evaluated must also be used to learn the database-vector. The algorithm only has access to a binary oracle Ο that answers whether a particular linear function of the database-vector plus random noise is larger than a threshold, which is specified by the algorithm. We note that we allow for a significant O(D) amount of noise to be added while other works focused on the low noise o (√ D )-setting. For a stream of T queries our algorithm achieves an average error O(1 over √ T ) by filtering out random noise, adapting threshold values given to the oracle based on its previous answers and, as a consequence, recovering with high precision a projection of a database-vector w * onto the manifold defining the query-space. Our algorithm may be also applied in the adversarial machine learning context to compromise machine learning engines by heavily exploiting the vulnerabilities of the systems that output only binary signal and in the presence of significant noise.",2015,Conference on Information and Knowledge Management,bisection method;theoretical computer science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Mining the Minds of Customers from Online Chat Logs,Kunwoo Park (KAIST);Jaewoo Kim (KAIST);Jaram Park (KAIST);Meeyoung Cha (KAIST);Jiin Nam (Samsung);Seunghyun Yoon (Samsung);Eunhee Rhim (Samsung);,"2498492915,2702642843,2147852179,2101274274,2159918401,2297107133,2050006517","This study investigates factors that may determine satisfaction in customer service operations. We utilized more than 170,000 online chat sessions between customers and agents to identify characteristics of chat sessions that incurred dissatisfying experience. Quantitative data analysis suggests that sentiments or moods conveyed in online conversation are the most predictive factor of perceived satisfaction. Conversely, other session related meta data (such as that length, time of day, and response time) has a weaker correlation with user satisfaction. Knowing in advance what can predict satisfaction allows customer service staffs to identify potential weaknesses and improve the quality of service for better customer experience.",2015,Conference on Information and Knowledge Management,attitudinal analytics;customer intelligence;customer advocacy;voice of the customer;customer to customer;customer delight;customer retention;conversion marketing;customer satisfaction;service quality;sentiment analysis;advertising;marketing;world wide web;computer science;
Learning User Preferences for Topically Similar Documents,Mustafa Zengin (University of Delaware);Ben Carterette (University of Delaware);,"2229087848,2645247999","Similarity measures have been used widely in information retrieval research. Most research has been done on query-document or document-document similarity without much attention to the user's perception of similarity in the context of the information need. In this study, we collect user preference judgements of web document similarity in order to investigate: (1) the correlation between similarity measures and users' perception of similarity, (2) the correlation between the web document features plus document-query features and users' similarity judgements. We analyze the performance of various similarity methods at predicting user preferences, in both unsupervised and supervised settings. We show that a supervised approach using many features is able to predict user preferences close to the level of agreement between users, and moreover achieve a 15% improvement in AUC over an unsupervised approach.",2015,Conference on Information and Knowledge Management,similarity heuristic;semantic similarity;information retrieval;data mining;pattern recognition;computer science;
Scalable Clustering Algorithm via a Triangle Folding Processing for Complex Networks,Ying Kang (Chinese Academy of Sciences);Xiaoyan Gu (Chinese Academy of Sciences);Weiping Wang (Chinese Academy of Sciences);Dan Meng (Chinese Academy of Sciences);,"2510709291,2232390094,2597937528,2713851801","Facing up to the incessant growth of complex networks, more and more researchers start turning to a multilevel computing paradigm with high scalability for clustering. By virtue of iterative coarsening level by level, the clustering results which are obtained from the coarsest network and then projected to the original network, is superior to the ones from mining the original complex network explicitly. Empirical works reflect that the local-aggregation characteristic is a key point for multilevel clustering algorithms, thus techniques like modularity, label propagation etc. are used to discover the micro-clusters for coarsening. In this paper, we propose a scalable clustering algorithm via a triangle folding processing for complex networks(SCAFT). Based on the strong cluster property of triangle, we fold each traversed triangle of the network into a superverex to realize coarsening. And each generated coarsened network by iteration is capable of reserving the cluster structures of last level network, or even the intrinsic cluster structures of original complex network, improving the computational accuracy. What's more, a streaming algorithm is embedded in our novel approach to generate a serial input sequence of vertices, reducing the heavy burdens of memory usage of system. Experimental results on real-world complex networks show that, SCAFT outperforms the state-of-the-art multilevel clustering algorithms in terms of clustering accuracy, running time, especially in memory usage.",2015,Conference on Information and Knowledge Management,hierarchical clustering of networks;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;streaming algorithm;fuzzy clustering;clustering high dimensional data;cluster analysis;theoretical computer science;data mining;artificial intelligence;machine learning;algorithm;computer science;
A Fast k-Nearest Neighbor Search Using Query-Specific Signature Selection,Youngki Park (Seoul National University);Heasoo Hwang (Seoul National University);Sang-goo Lee (Seoul National University);,"2122762898,2097983013,2126044724","k-nearest neighbor (k-NN) search aims at finding k points nearest to a query point in a given dataset. k-NN search is important in various applications, but it becomes extremely expensive in a high-dimensional large dataset. To address this performance issue, locality-sensitive hashing (LSH) is suggested as a method of probabilistic dimension reduction while preserving the relative distances between points. However, the performance of existing LSH schemes is still inconsistent, requiring a large amount of search time in some datasets while the k-NN approximation accuracy is low. In this paper, we target on improving the performance of k-NN search and achieving a consistent k-NN search that performs well in various datasets. In this regard, we propose a novel LSH scheme called Signature Selection LSH (S2LSH). First, we generate a highly diversified signature pool containing signature regions of various sizes and shapes. Then, for a given query point, we rank signature regions of the query and select points in the highly ranked signature regions as k-NN candidates of the query. Extensive experiments show that our approach consistently outperforms the state-of-the-art LSH schemes.",2015,Conference on Information and Knowledge Management,locality sensitive hashing;nearest neighbor search;information retrieval;data mining;pattern recognition;machine learning;computer science;
Weighted Similarity Estimation in Data Streams,Konstantin Kutzkov (NEC);Mohamed Ahmed (NEC);Sofia Nikitaki (NEC);,"280017384,2099801935,189799777","Similarity computation between pairs of objects is often a bottleneck in many applications that have to deal with massive volumes of data. Motivated by applications such as collaborative filtering in large-scale recommender systems, and influence probabilities learning in social networks, we present new randomized algorithms for the estimation of weighted similarity in data streams. Previous works have addressed the problem of learning binary similarity measures in a streaming setting. To the best of our knowledge, the algorithms proposed here are the first that specifically address the estimation of weighted similarity in data streams. The algorithms need only one pass over the data, making them ideally suited to handling massive data streams in real time. We obtain precise theoretical bounds on the approximation error and complexity of the algorithms. The results of evaluating our algorithms on two real-life datasets validate the theoretical findings and demonstrate the applicability of the proposed algorithms.",2015,Conference on Information and Knowledge Management,streaming algorithm;viral marketing;collaborative filtering;recommender system;theoretical computer science;world wide web;information retrieval;data mining;database;machine learning;statistics;computer science;
A Novel Class Noise Estimation Method and Application in Classification,Lin Gui (Harbin Institute of Technology);Qin Lu (Hong Kong Polytechnic University);Ruifeng Xu (Harbin Institute of Technology);Minglei Li (Hong Kong Polytechnic University);Qikang Wei (Harbin Institute of Technology);,"2622329122,2112113948,2099613179,2229811005,2222797435","Noise in class labels of any training set can lead to poor classification results no matter what machine learning method is used. In this paper, we first present the problem of binary classification in the presence of random noise on the class labels, which we call class noise. To model class noise, a class noise rate is normally defined as a small independent probability of the class labels being inverted on the whole set of training data. In this paper, we propose a method to estimate class noise rate at the level of individual samples in real data. Based on the estimation result, we propose two approaches to handle class noise. The first technique is based on modifying a given surrogate loss function. The second technique eliminates class noise by sampling. Furthermore, we prove that the optimal hypothesis on the noisy distribution can approximate the optimal hypothesis on the clean distribution using both approaches. Our methods achieve over 87% accuracy on a synthetic non-separable dataset even when 40% of the labels are inverted. Comparisons to other algorithms show that our methods outperform state-of-the-art approaches on several benchmark datasets in different domains with different noise rates.",2015,Conference on Information and Knowledge Management,value noise;noise measurement;pattern recognition;machine learning;statistics;
External Knowledge and Query Strategies in Active Learning: a Study in Clinical Information Extraction,Mahnoosh Kholghi (Queensland University of Technology);Laurianne Sitbon (Queensland University of Technology);Guido Zuccon (Queensland University of Technology);Anthony N. Nguyen (Commonwealth Scientific and Industrial Research Organisation);,"2343723799,279890580,1551779932,2651136081","This paper presents a new active learning query strategy for information extraction, called Domain Knowledge Informativeness (DKI). Active learning is often used to reduce the amount of annotation effort required to obtain training data for machine learning algorithms. A key component of an active learning approach is the query strategy, which is used to iteratively select samples for annotation. Knowledge resources have been used in information extraction as a means to derive additional features for sample representation . DKI is, however, the first query strategy that exploits such resources to inform sample selection . To evaluate the merits of DKI, in particular with respect to the reduction in annotation effort that the new query strategy allows to achieve, we conduct a comprehensive empirical comparison of active learning query strategies for information extraction within the clinical domain. The clinical domain was chosen for this work because of the availability of extensive structured knowledge resources which have often been exploited for feature generation. In addition, the clinical domain offers a compelling use case for active learning because of the necessary high costs and hurdles associated with obtaining annotations in this domain. Our experimental findings demonstrated that (1) amongst existing query strategies, the ones based on the classification model's confidence are a better choice for clinical data as they perform equally well with a much lighter computational load, and (2) significant reductions in annotation effort are achievable by exploiting knowledge resources within active learning query strategies, with up to 14% less tokens and concepts to manually annotate than with state-of-the-art query strategies.",2015,Conference on Information and Knowledge Management,web query classification;query expansion;query optimization;active learning;conditional random field;domain knowledge;active learning;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
DAAV: Dynamic API Authority Vectors for Detecting Software Theft,Dong-Kyu Chae (Hanyang University);Sang-Wook Kim (Hanyang University);Seong-Je Cho (Dankook University);Yesol Kim (Dankook University);,"2140107245,2114304489,2161408542,2161637229","This paper proposes a novel birthmark, a dynamic API authority vector (DAAV), for detecting software theft. DAAV satisfies four essential requirements for good birthmarks--credibility, resiliency, scalability, and packing-free--while existing birthmarks fail to satisfy all of them together. In particular, existing static birthmarks are unable to handle the packed programs and existing dynamic birthmarks do not satisfy credibility and resiliency. Our experimental results demonstrate that DAAV provides satisfying credibility and resiliency compared with existing dynamic birthmarks and also can cover packed programs.",2015,Conference on Information and Knowledge Management,similarity;graph;random walk;internet privacy;world wide web;computer security;data mining;database;statistics;
Identification of Microblogs Prominent Users during Events by Learning Temporal Sequences of Features,Imen Bizid (University of La Rochelle);Nibal Nayef (University of La Rochelle);Patrice Boursier (University of La Rochelle);Sami Faiz (Tunis University);Antoine Doucet (University of La Rochelle);,"278290391,2051909474,1238428725,2108524457,2152615820","During specific real-world events, some users of microblogging platforms could provide exclusive information about those events. The identification of such prominent users depends on several factors such as the freshness and the relevance of their shared information. This work proposes a probabilistic model for the identification of prominent users in microblogs during specific events. The model is based on learning and classifying user behavior over time using Mixture of Gaussians Hidden Markov Models. A user is characterized by a temporal sequence of feature vectors describing his activities. The features computed at each time-stamp are designed to reflect both the on- and off-topic activities of users, and they are computationally feasible in real-time. To validate the efficacy of our proposed model, we have conducted experiments on data collected from Twitter during the Herault floods that have occurred in France. The achieved results show that learning the time-series of users' actions is better than learning just those actions without temporal information.",2015,Conference on Information and Knowledge Management,internet privacy;world wide web;information retrieval;data mining;computer science;
Clustered Semi-Supervised Relevance Feedback,Kripabandhu Ghosh (Indian Statistical Institute);Swapan Kumar Parui (Indian Statistical Institute);,"2095646530,2001472639","In relevance feedback, first-round search results are used to boost second-round search results. Two forms have been traditionally considered: exhaustively labelled feedback, where all first-round results to depth k are annotated for relevance by the user; and blind feedback, where the top- k results are all assumed to be relevant. In this paper, we consider an intermediate, semi-supervised scheme, in which only a subset of results is selected for annotation, and then their labels are propagated to their nearest neighbours. Specifically, we use clustering to determine the nearest-neighbour groups, and seed selection to choose documents for annotation. We find that the effectiveness of this method is indistinguishable from the exhaustive relevance feedback, and is significantly higher than both blind feedback and the use of the annotated subset alone. We show that this approach works well in environments in which some but limited amounts of human feedback are available, such as early case assessment in e-discovery.",2015,Conference on Information and Knowledge Management,information retrieval;data mining;machine learning;
A Flash-aware Buffering Scheme using On-the-fly Redo,Kyosung Jeong (Hanyang University);Sang-Wook Kim (Hanyang University);Sungchae Lim (Dongduk Women's University);,"2228398118,2114304489,2167275165","In this paper, we address how to reduce the amount of page updates in flash-based DBMS equipped with SSD (Solid State Drive). We propose a novel buffering scheme that evicts a dirty page X without flushing it into SSD, and restores the right image of X when X is requested for later access. The restoration of X having previous flushing-less eviction is performed through our online redo actions on X. We call this page-restoring online redo the on-the-fly redo. Although our on-the-fly redo mechanism has some overhead of increasing the number of page reads, this can be compensated by infrequent page updates. Additionally, since the proposed buffering scheme with the on-the-fly redo can easily support the no-steal policy in buffer management, we can enjoy the advantages of smaller logging overhead and faster recovery. Through the TPC-C benchmarks using a Berkeley DB, we show that our scheme shortens the transaction processing times by up to 53%.",2015,Conference on Information and Knowledge Management,parallel computing;database;real time computing;computer science;
The Role Of Citation Context In Predicting Long-Term Citation Profiles: An Experimental Study Based On A Massive Bibliographic Text Dataset,Mayank Singh (Indian Institute of Technology Kharagpur);Vikas Patidar (Indian Institute of Technology Kharagpur);Suhansanu Kumar (Indian Institute of Technology Kharagpur);Tanmoy Chakraborty (Indian Institute of Technology Kharagpur);Animesh Mukherjee (Indian Institute of Technology Kharagpur);Pawan Goyal (Indian Institute of Technology Kharagpur);,"2322263662,2439224977,2224428986,2471175502,2134540012,2556932677","The impact and significance of a scientific publication is measured mostly by the number of citations it accumulates over the years. Early prediction of the citation profile of research articles is a significant as well as challenging problem. In this paper, we argue that features gathered from the citation contexts of the research papers can be very relevant for citation prediction. Analyzing a massive dataset of nearly 1.5 million computer science articles and more than 26 million citation contexts, we show that average countX (number of times a paper is cited within the same article) and average citeWords (number of words within the citation context) discriminate between various citation ranges as well as citation categories. We use these features in a stratified learning framework for future citation prediction. Experimental results show that the proposed model significantly outperforms the existing citation prediction models by a margin of 8-10% on an average under various experimental settings. Specifically, the features derived from the citation context help in predicting long-term citation behavior.",2015,Conference on Information and Knowledge Management,data science;information retrieval;data mining;computer science;
Data Driven Water Pipe Failure Prediction: A Bayesian Nonparametric Approach,Peng Lin (NICTA);Bang Zhang (NICTA);Yi Wang (NICTA);Zhidong Li (NICTA);Bin Li (NICTA);Yang Wang (NICTA);Fang Chen (NICTA);,"2427076175,2164807601,2692577326,2099787171,2307804300,2513938630,2559371593","Water pipe failures can cause significant economic and social costs, hence have become the primary challenge to water utilities. In this paper, we propose a Bayesian nonparametric approach, namely the Dirichlet process mixture of hierarchical beta process model, for water pipe failure prediction. It can select high-risk pipes for physical condition assessment, thereby preventing disastrous failures proactively. The proposed method is adaptable to the diversity of failure patterns. Its model structure and complexity can automatically adjust according to observed data. Additionally, the sparse failure data problem that often occurs in real-world data is tackled by the proposed method via flexible pipe grouping and failure data sharing. An approximated yet computational efficient Metropolis-within-Gibbs sampling method is developed with the exploitation of the failure data sparsity for model parameter inference. The proposed method has been applied to a metropolitan water supply network. The details of the application context are also presented for demonstrating its real-life impact. The comparison experiments conducted on the metropolitan water pipe data show that the proposed approach significantly outperforms the state-of-the-art prediction methods, and it is capable of bringing enormous economic and social savings to water utilities.",2015,Conference on Information and Knowledge Management,data mining;machine learning;statistics;
Inducing Space Dirichlet Process Mixture Large-Margin Entity RelationshipInference in Knowledge Bases,Sotirios P. Chatzis (Cyprus University of Technology);,2328971761,"In this paper, we focus on the problem of extending a given knowledge base by accurately predicting additional true facts based on the facts included in it. This is an essential problem of knowledge representation systems, since knowledge bases typically suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. To achieve our goals, in our work we introduce an inducing space nonparametric Bayesian large-margin inference model, capable of reasoning over relationships between pairs of entities. Previous works addressing the entity relationship inference problem model each entity based on atomic entity vector representations. In contrast, our method exploits word feature vectors to directly obtain high-dimensional nonlinear inducing space representations for entity pairs. This way, we allow for extracting salient latent characteristics and interaction dynamics within entity pairs that can be useful for inferring their relationships. On this basis, our model performs the relations inference task by postulating a set of binary Dirichlet process mixture large-margin classifiers, presented with the derived inducing space representations of the considered entity pairs. Bayesian inference for this inducing space model is performed under the mean-field inference paradigm. This is made possible by leveraging a recently proposed latent variable formulation of regularized large-margin classifiers that facilitates mean-field parameter estimation. We exhibit the superiority of our approach over the state-of-the-art by considering the problem of predicting additional true relations between entities given subsets of the WordNet and FreeBase knowledge bases.",2015,Conference on Information and Knowledge Management,data mining;pattern recognition;artificial intelligence;machine learning;
"On the Effect of ""Stupid"" Search Components on User Interaction with Search Engines",Lidia Grauer (Yandex);Aleksandra Lomakina (Yandex);,"2222969598,2527309082","Using eye-tracking, we investigate how searchers interact with Web search engines which get affected by nonsensical results. We conduct a user survey to choose ""stupid"" components for our laboratory experiment and explore the most conspicuous ones. This research provides insights about searchers' interactions with different kinds of ""stupid"" search components, such as organic search results, vertical results, ads and automatic misspell correction. We investigate the influence of each class of ""stupid"" components on users' attitude to a search engine. We found that sticking in memory of the impression about the ""stupidity"" of the search engine depended on whether the users were finally satisfied with their searches, or did not find the answer. Experimental results show that classes of ""stupid"" components can be differentiated by their influence on users' attitude. The most negative impression is caused by word losses, word collocation breaks and inappropriate misspell corrections.",2015,Conference on Information and Knowledge Management,internet privacy;multimedia;world wide web;information retrieval;data mining;database;computer science;
Fraud Transaction Recognition: A Money Flow Network Approach,Renxin Mao (Alibaba Group);Zhao Li (Alibaba Group);Jinhua Fu (Alibaba Group);,"2229836147,2337134791,2486475336","In this paper, we provide some insights into analysis of fraud transaction recognition on Alipay's Money Flow Network. We first show that the Money Flow Network follows a power-law distribution on daily, monthly or yearly basis, based on which we propose a new approach of fraud transaction recognition on the Money Flow Network from two perspectives. First, the Collapse Network is identified by the discovery that fraud transaction requires a huge amount of active controlled 'zombie' accounts, which are always intentionally manipulated by fraudulent online sellers, and the collapse of the Money Flow Network emerges due to their economic inactivity; Second, we define the Activation Forest that leads to the recognition of the controlled 'zombies' even no sooner than they enter into Alipay's ecosphere. These two networks are fully explored from the perspective of detecting 'zombies', and several key features have been adopted into anti-fraud recognition. Experimental results show that our strategy is capable of effectively identifying fraud transactions on the Money Flow Network with the accuracy as high as 99.88%.",2015,Conference on Information and Knowledge Management,money measurement concept;financial transaction;computer security;data mining;computer science;
Proceedings of the 7th International Workshop on Exploiting Semantic Annotations in Information Retrieval,Omar Alonso (Microsoft);Jaap Kamps (Google);Jussi Karlgren (University of Amsterdam);,"2292406529,2716884970,2679344696","These proceedings contain the contributed papers of the Seventh Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR 2014), held at CIKM 2014 in Shanghai, on November 7, 2014. After successful workshops at ECIR'08 in Glasgow, WSDM'09 in Barcelona, CIKM'10 in Toronto, CIKM'11 in Glasgow, CIKM'12 at Maui, and CIKM'13 in San Francisco, this year's workshop will remain to advance the general research agenda on this core problem, with an explicit focus on one of the most challenging aspects to address in the coming years. The main remaining challenge is on the user's side---the potential of rich document annotations can only be realized if matched by more articulate queries exploiting these powerful retrieval cues---and a more dynamic approach is emerging by exploiting new forms of query autosuggest. How can the query suggestion paradigm be used to encourage searcher to articulate longer queries, with concepts and relations linking their statement of request to existing semantic models? How do entity results and social network data in ""graph search"" change the classic division between searchers and information and lead to extreme personalization---are you the query? How to leverage transaction logs and recommendation, and how adaptive should we make the system? What are the privacy ramifications and the UX aspects---how to not creep out users? These and other related questions will be discussed at this open format workshop -- the aim is to provide paths for further research to change the way we understand information access today! The workshop will consist of three main parts: Two keynotes to help us frame the problem, and create a common understanding of the challenges: Peter Mika (Yahoo Labs) and Silviu-Petru Cucerzan (Microsoft Research). A boaster and poster session with 11 papers selected by the program committee from 15 submissions (a 73% acceptance rate). Each paper was reviewed by at least two members of the program committee. Breakout groups on different aspects of exploiting semantic annotations, with reports being discussed in the final session.",2014,Conference on Information and Knowledge Management,data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Proceedings of the 17th International Workshop on Data Warehousing and OLAP,Il-Yeol Song (Drexel University);Alkis Simitsis (HP Labs);Alfredo Cuzzocrea (Indian Council of Agricultural Research);,"2148782644,24841185,294375193","It is our great pleasure to welcome you to the 17th ACM International Workshop on Data Warehousing and OLAP (DOLAP 2014). The DOLAP workshop continues its tradition of being a premier forum where both researchers and practitioners in Data Warehousing and On-Line Analytical Processing (OLAP) share their findings in theoretical foundations, methodologies, physical designs, new trends, and practical experiences. The mission of the DOLAP workshop is to identify and explore new directions for future research and development, as well as emerging application domains in the areas of data warehousing and OLAP. Traditional solutions and architecture designs in Data Warehousing and OLAP are evolving to cope with emerging application domains and data types, such as MPP, big data infrastructures, and analytics. In recent years, research in these areas has addressed emerging topics and has provided solutions toward building effective decision-support applications, deploying them on modern hardware, and aiming at improving optimization objectives as system performance. The call for papers attracted 24 submissions (22 regular papers and 2 short papers) from 17 different countries. The program committee reviewed and accepted 8 full papers and 4 short papers, resulting to an acceptance rate of 36% for full papers and 50% overall. The accepted papers span a wide variety of topics, including query processing and physical design, security issues for cloud data warehouses, handling of 'exotic' data like genomic and GPS data, location intelligence, optimization and data generation for data flows, and modeling issues for movement data, analytical metadata, and OLAP sessions. The program also includes an invited keynote talk by Prof. Minos Garofalakis from the Technical University of Crete, on querying big, dynamic, distributed data, and a panel on how DW and OLAP technologies can be used in big graph analytics.",2014,Conference on Information and Knowledge Management,online analytical processing;data science;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Proceedings of the First International Workshop on Privacy and Secuirty of Big Data,Alfredo Cuzzocrea (Indian Council of Agricultural Research);,294375193,"The 1st International Workshop on Privacy and Security of Big Data (PSBD 2014) focuses the attention on privacy and security research issues in the context of Big Data, a vibrant and challenging research context which is playing a leading role in the Database research community. Indeed, while Big Data is gaining the attention from the research community, also driven by some relevant technological innovations (like Clouds) as well as novel paradigms (like social networks), the issues of privacy and security of Big Data represent a fundamental problem in this research context, due to the fact Big Data are typically published online for supporting knowledge management and fruition processes and, in addition to this, such data are usually handled by multiple owners, with possible secure multi-part computation issues. Some of the hot topics in the context privacy and security of Big Data include: (i) privacy and security of Big Data integration and exchange; (ii) privacy and security of Big Data in data-intensive Cloud computing; (iii) system architectures in support of privacy and security of Big Data, e.g., GPUs: (iv) privacy and security issues of Big Data querying and analysis. These topics are first-class aspects to be addressed and investigated by PSBD 2014. These proceedings contain the papers selected for presentation at the workshop. We received 12 submissions from countries in North America, Europe and Asia. After careful review, the program committee selected 5 papers for presentation at the workshop. The accepted papers were presented in 2 sessions: scalable privacy-preserving and security-control methods for Big Data processing, user-oriented and data-oriented privacy methods for Big Data processing. A panel discussed advanced aspects of privacy and security of Big Data. We hope that these proceedings will serve as a valuable reference for researchers and practitioners focusing on privacy and security of Big Data.",2014,Conference on Information and Knowledge Management,privacy software;privacy by design;cloud computing security;information privacy;internet privacy;world wide web;information retrieval;data mining;database;computer science;
A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval,Yelong Shen (Microsoft);Xiaodong He (Microsoft);Jianfeng Gao (Microsoft);Li Deng (Microsoft);Grégoire Mesnil (Université de Montréal);,"2170686878,2106698597,2104437897,2101552792,2078690267","In this paper, we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document, we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next, the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally, a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models.",2014,Conference on Information and Knowledge Management,semantic compression;semeval;semantic computing;social semantic web;semantic equivalence;document term matrix;semantic technology;explicit semantic analysis;probabilistic latent semantic analysis;semantic similarity;latent semantic analysis;semantic search;deep learning;convolutional neural network;natural language processing;information retrieval;data mining;pattern recognition;machine learning;computer science;
Sketch-based Influence Maximization and Computation: Scaling up with Guarantees,Edith Cohen (Microsoft);Daniel Delling (Microsoft);Thomas Pajor (Microsoft);Renato F. Werneck (Microsoft);,"2167811012,707694137,1960947543,2162596805","Propagation of contagion through networks is a fundamental process. It is used to model the spread of information, influence, or a viral infection. Diffusion patterns can be specified by a probabilistic model, such as Independent Cascade (IC), or captured by a set of representative traces. Basic computational problems in the study of diffusion are influence queries (determining the potency of a specified seed set of nodes) and Influence Maximization (identifying the most influential seed set of a given size). Answering each influence query involves many edge traversals, and does not scale when there are many queries on very large graphs. The gold standard for Influence Maximization is the greedy algorithm, which iteratively adds to the seed set a node maximizing the marginal gain in influence. Greedy has a guaranteed approximation ratio of at least (1-1/e) and actually produces a sequence of nodes, with each prefix having approximation guarantee with respect to the same-size optimum. Since Greedy does not scale well beyond a few million edges, for larger inputs one must currently use either heuristics or alternative algorithms designed for a pre-specified small seed set size. We develop a novel sketch-based design for influence computation. Our greedy Sketch-based Influence Maximization (SKIM) algorithm scales to graphs with billions of edges, with one to two orders of magnitude speedup over the best greedy methods. It still has a guaranteed approximation ratio, and in practice its quality nearly matches that of exact greedy. We also present influence oracles, which use linear-time preprocessing to generate a small sketch for each node, allowing the influence of any seed set to be quickly answered from the sketches of its nodes.",2014,Conference on Information and Knowledge Management,greedy randomized adaptive search procedure;theory;estimation;theoretical computer science;combinatorics;mathematical optimization;statistics;algorithm;mathematics;
Leveraging Social Connections to Improve Personalized Ranking for Collaborative Filtering,"Tong Zhao (The Chinese University of Hong Kong);Julian J. McAuley (University of California, San Diego);Irwin King (The Chinese University of Hong Kong);","2689099768,2041520510,2121363826","Recommending products to users means estimating their preferences for certain items over others. This can be cast either as a problem of estimating the rating that each user will give to each item, or as a problem of estimating users' relative preferences in the form of a ranking . Although collaborative-filtering approaches can be used to identify users who rate and rank products similarly, another source of data that informs us about users' preferences is their set of social connections . Both rating- and ranking-based paradigms are important in real-world recommendation settings, though rankings are especially important in settings where explicit feedback in the form of a numerical rating may not be available. Although many existing works have studied how social connections can be used to build better models for rating prediction, few have used social connections as a means to derive more accurate ranking-based models. Using social connections to better estimate users' rankings of products is the task we consider in this paper. We develop a model, SBPR (Social Bayesian Personalized Ranking), based on the simple observation that users tend to assign higher ranks to items that their friends prefer. We perform experiments on four real-world recommendation data sets, and show that SBPR outperforms alternatives in ranking prediction both in warm- and cold-start settings.",2014,Conference on Information and Knowledge Management,social network;recommender system;data science;world wide web;data mining;computer science;
Graph-based Point-of-interest Recommendation with Geographical and Temporal Influences,Quan Yuan (Nanyang Technological University);Gao Cong (Nanyang Technological University);Aixin Sun (Nanyang Technological University);,"2163879794,2295915604,2124989948","The availability of user check-in data in large volume from the rapid growing location-based social networks (LBSNs) enables a number of important location-aware services. Point-of-interest (POI) recommendation is one of such services, which is to recommend POIs that users have not visited before. It has been observed that: (i) users tend to visit nearby places, and (ii) users tend to visit different places in different time slots, and in the same time slot, users tend to periodically visit the same places. For example, users usually visit a restaurant during lunch hours, and visit a pub at night. In this paper, we focus on the problem of time-aware POI recommendation , which aims at recommending a list of POIs for a user to visit at a given time. To exploit both geographical and temporal influences in time aware POI recommendation, we propose the Geographical-Temporal influences Aware Graph (GTAG) to model check-in records, geographical influence and temporal influence. For effective and efficient recommendation based on GTAG, we develop a preference propagation algorithm named Breadth first Preference Propagation (BPP). The algorithm follows a relaxed breath-first search strategy, and returns recommendation results within at most 6 propagation steps. Our experimental results on two real-world datasets show that the proposed graph-based approach outperforms state-of-the-art POI recommendation methods substantially.",2014,Conference on Information and Knowledge Management,point of interest;world wide web;data mining;
People Search within an Online Social Network: Large Scale Analysis of Facebook Graph Search Query Logs,Nikita V. Spirin (University of Illinois at Urbana–Champaign);Junfeng He (Facebook);Mike Develin (Facebook);Karrie G. Karahalios (University of Illinois at Urbana–Champaign);Maxime Boucher (Facebook);,"2145605135,2672047181,134931231,244853069,2495936547","Popular online social networks (OSN) generate hundreds of terabytes of new data per day and connect millions of users. To help users cope with the immense scale and influx of new information, OSNs provide a search functionality. However, most of the search engines in OSNs today only support keyword queries and provide basic faceted search capabilities overlooking serendipitous network exploration and search for relationships between OSN entities. This results in siloed information and a limited search space. In 2013 Facebook introduced its innovative Graph Search product with the goal to take the OSN search experience to the next level and facilitate exploration of the Facebook Graph beyond the first degree. In this paper we explore people search on Facebook by analyzing an anonymized social graph, anonymized user profiles, and large scale anonymized query logs generated by users of Facebook Graph Search. We uncover numerous insights about people search across several demographics. We find that named entity and structured queries complement each other across one's duration on Facebook, that females search for people proportionately more than males, and that users submit more queries as they gain more friends. We introduce the concept of a lift predicate and highlight how a graph distance varies with the search goal. Based on these insights, we present a set of design implications to guide the research and development of the OSN search in the future.",2014,Conference on Information and Knowledge Management,search analytics;distance;web search query;search engine;semantic search;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Supporting Complex Search Tasks,Ahmed Hassan Awadallah (Microsoft);Ryen W. White (Microsoft);Patrick Pantel (Microsoft);Susan T. Dumais (Microsoft);Yi-Min Wang (Microsoft);,"2094223786,2096583854,2250462127,676500258,2137802269","We present methods to automatically identify and recommend sub-tasks to help people explore and accomplish complex search tasks. Although Web searchers often exhibit directed search behaviors such as navigating to a particular Website or locating a particular item of information, many search scenarios involve more complex tasks such as learning about a new topic or planning a vacation. These tasks often involve multiple search queries and can span multiple sessions. Current search systems do not provide adequate support for tackling these tasks. Instead, they place most of the burden on the searcher for discovering which aspects of the task they should explore. Particularly challenging is the case when a searcher lacks the task knowledge necessary to decide which step to tackle next. In this paper, we propose methods to automatically mine search logs for tasks and build an association graph connecting multiple tasks together. We then leverage the task graph to assist new searchers in exploring new search topics or tackling multi-step search tasks. We demonstrate through experiments with human participants that we can discover related and interesting tasks to assist with complex search scenarios.",2014,Conference on Information and Knowledge Management,search analytics;semantic search;world wide web;data mining;machine learning;simulation;computer science;
RC-NET: A General Framework for Incorporating Knowledge into Word Representations,Chang Xu (Nankai University);Yalong Bai (Harbin Institute of Technology);Jiang Bian (Microsoft);Bin Gao (Microsoft);Gang Wang (Nankai University);Xiaoguang Liu (Nankai University);Tie-Yan Liu (Microsoft);,"2665015169,2677465344,2609123459,2616890138,2610161333,2160066678,2108341226","Representing words into vectors in continuous space can form up a potentially powerful basis to generate high-quality textual features for many text mining and natural language processing tasks. Some recent efforts, such as the skip-gram model, have attempted to learn word representations that can capture both syntactic and semantic information among text corpus. However, they still lack the capability of encoding the properties of words and the complex relationships among words very well, since text itself often contains incomplete and ambiguous information. Fortunately, knowledge graphs provide a golden mine for enhancing the quality of learned word representations. In particular, a knowledge graph, usually composed by entities (words, phrases, etc.), relations between entities, and some corresponding meta information, can supply invaluable relational knowledge that encodes the relationship between entities as well as categorical knowledge that encodes the attributes or properties of entities. Hence, in this paper, we introduce a novel framework called RC-NET to leverage both the relational and categorical knowledge to produce word representations of higher quality. Specifically, we build the relational knowledge and the categorical knowledge into two separate regularization functions, and combine both of them with the original objective function of the skip-gram model. By solving this combined optimization problem using back propagation neural networks, we can obtain word representations enhanced by the knowledge graph. Experiments on popular text mining and natural language processing tasks, including analogical reasoning, word similarity, and topic prediction, have all demonstrated that our model can significantly improve the quality of word representations.",2014,Conference on Information and Knowledge Management,deep learning;natural language processing;information retrieval;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
CAST: A Context-Aware Story-Teller for Streaming Social Content,Pei Lee (University of British Columbia);Laks V. S. Lakshmanan (University of British Columbia);Evangelos E. Milios (Dalhousie University);,"2479271178,2289816208,2231563531","Online social streams such as Twitter timelines, forum discussions and email threads have emerged as important channels for information propagation. Mining transient stories and their correlations implicit in social streams is a challenging task, since these streams are noisy and surge quickly. In this paper, we propose CAST, which is a context-aware story-teller that discovers new stories from social streams and tracks their structural context on the fly to build a vein of stories. More precisely, we model the social stream as a capillary network, and define stories by a new cohesive subgraph type called ( k,d )-Core in the capillary network. We propose deterministic and randomized context search to support the iceberg query, which builds the story vein as social streams flow. We perform detailed experimental study on real Twitter streams and the results demonstrate the creativity and value of our approach.",2014,Conference on Information and Knowledge Management,internet privacy;multimedia;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Faceted Search over Ontology-Enhanced RDF Data,Marcelo Arenas (Pontifical Catholic University of Chile);Bernardo Cuenca Grau (University of Oxford);Evgeny Kharlamov (University of Oxford);Sarunas Marciuska (University of Oxford);Dmitriy Zheleznyakov (University of Oxford);,"2117861229,2117709049,2037532978,1319042119,1120393503","An increasing number of applications rely on RDF, OWL 2, and SPARQL for storing and querying data. SPARQL, however, is not targeted towards end-users, and suitable query interfaces are needed. Faceted search is a prominent approach for end-user data access, and several RDF-based faceted search systems have been developed. There is, however, a lack of rigorous theoretical underpinning for faceted search in the context of RDF and OWL 2. In this paper, we provide such solid foundations. We formalise faceted interfaces for this context, identify a fragment of first-order logic capturing the underlying queries, and study the complexity of answering such queries for RDF and OWL 2 profiles. We then study interface generation and update, and devise efficiently implementable algorithms. Finally, we have implemented and tested our faceted search algorithms for scalability, with encouraging results.",2014,Conference on Information and Knowledge Management,rdf xml;rdf schema;sparql;web ontology language;rdf;ontology;world wide web;information retrieval;database;artificial intelligence;computer science;
Identifying Latent Study Habits by Mining Learner Behavior Patterns in Massive Open Online Courses,Miaomiao Wen (Carnegie Mellon University);Carolyn Penstein Rose (Carnegie Mellon University);,"2155420771,2152131012","MOOCs attract diverse users with varying habits. Identifying those patterns through clickstream analysis could enable more effective personalized support for student information seeking and learning in that online context. We propose a novel method to characterize types of sessions in MOOCs by mining the habitual behaviors of students within individual sessions. We model learning sessions as a distribution of activities and activity sequences with a topical N-gram model. The representation offers insights into what groupings of habitual student behaviors are associated with higher or lower success in the course. We also investigate how context information, such as time of day or a user's demographic information, is associated with the types of learning sessions.",2014,Conference on Information and Knowledge Management,sequential pattern mining;multimedia;world wide web;data mining;simulation;computer science;
Exploiting Geographical Neighborhood Characteristics for Location Recommendation,Yong Liu (Nanyang Technological University);Wei Wei (Singapore Management University);Aixin Sun (Nanyang Technological University);Chunyan Miao (Nanyang Technological University);,"2657246124,2305652005,2124989948,2154137932","Geographical characteristics derived from the historical check-in data have been reported effective in improving location recommendation accuracy. However, previous studies mainly exploit geographical characteristics from a user's perspective, via modeling the geographical distribution of each individual user's check-ins. In this paper, we are interested in exploiting geographical characteristics from a location perspective, by modeling the geographical neighborhood of a location. The neighborhood is modeled at two levels: the instance-level neighborhood defined by a few nearest neighbors of the location, and the region-level neighborhood for the geographical region where the location exists. We propose a novel recommendation approach, namely I nstance- Re gion N eighborhood M atrix F actorization (IRenMF), which exploits two levels of geographical neighborhood characteristics: a) instance-level characteristics, i.e., nearest neighboring locations tend to share more similar user preferences; and b) region-level characteristics, i.e., locations in the same geographical region may share similar user preferences. In IRenMF, the two levels of geographical characteristics are naturally incorporated into the learning of latent features of users and locations, so that IRenMF predicts users' preferences on locations more accurately. Extensive experiments on the real data collected from Gowalla, a popular LBSN, demonstrate the effectiveness and advantages of our approach.",2014,Conference on Information and Knowledge Management,matrix decomposition;world wide web;data mining;
Question Retrieval with High Quality Answers in Community Question Answering,Kai Zhang (Beihang University);Wei Wu (Microsoft);Haocheng Wu (University of Science and Technology of China);Zhoujun Li (Beihang University);Ming Zhou (Microsoft);,"2677559652,2590381716,2131380619,2133880114,2143584880","This paper studies the problem of question retrieval in community question answering (CQA). To bridge lexical gaps in questions, which is regarded as the biggest challenge in retrieval, state-of-the-art methods learn translation models using answers under an assumption that they are parallel texts. In practice, however, questions and answers are far from ""parallel"". Indeed, they are heterogeneous for both the literal level and user behaviors. There are a particularly large number of low quality answers, to which the performance of translation models is vulnerable. To address these problems, we propose a supervised question-answer topic modeling approach. The approach assumes that questions and answers share some common latent topics and are generated in a ""question language"" and ""answer language"" respectively following the topics. The topics also determine an answer quality signal. Compared with translation models, our approach not only comprehensively models user behaviors on CQA portals, but also highlights the instinctive heterogeneity of questions and answers. More importantly, it takes answer quality into account and performs robustly against noise in answers. With the topic modeling approach, we propose a topic-based language model, which matches questions not only on a term level but also on a topic level. We conducted experiments on large scale data from Yahoo! Answers and Baidu Knows. Experimental results show that the proposed model can significantly outperform state-of-the-art retrieval models in CQA.",2014,Conference on Information and Knowledge Management,natural language processing;information retrieval;data mining;computer science;
Truth Discovery in Crowdsourced Detection of Spatial Events,"Robin Wentao Ouyang (University of California, Los Angeles);Mani Srivastava (University of California, Los Angeles);Alice Toniolo (University of Aberdeen);Timothy J. Norman (University of Aberdeen);","2040879778,2098642314,2420754383,2145508458","The ubiquity of smartphones has led to the emergence of mobile crowdsourcing tasks such as the detection of spatial events when smartphone users move around in their daily lives. However, the credibility of those detected events can be negatively impacted by unreliable participants with low-quality data. Consequently, a major challenge in quality control is to discover true events from diverse and noisy participants' reports. This truth discovery problem is uniquely distinct from its online counterpart in that it involves uncertainties in both participants' mobility and reliability. Decoupling these two types of uncertainties through location tracking will raise severe privacy and energy issues, whereas simply ignoring missing reports or treating them as negative reports will significantly degrade the accuracy of the discovered truth. In this paper, we propose a new method to tackle this truth discovery problem through principled probabilistic modeling. In particular, we integrate the modeling of location popularity, location visit indicators, truth of events and three-way participant reliability in a unified framework. The proposed model is thus capable of efficiently handling various types of uncertainties and automatically discovering truth without any supervision or the need of location tracking. Experimental results demonstrate that our proposed method outperforms existing state-of-the-art truth discovery approaches in the mobile crowdsourcing environment.",2014,Conference on Information and Knowledge Management,crowdsourcing;graphical model;quality control;information system;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Relevance and Effort: An Analysis of Document Utility,Emine Yilmaz (University College London);Manisha Verma (University College London);Nick Craswell (Microsoft);Filip Radlinski (Microsoft);Peter Bailey (Microsoft);,"2342836604,2289163828,2009495402,2072292845,2295915320","In this paper, we study one important source of the mis-match between user data and relevance judgments, those due to the high degree of effort required by users to identify and consume the information in a document. Information retrieval relevance judges are trained to search for evidence of relevance when assessing documents. For complex documents, this can lead to judges' spending substantial time considering each document. However, in practice, search users are often much more impatient: if they do not see evidence of relevance quickly, they tend to give up. Relevance judgments sit at the core of test collection construction, and are assumed to model the utility of documents to real users. However, comparisons of judgments with signals of relevance obtained from real users, such as click counts and dwell time, have demonstrated a systematic mismatch. Our results demonstrate that the amount of effort required to find the relevant information in a document plays an important role in the utility of that document to a real user. This effort is ignored in the way relevance judgments are currently obtained, despite the expectation that judges inform us about real users. We propose that if the goal is to evaluate the likelihood of utility to the user, effort as well as relevance should be taken into consideration, and possibly characterized independently, when judgments are obtained.",2014,Conference on Information and Knowledge Management,relevance;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
SharkDB: An In-Memory Column-Oriented Trajectory Storage,Haozhou Wang (University of Queensland);Kai Zheng (University of Queensland);Jiajie Xu (Soochow University);Bolong Zheng (University of Queensland);Xiaofang Zhou (University of Queensland);Shazia Wasim Sadiq (University of Queensland);,"2139729050,2150403146,2124260618,2342922762,2128990482,2122552307","The last decade has witnessed the prevalence of sensor and GPS technologies that produce a high volume of trajectory data representing the motion history of moving objects. However some characteristics of trajectories such as variable lengths and asynchronous sampling rates make it difficult to fit into traditional database systems that are disk-based and tuple-oriented. Motivated by the success of column store and recent development of in-memory databases, we try to explore the potential opportunities of boosting the performance of trajectory data processing by designing a novel trajectory storage within main memory. In contrast to most existing trajectory indexing methods that keep consecutive samples of the same trajectory in the same disk page, we partition the database into frames in which the positions of all moving objects at the same time instant are stored together and aligned in main memory. We found this column-wise storage to be surprisingly well suited for in-memory computing since most frames can be stored in highly compressed form, which is pivotal for increasing the memory throughput and reducing CPU-cache miss. The independence between frames also makes them natural working units when parallelizing data processing on a multi-core environment. Lastly we run a variety of common trajectory queries on both real and synthetic datasets in order to demonstrate advantages and study the limitations of our proposed storage.",2014,Conference on Information and Knowledge Management,trajectory;world wide web;data mining;database;real time computing;artificial intelligence;simulation;computer science;
Deviation-Based Contextual SLIM Recommenders,Yong Zheng (DePaul University);Bamshad Mobasher (DePaul University);Robin D. Burke (DePaul University);,"2467968861,1892801027,2122091461","Context-aware recommender systems (CARS) help improve the effectiveness of recommendations by adapting to users' preferences in different contextual situations. One approach to CARS that has been shown to be particularly effective is Context-Aware Matrix Factorization (CAMF). CAMF incorporates contextual dependencies into the standard matrix factorization (MF) process, where users and items are represented as collections of weights over various latent factors. In this paper, we introduce another CARS approach based on an extension of matrix factorization, namely, the Sparse Linear Method (SLIM). We develop a family of deviation-based contextual SLIM (CSLIM) recommendation algorithms by learning rating deviations in different contextual conditions. Our CSLIM approach is better at explaining the underlying reasons behind contextual recommendations, and our experimental evaluations over five context-aware data sets demonstrate that these CSLIM algorithms outperform the state-of-the-art CARS algorithms in the top- N recommendation task. We also discuss the criteria for selecting the appropriate CSLIM algorithm in advance based on the underlying characteristics of the data.",2014,Conference on Information and Knowledge Management,matrix decomposition;world wide web;information retrieval;data mining;computer science;
How Many Folders Do You Really Need?: Classifying Email into a Handful of Categories,Mihajlo Grbovic (Yahoo!);Guy Halawi (Yahoo!);Zohar Shay Karnin (Yahoo!);Yoelle Maarek (Yahoo!);,"2000240052,259131073,1985648170,262608878","Email classification is still a mostly manual task. Consequently, most Web mail users never define a single folder. Recently however, automatic classification offering the same categories to all users has started to appear in some Web mail clients, such as AOL or Gmail. We adopt this approach, rather than previous (unsuccessful) personalized approaches because of the change in the nature of consumer email traffic, which is now dominated by (non-spam) machine-generated email. We propose here a novel approach for (1) automatically distinguishing between personal and machine-generated email and (2) classifying messages into latent categories, without requiring users to have defined any folder. We report how we have discovered that a set of 6 ""latent"" categories (one for human- and the others for machine-generated messages) can explain a significant portion of email traffic. We describe in details the steps involved in building a Web-scale email categorization system, from the collection of ground-truth labels, the selection of features to the training of models. Experimental evaluation was performed on more than 500 billion messages received during a period of six months by users of Yahoo mail service, who elected to be part of such research studies. Our system achieved precision and recall rates close to 90% and the latent categories we discovered were shown to cover 70% of both email traffic and email search queries. We believe that these results pave the way for a change of approach in the Web mail industry, and could support the invention of new large-scale email discovery paradigms that had not been possible before.",2014,Conference on Information and Knowledge Management,html email;email authentication;email address harvesting;opt in email;internet privacy;world wide web;data mining;computer science;
CONR: A Novel Method for Sentiment Word Identification,Jiguang Liang (Chinese Academy of Sciences);Xiaofei Zhou (Chinese Academy of Sciences);Yue Hu (Chinese Academy of Sciences);Li Guo (Chinese Academy of Sciences);Shuo Bai (Chinese Academy of Sciences);,"2164511334,2106740761,2508518679,2122010476,2631588326","Sentiment word identification (SWI) is of high relevance to sentiment analysis technologies and applications. Currently most SWI methods heavily rely on sentiment seed words that have limited sentiment information. Even though there emerge non-seed approaches based on sentiment labels of documents, but in which the context information has not been fully considered. In this paper, based on matrix factorization with co-occurrence neighbor regularization which is derived from context, we propose a novel non-seed model called CONR for SWI. Instead of seed words, CONR exploits two important factors: sentiment matching and sentiment consistency for sentiment word identification. Experimental results on four publicly available datasets show that CONR can outperform the state of-the-art methods.",2014,Conference on Information and Knowledge Management,matrix decomposition;sentiment analysis;natural language processing;speech recognition;pattern recognition;computer science;
Incremental Update Summarization: Adaptive Sentence Selection based on Prevalence and Novelty,Richard McCreadie (University of Glasgow);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"2078704756,2148910894,336997814","The automatic summarization of long-running events from news steams is a challenging problem. A long-running event can contain hundreds of unique 'nuggets' of information to summarize, spread-out over its lifetime. Meanwhile, information reported about it can rapidly become outdated and is often highly redundant. Incremental update summarization (IUS) aims to select sentences from news streams to issue as updates to the user, summarising that event over time. The updates issued should cover all of the key nuggets concisely and before the information contained in those nuggets becomes outdated. Prior summarization approaches when applied to IUS can fail, since they define a fixed summary length that cannot effectively account for the different magnitudes and varying rate of development of such events. In this paper, we propose a novel IUS approach that adaptively alters the volume of content issued as updates over time with respect to the prevalence and novelty of discussions about the event. It incorporates existing state-of-the-art summarization techniques to rank candidate sentences, followed by a supervised regression model that balances novelty, nugget coverage and timeliness when selecting sentences from the top ranks. We empirically evaluate our approach using the TREC 2013 Temporal Summarization dataset extended with additional assessments. Our results show that by adaptively adjusting the number of sentences to select over time, our approach can nearly double the performance of effective summarization baselines.",2014,Conference on Information and Knowledge Management,multi document summarization;automatic summarization;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Analysis of Physical Activity Propagation in a Health Social Network,NhatHai Phan (University of Oregon);Dejing Dou (University of Oregon);Xiao Xiao (University of Oregon);Brigitte Piniewski;David Kil;,"2147653065,2040419331,2603860799,2006322229,2197540355","Modeling physical activity propagation, such as the activity level and intensity, is the key to prevent the cascades of obesity, and help spread wellness and healthy behavior in a social network. However, there has been lacking of scientific and quantitative study to elucidate how social communication may deliver physical activity interventions. In this work we introduce a Community-level Physical Activity Propagation (CPP) model to analyze physical activity propagation and social influence at different granularities (i.e., individual level and community level). CPP is a novel model which is inspired by the well-known Independent Cascade and Community-level Social Influence models. Given a social network, we utilize a hierarchical approach to detect a set of communities and their reciprocal influence strength of physical activities. CPP provides a powerful tool to discover, summarize, and investigate influence patterns of physical activities in a health social network. The detail experimental evaluation shows not only the effectiveness of our approach but also the correlation of the detected communities with various health outcome measures (i.e., both existing ones and our novel measure, named Wellness score , which is a combination of lifestyle parameters, biometrics, and biomarkers). Our promising results potentially pave a way for knowledge discovery in health social networks.",2014,Conference on Information and Knowledge Management,simulation;computer science;
Robust Entity Linking via Random Walks,Zhaochen Guo (University of Alberta);Denilson Barbosa (University of Alberta);,"2123768671,2117262728","Entity Linking is the task of assigning entities from a Knowledge Base to textual mentions of such entities in a document. State-of-the-art approaches rely on lexical and statistical features which are abundant for popular entities but sparse for unpopular ones, resulting in a clear bias towards popular entities and poor accuracy for less popular ones. In this work, we present a novel approach that is guided by a natural notion of semantic similarity which is less amenable to such bias. We adopt a unified semantic representation for entities and documents - the probability distribution obtained from a random walk on a subgraph of the knowledge base - which can overcome the feature sparsity issue that affects previous work. Our algorithm continuously updates the semantic signature of the document as mentions are disambiguated, thus focusing the search based on context. Our experimental evaluation uses well-known benchmarks and different samples of a Wikipedia-based benchmark with varying entity popularity; the results illustrate well the bias of previous methods and the superiority of our approach, especially for the less popular entities.",2014,Conference on Information and Knowledge Management,random walk;entity linking;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;statistics;computer science;
Multileaved Comparisons for Fast Online Evaluation,Anne Schuth (University of Amsterdam);Floor Sietsma (University of Amsterdam);Shimon Whiteson (University of Amsterdam);Damien Lefortier (Yandex);Maarten de Rijke (University of Amsterdam);,"1979729989,1585604930,2042571382,109639033,401833296","Evaluation methods for information retrieval systems come in three types: offline evaluation, using static data sets annotated for relevance by human judges; user studies, usually conducted in a lab-based setting; and online evaluation, using implicit signals such as clicks from actual users. For the latter, preferences between rankers are typically inferred from implicit signals via interleaved comparison methods, which combine a pair of rankings and display the result to the user. We propose a new approach to online evaluation called multileaved comparisons that is useful in the prevalent case where designers are interested in the relative performance of more than two rankers. Rather than combining only a pair of rankings, multileaved comparisons combine an arbitrary number of rankings. The resulting user clicks then give feedback about how all these rankings compare to each other. We propose two specific multileaved comparison methods. The first, called team draft multileave, is an extension of team draft interleave. The second, called optimized multileave, is an extension of optimized interleave and is designed to handle cases where a large number of rankers must be multileaved. We present experimental results that demonstrate that both team draft multileave and optimized multileave can accurately determine all pairwise preferences among a set of rankers using far less data than the interleaving methods that they extend.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;machine learning;computer science;
A Comparison of Retrieval Models using Term Dependencies,Samuel Huston (University of Massachusetts Amherst);W. Bruce Croft (University of Massachusetts Amherst);,"2093587599,2127889770","A number of retrieval models incorporating term dependencies have recently been introduced. Most of these modify existing ""bag-of-words"" retrieval models by including features based on the proximity of pairs of terms (or bi-terms). Although these term dependency models have been shown to be significantly more effective than the bag-of-words models, there have been no previous systematic comparisons between the different approaches that have been proposed. In this paper, we compare the effectiveness of recent bi-term dependency models over a range of TREC collections, for both short (title) and long (description) queries. To ensure the reproducibility of our study, all experiments are performed on widely available TREC collections, and all tuned retrieval model parameters are made public. These comparisons show that the weighted sequential dependence model is at least as effective as, and often significantly better than, any other model across this range of collections and queries. We observe that dependency features are much more valuable in improving the performance of longer queries than for shorter queries. We then examine the effectiveness of dependence models that incorporate proximity features involving more than two terms. The results show that these features can improve effectiveness, but not consistently, over the available data sets.",2014,Conference on Information and Knowledge Management,distance;evaluation;world wide web;information retrieval;data mining;computer science;
Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by Leveraging Hashtags and Sentiment Lexicon,Kar Wai Lim (Australian National University);Wray L. Buntine (Monash University);,"2152868894,2282891647","Aspect-based opinion mining is widely applied to review data to aggregate or summarize opinions of a product, and the current state-of-the-art is achieved with Latent Dirichlet Allocation (LDA)-based model. Although social media data like tweets are laden with opinions, their ""dirty"" nature (as natural language) has discouraged researchers from applying LDA-based opinion model for product review mining. Tweets are often informal, unstructured and lacking labeled data such as categories and ratings, making it challenging for product opinion mining. In this paper, we propose an LDA-based opinion model named Twitter Opinion Topic Model (TOTM) for opinion mining and sentiment analysis. TOTM leverages hashtags , mentions , emoticons and strong sentiment words that are present in tweets in its discovery process. It improves opinion prediction by modeling the target-opinion interaction directly, thus discovering target specific opinion words, neglected in existing approaches. Moreover, we propose a new formulation of incorporating sentiment prior information into a topic model, by utilizing an existing public sentiment lexicon. This is novel in that it learns and updates with the data. We conduct experiments on 9 million tweets on electronic products, and demonstrate the improved performance of TOTM in both quantitative evaluations and qualitative analysis. We show that aspect-based opinion analysis on massive volume of tweets provides useful opinions on products.",2014,Conference on Information and Knowledge Management,topic model;sentiment analysis;data science;natural language processing;world wide web;data mining;machine learning;computer science;
Influence Maximization over Large-Scale Social Networks: A Bounded Linear Approach,Qi Liu (University of Science and Technology of China);Biao Xiang (Search Technologies);Enhong Chen (University of Science and Technology of China);Hui Xiong (Rutgers–Newark);Fangshuang Tang (University of Science and Technology of China);Jeffrey Xu Yu (The Chinese University of Hong Kong);,"2420624292,2099862789,2136372366,2153710278,2223294387,2119358208","Information diffusion in social networks is emerging as a promising solution to successful viral marketing, which relies on the effective and efficient identification of a set of nodes with the maximal social influence. While there are tremendous efforts on the development of social influence models and algorithms for social influence maximization, limited progress has been made in terms of designing both efficient and effective algorithms for finding a set of nodes with the maximal social influence. To this end, in this paper, we provide a bounded linear approach for influence computation and influence maximization. Specifically, we first adopt a linear and tractable approach to describe the influence propagation. Then, we develop a quantitative metric, named Group-PageRank, to quickly estimate the upper bound of the social influence based on this linear approach. More importantly, we provide two algorithms Linear and Bound , which exploit the linear approach and Group-PageRank for social influence maximization. Finally, extensive experimental results demonstrate that (a) the adopted linear approach has a close relationship with traditional models and Group-PageRank provides a good estimation of social influence; (b) Linear and Bound can quickly find a set of the most influential nodes and both of them are scalable for large-scale social networks.",2014,Conference on Information and Knowledge Management,viral marketing;social influence;machine learning;mathematical optimization;
Identifying Your Customers in Social Networks,Chun Ta Lu (University of Illinois at Chicago);Hong Han Shuai (National Taiwan University);Philip S. Yu (University of Illinois at Chicago);,"2224372854,2184003779,2125104194","Personal social networks are considered as one of the most influential sources in shaping a customer's attitudes and behaviors. However, the interactions with friends or colleagues in social networks of individual customers are barely observable in most e-commerce companies. In this paper, we study the problem of customer identification in social networks, i.e., connecting customer accounts at e-commerce sites to the corresponding user accounts in online social networks such as Twitter. Identifying customers in social networks is a crucial prerequisite for many potential marketing applications. These applications, for example, include personalized product recommendation based on social correlations, discovering community of customers, and maximizing product adoption and profits over social networks. We introduce a methodology CSI (Customer-Social Identification) for identifying customers in online social networks effectively by using the basic information of customers, such as username and purchase history. It consists of two key phases. The first phase constructs the features across networks that can be used to compare the similarity between pairs of accounts across networks with different schema (e.g. an e-commerce company and an online social network). The second phase identifies the top-K maximum similar and stable matched pairs of accounts across partially aligned networks. Extensive experiments on real-world datasets show that our CSI model consistently outperforms other commonly-used baselines on customer identification.",2014,Conference on Information and Knowledge Management,social network;e commerce;world wide web;data mining;computer science;
Modeling Topic Diffusion in Multi-Relational Bibliographic Information Networks,Huan Gui (University of Illinois at Urbana–Champaign);Yizhou Sun (Northeastern University);Jiawei Han (University of Illinois at Urbana–Champaign);George Brova (University of Illinois at Urbana–Champaign);,"2634990551,2131539564,2121939561,2223498500","Information diffusion has been widely studied in networks, aiming to model the spread of information among objects when they are connected with each other. Most of the current research assumes the underlying network is homogeneous, i.e. , objects are of the same type and they are connected by links with the same semantic meanings. However, in the real word, objects are connected via different types of relationships, forming multi-relational heterogeneous information networks. In this paper, we propose to model information diffusion in such multi-relational networks, by distinguishing the power in passing information around for different types of relationships. We propose two variations of the linear threshold model for multi-relational networks, by considering the aggregation of information at either the model level or the relation level. In addition, we use real diffusion action logs to learn the parameters in these models, which will benefit diffusion prediction in real networks. We apply our diffusion models in two real bibliographic information networks, DBLP network and APS network, and experimentally demonstrate the effectiveness of our models compared with single-relational diffusion models. Moreover, our models can determine the diffusion power of each relation type, which helps us understand the diffusion process better in the multi-relational bibliographic network scenario.",2014,Conference on Information and Knowledge Management,world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Online User Location Inference Exploiting Spatiotemporal Correlations in Social Streams,Yuto Yamaguchi (University of Tsukuba);Toshiyuki Amagasa (University of Tsukuba);Hiroyuki Kitagawa (University of Tsukuba);Yohei Ikawa (IBM);,"2150454284,2008176303,2124997989,2138622415","The location profiles of social media users are valuable for various applications, such as marketing and real-world analysis. As most users do not disclose their home locations, the problem of inferring home locations has been well studied in recent years. In fact, most existing methods perform batch inference using static (i.e., pre-stored) social media contents. However, social media contents are generated and delivered in real-time as social streams . In this situation, it is important to continuously update current inference results based on the newly arriving contents to improve the results over time. Moreover, it is effective for location inference to use the spatiotemporal correlation between contents and locations. The main idea of this paper is that we can infer the locations of users who simultaneously post about a local event (e.g., earthquakes) . Hence, in this paper, we propose an online location inference method over social streams that exploits the spatiotemporal correlation, achieving 1) continuous updates with low computational and storage costs, and 2) better inference accuracy than that of existing methods. The experimental results using a Twitter dataset show that our method reduces the inference error to less than 68% of existing methods. The results also show that the proposed method can update inference results in constant time regardless of the amount of accumulated contents.",2014,Conference on Information and Knowledge Management,spatiotemporal database;world wide web;data mining;machine learning;
Query Augmentation based Intent Matching in Retail Vertical Ads,"Huasha Zhao (University of California, Berkeley);Ye Chen (Microsoft);John F. Canny (University of California, Berkeley);Tak W. Yan (Microsoft);","2161004278,2167005179,2101610026,2139394280","Search advertising shows trends of vertical extension. Vertical ads, including product ads and local search ads, are proliferating at an ever increasing pace. They typically offer better ROI to advertisers as a result of better user engagement. However, campaigns and bids in vertical ads are not set at the keyword level. As a result, the matching between user query and ads suffers low recall rate and the match quality is heavily impacted by tail queries. In this paper, we propose an ad retrieval framework for retail vertical ads, based on query rewrite using personal history data to improve ad recall rate. To insure ad quality, we also present a relevance model for matching rewritten queries with user search intent, with a particular focus on tail queries. In addition, we designed and implemented a GPU-based system to accelerate the training of the relevance model to meet production performance constraints. Finally, we carry out extensive experiments on large-scale logs collected from Bing, and show significant gains in ad retrieval rate without compromising ad quality.",2014,Conference on Information and Knowledge Management,personalization;internet privacy;world wide web;data mining;database;computer science;
SemStore: A Semantic-Preserving Distributed RDF Triple Store,Buwen Wu (Huazhong University of Science and Technology);Yongluan Zhou (University of Southern Denmark);Pingpeng Yuan (Huazhong University of Science and Technology);Hai Jin (Huazhong University of Science and Technology);Ling Liu (Georgia Institute of Technology);,"2096452023,2097638082,2709278085,2168417342,2125988131","The flexibility of the RDF data model has attracted an increasing number of organizations to store their data in an RDF format. With the rapid growth of RDF datasets, we envision that it is inevitable to deploy a cluster of computing nodes to process large-scale RDF data in order to deliver desirable query performance. In this paper, we address the challenging problems of data partitioning and query optimization in a scale-out RDF engine. We identify that existing approaches only focus on using fine-grained structural information for data partitioning, and hence fail to localize many types of complex queries. We then propose a radically different approach, where a coarse-grained structure, namely Rooted Sub-Graph (RSG), is used as the partition unit. By doing so, we can capture structural information at a much greater scale and hence are able to localize many complex queries. We also propose a k-means partitioning algorithm for allocating the RSGs onto the computing nodes as well as a query optimization strategy to minimize the inter-node communication during query processing. An extensive experimental study using benchmark datasets and real dataset shows that our engine, SemStore, outperforms existing systems by orders of magnitudes in terms of query response time.",2014,Conference on Information and Knowledge Management,cwm;rdf query language;rdf schema;sparql;rdf;query optimization;linked data;world wide web;information retrieval;data mining;database;computer science;
On the Importance of Venue-Dependent Features for Learning to Rank Contextual Suggestions,Romain Deveaud (University of Glasgow);M-Dyaa Albakour (University of Glasgow);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"314381667,209705036,2148910894,336997814","Suggesting venues to a user in a given geographic context is an emerging task that is currently attracting a lot of attention. Existing studies in the literature consist of approaches that rank candidate venues based on different features of the venues and the user, which either focus on modeling the preferences of the user or the quality of the venue. However, while providing insightful results and conclusions, none of these studies have explored the relative effectiveness of these different features. In this paper, we explore a variety of user-dependent and venue-dependent features and apply state-of-the-art learning to rank approaches to the problem of contextual suggestion in order to find what makes a venue relevant for a given context. Using the test collection of the TREC 2013 Contextual Suggestion track, we perform a number of experiments to evaluate our approach. Our results suggest that a learning to rank technique can significantly outperform a Language Modelling baseline that models the positive and negative preferences of the user. Moreover, despite the fact that the contextual suggestion task is a personalisation task (i.e. providing the user with personalised suggestions of venues), we surprisingly find that user-dependent features are less effective than venue-dependent features for estimating the relevance of a suggestion.",2014,Conference on Information and Knowledge Management,personalization;learning to rank;multimedia;world wide web;data mining;machine learning;computer science;
Cross-Device Search,George D. Montanez (Carnegie Mellon University);Ryen W. White (Microsoft);Xiao Huang (Microsoft);,"2013836882,2096583854,2227002492","Ownership and use of multiple devices such as desktop computers, smartphones, and tablets is increasing rapidly. Search is popular and people often perform search tasks that span device boundaries. Understanding how these devices are used and how people transition between them during information seeking is essential in developing search support for a multi-device world. In this paper, we study search across devices and propose models to predict aspects of cross-device search transitions. We characterize multi-device search across four device types, including aspects of search behavior on each device (e.g., topics of interest) and characteristics of device transitions. Building on the characterization, we learn models to predict various aspects of cross-device search, including the next device used for search. This enables many applications. For example, accurately forecasting the device used for the next query lets search engines proactively retrieve device-appropriate content (e.g., short documents for smartphones), while knowledge of the current device combined with device-specific topical interest models may assist in better query-sense disambiguation. %to help the searcher once they transition to the target device.",2014,Conference on Information and Knowledge Management,search analytics;search engine;semantic search;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Social Book Search Reranking with Generalized Content-Based Filtering,Bo-Wen Zhang (University of Science and Technology Beijing);Xu-Cheng Yin (University of Science and Technology Beijing);Xiao-Ping Cui (University of Science and Technology Beijing);Jiao Qu (University of Science and Technology Beijing);Bin Geng (University of Science and Technology Beijing);Fang Zhou (University of Science and Technology Beijing);Li Song (Chinese Academy of Sciences);Hong-Wei Hao (Chinese Academy of Sciences);,"2545197791,2155109488,2126926330,2133792670,2429490040,2431395688,2680253072,2712529348","Semantically searching and navigating products (e.g., on Taobao.com or Amazon.com) with professional metadata and user-generated content from social media is a hot topic in information retrieval and recommendation systems, while most existing methods are specifically designed as a purely searching system. In this paper, taking Social Book Search as an example, we propose a general search-recommendation hybrid system for this topic. Firstly, we propose a Generalized Content-Based Filtering (GCF) model. In this model, a preference value, which flexibly ranges from 0 to 1, is defined to describe a user's preference for each item to be recommended, unlike conventionally using a set of preferable items. We also design a weighting formulation for the measure of recommendation. Next, assuming that the query in a searching system acts as a user in a recommendation system, a general reranking model is constructed with GCF to rerank the initial resulting list by utilizing a variety of rich social information. Afterwards, we propose a general search-recommendation hybrid framework for Social Book Search, where learning-to-rank is used to adaptively combine all reranking results. Finally, our proposed system is extensively evaluated on the INEX 2012 and 2013 Social Book Search datasets, and has the best performance (NDCG@10) on both datasets compared to other state-of-the-art systems. Moreover, our system recently won the INEX 2014 Social Book Search Evaluation.",2014,Conference on Information and Knowledge Management,learning to rank;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Efficient Filter Approximation Using the Earth Mover's Distance in Very Large Multimedia Databases with Feature Signatures,Merih Seran Uysal (RWTH Aachen University);Christian Beecks (RWTH Aachen University);Jochen Schmücking (RWTH Aachen University);Thomas Seidl (RWTH Aachen University);,"1976045200,175699300,2226464860,2140301036","The Earth Mover's Distance, proposed in computer vision as a distance-based similarity model reflecting the human perceptual similarity, has been widely utilized in numerous domains for similarity search applicable on both feature histograms and signatures. While efficiency improvement methods towards the Earth Mover's Distance were frequently investigated on feature histograms, not much work is known to study this similarity model on feature signatures denoting object-specific feature representations. Given a very large multimedia database of features signatures, how can k-nearest-neighbor queries be processed efficiently by using the Earth Mover's Distance? In this paper, we propose an efficient filter approximation technique to lower bound the Earth Mover's Distance on feature signatures by restricting the number of earth flows locally. Extensive experiments on real world data indicate the high efficiency of the proposal, attaining order-of-magnitude query processing time cost reduction for high dimensional feature signatures.",2014,Conference on Information and Knowledge Management,earth mover s distance;upper and lower bounds;data mining;pattern recognition;machine learning;statistics;
A Fresh Look on Knowledge Bases: Distilling Named Events from News,Erdal Kuzey (Max Planck Society);Jilles Vreeken (Max Planck Society);Gerhard Weikum (Max Planck Society);,"280525616,1971070670,514836396","Knowledge bases capture millions of entities such as people, companies or movies. However, their knowledge of named events like sports finals, political scandals, or natural disasters is fairly limited, as these are continuously emerging entities. This paper presents a method for extracting named events from news articles, reconciling them into canonicalized representation, and organizing them into fine-grained semantic classes to populate a knowledge base. Our method captures similarity measures among news articles in a multi-view attributed graph, considering textual contents, entity occurrences, and temporal ordering. For distilling canonicalized events from this raw data, we present a novel graph coarsening algorithm based on the information-theoretic principle of minimum description length. The quality of our method is experimentally demonstrated by extracting, organizing, and evaluating 25,000 events from a corpus of 300,000 heterogeneous news articles.",2014,Conference on Information and Knowledge Management,minimum description length;information extraction;data science;natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
Revisiting the Divergence Minimization Feedback Model,Yuanhua Lv (Microsoft);ChengXiang Zhai (University of Illinois at Urbana–Champaign);,"2132538679,2152766206","Pseudo-relevance feedback (PRF) has proven to be an effective strategy for improving retrieval accuracy. In this paper, we revisit a PRF method based on statistical language models, namely the divergence minimization model (DMM). DMM not only has apparently sound theoretical foundation, but also has been shown to satisfy most of the retrieval constraints. However, it turns out to perform surprisingly poorly in many previous experiments. We investigate the cause, and reveal that DMM inappropriately tackles the entropy of the feedback model, which generates highly skewed feedback model. To address this problem, we propose a maximum-entropy divergence minimization model (MEDMM) by introducing an entropy term to regularize DMM. Our experiments on various TREC collections demonstrate that MEDMM not only works much better than DMM, but also outperforms several other state of the art PRF methods, especially on web collections. Moreover, unlike existing PRF models that have to be combined with the original query to perform well, MEDMM can work effectively even without being combined with the original query.",2014,Conference on Information and Knowledge Management,additive smoothing;principle of maximum entropy;data mining;database;artificial intelligence;machine learning;statistics;algorithm;computer science;
An Eye-tracking Study of User Interactions with Query Auto Completion,Kajta Hofmann (Microsoft);Bhaskar Mitra (Microsoft);Filip Radlinski (Microsoft);Milad Shokouhi (Microsoft);,"2419907998,2229276239,2072292845,2072421081","Query Auto Completion (QAC) suggests possible queries to web search users from the moment they start entering a query. This popular feature of web search engines is thought to reduce physical and cognitive effort when formulating a query. Perhaps surprisingly, despite QAC being widely used, users' interactions with it are poorly understood. This paper begins to address this gap. We present the results of an in-depth user study of user interactions with QAC in web search. While study participants completed web search tasks, we recorded their interactions using eye-tracking and client-side logging. This allows us to provide a first look at how users interact with QAC. We specifically focus on the effects of QAC ranking, by controlling the quality of the ranking in a within-subject design. We identify a strong position bias that is consistent across ranking conditions. Due to this strong position bias, ranking quality affects QAC usage. We also find an effect on task completion, in particular on the number of result pages visited. We show how these effects can be explained by a combination of searchers' behavior patterns, namely monitoring or ignoring QAC, and searching for spelling support or complete queries to express a search intent. We conclude the paper with a discussion of the important implications of our findings for QAC evaluation.",2014,Conference on Information and Knowledge Management,eye tracking;evaluation;world wide web;information retrieval;data mining;database;machine learning;computer science;
MapReduce Triangle Enumeration With Guarantees,Ha-Myung Park (KAIST);Francesco Silvestri (University of Padua);U. Kang (KAIST);Rasmus Pagh (IT University of Copenhagen);,"2229610034,2025878313,2615132872,1864519460","We describe an optimal randomized MapReduce algorithm for the problem of triangle enumeration that requires O(E 3/2 /(M√m) rounds, where m denotes the expected memory size of a reducer and M the total available space. This generalizes the well-known vertex partitioning approach proposed in (Suri and Vassilvitskii, 2011) to multiple rounds, significantly increasing the size of the graphs that can be handled on a given system. We also give new theoretical (high probability) bounds on the work needed in each reducer, addressing the ""curse of the last reducer"". Indeed, our work is the first to give guarantees on the maximum load of each reducer for an arbitrary input graph. Our experimental evaluation shows the scalability of our approach, that it is competitive with existing methods improving the performance by a factor up to 2X, and that it can significantly increase the size of datasets that can be processed.",2014,Conference on Information and Knowledge Management,theoretical computer science;
Tagging Your Tweets: A Probabilistic Modeling of Hashtag Annotation in Twitter,Zongyang Ma (Nanyang Technological University);Aixin Sun (Nanyang Technological University);Quan Yuan (Nanyang Technological University);Gao Cong (Nanyang Technological University);,"2111067505,2124989948,2163879794,2295915604","The adoption of hashtags in major social networks including Twitter, Facebook, and Google+ is a strong evidence of its importance in facilitating information diffusion and social chatting. To understand the factors ( e.g. , user interest, posting time and tweet content) that may affect hashtag annotation in Twitter and to capture the implicit relations between latent topics in tweets and their corresponding hashtags, we propose two PLSA-style topic models to model the hashtag annotation behavior in Twitter. Content-Pivoted Model (CPM) assumes that tweet content guides the generation of hashtags while Hashtag-Pivoted Model (HPM) assumes that hashtags guide the generation of tweet content. Both models jointly incorporate user, time, hashtag and tweet content in a probabilistic framework. The PLSA-style models also enable us to verify the impact of social factor on hashtag annotation by introducing social network regularization in the two models. We evaluate the proposed models using perplexity and demonstrate their effectiveness in two applications: retrospective hashtag annotation and related hashtag discovery. Our results show that HPM outperforms CPM by perplexity and both user and time are important factors that affect model performance. In addition, incorporating social network regularization does not improve model performance. Our experimental results also demonstrate the effectiveness of our models in both applications compared with baseline methods.",2014,Conference on Information and Knowledge Management,topic model;internet privacy;multimedia;world wide web;information retrieval;data mining;database;machine learning;computer science;
Meta-Path-Based Ranking with Pseudo Relevance Feedback on Heterogeneous Graph for Citation Recommendation,Xiaozhong Liu (Indiana University Bloomington);Yingying Yu (Dalian Maritime University);Chun Guo (Indiana University Bloomington);Yizhou Sun (Northeastern University);,"2171587459,2116782962,2279146887,2131539564","The sheer volume of scholarly publications available online significantly challenges how scholars retrieve the new information available and locate the candidate reference papers. While classical text retrieval and pseudo relevance feedback (PRF) algorithms can assist scholars in accessing needed publications, in this study, we propose an innovative publication ranking method with PRF by leveraging a number of meta-paths on the heterogeneous bibliographic graph. Different meta-paths on the graph address different ranking hypotheses, whereas the pseudo-relevant papers (from the retrieval results) are used as the seed nodes on the graph. Meanwhile, unlike prior studies, we propose ""restricted meta-path"" facilitated by a new context-rich heterogeneous network extracted from full-text publication content along with citation context. By using learning-to-rank, we integrate 18 different meta-path-based ranking features to derive the final ranking scores for candidate cited papers. Experimental results with ACM full-text corpus show that meta-path-based ranking with PRF on the new graph significantly ( p",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;machine learning;computer science;
Scalable Privacy-Preserving Record Linkage for Multiple Databases,Dinusha Vatsalan (Australian National University);Peter Christen (Australian National University);,"145048928,2023765750","Privacy-preserving record linkage (PPRL) is the process of identifying records that correspond to the same real-world entities across several databases without revealing any sensitive information about these entities. Various techniques have been developed to tackle the problem of PPRL, with the majority of them only considering linking two databases. However, in many real-world applications data from more than two sources need to be linked. In this paper we consider the problem of linking data from three or more sources in an efficient and secure way. We propose a protocol that combines the use of Bloom filters, secure summation, and Dice coefficient similarity calculation with the aim to identify all records held by the different data sources that have a similarity above a certain threshold. Our protocol is secure in that no party learns any sensitive information about the other parties' data, but all parties learn which of their records have a high similarity with records held by the other parties. We evaluate our protocol on a large dataset showing the scalability, linkage quality, and privacy of our protocol.",2014,Conference on Information and Knowledge Management,bloom filter;record linkage;privacy;information security;internet privacy;world wide web;information retrieval;data mining;database;computer science;
Multi-task Sparse Structure Learning,André Ricardo Gonçalves (University of Minnesota);Puja Das (University of Minnesota);Soumyadeep Chatterjee (University of Minnesota);Vidyashankar Sivakumar (University of Minnesota);Fernando J. Von Zuben (State University of Campinas);Arindam Banerjee (University of Minnesota);,"2152966786,2155380678,2265873320,2018949929,2112999452,2037585042","Multi-task learning (MTL) aims to improve generalization performance by learning multiple related tasks simultaneously. While sometimes the underlying task relationship structure is known, often the structure needs to be estimated from data at hand. In this paper, we present a novel family of models for MTL, applicable to regression and classification problems, capable of learning the structure of task relationships. In particular, we consider a joint estimation problem of the task relationship structure and the individual task parameters, which is solved using alternating minimization. The task relationship structure learning component builds on recent advances in structure learning of Gaussian graphical models based on sparse estimators of the precision (inverse covariance) matrix. We illustrate the effectiveness of the proposed model on a variety of synthetic and benchmark datasets for regression and classification. We also consider the problem of combining climate model outputs for better projections of future climate, with focus on temperature in South America, and show that the proposed model outperforms several existing methods for the problem.",2014,Conference on Information and Knowledge Management,multi task learning;generalization error;active learning;semi supervised learning;unsupervised learning;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
DFD: Efficient Functional Dependency Discovery,Ziawasch Abedjan (Hasso Plattner Institute);Patrick Schulze (Hasso Plattner Institute);Felix Naumann (Hasso Plattner Institute);,"2633291647,2228938974,2099727678","The discovery of unknown functional dependencies in a dataset is of great importance for database redesign, anomaly detection and data cleansing applications. However, as the nature of the problem is exponential in the number of attributes none of the existing approaches can be applied on large datasets. We present a new algorithm DFD for discovering all functional dependencies in a dataset following a depth-first traversal strategy of the attribute lattice that combines aggressive pruning and efficient result verification. Our approach is able to scale far beyond existing algorithms for up to 7.5 million tuples, and is up to three orders of magnitude faster than existing approaches on smaller datasets.",2014,Conference on Information and Knowledge Management,functional dependency;theoretical computer science;data mining;database;computer science;
Exploring Tag-Free RFID-Based Passive Localization and Tracking via Learning-Based Probabilistic Approaches,Lina Yao (University of Adelaide);Wenjie Ruan (University of Adelaide);Quan Z. Sheng (University of Adelaide);Xue Li (University of Queensland);Nicholas J.G. Falkner (University of Adelaide);,"2223456168,2148844920,1740996049,2239470812,2619920303","RFID-based localization and tracking has some promising potentials. By combining localization with its identification capability, existing applications can be enhanced and new applications can be developed. In this paper, we investigate a tag-free indoor localizing and tracking problem (e.g., people tracking) without requiring subjects to carry any tags or devices in a pure passive environment. We formulate localization as a classification task. In particular, we model the received signal strength indicator (RSSI) of passive tags using multivariate Gaussian Mixture Model (GMM), and use the Expectation Maximization (EM) to learn the maximum likelihood estimates of the model parameters. Several other learning-based probabilistic approaches are also explored in the localization problem. To track a moving subject, we propose GMM based Hidden Markov Model (HMM) and k Nearest Neighbor ( k NN) based HMM approaches. We conduct extensive experiments in a testbed formed by passive RFID tags, and the experimental results demonstrate the effectiveness and accuracy of our approach.",2014,Conference on Information and Knowledge Management,radio frequency identification;mixture model;internationalization and localization;hidden markov model;speech recognition;pattern recognition;machine learning;computer science;
Truth Discovery in Data Streams: A Single-Pass Probabilistic Approach,Zhou Zhao (Hong Kong University of Science and Technology);James Cheng (The Chinese University of Hong Kong);Wilfred Siu Hung Ng (Hong Kong University of Science and Technology);,"2118299058,2304873892,2170178419","Truth discovery is a long-standing problem for assessing the validity of information from various data sources that may provide different and conflicting information. With the increasing prominence of data streams arising in a wide range of applications such as weather forecast and stock price prediction, effective techniques for truth discovery in data streams are demanded. However, existing work mainly focuses on truth discovery in the context of static databases, which is not applicable in applications involving streaming data. This motivates us to develop new techniques to tackle the problem of truth discovery in data streams. In this paper, we propose a probabilistic model that transforms the problem of truth discovery over data streams into a probabilistic inference problem. We first design a streaming algorithm that infers the truth as well as source quality in real time. Then, we develop a one-pass algorithm, in which the inference of source quality is proved to be convergent and the accuracy is further improved. We conducted extensive experiments on real datasets which verify both the efficiency and accuracy of our methods for truth discovery in data streams.",2014,Conference on Information and Knowledge Management,data science;information retrieval;data mining;database;computer science;
Concept-based Short Text Classification and Ranking,Fang Wang (Beihang University);Zhongyuan Wang (Microsoft);Zhoujun Li (Beihang University);Ji-Rong Wen (Renmin University of China);,"2699541109,2585510981,2133880114,2593770520","Most existing approaches for text classification represent texts as vectors of words, namely ``Bag-of-Words.'' This text representation results in a very high dimensionality of feature space and frequently suffers from surface mismatching. Short texts make these issues even more serious, due to their shortness and sparsity. In this paper, we propose using ``Bag-of-Concepts'' in short text representation, aiming to avoid the surface mismatching and handle the synonym and polysemy problem. Based on ``Bag-of-Concepts,'' a novel framework is proposed for lightweight short text classification applications. By leveraging a large taxonomy knowledgebase, it learns a concept model for each category, and conceptualizes a short text to a set of relevant concepts. A concept-based similarity mechanism is presented to classify the given short text to the most similar category. One advantage of this mechanism is that it facilitates short text ranking after classification, which is needed in many applications, such as query or ad recommendation. We demonstrate the usage of our proposed framework through a real online application: Channel-based Query Recommendation. Experiments show that our framework can map queries to channels with a high degree of precision (avg. precision=90.3%), which is critical for recommendation applications.",2014,Conference on Information and Knowledge Management,natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
NCR: A Scalable Network-Based Approach to Co-Ranking in Question-and-Answer Sites,Jingyuan Zhang (University of Illinois at Chicago);Xiangnan Kong (University of Illinois at Chicago);Roger Jie Luo (Yahoo!);Yi Chang (Yahoo!);Philip S. Yu (University of Illinois at Chicago);,"2142129048,2204127537,2226359548,2168000538,2125104194","Question-and-answer (QA b) The large-scale Q&A data makes extracting supervised information very expensive. In order to address these issues, we propose an unsupervised N etwork-based C o- R anking framework (NCR) to rank multiple objects in Q&A sites. Empirical studies on real-world Yahoo! Answers datasets demonstrate the effectiveness and the efficiency of the proposed NCR method.",2014,Conference on Information and Knowledge Management,data science;data mining;machine learning;computer science;
Unsupervised Feature Selection for Multi-View Clustering on Text-Image Web News Data,Mingjie Qian (University of Illinois at Urbana–Champaign);Chengxiang Zhai (University of Illinois at Urbana–Champaign);,"2110740920,2152766206","Unlabeled high-dimensional text-image web news data are produced every day, presenting new challenges to unsupervised feature selection on multi-view data. State-of-the-art multi-view unsupervised feature selection methods learn pseudo class labels by spectral analysis, which is sensitive to the choice of similarity metric for each view. For text-image data, the raw text itself contains more discriminative information than similarity graph which loses information during construction, and thus the text feature can be directly used for label learning, avoiding information loss as in spectral analysis. We propose a new multi-view unsupervised feature selection method in which image local learning regularized orthogonal nonnegative matrix factorization is used to learn pseudo labels and simultaneously robust joint $l_{2,1}$-norm minimization is performed to select discriminative features. Cross-view consensus on pseudo labels can be obtained as much as possible. We systematically evaluate the proposed method in multi-view text-image web news datasets. Our extensive experiments on web news datasets crawled from two major US media channels: CNN and FOXNews demonstrate the efficacy of the new method over state-of-the-art multi-view and single-view unsupervised feature selection methods.",2014,Conference on Information and Knowledge Management,unsupervised learning;data mining;pattern recognition;machine learning;computer science;
Head First: Living Labs for Ad-hoc Search Evaluation,Krisztian Balog (University of Stavanger);Liadh Kelly (Dublin City University);Anne Schuth (University of Amsterdam);,"2100338238,2156417348,1979729989","The information retrieval (IR) community strives to make evaluation more centered on real users and their needs. The living labs evaluation paradigm, i.e., observing users in their natural task environments, offers great promise in this regard. Yet, progress in an academic setting has been limited. This paper presents the first living labs for the IR community benchmarking campaign initiative, taking as test two use-cases: local domain search on a university website and product search on an e-commerce site. There are many challenges associated with this setting, including incorporating results from experimental search systems into live production systems, and obtaining sufficiently many impressions from relatively low traffic sites. We propose that head queries can be used to generate result lists offline, which are then interleaved with results of the production system for live evaluation. An API is developed to orchestrate the communication between commercial parties and benchmark participants. This campaign acts to progress the living labs for IR evaluation methodology, and offers important insight into the role of living labs in this space.",2014,Conference on Information and Knowledge Management,evaluation;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;simulation;computer science;
"""Strength Lies in Differences"": Diversifying Friends for Recommendations through Subspace Clustering",Eirini Ntoutsi (Ludwig Maximilian University of Munich);Kostas Stefanidis (Norwegian University of Science and Technology);Katharina Rausch (Ludwig Maximilian University of Munich);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);,"147176459,1975499546,2223546342,1919135125","Nowadays, WWW brings overwhelming variety of choices to consumers. Recommendation systems facilitate the selection by issuing recommendations to them. Recommendations for users, or groups, are determined by considering users similar to the users in question. Scanning the whole database for locating similar users, though, is expensive. Existing approaches build cluster models by employing full-dimensional clustering to find sets of similar users. As the datasets we deal with are high-dimensional and incomplete, full-dimensional clustering is not the best option. To this end, we explore the fault-tolerant subspace clustering approach. We extend the concept of fault tolerance to density-based subspace clustering, and to speed up our algorithms, we introduce the significance threshold for considering only promising dimensions for subspace extension. Moreover, as we potentially receive a multitude of users from subspace clustering, we propose a weighted ranking approach to refine the set of like-minded users. Our experiments on real movie datasets show that the diversification of the similar users that the subspace clustering approaches offer results in better recommendations compared to traditional collaborative filtering and full-dimensional clustering approaches.",2014,Conference on Information and Knowledge Management,correlation clustering;constrained clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;fault tolerance;cluster analysis;world wide web;data mining;database;machine learning;computer science;
Canonicalizing Open Knowledge Bases,Luis Galárraga (Télécom ParisTech);Geremy Heitz (Google);Kevin Murphy (Google);Fabian M. Suchanek (Télécom ParisTech);,"2110653650,2000496673,2167731548,2681494453","Open information extraction approaches have led to the creation of large knowledge bases from the Web. The problem with such methods is that their entities and relations are not canonicalized, leading to redundant and ambiguous facts. For example, they may store { Barack Obama, was born, Honolulu and { Obama, place of birth, Honolulu }. In this paper, we present an approach based on machine learning methods that can canonicalize such Open IE triples, by clustering synonymous names and phrases. We also provide a detailed discussion about the different signals, features and design choices that influence the quality of synonym resolution for noun phrases in Open IE KBs, thus shedding light on the middle ground between ""open"" and ""closed"" information extraction systems.",2014,Conference on Information and Knowledge Management,entity;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
ExpressQ: Identifying Keyword Context and Search Target in Relational Keyword Queries,Zhong Zeng (National University of Singapore);Zhifeng Bao (University of Tasmania);Thuy Ngoc Le (National University of Singapore);Mong Li Lee (National University of Singapore);Wang Tok Ling (National University of Singapore);,"2119459855,2098147036,2166534434,2159408573,2222315122","Keyword search in relational databases has gained popularity due to its ease of use. However, the challenge to return query answers that satisfy users' information need remains. Traditional keyword queries have limited expressive capability and are ambiguous. In this work, we extend keyword queries to enhance their expressive power and describe an semantic approach to process these queries. Our approach considers keywords that match meta-data such as the names of relations and attributes, and utilizes them to provide the context of subsequent keywords in the query. Based on the ORM schema graph which captures the semantics of objects and relationships in the database, we determine the objects and relationships referred to by the keywords in order to infer the search target of the query. Then, we construct a set of minimal connected graphs called query patterns, to represent user's possible search intentions. Finally, we translate the top-k ranked query patterns into SQL statements in order to retrieve information that the user is interested in. We develop a system prototype called ExpressQ to process the extended keyword queries. Experimental results show that our system is able to generate SQL statements that retrieve user intended information effectively.",2014,Conference on Information and Knowledge Management,sargable;keyword density;search oriented architecture;web search query;web query classification;conjunctive query;spatial query;query by example;query expansion;query optimization;query language;relational database;information retrieval;data mining;database;computer science;
Medical Semantic Similarity with a Neural Language Model,Lance De Vine (Queensland University of Technology);Guido Zuccon (Queensland University of Technology);Bevan Koopman (Commonwealth Scientific and Industrial Research Organisation);Laurianne Sitbon (Queensland University of Technology);Peter Bruza (Queensland University of Technology);,"2152283292,1551779932,2154133250,279890580,2101395307","Advances in neural network language models have demonstrated that these models can effectively learn representations of words meaning. In this paper, we explore a variation of neural language models that can learn on concepts taken from structured ontologies and extracted from free-text, rather than directly from terms in free-text. This model is employed for the task of measuring semantic similarity between medical concepts, a task that is central to a number of techniques in medical informatics and information retrieval. The model is built with two medical corpora (journal abstracts and patient records) and empirically validated on two ground-truth datasets of human-judged concept pairs assessed by medical professionals. Empirically, our approach correlates closely with expert human assessors (≈0.9) and outperforms a number of state-of-the-art benchmarks for medical semantic similarity. The demonstrated superiority of this model for providing an effective semantic similarity measure is promising in that this may translate into effectiveness gains for techniques in medical information retrieval and medical informatics (e.g., query expansion and literature-based discovery).",2014,Conference on Information and Knowledge Management,semantic computing;semantic similarity;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Identifying Time Intervals of Interest to Queries,Dhruv Gupta (Max Planck Society);Klaus Berberich (Max Planck Society);,"2492420228,2064029816","We investigate how time intervals of interest to a query can be identified automatically based on pseudo-relevant documents, taking into account both their publication dates and temporal expressions from their contents. Our approach is based on a generative model and is able to determine time intervals at different temporal granularities (e.g., day, month, or year). We evaluate our approach on twenty years' worth of newspaper articles from The New York Times using two novel testbeds consisting of temporally unambiguous and temporally ambiguous queries, respectively.",2014,Conference on Information and Knowledge Management,data science;information retrieval;data mining;database;computer science;
Time-sensitive Personalized Query Auto-Completion,Fei Cai (University of Amsterdam);Shangsong Liang (University of Amsterdam);Maarten de Rijke (University of Amsterdam);,"2224987176,2131113258,401833296","Query auto-completion (QAC) is a prominent feature of modern search engines. It is aimed at saving user's time and enhancing the search experience. Current QAC models mostly rank matching QAC candidates according to their past popularity, i.e., frequency. However, query popularity changes over time and may vary drastically across users. Hence, rankings of QAC candidates should be adjusted accordingly. In previous work time-sensitive QAC models and user-specific QAC models have been developed separately. Both types of QAC model lead to important improvements over models that are neither time-sensitive nor personalized. We propose a hybrid QAC model that considers both of these aspects: time-sensitivity and personalization. Using search logs, we return the top N QAC candidates by predicted popularity based on their recent trend and cyclic behavior. We use auto-correlation to detect query periodicity by long-term time-series analysis, and anticipate the query popularity trend based on observations within an optimal time window returned by a regression model. We rerank the returned top N candidates by integrating their similarities with a user's preceding queries (both in the current session and in previous sessions by the same user) on a character level to produce a final QAC list. Our experimental results on two real-world datasets show that our hybrid QAC model outperforms state-of-the-art time-sensitive QAC baseline, achieving total improvements of between 3% and 7% in terms of MRR.",2014,Conference on Information and Knowledge Management,personalization;world wide web;information retrieval;data mining;database;computer science;
Robust and Skew-resistant Parallel Joins in Shared-Nothing Systems,Long Cheng (Maynooth University);Spyros Kotoulas (IBM);Tomas E. Ward (Maynooth University);Georgios Theodoropoulos (Durham University);,"2143100546,2695581469,2162116221,2111858688","The performance of joins in parallel database management systems is critical for data intensive operations such as querying. Since data skew is common in many applications, poorly engineered join operations result in load imbalance and performance bottlenecks. State-of-the-art methods designed to handle this problem offer significant improvements over naive implementations. However, performance could be further improved by removing the dependency on global skew knowledge and broadcasting. In this paper, we propose PRPQ (partial redistribution & partial query), an efficient and robust join algorithm for processing large-scale joins over distributed systems. We present the detailed implementation and a quantitative evaluation of our method. The experimental results demonstrate that the proposed PRPQ algorithm is indeed robust and scalable under a wide range of skew conditions. Specifically, compared to the state-of-art PRPD method, we achieve 16% - 167% performance improvement and 24% - 54% less network communication under different join workloads.",2014,Conference on Information and Knowledge Management,performance;parallel computing;distributed computing;database;computer science;
Dual-Regularized One-Class Collaborative Filtering,Yuan Yao (Nanjing University);Hanghang Tong (Arizona State University);Guo Yan (Nanjing University);Feng Xu (Nanjing University);Xiang Zhang (Case Western Reserve University);Boleslaw K. Szymanski (Rensselaer Polytechnic Institute);Jian Lu (Nanjing University);,"2617797049,2667261544,2225364862,2720220320,2553248206,1974741261,2639471847","Collaborative filtering is a fundamental building block in many recommender systems. While most of the existing collaborative filtering methods focus on explicit, multi-class settings (e.g., 1-5 stars in movie recommendation), many real-world applications actually belong to the one-class setting where user feedback is implicitly expressed (e.g., views in news recommendation and video recommendation). The main challenges in such one-class setting include the ambiguity of the unobserved examples and the sparseness of existing positive examples. In this paper, we propose a dual-regularized model for one-class collaborative filtering. In particular, we address the ambiguity challenge by integrating two state-of-the-art one-class collaborative filtering methods to enjoy the best of both worlds. We tackle the sparseness challenge by exploiting the side information from both users and items. Moreover, we propose efficient algorithms to solve the proposed model. Extensive experimental evaluations on two real data sets demonstrate that our method achieves significant improvement over the state-of-the-art methods. Overall, the proposed method leads to 7.9% - 21.1% improvement over its best known competitors in terms of prediction accuracy, while enjoying the linear scalability.",2014,Conference on Information and Knowledge Management,collaborative filtering;recommender system;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Ranking-based Clustering on General Heterogeneous Information Networks by Network Projection,Chuan Shi (Beijing University of Posts and Telecommunications);Ran Wang (Beijing University of Posts and Telecommunications);Yitong Li (Beijing University of Posts and Telecommunications);Philip S. Yu (University of Illinois at Chicago);Bin Wu (Beijing University of Posts and Telecommunications);,"2703246814,2669616095,2104429188,2125104194,2464938123","Recently there is an increasing attention in heterogeneous information network analysis, which models networked data as networks including different types of objects and relations. Many data mining tasks have been exploited in heterogeneous networks, among which clustering and ranking are two basic tasks. These two tasks are usually done separately, whereas recent researches show that they can mutually enhance each other. Unfortunately, these works are limited to heterogeneous networks with special structures (e.g. bipartite or star-schema network ). However, real data are more complex and irregular, so it is desirable to design a general method to manage objects and relations in heterogeneous networks with arbitrary schema. In this paper, we study the ranking-based clustering problem in a general heterogeneous information network and propose a novel solution HeProjI. HeProjI projects a general heterogeneous network into a sequence of sub-networks and an information transfer mechanism is designed to keep the consistency among sub-networks. For each sub-network, a path-based random walk model is built to estimate the reachable probability of objects which can be used for clustering and ranking analysis. Iteratively analyzing each sub-network leads to effective ranking-based clustering. Extensive experiments on three real datasets illustrate that HeProjI can achieve better clustering and ranking performances compared to other well-established algorithms.",2014,Conference on Information and Knowledge Management,correlation clustering;ranking;fuzzy clustering;cluster analysis;theoretical computer science;data mining;database;machine learning;statistics;computer science;
Aligning Vertical Collection Relevance with User Intent,Ke Zhou (Yahoo!);Thomas Demeester (Ghent University);Dong Nguyen (University of Twente);Djoerd Hiemstra (University of Twente);Dolf Trieschnigg (University of Twente);,"2308026972,2253240189,2112184148,2125867230,2035566089","Selecting and aggregating different types of content from multiple vertical search engines is becoming popular in web search. The user vertical intent , the verticals the user expects to be relevant for a particular information need, might not correspond to the vertical collection relevance , the verticals containing the most relevant content. In this work we propose different approaches to define the set of relevant verticals based on document judgments. We correlate the collection-based relevant verticals obtained from these approaches to the real user vertical intent, and show that they can be aligned relatively well. The set of relevant verticals defined by those approaches could therefore serve as an approximate but reliable ground-truth for evaluating vertical selection, avoiding the need for collecting explicit user vertical intent, and vice versa.",2014,Conference on Information and Knowledge Management,evaluation;world wide web;information retrieval;data mining;computer science;
From Skimming to Reading: A Two-stage Examination Model for Web Search,Yiqun Liu (Tsinghua University);Chao Wang (Tsinghua University);Ke Zhou (Yahoo!);Jianyun Nie (Université de Montréal);Min Zhang (Tsinghua University);Shaoping Ma (Tsinghua University);,"2111097927,2679615606,2308026972,2620303841,2526008467,2109195263","User's examination of search results is a key concept involved in all the click models. However, most studies assumed that eye fixation means examination and no further study has been carried out to better understand user's examination behavior. In this study, we design an experimental search engine to collect both the user's feedback on their examinations and the eye-tracking/click-through data. To our surprise, a large proportion (45.8%) of the results fixated by users are not recognized as being ""read"". Looking into the tracking data, we found that before the user actually ""reads"" the result, there is often a ""skimming"" step in which the user quickly looks at the result without reading it. We thus propose a two-stage examination model which composes of a first ""from skimming to reading"" stage (Stage 1) and a second ""from reading to clicking"" stage (Stage 2). We found that the biases (e.g. position bias, domain bias, attractiveness bias) considered in many studies impact in different ways in Stage 1 and Stage 2, which suggests that users make judgments according to different signals in different stages. We also show that the two-stage examination behaviors can be predicted with mouse movement behavior, which can be collected at large scale. Relevance estimation with the two-stage examination model also outperforms that with a single-stage examination model. This study shows that the user's examination of search results is a complex cognitive process that needs to be investigated in greater depth and this may have a significant impact on Web search.",2014,Conference on Information and Knowledge Management,eye tracking;attention;world wide web;simulation;computer science;
The Effects of Vertical Rank and Border on Aggregated Search Coherence and Search Behavior,Jaime Arguello (University of North Carolina at Chapel Hill);Robert G. Capra (University of North Carolina at Chapel Hill);,"2128535409,1594411892","Aggregated search is the task of blending results from different search services, or verticals , into a set of web search results. Aggregated search coherence is the extent to which results from different sources focus on similar senses of an ambiguous or underspecified query. Prior work investigated the ""spill-over"" effect between a set of blended vertical results and the web results. These studies found that users are more likely to interact with the web results when the vertical results are more consistent with the user's intended query-sense. We extend this prior work by investigating three new research questions: (1) Does the spill-over effect generalize across different verticals? (2) Does the vertical rank moderate the level of spill-over? and (3) Does the presence of a border around the vertical results moderate the level of spill-over? We investigate four different verticals (images, news, shopping, and video) and measure spill-over using interaction measures associated with varying levels of engagement with the web results (bookmarks, clicks, scrolls, and mouseovers). Results from a large-scale crowdsourced study suggest that: (1) The spill-over effect generalizes across verticals, but is stronger for some verticals than others, (2) Vertical rank has a stronger moderating effect for verticals with a mid-level of spill-over, and (3) Including a border around the vertical results has a subtle moderating effect for those verticals with a low level of spill-over.",2014,Conference on Information and Knowledge Management,evaluation;multimedia;world wide web;
Fast Heuristics for Near-Optimal Task Allocation in Data Stream Processing over Clusters,Andreas Chatzistergiou (University of Edinburgh);Stratis D. Viglas (University of Edinburgh);,"572055359,335360864","We study provisioning and job reconfiguration techniques for adapting to execution environment changes when processing data streams on cluster-based deployments. By monitoring the performance of an executing job, we identify computation and communication bottlenecks. In such cases we reconfigure the job by reallocating its tasks to minimize the communication cost. Our work targets data-intensive applications where the inter-node transfer latency is significant. We aim to minimize the transfer latency while keeping the nodes below some computational load threshold. We propose a scalable centralized scheme that employs fast allocation heuristics. Our techniques are based on a general group-based job representation that is commonly found in many distributed data stream processing frameworks. Using this representation we devise linear-time task allocation algorithms that improve existing quadratic-time solutions in practical cases. We have implemented and evaluated our proposals using both synthetic and real-world scenarios. Our results show that our algorithms: (a) exhibit significant allocation throughput while producing near-optimal allocations, and (b) significantly improve existing task-level approaches.",2014,Conference on Information and Knowledge Management,in situ resource utilization;parallel computing;distributed computing;database;real time computing;computer science;
CARS2: Learning Context-aware Representations for Context-aware Recommendations,Yue Shi (Yahoo!);Alexandros Karatzoglou (Telefónica);Linas Baltrunas (Telefónica);Martha Larson (Delft University of Technology);Alan Hanjalic (Delft University of Technology);,"2714713288,14841688,86652860,2111809670,713704318","Rich contextual information is typically available in many recommendation domains allowing recommender systems to model the subtle effects of context on preferences. Most contextual models assume that the context shares the same latent space with the users and items. In this work we propose CARS2, a novel approach for learning context-aware representations for context-aware recommendations. We show that the context-aware representations can be learned using an appropriate model that aims to represent the type of interactions between context variables, users and items. We adapt the CARS2 algorithms to explicit feedback data by using a quadratic loss function for rating prediction, and to implicit feedback data by using a pairwise and a listwise ranking loss functions for top-N recommendations. By using stochastic gradient descent for parameter estimation we ensure scalability. Experimental evaluation shows that our CARS2 models achieve competitive recommendation performance, compared to several state-of-the-art approaches.",2014,Conference on Information and Knowledge Management,collaborative filtering;knowledge management;data mining;machine learning;computer science;
Optimizing Multi-Relational Factorization Models for Multiple Target Relations,Lucas Rego Drumond (University of Hildesheim);Ernesto Diaz-Aviles (IBM);Lars Schmidt-Thieme (University of Hildesheim);Wolfgang Nejdl (Leibniz University of Hanover);,"2103850662,181126789,78243962,2228144965","Multi-matrix factorization models provide a scalable and effective approach for multi-relational learning tasks such as link prediction, Linked Open Data (LOD) mining, recommender systems and social network analysis. Such models are learned by optimizing the sum of the losses on all relations in the data. Early models address the problem where there is only one target relation for which predictions should be made. More recent models address the multi-target variant of the problem and use the same set of parameters to make predictions for all target relations. In this paper, we argue that a model optimized for each target relation individually has better predictive performance than models optimized for a compromise on the performance on all target relations. We introduce specific parameters for each target but, instead of learning them independently from each other, we couple them through a set of shared auxiliary parameters, which has a regularizing effect on the target specific ones. Experiments on large Web datasets derived from DBpedia, Wikipedia and BlogCatalog show the performance improvement obtained by using target specific parameters and that our approach outperforms competitive state-of-the-art methods while being able to scale gracefully to big data.",2014,Conference on Information and Knowledge Management,statistical inference;statistical relational learning;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Modelling and Detecting Changes in User Satisfaction,Julia Kiseleva (Eindhoven University of Technology);Eric Crestan (Microsoft);Riccardo Brigo (Microsoft);Roland Dittel (Microsoft);,"2165175320,2224965582,2229288943,2229976585","Informational needs behind queries, that people issue to search engines, are inherently sensitive to external factors such as breaking news, new models of devices, or seasonal changes as ' black Friday '. Mostly these changes happen suddenly and it is natural to suppose that they may cause a shift in user satisfaction with presented old search results and push users to reformulate their queries. For instance, if users issued the query ' CIKM conference ' in 2013 they were satisfied with results referring to the page cikm2013.org and this page gets a majority of clicks. However, the confernce site has been changed and the same query issued in 2014 should be linked to the different page cikm2014.fudan.edu.cn. If the link to the fresh page is not among the retrieved results then users will reformulate the query to find desired information. In this paper, we examine how to detect changes in user satisfaction if some events affect user information goals but search results remained the same. We formulate a problem using concept drift detection techniques. The proposed method works in an unsupervised manner, we do not rely on any labelling. We report results of a large scale evaluation over real user interactions, that are collected by a commercial search engine within six months. The final datasets consist of more than sixty millions log entries. The results of our experiments demonstrate that by using our method we can accurately detect changes in user behavior. The detected drifts can be used to enhance query auto-completion, user satisfaction metrics, and recency ranking.",2014,Conference on Information and Knowledge Management,ranking;computer user satisfaction;web query classification;concept drift;query expansion;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Structure Learning via Parameter Learning,William Yang Wang (Carnegie Mellon University);Kathryn Mazaitis (Carnegie Mellon University);William W. Cohen (Carnegie Mellon University);,"2110566271,2040177228,2115385359","A key challenge in information and knowledge management is to automatically discover the underlying structures and patterns from large collections of extracted information. This paper presents a novel structure-learning method for a new, scalable probabilistic logic called ProPPR. Our approach builds on the recent success of meta-interpretive learning methods in Inductive Logic Programming (ILP), and we further extends it to a framework that enables robust and efficient structure learning of logic programs on graphs: using an abductive second-order probabilistic logic, we show how first-order theories can be automatically generated via parameter learning. To learn better theories, we then propose an iterated structural gradient approach that incrementally refines the hypothesized space of learned first-order structures. In experiments, we show that the proposed method further improves the results, outperforming competitive baselines such as Markov Logic Networks (MLNs) and FOIL on multiple datasets with various settings; and that the proposed approach can learn structures in a large knowledge base in a tractable fashion.",2014,Conference on Information and Knowledge Management,probabilistic ctl;probabilistic logic;statistical relational learning;theoretical computer science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Within-Network Classification Using Radius-Constrained Neighborhood Patterns,Jialong Han (Renmin University of China);Ji-Rong Wen (Renmin University of China);Jian Pei (Simon Fraser University);,"2222918829,2593770520,2126330539","Within-Network Classification (WNC) techniques are designed for applications where objects to be classified and those with known labels are interlinked. For WNC tasks like web page classification, the homophily principle succeeds by assuming that linked objects, represented as adjacent vertices in a network, are likely to have the same labels. However, in other tasks like chemical structure completion, recent works suggest that the label of a vertex should be related to the local structure it resides in, rather than equated with those of its neighbors. These works also propose structure-aware vertex features or methods to deal with such an issue. In this paper, we demonstrate that frequent neighborhood patterns , originally studied in the pattern mining literature, serve as a strong class of structure-aware features and provide satisfactory effectiveness in WNC. In addition, we identify the problem that the neighborhood pattern miner indiscriminately mines patterns of all radiuses, while heuristics and experiments both indicate that patterns with a large radius take much time only to bring negligible effectiveness gains. We develop a specially designed algorithm capable of working under radius threshold constraints, by which patterns with a large radius are not mined at all. Experiments suggest that our algorithm helps with the trade-off between efficiency and effectiveness in WNC tasks.",2014,Conference on Information and Knowledge Management,data mining;artificial intelligence;machine learning;computer science;
Improving Term Weighting for Community Question Answering Search Using Syntactic Analysis,David Carmel (Yahoo!);Avihai Mejer (Yahoo!);Yuval Pinter (Yahoo!);Idan Szpektor (Yahoo!);,"2088014474,2050677669,2222817613,665682607","Query term weighting is a fundamental task in information retrieval and most popular term weighting schemes are primarily based on statistical analysis of term occurrences within the document collection. In this work we study how term weighting may benefit from syntactic analysis of the corpus. Focusing on community question answering (CQA) sites, we take into account the syntactic function of the terms within CQA texts as an important factor affecting their relative importance for retrieval. We analyze a large log of web queries that landed on Yahoo Answers site, showing a strong deviation between the tendencies of different document words to appear in a landing (click-through) query given their syntactic function. To this end, we propose a novel term weighting method that makes use of the syntactic information available for each query term occurrence in the document, on top of term occurrence statistics. The relative importance of each feature is learned via a learning to rank algorithm that utilizes a click-through query log. We examine the new weighting scheme using manual evaluation based on editorial data and using automatic evaluation over the query log. Our experimental results show consistent improvement in retrieval when syntactic information is taken into account.",2014,Conference on Information and Knowledge Management,dependency grammar;learning to rank;natural language processing;information retrieval;data mining;database;pattern recognition;machine learning;computer science;
Understanding Within-Content Engagement through Pattern Analysis of Mouse Gestures,Ioannis Arapakis (Yahoo!);Mounia Lalmas (Yahoo!);George Valkanas (National and Kapodistrian University of Athens);,"2091815359,46148421,2032326962","The availability of large volumes of interaction data and scalable data mining techniques have made possible to study the online behaviour for millions of Web users. Part of the efforts have focused on understanding how users interact and engage with web content. However, the measurement of within-content engagement remains a difficult and unsolved task. This is because of the lack of standardised, well-validated methods for measuring engagement, especially in an online context. To address this gap, we perform a controlled user study where we observe how users respond to online news in the presence or lack of interest. We collect mouse tracking data, which are known to correlate with visual attention, and examine how cursor behaviour can inform user engagement measures. The proposed method does not use any pre-determined concepts to characterise the cursor patterns. We, rather, follow an unsupervised approach and use a large set of features engineered from our data to extract the cursor patterns. Our findings support the connection between gaze and cursor behaviour but also, and more importantly, reveal other dependencies, such as the correlation between cursor activity and experienced affect. Finally, we demonstrate the value of our method by predicting the outcome of online news reading experiences.",2014,Conference on Information and Knowledge Management,prediction;multimedia;world wide web;data mining;statistics;computer science;
CLIR for Informal Content in Arabic Forum Posts,"Mossaab Bagdouri (University of Maryland, College Park);Douglas W. Oard (University of Maryland, College Park);Vittorio Castelli (IBM);","2046366089,7916806,2132335929","The field of Cross-Language Information Retrieval (CLIR) addresses the problem of finding documents in some language that are relevant to a question posed in a different language. Retrieving answers to questions written using formal vocabulary from collections of informal documents, as with many types of social media, is a largely unexplored subfield of CLIR. Because formal and informal content are often intermingled, CLIR systems that excel at finding formal content may tend to select formal over informal content. To measure this effect, a test collection annotated for both relevance and informality is needed. This paper describes the development of a small test collection for this task, with questions posed in formal English and the documents consisting of intermixed formal and informal Arabic. Experiments with this collection show that dialect classification can help to recognize informal content, thus improving precision. At the same time, the results indicate that neither dialect-tuned morphological analysis nor a lightweight CLIR approach that minimizes propagation of translation errors yet yield a reliable improvement in recall for informal content when compared to a straightforward document translation architecture.",2014,Conference on Information and Knowledge Management,social media;evaluation;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
An Appliance-Driven Approach to Detection of Corrupted Load Curve Data,Guoming Tang (University of Victoria);Kui Wu (University of Victoria);Jian Pei (Simon Fraser University);Jiuyang Tang (National University of Defense Technology);Jingsheng Lei (Shanghai University of Electric Power);,"2128384849,2149089207,2126330539,2130263585,2144575389","Load curve data in power systems refers to users' electrical energy consumption data periodically collected with meters. It has become one of the most important assets for modern power systems. Many operational decisions are made based on the information discovered in the data. Load curve data, however, usually suffers from corruptions caused by various factors, such as data transmission errors or malfunctioning meters. To solve the problem, tremendous research efforts have been made on load curve data cleansing. Most existing approaches apply outlier detection methods from the supply side ( i.e. , electricity service providers), which may only have aggregated load data. In this paper, we propose to seek aid from the demand side ( i.e. , electricity service users). With the help of readily available knowledge on consumers' appliances, we present an appliance-driven approach to load curve data cleansing. This approach utilizes data generation rules and a Sequential Local Optimization Algorithm (SLOA) to solve the Corrupted Data Identification Problem (CDIP). We evaluate the performance of SLOA with real-world trace data and synthetic data. The results indicate that, comparing to existing load data cleansing methods, such as B-spline smoothing, our approach has an overall better performance and can effectively identify consecutive corrupted data. Experimental results also show that our method is robust in various tests.",2014,Conference on Information and Knowledge Management,data analysis;world wide web;computer security;data mining;database;real time computing;statistics;computer science;
Focused Crawling for Structured Data,Robert Meusel (University of Mannheim);Peter Mika (Yahoo!);Roi Blanco (Yahoo!);,"1937779059,2251781635,2128286424","The Web is rapidly transforming from a pure document collection to the largest connected public data space. Semantic annotations of web pages make it notably easier to extract and reuse data and are increasingly used by both search engines and social media sites to provide better search experiences through rich snippets, faceted search, task completion, etc. In our work, we study the novel problem of crawling structured data embedded inside HTML pages. We describe Anthelion , the first focused crawler addressing this task. We propose new methods of focused crawling specifically designed for collecting data-rich pages with greater efficiency. In particular, we propose a novel combination of online learning and bandit-based explore/exploit approaches to predict data-rich web pages based on the context of the page as well as using feedback from the extraction of metadata from previously seen pages. We show that these techniques significantly outperform state-of-the-art approaches for focused crawling, measured as the ratio of relevant pages and non-relevant pages collected within a given budget.",2014,Conference on Information and Knowledge Management,distributed web crawling;microdata;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
SocialTransfer: Transferring Social Knowledge for Cold-Start Cowdsourcing,Zhou Zhao (Hong Kong University of Science and Technology);James Cheng (The Chinese University of Hong Kong);Furu Wei (Microsoft);Ming Zhou (Microsoft);Wilfred Siu Hung Ng (Hong Kong University of Science and Technology);Yingjun Wu (National University of Singapore);,"2118299058,2304873892,2171151462,2143584880,2170178419,2667922236","An essential component of building a successful crowdsourcing market is effective task matching , which matches a given task to the right crowdworkers. In order to provide high- quality task matching, crowdsourcing systems rely on past task-solving activities of crowdworkers. However, the average number of past activities of crowdworkers in most crowd- sourcing systems is very small. We call the workers who have only solved a small number of tasks cold-start crowdworkers . We observe that most of the workers in crowdsourcing systems are cold-start crowdworkers, and crowdsourcing systems actually enjoy great benefits from cold-start crowd-workers. However, the problem of task matching with the presence of many cold-start crowdworkers has not been well studied. We propose a new approach to address this issue. Our main idea, motivated by the prevalence of online social networks, is to transfer the knowledge about crowdworkers in their social networks to crowdsourcing systems for task matching. We propose a SocialTransfer model for cold-start crowdsourcing, which not only infers the expertise of warm- start crowdworkers from their past activities, but also transfers the expertise knowledge to cold-start crowdworkers via social connections. We evaluate the SocialTransfer model on the well-known crowdsourcing system Quora, using knowledge from the popular social network Twitter. Experimental results show that, by transferring social knowledge, our method achieves significant improvements over the state-of-the-art methods.",2014,Conference on Information and Knowledge Management,crowdsourcing;social network;data science;knowledge management;world wide web;data mining;artificial intelligence;machine learning;computer science;
Identification of Answer-Seeking Questions in Arabic Microblogs,Maram Hasanain (Qatar University);Tamer Elsayed (Qatar University);Walid Magdy (Qatar Computing Research Institute);,"1986281005,2688113365,2662772209","Over the past years, Twitter has earned a growing reputation as a hub for communication, and events advertisement and tracking. However, several recent research studies have shown that Twitter users (and microblogging platforms' users in general) are increasingly posting microblogs containing questions seeking answers from their readers. To help those users answer or route their questions, the problem of question identification in tweets has been studied over English tweets; up to our knowledge, no study has attempted it over Arabic (not to mention dialectal Arabic) tweets. In this paper, we tackle the problem of identifying answer-seeking questions in different dialects over a large collection of Arabic tweets. Our approach is 2-stage. We first used a rule-based filter to extract tweets with interrogative questions. We then leverage a binary classifier (trained using a carefully-developed set of features) to detect tweets with answer-seeking questions. In evaluating the classifier, we used a set of randomly-sampled dialectal Arabic tweets that were labeled using crowdsourcing. Our approach achieved a relatively-good performance as a first study of that problem on the Arabic domain, exhibiting 64% recall with 80% precision in identifying tweets with answer-seeking questions.",2014,Conference on Information and Knowledge Management,crowdsourcing;arabic;natural language processing;world wide web;speech recognition;computer science;
Designing Test Collections for Comparing Many Systems,Tetsuya Sakai (Waseda University);,2655523027,"A researcher decides to build a test collection for comparing her new information retrieval (IR) systems with several state-of-the-art baselines. She wants to know the number of topics ( n ) she needs to create in advance, so that she can start looking for (say) a query log large enough for sampling n good topics, and estimating the relevance assessment cost. We provide practical solutions to researchers like her using power analysis and sample size design techniques, and demonstrate its usefulness for several IR tasks and evaluation measures. We consider not only the paired t -test but also one-way analysis of variance (ANOVA) for significance testing to accommodate comparison of m (≥ 2) systems under a given set of statistical requirements (α: the Type I error rate, s: the Type II error rate, and minD : the minimum detectable difference between the best and the worst systems). Using our simple Excel tools and some pooled variance estimates from past data, researchers can design statistically well-designed test collections. We demonstrate that, as different evaluation measures have different variances across topics, they inevitably require different topic set sizes. This suggests that the evaluation measures should be chosen at the test collection design phase. Moreover, through a pool depth reduction experiment with past data, we show how the relevance assessment cost can be reduced dramatically while freezing the set of statistical requirements. Based on the cost analysis and the available budget, researchers can determine the right balance between n and the pool depth pd . Our techniques and tools are applicable to test collections for non-IR tasks as well.",2014,Conference on Information and Knowledge Management,effect size;power;sample size determination;evaluation;statistical significance;data mining;statistics;computer science;
Robust Principal Component Analysis with Missing Data,Fanhua Shang (The Chinese University of Hong Kong);Yuanyuan Liu (The Chinese University of Hong Kong);James Cheng (The Chinese University of Hong Kong);Hong Cheng (The Chinese University of Hong Kong);,"1972696148,2126680102,2304873892,2161754280","Recovering matrices from incomplete and corrupted observations is a fundamental problem with many applications in various areas of science and engineering. In theory, under certain conditions, this problem can be solved via a natural convex relaxation. However, all current provable algorithms suffer from superlinear per-iteration cost, which severely limits their applicability to large scale problems. In this paper, we propose a robust principal component analysis (RPCA) plus matrix completion framework to recover low-rank and sparse matrices from missing and grossly corrupted observations. Under the unified framework, we first present a convex robust matrix completion model to replace the linear projection operator constraint by a simple equality one. To further improve the efficiency of our convex model, we also develop a scalable structured factorization model, which can yield an orthogonal dictionary and a robust data representation simultaneously. Then, we develop two alternating direction augmented Lagrangian (ADAL) algorithms to efficiently solve the proposed problems. Finally, we discuss the convergence analysis of our algorithms. Experimental results verified both the efficiency and effectiveness of our methods compared with the state-of-the-art algorithms.",2014,Conference on Information and Knowledge Management,machine learning;mathematical optimization;statistics;
A Retrievability Analysis: Exploring the Relationship Between Retrieval Bias and Retrieval Performance,Colin Wilkie (University of Glasgow);Leif Azzopardi (University of Glasgow);,"2098928293,2163026013","Retrievability provides an alternative way to assess an Information Retrieval (IR) system by measuring how easily documents can be retrieved. Retrievability can also be used to determine the level of retrieval bias a system exerts upon a collection of documents. It has been hypothesised that reducing the retrieval bias will lead to improved performance. To date, it has been shown that this hypothesis does not appear to hold on standard retrieval performance measures (MAP and P@10) when exploring the parameter space of a given retrieval model. However, the evidence is limited and confined to only a few models, collections and measures. In this paper, we perform a comprehensive empirical evaluation analysing the relationship between retrieval bias and retrieval performance using several well known retrieval models, five large TREC test collections and ten performance measures (including the recently proposed PRES, Time Biased Gain (TBG) and U-Measure). For traditional relevance based measures (MAP, P@10, MRR, Recall, etc) the correlation between retrieval bias and performance is moderate. However, for TBG and U-Measure, we find that there is strong and significant negative correlations between retrieval bias and performance (i.e as bias drops, performance increases). These findings suggest that for these more sophisticated, user oriented measures the retrievability bias hypothesis tends to hold. The implication is that for these measures, systems can then be tuned using retrieval bias, without recourse to relevance judgements.",2014,Conference on Information and Knowledge Management,term discrimination;retrievability;evaluation;world wide web;information retrieval;data mining;computer science;
Learning a Linear Influence Model from Transient Opinion Dynamics,Abir De (Indian Institute of Technology Kharagpur);Sourangshu Bhattacharya (Indian Institute of Technology Kharagpur);Parantapa Bhattacharya (Indian Institute of Technology Kharagpur);Niloy Ganguly (Indian Institute of Technology Kharagpur);Soumen Chakrabarti (Indian Institute of Technology Bombay);,"2100683166,2151480652,2118391709,2097625090,2103349674","Many social networks are characterized by actors (nodes) holding quantitative opinions about movies, songs, sports, people, colleges, politicians, and so on. These opinions are influenced by network neighbors. Many models have been proposed for such opinion dynamics, but they have some limitations. Most consider the strength of edge influence as fixed. Some model a discrete decision or action on part of each actor, and an edge as causing an ``infection'' (that is often permanent or self-resolving). Others model edge influence as a stochastic matrix to reuse the mathematics of eigensystems. Actors' opinions are usually observed globally and synchronously. Analysis usually skirts transient effects and focuses on steady-state behavior. There is very little direct experimental validation of estimated influence models. Here we initiate an investigation into new models that seek to remove these limitations. Our main goal is to estimate, not assume, edge influence strengths from an observed series of opinion values at nodes. We adopt a linear (but not stochastic) influence model. We make no assumptions about system stability or convergence. Further, actors' opinions may be observed in an asynchronous and incomplete fashion, after missing several time steps when an actor changed its opinion based on neighbors' influence. We present novel algorithms to estimate edge influence strengths while tackling these aggressively realistic assumptions. Experiments with Reddit, Twitter, and three social games we conducted on volunteers establish the promise of our algorithms. Our opinion estimation errors are dramatically smaller than strong baselines like the DeGroot, flocking, voter, and biased voter models. Our experiments also lend qualitative insights into asynchronous opinion updates and aggregation.",2014,Conference on Information and Knowledge Management,social network;world wide web;data mining;artificial intelligence;machine learning;simulation;statistics;
Search Result Diversification via Filling Up Multiple Knapsacks,Hai-Tao Yu (University of Tokushima);Fuji Ren (University of Tokushima);,"2169908130,2131525672","Result diversification is a topic of great value for enhancing user experience in many fields, such as web search and recommender systems. Many existing methods generate a diversified result in a sequential manner, but they work well only if the preceding choices are optimal or close to the optimal solution. Moreover, a manually tuned parameter (say,λ) is often required to trade off relevance and diversity . This makes it difficult to know whether the failures are caused by the optimization criterion or the setting of λ. In context of web search, we formulate the result diversification task as a 0-1 multiple subtopic knapsack problem (MSKP), where a subset of documents are optimally chosen like filling up multiple subtopic knapsacks. This formulation yields no trade-off parameters to be specified beforehand. Solving the 0-1 MSKP is NP-hard, we treat the optimization of 0-1 MSKP using a graphical model over latent binary variables as a maximum posterior inference problem, and tackle it with the max-sum belief propagation algorithm. To validate the effectiveness and efficiency of the proposed 0-1 MSKP model, we conduct a series of experiments on two TREC diversity collections. The experimental results show that the proposed model outperforms several state-of-the-art methods significantly, not only in terms of standard diversity metrics (α-nDCG, nERRIA and subtopic recall), but also in terms of efficiency.",2014,Conference on Information and Knowledge Management,diversification;knapsack problem;message passing;world wide web;data mining;database;artificial intelligence;machine learning;mathematical optimization;statistics;computer science;
Multi-task Multi-view Learning for Heterogeneous Tasks,Xin Jin (Chinese Academy of Sciences);Fuzhen Zhuang (Chinese Academy of Sciences);Hui Xiong (Rutgers University);Changying Du (Chinese Academy of Sciences);Ping Luo (Chinese Academy of Sciences);Qing He (Chinese Academy of Sciences);,"2695402291,2050314250,2153710278,2116524837,2291210646,2167314737","Multi-task multi-view learning deals with the learning scenarios where multiple tasks are associated with each other through multiple shared feature views. All previous works for this problem assume that the tasks use the same set of class labels. However, in real world there exist quite a few applications where the tasks with several views correspond to different set of class labels. This new learning scenario is called Multi-task Multi-view Learning for Heterogeneous Tasks in this study. Then, we propose a Multi-tAsk MUlti-view Discriminant Analysis (MAMUDA) method to solve this problem. Specifically, this method collaboratively learns the feature transformations for different views in different tasks by exploring the shared task-specific and problem intrinsic structures. Additionally, MAMUDA method is convenient to solve the multi-class classification problems. Finally, the experiments on two real-world problems demonstrate the effectiveness of MAMUDA for heterogeneous tasks.",2014,Conference on Information and Knowledge Management,multi task learning;multiclass classification;semi supervised learning;linear discriminant analysis;data mining;artificial intelligence;machine learning;computer science;
What a Nasty Day: Exploring Mood-Weather Relationship from Twitter,Jiwei Li (Stanford University);Xun Wang (Peking University);Eduard H. Hovy (Carnegie Mellon University);,"2294693014,2652528489,2706585063","While it has long been believed in psychology that weather somehow influences human's mood, the debates have been going on for decades about how they are correlated. In this paper, we try to study this long-lasting topic by harnessing a new source of data compared from traditional psychological researches: Twitter. We analyze 2 years' twitter data collected by twitter API which amounts to 10% of all postings and try to reveal the correlations between multiple dimensional structure of human mood with meteorological effects. Some of our findings confirm existing hypotheses, while others contradict them. We are hopeful that our approach, along with the new data source, can shed on the long-going debates on weather-mood correlation.",2014,Conference on Information and Knowledge Management,climate;internet privacy;social psychology;world wide web;
Succinct Queries for Linking and Tracking News in Social Media,Luchen Tan (University of Waterloo);Charles L.A. Clarke (University of Waterloo);,"2095969387,2098618034","Given a current news article, we wish to create a succinct query reflecting its content, which may be used to follow the news story over a period of days, or even weeks. In part, the need for succinct queries is occasioned by limitations of commercial social media search engines, which can perform poorly with longer queries. We start by applying established key phrase extraction methods to the article, creating an initial set of candidate query terms. We then generate a series of probe queries, each a subset of these candidate terms, which we apply to search current social media streams. By analyzing the results of these probes, we rank and trim the candidate set to create a succinct query. We present an experimental study of this method based on a collection of news articles taken from March-April 2014, with the resulting succinct queries used to re-query social media one week later.",2014,Conference on Information and Knowledge Management,news;social media;world wide web;information retrieval;data mining;database;computer science;
Similarity Search using Concept Graphs,Rakesh Agrawal (Microsoft);Sreenivas Gollapudi (Microsoft);Anitha Kannan (Microsoft);Krishnaram Kenthapadi (Microsoft);,"2537924216,2023254819,2146153601,2088122068","The rapid proliferation of hand-held devices has led to the development of rich, interactive and immersive applications, such as e-readers for electronic books. These applications motivate retrieval systems that can implicitly satisfy any information need of the reader by exploiting the context of the user's interactions. Such retrieval systems differ from traditional search engines in that the queries constructed using the context are typically complex objects (including the document and its structure). In this paper, we develop an efficient retrieval system, only assuming an oracle access to a traditional search engine that admits 'succinct' keyword queries for retrieving objects of a desired media type. As part of query generation, we first map the complex query object to a concept graph and then use the concepts along with their relationships in the graph to compute a small set of keyword queries to the search engine. Next, as part of the result generation, we aggregate the results of these queries to identify relevant web content of the desired type, thereby eliminating the need for explicitly computing similarity between the query object and all web content. We present a theoretical analysis of our approach and carry out a detailed empirical evaluation to show the practicality of the approach for the task of augmenting electronic documents with high quality videos from the web.",2014,Conference on Information and Knowledge Management,web search query;web query classification;query expansion;nearest neighbor search;search engine;natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
Active Learning based Survival Regression for Censored Data,Bhanukiran Vinzamuri (Wayne State University);Yan Li (Wayne State University);Chandan K. Reddy (Wayne State University);,"23137369,2607418379,2100435683","Time-to-event outcomes based data can be modelled using survival regression methods which can predict these outcomes in different censored data applications in diverse fields such as engineering, economics and healthcare. Predictive models are built by inferring from the censored variable in time-to-event data, which differentiates them from other regression methods. Censoring is represented as a binary indicator variable and machine learning methods have been tuned to account for the censored attribute. Active learning from censored data using survival regression methods can make the model query a domain expert for the time-to-event label of the sampled instances. This offers higher advantages in the healthcare domain where a domain expert can interactively refine the model with his feedback. With this motivation, we address this problem by providing an active learning based survival model which uses a novel model discriminative gradient based sampling scheme. We evaluate this framework on electronic health records (EHR), publicly available survival and synthetic censored datasets of varying diversity. Experimental evaluation against state of the art survival regression methods indicates the higher discriminative ability of the proposed approach. We also present the sampling results for the proposed approach in an active learning setting which indicate better learning rates in comparison to other sampling strategies.",2014,Conference on Information and Knowledge Management,active learning;proportional hazards model;survival analysis;data mining;machine learning;statistics;computer science;
Narrow or Broad?: Estimating Subjective Specificity in Exploratory Search,Kumaripaba Athukorala (Helsinki Institute for Information Technology);Antti Oulasvirta (Max Planck Society);Dorota Głowacka (Helsinki Institute for Information Technology);Jilles Vreeken (Max Planck Society);Giulio Jacucci (Helsinki Institute for Information Technology);,"1793834987,1968824034,2042460623,1971070670,1878836720","Supporting exploratory search is a very challenging problem, not least because of the dynamic nature of the exercise: both the knowledge and interests of the user are subject to constant change. Moreover, whether the results for a query are informative is strongly subjective. What is informative to one user, is too specific for the other; specificity differs between users depending on their intent and accumulated knowledge about the domain. We propose a formal model - motivated by Information Foraging Theory - for predicting the subjective specificity of search results based on simple observables such as result-clicks. Through two studies including both controlled and free-form exploratory search we show our model allows us to differentiate between levels of subjective result specificity with regard to the current information need of the user.",2014,Conference on Information and Knowledge Management,data mining;
EgoCentric: Ego Networks for Knowledge-based Short Text Classification,William Lucia (University of Insubria);Elena Ferrari (University of Insubria);,"2232469801,2170777979","Classification of short text messages is becoming more and more relevant in these years, where billion of users use online social networks to communicate with other people. Understanding message content can have a huge impact on many data analysis processes, ranging from the study of online social behavior to targeted advertisement, to security and privacy purposes. In this paper, we propose a new unsupervised knowledge-based classifier for short text messages, where each category is represented by an ego-network. A short text is classified into a category depending on how far its words are from the ego of that category. We show how this technique can be used both in single label and in multi-label classification, and how it outperforms the state of the art for short text messages classification.",2014,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;artificial intelligence;machine learning;computer science;
Improving Co-Cluster Quality with Application to Product Recommendations,Michail Vlachos (IBM);Francesco Fusco (IBM);Charalambos Mavroforakis (Boston University);Anastasios Kyrillidis (École Polytechnique Fédérale de Lausanne);Vassilios G. Vassiliadis (IBM);,"2146138755,2634347212,2231983270,2288456018,2229061546","Businesses store an ever increasing amount of historical customer sales data. Given the availability of such information, it is advantageous to analyze past sales, both for revealing dominant buying patterns, and for providing more targeted recommendations to clients. In this context, co-clustering has proved to be an important data-modeling primitive for revealing latent connections between two sets of entities, such as customers and products. In this work, we introduce a new algorithm for co-clustering that is both scalable and highly resilient to noise. Our method is inspired by k -Means and agglomerative hierarchical clustering approaches: ( i ) first it searches for elementary co-clustering structures and ( ii ) then combines them into a better, more compact, solution. The algorithm is flexible as it does not require an explicit number of co-clusters as input, and is directly applicable on large data graphs. We apply our methodology on real sales data to analyze and visualize the connections between clients and products. We showcase a real deployment of the system, and how it has been used for driving a recommendation engine. Finally, we demonstrate that the new methodology can discover co-clusters of better quality and relevance than state-of-the-art co-clustering techniques.",2014,Conference on Information and Knowledge Management,biclustering;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
TwinChat: A Twitter and Web User Interactive Chat System,Yuanyuan Wang (Kyoto Sangyo University);Gouki Yasui (Kyoto Sangyo University);Yuji Hosokawa (Kyoto Sangyo University);Yukiko Kawai (Kyoto Sangyo University);Toyokazu Akiyama (Kyoto Sangyo University);Kazutoshi Sumiya (University of Hyogo);,"2523798760,2229548757,2231628542,2116005948,2190548400,2140833164","This paper presents TWinChat , a Twitter and Web user interactive chat system to support simultaneous communication between microbloggers and Web users in real-time through both the contents of microblogs and Web pages. TWinChat provides a question answering interface attached to Web pages, which allows Web users to chat with Twitter users in real-time while presenting tweets that are associated with Web pages, i.e., simultaneous cross-media communication. In order to map heterogeneous media, the system extracts relationship between tweets and Web pages by generating queries based on location names. Thus, our system can effectively present messages from Web users to help Twitter users immediately obtain useful information or knowledge, and it also can effectively present tweets from the Twitter users to help the Web users easily grasp the current situation in real-time.",2014,Conference on Information and Knowledge Management,web 2 0;social semantic web;web analytics;static web page;data web;site map;web mapping;web application security;web development;web design;web navigation;web server;web service;web page;internet privacy;multimedia;world wide web;computer science;
Extending Faceted Search to the General Web,Weize Kong (University of Massachusetts Amherst);James Allan (University of Massachusetts Amherst);,"2167771460,2097030689","Faceted search helps users by offering drill-down options as a complement to the keyword input box, and it has been used successfully for many vertical applications, including e-commerce and digital libraries. However, this idea is not well explored for general web search, even though it holds great potential for assisting multi-faceted queries and exploratory search. In this paper, we explore this potential by extending faceted search into the open-domain web setting, which we call Faceted Web Search. To tackle the heterogeneous nature of the web, we propose to use query-dependent automatic facet generation, which generates facets for a query instead of the entire corpus. To incorporate user feedback on these query facets into document ranking, we investigate both Boolean filtering and soft ranking models. We evaluate Faceted Web Search systems by their utility in assisting users to clarify search intent and find subtopic information. We describe how to build reusable test collections for such tasks, and propose an evaluation method that considers both gain and cost for users. Our experiments testify to the potential of Faceted Web Search, and show Boolean filtering feedback models, which are widely used in conventional faceted search, are less effective than soft ranking models.",2014,Conference on Information and Knowledge Management,web search query;web query classification;search engine;semantic search;world wide web;information retrieval;data mining;database;computer science;
Efficient Subgraph Skyline Search Over Large Graphs,Weiguo Zheng (Peking University);Lei Zou (Peking University);Xiang Lian (University of Texas–Pan American);Liang Hong (Wuhan University);Dongyan Zhao (Peking University);,"2110660074,2334791189,2081778406,2614500932,2156639542","Subgraph search is very useful in many real-world applications. However, users may be overwhelmed by the masses of matches. In this paper, we propose subgraph skyline search problem, denoted as S 3 , to support more complicated analysis over graph data. Specifically, given a large graph G and a query graph q , we want to find all the subgraphs g in G , such that g is graph isomorphic to q and not dominated by any other subgraphs. In order to improve the efficiency, we devise a hybrid feature encoding incorporating both structural and numeric features. Moreover, we present some optimizations based on partitioning strategy. We also propose a skylayer index to facilitate the dynamic subgraph skyline computation. Extensive experiments over real dataset confirm the effectiveness and efficiency of our algorithm.",2014,Conference on Information and Knowledge Management,degeneracy;factor critical graph;distance hereditary graph;induced subgraph isomorphism problem;forbidden graph characterization;graph power;graph factorization;universal graph;claw free graph;subgraph isomorphism problem;line graph;data mining;pattern recognition;machine learning;
Distributed Graph Summarization,Xingjie Liu (Pennsylvania State University);Yuanyuan Tian (IBM);Qi He (LinkedIn);Wang-Chien Lee (Pennsylvania State University);John McPherson (IBM);,"2141742294,2129760627,2657625239,2143778659,2106934193","Graph has been a ubiquitous and essential data representation to model real world objects and their relationships. Today, large amounts of graph data have been generated by various applications. Graph summarization techniques are crucial in uncovering useful insights about the patterns hidden in the underlying data. However, all existing works in graph summarization are single-process solutions, and as a result cannot scale to large graphs. In this paper, we introduce three distributed graph summarization algorithms to address this problem. Experimental results show that the proposed algorithms can produce good quality summaries and scale well with increasing data sizes. To the best of our knowledge, this is the first work to study distributed graph summarization methods.",2014,Conference on Information and Knowledge Management,graph database;graph;graph rewriting;text graph;automatic summarization;theoretical computer science;information retrieval;data mining;database;machine learning;computer science;
Understanding the Sparsity: Augmented Matrix Factorization with Sampled Constraints on Unobservables,"Yongfeng Zhang (Tsinghua University);Min Zhang (Tsinghua University);Yi Zhang (University of California, Santa Cruz);Yiqun Liu (Tsinghua University);Shaoping Ma (Tsinghua University);","2097552573,2526008467,2671671868,2111097927,2109195263","An important problem of matrix completion/approximation based on Matrix Factorization (MF) algorithms is the existence of multiple global optima ; this problem is especially serious when the matrix is sparse , which is common in real-world applications such as personalized recommender systems. In this work, we clarify data sparsity by bounding the solution space of MF algorithms. We present the conditions that an MF algorithm should satisfy for reliable completion of the unobservables, and we further propose to augment current MF algorithms with extra constraints constructed by compressive sampling on the unobserved values, which is well-motivated by the theoretical analysis. Model learning and optimal solution searching is conducted in a properly reduced solution space to achieve more accurate and efficient rating prediction performances. We implemented the proposed algorithms in the Map-Reduce framework, and comprehensive experimental results on Yelp and Dianping datasets verified the effectiveness and efficiency of the augmented matrix factorization algorithms.",2014,Conference on Information and Knowledge Management,compressed sensing;collaborative filtering;matrix decomposition;recommender system;theoretical computer science;machine learning;mathematical optimization;computer science;
Mining Semi-Structured Online Knowledge Bases to Answer Natural Language Questions on Community QA Websites,Parikshit Sondhi (University of Illinois at Urbana–Champaign);ChengXiang Zhai (University of Illinois at Urbana–Champaign);,"2019386676,2152766206","Over the past few years, community QA websites (e.g. Yahoo! Answers) have become a useful platform for users to post questions and obtain answers. However, not all questions posted there receive informative answers or are answered in a timely manner. In this paper, we show that the answers to some of these questions are available in online domain-specific knowledge bases and propose an approach to automatically discover those answers. In the proposed approach, we would first mine appropriate SQL query patterns by leveraging an existing collection of QA pairs, and then use the learned query patterns to answer previously unseen questions by returning relevant entities from the knowledge base. Evaluation on a collection of health domain questions from Yahoo! Answers shows that the proposed method is effective in discovering potential answers to user questions from an online medical knowledge base.",2014,Conference on Information and Knowledge Management,question answering;knowledge base;text mining;world wide web;information retrieval;data mining;database;computer science;
On the Semantic Annotation of Daily Places: A Machine-Learning Approach,Chih-Wei Chang (National Chung Hsing University);Yao-Chung Fan (National Chung Hsing University);Kuo-Chen Wu (HTC);Arbee L.P. Chen (National Chengchi University);,"2223385595,2147711999,2535776677,2211440602","Over the recent years smart devices have become a ubiquitous medium supporting various forms of functionality and are widely accepted for common users. One distinguishing feature for smart devices is the ability of positioning the physical location of a device, and numerous applications based on user location information have been proposed. While the potentials have been foreseen, location based services fundamentally suffer from the problem of lacking an effective and scalable mechanism to bridge the gap between the machine-observed locations and the human understandable places. In this study, we contribute on this fundamental problem. Differing from the existing solutions on this subject, we start from a novel perspective; we propose to address the place semantic understanding problem by casting it as a classification problem and employ machine learning techniques to automatically infer the types of the places. The key observation is that human behaviors are not random, e.g., people visit restaurants around noon, go for work in the daytime, and stay at home at night. Namely, by properly selecting features, a mechanism for automatically inferring place type semantics can be achieved. This paper summarizes our treatment and findings of leveraging the human behaviors patterns to infer the type of a place. Experiments using month-long trace logs from the recruited participants are conducted, and the experiment results demonstrate the effectiveness of the proposed method.",2014,Conference on Information and Knowledge Management,location based service;mobile device;biological classification;semantics;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
RApID: A System for Real-time Analysis of Information Diffusion in Twitter,Io Taxidou (University of Freiburg);Peter M. Fischer (University of Freiburg);,"47752373,2571461549","The advent of social media has facilitated the study of information diffusion, expressing information spreading and influence among users on social graphs. In this demo paper, we present a system for real-time analysis of information diffusion on Twitter; it constructs the so-called information cascades that capture how information is being propagated from user to user. We face the challenge of managing and presenting large and fast-evolving graph data. For this purpose, we have developed methods for computing and visualizing information flow dynamically, offering rich structural and temporal information. The interface offers the possibility to interact with the dynamic, evolving cascades and gives valuable insights in terms of how information propagates on real-time and how users are influenced from each other.",2014,Conference on Information and Knowledge Management,information cascade;multimedia;world wide web;data mining;simulation;computer science;
Focusing Decomposition Accuracy by Personalizing Tensor Decomposition (PTD),Xinsheng Li (Arizona State University);Shengyu Huang (Arizona State University);Kasim Selçuk Candan (Arizona State University);Maria Luisa Sapino (University of Turin);,"2164275229,2310006983,2693995032,351919550","Tensor decomposition operation is the basis for many data analysis tasks from clustering, trend detection, anomaly detection, to correlation analysis. One key problem with tensor decomposition, however, is its computational complexity -- especially for dense data sets, the decomposition process takes exponential time in the number of tensor modes; the process is relatively faster for sparse tensors, but decomposition is still a major bottleneck in many applications. While it is possible to reduce the decomposition time by trading performance with decomposition accuracy, a drop in accuracy may not always be acceptable. In this paper, we first recognize that in many applications, the user may have a focus of interest -- i.e., part of the data for which the user needs high accuracy -- and beyond this area focus, accuracy may not be as critical. Relying on this observation, we propose a novel Personalized Tensor Decomposition (PTD) mechanism for accounting for the user's focus: PTD takes as input one or more areas of focus and performs the decomposition in such a way that, when reconstructed, the accuracy of the tensor is boosted for these areas of focus. We discuss alternative ways PTD can be implemented. Experiments show that PTD helps boost accuracy at the foci of interest, while reducing the overall tensor decomposition time.",2014,Conference on Information and Knowledge Management,personalization;tensor;scalability;theoretical computer science;data mining;database;machine learning;computer science;
Predicting Search Task Difficulty at Different Search Stages,Chang Liu (Peking University);Jingjing Liu (University of South Carolina);Nicholas J. Belkin (Rutgers University);,"2553865559,2255820091,682752941","Knowing, in real time, whether a current searcher in an information retrieval system finds the search task difficult can be valuable for tailoring the system's support for that searcher. This study investigated searcher's behaviors at different stages of the search process; they are: 1) first-round point at the beginning of the search, right before searchers issued their second query; 2) middle point, when searchers proceeded to the middle of the search process, and 3) end point, when searchers finished the whole task. We compared how the behavioral features calculated at these three points were different between difficult and easy search tasks, and identified behavioral features during search sessions that can be used in real-time to predict perceived task difficulty. In addition, we compared the prediction performance at different stages of search process. Our results show that a number of user behavioral measures at all three points differed between easy and difficult tasks. Query interval time, dwell time on viewed documents, and number of viewed documents per query were important predictors of task difficulty. The results also indicate that it is possible to make relatively accurate prediction of task difficulty at the first query round of a search. Our findings can help search systems predict task difficulty which is necessary in personalizing support for the individual searcher.",2014,Conference on Information and Knowledge Management,personalization;search engine;information retrieval;data mining;machine learning;computer science;
A Word-Scale Probabilistic Latent Variable Model for Detecting Human Values,"Yasuhiro Takayama;Yoichi Tomiura (Kyushu University);Emi Ishita (Kyushu University);Douglas W. Oard (University of Maryland, College Park);Kenneth R. Fleischmann (University of Texas at Austin);An Shou Cheng (National Sun Yat-sen University);","2164659975,362757229,328053997,7916806,2024211715,2147655356","This paper describes a probabilistic latent variable model that is designed to detect human values such as justice or freedom that a writer has sought to reflect or appeal to when participating in a public debate. The proposed model treats the words in a sentence as having been chosen based on specific values; values reflected by each sentence are then estimated by aggregating values associated with each word. The model can determine the human values for the word in light of the influence of the previous word. This design choice was motivated by syntactic structures such as noun+noun, adjective+noun, and verb+adjective. The classifier based on the model was evaluated on a test collection containing 102 manually annotated documents focusing on one contentious political issue - Net neutrality , achieving the highest reported classification effectiveness for this task. We also compared our proposed classifier with human second annotator. As a result, the proposed classifier effectiveness is statistically comparable with human annotators.",2014,Conference on Information and Knowledge Management,statistical model;computational linguistics;natural language processing;world wide web;speech recognition;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Adaptive Pairwise Preference Learning for Collaborative Recommendation with Implicit Feedbacks,Hao Zhong (Zhejiang University);Weike Pan (Shenzhen University);Congfu Xu (Zhejiang University);Zhi Yin (Ningbo University of Technology);Zhong Ming (Shenzhen University);,"2419727574,2557864391,2692648732,2487426075,2693431158","Learning users' preferences is critical to enable personalized recommendation services in various online applications such as e-commerce, entertainment and many others. In this paper, we study on how to learn users' preferences from abundant online activities, e.g., browsing and examination, which are usually called implicit feedbacks since they cannot be interpreted as users' likes or dislikes on the corresponding products directly. Pairwise preference learning algorithms are the state-of-the-art methods for this important problem, but they have two major limitations of low accuracy and low efficiency caused by noise in observed feedbacks and non-optimal learning steps in update rules. As a response, we propose a novel adaptive pairwise preference learning algorithm, which addresses the above two limitations in a single algorithm with a concise and general learning scheme. Specifically, in the proposed learning scheme, we design an adaptive utility function and an adaptive learning step for the aforementioned two problems, respectively. Empirical studies show that our algorithm achieves significantly better results than the state-of-the-art method on two real-world data sets.",2014,Conference on Information and Knowledge Management,preference learning;active learning;semi supervised learning;knowledge management;world wide web;data mining;machine learning;computer science;
Predicting the Popularity of Online Serials with Autoregressive Models,Biao Chang (University of Science and Technology of China);Hengshu Zhu (University of Science and Technology of China);Yong Ge (University of North Carolina at Charlotte);Enhong Chen (University of Science and Technology of China);Hui Xiong (Rutgers University);Chang Tan (University of Science and Technology of China);,"2231910817,2098414524,2218492437,2136372366,2153710278,2125553367","Recent years have witnessed the rapid prevalence of online serials, which play an important role in our daily entertainment. A critical demand along this line is to predict the popularity of online serials, which can enable a wide range of applications, such as online advertising, and serial recommendation. However, compared with traditional online media such as user-generated content (UGC), online serials have unique characteristics of sequence dependence, release date dependence as well as unsynchronized update regularity. Therefore, the popularity prediction for online serials is a nontrivial task and still under-addressed. To this end, in this paper we present a comprehensive study for predicting the popularity of online serials with autoregressive models. Specifically, we first introduce a straightforward yet effective Naive Autoregressive (NAR) model based on the correlations of serial episodes. Furthermore, we develop a sophisticated model, namely Transfer Autoregressive (TAR) model, to capture the dynamic behaviors of audiences, which can achieve better prediction performance than the NAR model. Indeed, the two models can reveal the popularity generation from different perspectives. In addition, as a derivative of the TAR model, we also design a novel metric, namely favor, for evaluating the quality of online serials. Finally, extensive experiments on two real-world data sets clearly show that both models are effective and outperform baselines in terms of the popularity prediction for online serials. And the new metric performs better than other metrics for quality estimation.",2014,Conference on Information and Knowledge Management,autoregressive model;world wide web;data mining;database;statistics;computer science;
HGMF: Hierarchical Group Matrix Factorization for Collaborative Recommendation,Xin Wang (Zhejiang University);Weike Pan (Shenzhen University);Congfu Xu (Zhejiang University);,"2720655070,2557864391,2692648732","Matrix factorization is one of the most powerful techniques in collaborative filtering, which models the (user, item) interactions behind historical explicit or implicit feedbacks. However, plain matrix factorization may not be able to uncover the structure correlations among users and items well such as communities and taxonomies. As a response, we design a novel algorithm, i.e., hierarchical group matrix factorization (HGMF), in order to explore and model the structure correlations among users and items in a principled way. Specifically, we first define four types of correlations, including (user, item), (user, item group), (user group, item) and (user group, item group); we then extend plain matrix factorization with a hierarchical group structure; finally, we design a novel clustering algorithm to mine the hidden structure correlations. In the experiments, we study the effectiveness of our HGMF for both rating prediction and item recommendation, and find that it is better than some state-of-the-art methods on several real-world data sets.",2014,Conference on Information and Knowledge Management,collaborative filtering;world wide web;information retrieval;data mining;machine learning;computer science;
Mining and Planning Time-aware Routes from Check-in Data,Hsun-Ping Hsieh (National Taiwan University);Cheng-Te Li (Academia Sinica);,"2109618838,2139086518","Location-based services allow users to perform check-in actions, which not only record their geo-spatial activities, but also provide a plentiful source for data scientists to analyze and plan more accurate and useful geographical recommender system. In this paper, we present a novel Time-aware Route Planning (TRP) problem using location check-in data. The central idea is that the pleasure of staying at the locations along a route is significantly affected by their visiting time. Each location has its own proper visiting time due to the category, objective, and population. To consider the visiting time of locations into route planning, we develop a three-stage time-aware route planning framework. First, since there is usually either noise time on existing locations or no visiting information on new locations constructed, we devise an inference method, LocTimeInf, to predict and recover the location visiting time on routes. Second, we aim to find the representative and popular time-aware location-transition behaviors from user check-in data, and a Time-aware Transit Pattern Mining (TTPM) algorithm is proposed correspondingly. Third, based on the mined time-aware transit patterns, we develop a Proper Route Search (PR-Search) algorithm to construct the final time-aware routes for recommendation. Experiments on Gowalla check-in data exhibit the promising effectiveness and efficiency of the proposed methods, comparing to a series of competitors.",2014,Conference on Information and Knowledge Management,world wide web;data mining;simulation;
Online Exploration for Detecting Shifts in Fresh Intent,Damien Lefortier (Yandex);Pavel Serdyukov (Yandex);Maarten de Rijke (University of Amsterdam);,"109639033,2130450538,401833296","In web search, recency ranking refers to the task of ranking documents while taking into account freshness as one of the criteria of their relevance. There are two approaches to recency ranking. One focuses on extending existing learning to rank algorithms to optimize for both freshness and relevance. The other relies on an aggregated search strategy: a (dedicated) fresh vertical is used and fresh results from this vertical are subsequently integrated into the search engine result page. In this paper, we adopt the second strategy. In particular, we focus on the fresh vertical prediction task for repeating queries and identify the following novel algorithmic problem: how to quickly correct fresh intent detection mistakes made by a state-of-the-art fresh intent detector, which erroneously detected or missed a fresh intent shift upwards for a particular repeating query (i.e., a change in the degree to which the query has a fresh intent). We propose a method for solving this problem. We use online exploration at the early start of what we believe to be a detected intent shift. Based on this exploratory phase, we correct fresh intent detection mistakes made by a state-of-that-art fresh intent detector for queries, whose fresh intent has shifted. Using query logs of Yandex, we demonstrate that our methods allow us to significantly improve the speed and quality of the detection of fresh intent shifts.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
A Fixed-Point Method for Weighting Terms in Verbose Informational Queries,"Jiaul H. Paik (University of Maryland, College Park);Douglas W. Oard (University of Maryland, College Park);","2308983664,7916806","The term weighting and document ranking functions used with informational queries are typically optimized for cases in which queries are short and documents are long. It is reasonable to assume that the presence of a term in a short query reflects some aspect of the topic that is important to the user, and thus rewarding documents that contain the greatest number of distinct query terms is a useful heuristic. Verbose informational queries, such as those that result from cut-and-paste of example text, or that might result from informal spoken interaction, pose a different challenge in which many extraneous (and thus potentially misleading) terms may be present in the query. Modest improvements have been reported from applying supervised methods to learn which terms in a verbose query deserve the greatest emphasis. This paper proposes a novel unsupervised method for weighting terms in verbose informational queries that relies instead on iteratively estimating which terms are most central to the query. The key idea is to use an initial set of retrieval results to define a recursion on the term weight vector that converges to a fixed point representing the vector that optimally describes the initial result set. Experiments with several TREC news and Web test collections indicate that the proposed method often statistically significantly outperforms state of the art supervised methods.",2014,Conference on Information and Knowledge Management,ranking;world wide web;information retrieval;data mining;database;machine learning;
A Mixtures-of-Trees Framework for Multi-Label Classification,Charmgil Hong (University of Pittsburgh);Iyad Batal (GE Global Research);Milos Hauskrecht (University of Pittsburgh);,"2168526916,1841724547,85581826","We propose a new probabilistic approach for multi-label classification that aims to represent the class posterior distribution P ( Y | X ). Our approach uses a mixture of tree-structured Bayesian networks, which can leverage the computational advantages of conditional tree-structured models and the abilities of mixtures to compensate for tree-structured restrictions. We develop algorithms for learning the model from data and for performing multi-label predictions using the learned model. Experiments on multiple datasets demonstrate that our approach outperforms several state-of-the-art multi-label classification methods.",2014,Conference on Information and Knowledge Management,bayesian network;text mining;data science;information retrieval;data mining;machine learning;statistics;computer science;
Towards Efficient Dissemination of Linked Data in the Internet of Things,"Yongrui Qin (University of Adelaide);Quan Z. Sheng (University of Adelaide);Nickolas J.G. Falkner (University of Adelaide);Ali Shemshadi (University of Adelaide);Edward Curry (National University of Ireland, Galway);","2110208407,1740996049,2309817396,1986812620,2153318372","The Internet of Things (IoT) envisions smart objects collecting and sharing data at a global scale via the Internet. One challenging issue is how to disseminate data to relevant data consumers efficiently. In this paper, we leverage semantic technologies which can facilitate machine-to-machine communications, such as Linked Data, to build an efficient information dissemination system for semantic IoT. The system integrates Linked Data streams generated from various data collectors and disseminates matched data to relevant data consumers based on Basic Graph Patterns (BGPs) registered in the system by those consumers. To efficiently match BGPs against Linked Data streams, we introduce two types of matching, namely semantic matching and pattern matching, by considering whether the matching process supports semantic relatedness computation. Two new data structures, namely MVR-tree and TP-automata, are introduced to suit these types of matching respectively. Experiments show that an MVR-tree designed for semantic matching can achieve a twofold increase in throughput compared with the naive R-tree based method. TP-automata, as the first approach designed for pattern matching over Linked Data streams, also provides two to three orders of magnitude improvements on throughput compared with semantic matching approaches.",2014,Conference on Information and Knowledge Management,linked data;world wide web;information retrieval;data mining;database;computer science;
Transfer Understanding from Head Queries to Tail Queries,Yangqiu Song (University of Illinois at Urbana–Champaign);Haixun Wang (Google);Weizhu Chen (Microsoft);Shusen Wang (Zhejiang University);,"2099747503,2116756368,2108390110,2650560419","One of the biggest challenges of commercial search engines is how to handle tail queries, or queries that occur very infrequently. Frequent queries, also known as head queries, are easier to handle largely because their intents are evidenced by abundant click-through data (query logs). Tail queries have little historical data to rely on, which makes them difficult to be learned by ranking algorithms. In this paper, we leverage knowledge from two resources to fill the gap. The first is a general knowledgebase containing different granularities of concepts automatically harnessed from the Web. The second is the click-through data for head queries. From the click-through data, we obtain an understanding of queries that trigger clicks. Then, we show that by extracting single or multi-word expressions from both head and tail queries and mapping them to a common concept space defined by the knowledgebase, we are able to transfer the click information of the head queries to the tail queries. To validate our approach, we conduct large scale experiments on two real data sets. One is a mixture of head and tail queries, and the other contains pure tail queries. We show that our approach effectively improves tail query search relevance.",2014,Conference on Information and Knowledge Management,queries per second;spatial query;knowledge base;world wide web;information retrieval;data mining;database;computer science;
Improving Recommendation Accuracy by Combining Trust Communities and Collaborative Filtering,Xiao Ma (Huazhong University of Science and Technology);Hongwei Lu (Huazhong University of Science and Technology);Zaobin Gan (Huazhong University of Science and Technology);,"2438657433,2251920276,2145568642","With the booming of online social networks, social trust has been used to cluster users in recommender systems. It has been proven to improve the recommendation accuracy when trust communities are integrated into memory-based collaborative filtering algorithms. However, existing trust community mining methods only consider the trust relationships, regardless of the distrust information. In this paper, considering both the trust and distrust relationships, a SVD signs based community mining method is proposed to process the trust relationship matrix in order to discover the trust communities. A modified trust metric which considers a given user's expertise level in a community is presented to obtain the indirect trust values between users. Then some missing ratings of the given user are complemented by the weighted average preference of his/her trusted neighbors selected in the same community during the random walk procedures. Finally, the prediction for a given item is generated by the conventional collaborative filtering. The comparison experiments on Epinions data set demonstrate that our approach outperforms other state-of-the-art methods in terms of RMSE and RC.",2014,Conference on Information and Knowledge Management,collaborative filtering;cluster analysis;world wide web;data mining;machine learning;computer science;
Enabling Precision/Recall Preferences for Semi-supervised SVM Training,Zeyi Wen (University of Melbourne);Rui Zhang (University of Melbourne);Kotagiri Ramamohanarao (University of Melbourne);,"2154047257,2690388134,123309386","Semi-supervised learning is an essential approach to classification when the available labeled data is insufficient and we need to also make use of unlabeled data in the learning process. Numerous research efforts have focused on designing algorithms to improve the F 1 score, but have any mechanism to control precision or recall individually. However, many applications have precision/recall preferences. For instance, an email spam classifier requires a precision of 0.9 to mitigate the false dismissal of useful emails. In this paper, we propose a method that allows to specify a precision/recall preference while maximising the F 1 score. Our key idea is that we divide the semi-supervised learning process into multiple rounds of supervised learning, and the classifier learned at each round is calibrated using a sub-set of the labeled dataset before we use it on the unlabeled dataset for enlarging the training dataset. Our idea is applicable to a number of learning models such as Support Vector Machines (SVMs), Bayesian networks and neural networks. We focus our research and the implementation of our idea on SVMs. We conduct extensive experiments to validate the effectiveness of our method. The experimental results show that our method can train classifiers with a precision/recall preference, while the popular semi-supervised SVM training algorithm (which we use as the baseline) cannot. When we specify the precision preference and the recall preference to be the same, which indicates to maximise the F 1 score only as the baseline does, our method achieves better or similar F 1 scores to the baseline. An additional advantage of our method is that it converges much faster than the baseline.",2014,Conference on Information and Knowledge Management,precision and recall;preference learning;recall;accuracy and precision;information retrieval;data mining;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Generative Modeling of Entity Comparisons in Text,Maksim Tkachenko (Saint Petersburg State University);Hady Wirawan Lauw (Singapore Management University);,"1974642809,2024254804","Users frequently rely on online reviews for decision making. In addition to allowing users to evaluate the quality of individual products, reviews also support comparison shopping. One key user activity is to compare two (or more) products based on a specific aspect. However, making a comparison across two different reviews, written by different authors, is not always equitable due to the different standards and preferences of individual authors. Therefore, we focus instead on comparative sentences, whereby two products are compared directly by a review author within a single sentence. We study the problem of comparative relation mining. Given a set of comparative sentences, each relating a pair of entities, our objective is two-fold: to interpret the comparative direction in each sentence, and to determine the relative merits of each entity. This requires mining comparative relations at two levels of resolution: at the sentence level, as well as at the entity level. Our key observation is that there is significant synergy between the two levels. We therefore propose a generative model for comparative text, which jointly models comparative directions at the sentence level, and ranking at the entity level. This model is tested comprehensively on Amazon reviews dataset with good empirical outperformance over the state-of-the-art baselines.",2014,Conference on Information and Knowledge Management,generative model;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;machine learning;computer science;
Active Learning for Streaming Networked Data,Zhilin Yang (Tsinghua University);Jie Tang (Tsinghua University);Yutao Zhang (Tsinghua University);,"2489788272,2158012360,2223115198","Mining high-speed data streams has become an important topic due to the rapid growth of online data. In this paper, we study the problem of active learning for streaming networked data. The goal is to train an accurate model for classifying networked data that arrives in a streaming manner by querying as few labels as possible. The problem is extremely challenging, as both the data distribution and the network structure may change over time. The query decision has to be made for each data instance sequentially, by considering the dynamic network structure. We propose a novel streaming active query strategy based on structural variability . We prove that by querying labels we can monotonically decrease the structural variability and better adapt to concept drift. To speed up the learning process, we present a network sampling algorithm to sample instances from the data stream, which provides a way for us to handle large volume of streaming data. We evaluate the proposed approach on four datasets of different genres: Weibo, Slashdot, IMDB, and ArnetMiner. Experimental results show that our model performs much better (+5-10% by F1-score on average) than several alternative methods for active learning over streaming networked data.",2014,Conference on Information and Knowledge Management,active learning;data stream mining;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Distributed Stochastic ADMM for Matrix Factorization,Zhi-Qin Yu (Shanghai Jiao Tong University);Xing-Jian Shi (Hong Kong University of Science and Technology);Ling Yan (Shanghai Jiao Tong University);Wu-Jun Li (Nanjing University);,"2224814420,2665781162,2150613736,2697684806","Matrix factorization (MF) has become the most popular technique for recommender systems due to its promising performance. Recently, distributed (parallel) MF models have received much attention from researchers of big data community. In this paper, we propose a novel model, called d istributed s tochastic a lternating d irection m ethods of m ultipliers (DS-ADMM), for large-scale MF problems. DS-ADMM is a distributed stochastic variant of ADMM. In particular, we first devise a new data split strategy to make the distributed MF problem fit for the ADMM framework. Then, a stochastic ADMM scheme is designed for learning. Finally, we implement DS-ADMM based on m essage p assing i nterface (MPI), which can run on clusters with multiple machines (nodes). Experiments on several data sets from recommendation applications show that our DS-ADMM model can outperform other state-of-the-art distributed MF models in terms of both efficiency and accuracy.",2014,Conference on Information and Knowledge Management,matrix decomposition;recommender system;theoretical computer science;distributed computing;data mining;machine learning;computer science;
What is the Shape of a Cluster?: Structural Comparisons of Document Clusters,Vinay Deolalikar (Hewlett-Packard);,2150307071,"Even today, most interfaces to document clustering present clusters to users and applications as a ""bag of descriptive terms""? a technique that was proposed two decades ago. Consequently, users and applications are not able to obtain sophisticated structural knowledge that is indeed lying hidden in document clusters. In particular, the structural information about interaction of concepts that the cluster speaks about is completely missing from the bag of terms presentation. As the needs of unstructured information management increase, this shortcoming is coming into sharper focus. To address this shortcoming, we propose a rich representation of document clusters that surfaces the concept interactions within a cluster into the representation. We show that these interactions give a ""shape"" to the cluster. This ""shape"" is conveniently captured using a directed, colored, vertex-weighted graph, called the shape graph or, simply, the shape of the cluster. We show that shapes convey important structural information about document clusters, and can be computed efficiently.",2014,Conference on Information and Knowledge Management,theoretical computer science;data mining;machine learning;computer science;
Pushing the Envelope in Graph Compression,Panagiotis Liakos (National and Kapodistrian University of Athens);Katia Papakonstantinopoulou (National and Kapodistrian University of Athens);Michael Sioutis (Centre national de la recherche scientifique);,"2169631048,115028611,2022326286","We improve the state-of-the-art method for the compression of web and other similar graphs by introducing an elegant technique which further exploits the clustering properties observed in these graphs. The analysis and experimental evaluation of our method shows that it outperforms the currently best method of Boldi et al. by achieving a better compression ratio and retrieval time. Our method exhibits vast improvements on certain families of graphs, such as social networks, by taking advantage of their compressibility characteristics, and ensures that the compression ratio will not worsen for any graph, since it easily falls back to the state-of-the-art method.",2014,Conference on Information and Knowledge Management,distance hereditary graph;voltage graph;indifference graph;1 planar graph;graph operations;comparability graph;universal graph;block graph;topological graph theory;graph product;clique width;split graph;modular decomposition;pathwidth;line graph;clustering coefficient;theoretical computer science;world wide web;computer science;
Analysis on Community Variational Trend in Dynamic Networks,Xiaowei Jia (University at Buffalo);Nan Du (University at Buffalo);Jing Gao (University at Buffalo);Aidong Zhang (University at Buffalo);,"2106755540,2224413342,2096731881,2228514421","Temporal analysis on dynamic networks has become a popularly discussed topic today, with more and more emerging data over time. In this paper we investigate the problem of detecting and tracking the variational communities within a given time period. We first define a metric to measure the strength of a community, called the normalized temporal community strength. And then, we propose our analysis framework. The community may evolve over time, either split to multiple communities or merge with others. We address the problem of evolutionary clustering with requirement on temporal smoothness and propose a revised soft clustering method based on non-negative matrix factorization. Then we use a clustering matching method to find the soft correspondence between different community distribution structures. This matching establishes the connection between consecutive snapshots. To estimate the variational rate and meanwhile address the smoothness during continuous evolution, we propose an objective function that combines the conformity of current variation and historical variational trend. In addition, we integrate the weights to the objective function to identify the temporal outliers. An iterative coordinate descent method is proposed to solve the optimization framework. We extensively evaluate our method with a synthetic dataset and several real datasets. The experimental results demonstrate the effectiveness of our method, which is greatly superior to the baselines on detection of the communities with significant variation over time.",2014,Conference on Information and Knowledge Management,data mining;artificial intelligence;machine learning;statistics;
Customized Organization of Social Media Contents using Focused Topic Hierarchy,Xingwei Zhu (Tsinghua University);Zhao-Yan Ming (National University of Singapore);Yu Hao (Tsinghua University);Xiaoyan Zhu (Tsinghua University);Tat-Seng Chua (National University of Singapore);,"2298544045,2107469214,2672246779,2147746173,2160663097","With the popularity of social media platforms such as Facebook and Twitter, the amount of useful data in these sources is rapidly increasing, making them promising places for information acquisition. This research aims at the customized organization of a social media corpus using focused topic hierarchy. It organizes the contents into different structures to meet with users' different information needs (e.g., ""iPhone 5 problem"" or ""iPhone 5 camera""). To this end, we introduce a novel function to measure the likelihood of a topic hierarchy, by which the users' information need can be incorporated into the process of topic hierarchy construction. Using the structure information within the generated topic hierarchy, we then develop a probability based model to identify the representative contents for topics to assist users in document retrieval on the hierarchy. Experimental results on real world data illustrate the effectiveness of our method and its superiority over state-of-the-art methods for both information organization and retrieval tasks.",2014,Conference on Information and Knowledge Management,information needs;multimedia;world wide web;information retrieval;data mining;database;computer science;
Recognizing Humor on Twitter,Renxian Zhang (Tongji University);Naishi Liu (Shanghai Jiao Tong University);,"2676048712,2722368455","In this paper, we present our work of humor recognition on Twitter, which will facilitate affect and sentimental analysis in the social network. The central question of what makes a tweet (Twitter post) humorous drives us to design humor-related features, which are derived from influential humor theories, linguistic norms, and affective dimensions. Using machine learning techniques, we are able to recognize humorous tweets with high accuracy and F-measure. More importantly, we single out features that contribute to distinguishing non-humorous tweets from humorous tweets, and humorous tweets from other short humorous texts (non-tweets). This proves that humorous tweets possess discernible characteristics that are neither found in plain tweets nor in humorous non-tweets. We believe our novel findings will inform and inspire the burgeoning field of computational humor research in the social media.",2014,Conference on Information and Knowledge Management,computational humor;multimedia;machine learning;computer science;
Dynamic Clustering of Contextual Multi-Armed Bandits,Trong T. Nguyen (Singapore Management University);Hady Wirawan Lauw (Singapore Management University);,"2226649733,2024254804","With the prevalence of the Web and social media, users increasingly express their preferences online. In learning these preferences, recommender systems need to balance the trade-off between exploitation, by providing users with more of the ""same"", and exploration, by providing users with something ""new"" so as to expand the systems' knowledge. Multi-armed bandit (MAB) is a framework to balance this trade-off. Most of the previous work in MAB either models a single bandit for the whole population, or one bandit for each user. We propose an algorithm to divide the population of users into multiple clusters, and to customize the bandits to each cluster. This clustering is dynamic, i.e., users can switch from one cluster to another, as their preferences change. We evaluate the proposed algorithm on two real-life datasets.",2014,Conference on Information and Knowledge Management,multi armed bandit;cluster analysis;data mining;machine learning;simulation;computer science;
Verifiable UML Artifact-Centric Business Process Models,Diego Calvanese (Free University of Bozen-Bolzano);Marco Montali (Free University of Bozen-Bolzano);Montserrat Estañol (Polytechnic University of Catalonia);Ernest Teniente (Polytechnic University of Catalonia);,"1987600604,2263906729,2166889415,678245920","Artifact-centric business process models have gained increasing momentum recently due to their ability to combine structural (i.e., data related) with dynamical (i.e., process related) aspects. In particular, two main lines of research have been pursued so far: one tailored to business artifact modeling languages and methodologies, the other focused on the foundations for their formal verification. In this paper, we merge these two lines of research, by showing how recent theoretical decidability results for verification can be fruitfully transferred to a concrete UML-based modeling methodology. In particular, we identify additional steps in the methodology that, in significant cases, guarantee the possibility of verifying the resulting models against rich first-order temporal properties. Notably, our results can be seamlessly transferred to different languages for the specification of the artifact lifecycles.",2014,Conference on Information and Knowledge Management,applications of uml;artifact centric business process model;business process management;formal verification;unified modeling language;data mining;database;programming language;computer science;
Estimating the Number and Sizes of Fuzzy-Duplicate Clusters,Arvid Heise (Hasso Plattner Institute);Gjergji Kasneci (Hasso Plattner Institute);Felix Naumann (Hasso Plattner Institute);,"2045630383,2569257135,2099727678","Duplicates in a dataset are multiple representations of the same real-world entity and constitute a major data quality problem. This paper investigates the problem of estimating the number and sizes of duplicate record clusters in advance and describes a sampling-based method for solving this problem. In extensive experiments, on multiple datasets, we show that the proposed method reliably estimates the number of duplicate clusters, while being highly efficient. Our method can be used a) to measure the dirtiness of a dataset, b) to assess the quality of duplicate detection configurations, such as similarity measures, and c) to gather approximate statistics about the true number of entities represented in the dataset.",2014,Conference on Information and Knowledge Management,data integration;cluster;estimation;information retrieval;data mining;statistics;computer science;
Competitive Game Designs for Improving the Cost Effectiveness of Crowdsourcing,Markus Rokicki;Sergiu Chelaru;Sergej Zerr (Leibniz University of Hanover);Stefan Siersdorfer (Max Planck Society);,"2680689171,2086827253,2165764572,138385633","Crowd based online work is leveraged in a variety of applications such as semantic annotation of images, translation of texts in foreign languages, and labeling of training data for machine learning models. However, annotating large amounts of data through crowdsourcing can be slow and costly. In order to improve both cost and time efficiency of crowdsourcing we examine alternative reward mechanisms compared to the ""Pay-per-HIT"" scheme commonly used in platforms such as Amazon Mechanical Turk. To this end, we explore a wide range of monetary reward schemes that are inspired by the success of competitions, lotteries, and games of luck. Our large-scale experimental evaluation with an overall budget of more than 1,000 USD and with 2,700 hours of work spent by crowd workers demonstrates that our alternative reward mechanisms are well accepted by online workers and lead to substantial performance boosts.",2014,Conference on Information and Knowledge Management,crowdsourcing;world wide web;data mining;artificial intelligence;machine learning;simulation;computer science;
Collaborative Filtering Incorporating Review Text and Co-clusters of Hidden User Communities and Item Groups,Yinqing Xu (The Chinese University of Hong Kong);Wai Lam (The Chinese University of Hong Kong);Tianyi Lin (The Chinese University of Hong Kong);,"2156201790,2119595446,2654068848","Most collaborative filtering (CF) algorithms only make use of the rating scores given by users for items. However, it is often the case that each rating score is associated with a piece of review text. Such review texts, which are capable of providing us valuable information to reveal the reasons why users give a certain rating, have not been exploited and they are usually ignored by most CF algorithms. Moreover, the underlying relationship buried in users and items has not been fully exploited. Items we would recommend can often be characterized into hidden groups (e.g. comedy, horror movie and action movie), and users can also be organized as hidden communities. We propose a new generative model to predict user's ratings on previously unrated items by considering review texts as well as hidden user communities and item groups relationship. Regarding the rating scores, traditional algorithms would not perform well on uncovering the community and group information of each user and each item since the user-item rating matrix is dyadic involving the mutual interactions between users and items. Instead, co-clustering, which is capable of conducting simultaneous clustering of two variables, is able to take advantage of such user-item relationships to better predict the rating scores. Additionally, co-clustering would be more effective for modeling the generation of review texts since different user communities would discuss different topics and vary their own wordings or expression patterns when dealing with different item groups. Besides, by modeling as a mixed membership over community and group respectively, each user or item can belong to multiple communities or groups with varying degrees. We have conducted extensive experiments to predict the missing rating scores on 22 real word datasets. The experimental results demonstrate the superior performance of our proposed model comparing with the state-of-the-art methods.",2014,Conference on Information and Knowledge Management,topic model;collaborative filtering;biclustering;multimedia;world wide web;information retrieval;data mining;database;machine learning;computer science;
"AESTHETICS: Analytics with Strings, Things, and Cats",Johannes Hoffart (Max Planck Society);Dragan Milchevski (Max Planck Society);Gerhard Weikum (Max Planck Society);,"1019296130,39133813,514836396","This paper describes an advanced news analytics and exploration system that allows users to visualize trends of entities like politicians, countries, and organizations in continuously updated news articles. Our system improves state-of-the-art text analytics by linking ambiguous names in news articles to entities in knowledge bases like Freebase, DBpedia or YAGO. This step enables indexing entities and interpreting the contents in terms of entities. This way, the analysis of trends and co-occurrences of entities gains accuracy, and by leveraging the taxonomic type hierarchy of knowledge bases, also in expressiveness and usability. In particular, we can analyze not only individual entities, but also categories of entities and their combinations, including co-occurrences with informative text phrases. Our Web-based system demonstrates the power of this approach by insightful anecdotic analysis of recent events in the news.",2014,Conference on Information and Knowledge Management,semantic analytics;analytics;data science;world wide web;information retrieval;data mining;database;computer science;
Tracking Temporal Dynamics of Purchase Decisions via Hierarchical Time-Rescaling Model,Hideaki Kim;Noriko Takaya (Nippon Telegraph and Telephone);Hiroshi Sawada (Nippon Telegraph and Telephone);,"2664386148,2584052289,2099875912","Improvements in information technology have made it easier for industry to communicate with their customers, raising hopes for a scheme that can estimate when customers will want to make purchases. Although a number of models have been developed to estimate the time-varying purchase probability, they are based on very restrictive assumptions such as preceding purchase-event dependence and discrete-time effect of covariates. Our preliminary analysis of real-world data finds that these assumptions are invalid: self-exciting behavior, as well as marketing stimulus and preceding purchase dependence, should be examined as possible factors influencing purchase probability. In this paper, by employing the novel idea of hierarchical time rescaling, we propose a tractable but highly flexible model that can meld various types of intrinsic history dependency and marketing stimuli in a continuous-time setting. By employing the proposed model, which incorporates the three factors, we analyze actual data, and show that our model has the ability to precisely track the temporal dynamics of purchase probability at the level of individuals. It enables us to take effective marketing actions such as advertising and recommendations on timely and individual bases, leading to the construction of a profitable relationship with each customer.",2014,Conference on Information and Knowledge Management,point process;panel data;e commerce;world wide web;data mining;artificial intelligence;statistics;computer science;
"""Picture the scene..."";: Visually Summarising Social Media Events",Philip J. McParlane (University of Glasgow);Andrew James McMinn (University of Glasgow);Joemon M. Jose (University of Glasgow);,"1972083292,2474169165,2167481407","Due to the advent of social media and web 2.0, we are faced with a deluge of information; recently, research efforts have focused on filtering out noisy, irrelevant information items from social media streams and in particular have attempted to automatically identify and summarise events . However, due to the heterogeneous nature of such social media streams, these efforts have not reached fruition. In this paper, we investigate how images can be used as a source for summarising events. Existing approaches have considered only textual summaries which are often poorly written, in a different language and slow to digest. Alternatively, images are ""worth 1,000 words"" and are able to quickly and easily convey an idea or scene. Since images in social media can also be noisy, irrelevant and repetitive, we propose new techniques for their automatic selection , ranking and presentation . We evaluate our approach on a recently created social media event data set containing 365k tweets and 50 events, for which we extend by collecting 625k related images. By conducting two crowdsourced evaluations, we firstly show how our approach overcomes the problems of automatically collecting relevant and diverse images from noisy microblog data, before highlighting the advantages of multimedia summarisation over text based approaches.",2014,Conference on Information and Knowledge Management,social media;internet privacy;natural language processing;world wide web;information retrieval;data mining;database;computer science;
Exploring Ensemble of Models in Taxonomy-based Cross-Domain Sentiment Classification,Cong-Kai Lin (National Taiwan University);Yang-Yin Lee (National Taiwan University);Chi-Hsin Yu (National Taiwan University);Hsin-Hsi Chen (National Taiwan University);,"2122992001,2140243690,2145679261,2102355148","Most cross-domain sentiment classification techniques consider a domain as a whole set of opinionated instances for training. However, many online shopping websites organize their data in terms of taxonomy. With multiple domains (or, nodes) organized in a tree-structured representation, we propose a general ensemble algorithm which takes into account: 1) the model application, 2) the model weight and 3) the strategies for selecting the most related models with respect to a target node. The traditional sentiment classification technique SVM and the transfer learning algorithm Spectral Features Alignment (SFA) were applied as our model applications. In addition, the model weight takes the tree information and the similarity between domains into account. Finally, two strategies, cosine function and taxonomy-based regression model (TBRM) are proposed to select the most related models with respect to a target node. Experimental results showed both (cosine function and TBRM) proposed strategies outperform two baselines on an Amazon dataset. Three tasks of the proposed methods surpass the gold standard generated by the in-domain classifiers trained on the labeled data from the target nodes. Good results from the three tasks enable this algorithm to shed some new light on eliminating the major difficulties in transfer learning research: the distribution gap.",2014,Conference on Information and Knowledge Management,ensemble learning;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Efficient Static and Dynamic In-Database Tensor Decompositions on Chunk-Based Array Stores,Mijung Kim (Arizona State University);K. Selçuk Candan (Arizona State University);,"2129489018,674992784","As the relevant data sets get large, existing in-memory schemes for tensor decomposition become increasingly ineffective and, instead, memory-independent solutions, such as in-database analytics, are necessitated. In this paper, we present techniques for efficient implementations of in-database tensor decompositions on chunk-based array data stores. The proposed static and incremental in-database tensor decomposition operators and their optimizations address the constraints imposed by the main memory limitations when handling large and high-order tensor data. Firstly, we discuss how to implement alternating least squares operations efficiently on a chunk-based data storage system. Secondly, we consider scenarios with frequent data updates and show that compressed matrix multiplication techniques can be effective in reducing the incremental tensor decomposition maintenance costs. To the best of our knowledge, this paper presents the first attempt to develop efficient and optimized in-database tensor decomposition operations. We evaluate the proposed algorithms on tensor data sets that do not fit into the available memory and results show that the proposed techniques significantly improve the scalability of this core data analysis.",2014,Conference on Information and Knowledge Management,tensor product network;multilinear subspace learning;theoretical computer science;machine learning;mathematical optimization;computer science;
Forest-Based Dynamic Sorted Neighborhood Indexing for Real-Time Entity Resolution,Banda Ramadan (Australian National University);Peter Christen (Australian National University);,"2126170099,2023765750","Real-time entity resolution (ER) is the process of matching a query record in sub-second time with records in a database that represent the same real-world entity. To facilitate real-time matching on large databases, appropriate indexing approaches are required to reduce the search space. Most available indexing techniques are based on batch algorithms that work only with static databases and are not suitable for real-time ER. In this paper, we propose a forest-based sorted neighborhood index that uses multiple index trees with different sorting keys to facilitate real-time ER for read-most databases. Our technique aims to reduce the effect of errors and variations in attribute values on matching quality by building several distinct index trees. We conduct an experimental evaluation on two large real-world data sets, and multiple synthetic data sets with various data corruption rates. The results show that our approach is scalable to large databases and that using multiple trees gives a noticeable improvement on matching quality with only a small increase in query time. Our approach also achieves over one order of magnitude faster indexing and querying times, as well as higher matching accuracy, compared to another recently proposed real-time ER technique.",2014,Conference on Information and Knowledge Management,record linkage;world wide web;information retrieval;data mining;database;computer science;
Modelling Complex Relevance Spaces with Copulas,Carsten Eickhoff (ETH Zurich);Arjen P. de Vries (College of Western Idaho);,"1992666041,2506496362","Modern relevance models consider a wide range of criteria in order to identify those documents that are expected to satisfy the user's information need. With growing dimensionality of the underlying relevance spaces the need for sophisticated score combination and estimation schemes arises. In this paper, we investigate the use of copulas, a model family from the domain of robust statistics, for the formal estimation of the probability of relevance in high-dimensional spaces. Our experiments are based on the MSLR-WEB10K and WEB30K datasets, two annotated, publicly available samples of hundreds of thousands of real Web search impressions, and suggest that copulas can significantly outperform linear combination models for high-dimensional problems. Our models achieved a performance on par with that of state-of-the-art machine learning approaches.",2014,Conference on Information and Knowledge Management,probabilistic relevance model;ranking;data mining;machine learning;statistics;
Automatic Social Circle Detection Using Multi-View Clustering,Yuhao Yang (University of Kansas);Chao Lan (University of Kansas);Xiaoli Li (University of Kansas);Bo Luo (University of Kansas);Jun Huan (University of Kansas);,"2230516262,2125332459,2672212736,2311601423,2139058963","With the development of information technology, online social networks grow dramatically. They now play a significant role in people's social life, especially for the younger generation. While huge amount of information is available in online social networks, privacy concerns arise. Among various privacy protection proposals, the notions of privacy as control and information boundary have been introduced. Commercial social networking sites have adopted the concept to implement mechanisms such as Google circles and Facebook custom lists. However, the functions are not widely accepted by the users, partly because it is tedious and labor-intensive to manually assign friends into circles. In this paper, we introduce a social circle discovery approach using multi-view clustering. First, we present our observations on the key features of social circles: friendship links, content similarity and social interactions. We propose a one-side co-trained spectral clustering algorithm, which is tailored for the sparse nature of social network data. We also propose two evaluation measurements. One is based on quantitative similarity measures, while the other employs human evaluators to examine pairs of users selected by the max-risk evaluation approach. We evaluate our approach on ego networks of twitter users, and compare the proposed technique with single-view clustering and original co-trained spectral clustering techniques. Results show that multi-view clustering is more accurate for social circle detection; and our proposed approach gains significantly higher similarity ratio than the original multi-view clustering approach.",2014,Conference on Information and Knowledge Management,fuzzy clustering;privacy;social network;internet privacy;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Pattern Match Query in a Large Uncertain Graph,Ye Yuan (Northeastern University);Guoren Wang (Northeastern University);Lei Chen (Hong Kong University of Science and Technology);,"2104055677,2166985210,2318776917","Many studies have been conducted on seeking an efficient solution for pattern matching over graphs. This interest is largely due to large number of applications in many fields, which require efficient solutions for pattern matching, including protein complex prediction, social network analysis and structural pattern recognition. However, in many real applications, the graph data are often noisy, incomplete, and inaccurate. In other words, there exist many uncertain graphs. Therefore, in this paper, we study pattern matching in a large uncertain graph. Specifically, we want to retrieve all qualified matches of a query pattern in the uncertain graph. Though pattern matching over an uncertain graph is NP-hard, we employ a filtering-and verification framework to speed up the search. In the filtering phase, we propose a probabilistic matching tree , PM-tree, based on match cuts obtained by a cut selection process. Based on PM-tree, we devise a collective pruning strategy to prune a large number of unqualified matches. During the verification phase, we develop an efficient sampling algorithm to validate the remaining candidates. Extensive experimental results demonstrate the effectiveness and efficiency of the proposed algorithms.",2014,Conference on Information and Knowledge Management,3 dimensional matching;null model;database index;data mining;database;pattern recognition;machine learning;computer science;
Keeping You in the Loop: Enabling Web-based Things Management in the Internet of Things,Lina Yao (University of Adelaide);Quan Z. Sheng (University of Adelaide);Anne H. H. Ngu (Texas State University);Byron J. Gao (Texas State University);,"2223456168,1740996049,2310841419,2165486582","Internet of Things (IoT) is an emerging paradigm where physical objects are connected and communicated over the Web. Its capability in assimilating the virtual world and the physical one offers many exciting opportunities. However, how to realize a smooth, seamless integration of the two worlds remains an interesting and challenging topic. In this paper, we showcase an IoT prototype system that enables seamless integration of the virtual and the physical worlds and efficient management of things of interest (TOIs), where services and resources offered by things can be easily monitored, visualized, and aggregated for value-added services by users. This paper presents the motivation, system design, implementation, and demonstration scenario of the system.",2014,Conference on Information and Knowledge Management,internet of things;radio frequency identification;web of things;internet privacy;multimedia;world wide web;computer science;
Distance or Coverage?: Retrieving Knowledge-Rich Documents From Enterprise Text Collections,Vinay Deolalikar (Hewlett-Packard);,2150307071,"We formulate a problem that arises in unstructured enterprise information management, and has high commercial impact: retrieve knowledge-rich documents in a large textual collection of technical documents. We call such documents principal documents . We exploit the properties of large sparse text collections in order to address this problem. It is known that the centroids of document clusters on such collections form so-called ""concept vectors"" for the collection. However, typically these centroids do not correspond to documents in the collection. How then should they be used for retrieving documents? An immediate approach is to collect documents that are closest to the centroid, which we call CTC. We also propose an algorithm called PrinDocs . The key insight behind PrinDocs is the following: replace distance functions by coverage. In other words, instead of finding the ""closest"" documents to a concept vector, find those that ""cover"" the concept vector. PrinDocs employs greedy weighted set covering and uses the concept decomposition offered by centroids, but does not use the cosine distance on documents. We compare CTC and PrinDocs for retrieving knowledge-rich documents in enterprise unstructured technical collections. We demonstrate that PrinDocs comprehensively outperforms CTC. Our work suggests that coverage based approaches might be preferable to distance based ones for similar retrieval tasks.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
Hashcube: A Data Structure for Space- and Query-Efficient Skycube Compression,Kenneth S. Bøgh (Aarhus University);Sean Chester (Aarhus University);Darius šidlauskas (Aarhus University);Ira Assent (Aarhus University);,"2033707615,2167628457,2058785602,145164693","The skyline operator returns records in a dataset that provide optimal trade-offs of multiple dimensions. It is an expensive operator whose query performance can greatly benefit from materialization. However, a skyline can be executed over any subspace of dimensions, and the materialization of all subspace skylines, called the skycube, dramatically multiplies data size. Existing methods for skycube compression sacrifice too much query performance; so, we present a novel hashing- and bitstring-based compressed data structure that supports orders of magnitude faster query performance.",2014,Conference on Information and Knowledge Management,hash table;compression;data structure;theoretical computer science;data mining;database;computer science;
Sequential Action Patterns in Collaborative Ontology-Engineering Projects: A Case-Study in the Biomedical Domain,Simon Walk (Graz University of Technology);Philipp Singer (Leibniz Association);Markus Strohmaier (Leibniz Association);,"2126187198,2167599249,142799918","Within the last few years the importance of collaborative ontology-engineering projects, especially in the biomedical domain, has drastically increased. This recent trend is a direct consequence of the growing complexity of these structured data representations, which no single individual is able to handle anymore. For example, the World Health Organization is currently actively developing the next revision of the International Classification of Diseases (ICD), using an OWL-based core for data representation and Web 2.0 technologies to augment collaboration. This new revision of ICD consists of roughly 50,000 diseases and causes of death and is used in many countries around the world to encode patient history, to compile health-related statistics and spendings. Hence, it is crucial for practitioners to better understand and steer the underlying processes of how users collaboratively edit an ontology. Particularly, generating predictive models is a pressing issue as these models may be leveraged for generating recommendations in collaborative ontology-engineering projects and to determine the implications of potential actions on the ontology and community. In this paper we approach this task by (i) exploring whether regularities and common patterns in user action sequences, derived from change-logs of five different collaborative ontology-engineering projects from the biomedical domain, exist. Based on this information we (ii) model the data using Markov chains of varying order, which are then used to (iii) predict user actions in the sequences at hand.",2014,Conference on Information and Knowledge Management,markov chain;data science;natural language processing;knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
iMiner: Mining Inventory Data for Intelligent Management,Lei Li (Florida International University);Chao Shen (Florida International University);Long Wang (Florida International University);Li Zheng (Florida International University);Yexi Jiang (Florida International University);Liang Tang (Florida International University);Hongtai Li (Florida International University);Longhui Zhang (Florida International University);Chunqiu Zeng (Florida International University);Tao Li (Florida International University);Jun Tang;Dong Liu;,"2432045905,2171136085,2435336103,2112178922,2402026574,2128176332,2154980435,2147074165,2155150411,2472069284,2657925133,2709166452","Inventory management refers to tracing inventory levels, orders and sales of a retailing business. In the current retailing market, a tremendous amount of data regarding stocked goods (items) in an inventory will be generated everyday. Due to the increasing volume of transaction data and the correlated relations of items, it is often a non-trivial task to efficiently and effectively manage stocked goods. In this demo, we present an intelligent system, called iMiner, to ease the management of enormous inventory data. We utilize distributed computing resources to process the huge volume of inventory data, and incorporate the latest advances of data mining technologies into the system to perform the tasks of inventory management, e.g., forecasting inventory, detecting abnormal items, and analyzing inventory aging. Since 2014, iMiner has been deployed as the major inventory management platform of ChangHong Electric Co., Ltd, one of the world's largest TV selling companies in China.",2014,Conference on Information and Knowledge Management,stock taking;perpetual inventory;inventory control;inventory theory;anomaly detection;machine learning;computer science;
Modeling Retail Transaction Data for Personalized Shopping Recommendation,Pengfei Wang (Chinese Academy of Sciences);Jiafeng Guo (Chinese Academy of Sciences);Yanyan Lan (Chinese Academy of Sciences);,"2671177797,2581340266,2154124860","Retail transaction data conveys rich preference information on brands and goods from customers. How to mine the transaction data to provide personalized recommendation to customers becomes a critical task for retailers. Previous recommendation methods either focus on the user-product matrix and ignore the transactions, or only use the partial information of transactions, leading to inferior performance in recommendation. Inspired by association rule mining, we introduce association pattern as a basic unit to capture the correlation between products from both intra- and intertransactions. A Probabilistic model over the Association Patterns (PAP for short) is then employed to learn the potential shopping interests and also to provide personalized recommendations. Experimental results on two real world retail data sets show that our proposed method can outperform the state-of-the-art recommendation methods.",2014,Conference on Information and Knowledge Management,statistical model;world wide web;data mining;database;statistics;
Aroma: A New Data Protection Method with Differential Privacy and Accurate Query Answering,Chunyao Song (University of Massachusetts Lowell);Tingjian Ge (University of Massachusetts Lowell);,"2142816583,2185270649","We propose a new local data perturbation method called Aroma. We first show that Aroma is sound in its privacy protection. For that, we devise a realistic privacy game, called the exposure test. We prove that the αβ algorithm, a previously proposed method that is most closely related to Aroma, performs poorly under the exposure test and fails to provide sufficient privacy in practice. Moreover, any data protection method that satisfies e-differential privacy will succeed in the test. By proving that Aroma satisfies e-differential privacy, we show that Aroma offers strong privacy protection. We then demonstrate the utility of Aroma by proving that its estimator has significantly smaller errors than the previous state-of-the-art algorithms such as αβ, AM, and FRAPP. We carry out a systematic empirical study using real-world data to evaluate Aroma, which shows its clear advantages over previous methods.",2014,Conference on Information and Knowledge Management,differential privacy;internet privacy;world wide web;data mining;database;machine learning;computer science;
Latent Aspect Mining via Exploring Sparsity and Intrinsic Information,Yinqing Xu (The Chinese University of Hong Kong);Tianyi Lin (The Chinese University of Hong Kong);Wai Lam (The Chinese University of Hong Kong);Zirui Zhou (The Chinese University of Hong Kong);Hong Cheng (The Chinese University of Hong Kong);Anthony Man-Cho So (The Chinese University of Hong Kong);,"2156201790,2654068848,2119595446,2156492948,2161754280,2165238224","We investigate latent aspect mining problem that aims at automatically discovering aspect information from a collection of review texts in a domain in an unsupervised manner. One goal is to discover a set of aspects which are previously unknown for the domain, and predict the user's ratings on each aspect for each review. Another goal is to detect key terms for each aspect. Existing works on predicting aspect ratings fail to handle the aspect sparsity problem in the review texts leading to unreliable prediction. We propose a new generative model to tackle the latent aspect mining problem in an unsupervised manner. By considering the user and item side information of review texts, we introduce two latent variables, namely, user intrinsic aspect interest and item intrinsic aspect quality facilitating better modeling of aspect generation leading to improvement on the accuracy and reliability of predicted aspect ratings. Furthermore, we provide an analytical investigation on the Maximum A Posterior (MAP) optimization problem used in our proposed model and develop a new block coordinate gradient descent algorithm to efficiently solve the optimization with closed-form updating formulas. We also study its convergence analysis. Experimental results on the two real-world product review corpora demonstrate that our proposed model outperforms existing state-of-the-art models.",2014,Conference on Information and Knowledge Management,topic model;neural coding;data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Novel Query Suggestions: Initial Work Report,Ilona Nawrot (University of Caen Lower Normandy);Oskar Gross (University of Helsinki);Antoine Doucet (University of La Rochelle);Hannu Toivonen (University of Helsinki);,"2098622792,2141456701,2152615820,2250270171","Query auto-completion (QAC) is one of the most recognizable and widely used services of modern search engines. Its goal is to assist a user in the process of query formulation. Current QAC systems are mainly reactive. They respond to the present request using past knowledge. Specifically, they mostly rely on query logs analysis or corpus terms co-occurrences and rank suggestions according to their similarity with the partial user query, their past popularity, or their temporal dynamics features (e.g. trends, bursts, seasonality in query popularity). Consequently, a suggestion to be recommended by the QAC system must be preceded with a substantial users' interest and ipso facto must be an old information. However, a growing amount of people turns to search engines to find novel information, that is emergent or recently created (not redundant) one. Conventional QAC systems are thus unable to fulfill the increasingly real-time needs of the users. In this work-in-progress report, we introduce a new approach to QAC - the system filtering out potentially novel information and proactively delivering it to the users. It aims at providing the users with some novel insight. Thus, it caters for their open-ended or persistent and increasingly real-time information needs. The preliminary method proposed in this paper to evaluate this approach forms time specific suggestions based on a comparison of two corpora constantly being updated with new data from chosen sources. An unsupervised and language-independent algorithm relying on relative novelty of terms co-occurrences is used to generate suggestions. The initial experimental results demonstrate the effectiveness of the approach in recommending queries leading to novel information. Therefore, they prove that such a system can enhance the exploratory power of a search engine and support the proactive information search.",2014,Conference on Information and Knowledge Management,ranking;web search query;web query classification;query expansion;query optimization;query language;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Scalable Vaccine Distribution in Large Graphs given Uncertain Data,Yao Zhang (Virginia Tech);B. Aditya Prakash (Virginia Tech);,"2293580633,2124002246","Given an noisy or sampled snapshot of a network, like a contact-network or the blogosphere, in which an infection (or meme/virus) has been spreading for some time, what are the best nodes to immunize (vaccinate)? Manipulating graphs via node removal by itself is an important problem in multiple different domains like epidemiology, public health and social media. Moreover, it is important to account for uncertainty as typically surveillance data on who is infected is limited or the data is sampled. Efficient algorithms for such a problem can help public-health experts take more informed decisions. In this paper, we study the problem of designing vaccine-distribution algorithms under an uncertain environment, with known information consisting of confirmed cases as well as a probability distribution of unknown cases. We formulate the NP-Hard Uncertain Data-Aware Vaccination problem, and design multiple efficient algorithms for factorizable distributions (including a novel sub-quadratic algorithm) which naturally take into account the uncertainty, while providing robust solutions. Finally, we show the effectiveness and scalability of our methods via extensive experiments on real datasets, including large epidemiological and social networks.",2014,Conference on Information and Knowledge Management,diffusion;uncertainty;theoretical computer science;data mining;database;artificial intelligence;machine learning;simulation;statistics;computer science;
A Bootstrapping Based Refinement Framework for Mining Opinion Words and Targets,Qiyun Zhao (Chinese Academy of Sciences);Hao Wang (Chinese Academy of Sciences);Pin Lv (Chinese Academy of Sciences);Chen Zhang (Chinese Academy of Sciences);,"2224617789,2594397125,2134718210,2592922597","This paper proposes a novel bootstrapping based framework jointed with automatic refinement to extract opinion words and targets. We employ a reasonable set of opinion seed words and pre-defined rules to start bootstrapping. We leverage statistical word co-occurrence and dependency patterns for propagation between opinion words and targets. A Sentiment Graph Model (SGM) is constructed to evaluate these opinion relations. Furthermore, we employ Automatic Rule Refinement (ARR) to refine the rules to extract false results. By using false results pruning and ARR process, we can efficiently alleviate the error propagation problem in traditional bootstrapping-based methods. Preliminary evaluation shows the effectiveness of our method.",2014,Conference on Information and Knowledge Management,bootstrapping;refinement;sentiment analysis;data mining;pattern recognition;machine learning;computer science;
Semantic Compositionality in Tree Kernels,Paolo Annesi;Danilo Croce (University of Rome Tor Vergata);Roberto Basili (University of Rome Tor Vergata);,"149560453,2167821181,1633289514","Kernel-based learning has been largely applied to semantic textual inference tasks. In particular, Tree Kernels (TKs) are crucial in the modeling of syntactic similarity between linguistic instances in Question Answering or Information Extraction tasks. At the same time, lexical semantic information has been studied through the adoption of the so-called Distributional Semantics (DS) paradigm, where lexical vectors are acquired automatically from large corpora. Notice how methods to account for compositional linguistic structures (e.g. grammatically typed bi-grams or complex verb or noun phrases) have been proposed recently by defining algebras on lexical vectors. The result is an extended paradigm called Distributional Compositional Semantics (DCS). Although lexical extensions have been already proposed to generalize TKs towards semantic phenomena (e.g. the predicate argument structures as for role labeling), currently studied TKs do not account for compositionality, in general. In this paper, a novel kernel called Compositionally Smoothed Partial Tree Kernel is proposed to integrate DCS operators into the tree kernel evaluation, by acting both over lexical leaves and non-terminal, i.e. complex compositional, nodes. The empirical results obtained on a Question Classification and Paraphrase Identification tasks show that state-of-the-art performances can be achieved, without resorting to manual feature engineering, thus suggesting that a large set of Web and text mining tasks can be handled successfully by the kernel proposed here.",2014,Conference on Information and Knowledge Management,tree kernel;natural language processing;data mining;database;artificial intelligence;machine learning;algorithm;computer science;
Multi-document Hyperedge-based Ranking for Text Summarization,Abdelghani Bellaachia (George Washington University);Mohammed Al-Dhelaan (George Washington University);,"231008878,1708280675","In a multi-document settings, graph-based extractive summarization approaches build a similarity graph out of sentences in each cluster of documents then use graph centrality approaches to measure the importance of sentences. The similarity is computed between each pair of sentences. However, it is not clear if such approach captures high-order relations among more than two sentences or can differentiate between descriptive sentences of the cluster in comparison with other clusters. In this paper, we propose to model sentences as hyperedges and words as vertices using a hypergraph and combine it with topic signatures to differentiate between descriptive sentences and non-descriptive sentences. To rank sentences, we propose a new random walk over hyperedges that will prefer descriptive sentences of the cluster when measuring their centrality scores. Our approach outperform a number of baseline in the DUC 2001 dataset using the ROUGE metric.",2014,Conference on Information and Knowledge Management,multi document summarization;automatic summarization;natural language processing;information retrieval;pattern recognition;computer science;
Scalable Distributed Belief Propagation with Prioritized Block Updates,Jiangtao Yin (University of Massachusetts Amherst);Lixin Gao (University of Massachusetts Amherst);,"2162592334,2251223525","Belief propagation (BP) is a popular method for performing approximate inference on probabilistic graphical models. However, its message updates are time-consuming, and the schedule for updating messages is crucial to its running time and even convergence. In this paper, we propose a new scheduling scheme that selects a set of messages to update at a time and leverages a novel priority to determine which messages are selected. Additionally, an incremental update approach is introduced to accelerate the computation of the priority. As the size of the model grows, it is desirable to leverage the parallelism of a cluster of machines to reduce the inference time. Therefore, we design a distributed framework, Prom, to facilitate the implementation of BP algorithms. We evaluate the proposed scheduling scheme (supported by Prom) via extensive experiments on a local cluster as well as the Amazon EC2 cloud. The evaluation results show that our scheduling scheme outperforms the state-of-the-art counterpart.",2014,Conference on Information and Knowledge Management,belief propagation;theoretical computer science;distributed computing;data mining;database;real time computing;machine learning;computer science;
Active Exploration in Networks: Using Probabilistic Relationships for Learning and Inference,Joseph John Pfeiffer (Purdue University);Jennifer Neville (Purdue University);Paul N. Bennett (Microsoft);,"2135459169,2124572662,2137013502","Many interesting domains in machine learning can be viewed as networks, with relationships (e.g., friendships) connecting items (e.g., individuals). The Active Exploration (AE) task is to identify all items in a network with a desired trait (i.e., positive labels) given only partial information about the network. The AE process iteratively queries for labels or network structure within a limited budget; thus, accurate predictions prior to making each query is critical to maximizing the number of positives gathered. However, the targeted AE query process produces partially observed networks that can create difficulties for predictive modeling. In particular, we demonstrate that these partial networks can exhibit extreme label correlation bias, which makes it difficult for conventional relational learning methods to accurately estimate relational parameters. To overcome this issue, we model the joint distribution of possible edges and labels to improve learning and inference. Our proposed method, Probabilistic Relational Expectation Maximization (PR-EM), is the first AE approach to accurately learn the complex dependencies between attributes, labels, and structure to improve predictions. PR-EM utilizes collective inference over the missing relationships in the partial network to jointly infer unknown item traits. Further, we develop a linear inference algorithm to facilitate efficient use of PR-EM in large networks. We test our approach on four real world networks, showing that AE with PR-EM gathers significantly more positive items compared to state-of-the-art methods.",2014,Conference on Information and Knowledge Management,statistical relational learning;data mining;artificial intelligence;machine learning;statistics;computer science;
SmartVenues: Recommending Popular and Personalised Venues in a City,Romain Deveaud (University of Glasgow);M-Dyaa Albakour (University of Glasgow);Jarana Manotumruksa (University of Glasgow);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"314381667,209705036,2232580914,2148910894,336997814","We present SmartVenues, a system that recommends nearby venues to a user who visits or lives in a city. SmartVenues models the variation over time of each venue's level of attendance, and uses state-of-the-art time series forecasting algorithms to predict the future attendance of these venues. We use the predicted levels of attendance to infer the popularity of a venue at future points in time, and to provide the user with recommendations at different times of the day. If the users log in with their Facebook account, the recommendations are personalised using the pages they ""like"". In this demonstrator, we detail the architecture of the system and the data that we collect in real-time to be able to perform the predictions. We also present two different interfaces that build upon our system to display the recommendations: a web-based application and a mobile application.",2014,Conference on Information and Knowledge Management,time series;multimedia;world wide web;data mining;statistics;
Predictability of Distrust with Interaction Data,Jiliang Tang (Arizona State University);Xia Hu (Arizona State University);Yi Chang (Yahoo!);Huan Liu (Arizona State University);,"2147392410,2161448330,2168000538,2122391114","Trust plays a crucial role in helping users collect reliable information in an online world, and has attracted more and more attention in research communities lately. As a conceptual counterpart of trust, distrust can be as important as trust. However, distrust is rarely studied in social media because distrust information is usually unavailable. The value of distrust has been widely recognized in social sciences and recent work shows that distrust can benefit various online applications in social media. In this work, we investigate whether we can obtain distrust information via learning when it is not directly available, and propose to study a novel problem - predicting distrust using pervasively available interaction data in an online world. In particular, we analyze interaction data, provide a principled way to mathematically incorporate interaction data in a novel framework dTrust to predict distrust information. Experimental results using real-world data show that distrust information is predictable with interaction data by the proposed framework dTrust. Further experiments are conducted to gain a deep understand on which factors contribute to the effectiveness of the proposed framework.",2014,Conference on Information and Knowledge Management,balance theory;data mining;
Building and Exploring Dynamic Topic Models on the Web,Michael Derntl (RWTH Aachen University);Nikou Günnemann (Carnegie Mellon University);Alexander Tillmann (RWTH Aachen University);Ralf Klamma (RWTH Aachen University);Matthias Jarke (RWTH Aachen University);,"1975168527,177157178,2659841162,292844567,251194211","Topic modeling is a machine learning technique that identifies latent topics in a text corpus. There are several existing tools that allow end-users to create and explore topic models using graphical user interfaces. In this paper, we present a visual analytics system for dynamic topic models that goes beyond the existing breed of tools. First, it decouples the Web-based user interface from the underlying data sets, enabling exploration of arbitrary text data sets in the Web browser. Second, it allows users to explore dynamic topic models, while existing tools are often limited to static topic models. Finally, it comes with a tool server in the backend that allows the design and execution of scientific workflows to build topic models from any data source. The system is demonstrated by building and exploring a dynamic topic model of CIKM proceedings published since 2001.",2014,Conference on Information and Knowledge Management,topic model;web crawler;visual analytics;text mining;data science;world wide web;information retrieval;data mining;database;machine learning;computer science;
WiiCluster: a Platform for Wikipedia Infobox Generation,"Kezun Zhang (Fudan University);Yanghua Xiao (Fudan University);Hanghang Tong (Arizona State University);Haixun Wang (Google);Wei Wang (University of California, Los Angeles);","2124160878,2131222654,2667261544,2116756368,2315689540","Wikipedia has become one of the best sources for creating and sharing a massive volume of human knowledge. Much effort has been devoted to generating and enriching the structured data by automatic information extraction from unstructured text in Wikipedia. Most, if not all, of the existing work share the same paradigm, that is, starting with information extraction over the unstructured text data, followed by supervised machine learning. Although remarkable progresses have been made, this paradigm has its own limitations in terms of effectiveness, scalability as well as the high labeling cost. We present WiiCluster, a scalable platform for automatically generating infobox for articles in Wikipedia. The heart of our system is an effective cluster-then-label algorithm over a rich set of semi-structured data in Wikipedia articles: linked entities . It is totally unsupervised and thus does not require any human label. It is effective in generating semantically meaningful summarization for Wikipedia articles. We further propose a cluster-reuse algorithm to scale up our system. Overall, our WiiCluster is able to generate nearly 10 million new facts. We also develop a web-based platform to demonstrate WiiCluster, which enables the users to access and browse the generated knowledge.",2014,Conference on Information and Knowledge Management,infobox;knowledge extraction;world wide web;information retrieval;data mining;database;computer science;
Time-Aware Rank Aggregation for Microblog Search,Shangsong Liang (University of Amsterdam);Zhaochun Ren (University of Amsterdam);Wouter Weerkamp (University of Amsterdam);Edgar Meij (Yahoo!);Maarten de Rijke (University of Amsterdam);,"2131113258,2158267603,197647246,2160283388,401833296","We tackle the problem of searching microblog posts and frame it as a rank aggregation problem where we merge result lists generated by separate rankers so as to produce a final ranking to be returned to the user. We propose a rank aggregation method, TimeRA, that is able to infer the rank scores of documents via latent factor modeling. It is time-aware and rewards posts that are published in or near a burst of posts that are ranked highly in many of the lists being aggregated. Our experimental results show that it significantly outperforms state-of-the-art rank aggregation and time-sensitive microblog search algorithms.",2014,Conference on Information and Knowledge Management,sensor fusion;world wide web;information retrieval;data mining;computer science;
On Independence Atoms and Keys,Miika Hannula (University of Helsinki);Juha Kontinen (University of Helsinki);Sebastian Link (University of Auckland);,"2165948178,1974601026,2095647292","Uniqueness and independence are two fundamental properties of data. Their enforcement in knowledge systems can lead to higher quality data, faster data service response time, better data-driven decision making and knowledge discovery from data. The applications can be effectively unlocked by providing efficient solutions to the underlying implication problems of keys and independence atoms. Indeed, for the sole class of keys and the sole class of independence atoms the associated finite and general implication problems coincide and enjoy simple axiomatizations. However, the situation changes drastically when keys and independence atoms are combined. We show that the finite and the general implication problems are already different for keys and unary independence atoms. Furthermore, we establish a finite axiomatization for the general implication problem, and show that the finite implication problem does not enjoy a k-ary axiomatization for any k.",2014,Conference on Information and Knowledge Management,key;independence;technical report;world wide web;statistics;algorithm;computer science;
Rubato DB: A Highly Scalable Staged Grid Database System for OLTP and Big Data Applications,Li-Yan Yuan (University of Alberta);Lengdong Wu (University of Alberta);Jia-Huai You (University of Alberta);Yan Chi;,"2251000736,2148759304,2100595540,2582657811","This paper proposes a new formula protocol for distributed concurrency control, and specifies a staged grid architecture for highly scalable database management systems. The paper also describes novel implementation techniques of Rubato DB based on the proposed protocol and architecture. We have conducted extensive experiments which clearly show that Rubato DB is highly scalable with efficient performance under both TPC-C and YCSB benchmarks. Our paper verifies that the formula protocol and the staged grid architecture provide a satisfactory solution to one of the important challenges in the database systems: to develop a highly scalable database management system that supports various consistency levels from ACID to BASE.",2014,Conference on Information and Knowledge Management,acid;concurrency control;parallel computing;database;real time computing;computer science;
Solving Linear SVMs with Multiple 1D Projections,Johannes Schneider (ABB Ltd);Jasmina Bogojeska (IBM);Michail Vlachos (IBM);,"2306252458,317490117,2146138755","We present a new methodology for solving linear Support Vector Machines (SVMs) that capitalizes on multiple 1D projections. We show that the approach approximates the optimal solution with high accuracy and comes with analytical guarantees. Our solution adapts on methodologies from random projections, exponential search, and coordinate descent. In our experimental evaluation, we compare our approach with the popular liblinear SVM library. We demonstrate a significant speedup on various benchmarks. At the same time, the new methodology provides a comparable or better approximation factor of the optimal solution and exhibits smooth convergence properties. Our results are accompanied by bounds on the time complexity and accuracy.",2014,Conference on Information and Knowledge Management,coordinate descent;biological classification;data mining;pattern recognition;machine learning;mathematical optimization;computer science;
Controllable Information Sharing for User Accounts Linkage across Multiple Online Social Networks,Yilin Shen (Samsung);Hongxia Jin (Samsung);,"2228306107,2707082889","People have multiple accounts on Online Social Networks (OSNs) for various purposes. It is of great interest for third parties to collect more users' information by linking their accounts on different OSNs. Unfortunately, most users have not been aware of potential risks of such accounts linkage. Therefore, the design of a control methodology that allows users to share their information without the risk of being linked becomes an urgent need, yet still remains open. In this paper, we first aim to raise the users' awareness by presenting an effective User Accounts Linkage Inference (UALI), which is shown to be more powerful to users than existing methods. In order to help users control the risks of UALI, we next propose the first Information Control Mechanism (ICM), in which users' information is still visible as intended and, in the meanwhile, the risk of their accounts linkage can be controlled. Using real-world datasets, the performance of ICM is validated, and we also show that it works well for various linkage inference approaches. Both UALI and ICM approaches, designed to take generic inputs, extend their ability to be widely applied into many practical social services.",2014,Conference on Information and Knowledge Management,world wide web;data mining;database;simulation;computer science;
Size and Source Matter: Understanding Inconsistencies in Test Collection-Based Evaluation,Timothy Jones (RMIT University);Andrew Turpin (University of Melbourne);Stefano Mizzaro (University of Udine);Falk Scholer (RMIT University);Mark Sanderson (RMIT University);,"2708624362,2079334450,156657161,1970689224,2704667184","Past work showed that significant inconsistencies between retrieval results occurred on different test collections, even when one of the test collections contained only a subset of the documents in the other. However, the experimental methodologies in that paper made it hard to determine the cause of the inconsistencies. Using a novel methodology that eliminates the problems with uneven distribution of relevant documents, we confirm that observing a statistically significant improvement between two IR systems can be strongly influenced by the choice of documents in the test collection. We investigate two possible causes of this problem of test collections. Our results show that collection size and document source have a strong influence in the way that a test collection will rank one retrieval system relative to another. This is of particular interest when constructing test collections, as we show that using different subsets of a collection produces differing evaluation results.",2014,Conference on Information and Knowledge Management,evaluation;world wide web;information retrieval;data mining;computer science;
How People Use the Web in Large Indoor Spaces,Yongli Ren (RMIT University);Martin Tomko (University of Melbourne);Kevin Ong (RMIT University);Mark Sanderson (RMIT University);,"2128272737,2093441474,2480409620,2704667184","We report a preliminary study of mobile Web behaviour in a large indoor retail space. By analysing a Web log collected over a 1 year period at an inner city shopping mall in Sydney, Australia, we found that 1) around 60% of registered Wi-Fi users actively browse the Internet, and the rest 40% do not, with around 10% of these users using Web search engines. Around 70% of this Web activity in the investigated mall come from frequent visitors; 2) the content that indoor users search for is different from the content they consume while browsing; 3) the popularity of future indoor search queries can be predicted with a simple theoretical model based on past queries treated as a weighted directed graph. The work described in this paper underpins applications such as the prediction of users' information needs, retail recommendation systems, and improving the mobile Web search experience.",2014,Conference on Information and Knowledge Management,mobile search;web query classification;web navigation;multimedia;world wide web;computer science;
On Efficient Meta-Level Features for Effective Text Classification,Sérgio D. Canuto (Universidade Federal de Minas Gerais);Thiago Salles (Universidade Federal de Minas Gerais);Marcos André Gonçalves (Universidade Federal de Minas Gerais);Leonardo C. da Rocha (Universidade Federal de Minas Gerais);Gabriel Spada Ramos (Universidade Federal de São João del-Rei);Luiz Gonçalves (Universidade Federal de Minas Gerais);Thierson Couto Rosa (Francisco Gavidia University);Wellington Santos Martins (Universidade Federal de Goiás);,"2027273974,1989698489,2115586749,2175269910,2118839055,2163774020,2385084868,2140379218","This paper addresses the problem of automatically learning to classify texts by exploiting information derived from meta-level features (i.e., features derived from the original bag-of-words representation). We propose new meta-level features derived from the class distribution, the entropy and the within-class cohesion observed in the k nearest neighbors of a given test document x, as well as from the distribution of distances of x to these neighbors. The set of proposed features is capable of transforming the original feature space into a new one, potentially smaller and more informed. Experiments performed with several standard datasets demonstrate that the effectiveness of the proposed meta-level features is not only much superior than the traditional bag-of-word representation but also superior to other state-of-art meta-level features previously proposed in the literature. Moreover, the proposed meta-features can be computed about three times faster than the existing meta-level ones, making our proposal much more scalable. We also demonstrate that the combination of our meta features and the original set of features produce significant improvements when compared to each feature set used in isolation.",2014,Conference on Information and Knowledge Management,information retrieval;data mining;pattern recognition;machine learning;computer science;
Exploring Document Collections with Topic Frames,Alexander Hinneburg (Martin Luther University of Halle-Wittenberg);Frank Rosner (Martin Luther University of Halle-Wittenberg);Stefan Pessler (Martin Luther University of Halle-Wittenberg);Christian Oberländer (Martin Luther University of Halle-Wittenberg);,"293376274,2123779610,2225413172,2232079374","Topics automatically derived by topic models are not always easy and clearly interpretable by humans. The most probable top words of a topic may leave room for ambiguous interpretations, especially when the top words are exclusively nouns. We demonstrate how part-of-speech (POS) tagging and co-location analysis of terms can be used to derive linguistic frames that yield more interpretable topic representations. The so-called topic frames are demonstrated as feature of the TopicExplorer system that allows to explore document collections using topic models, visualizations and key word search. Demo versions of TopicExplorer are available at http://topicexplorer.informatik.uni-halle.de/ .",2014,Conference on Information and Knowledge Management,topic model;visualization;document clustering;natural language processing;world wide web;information retrieval;machine learning;computer science;
Nonlinear Classification via Linear SVMs and Multi-Task Learning,Xue Mao (Chinese Academy of Sciences);Ou Wu (Chinese Academy of Sciences);Weiming Hu (Chinese Academy of Sciences);Peter O'Donovan (University of Toronto);,"2619899313,2682198127,2124189993,2582363340","Kernel SVM is prohibitively expensive when dealing with large nonlinear data. While ensembles of linear classifiers have been proposed to address this inefficiency, these methods are time-consuming or lack robustness. We propose an efficient classifier for nonlinear data using a new iterative learning algorithm, which partitions the data into clusters, and then trains a linear SVM for each cluster. These two steps are combined into a graphical model, with the parameters estimated efficiently using the EM algorithm. During training, clustered multi-task learning is used to capture the relatedness among the multiple linear SVMs and avoid overfitting. Experimental results on benchmark datasets show that our method outperforms state-of-the-art methods. During prediction, it also obtains comparable classification performance to kernel SVM, with much higher efficiency.",2014,Conference on Information and Knowledge Management,multi task learning;linear classifier;biological classification;data mining;pattern recognition;machine learning;computer science;
TensorDB: In-Database Tensor Manipulation with Tensor-Relational Query Plans,Mijung Kim (Arizona State University);K. Selçuk Candan (Arizona State University);,"2129489018,674992784","Today's data management systems increasingly need to support both tensor-algebraic operations (for analysis) as well as relational-algebraic operations (for data manipulation and integration). Tensor decomposition techniques are commonly used for discovering underlying structures of multi-dimensional data sets. However, as the relevant data sets get large, existing in-memory schemes for tensor decomposition become increasingly ineffective and, instead, memory-independent solutions, such as in-database analytics, are necessitated. We introduce an in-database analytic system for efficient implementations of in-database tensor decompositions on chunk-based array data stores, so called, TensorDB. TensorDB includes static in-database tensor decomposition and dynamic in-database tensor decomposition operators. TensorDB extends an array database and leverages array operations for data manipulation and integration. TensorDB supports complex data processing plans where multiple relational algebraic and tensor algebraic operations are composed with each other.",2014,Conference on Information and Knowledge Management,tensor;multilinear subspace learning;theoretical computer science;data mining;computer science;
Cleanix: A Big Data Cleaning Parfait,"Hongzhi Wang (Harbin Institute of Technology);Mingda Li (Harbin Institute of Technology);Yingyi Bu (University of California, Irvine);Jianzhong Li (Harbin Institute of Technology);Hong Gao (Harbin Institute of Technology);Jiacheng Zhang (Harbin Institute of Technology);","2589657406,2435036128,2666781946,2130201582,2607637236,2628695146","In this demo, we present Cleanix, a prototype system for cleaning relational Big Data. Cleanix takes data integrated from multiple data sources and cleans them on a shared-nothing machine cluster. The backend system is built on-top-of an extensible and flexible data-parallel substrate - the Hyracks framework. Cleanix supports various data cleaning tasks such as abnormal value detection and correction, incomplete data filling, de-duplication, and conflict resolution. We demonstrate that Cleanix is a practical tool that supports effective and efficient data cleaning at the large scale.",2014,Conference on Information and Knowledge Management,data quality;big data;data science;data mining;database;computer science;
Effect of Intent Descriptions on Retrieval Evaluation,Emine Yilmaz (University College London);Evangelos Kanoulas (Google);Nick Craswell (Microsoft);,"2342836604,2709998967,2009495402","Test collections play an important role in adhoc and diversity retrieval evaluation. Constructing a test collection for adhoc evaluation involves (1) selecting a set of queries to be judged, (2) selecting an intent (topic) description for that query, and (3) obtaining relevance judgments with respect to the specific intent description for that particular query. Recent work showed that the selection of intents play an important role in the relative performance of retrieval systems for diversity evaluation. However, no previous work has analysed how the choice of a specific intent description may affect adhoc evaluation. We show that intent descriptions have a significant impact in adhoc evaluation and that special care should be given as to how the intent descriptions are selected. We further show that it is better to have very general intent descriptions or no intent descriptions at all when constructing test collections for adhoc evaluation. We then focus on diversity evaluation and identify the effect intent descriptions have on diversity based retrieval evaluation. We quantify this effect and discuss experimental design decisions for the optimal distribution of judgment effort across different intents for a query vs. different queries.",2014,Conference on Information and Knowledge Management,mixed model;evaluation;world wide web;information retrieval;data mining;database;statistics;computer science;
Knowledge Management for Keyword Search over Data Graphs,Yosi Mass (IBM);Yehoshua Sagiv (Hebrew University of Jerusalem);,"2117117435,734152518","This demo presents exploratory keyword search over data graphs by means of semantic facets. The demo starts with a keyword search over data graphs. Answers are first ranked by an existing search engine that considers their textual relevance and semantic structure. The user can then explore the answers through facets of structural patterns (i.e., schemas) as well as through other features. A particular way of presenting answers in a compact form is also supported and is applicable when looking for a single entity that connects the keywords. The demo is based on a working prototype that users can try on their own. It includes five data graphs that are quite diversified. In particular, three of them were generated from relational databases and two - from RDF triples. The demo shows that the system enables users to easily and quickly perform various search tasks by means of exploration, filtering and summarization.",2014,Conference on Information and Knowledge Management,semantic search;world wide web;information retrieval;data mining;database;computer science;
Generalized Bias-Variance Evaluation of TREC Participated Systems,Peng Zhang (Tianjin University);Linxue Hao (Tianjin University);Dawei Song (Tianjin University);Jun Wang (University College London);Yuexian Hou (Tianjin University);Bin Hu (Lanzhou University);,"2670383678,2222192345,2113829419,2557836567,2112843352,2706369549","Recent research has shown that the improvement of mean retrieval effectiveness (e.g., MAP) may sacrifice the retrieval stability across queries, implying a tradeoff between effectiveness and stability. The evaluation of both effectiveness and stability are often based on a baseline model, which could be weak or biased. In addition, the effectiveness-stability tradeoff has not been systematically or quantitatively evaluated over TREC participated systems. The above two problems, to some extent, limit our awareness of such tradeoff and its impact on developing future IR models. In this paper, motivated by a recently proposed bias-variance based evaluation, we adopt a strong and unbiased ""baseline"", which is a virtual target model constructed by the best performance (for each query) among all the participated systems in a retrieval task. We also propose generalized bias-variance metrics, based on which a systematic and quantitative evaluation of the effectiveness-stability tradeoff is carried out over the participated systems in the TREC Ad-hoc Track (1993-1999) and Web Track (2010-2012). We observe a clear effectiveness-stability tradeoff, with a trend of becoming more obvious in more recent years. This implies that when we pursue more effective IR systems over years, the stability has become problematic and could have been largely overlooked.",2014,Conference on Information and Knowledge Management,evaluation;stability;world wide web;information retrieval;data mining;simulation;statistics;computer science;
RecLand: A Recommender System for Social Networks,Ryadh Dahimene (Conservatoire national des arts et métiers);Camelia Constantin (Pierre-and-Marie-Curie University);Cédric du Mouza (Conservatoire national des arts et métiers);,"33123579,2108556048,369600110","Social networks have become an important information source. Due to their unprecedented success, these systems have to face an exponentially increasing amount of user generated content. As a consequence, finding relevant users or data matching specific interests is a challenging. We present RecLand, a recommender system that takes advantage of the social graph topology and of the existing contextual information to recommend users. The graphical interface of RecLand shows recommendations that match the topical interests of users and allows to tune the parameters to adapt the recommendations to their needs.",2014,Conference on Information and Knowledge Management,social network;world wide web;data mining;artificial intelligence;computer science;
"Fast, Accurate, and Space-efficient Tracking of Time-weighted Frequent Items from Data Streams",Yongsub Lim (KAIST);Jihoon Choi;U. Kang (KAIST);,"2118432040,2431605362,2615132872","How can we discover interesting patterns from time-evolving high speed data streams? How to analyze the data streams quickly and accurately, with little space overhead? High speed data stream has been receiving increasing attentions due to its wide applications such as sensors, network traffic, social networks, etc. One of the most fundamental tasks in the data stream is to find frequent items; especially, finding recently frequent items has become important in real world applications. In this paper, we propose TwMinSwap , a fast, accurate, and space-efficient method for tracking recent frequent items. TwMinSwap is a deterministic version of our motivating algorithm TwSample which is a sampling based randomized algorithm with nice theoretical guarantees. TwMinSwap improves TwSample in terms of speed, accuracy, and memory usage. Both require only O(k) memory spaces, and do not require any prior knowledge on the stream such as its length and the number of distinct items in the stream. Through extensive experiments, we demonstrate that TwMinSwap outperforms all competitors in terms of accuracy and memory usage, with fast running time. Thanks to TwMinSwap , we report interesting discoveries in real world data streams, including the difference of trends between the winner and the loser of U.S. presidential candidates, and doubly-active patterns of movies.",2014,Conference on Information and Knowledge Management,sampling;world wide web;data mining;database;statistics;computer science;
Efficient Probabilistic Supergraph Search Over Large Uncertain Graphs,Yongxin Tong (Hong Kong University of Science and Technology);Xiaofei Zhang (Hong Kong University of Science and Technology);Caleb Chen Cao (Hong Kong University of Science and Technology);Lei Chen (Hong Kong University of Science and Technology);,"2114386387,2102579599,2136041333,2318776917","In recent years, with the emergence of a number of new real applications, such as protein-protein interaction (PPI) networks, visual pattern recognition, and intelligent traffic systems, managing huge volumes of uncertain graphs has attracted much attention in the database community. Currently, most existing fundamental queries over graphs only support deterministic (or certain) graphs, although real graph data are often noisy, inaccurate, and incomplete. In this paper, we study a new type of uncertain graph query, probabilistic supergraph containment query over large uncertain graphs. Specifically, given an uncertain graph database UGD which contains a set of uncertain graphs, a deterministic query graph q , and a probabilistic threshold δ, a probabilistic supergraph containment query is to find the set of uncertain graphs from UGD , denoted as UGD q , such that UGD q ={ug i ∈ UGD | Pr ( ug i ⊆ q )≥δ} where Pr ( ug i ⊆ q ) means the likelihood that ug i is a subgraph of q . We prove that the computation of Pr ( ug i ⊆ q ) is #P-hard and design an efficient filtering-and-verification framework to avoid the expensive computation. In particular, we propose an effective filtering strategy and a novel probabilistic inverted index, called PS-Index , to enhance pruning power in the filtering phase. Furthermore, the candidate graphs which pass the filtering phase are tested in the verification phase via an efficient unequal probability sampling-based approximation algorithm. Finally, we verify the effectiveness and efficiency of the proposed methods through extensive experiments.",2014,Conference on Information and Knowledge Management,indifference graph;chordal graph;theoretical computer science;data mining;database;machine learning;
CONDOR: A System for CONstraint DiscOvery and Repair,Joshua Segeren (McMaster University);Dhruv Gairola (McMaster University);Fei Chiang (McMaster University);,"2231618646,2060800546,2106014425","We present CONDOR, a tool for managing constraints towards improved data quality. As increasing amounts of heterogeneous data are being generated, integrity constraints are the primary tool for enforcing data integrity. It is essential that an accurate and up-to-date set of constraints exist to validate that the correct application semantics are being enforced. We consider the widely used constraint, functional dependencies (FDs). CONDOR is an integrated system that identifies inconsistent data values (along with suggestions for clean values), and generates repairs to both the data and/or FDs to resolve inconsistencies. We extend the set of FD repair operations proposed in past work, by (1) adding a set of attributes to an FD; (2) transforming an FD to a conditional functional dependency (CFD); and (3) identifying redundant attributes in an FD. Our demonstration will showcase the visualization and interactive features of CONDOR to help users determine the best repairs that resolve the underlying inconsistencies to improve data quality.",2014,Conference on Information and Knowledge Management,data quality;data mining;database;computer science;
Query Performance Prediction for Aspect Weighting in Search Result Diversification,Ahmet Murat Ozdemiray (Middle East Technical University);Ismail Sengor Altingovde (Middle East Technical University);,"114316977,686977125","Accurate estimation of query aspect weights is an important issue to improve the performance of explicit search result diversification algorithms. For the first time in the literature, we propose using post-retrieval query performance predictors (QPPs) to estimate, for each aspect, the retrieval effectiveness on the candidate document set, and leverage these estimations to set the aspect weights. In addition to utilizing well-known QPPs from the literature, we also introduce three new QPPs that are based on score distributions and hence, can be employed for online query processing in real-life search engines. Our exhaustive experiments reveal that using QPPs for aspect weighting improves almost all state-of-the-art diversification algorithms in comparison to using a uniform weight estimator. Furthermore, the proposed QPPs are comparable or superior to the existing predictors in the context of aspect weighting.",2014,Conference on Information and Knowledge Management,diversification;information retrieval;data mining;pattern recognition;computer science;
INK: A Cloud-Based System for Efficient Top-k Interval Keyword Search,Rui Li (Renmin University of China);Xiao Zhang (Renmin University of China);Xin Zhou (Renmin University of China);Shan Wang (Renmin University of China);,"2428673222,2585789023,2425468966,2131088066","It is insufficient to search temporal text by only focusing on either time attribute or keywords today as we pay close attention to the evolution of event with time. Both temporal and textual constraints need to be considered in one single query, called Top-k Interval Keyword Query (TIKQ ).In this paper, we presents a cloud-based system named INK that supports efficient execution of TIKQs with appropriate effectiveness on Hadoop and HBase. In INK, an Adaptive Index Selector (AIS) is devised to choose the better execution plan for various TIKQs adaptively based on the proposed cost model, and leverage two novel hybrid index modules (TriI and IS-Tree) to combine keyword and interval filtration seamlessly.",2014,Conference on Information and Knowledge Management,keyword density;information retrieval;data mining;database;computer science;
Modelling Relevance towards Multiple Inclusion Criteria when Ranking Patients.,Nut Limsopatham (University of Glasgow);Craig Macdonald (University of Glasgow);Iadh Ounis (University of Glasgow);,"184570117,2148910894,336997814","In the medical domain, information retrieval systems can be used for identifying cohorts (i.e. patients) required for clinical studies. However, a challenge faced by such search systems is to retrieve the cohorts whose medical histories cover the inclusion criteria specified in a query, which are often complex and include multiple medical conditions. For example, a query may aim to find patients with both 'lupus nephritis' and 'thrombotic thrombocytopenic purpura'. In a typical best-match retrieval setting, any patient exhibiting all of the inclusion criteria should naturally be ranked higher than a patient that only exhibits a subset, or none, of the criteria. In this work, we extend the two main existing models for ranking patients to take into account the coverage of the inclusion criteria by adapting techniques from recent research into coverage-based diversification. We propose a novel approach for modelling the coverage of the query inclusion criteria within the records of a particular patient, and thereby rank highly those patients whose medical records are likely to cover all of the specified criteria. In particular, our proposed approach estimates the relevance of a patient, based on the mixture of the probability that the patient is retrieved by a patient ranking model for a given query, and the likelihood that the patient's records cover the query criteria. The latter is measured using the relevance towards each of the criteria stated in the query, represented in the form of sub-queries. We thoroughly evaluate our proposed approach using the test collection provided by the TREC 2011 and 2012 Medical Records track. Our results show significant improvements over existing strong baselines.",2014,Conference on Information and Knowledge Management,ranking;information retrieval;data mining;database;computer science;
Templated Search over Relational Databases,"Anastasios Zouzias (IBM);Michail Vlachos (IBM);Vagelis Hristidis (University of California, Riverside);","2697697100,2146138755,238786035","Businesses and large organizations accumulate increasingly large amounts of customer interaction data. Analysis of such data holds great importance for tasks such as strategic planning and orchestration of sales/marketing campaigns. However, discovery and analysis over heterogeneous enterprise data can be challenging. Primary reasons for this are dispersed data repositories, requirements for schema knowledge, and difficulties in using complex user interfaces. As a solution to the above, we propose a TEmplated Search paradigm (TES) for exploring relational data that combines the advantages of keyword search interfaces with the expressive power of question-answering systems. The user starts typing a few keywords and TES proposes data exploration questions in real time. A key aspect of our approach is that the questions displayed are diverse to each other and optimally cover the space of possible questions for a given question-ranking framework. Efficient exact and provably approximate algorithms are presented. We show that the Templated Search paradigm renders the potentially complex underlying data sources intelligible and easily navigable. We support our claims with experimental results on real-world enterprise data.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Compact Auxiliary Dictionaries for Incremental Compression of Large Repositories,Jiancong Tong (Nankai University);Anthony Wirth (University of Melbourne);Justin Zobel (University of Melbourne);,"2106974030,2091550662,2019828590","Compression is widely exploited in retrieval systems, such as search engines and text databases, to lower both retrieval costs and system latency. In particular, compression of repositories can reduce storage requirements and fetch times, while improving caching. One of the most effective techniques is relative Lempel-Ziv, RLZ, in which a RAM-resident dictionary encodes the collection. With RLZ, a specified document can be decoded independently and extremely fast, while maintaining a high compression ratio. For terabyte-scale collections, this dictionary need only be a fraction of a per cent of the original data size. However, as originally described, RLZ uses a static dictionary, against which encoding of new data may be inefficient. An obvious alternative is to generate a new dictionary solely from the new data. However, this approach may not be scalable because the combined RAM-resident dictionary will grow in proportion to the collection. In this paper, we describe effective techniques for extending the original dictionary to manage new data. With these techniques, a new auxiliary dictionary, relatively limited in size, is created by interrogating the original dictionary with the new data. Then, to compress this new data, we combine the auxiliary dictionary with some parts of the original dictionary (the latter in fact encoded as pointers into that original dictionary) to form a second dictionary. Our results show that excellent compression is available with only small auxiliary dictionaries, so that RLZ can feasibly transmit and store large, growing collections.",2014,Conference on Information and Knowledge Management,incremental encoding;dictionary coder;k svd;encoding;document retrieval;world wide web;information retrieval;data mining;database;computer science;
Component Detection in Directed Networks,Yu-Keng Shih (American Express);Sungmin Kim (Google);Yiye Ruan (Ohio State University);Jinxing Cheng (Walmart Labs);Abhishek Gattani (Walmart Labs);Tao Shi (Ohio State University);Srinivasan Parthasarathy (Ohio State University);,"2305131738,2653024683,2145305802,2136512647,2090425178,2655782989,2106796124","Community detection has been one of the fundamental problems in network analysis. Results from community detection (for example, grouping of products by latent category) can also serve as information nuggets to other business applications, such as product recommendation or taxonomy building. Because several real networks are naturally directed, e.g. World Wide Web, some recent studies proposed algorithms for detecting various types of communities in a directed network. However, few of them considered that nodes play two different roles, source and terminal, in a directed network. In this paper, we adopt a novel concept of communities, directional community , and propose a new algorithm based on Markov Clustering to detect directional communities. We then first compare our algorithm, Dual R-MCL, on synthetic networks with two recent algorithms also designed for detecting directional communities. We show that Dual R-MCL can detect directional communities with significantly higher accuracy and 3x to 25x faster than the two other algorithms. Second, we compare a set of directed network community detection algorithms on a one-day Twitter interaction network and demonstrate that Dual R-MCL can generate clusters more correctly matched to hashtags. Finally, we exhibit our algorithm's capacity to identify directional communities from product description networks, where nodes are otherwise not directly connected. Results indicate that directional communities exist in real networks, and Dual R-MCL can effectively detect these directional communities. We believe it will enable the discovery of interesting components in a diverse types of networks where existing methods cannot, and it manifests strong application values.",2014,Conference on Information and Knowledge Management,cluster analysis;world wide web;data mining;machine learning;computer science;
Deal or deceit: detecting cheating in distribution channels,Kai Shu (Chinese Academy of Sciences);Ping Luo (Chinese Academy of Sciences);Wan Li (Chongqing University);Peifeng Yin (Pennsylvania State University);Linpeng Tang (Princeton University);,"2651096631,2291210646,2680853845,2113084173,2119198671","Distribution channel is a system that partners move products from manufacturer to end users. To increase sales, it is quite common for manufacturers to adjust the product prices to partners according to the product volume per deal. However, the price adjustment is like a double-edged sword. It also spurs some partners to form a cheating alliance, where a cheating seller applies for a falsified big deal with a low price and then re-sells the products to the cheating buyers . Since these cheating behaviors are harmful to a healthy ecosystem of distribution channel, we need the automatic method to guide the tedious audit process. Thus, in this study we propose the method to rank all partners by the degree of cheating, either as seller or buyer. It is mainly motivated by the observation that the sales volumes of a cheating seller and its corresponding cheating buyer are often negatively correlated with each other. Specifically, the proposed framework consists of three parts: 1) an asymmetric correlation measure which is needed to distinguish cheating sellers from cheating buyers; 2) a systematic approach which is needed to remove false positive pairs, i.e., two partners whose sale correlation is purely coincident; 3) finally, a probabilistic model to measure the degree of cheating behaviors for each partner. Based on the 4-year channel data of an IT company we empirically show how the proposed method outperforms the other baseline ones. It is worth mentioning that with the proposed unsupervised method more than half of the partners in the resultant top-30 ranking list are true cheating partners.",2014,Conference on Information and Knowledge Management,time series;computer security;statistics;
Entity Oriented Task Extraction from Query Logs,Manisha Verma (University College London);Emine Yilmaz (University College London);,"2289163828,2342836604","Identifying user tasks from query logs has garnered considerable interest from the research community lately. Several approaches have been proposed to extract tasks from search sessions. Current approaches segment a user session into disjoint tasks using features extracted from query, session or clicked document text. However, user tasks most often than not are entity centric and text based features will not exploit entities directly for task extraction. In this work, we explore entity specific task extraction from search logs. We evaluate the quality of extracted tasks with Session track data. Empirical evaluation shows that terms associated with entity oriented tasks can not only be used to predict terms in user sessions but also improve retrieval when used for query expansion.",2014,Conference on Information and Knowledge Management,web search query;web query classification;query expansion;world wide web;information retrieval;data mining;database;computer science;
Computing Multi-Relational Sufficient Statistics for Large Databases,Zhensong Qian (Simon Fraser University);Oliver Schulte (Simon Fraser University);Yan Lindsay Sun (Simon Fraser University);,"2114496380,1896956012,2429465879","Databases contain information about which relationships do and do not hold among entities. To make this information accessible for statistical analysis requires computing sufficient statistics that combine information from different database tables. Such statistics may involve any number of positive and negative relationships. With a naive enumeration approach, computing sufficient statistics for negative relationships is feasible only for small databases. We solve this problem with a new dynamic programming algorithm that performs a virtual join, where the requisite counts are computed without materializing join tables. Contingency table algebra is a new extension of relational algebra, that facilitates the efficient implementation of this Moobius virtual join operation. The Mobius Join scales to large datasets (over 1M tuples) with complex schemas. Empirical evaluation with seven benchmark datasets showed that information about the presence and absence of links can be exploited in feature selection, association rule mining, and Bayesian network learning.",2014,Conference on Information and Knowledge Management,recursive join;sort merge join;hash join;relational algebra;sufficient statistic;theoretical computer science;data mining;database;machine learning;computer science;mathematics;
High Impact Academic Paper Prediction Using Temporal and Topological Features,Feruz Davletov (Istanbul Şehir University);Ali Selman Aydin (Istanbul Şehir University);Ali Cakmak (Istanbul Şehir University);,"2222741030,2302995590,2688318500","Predicting promising academic papers is useful for a variety of parties, including researchers, universities, scientific councils, and policymakers. Researchers may benefit from such data to narrow down their reading list and focus on what will be important, and policymakers may use predictions to infer rising fields for a more strategic distribution of resources. This paper proposes a novel technique to predict a paper's future impact (i.e., number of citations) by using temporal and topological features derived from citation networks. We use a behavioral modeling approach in which the temporal change in the number of citations a paper gets is clustered, and new papers are evaluated accordingly. Then, within each cluster, we model the impact prediction as a regression problem where the objective is to predict the number of citations that a paper will get in the near or far future, given the early citation performance of the paper. The results of empirical evaluations on data from several well-known citation databases show that the proposed framework performs significantly better than the state of the art approaches.",2014,Conference on Information and Knowledge Management,network analysis;regression;cluster analysis;time series;data science;operations research;world wide web;information retrieval;data mining;artificial intelligence;machine learning;statistics;computer science;
Ranking Optimization with Constraints,Fangzhao Wu (Tsinghua University);Jun Xu (Huawei);Hang Li (Huawei);Xin Jiang (Huawei);,"2142281011,2598177019,2128739099,2617925750","This paper addresses the problem of post-processing of ranking in search, referred to as post ranking. Although important, no research seems to have been conducted on the problem, particularly with a principled approach, and in practice ad-hoc ways of performing the task are being adopted. This paper formalizes the problem as constrained optimization in which the constraints represent the post-processing rules and the objective function represents the trade-off between adherence to the original ranking and satisfaction of the rules. The optimization amounts to refining the original ranking result based on the rules. We further propose a specific probabilistic implementation of the general formalization on the basis of the Bradley-Terry model, which is theoretically sound, effective, and efficient. Our experimental results, using benchmark datasets and enterprise search dataset, show that the proposed method works much better than several baseline methods of utilizing rules.",2014,Conference on Information and Knowledge Management,ranking;ranking svm;data science;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
A Flexible Framework for Projecting Heterogeneous Data,"Aubrey Gress (University of California, Davis);Ian Davidson (University of California, Davis);","2226299968,2560595684","In many real world settings the data to analyze is heterogeneous consisting of (say) images, text and video. An elegant approach when dealing with such data is to project all the data to a common space so standard learning methods can be used. However, typical projection methods make strong assumptions such as the multi-view assumption (datum in one data set are always associated with a single datum in the other view) or that the multiple data sets have an overlapping feature space. Such strong assumptions limit what data such work can be applied to. We present a framework for projecting heterogeneous data from multiple data sets into a common lower dimensional space using a rich range of guidance which does not assume any overlap between the instances or features in different data sets. Our work can specify inter-dataset (between instances in different data sets) guidance and intra-dataset (between instances in the same data set) guidance, both of which can be positively or negatively weighted. We show our work offers substantially more flexibility over related methods such as Canonical Correlation Analysis (CCA) and Locality Preserving Projections (LPP) and illustrate its superior performance for supervised and unsupervised learning problems.",2014,Conference on Information and Knowledge Management,spectral method;dimensionality reduction;theoretical computer science;data mining;machine learning;statistics;computer science;
VFDS: An Application to Generate Fast Sample Databases,Teodora Sandra Buda (University College Dublin);Thomas Cerqueus (University College Dublin);John Murphy (University College Dublin);Morten Kristiansen (IBM);,"2067941110,2480801759,2087471959,2159489719","Large amounts of data often require expensive and time-consuming analysis. Therefore, highly scalable and efficient techniques are necessary to process, analyze and discover useful information. Database sampling has proven to be a powerful method to surpass these limitations. Using only a sample of the original large database brings the benefit of obtaining useful information faster, at the potential expense of lower accuracy. In this paper, we demonstrate \vfds, a novel fast database sampling system that maintains the referential integrity of the data. The system is developed over the open-source database management system, MySQL. We present various scenarios to demonstrate the effectiveness of VFDS in approximate query answering, sample size, and execution time, on both real and synthetic databases.",2014,Conference on Information and Knowledge Management,database testing;database tuning;database design;relational database;information retrieval;data mining;database;computer science;
Microblog Topic Contagiousness Measurement and Emerging Outbreak Monitoring,Victor W. Chu (University of New South Wales);Raymond K. K. Wong (University of New South Wales);Fang Chen (University of New South Wales);Chi-Hung Chi (Commonwealth Scientific and Industrial Research Organisation);,"2037363954,2290077475,2656583616,2135680340","A recent study on collective attention in Twitter shows that an epidemic spreading of hashtags is predominantly driven by external factors. We extend a time-series form of susceptible-infectious-recovered (SIR) model to monitor microblog emerging outbreaks by considering both endogenous and exogenous drivers. In addition, we adopt partially labeled Dirichlet allocation (PLDA) model to generate both background latent topics and hashtag topics. It overcomes the problem of small available samples in hashtag analysis by including related but unlabeled tweets through inference. We standardize hashtag topic contagiousness measure as the estimated effective-reproduction-number R derived from epidemiology. It is obtained by Bayesian parameter estimation. Guided by R , one can profile and categorize emerging topics, and generate alerts on potential outbreaks. Experiment results confirm the effectiveness of this approach.",2014,Conference on Information and Knowledge Management,topic model;microblogging;data science;world wide web;data mining;machine learning;simulation;computer science;
Maximizing Multi-scale Spatial Statistical Discrepancy,Weishan Dong (IBM);Renjie Yao (IBM);Chunyang Ma (IBM);Changsheng Li (IBM);Lei Shi (Chinese Academy of Sciences);Lu Wang (Chinese Academy of Sciences);Yu Wang (IBM);Peng Gao (IBM);Junchi Yan (IBM);,"2097253510,2100134491,2223184971,2571986204,2581263356,2712781587,2306750099,2437588044,2151026072","Detecting anomalous events from spatial data has important applications in real world. The spatial scan statistic methods are popular in this area. With maximizing the spatial statistical discrepancy by comparing observed data with a given baseline data distribution, significant spatial overdensity and underdensity can be detected. In reality, the spatial discrepancy is often irregularly shaped and has a structure of multiple spatial scales. However, a large-scale discrepancy pattern may not be significant when conducting fine granularity analysis. Meanwhile, local irregular boundaries of a maximized discrepancy cannot be well approximated with a coarse granularity analysis. Existing methods mostly work either on a fixed granularity, or with a regularly shaped scanning window. Thus, they have difficulties in characterizing such flexible spatial discrepancies. To solve the problem, in this paper we propose a novel discrepancy maximization algorithm, RefineScan. A grid hierarchy encoding multi-scale information is employed, making the algorithm capable of maximizing spatial discrepancies with multi-scale structures and irregular shapes. Experiments on a wide range of datasets demonstrate the advantages of RefineScan over the state-of-the-art algorithms: It always finds the largest discrepancy scores and remarkably better characterizes multi-scale discrepancy boundaries. Theoretical and empirical analyses also show that RefineScan has a moderate computational complexity and a good scalability.",2014,Conference on Information and Knowledge Management,data mining;statistics;
Increasing the Responsiveness of Recommended Expert Collaborators for Online Open Projects,Mohammad Y. Allaho (Pennsylvania State University);Wang-Chien Lee (Pennsylvania State University);,"91660731,2143778659","We consider the experts recommendation problem for open collaborative projects in large-scale Open Source Software (OSS) communities. In large-scale online community, recommending expert collaborators to a project coordinator or lead developer has two prominent challenges: (i) the ""cold shoulder""' problem, which is the lack of interest from the experts to collaborate and share their skills, and (ii) the ""cold start"" problem, which is an issue with community members who has scarce data history. In this paper, we consider the Degree of Knowledge (DoK) which imposes the knowledge of the skills factor, and the Social Relative Importance (SRI) which imposes the social distance factor to tackle the aforementioned challenges. We propose four DoK models and integrate them with three SRI methods under our proposed Expert Ranking (ER) framework to rank the candidate expert collaborators based on their likelihood of collaborating in response to a query formulated by the social network of a query initiator and certain required skills to a project/task. We evaluate our proposal using a dataset collected from Github.com, which is one of the most fast-growing, large-scale online OSS community. In addition, we test the models under different data scarcity levels. The experiment shows promising results of recommending expert collaborators who tend to make real collaborations to projects.",2014,Conference on Information and Knowledge Management,subject matter expert;knowledge management;world wide web;data mining;database;artificial intelligence;
GI-NMF: Group Incremental Non-Negative Matrix Factorization on Data Streams,Xilun Chen (Arizona State University);K. Selçuk Candan (Arizona State University);,"2224976689,674992784","Non-negative matrix factorization (NMF) is a well known method for obtaining low rank approximations of data sets, which can then be used for efficient indexing, classification, and retrieval. The non-negativity constraints enable probabilistic interpretation of the results and discovery of generative models. One key disadvantage of the NMF, however, is that it is costly to obtain and this makes it difficult to apply NMF in applications where data is dynamic. In this paper, we recognize that many applications involve redundancies and we argue that these redundancies can and should be leveraged for reducing the computational cost of the NMF process: Firstly, online applications involving data streams often include temporal redundancies. Secondly, and perhaps less obviously, many applications include integration of multiple data streams (with potential overlaps) and/or involves tracking of multiple similar (but different) queries; this leads to significant data and query redundancies, which if leveraged properly can help alleviate computational cost of NMF. Based on these observations, we introduce Group Incremental Non-Negative Matrix Factorization (GI-NMF) which leverages redundancies across multiple NMF tasks over data streams. The proposed algorithm relies on a novel group multiplicative update rules (G-MUR) method to significantly reduce the cost of NMF. GMUR is further complemented to support incremental update of the factors where data evolves continuously. Experiments show that GI-NMF significantly reduces the processing time, with minimal error overhead.",2014,Conference on Information and Knowledge Management,non negative matrix factorization;data stream mining;theoretical computer science;world wide web;information retrieval;data mining;database;machine learning;computer science;
Domain Cartridge: Unsupervised Framework for Shallow Domain Ontology Construction from Corpus,Subhabrata Mukherjee (Max Planck Society);Jitendra Ajmera (IBM);Sachindra Joshi (IBM);,"2301124665,129725321,2129013125","In this work we propose an unsupervised framework to construct a shallow domain ontology from corpus. It is essential for Information Retrieval systems, Question-Answering systems, Dialogue etc. to identify important concepts in the domain and the relationship between them. We identify important domain terms of which multi-words form an important component. We show that the incorporation of multi-words improves parser performance, resulting in better parser output, which improves the performance of an existing Question-Answering system by upto 7%. On manually annotated smartphone dataset, the proposed system identifies 40:87% of the domain terms, compared to 22% recall obtained using WordNet, 43:77% by Yago and 53:74% by BabelNet respectively. However, it does not use any manually annotated resource like the compared systems. Thereafter, we propose a framework to construct a shallow ontology from the discovered domain terms by identifying four domain relations namely, Synonyms ('similar-to'), Type-Of ('is-a'), Action-On ('methods') and Feature-Of ('attributes'), where we achieve significant performance improvement over WordNet, BabelNet and Yago without using any mode of supervision or manual annotation.",2014,Conference on Information and Knowledge Management,ontology;natural language processing;world wide web;information retrieval;data mining;database;computer science;
Data/Feature Distributed Stochastic Coordinate Descent for Logistic Regression,Dongyeop Kang (KAIST);Woosang Lim (KAIST);Kijung Shin (Seoul National University);Lee Sael (Stony Brook University);U. Kang (KAIST);,"2160241336,2654772806,2226806500,240407218,2615132872","How can we scale-up logistic regression, or L1 regularized loss minimization in general, for Terabyte-scale data which do not fit in the memory? How to design the distributed algorithm efficiently? Although there exist two major algorithms for logistic regression, namely Stochastic Gradient Descent (SGD) and Stochastic Coordinate Descent (SCD), they face limitations in distributed environments. Distributed SGD enables data parallelism (i.e., different machines access different part of the input data), but it does not allow feature parallelism (i.e., different machines compute different subsets of the output), and thus the communication cost is high. On the other hand, Distributed SCD allows feature parallelism, but it does not allow data parallelism and thus is not suitable to work in distributed environments. In this paper we propose DF-DSCD (Data/Feature Distributed Stochastic Coordinate Descent), an efficient distributed algorithm for logistic regression, or L1 regularized loss minimization in general. DF-DSCD allows both data and feature parallelism. The benefits of DF-DSCD are (a) full utilization of the capabilities provided by modern distributing computing platforms like MapReduce to analyze web-scale data, and (b) independence of each machine in updating parameters with little communication cost. We prove the convergence of DF-DSCD both theoretically, and also show empirical evidence that it is scalable, handles very high-dimensional data with up to 29 millions of features, and converges 2.2 times faster than competitors.",2014,Conference on Information and Knowledge Management,coordinate descent;stochastic gradient descent;logistic regression;data mining;database;pattern recognition;machine learning;statistics;computer science;
Supervised Hashing with Soft Constraints,Cong Leng (Chinese Academy of Sciences);Jian Cheng (Chinese Academy of Sciences);Jiaxiang Wu (Chinese Academy of Sciences);Xi Zhang (Chinese Academy of Sciences);Hanqing Lu (Chinese Academy of Sciences);,"2170999642,2143134920,2326525546,2703676777,2096321700","Due to the ability to preserve semantic similarity in Hamming space, supervised hashing has been extensively studied recently. Most existing approaches encourage two dissimilar samples to have maximum Hamming distance. This may lead to an unexpected consequence that two unnecessarily similar samples would have the same code if they are both dissimilar with another sample. Besides, in existing methods, all labeled pairs are treated with equal importance without considering the semantic gap, which is not conducive to thoroughly leverage the supervised information. We present a general framework for supervised hashing to address the above two limitations. We do not toughly require a dissimilar pair to have maximum Hamming distance. Instead, a soft constraint which can be viewed as a regularization to avoid over-fitting is utilized. Moreover, we impose different weights to different training pairs, and these weights can be automatically adjusted in the learning process. Experiments on two benchmarks show that the proposed method can easily outperform other state-of-the-art methods.",2014,Conference on Information and Knowledge Management,boosting;data mining;pattern recognition;machine learning;computer science;
Simple Arabic Stemmer,Mohammed Algarni (University of Canterbury);Brent Martin;Tim Bell (University of Canterbury);Kourosh Neshatian (University of Canterbury);,"2268149131,2540044542,2109278650,198144689","We propose a root stemmer for the Modern Standard Arabic (MSA) language in an attempt to enhance the performance of Arabic Information Retrieval (AIR). The new Simple Arabic Stemmer (SAS) is based on the Quran morphology, since the Quran was a key source for the derivation of Arabic morphological rules. The stemmer is developed by decomposing all of the Quran words and studying their internal morphological structure including the roots, the patterns, and the affixes employed in the generation process. We were able to construct a relatively small lexicon capable of finding the root for most of the MSA vocabulary. Using the TREC corpus and queries, we test our approach against two well-known root stemmers, Khoja and Sebawai. The results show that SAS gives an improvement in terms of precision.",2014,Conference on Information and Knowledge Management,arabic;root;natural language processing;speech recognition;computer science;
On Building Decision Trees from Large-scale Data in Applications of On-line Advertising,Shivaram Kalyanakrishnan (Indian Institute of Science);Deepthi Singh (Yahoo!);Ravi Kant (Yahoo!);,"246121163,2429457387,2302013680","Decision trees have been used for several decades as simple and effective solutions to supervised learning problems. Their success extends to tasks across a variety of areas. Yet, data collected today through web-domains such as on-line advertising presents many new challenges: sheer size, the prevalence of high-arity categorical features, unknown feature-values, ""cold starts"", sparse training instances, and imbalance in the class labels. We argue that decision trees remain an ideal choice for applications of on-line advertising as they naturally construct higher-order conjunctive features; we then contribute two ideas to improve tree-building accordingly. First, to handle high-arity categorical features, we introduce a method to cluster feature-values based on their output responses. The result is more ""data-dense"" trees with relatively small branching factors. Second, we employ cross-validation as a principled approach to derive splitting and stopping criteria: thereby we identify splits that generalize well, and also curb overfitting. Evaluated on three distinct probability-estimation tasks in on-line advertising, our method, ""CCDT"", shows significant improvements in the accuracy of prediction.",2014,Conference on Information and Knowledge Management,cross validation;decision tree;cluster analysis;world wide web;data mining;database;artificial intelligence;machine learning;statistics;computer science;
Cross-Modality Submodular Dictionary Learning for Information Retrieval,Fan Zhu (University of Sheffield);Ling Shao (University of Sheffield);Mengyang Yu (University of Sheffield);,"2588290688,2142547891,2433076127","This paper addresses the problem of joint modeling of multimedia components in different media forms. We consider the information retrieval task across both text and image documents, which includes retrieving relevant images that closely match the description in a text query and retrieving text documents that best explain the content of an image query. A greedy dictionary construction approach is introduced for learning an isomorphic feature space, to which cross-modality data can be adapted while data smoothness is guaranteed. The proposed objective function consists of two reconstruction error terms for both modalities and a Maximum Mean Discrepancy (MMD) term that measures the cross-modality discrepancy. Optimization of the reconstruction terms and the MMD term yields a compact and modality-adaptive dictionary pair. We formulate the joint combinatorial optimization problem by maximizing variance reduction over a candidate signal set while constraining the dictionary size and coefficients' sparsity. By exploiting the submodularity and the monotonicity property of the proposed objective function, the optimization problem can be solved by a highly efficient greedy algorithm, and is guaranteed to be at least a ( e - 1)=/ e ≈0.632- approximation to the optimum. The proposed method achieves state-of-the-art performance on the Wikipedia dataset.",2014,Conference on Information and Knowledge Management,k svd;natural language processing;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;computer science;
Vertical-Aware Click Model-Based Effectiveness Metrics,Ilya Markov (University of Amsterdam);Eugene Kharitonov (Yandex);Vadim Nikulin (Yandex);Pavel Serdyukov (Yandex);Maarten de Rijke (University of Amsterdam);Fabio Crestani (University of Lugano);,"2311084885,2115606974,2224319808,2130450538,401833296,2303795236","Today's web search systems present users with heterogeneous information coming from sources of different types, also known as verticals. Evaluating such systems is an important but complex task, which is still far from being solved. In this paper we examine the hypothesis that the use of models that capture user search behavior on heterogeneous result pages helps to improve the quality of offline metrics. We propose two vertical-aware metrics based on user click models for federated search and evaluate them using query logs of the Yandex search engine. We show that depending on the type of vertical, the proposed metrics have higher correlation with online user behavior than other state-of-the-art techniques.",2014,Conference on Information and Knowledge Management,evaluation;multimedia;world wide web;data mining;computer science;
A Generative Model for Generating Relevance Labels from Human Judgments and Click-Logs,Xugang Ye (Microsoft);Jingjing Li (Microsoft);Zijie Qi (Microsoft);Bingyue Peng (Microsoft);Dan Massey (Microsoft);,"2600378141,2303095549,2109088733,2230378781,2123370045","Lack of high quality relevance labels is a common challenge in the early stage of search engine development. In media search, due to the high recruiting and training cost, the labeling process is usually conducted by a small number of human judges. Consequently, the generated labels are often limited and biased. On the contrary, the click data that is extracted from a large population of real users is massive and less biased. However, the click data also contains considerable noise. Therefore, more and more researchers have begun to focus on combining those two resources to generate a better ground-truth approximation. In this paper, we present a novel method of generating the relevance labels for media search. The method is based on a generative model that considers human judgment, position, and click status as observations generated from a hidden relevance with multinomial prior. The model considers the position bias with a requirement that the click status depends on both the hidden relevance and the position. We infer the model parameters by using a Gibbs sampling procedure with hyper-parameter optimization. From experiments on the Xbox's data, the newly inferred relevance labels significantly increase the data volume for ranker training and have demonstrated superior performance compared to using the limited human labels only, the click-through-rates only, and the heuristic combination of the two.",2014,Conference on Information and Knowledge Management,generative model;labeling theory;relevance;data mining;artificial intelligence;machine learning;statistics;computer science;
Rebuilding the Tower of Babel: Towards Cross-System Malware Information Sharing,Ting Wang (IBM);Shicong Meng (Facebook);Wei Gao (University of Tennessee);Xin Hu (IBM);,"2568094062,2156988580,2118807127,2307873267","Anti-virus systems developed by different vendors often demonstrate strong discrepancies in how they name malware, which signficantly hinders malware information sharing. While existing work has proposed a plethora of malware naming standards, most anti-virus vendors were reluctant to change their own naming conventions. In this paper we explore a new, more pragmatic alternative. We propose to exploit the correlation between malware naming of different anti-virus systems to create their consensus classification, through which these systems can share malware information without modifying their naming conventions. Specifically we present Latin, a novel classification integration framework leveraging the correspondence between participating anti-virus systems as reflected in heterogeneous information sources at instance-instance, instance-name, and name-name levels. We provide results from extensive experimental studies using real malware datasets and concrete use cases to verify the efficacy of Latin in supporting cross-system malware information sharing.",2014,Conference on Information and Knowledge Management,internet privacy;world wide web;computer security;data mining;database;artificial intelligence;computer science;
Using Crowdsourcing to Investigate Perception of Narrative Similarity,Dong Nguyen (University of Twente);Dolf Trieschnigg (University of Twente);Mariët Theune (University of Twente);,"2112184148,2035566089,1998152884","For many applications measuring the similarity between documents is essential. However, little is known about how users perceive similarity between documents. This paper presents the first large-scale empirical study that investigates perception of narrative similarity using crowdsourcing. As a dataset we use a large collection of Dutch folk narratives. We study the perception of narrative similarity by both experts and non-experts by analyzing their similarity ratings and motivations for these ratings. While experts focus mostly on the plot, characters and themes of narratives, non-experts also pay attention to dimensions such as genre and style. Our results show that a more nuanced view is needed of narrative similarity than captured by story types, a concept used by scholars to group similar folk narratives. We also evaluate to what extent unsupervised and supervised models correspond with how humans perceive narrative similarity.",2014,Conference on Information and Knowledge Management,narrative criticism;crowdsourcing;narrative;similarity;data mining;computer science;
Exploring Legal Patent Citations for Patent Valuation,Shuting Wang (Pennsylvania State University);Zhen Lei (Pennsylvania State University);Wang-Chien Lee (Pennsylvania State University);,"2229790191,2169563929,2143778659","Effective patent valuation is important for patent holders. Forward patent citations, widely used in assessing patent value, have been considered as reflecting knowledge flows, just like paper citations. However, patent citations also carry legal implication, which is important for patent valuation. We argue that patent citations can either be technological citations that indicate knowledge transfer or be legal citations that delimit the legal scope of citing patents. In this paper, we first develop citation-network based methods to infer patent quality measures at either the legal or technological dimension. Then we propose a probabilistic mixture approach to incorporate both the legal and technological dimensions in patent citations, and an iterative learning process that integrates a temporal decay function on legal citations, a probabilistic citation network based algorithm and a prediction model for patent valuation. We learn all the parameters together and use them for patent valuation. We demonstrate the effectiveness of our approach by using patent maintenance status as an indicator of patent value and discuss the insights we learned from this study.",2014,Conference on Information and Knowledge Management,patent visualisation;data mining;
Phrase Query Optimization on Inverted Indexes,Avishek Anand (Max Planck Society);Ida Mele (Max Planck Society);Srikanta J. Bedathur (Indraprastha Institute of Information Technology);Klaus Berberich (Max Planck Society);,"2127850459,1999225486,1218200837,2064029816","Phrase queries are a key functionality of modern search engines. Beyond that, they increasingly serve as an important building block for applications such as entity-oriented search, text analytics, and plagiarism detection. Processing phrase queries is costly, though, since positional information has to be kept in the index and all words, including stopwords, need to be considered. We consider an augmented inverted index that indexes selected variable-length multi-word sequences in addition to single words. We study how arbitrary phrase queries can be processed efficiently on such an augmented inverted index. We show that the underlying optimization problem is NP -hard in the general case and describe an exact exponential algorithm and an approximation algorithm to its solution. Experiments on ClueWeb09 and The New York Times with different real-world query workloads examine the practical performance of our methods.",2014,Conference on Information and Knowledge Management,phrase search;query optimization;natural language processing;information retrieval;database;computer science;
Seventh Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR'14): CIKM 2014 Workshop,Omar Alonso (Microsoft);Jaap Kamps (University of Amsterdam);Jussi Karlgren (Swedish Institute of Computer Science);,"2292406529,2088944921,2629262436","There is an increasing amount of structure on the Web as a result of modern Web languages, user tagging and annotation, emerging robust NLP tools, and an ever growing volume of linked data. These meaningful, semantic, annotations hold the promise to significantly enhance information access, by enhancing the depth of analysis of today's systems. The goal of the ESAIR'14 workshop remains to advance the general research agenda on this core problem, with an explicit focus on one of the most challenging aspects to address in the coming years. The main remaining challenge is on the user's side - the potential of rich document annotations can only be realized if matched by more articulate queries exploiting these powerful retrieval cues - and a more dynamic approach is emerging by exploiting new forms of query autosuggest. How can the query suggestion paradigm be used to encourage searcher to articulate longer queries, with concepts and relations linking their statement of request to existing semantic models? How do entity results and social network data in ""graph search"" change the classic division between searchers and information and lead to extreme personalization - are you the query? How to leverage transaction logs and recommendation, and how adaptive should we make the system? What are the privacy ramifications and the UX aspects - how to not creep out users?",2014,Conference on Information and Knowledge Management,query language;information system;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Learning to Propagate Rare Labels,Rakesh Pimplikar (IBM);Dinesh Garg (IBM);Deepesh Bharani;Gyana R. Parija (IBM);,"2023870058,2210115675,2224249715,2630005675","Label propagation is a well-explored family of methods for training a semi-supervised classifier where input data points (both labeled and unlabeled) are connected in the form of a weighted graph. For binary classification, the performance of these methods starts degrading considerably whenever input dataset exhibits following characteristics - (i) one of the class label is rare label or equivalently, class imbalance (CI) is very high , and (ii) degree of supervision (DoS) is very low -- defined as fraction of labeled points . These characteristics are common in many real-world datasets relating to network fraud detection. Moreover, in such applications, the amount of class imbalance is not known a priori. In this paper, we have proposed and justified the use of an alternative formulation for graph label propagation under such extreme behavior of the datasets. In our formulation, objective function is the difference of two convex quadratic functions and the constraints are box constraints. We solve this program using Concave-Convex Procedure (CCCP) . Whenever the problem size becomes too large, we suggest to work with a k -NN subgraph of the given graph which can be sampled by using Locality Sensitive Hashing (LSH) technique. We have also discussed various issues that one typically faces while sampling such a k -NN subgraph in practice. Further, we have proposed a novel label flipping method on top of the CCCP solution, which improves the result of CCCP further whenever class imbalance information is made available a priori. Our method can be easily adopted for a MapReduce platform, such as Hadoop. We have conducted experiments on 11 datasets comprising a graph size of up to 20K nodes, CI as high as 99:6%, and DoS as low as 0:5%. Our method has resulted up to 19:5-times improvement in F -measure and up to 17:5-times improvement in AUC-PR measure against baseline methods.",2014,Conference on Information and Knowledge Management,data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;
Modeling Paying Behavior in Game Social Networks,Zhanpeng Fang (Tsinghua University);Xinyu Zhou (Tsinghua University);Jie Tang (Tsinghua University);Wei Shao (Tencent);Alvis Cheuk M. Fong (Auckland University of Technology);Longjun Sun (Tencent);Ying Ding (Indiana University Bloomington);Ling Zhou (Tsinghua University);Jarder Luo (Tsinghua University);,"2119723005,2236515960,2158012360,2483303229,2423977144,2231916925,2161065209,2223127462,2532752751","Online gaming is one of the largest industries on the Internet, generating tens of billions of dollars in revenues annually. One core problem in online game is to find and convert free users into paying customers, which is of great importance for the sustainable development of almost all online games. Although much research has been conducted, there are still several challenges that remain largely unsolved: What are the fundamental factors that trigger the users to pay? How does users? paying behavior influence each other in the game social network? How to design a prediction model to recognize those potential users who are likely to pay? In this paper, employing two large online games as the basis, we study how a user becomes a new paying user in the games. In particular, we examine how users' paying behavior influences each other in the game social network. We study this problem from various sociological perspectives including strong/weak ties, social structural diversity and social influence. Based on the discovered patterns, we propose a learning framework to predict potential new payers. The framework can learn a model using features associated with users and then use the social relationships between users to refine the learned model. We test the proposed framework using nearly 50 billion user activities from two real games. Our experiments show that the proposed framework significantly improves the prediction accuracy by up to 3-11% compared to several alternative methods. The study also unveils several intriguing social phenomena from the data. For example, influence indeed exists among users for the paying behavior. The likelihood of a user becoming a new paying user is 5 times higher than chance when he has 5 paying neighbors of strong tie. We have deployed the proposed algorithm into the game, and the Lift_Ratio has been improved up to 196% compared to the prior strategy.",2014,Conference on Information and Knowledge Management,social network;world wide web;data mining;artificial intelligence;machine learning;simulation;
Document Prioritization for Scalable Query Processing,Hao Wu (University of Delaware);Hui Fang (University of Delaware);,"2225904997,2618399871","Query latency is an important performance measure of any search engines because it directly affects search users' satisfaction. The key challenge is how to efficiently retrieve top-K ranked results for a query. Current search engines process queries in either the conjunctive or disjunctive modes. However, there is still a large performance gap between these two modes since the conjunctive mode is more efficient with lower search accuracy while the disjunctive mode is more effective but requires more time to process the queries. In this paper, we propose a novel query evaluation method that aims to achieve a better balance between the efficiency and effectiveness of top-K query processing. The basic idea is to prioritize candidate documents based on the number of the matched query terms in the documents as well as the importance of the matched terms. We propose a simple priority function and then discuss how to implement the idea based on a decision tree. Experimental results over both Web and Twitter collections show that the proposed method is able to narrow the performance gap with the conjunctive and disjunctive modes when K is larger or the length of a query is longer. In particular, compared with one of the fastest existing query processing methods, the propose method can achieve a speedup of 2 with marginal loss in the retrieval effectiveness on the Web collection.",2014,Conference on Information and Knowledge Management,sargable;ranking;range query;rdf query language;boolean conjunctive query;online aggregation;web search query;web query classification;spatial query;query by example;query expansion;query optimization;query language;efficiency;world wide web;information retrieval;data mining;database;computer science;
A Demonstration of SearchonTS: An Efficient Pattern Search Framework for Time Series Data,Xiaomin Xu (IBM);Sheng Huang (IBM);Yaoliang Chen (IBM);Chen Wang (IBM);Inge Halilovic (IBM);Kevin Brown (IBM);Mark Ashworth (IBM);,"2504680071,2654599160,2112166664,2715457836,2231578744,2422599325,2479520232","In recent years, time series data are everywhere across different industry, which creates a huge demand on time series data analysis, such as pattern search. Meanwhile, it is increasingly realized that only when pattern search results together with information from relational tables could be used in a programming-free way, can they perform analysis on time series conveniently. Hence, casual users highly demand that queries involving pattern search could be performed via SQLs. However, existing database products supporting time series data type lack the capability to perform pattern searches on time series data. This paper presents SearchonTS, an extendable framework for in-database pattern search on time series data. It provides a series of interfaces so that time series index and pattern search can be added and performed in a uniformed and query optimized manner. SearchonTS is implemented as an extension on Informix, which is a database product in IBM software product series. It targets a future release of IBM Informix. We have implemented index-based pattern search for Euclid Distance(ED) via SearhonTS to demonstrate its usability for developers. And real scenario is also provided to show SQL involving pattern search so that users can have a more clear experience of the convenience.",2014,Conference on Information and Knowledge Management,state pattern;pattern search;time series;world wide web;information retrieval;data mining;database;real time computing;computer science;
Enterprise Discussion Analysis,Sara Rosenthal (Columbia University);Ashish Jagmohan (IBM);,"2124036869,97484136","Recent business studies have shown that social technologies can significantly improve productivity within enterprises by improving access to information, ideas, and collaborators. A manifestation of the growing adoption of enterprise social technologies is the increasing use of enterprise virtual discussions to engage customers and employees. In this paper we present an enterprise discussion analysis system which seeks to enable rapid interactive inference of insights from virtual online enterprise discussions. Rapid understanding is facilitated by extracting a hierarchy of key concepts, which represent a multi-faceted thematic categorization of discussion content, and by identifying high-quality thematic exemplar comments. The concept hierarchy and exemplar comments are presented through an intuitive web user-interface which allows an analyst to quickly navigate through the main concepts and the most relevant comments extracted from the discussion. We present a preliminary validation of system efficacy through user surveys provided to test users.",2014,Conference on Information and Knowledge Management,integrated enterprise modeling;enterprise software;architecture domain;enterprise architecture;enterprise integration;user interface;enterprise systems engineering;enterprise information system;knowledge management;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Semantic Topology,Jussi Karlgren (Swedish Institute of Computer Science);Martin Bohman (Royal Institute of Technology);Ariel Ekgren (Royal Institute of Technology);Gabriel Isheden (Royal Institute of Technology);Emelie Kullmann (Royal Institute of Technology);David Nilsson (Royal Institute of Technology);,"2629262436,2131338338,629766135,2295804929,2146938805,2099892473","Semantic spaces, a useful learning framework for lexical resources, are typically treated as black boxes and applied using geometric and linear algebraic processing tools. We have found that topological methods are useful for exploring the makeup of a semantic space.",2014,Conference on Information and Knowledge Management,semantic compression;semantic computing;semantic equivalence;semantic grid;semantic similarity;computational topology;theoretical computer science;natural language processing;computer science;
Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,Jianzhong Li (Harbin Institute of Technology);X. Sean Wang (Fudan University);Minos Garofalakis (Technical University of Crete);Ian Soboroff (National Institute of Standards and Technology);Torsten Suel (New York University);Min Wang (Google);,"2719817558,2670041280,2089290244,2031005049,2639959275,2705698129","On behalf of the conference organizing committee, it is our great pleasure to welcome you to the 23rd ACM International Conference on Information and Knowledge Management (CIKM 2014). CIKM is a top-tier ACM conference in Databases, Information Retrieval, and Knowledge Management. The purpose of the conference is to identify challenging problems facing the development of future knowledge and information systems, and to shape future research directions through the publication of high quality, applied and theoretical research findings. The 23rd edition of CIKM continues the tradition of promoting collaboration among multiple areas. The conference this year has attracted 838 valid full paper submissions, 260 valid poster submissions, 73 valid demonstration submissions, and 15 valid workshop proposals. Among them, we accepted 175 full papers, 57 posters, 29 demonstrations, and 9 workshops. On top of the regular track, the conference has an outstanding keynote program, an exciting industry event, and six tutorials of contemporary topics. This time again, the conference is standing out among the many of its peers in its ability to attract researchers to exchange ideas and to interact, and the sheer numbers are a testament of the vitality of the three research areas and their interactions. We are honored to present three distinguished keynote speakers: Jeff Dean of Google, Qi Lu of Microsoft, and Gerhard Weikum of Max-Planck Institute for Informatics. We are also honored to present six industry event invitees to share their deep knowledge and insights: Soumen Chakrabarti, Chih Jen Lin, Wei-Ying Ma, Alex J. Smola, Limsoon Wong, and Tong Zhang. At CIKM 2014, we inaugurate a programming competition, sponsored by Baidu Inc. The competition has attracted 571 teams to sign up from around the world, with top-ranked teams achieving significant results on the task given.",2014,Conference on Information and Knowledge Management,operations research;world wide web;data mining;artificial intelligence;computer science;
Non-independent Cascade Formation: Temporal and Spatial Effects,Biru Cui (Rochester Institute of Technology);Shanchieh Jay Yang (Rochester Institute of Technology);Christopher Homan (Rochester Institute of Technology);,"2683662892,2654641308,2035277272","Determining cascade size and the factors affecting cascade size are two fundamental research problems in social network analysis. The commonly considered independent cascade model, when applied to social networks such as Digg, produces a phase-transition phenomenon where the cascade is either very small or very large. This phenomenon can be explained based on the concept of Giant Propagation Component (GPC). The GPC is defined as a maximally connected component, such that, by applying the independent cascade model, once any node of the component is infected, most of the remaining nodes in the component will eventually become infected with a high probability. While GPC exists in social networks, the phase-transition phenomenon, is not observed in the actual cascade size distribution when the information propagation is due to actions such as ``like'' or ``dig''. This paper hypothesizes that the cascade process, i.e., the likeliness of a node being infected changes over time and depends on how far away the node is from the seed. Furthermore, each node will not be exactly independently considered for infection from each of its infected friends, because the chance of information propagation through ``like'' or ``dig'' does not necessarily increase when there are more friends like/dig the information. To this end, we develop and simulate a new non-independent infection cascade process. The experiment results show that the proposed cascade process generates power-law like cascade size distribution without phase transition, which resembles much better the real-world cascade distribution observed in the Digg social network.",2014,Conference on Information and Knowledge Management,information cascade;artificial intelligence;computer science;
Travel distance versus navigation complexity: a study on different spatial queries on road networks,Jie Shao (University of Electronic Science and Technology of China);Lars Kulik (University of Melbourne);Egemen Tanin (University of Melbourne);Long Guo (National University of Singapore);,"2110372033,1899350157,66485931,2654622697","Research on cognitive science indicates that humans often use different criteria for route selection. An alternative type of spatial proximity search on road networks recently has been proposed to find the easiest-to-reach neighboring object with the smallest navigation complexity. This paper presents an evaluation to compare the effectiveness of easiest-to-reach neighbor query against a classic nearest neighbor query in a real-world setting. Our user study demonstrates usability of the new spatial query type and suggests people may not always care about travel distance most. To provide flexibility to accommodate different requirements, we also show how to achieve tradeoff between navigation complexity and travel distance for advanced navigational assistance.",2014,Conference on Information and Knowledge Management,turn by turn navigation;data mining;machine learning;simulation;computer science;
A Cross-modal Multi-task Learning Framework for Image Annotation,Liang Xie (Huazhong University of Science and Technology);Peng Pan (Huazhong University of Science and Technology);Yansheng Lu (Huazhong University of Science and Technology);Shixun Wang (Huazhong University of Science and Technology);,"2101520680,2200848734,2141641048,2148230945","With the advance of internet, multi-modal data can be easily collected from many social websites such as Wikipedia, Flickr, YouTube, etc. Images shared on the web are usually associated with social tags or other textual information. Although existing multi-modal methods can make use of associated text to improve image annotation, the disadvantages of them are that associated text is also required for a new image to be predicted. In this paper, we propose the cross-modal multi-task learning (CMMTL) framework for image annotation. Labeled and unlabeled multi-modal data are both levaraged for training in CMMTL, and it finally obtains visual classifiers which can predict concepts for a single image without any associated information. CMMTL integrates graph learning, multi-task learning and cross-modal learning into a joint framework, where a shared subspace is learned to preserve both cross-modal correlation and concept correlation. The optimal solution of the proposed framework can be obtained by solving a generalized eigenvalue problem. We conduct comprehensive experiments on two real world image datasets: MIR Flickr and NUS-WIDE, to evaluate the performance of the proposed framework. Experimental results demonstrate that CMMTL obtains a significant improvement over several representative methods for cross-modal image annotation.",2014,Conference on Information and Knowledge Management,multi task learning;automatic image annotation;semi supervised learning;image retrieval;world wide web;information retrieval;data mining;database;machine learning;computer science;
Searching Locally-Defined Entities,Zhaohui Wu (Pennsylvania State University);Yuanhua Lv (Microsoft);Ariel Fuxman (Microsoft);,"2708527874,2132538679,2665095167","When consuming content, users typically encounter entities that they are not familiar with. A common scenario is when users want to find information about entities directly within the content they are consuming. For example, when reading the book ""Adventures of Huckleberry Finn"", a user may lose track of the character Mary Jane and want to find some paragraph in the book that gives relevant information about her. The way this is achieved today is by invoking the ubiquitous Find function (""Ctrl-F""). However, this only returns exact-matching results without any relevance ranking, leading to a suboptimal user experience. How can we go beyond the Ctrl-F function? To tackle this problem, we present algorithms for semantic matching and relevance ranking that enable users to effectively search and understand entities that have been defined in the content that they are consuming, which we call locally-defined entities . We first analyze the limitations of standard information retrieval models when applied to searching locally-defined entities, and then we propose a novel semantic entity retrieval model that addresses these limitations. We also present a ranking model that leverages multiple novel signals to model the relevance of a passage. A thorough experimental evaluation of the approach in the real-word application of searching characters within e-books shows that it outperforms the baselines by 60%+ in terms of NDCG.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
MaC: A Probabilistic Framework for Query Answering with Machine-Crowd Collaboration,Chen Jason Zhang (Hong Kong University of Science and Technology);Lei Chen (Hong Kong University of Science and Technology);Yongxin Tong (Hong Kong University of Science and Technology);,"2136657330,2318776917,2114386387","The popularity of crowdsourcing has recently brought about brand new opportunities for engaging human intelligence in the process of data analysis. Most existing works on crowdsourcing have developed sophisticated methods to utilize the crowd as a new kind of processor, a.k.a. Human Processor Units (HPU). In this paper, we propose a framework, called MaC, to combine the powers of both CPUs and HPUs. In order to build MaC, we need to tackle the following two challenges: (1) HIT Selection: Selecting the ""right"" HITs (Human Intelligent Tasks) can help reducing the uncertainty significantly and the results can converge quickly. Thus, we propose an entropy-based model to evaluate the informativeness of HITs. Furthermore, we find that selecting HITs has factorial complexity and the optimization function is non-linear, thus, we propose an efficient approximation algorithm with a bounded error. (2) Uncertainty Management: Crowdsourced answers can be inaccurate. To address this issue, we provide effective solutions in three common scenarios of crowdsourcing: (a) the answer and the confidence of each worker are available; (b) the confidence of each worker and the voting score for each HIT are available; (c) only the answer of each worker is available. To verify the effectiveness of the MaC framework, we built a hybrid Machine-Crowd system and tested it on three real-world applications - data fusion, information extraction and pattern recognition. The experimental results verified the effectiveness and the applicability of our framework.",2014,Conference on Information and Knowledge Management,crowdsourcing;data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
LocWeb'14 - 4th International Workshop on Location and the Web: CIKM 2014 Workshop Summary,Dirk Ahlers (Norwegian University of Science and Technology);Erik Wilde (EMC Corporation);Bruno Martins (University of Lisbon);,"2019721281,2122182102,2238216042","The LocWeb 2014 workshop continues a successful workshop series at the intersection of geospatial search, information management, and Web architecture with a focus towards location-aware information access . The workshop reflects a multitude of fields that demand and utilize location features, featuring presentations that look at the topic of location on the Web from an interdisciplinary perspective, including new approaches dealing with or utilizing geospatial information.",2014,Conference on Information and Knowledge Management,web modeling;world wide web;information retrieval;data mining;computer science;
A Cross-Lingual Joint Aspect/Sentiment Model for Sentiment Analysis,Zheng Lin (Chinese Academy of Sciences);Xiaolong Jin (Chinese Academy of Sciences);Xueke Xu (Chinese Academy of Sciences);Weiping Wang (Chinese Academy of Sciences);Xueqi Cheng (Chinese Academy of Sciences);Yuanzhuo Wang (Chinese Academy of Sciences);,"2085002608,2098785527,2637515203,2597937528,2129598186,2120380447","Sentiment analysis in various languages has been a research hotspot with many applications. However, sentiment resources (e.g., labeled corpora, sentiment lexicons) of different languages are unbalanced in terms of quality and quantity, which arouses interests in cross-lingual sentiment analysis aiming at using the resources in a source language to improve sentiment analysis in a target language. Nevertheless, many existing cross-lingual related works rely on a certain machine translation system to directly adapt the labeled data from the source language to the target language, which usually suffers from inaccurate results generated by the machine translation system. On the other hand, most sentiment analysis studies focus on document-level sentiment classification that cannot solve the aspect dependency problem of sentiment words. For instance, in the reviews on a cell phone, long is positive for the lifespan of its battery, but negative for the response time of its operating system. To solve these problems, this paper develops a novel Cross-Lingual Joint Aspect/Sentiment (CLJAS) model to carry out aspect-specific sentiment analysis in a target language using the knowledge learned from a source language. Specifically, the CLJAS model jointly detects aspects and sentiments of two languages simultaneously by incorporating sentiments into a cross-lingual topic model framework. Extensive experiments on different domains and different languages demonstrate that the proposed model can significantly improve the accuracy of sentiment classification in the target language.",2014,Conference on Information and Knowledge Management,topic model;sentiment analysis;natural language processing;speech recognition;data mining;machine learning;computer science;
Towards Consistency Checking over Evolving Ontologies,Jiewen Wu (IBM);Freddy Lecue (IBM);,"2307464615,233931727","Data captured in OWL ontologies is generally considered to be more prone to changes than the schema in many situations. Such changes often necessitate consistency checking over the resulting ontologies in order to maintain coherent knowledge, specifically in dynamic settings. In this paper, we present an approach to check the consistency over an evolving ontology resulting from data insertions and deletions, given by some expressive underlying Description Logic dialect. The approach, assuming an initially consistent ontology, works by syntactically identifying ""relevant"" and representative parts of the data for the given updates, i.e., the part that may contribute to subsequent consistency checking. Our approach has demonstrated its efficacy in checking consistency over large and real-world ontologies and outperforms existing approaches in several circumstances.",2014,Conference on Information and Knowledge Management,consistency model;description logic;theoretical computer science;data mining;database;computer science;
Probabilistic Classifier Chain Inference via Gibbs Sampling,Li Li (Peking University);Longkai Zhang (Peking University);Guangyi Li (Peking University);Houfeng Wang (Peking University);,"2658257073,2654400204,2138858145,2717761748","Multi-label classification is supervised learning, where an instance may be assigned with multiple categories (labels) simultaneously. Recently, a method called Probabilistic Classifier Chain (PCC) was proposed with numerous appealing properties, such as conceptual simplicity, flexibility, and theoretical justification. Nevertheless, PCC suffers from high inference complexity. To address this problem, we propose a novel inference method with gibbs sampling . An acceleration scheme is proposed to accelerate this method further. Our proposed method is based on our claim that PCC is a special case of Bayesian network. This claim may inspire more inference algorithms for PCC. Experiments with real-world data sets show effectiveness of our proposed method.",2014,Conference on Information and Knowledge Management,gibbs sampling;data mining;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Towards Pathway Variation Identification: Aligning Patient Records with a Care Pathway,Haifeng Liu (IBM);Yang Liu 0007 (Chinese Academy of Sciences);Xiang Li (IBM);Guo Tong Xie (IBM);Geetika T. Lakshmanan (IBM);,"2281948475,2637951410,2304760860,2095693315,2150824222",A Care Pathway is a knowledge-centric process to guide clinicians to provide evidence-based care to patients with specific conditions. One existing problem for care pathways is that they often fail to reflect the best clinical practice as a result of not being adequately updated. A better understanding of the gaps between a care pathway and real practice requires aligning patient records with the pathway. Patient records are unlabeled in practice making it difficult to align them with a care pathway which is inherently complex due to its representation as a hierarchical and declarative process model (HDPM). This paper proposes to solve this problem by developing a Hierarchical Markov Random Field (HMRF) method so that a set of patient records can best fit a given care pathway. We validate the effectiveness of the method with experiments on both synthesized data and real clinical data.,2014,Conference on Information and Knowledge Management,bioinformatics;data mining;
Indexing Linked Data in a Wireless Broadcast System with 3D Hilbert Space-Filling Curves,"Yongrui Qin (University of Adelaide);Quan Z. Sheng (University of Adelaide);Nickolas J.G. Falkner (University of Adelaide);Wei Emma Zhang (University of Adelaide);Hua Wang (Victoria University, Australia);","2110208407,1740996049,2309817396,2104649335,2306205450","Semantic technologies aim to facilitate machine-to-machine communication and are attracting more and more interest from both academia and industry, especially in the emerging Internet of Things (IoT). In this paper, we consider large-scale information sharing scenarios among mobile objects in IoT by leveraging semantic techniques. We propose to broadcast Linked Data on-air using RDF format to allow simultaneous access to the information and to achieve better scalability. We introduce a novel air indexing method to reduce the information access latency and energy consumption. To build air indexes, we firstly map RDF triples in the Linked Data into points in a 3D space and build B + -trees based on 3D Hilbert curve mappings for all of the 3D points. We then convert these trees into linear sequences so that they can be broadcast over a wireless channel. A novel search algorithm is also designed to efficiently evaluate queries against the air indexes. Experiments show that our indexing method outperforms the air indexing method based on traditional 3D R-trees.",2014,Conference on Information and Knowledge Management,internet of things;world wide web;information retrieval;data mining;database;computer science;
A Meta-reasoner to Rule Them All: Automated Selection of OWL Reasoners Based on Efficiency,"Yong-Bin Kang (Monash University, Clayton campus);Shonali Krishnaswamy (Agency for Science, Technology and Research);Yuan-Fang Li (Monash University, Clayton campus);","2145850011,2722391233,2119270058","It has been shown, both theoretically and empirically, that reasoning about large and expressive ontologies is computationally hard. Moreover, due to the different reasoning algorithms and optimisation techniques employed, each reasoner may be efficient for ontologies with different characteristics. Based on recently-developed prediction models for various reasoners for reasoning performance, we present our work in developing a meta-reasoner that automatically selects from a number of state-of-the-art OWL reasoners to achieve optimal efficiency. Our preliminary evaluation shows that the meta-reasoner significantly and consistently outperforms 6 state-of-the-art reasoners and it achieves a performance close to the hypothetical gold standard reasoner.",2014,Conference on Information and Knowledge Management,semantic reasoner;predictive modelling;ontology;data mining;artificial intelligence;machine learning;computer science;
Sparse Semantic Hashing for Efficient Large Scale Similarity Search,Qifan Wang (Purdue University);Bin Shen (Purdue University);Zhiwei Zhang (Purdue University);Luo Si (Purdue University);,"2168727712,2310329050,2232150411,2127260490","Similarity search, or finding approximate nearest neighbors, is an important technique in various large scale information retrieval applications such as document retrieval. Many recent research demonstrate that hashing methods can achieve promising results for large scale similarity search due to its computational and memory efficiency. However, most existing hashing methods ignore the hidden semantic structure of documents but only use the keyword features (e.g., tf-idf) in hashing codes learning. This paper proposes a novel sparse semantic hashing (SpSH) approach that explores the hidden semantic representation of documents in learning their corresponding hashing codes. In particular, a unified framework is designed for ensuring the hidden semantic structure among the documents by a sparse coding model, while at the same time preserving the document similarity via graph Laplacian. An iterative coordinate descent procedure is then proposed for solving the optimization problem. Extensive experiments on two large scale datasets demonstrate the superior performance of the proposed research over several state-of-the-art hashing methods.",2014,Conference on Information and Knowledge Management,feature hashing;locality preserving hashing;dynamic perfect hashing;universal hashing;locality sensitive hashing;neural coding;hash function;hash table;information retrieval;data mining;pattern recognition;machine learning;computer science;
TweetMogaz v2: Identifying News Stories in Social Media,Eslam Elsawy;Moamen Mokhtar;Walid Magdy (Qatar Computing Research Institute);,"2477596829,2632764174,2662772209","TweetMogaz is a news portal platform that generates news reports from social media content. It uses an adaptive information filtering technique for tracking tweets relevant to news topics, such as politics and sports in some regions. Relevant tweets for each topic are used to generate a comprehensive report about public reaction toward events happening. Showing a news report about an entire topic may be suboptimal for some users, since users prefer story-oriented presentation. In this demonstration, we present a technique for identifying stories within a stream of microblogs on a given topic. Detected tweets on a news story are used to generate a dynamic pseudo-article that gets its content updated in real-time based on trends on Twitter. Pseudo-article consists of a title, front-page image, set of tweets on the story, and links to external news articles. The platform is running live and tracks news on hot topics including Egyptian politics, Syrian conflict, and international sports.",2014,Conference on Information and Knowledge Management,news media;arabic;internet privacy;multimedia;world wide web;machine learning;computer science;
Fair Allocation in Online Markets,Sreenivas Gollapudi (Microsoft);Debmalya Panigrahi (Duke University);,"2023254819,2138771547",-,2014,Conference on Information and Knowledge Management,-
Exploit Latent Dirichlet Allocation for One-Class Collaborative Filtering,Haijun Zhang (Beihang University);Zhoujun Li (Beihang University);Yan Chen (Beihang University);Xiaoming Zhang (Beihang University);Senzhang Wang (Beihang University);,"2229017365,2133880114,2689119075,2233897379,2108200212","Previous work studied one-class collaborative filtering (OCCF) problems including pointwise methods, pairwise methods, and content-based methods. The fundamental assumptions made on these approaches are roughly the same. They regard all missing values as negative. However, this is unreasonable since the missing values actually are the mixture of negative and positive examples. A user does not give a positive feedback on an item probably only because she/he is unaware of the item, but in fact, she/he is fond of it. Furthermore, content-based methods, e.g. collaborative topic regression (CTR), usually require textual content information of items. This cannot be satisfied in some cases. In this paper, we exploit latent Dirichlet allocation (LDA) model on OCCF problem. It assumes missing values unknown and only models the observed data, and it also does not need content information of items. In our model items are regarded as words and users are considered as documents and the user-item feedback matrix denotes the corpus. Experimental results show that our proposed method outperforms the previous methods on various ranking-oriented evaluation metrics.",2014,Conference on Information and Knowledge Management,topic model;collaborative filtering;latent dirichlet allocation;information retrieval;data mining;database;pattern recognition;machine learning;statistics;computer science;
Exploiting Knowledge Structure for Proximity-aware Movie Retrieval Model,Sansung Kim (KAIST);Keejun Han (KAIST);Mun Y. Yi (KAIST);Sinhee Cho (KAIST);Seongchan Kim (KAIST);,"2270884672,2128874656,2128401584,2170836447,2111021341","Current movie title retrieval models, such as IMDB, mainly focus on utilizing structured or semi-structured data. However, user queries for searching a movie title are often based on the movie plot, rather than its metadata. As a solution to this problem, our movie title retrieval model proposes a new way of elaborately utilizing associative relations between multiple key terms that exist in the movie plot, in order to improve search performance when users enter more than one keyword. More specifically, the proposed model exploits associative networks of key terms, called knowledge structures, derived from the movie plots. Using the search query terms entered by Amazon Mechanical Turk users as the golden standard, experiments were conducted to compare the proposed retrieval model with the extant state-of-the-art retrieval models. The experiment results show that the proposed retrieval model consistently outperforms the baseline models. The findings have practical implications for semantic search of movie titles particularly, and of online entertainment contents in general.",2014,Conference on Information and Knowledge Management,distance;world wide web;information retrieval;data mining;database;computer science;
Hotspot Detection in a Service-Oriented Architecture,Pranay Anchuri (Rensselaer Polytechnic Institute);Roshan Sumbaly (LinkedIn);Sam Shah (LinkedIn);,"73046339,2045907651,2132445812","Large-scale websites are predominantly built as a service-oriented architecture. Here, services are specialized for a certain task, run on multiple machines, and communicate with each other to serve a user's request. Reducing latency and improving the cost to serve is quite important, but optimizing this service call graph is particularly challenging due to the volume of data and the graph's non-uniform and dynamic nature. In this paper, we present a framework to detect hotspots in a service-oriented architecture. The framework is general, in that it can handle arbitrary objective functions. We show that finding the optimal set of hotspots for a metric, such as latency, is NP-complete and propose a greedy algorithm by relaxing some constraints. We use a pattern mining algorithm to rank hotspots based on the impact and consistency. Experiments on real world service call graphs from LinkedIn, the largest online professional social network, show that our algorithm consistently outperforms baseline methods.",2014,Conference on Information and Knowledge Management,hotspot;call graph;service oriented architecture;world wide web;distributed computing;data mining;database;real time computing;computer science;
PraDa: Privacy-preserving Data-Deduplication-as-a-Service,Boxiang Dong (Stevens Institute of Technology);Ruilin Liu (Stevens Institute of Technology);Wendy Hui Wang (Stevens Institute of Technology);,"2134322708,2111878088,2107286628","The data-cleaning-as-a-service ( DCaS ) paradigm enables users to outsource their data and data cleaning needs to computationally powerful third-party service providers. It raises several security issues. One of the issues is how the client can protect the private information in the outsourced data. In this paper, we focus on data deduplication as the main data cleaning task, and design two efficient privacy-preserving data-deduplication methods for the DCaS paradigm. We analyze the robustness of our two methods against the attacks that exploit the auxiliary frequency distribution and the knowledge of the encoding algorithms. Our empirical study demonstrates the efficiency and effectiveness of our privacy preserving approaches.",2014,Conference on Information and Knowledge Management,data deduplication;outsourcing;information security;world wide web;computer security;data mining;database;computer science;
Re-call and Re-cognition in Episode Re-retrieval: A User Study on News Re-finding a Fortnight Later,Shuya Ochiai (Kyoto University);Makoto P. Kato (Kyoto University);Katsumi Tanaka (Kyoto University);,"2255109720,1993270567,2100196114","This study investigates recall and recognition in a news refinding task where participants were asked to read news articles and then to search for the same articles a fortnight later. Recall, which is a task to express what a person remembers, corresponds to query formulations, while recognition, which is a task to judge whether a presented item has been shown before, corresponds to a user's relevance judgment on search results in a refinding task. Our four main contributions can be summarized as follows: (i) we developed a method to investigate the effects of memory loss on episode refinding tasks on a large scale; (ii) our user study revealed a big drop on search performances in the refinding task after a fortnight and several differences between search queries input immediately after news browsing and ones at a later time; (iii) we found that asking questions and expanding input queries on the basis of the answers significantly improved the search performance in the news refinding task; and (iv) the users' recognition abilities were different than their recall abilities, e.g. object names in a news story could be correctly recognized even though they were rarely recalled. Our findings support several findings in cognitive psychology from the viewpoint of information refinding and also have several implications for search algorithms for assisting user refinding.",2014,Conference on Information and Knowledge Management,multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
Ranking Sentiment Explanations for Review Summarization Using Dual Decomposition,Lei Fang (Tsinghua University);Qiao Qian (Tsinghua University);Minlie Huang (Tsinghua University);Xiaoyan Zhu (Tsinghua University);,"2125249401,2112006610,2162268045,2147746173","For online reviews, sentiment explanations refer to the sentences that may suggest detailed reasons of sentiment, which are very important for applications in review mining like opinion summarization. In this paper, we address the problem of ranking sentiment explanations by formulating the process as two subproblems: sentence informativeness ranking and structural sentiment analysis. Tractable inference in joint prediction is performed through dual decomposition. Preliminary experiments on publicly available data demonstrate that our approach obtains promising performance.",2014,Conference on Information and Knowledge Management,sentiment analysis;data science;natural language processing;data mining;computer science;
Accelerometer-based Activity Recognition on Smartphone,"Xing Su (The Graduate Center, CUNY);Hanghang Tong (Arizona State University);Ping Ji (The Graduate Center, CUNY);","2305733563,2667261544,2678455680","Smartphones are ubiquitous and becoming more and more sophisticated, with ever-growing computing, networking and sensing powers. How can we help the users form a healthy habit by sending a reminder if s/he is sitting too long? How can we localize where we are inside a building and/or find the reception desk? Recognizing the physical activities (e.g., sitting, walking, jogging, etc) is a core building block to answer these questions and many more. We present AcRe, a human activity recognition application on smartphone. AcRe takes the motion data from different sensors on smartphones as inputs (e.g., accelerometer, compass, etc), and predicts a user's motion activities (e.g., walking upstairs, standing, sitting, etc) in real-time. It provides some additional functionalities, such as incorporating a user's feedback, daily activity summerization, etc. The application is built on iOS 7.0 and will be released soon in Apple's App Store. We will invite the audience to experiment with our AcRe in terms of its effectiveness, efficiency and applicability to various domains and the potential for further improvements.",2014,Conference on Information and Knowledge Management,mobile technology;activity recognition;embedded system;world wide web;data mining;machine learning;simulation;computer science;
Axiomatic Analysis of Cross-Language Information Retrieval,Razieh Rahimi (University of Tehran);Azadeh Shakery (University of Tehran);Irwin King (The Chinese University of Hong Kong);,"2134428435,2048088267,2121363826","A major challenge in Cross-Language Information Retrieval (CLIR) is the adoption of translation knowledge in retrieval models, as it affects the term weighting which is known to highly impact the retrieval performance. In this paper, we present an analytical study of using translation knowledge in CLIR. In particular, by adopting axiomatic analysis framework, we formulate the impacts of translation knowledge on document ranking as constraints that any cross-language retrieval model should satisfy. We then consider the state-of-the-art CLIR methods and check whether they satisfy these constraints. Finally, we show through empirical evaluation that violating one of the constraints harms the retrieval performance significantly which calls for further investigation.",2014,Conference on Information and Knowledge Management,cognitive models of information retrieval;divergence from randomness model;human computer information retrieval;natural language processing;information retrieval;data mining;database;computer science;
PatentDom: Analyzing Patent Relationships on Multi-View Patent Graphs,Longhui Zhang (Florida International University);Lei Li (Florida International University);Tao Li (Florida International University);Dingding Wang (Florida Atlantic University);,"2147074165,2432045905,2472069284,2097650207","The fast growth of technologies has driven the advancement of our society. It is often necessary to quickly grasp the linkage between different technologies in order to better understand the technical trend. The availability of huge volumes of granted patent documents provides a reasonable basis for analyzing the relationships between technologies. In this paper, we propose a unified framework, named PatentDom, to identify important patents related to key techniques from a large number of patent documents. The framework integrates different types of patent information, including patent content, citations of patents, and temporal relations, and provides a concise yet comprehensive technology summary. The identified key patents enable a variety of patent-related analytical applications, e.g., outlining the technology evolution of a particular domain, tracing a given technique to prior technologies, and mining the technical connection of two given patent documents. Empirical analysis and extensive case studies on a collection of US patent documents demonstrate the efficacy of our proposed framework.",2014,Conference on Information and Knowledge Management,patent visualisation;dominating set;steiner tree problem;data science;data mining;
Constrained Question Recommendation in MOOCs via Submodularity,Diyi Yang (Carnegie Mellon University);Jingbo Shang (Shanghai Jiao Tong University);Carolyn Penstein Rosé (Carnegie Mellon University);,"2127567756,2223914299,2152131012","A recent area in which recommender systems have shown their value is in online discussion forums and question-answer sites. Earlier work in this space has focused on the problem of matching participants to opportunities but has not adequately addressed the problem that in these social contexts, multiple dimensions of constraints must be satisfied, including limitations on capacity and minimal requirements for expertise. In this work, we propose such a constrained question recommendation problem with load balance constraints in discussion forums and use flow based model to generate the optimal solution. In particular, to address the introduced computation complexity, we investigate the concept of submodularity of the objective function and propose a specific submodular method to give an approximated solution. We present experiments conducted on two Massive Open Online Course (MOOC) discussion forum datasets, and demonstrate the effectiveness and efficiency of our submodular method in solving constrained question recommendation tasks.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Pulling Conjunctive Query Equivalence out of the Bag,Stefan Böttcher (University of Paderborn);Sebastian Link (University of Auckland);Lin Zhang (University of Auckland);,"2100168392,2095647292,2657879310","We present LECQTER, a tool for generating a 'perfect example' database, called exemplar, for a given conjunctive query. Indeed, exemplars separate the given query from any non-equivalent query. Therefore, LECQTER reduces the query equivalence problem to an evaluation of the queries on the exemplar. LECQTER can thus be used for applications ranging from testing coded conjunctive SQL queries to learning how to write sound conjunctive SQL queries, as it provides immediate feedback about the semantic correctness of a query, and not just the correctness of the query answer on some database as, e.g., other SQL tutoring systems. This key novelty of LECQTER relies on the bag semantics of SQL since exemplars do not always exist under set semantics. Detailed experiments show that our construction of exemplars is efficient in practice, and that they can separate a number of non-equivalent user queries that is exponential in the size of the exemplar for the target query. We identify natural parameters to control the time and size of the exemplars constructed. Finally, we offer a solution that overcomes the non-existence of exemplars under set semantics.",2014,Conference on Information and Knowledge Management,sargable;boolean conjunctive query;online aggregation;test data;web search query;web query classification;conjunctive query;spatial query;view;query by example;query expansion;sql;query optimization;query language;information retrieval;data mining;database;computer science;
"Anything You Can Do, I Can Do Better: Finding Expert Teams by CrewScout",Naeemul Hassan (University of Texas at Arlington);Huadong Feng (University of Texas at Arlington);Ramesh Venkataraman (University of Texas at Arlington);Gautam Das (University of Texas at Arlington);Chengkai Li (University of Texas at Arlington);Nan Zhang (George Washington University);,"2222345529,2228441109,2497400222,2112689123,2145831560,2166589344","CrewScout is an expert-team finding system based on the concept of skyline teams and efficient algorithms for finding such teams. Given a set of experts, CrewScout finds all k -expert skyline teams, which are not dominated by any other k -expert teams. The dominance between teams is governed by comparing their aggregated expertise vectors. The need for finding expert teams prevails in applications such as question answering, crowdsourcing, panel selection, and project team formation. The new contributions of this paper include an end-to-end system with an interactive user interface that assists users in choosing teams and an demonstration of its application domains.",2014,Conference on Information and Knowledge Management,knowledge management;world wide web;data mining;computer science;
Machine-Assisted Search Preference Evaluation,Ahmed Hassan Awadallah (Microsoft);Imed Zitouni (Microsoft);,"2094223786,2507515815","Information Retrieval systems are traditionally evaluated using the relevance of web pages to individual queries. Other work on IR evaluation has focused on exploring the use of preference judgments over two search result lists. Unlike traditional query-document evaluation, collecting preference judgments over two search result-lists takes the context of documents, and hence takes the interaction between search results, into consideration. Moreover, preference judgments have been shown to produce more accurate results compared to absolute judgment. On the other hand result list preference judgments have very high annotation cost. In this work, we investigate how machine learned models can assist human judges in order to collect reliable result list preference judgments at large scale with lower judgment-cost. We build novel models that can predict user preference automatically. We investigate the effect of different features on the prediction quality. We focus on predicting preferences with high confidence and show that these models can be effectively used to assist human judges resulting in significant reduction in annotation cost.",2014,Conference on Information and Knowledge Management,preference learning;information retrieval;data mining;computer science;
Query-Driven Mining of Citation Networks for Patent Citation Retrieval and Recommendation,Parvaz Mahdabi (University of Lugano);Fabio Crestani (University of Lugano);,"257166816,2303795236","Prior art search or recommending citations for a patent application is a challenging task. Many approaches have been proposed and shown to be useful for prior art search. However, most of these methods do not consider the network structure for integrating and diffusion of different kinds of information present among tied patents in the citation network. In this paper, we propose a method based on a time-aware random walk on a weighted network of patent citations, the weights of which are characterized by contextual similarity relations between two nodes on the network. The goal of the random walker is to find influential documents in the citation network of a query patent, which can serve as candidates for drawing query terms and bigrams for query refinement. The experimental results on CLEF-IP datasets (CLEF-IP 2010 and CLEF-IP 2011) show the effectiveness of encoding contextual similarities (common classification codes, common inventor, and common applicant) between nodes in the citation network. Our proposed approach can achieve significantly better results in terms of recall and Mean Average Precision rates compared to strong baselines of prior art search.",2014,Conference on Information and Knowledge Management,data science;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Negative FaceBlurring: A Privacy-by-Design Approach to Visual Lifelogging with Google Glass,Tengqi Ye (Dublin City University);Brian Moynagh (Dublin City University);Rami Albatal (Dublin City University);Cathal Gurrin (Dublin City University);,"2107226643,21149052,60638085,2009834041","Wearable devices such as Google Glass are receiving increasing attention and look set to become part of our technical landscape over the next few years. At the same time, lifelogging is a topic that is growing in popularity with a host of new devices on the market that visually capture life experience in an automated manner. In this paper, we describe a visual lifelogging solution for Google Glass that is designed to capture life experience in rich visual detail, yet maintain the privacy of unknown bystanders. We present the approach called negative face blurring and evaluate it on a collection of lifelogging data of around nine thousand pictures from Google Glass.",2014,Conference on Information and Knowledge Management,smartglasses;lifelog;internet privacy;multimedia;world wide web;information retrieval;data mining;database;machine learning;computer science;
Using Local Information to Significantly Improve Classification Performance,"Wei Liu (University of Technology, Sydney);Dong Lee (University of Melbourne);Kotagiri Rao (University of Melbourne);","2172864801,2421194493,2222003406","In this research we propose to derive new features based on data samples' local information with the aim of improving the performance of general supervised learning algorithms. The creation of new features is inspired by the measure of average precision which is known to be a robust measure that is insensitive to the number of retrieved items in information retrieval. We use the idea of average precision to weight the neighbours of an instance and show that this weighting strategy is insensitive to the number of neighbours in the locality. Information captured in the new features allows a general classifier to learn additional useful peripheral knowledge that are helpful in building effective classification models. We comprehensively evaluate our method on real datasets and the results show substantial improvements in the performance of classifiers including SVM, Bayesian networks, random forest, and C4.5.",2014,Conference on Information and Knowledge Management,biological classification;data mining;pattern recognition;machine learning;
Supervised Nested PageRank,Maxim Zhukovskiy (Yandex);Gleb Gusev (Yandex);Pavel Serdyukov (Yandex);,"2018740001,2005728791,2130450538","Graph-based ranking plays a key role in many applications, such as web search and social computing. Pioneering methods of ranking on graphs (e.g., PageRank and HITS) computed ranking scores relying only on the graph structure. Recently proposed methods, such as Semi-Supervised Page-Rank, take into account both the graph structure and the metadata associated with nodes and edges in a unified optimization framework. Such approaches are based on initializing the underlying random walk models with prior weights of nodes and edges that in turn depend on their individual properties. While in those models the prior weights of nodes and edges depend only on their own features, one can also assume that such weights may also depend or be related to the prior weights of their neighbors. This paper addresses the problem of weighting nodes and edges according to this intuition by realizing it in a general ranking model and an efficient algorithm of tuning the parameters of that model.",2014,Conference on Information and Knowledge Management,random walk;world wide web;data mining;database;machine learning;statistics;computer science;
Learning Interactions for Social Prediction in Large-scale Networks,Xiaofeng Yu (HP Labs);Junqing Xie (HP Labs);,"2706263546,2666783490","Social networks have already emerged as inconceivably vast information repositories and have provided great opportunities for social connection and information diffusion. In light of these notable outcomes, social prediction is a critical research goal for analyzing and understanding social media and online social networks. We investigate underlying social theories that drive the characteristics and dynamics of social networks, including homophily, heterophily, and the structural hole theories. We propose a unified coherent framework, namely mutual latent random graphs (MLRGs), to exploit mutual interactions and benefits for predicting social actions (e.g., users' behaviors, opinions, preferences or interests) and discovering social ties (e.g., multiple labeled relationships between users) simultaneously in large-scale social networks. MLRGs introduce latent, or hidden factors and coupled models with users, users' actions and users' ties to flexibly encode evidences from both sources. We propose an approximate optimization algorithm to learn the model parameters efficiently. Furthermore, we speedup this algorithm based on the Hadoop MapReduce framework to handle large-scale social networks. We performed experiments on two real-world social networking datasets to demonstrate the validity and competitiveness of our approach.",2014,Conference on Information and Knowledge Management,social heuristics;interpersonal ties;social network;world wide web;data mining;database;artificial intelligence;machine learning;computer science;
Analytical Performance Modeling for Top-K Query Processing,Hao Wu (University of Delaware);Hui Fang (University of Delaware);,"2225904997,2618399871","Top-K query processing is one of the most important problems in large-scale Information Retrieval systems. Since query processing time varies for different queries, an accurate run-time performance prediction is critical for online query scheduling and load balancing, which could eventually reduce the query waiting time and improve the throughput. Previous studies estimated the query processing time based on the combination of term-level features. Unfortunately, these features were often selected arbitrarily, and the linear combination of these features might not be able to accurately capture the complexity in the query processing. In this paper, we propose a novel analytical performance modeling framework for top-K query processing. Our goal is to provide a systematic way of identifying important features for the efficiency prediction and then develop a general framework for estimating the query processing time. Specifically, we divide the query processing into three stages, identify useful features and discuss how to use them to model the query processing time for each stage. After that, we propose to fit the model using a step-by-step strategy and compute the approximated feature values based on easily obtained statistics. Experimental results on TREC collections show that the developed performance model can predict the query processing time more accurately than the state of the art efficiency predictor, in particular for the dynamic pruning methods.",2014,Conference on Information and Knowledge Management,sargable;ranking;online aggregation;web query classification;spatial query;query expansion;query optimization;information retrieval;data mining;database;machine learning;computer science;
AMiner-mini: A People Search Engine for University,Jingyuan Liu (Tsinghua University);Debing Liu (Tsinghua University);Xingyu Yan (Tsinghua University);Li Dong (Tsinghua University);Ting Zeng (Tsinghua University);Yutao Zhang (Tsinghua University);Jie Tang (Tsinghua University);,"2492217781,2223203911,2222431949,2590279867,2564083843,2223115198,2158012360","We present a distributed academic search and mining system? AMiner-mini. The system offers intra- and inter- university level academic search and mining services. It integrates academic data from multiple sources and performs disambiguation for people names, which is a fundamental issue for searching people. We employ a two-phases approach that formalizes the disambiguation problem into a HMRF framework, which significantly improves the disambiguation performance. Based on the disambiguation results, AMiner-mini offers a people search function, which returns experts (or related researchers) for a given query by the user. The user can also choose different metrics to rank the search results and explore the results from different dimensions. The system is designed in a distributed structure. It can be deployed in a university as a stand-alone system for finding the right people who are working on a research topic. Multiple distributed systems can be also connected via Web services and perform search or mining in an asynchronous way and return the combination results. We have deployed the system in Tsinghua University and feedback from university academic users shows that the system worked well and achieved its primary objective.",2014,Conference on Information and Knowledge Management,data science;natural language processing;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
A Dynamic Reconstruction Approach to Topic Summarization of User-Generated-Content,Zhao Yan Ming (National University of Singapore);Jintao Ye;Tat Seng Chua (National University of Singapore);,"2344601562,2701394562,2283542782","User generated contents (UGCs) from various social media sites give analysts the opportunity to obtain a comprehensive and dynamic view of any topic from multiple heterogeneous information sources. Summarization provides a promising means of distilling the overview of the targeted topic by aggregating and condensing the related UGCs. However, the mass volume, uneven quality, and dynamics of UGCs, pose new challenges that are not addressed by existing multi-document summarization techniques. In this paper, we introduce a timely task of dynamic structural and textual summarization. We generate topic hierarchy from the UGCs as a high level overview and structural guide for exploring and organizing the content. To capture the evolution of events in the content, we propose a unified dynamic reconstruction approach to detect the update points and generate the time-sequence textual summary. To enhance the expressiveness of the reconstruction space, we further use the topic hierarchy to organize the UGCs and the hierarchical subtopics to augment the sentence representation. Experimental comparison with the state-of-the-art summarization models on a multi-source UGC dataset shows the superiority of our proposed methods. Moreover, we conducted a user study on our usability enhancement measures. It suggests that by disclosing some meta information of the summary generation process in the proposed framework, the time-sequence textual summaries can pair with the structural overview of the topic hierarchy to achieve interpretable and verifiable summarization.",2014,Conference on Information and Knowledge Management,user generated content;multi document summarization;automatic summarization;world wide web;information retrieval;data mining;database;machine learning;computer science;
MeowsReader: Real-Time Ranking and Filtering of News with Generalized Continuous Top-k Queries,Nelly Vouzoukidou (Pierre-and-Marie-Curie University);Bernd Amann (Pierre-and-Marie-Curie University);Vassilis Christophides (Technicolor);,"2094178657,2702613376,55450124","This demonstration presents MeowsReader, a real-time news ranking and filtering prototype. MeowsReader illustrates how a general class of continuous top-k queries offers a suitable abstraction for modeling and implementing real-time search services over highly dynamic information streams combining keyword search and realtime web signals about information items. Users express their interest by simple text queries and continuously receive the best matching results in an alert-like environment. The main innovative feature are dynamic item scores which take account of information decay, real-time web attention and other online user feedback. Additionally, a trends detection mechanism automatically generates trending entities from the input streams, which can smoothly be added to user profiles in form of keyword queries.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;computer science;
GTE-Rank: Searching for Implicit Temporal Query Results,Ricardo Campos (University of Beira Interior);Gaël Dias (University of Caen Lower Normandy);Alípio Mário Jorge (University of Porto);Célia Nunes (University of Beira Interior);,"2141847506,2658899117,2165617838,2015837873","Temporal information retrieval has been a topic of great interest in recent years. Despite the efforts that have been conducted so far, most popular search engines remain underdeveloped when it comes to explicitly considering the use of temporal information in their search process. In this paper we present GTE-Rank, an online searching tool that takes time into account when ranking time-sensitive query web search results. GTE-Rank is defined as a linear combination of topical and temporal scores to reflect the relevance of any web page both in topical and temporal dimensions. The resulting system can be explored graphically through a search interface made available for research purposes.",2014,Conference on Information and Knowledge Management,ranking;web search query;query expansion;temporal database;world wide web;information retrieval;data mining;database;computer science;
Semantic Approximate Keyword Query Based on Keyword and Query Coupling Relationship Analysis,"Xiangfu Meng (Liaoning Technical University);longbing Cao (University of Technology, Sydney);Jingyu Shao (University of Technology, Sydney);","2703902334,2115085568,2231241261","Due to imprecise query intention, Web database users often use a limited number of keywords that are not directly related to their precise query to search information. Semantic approximate keyword query is challenging but helpful for specifying such query intent and providing more relevant answers. By extracting the semantic relationships both between keywords and keyword queries, this paper proposes a new keyword query approach which generates semantic approximate answers by identifying a set of keyword queries from the query history whose semantics are related to the given keyword query. To capture the semantic relationships between keywords, a semantic coupling relationship analysis model is introduced to model both the intra - and inter-keyword couplings . Building on the coupling relationships between keywords, the semantic similarity of different keyword queries is then measured by a semantic matrix. The representative queries in query history are identified and then a priori order of remaining queries corresponding to each representative query in an off-line preprocessing step is created. These representative queries and associated orders are then used to expeditiously generate top- k ranked semantically related keyword queries. We demonstrate that our coupling relationship analysis model can accurately capture the semantic relationships both between keywords and queries. The efficiency of top- k keyword query selection algorithm is also demonstrated.",2014,Conference on Information and Knowledge Management,sargable;keyword density;boolean conjunctive query;web search query;web query classification;spatial query;query expansion;query optimization;query language;information retrieval;data mining;database;computer science;
Manual Annotation of Semi-Structured Documents for Entity-Linking,Salvatore Trani (National Research Council);Diego Ceccarelli (National Research Council);Claudio Lucchese (National Research Council);Salvatore Orlando (Ca' Foscari University of Venice);Raffaele Perego (National Research Council);,"2222901681,2307320251,1989507918,2109622093,1650486011","The Entity Linking (EL) problem consists in automatically linking short fragments of text within a document to entities in a given Knowledge Base like Wikipedia. Due to its impact in several text-understanding related tasks, EL is an hot research topic. The correlated problem of devising the most relevant entities mentioned in the document, a.k.a. salient entities (SE), is also attracting increasing interest. Unfortunately, publicly available evaluation datasets that contain accurate and supervised knowledge about mentioned entities and their relevance ranking are currently very poor both in number and quality. This lack makes very difficult to compare different EL and SE solutions on a fair basis, as well as to devise innovative techniques that relies on these datasets to train machine learning models, in turn used to automatically link and rank entities. In this demo paper we propose a Web-deployed tool that allows to crowdsource the creation of these datasets, by supporting the collaborative human annotation of semi-structured documents. The tool, called Elianto, is actually an open source framework, which provides a user friendly and reactive Web interface to support both EL and SE labelling tasks, through a guided two-step process.",2014,Conference on Information and Knowledge Management,entity linking;natural language processing;world wide web;information retrieval;data mining;database;machine learning;computer science;
DEESSE: entity-Driven Exploratory and sErendipitous Search SystEm,Olivier Van Laere (Yahoo!);Ilaria Bordino (Yahoo!);Yelena Mejova (Qatar Computing Research Institute);Mounia Lalmas (Yahoo!);,"1985108775,22319059,2083323769,46148421","We present DEESSE [1], a tool that enables an exploratory and serendipitous exploration - at entity level, of the content of two different social media: Wikipedia, a user-curated online encyclopedia, and Yahoo Answers, a more unconstrained question/answering forum. DEESSE represents the content of each source as an entity network, which is further enriched with metadata about sentiment, writing quality, and topical category. Given a query entity, entity results are retrieved from the network by employing an algorithm based on a random walk with restart to the query. Following the emerging paradigm of composite retrieval , we organize the results into topically coherent bundles instead of showing them in a simple ranked list.",2014,Conference on Information and Knowledge Management,entity linking;world wide web;information retrieval;data mining;database;computer science;
Exploring Features for Complicated Objects: Cross-View Feature Selection for Multi-Instance Learning,"Jia Wu (University of Technology, Sydney);Zhibin Hong (University of Technology, Sydney);Shirui Pan (University of Technology, Sydney);Xingquan Zhu (Florida Atlantic University);Zhihua Cai (China University of Geosciences);Chengqi Zhang (University of Technology, Sydney);","2151584597,2110797701,2132909836,2618356905,2136429757,2166080598","In traditional multi-instance learning (MIL), instances are typically represented by using a single feature view. As MIL becoming popular in domain specific learning tasks, aggregating multiple feature views to represent multi-instance bags has recently shown promising results, mainly because multiple views provide extra information for MIL tasks. Nevertheless, multiple views also increase the risk of involving redundant views and irrelevant features for learning. In this paper, we formulate a new cross-view feature selection problem that aims to identify the most representative features across all feature views for MIL. To achieve the goal, we design a new optimization problem by integrating both multi-view representation and multi-instance bag constraints. The solution to the objective function will ensure that the identified top- m features are the most informative ones across all feature views. Experiments on two real-world applications demonstrate the performance of the cross-view feature selection for content-based image retrieval and social media content recommendation.",2014,Conference on Information and Knowledge Management,feature recognition;feature;feature learning;data mining;pattern recognition;machine learning;computer science;
CoDEM: An Ingenious Tool of Insight into Community Detection in Social Networks,Meng Wang (Tsinghua University);Chaokun Wang (Tsinghua University);Jun Chen (Tsinghua University);,"2652007641,2106340623,2699188541","In recent years, community structure has attracted increasing attention in social network analysis. However, performances of multifarious approaches to community detection are seldom evaluated in a suite of systematic measurements. Furthermore, we can hardly find works which reveal diverse features based on the detected community structure. In this paper, we build a tool called CoDEM to make both quality evaluations of community detection and an in-depth mining for pivotal nodes inside communities. This tool integrates several effective approaches to community detection, establishes an overall evaluation system and gets the multi-dimensional ranking for the local importance of nodes. Moreover, the tool is built with a friendly user interface.",2014,Conference on Information and Knowledge Management,evaluation;world wide web;data mining;simulation;
Improving Tail Query Performance by Fusion Model,Shuai Huo (Tsinghua University);Min Zhang (Tsinghua University);Yiqun Liu (Tsinghua University);Shaoping Ma (Tsinghua University);,"2525866987,2526008467,2111097927,2109195263","Tail queries, which occur with low frequency, make up a large fraction of unique queries and often affect a user's experience during Web searching. Because of the data sparseness problem, information that can be leveraged for tail queries is not sufficient. Hence, it is important and difficult to improve the tail query performance. According to our observation, 26% of the tail queries are not essentially scarce: they are expressed in an unusual way, but the information requirements are not rare. In this study, we improve the tail query performance by fusing the results from original query and the query reformulation candidates. Other than results re-ranking, new results can be introduced by the fusion model. We emphasize that queries that can be improved are not only bad queries, and we propose to extract features that predict whether the performance can be improved. Then, we utilize a learning-to-rank method, which is trained to directly optimize a retrieval metric, to fuse the documents and obtain a final results list. We conducted experiments using data from two popular Chinese search engines. The results indicate that our fusion method significantly improves the performance of the tail queries and outperforms the state-of-the-art approaches on the same reformulations. Experiments show that our method is effective for the non-tail queries as well.",2014,Conference on Information and Knowledge Management,web query classification;spatial query;query expansion;query optimization;learning to rank;world wide web;information retrieval;data mining;database;machine learning;computer science;
Tell Me What You Want and I Will Tell Others Where You Have Been,Anthony Quattrone (University of Melbourne);Elham Naghizade (University of Melbourne);Lars Kulik (University of Melbourne);Egemen Tanin (University of Melbourne);,"2228545386,2231407868,1899350157,66485931","Trajectory data does not only show the location of users over a period of time, but also reveals a high level of detail regarding their lifestyle, preferences and habits. Hence, it is highly susceptible to privacy concerns. Trajectory privacy has become a key research topic when sharing/exchanging trajectory datasets. Most existing studies focus on protecting trajectory data through obfuscating, anonymising or perturbing the data with the aim to maximize user privacy. Although such approaches appear plausible, our work suggests that precise trajectory information can be inferred even from other sources of data. We consider the case in which a location service provider only shares POI query results of users with third parties instead of exchanging users' raw trajectory data to preserve privacy. We develop an inference algorithm and show that it can effectively approximate original trajectories using solely the POI query results.",2014,Conference on Information and Knowledge Management,internet privacy;world wide web;data mining;database;computer science;
Parameter Tuning with User Models: Influencing Aggregate User Behavior in Cluster Based Retrieval Systems,Vinay Deolalikar (Hewlett-Packard);,2150307071,"Can we effectively influence aggregate user behavior in a cluster based retrieval (CBR) system by tuning its parameters? This question combines parameter tuning with models of user behavior. To address this question, we propose an approach based on three components: user model, criterion metric, and sensitivity analysis. We then demonstrate this approach on one of the most frequently asked questions to designers and operators of CBR systems in enterprises: namely, ""suggest a value for k ."" Both the users and the system desire a value that is likely to maximize user satisfaction, and sway them towards a cluster based examination of their retrieved result set (rather than prefer the original ranked retrieved list). Based on observed user behavior in CBR systems, we posit a two-stage user model. We isolate its core element, which is a ""query coverage metric."" We then perform an empirical sensitivity analysis of this metric. Our analysis reveals that this metric is, surprisingly, robust to changes in k (i.e., insensitive to k ) in a wide range around its de-facto value. We conclude that in cases where our model approximates user behavior, the system cannot substantially increase the chances of the user resorting to CBR by tuning k . This has practical implications on the design and day-to-day operation of CBR systems. Similar analyses can be carried out for other parameters.",2014,Conference on Information and Knowledge Management,world wide web;information retrieval;data mining;database;machine learning;simulation;computer science;
Adding Robustness to Support Vector Machines Against Adversarial Reverse Engineering,Ibrahim M. Alabdulmohsin (King Abdullah University of Science and Technology);Xin Gao (King Abdullah University of Science and Technology);Xiangliang Zhang (King Abdullah University of Science and Technology);,"717680490,2588767281,2129841492","Many classification algorithms have been successfully deployed in security-sensitive applications including spam filters and intrusion detection systems. Under such adversarial environments, adversaries can generate exploratory attacks against the defender such as evasion and reverse engineering. In this paper, we discuss why reverse engineering attacks can be carried out quite efficiently against fixed classifiers, and investigate the use of randomization as a suitable strategy for mitigating their risk. In particular, we derive a semidefinite programming (SDP) formulation for learning a distribution of classifiers subject to the constraint that any single classifier picked at random from such distribution provides reliable predictions with a high probability. We analyze the tradeoff between variance of the distribution and its predictive accuracy, and establish that one can almost always incorporate randomization with large variance without incurring a loss in accuracy. In other words, the conventional approach of using a fixed classifier in adversarial environments is generally Pareto suboptimal. Finally, we validate such conclusions on both synthetic and real-world classification problems.",2014,Conference on Information and Knowledge Management,reverse engineering;data mining;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
A Problem-Action Relation Extraction Based on Causality Patterns of Clinical Events in Discharge Summaries,Jae-Wook Seol (Chonbuk National University);Seung-Hyeon Jo (Chonbuk National University);Wangjin Yi (Seoul National University);Jinwook Choi (Seoul National University);Kyung-Soon Lee (Chonbuk National University);,"2055617802,2502181884,2437587865,2124740825,2103478774","Medical knowledge extraction has great potential to improve the treatment quality of hospitals. In this paper, we propose a clinical problem-action relation extraction method. It is based on clinical semantic units and event causality patterns in order to present a chronological view of a patient's problem and a physician's action. Based on our observation, a clinical semantic unit is defined as a conceptual medical knowledge for a problem and/or action. Since a clinical event is a basic concept of the problem-action relation, events are detected from clinical texts based on conditional random fields. A clinical semantic unit is segmented from a sentence based on time expressions and inherent structure of events. Then, a clinical semantic unit is classified into a problem and/or action relation based on event causality features in support vector machines. The experimental result on Korean medical collection shows 78.8% in F-measure when given the answer of clinical events. This result shows that the proposed method is effective for extracting clinical problem-action relations.",2014,Conference on Information and Knowledge Management,causality;relationship extraction;data science;data mining;pattern recognition;computer science;
Term Selection and Result Reranking for Question Retrieval by Exploiting Hierarchical Classification,Wen Chan (Fudan University);Jintao Du (Fudan University);Weidong Yang (Fudan University);Jinhui Tang (Nanjing University of Science and Technology);Xiangdong Zhou (Fudan University);,"2113599735,2108134562,2721360668,2683885818,2150544467","Question retrieval aims to increase the accessibility of the community Question Answer (cQA) archives and has attracted increasing research interests recently. In this paper, we present a novel method for improving the question retrieval performance by investigating the question term selection and weighting as well as reranking results. Different from previous work, we propose a hierarchical question classification method with a sparse regularization to mimc user's question labeling in cQAs. Based on the hierarchical classification, we explore the local context of the question for term selection and reranking results and then integrating them into our proposed general question retrieval framework. The experimental results on a Yahoo! Answers dataset show the effectiveness of our method as compared to existing general question retrieval models and some state-of-the-art methods of utilizing category information for question retrieval.",2014,Conference on Information and Knowledge Management,information retrieval;data mining;pattern recognition;
User Interests Imbalance Exploration in Social Recommendation: A Fitness Adaptation,Tianchun Wang (Tsinghua University);Xiaoming Jin (Tsinghua University);Xuetao Ding (Yahoo!);Xiaojun Ye (Tsinghua University);,"2689849113,2127078753,2112154713,2111378818","Recent years have witnessed an increasing interest in how to incorporate social network information into recommendation algorithms to enhance the user experience. In this paper, we find the phenomenon that users in the contexts of recommendation system and social network do not share the same interest space. Based on this finding, we proposed the social regulatory factor regression model (SRFRM) which could connect different interest spaces in different contexts together in an unified latent factor model. Specifically, different from the traditional social based latent factor models with strong limitation that all sides share the same feature space, the proposed method leverages the regulatory factor number on both sides to meet the fact that users and items or users in different contexts may not share the same interest space. It works by incorporating two linear transformation matrices into the matrix co-factorization framework that matrix factorization of user ratings is regularized by that of social trust network. We study a large subsets of data from epinions.com and douban.com respectively. The experimental results indicate that users in different contexts have different interest spaces and our model achieves a higher performance compared with related state-of-the-art methods.",2014,Conference on Information and Knowledge Management,matrix decomposition;social network;recommender system;multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;machine learning;computer science;
Faceted Exploring for Domain Knowledge over Linked Open Data,Meng Wang (Xi'an Jiaotong University);Jun Liu (Xi'an Jiaotong University);Wenqiang Liu (Xi'an Jiaotong University);Qinghua Zheng (Xi'an Jiaotong University);Wei Zhang (Amazon.com);Lingyun Song (Xi'an Jiaotong University);Siyu Yao (Xi'an Jiaotong University);,"2644358849,2659490034,2693089167,2149828499,2710488335,2226229048,2303999623","The rapidly increasing RDF data in the Linked Open Data (LOD) community project is a valuable resource for obtaining domain knowledge. However, RDF data of specific topics also shows a trend of being more decentralized and fragmented, which makes it difficult and inefficient for the users to get an overview of a specific topic and retrieve the desired information. In this paper, we demonstrate a novel system called KFM, which can aggregate the distributed RDF data of a topic according to the facets of this topic. KFM provides a new way for users to obtain and explore domain knowledge in the LOD cloud.",2014,Conference on Information and Knowledge Management,simple knowledge organization system;rdf schema;rdf;linked data;domain knowledge;sensor fusion;world wide web;information retrieval;data mining;database;computer science;
Spatial Verification for Scalable Mobile Image Retrieval,Xiyu Yang (Xi'an Jiaotong University);Xueming Qian (Xi'an Jiaotong University);,"2658007144,2155012687","Owing to the portable and excellent phone camera, people now prefer to take photos and upload them by mobile phone. Content based image retrieval is effective for users to obtain relevant information about a photo. Taking the limited bandwidth and instability into account, we propose an effective scalable mobile image retrieval approach in this paper. The proposed mobile image retrieval algorithm first determines the relevant photos according to visual similarity in mobile end, then mines salient visual words by exploring saliency from multiple relevant images, and finally we determine the contribution order of salient visual words for scalable retrieval. In server terminal, spatial verification is performed to re-rank the results. Compared to the existing approaches of mobile image retrieval, our approach transmits less data and reduces the computational cost of spatial verification. Most importantly, when the bandwidth is limited, we can transmit a part of features according their contributions to retrieval. Experimental results show the effectiveness of the proposed approach.",2014,Conference on Information and Knowledge Management,visual word;image retrieval;multimedia;information retrieval;computer vision;computer science;
Exploring Shared Subspace and Joint Sparsity for Canonical Correlation Analysis,Liang Tao (City University of Hong Kong);Horace Ho-Shing Ip (City University of Hong Kong);Yinglin Wang (Shanghai University of Finance and Economics);Xin Shu (Nanjing Agricultural University);,"2397065378,2160722999,2688316405,2438379670","Canonical correlation analysis (CCA) has been extensively employed in various real-world applications of multi-label annotation. However, two major challenges are raised by the classical CCA. First, CCA frequently fails to remove noisy and irrelevant features. Second, CCA cannot effectively capture correlations between multiple labels, which are especially beneficial for multi-label learning. In this paper, we propose a novel framework that integrates joint sparsity and low-rank shared subspace into the least-squares formulation of CCA. Under this framework, multiple label interactions can be uncovered by the shared structure of the input features and a few highly discriminative features can be decided via structured sparsity inducing norm. Owing to the inclusion of the non-smooth row sparsity, a new efficient iterative algorithm is derived with proved convergence. The empirical studies on several popular web image and movie data collections consistently deliver the effectiveness of our new formulation in comparison with competing algorithms.",2014,Conference on Information and Knowledge Management,canonical correlation;sparsity of effects principle;data mining;pattern recognition;machine learning;statistics;computer science;
Model Selection with the Covering Number of the Ball of RKHS,Lizhong Ding (Tianjin University);Shizhong Liao (Tianjin University);,"2691349481,2720258824","Model selection in kernel methods is the problem of choosing an appropriate hypothesis space for kernel-based learning algorithms to avoid either underfitting or overfitting of the resulting hypothesis. One of main problems faced by model selection is how to control the sample complexity when designing the model selection criterion. In this paper, we take balls of reproducing kernel Hilbert spaces (RKHSs) as candidate hypothesis spaces and propose a novel model selection criterion via minimizing the empirical optimal error in the ball of RKHS and the covering number of the ball. By introducing the covering number to measure the capacity of the ball of RKHS, our criterion could directly control the sample complexity. Specifically, we first prove the relation between expected optimal error and empirical optimal error in the ball of RKHS. Using the relation as the theoretical foundation, we give the definition of our criterion. Then, by estimating the expectation of optimal empirical error and proving an upper bound of the covering number, we represent our criterion as a functional of the kernel matrix. An efficient algorithm is further developed for approximately calculating the functional so that the fast Fourier transform (FFT) can be applied to achieve a quasi-linear computational complexity. We also prove the consistency between the approximate criterion and the accurate one for large enough samples. Finally, we empirically evaluate the performance of our criterion and verify the consistency between the approximate and accurate criterion.",2014,Conference on Information and Knowledge Management,bayesian information criterion;kernel method;model selection;machine learning;mathematical optimization;statistics;computer science;
Log-Bilinear Document Language Model for Ad-hoc Information Retrieval,Xinhui Tu (Central China Normal University);Jing Luo (Wuhan University);Bo Li (Central China Normal University);Tingting He (Central China Normal University);,"2721759343,2721096982,2180354522,2204855006","Incorporating semantic information into document representation is effective and potentially significant to improve retrieval performance. Recently, log-bilinear language model (LBL), as a form of neural language model, has been proved to be an effective way to learn semantic word representations, but its feasibility and effectiveness in information retrieval is mostly unknown. In this paper, we study how to efficiently use LBL to improve as-hoc retrieval. We propose a log-bilinear document language model (LB-DM) within the language modeling framework. The key idea is to learn semantically oriented representations for words, and estimate document language models based on these representations. Noise-constrictive estimation is employed to perform fast training on large document collections. Experiment results on standard TREC collections show that LB-DM performs better than translation language model and LDA-based retrieval model.",2014,Conference on Information and Knowledge Management,cognitive models of information retrieval;divergence from randomness model;cache language model;universal networking language;explicit semantic analysis;bag of words model;language identification;vector space model;document clustering;language model;question answering;document retrieval;natural language processing;world wide web;information retrieval;data mining;database;computer science;
A Practical Fine-grained Approach to Resolving Incoherent OWL 2 DL Terminologies,Jianfeng Du (Guangdong University of Foreign Studies);Guilin Qi (Southeast University);Xuefeng Fu (Southeast University);,"2715239518,2178685138,2412203397","Resolving incoherent terminologies is an important task in the maintenance of evolving OWL 2 DL ontologies. Existing approaches to this task are either semi-automatic or based on simple deletion of axioms. There is a need of fine-grained approaches to automatize this task. Since a fine-grained approach should consider multiple choices for modifying an axiom other than the deletion of axioms only, the primary challenges for developing such an approach lie in both the semantics of the repaired results and the efficiency in computing the repaired results. To tackle these challenges, we first introduce the notion of fine-grained repair based on modifying one axiom to zero or more axioms, then propose an efficient incremental method for computing all fine-grained repairs one by one. We also propose a modification function for axioms expressed in OWL 2 DL, which returns weaker axioms. Based on this modification function and the method for computing fine-grained repairs, we develop an automatic approach to resolving incoherent OWL 2 DL terminologies. Our extensive experimental results demonstrate that the proposed approach is efficient and practical.",2014,Conference on Information and Knowledge Management,web ontology language;description logic;theoretical computer science;database;artificial intelligence;algorithm;computer science;
Clairvoyant: An Early Prediction System For Video Hits,Hao Chen (East China Normal University);Qinmin Hu (East China Normal University);Liang He (East China Normal University);,"2656495818,2722241681,2635866734","Our slogan for the proposed Clairvoyant system is ""with several clicks, the future is in your hand, the plan comes into your mind"". Clairvoyant is to predict the future of new videos with only few data. The core function in the system is the novel shifted shape match prediction algorithm, based on a K-Nearest Neighbor model. Tons of experiments have been conducted on the open data sets. The experimental results confirms that the proposed SSMP algorithm is promising and outperforms the baselines with significant improvements on various evaluation methods. A demonstration video has been published at http://1drv.ms/1nyH3hD.",2014,Conference on Information and Knowledge Management,k nearest neighbors algorithm;world wide web;data mining;database;artificial intelligence;machine learning;simulation;computer science;
Proceedings of the 4th International Workshop on Location and the Web,Dirk Ahlers (Norwegian University of Science and Technology);Erik Wilde (EMC Corporation);Bruno Martins (University of Lisbon);,"2019721281,2122182102,2238216042","It is our great pleasure to welcome you to the 2014 ACM Workshop on Location and the Web -- LocWeb'14. This is the fourth workshop in its series which is hosted by CIKM after having been held previously at WWW, CHI, and IoT. The main objective of the workshop is to bring together a community of researchers at the intersection of location and the Web, serving as a unique venue to integrate different backgrounds and to stimulate the exchange of ideas and closer cooperation. LocWeb will provide a topicspecific venue where researchers from different fields, be it data mining, recommendation, search, systems, social media, applications, or standards, can discuss and develop the role of location. In the context of LocWeb 2014, the location topic is understood as a cross-cutting issue that not only concerns information retrieval, but databases, knowledge management, and systems as well. The workshop establishes an integrated venue where the location aspect can be discussed in depth within an interested community. LocWeb follows the main theme of Location-Aware Information Access, with subtopics related to Search, Analytics, Mobility, Apps, Services, and Systems. It is designed to reflect the multitude of fields that demand and utilize location features from an interdisciplinary perspective. We also encourage attendees to attend the highly relevant keynote presentation. It will give an interesting overview of different ways to think about human mobility and explore research into modeling approaches: Two Ways of Thinking About Where People Go, Vanessa Murdock (Microsoft).",2014,Conference on Information and Knowledge Management,multimedia;world wide web;information retrieval;data mining;database;artificial intelligence;computer science;
GPQ: Directly Optimizing Q-measure based on Genetic Programming,Yuan Lin (Dalian University of Technology);Hongfei Lin (Dalian University of Technology);Ping Zhang (Dalian University of Technology);Bo Xu (Dalian University of Technology);,"2682169987,2130664977,2425835588,2671010470","Ranking plays an important role in information retrieval system. In recent years, a kind of research named 'learning to rank' becomes more and more popular, which applies machine learning technology to solve ranking problems. Lots of ranking models belonged to learning to rank have been proposed, such as Regression, RankNet, and ListNet. Inspired by this, we proposed a novel learning to rank algorithm named GPQ in this paper, in which genetic programming was employed to directly optimize Q-measure evaluation metric. Experimental results on OHSUMED benchmark dataset indicated that our method GPQ could be competitive with Ranking SVM, SVMMAP and ListNet, and improve the ranking accuracies.",2014,Conference on Information and Knowledge Management,ranking svm;genetic programming;learning to rank;information retrieval;data mining;pattern recognition;artificial intelligence;machine learning;computer science;
Correct Me If I'm Wrong: Fixing Grammatical Errors by Preposition Ranking,Roman Prokofyev (University of Fribourg);Ruslan Mavlyutov (University of Fribourg);Martin Grund (University of Fribourg);Gianluca Demartini (University of Fribourg);Philippe Cudré-Mauroux (University of Fribourg);,"38035707,2424491034,2696807352,1990425973,2704036476","The detection and correction of grammatical errors still represent very hard problems for modern error-correction systems. As an example, the top-performing systems at the preposition correction challenge CoNLL-2013 only achieved a F1 score of 17%. In this paper, we propose and extensively evaluate a series of approaches for correcting prepositions, analyzing a large body of high-quality textual content to capture language usage. Leveraging n-gram statistics, association measures, and machine learning techniques, our system is able to learn which words or phrases govern the usage of a specific preposition. Our approach makes heavy use of n-gram statistics generated from very large textual corpora. In particular, one of our key features is the use of n-gram association measures (e.g., Pointwise Mutual Information) between words and prepositions to generate better aggregated preposition rankings for the individual n-grams. We evaluate the effectiveness of our approach using cross-validation with different feature combinations and on two test collections created from a set of English language exams and StackExchange forums. We also compare against state-of-the-art supervised methods. Experimental results from the CoNLL-2013 test collection show that our approach to preposition correction achieves ∼30% in F1 score which results in 13% absolute improvement over the best performing approach at that challenge.",2014,Conference on Information and Knowledge Management,pointwise mutual information;supervised learning;natural language processing;world wide web;information retrieval;data mining;database;pattern recognition;artificial intelligence;machine learning;statistics;computer science;
Proceedings of the 7th Workshop on Ph.D Students,Gerard de Melo (Tsinghua University);Mouna Kacimi (Free University of Bozen-Bolzano);Aparna Varde (Montclair State University);,"2134233121,2629444457,74820909","It is our pleasure to host PIKM, the PhD workshop in Information and Knowledge Management, in conjunction with the ACM CIKM 2014 conference in Shanghai, China. PIKM has been a popular event in CIKM since its inception in 2007. This is the 7th time PIKM is being held and has attracted participants from all over the world. PIKM provides PhD students an opportunity to present their dissertation proposals and / or early doctoral research worldwide and get recognition for their work. It gives them valuable feedback at a relatively early stage from experts in their field in academia and industry. This helps them assess their work with respect to its novelty, technical contributions and real-world applications. Moreover, PIKM also presents a panorama of upcoming doctoral work to established researchers in information and knowledge management. It gives them an idea of the interesting topics that attract fresh doctorates. It could help them tap this potential at an early stage through summer internships, research collaborations and more. Also, in recent PIKM workshops it has been noticed that in addition to the main areas of CIKM, namely, database systems, information retrieval and knowledge management / data mining, there are papers overlapping with other areas. These include computer science fields such as networking and artificial intelligence and other fields such as management information systems, biology and engineering. This multidisciplinary research propels further collaboration and is being highly encouraged by universities and funding agencies. A significant highlight of PIKM 2014 includes both poster and oral presentations for all accepted papers to increase visibility and interaction. Another distinguished aspect this year is a session of invited talks and papers from PhD graduates and ABD (all but dissertation) candidates to encourage interactions between them and early doctoral students. The peer-reviewed submissions include around 10 papers of which 4 have been accepted as full papers and 2 as short papers. We have a keynote speech by Dr. Iadh Ounis from University of Glasgow, Scotland, United Kingdom. Dr. Ounis is a Reader in the School of Computing Science and has authored over a 100 publications. His talk would feature research along with useful advice for PhD students. The PIKM 2014 team includes Program Committee members from 16 countries spanning 6 continents. These comprise a good balance of industry and academia. We thank the reviewers for providing quick and useful feedback to the students amidst their busy schedule of work. In recent years, PIKM has been giving a best reviewer award in order to honor the exceptional contributions of a PC member, analogous to the best paper award that provides recognition to outstanding PhD student research. This year, the best reviewer award goes to Fabian Suchanek from Telecom Paristech, Paris, France. We sincerely applaud him for his time and effort in providing excellent and detailed reviews. The best paper award goes to Arunav Mishra from the Max Planck Institute for Informatics, Saarbrucken, Germany for his work on ""Linking Today's Wikipedia and News from the Past"". The awards will be presented as ACM certificates during the PIKM workshop at the CIKM conference.",2014,Conference on Information and Knowledge Management,operations research;world wide web;data mining;artificial intelligence;computer science;
Two Phases Outlier Detection in Different Subspaces,Zhana Bao (Waseda University);Wataru Kameyama (Waseda University);,"2136360010,308872687","Mining high dimensional outlier is not fully resolved for its dimensional particularity. The existing full space based methods can find distinct outliers and neglect those hidden in some subspaces. Subspace based approaches can detect most outliers that are apparent in low dimensional spaces, while missing the invisible outliers in subspaces. This paper proposes a novel two-phase inspection model. The first phase measures neighbor's density in subspaces to find low dimensional outliers. The second phase evaluates deviation degree of neighbors in connected subspaces. The undiscovered outliers appear a fast dispersion and scatter more than its neighbors. We analysis two-phase results statistically, and merge into one score for each object. The outliers are expressed with top score objects. The evaluation on synthetic and real data sets shows that our proposal outperform state of the art algorithms in high dimensional outlier issue.",2014,Conference on Information and Knowledge Management,data mining;pattern recognition;statistics;
Sampling Triples from Restricted Networks using MCMC Strategy,Mahmudur Rahman (Indiana University – Purdue University Indianapolis);Mohammad Al Hasan (Indiana University – Purdue University Indianapolis);,"2107991719,2430381672","In large networks, the connected triples are useful for solving various tasks including link prediction, community detection, and spam filtering. Existing works in this direction concern mostly with the exact or approximate counting of connected triples that are closed (aka, triangles). Evidently, the task of triple sampling has not been explored in depth, although sampling is a more fundamental task than counting, and the former is useful for solving various other tasks, including counting. In recent years, some works on triple sampling have been proposed that are based on direct sampling, solely for the purpose of triangle count approximation. They sample only from a uniform distribution, and are not effective for sampling triples from an arbitrary user-defined distribution. In this work we present two indirect triple sampling methods that are based on Markov Chain Monte Carlo (MCMC) sampling strategy. Both of the above methods are highly efficient compared to a direct sampling-based method, specifically for the task of sampling from a non-uniform probability distribution. Another significant advantage of the proposed methods is that they can sample triples from networks that have restricted access, on which a direct sampling based method is simply not applicable.",2014,Conference on Information and Knowledge Management,slice sampling;umbrella sampling;rejection sampling;systematic sampling;simple random sample;metropolis hastings algorithm;importance sampling;mathematical optimization;statistics;
Relationship Emergence Prediction in Heterogeneous Networks through Dynamic Frequent Subgraph Mining,Yang Liu (New Jersey Institute of Technology);Songhua Xu (New Jersey Institute of Technology);Lian Duan (New Jersey Institute of Technology);,"2699542358,2226189406,2667412764","With the rapid development of Web 2.0 and the Internet of things, predicting relationships in heterogeneous networks has evolved as a heated research topic. Traditionally, people analyze existing relationships in heterogeneous networks that relate in a particular way to a target relationship of interest to predict the emergence of the target relationship. However most existing methods are incapable of systematically identifying relevant relationships useful for the prediction task, especially those relationships involving multiple objects of heterogeneous types, which may not rest on a simple path in the concerned heterogeneous network. Another problem with the current practice is that the existing solutions often ignore the dynamic evolution of the network structure after the introduction of newly emerged relationships. To overcome the first limitation, we propose a new algorithm that can systematically and comprehensively detect relevant relationships useful for the prediction of an arbitrarily given target relationship through a disciplined graph searching process. To address the second limitation, the new algorithm leverages a series of temporally-sensitive features for the relationship occurrence prediction via a supervised learning approach. To explore the effectiveness of the new algorithm, we apply the prototype implementation of the algorithm on the DBLP bibliographic network to predict the author citation relationships and compare the algorithm performance with that of a state-of-the-art peer method and a series of baseline methods. The comparison shows consistently higher prediction accuracy under a range of prediction scenarios.",2014,Conference on Information and Knowledge Management,heterogeneous network;data mining;artificial intelligence;machine learning;computer science;
PSBD 2014: Overview of the 1st International Workshop on Privacy and Security of Big Data,Alfredo Cuzzocrea (Indian Council of Agricultural Research);,294375193,"The ACM 1st International Workshop on Privacy and Security of Big Data (PSBD 2014), held in Shanghai, China on November 7, 2014, in conjunction with the ACM 23rd International Conference on Information and Knowledge Management (CIKM 2014), presents research on privacy and security of big data, an emerging challenge in actual database and data mining research. PSBD 2014 program has two interesting s/essions on (i) scalable privacy-preserving and security-control methods for big data processing , and (ii) user-oriented and data-oriented privacy methods for big data processing , plus a panel discussing current challenges and future research perspectives of privacy and security of big data.",2014,Conference on Information and Knowledge Management,privacy by design;information privacy;internet privacy;world wide web;data mining;computer science;
Query Performance Prediction By Considering Score Magnitude and Variance Together,Yongquan Tao (Jiangsu University);Shengli Wu (Jiangsu University);,"2229128448,2686164239","Query Performance prediction aims to evaluate the effectiveness of the results returned by a search system in response to a query without any relevance information. In this paper, we propose a method that considers both magnitude and variance of scores of the ranked list of results to measure the performance of a query. Using six different TREC test sets, we compare our predictor with three of the state-of-the-art techniques. The experimental results show that our method is very competitive. Pairwise comparisons with each of the three other methods show that our predictor performs better in more data sets.",2014,Conference on Information and Knowledge Management,ranking;information retrieval;data mining;pattern recognition;computer science;
Report on the CIKM workshop on living labsfor information retrieval evaluation,Krisztian Balog (University of Stavanger);David Elsweiler (University of Regensburg);Evangelos Kanoulas (University of Sheffield);Liadh Kelly (Dublin City University);Mark Smucker (University of Waterloo);,"2100338238,286123653,1419676578,2156417348,1959697873","Evaluation is a central aspect of information retrieval (IR) research. In the past few years, a new evaluation methodology known as living labs has been proposed as a way for researchers to be able to perform in-situ evaluation. The rst CIKM workshop on Living Labs for IR evaluation (LL'13) was held on 1st November 2013 in San Francisco, USA. The workshop consisted of an industrial keynote, four oral paper presentations, three demo presentations, and a discussion session. This report presents an overview of the scope and contents of the workshop and outlines the major outcomes.",2014,Conference on Information and Knowledge Management,review article;multimedia;information retrieval;computer science;
A prototype application for real-time recognition and disambiguation of clinical abbreviations,Yonghui Wu (University of Texas Health Science Center at Houston);Joshua C. Denny (Vanderbilt University);S. Trent Rosenbloom (Vanderbilt University);Randolph A. Miller (Vanderbilt University);Dario A. Giuse (Vanderbilt University);Min Song (Yonsei University);Hua Xu (University of Texas Health Science Center at Houston);,"2290077271,2143892069,1560803688,2163217771,61597068,2708599032,2625138606","To save time, healthcare providers frequently use abbreviations while authoring clinical documents. Nevertheless, abbreviations that authors deem unambiguous often confuse other readers, including clinicians, patients, and natural language processing (NLP) systems. Most current clinical NLP systems ""post-process"" notes long after clinicians enter them into electronic health record systems (EHRs). Such post-processing cannot guarantee 100% accuracy in abbreviation identification and disambiguation, since multiple alternative interpretations exist. In this paper, authors describe a prototype system for real-time Clinical Abbreviation Recognition and Disambiguation (CARD) -- i.e., a system that interacts with authors during note generation to verify correct abbreviation senses. The CARD system design anticipates future integration with web-based clinical documentation systems to improve quality of healthcare records. The prototype application embodies three word sense disambiguation (WSD) methods. We evaluated the accuracy and response times of the prototype CARD system in a simulated study. Using an existing test data set of 25 commonly observed, highly ambiguous clinical abbreviations the evaluation demonstrated that the best WSD method had an accuracy of 88.8%, and a reasonable average response time of 1.6 milliseconds per each abbreviation. The study indicates potential feasibility of real-time NLP-enabled abbreviation disambiguation within clinical documentation systems.",2013,Conference on Information and Knowledge Management,natural language processing;speech recognition;information retrieval;database;computer science;
FindiLike: a preference driven entity search engine for evaluating entity retrieval and opinion summarization,Kavita Ganesan (University of Illinois at Urbana–Champaign);ChengXiang Zhai (University of Illinois at Urbana–Champaign);,"2128131365,2152766206","We describe a novel preference-driven search engine (FindiLike) which allows users to find entities of interest based on preferences and also allows users to digest opinions about the retrieved entities easily. FindiLike leverages large amounts of online reviews about various entities, and ranks entities based on how well their associated reviews match a user's preference query (expressed in keywords). FindiLike then uses abstractive summarization techniques to generate concise opinion summaries to enable users to digest the opinions about an entity. We discuss how the system can be extended to support in situ evaluation of two interesting new tasks, i.e., opinion-based entity ranking and abstractive summarization of opinions. The system is currently supporting hotel search and being extended to support in situ evaluation of these two tasks. We will demonstrate the system in the domain of hotel search and show how in situ evaluation can be supported through natural user interaction with the system.",2013,Conference on Information and Knowledge Management,evaluation;multi document summarization;automatic summarization;natural language processing;world wide web;information retrieval;data mining;computer science;
