Online Unsupervised Multi-view Feature Selection,Weixiang Shao (University of Illinois at Chicago)Lifang He (Shenzhen University)Chun Ta Lu (University of Illinois at Chicago)Xiaokai Wei (University of Illinois at Chicago)Philip S. Yu (University of Illinois at Chicago),"2151340973,2555188826,2224372854,2405326445,2125104194","In this paper, we propose an Online unsupervised Multi-View Feature Selection method, OMVFS, which deals with large-scale/streaming multi-view data in an online fashion. OMVFS embeds unsupervised feature selection into a clustering algorithm via nonnegative matrix factorization with sparse learning. It further incorporates the graph regularization to preserve the local structure information and help select discriminative features. Instead of storing all the historical data, OMVFS processes the multi-view data chunk by chunk and aggregates all the necessary information into several small matrices. By using the buffering technique, the proposed OMVFS can reduce the computational and storage cost while taking advantage of the structure information. Furthermore, OMVFS can capture the concept drifts in the data streams. Extensive experiments on four real-world datasets show the effectiveness and efficiency of the proposed OMVFS method. More importantly, OMVFS is about 100 times faster than the off-line methods.",2016,International Conference on Data Mining,Fields of study: sparse matrixlinear programmingdata miningpattern recognitionmachine learningcomputer sciencemathematics
"CoreScope: Graph Mining Using k-Core Analysis — Patterns, Anomalies and Algorithms",Kijung Shin (Carnegie Mellon University)Tina Eliassi-Rad (Rutgers University)Christos Faloutsos (Carnegie Mellon University),"2226806500,218538652,2198983026","How do the k-core structures of real-world graphs look like? What are the common patterns and the anomalies? How can we use them for algorithm design and applications? A k-core is the maximal subgraph where all vertices have degree at least k. This concept has been applied to such diverse areas as hierarchical structure analysis, graph visualization, and graph clustering. Here, we explore pervasive patterns that are related to k-cores and emerging in graphs from several diverse domains. Our discoveries are as follows: (1) Mirror Pattern: coreness of vertices (i.e., maximum k such that each vertex belongs to the k-core) is strongly correlated to their degree. (2) Core-Triangle Pattern: degeneracy of a graph (i.e., maximum k such that the k-core exists in the graph) obeys a 3-to-1 power law with respect to the count of triangles. (3) Structured Core Pattern: degeneracy-cores are not cliques but have non-trivial structures such as core-periphery and communities. Our algorithmic contributions show the usefulness of these patterns. (1) Core-A, which measures the deviation from Mirror Pattern, successfully finds anomalies in real-world graphs complementing densest-subgraph based anomaly detection methods. (2) Core-D, a single-pass streaming algorithm based on Core-Triangle Pattern, accurately estimates the degeneracy of billion-scale graphs up to 7× faster than a recent multipass algorithm.(3) Core-S, inspired by Structured Core Pattern, identifies influential spreaders up to 17× faster than top competitors with comparable accuracy.",2016,International Conference on Data Mining,Fields of study: degeneracydistance hereditary graphcomplement graphforbidden graph characterization1 planar graphgraph powercomparability graphsplit graphmodular decompositionpathwidthline graphchordal graphdegreeindependent setbipartite graphcorrelationalgorithm designdiscrete mathematicscombinatoricsdata miningmachine learningcomputer sciencemathematics
Change-Point Analysis of the Public Mood in UK Twitter during the Brexit Referendum,Thomas Lansdall-Welfare (University of Bristol)Faabom T Dzogang (University of Bristol)Nello Cristianini (University of Bristol),"1825665823,2344771608,156417696","We study the changes in public mood within the contents of Twitter in the UK, in the days before and after the Brexit referendum. We measure the levels of anxiety, anger, sadness, negative affect and positive affect in various geographic regions of the UK, at hourly intervals. We analyse these affect time series' by looking for change-points common to all five components, locating points of simultaneous change in the multivariate series using the fast group LARS algorithm, originally developed for bioinformatics applications. We find that there are three key times in the period leading up to and including the EU referendum. In each case, we find that the public mood is characterised by an increase in negative affect, anger, anxiety and sadness, with a corresponding drop in positive affect. The hour by hour evolution of public mood in the hours leading up to and following the closure of the polls is further analysed in conjunction with the GBP/EUR exchange rate, finding four change-points in the hours following the vote, and significant correlation between the exchange rate and the affect components tested.",2016,International Conference on Data Mining,Fields of study: brandsocial mediatimediscrete fourier transformtime seriesbig datapoliticsmental healthdata miningstatisticscomputer science
Seasonal Fluctuations in Collective Mood Revealed by Wikipedia Searches and Twitter Posts,Fabon Dzogang (Pierre-and-Marie-Curie University)Thomas Lansdall-Welfare (University of Bristol)Nello Cristianini (University of Bristol),"797671026,1825665823,156417696","Understanding changes in the mood and mentalhealth of large populations is a challenge, with the need for largenumbers of samples to uncover any regular patterns within thedata. The use of data generated by online activities of healthyindividuals offers the opportunity to perform such observationson the large scales and for the long periods that are required. Various studies have previously examined circadian fluctuationsof mood in this way. In this study, we investigate seasonalfluctuations in mood and mental health by analyzing the accesslogs of Wikipedia pages and the content of Twitter in the UK overa period of four years. By using standard methods of NaturalLanguage Processing, we extract daily indicators of negativeaffect, anxiety, anger and sadness from Twitter and comparethis with the overall daily traffic to Wikipedia pages aboutmental health disorders. We show that both negative affect onTwitter and access to mental health pages on Wikipedia follow anannual cycle, both peaking during the winter months. Breakingthis down into specific moods and pages, we find that peakaccess to the Wikipedia page for Seasonal Affective Disordercoincides with the peak period for the sadness indicator inTwitter content, with both most over-expressed in Novemberand December. A period of heightened anger and anxiety onTwitter partly overlaps with increased information seeking aboutstress, panic and eating disorders on Wikipedia in the late winterand early spring. Finally, we compare Twitter mood indicatorswith various weather time series, finding that negative affectand anger can be partially explained in terms of the climatictemperature and photoperiod, sadness can be partially explainedby the photoperiod and the perceived change in the photoperiod, while anxiety is partially explained by the level of precipitation. Using these multiple sources of data allows us to have accessto inexpensive, although indirect, information about collectivevariations in mood over long periods of time, in turn helpingus to begin to separate out the various possible causes of these fluctuations.",2016,International Conference on Data Mining,Fields of study: encyclopediadatabase indexthe internetelectronic publishingworld wide webcomputer science
Vote-and-Comment: Modeling the Coevolution of User Interactions in Social Voting Web Sites,Alceu Ferraz Costa (University of São Paulo)Agma Juci Machado Traina (University of São Paulo)Caetano Traina (University of São Paulo)Christos Faloutsos (Carnegie Mellon University),"2105073060,2017812127,2108706841,2198983026","In social voting Web sites, how do the user actions – up-votes, down-votes and comments – evolve over time? Are there relationships between votes and comments? What is normal and what is suspicious? These are the questions we focus on. We analyzed over 20,000 submissions corresponding to more than 100 million user interactions from three social voting Web sites: Reddit, Imgur and Digg. Our first contribution is two discoveries: (i) the number of comments grows as a power-law on the number of votes and (ii) the time between a submission creation and a user's reaction obeys a log-logistic distribution. Based on these patterns, we propose VnC (Vote-and-Comment), a parsimonious but accurate and scalable model that models the coevolution of user activities. In our experiments on real data, VnC outperformed state-of-the-art baselines on accuracy. Additionally, we illustrate VnC usefulness for forecasting and outlier detection.",2016,International Conference on Data Mining,Fields of study: data modelingtrajectoryforecastingcomputational modeldata scienceworld wide webdata miningmachine learningstatisticscomputer science
Gender Classification by Deep Learning on Millions of Weakly Labelled Images,Sen Jia (University of Bristol)Thomas Lansdall-Welfare (University of Bristol)Nello Cristianini (University of Bristol),"2118603949,1825665823,156417696","When analysing human activities using data mining or machine learning techniques, it can be useful to infer properties such as the gender or age of the people involved. This paper focuses on the sub-problem of gender recognition, which has been studied extensively in the literature, with two main problems remaining unsolved: how to improve the accuracy on real-world face images, and how to generalise the models to perform well on new datasets. We address these problems by collecting five million weakly labelled face images, and performing three different experiments, investigating: the performance difference between convolutional neural networks (CNNs) of differing depths and a support vector machine approach using local binary pattern features on the same training data, the effect of contextual information on classification accuracy, and the ability of convolutional neural networks and large amounts of training data to generalise to cross-database classification. We report record-breaking results on both the Labeled Faces in the Wild (LFW) dataset, achieving an accuracy of 98.90%, and the Images of Groups (GROUPS) dataset, achieving an accuracy of 91.34% for cross-database gender classification.",2016,International Conference on Data Mining,Fields of study: training setsupport vector machinefacefeature extractiondeep learningbig datadata miningpattern recognitionmachine learningcomputer science
Edge Weight Prediction in Weighted Signed Networks,"Srijan Kumar (University of Maryland, College Park)Francesca Spezzano (Boise State University)V. S. Subrahmanian (University of Maryland, College Park)Christos Faloutsos (Carnegie Mellon University)","2191206652,2203751546,2261167843,2198983026","Weighted signed networks (WSNs) are networks in which edges are labeled with positive and negative weights. WSNs can capture like/dislike, trust/distrust, and other social relationships between people. In this paper, we consider the problem of predicting the weights of edges in such networks. We propose two novel measures of node behavior: the goodness of a node intuitively captures how much this node is liked/trusted by other nodes, while the fairness of a node captures how fair the node is in rating other nodes' likeability or trust level. We provide axioms that these two notions need to satisfy and show that past work does not meet these requirements for WSNs. We provide a mutually recursive definition of these two concepts and prove that they converge to a unique solution in linear time. We use the two measures to predict the edge weight in WSNs. Furthermore, we show that when compared against several individual algorithms from both the signed and unsigned social network literature, our fairness and goodness metrics almost always have the best predictive power. We then use these as features in different multiple regression models and show that we can predict edge weights on 2 Bitcoin WSNs, an Epinions WSN, 2 WSNs derived from Wikipedia, and a WSN derived from Twitter with more accurate results than past work. Moreover, fairness and goodness metrics form the most significant feature for prediction in most (but not all) cases.",2016,International Conference on Data Mining,Fields of study: wireless sensor networkcorrelationpredictiontheoretical computer sciencecomputer securitydata miningmachine learningstatisticsmathematics
ExploreKit: Automatic Feature Generation and Selection,"Gilad Katz (Ben-Gurion University of the Negev)Eui Chul Richard Shin (University of California, Berkeley)Dawn Song (University of California, Berkeley)","2132343420,2058008366,2131252044","Feature generation is one of the challenging aspects of machine learning. We present ExploreKit, a framework for automated feature generation. ExploreKit generates a large set of candidate features by combining information in the original features, with the aim of maximizing predictive performance according to user-selected criteria. To overcome the exponential growth of the feature space, ExploreKit uses a novel machine learning-based feature selection approach to predict the usefulness of new candidate features. This approach enables efficient identification of the new features and produces superior results compared to existing feature selection solutions. We demonstrate the effectiveness and robustness of our approach by conducting an extensive evaluation on 25 datasets and 3 different classification algorithms. We show that ExploreKit can achieve classification-error reduction of 20% overall. Our codeis available at https://github.com/giladkatz/ExploreKit.",2016,International Conference on Data Mining,Fields of study: featurespace explorationdimensionality reductionfeature vectorfeaturepredictionfeature extractionk nearest neighbors algorithmfeature learningdata miningpattern recognitionmachine learningstatisticscomputer science
Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis,Soujanya Poria (Nanyang Technological University)Iti Chaturvedi (Nanyang Technological University)Erik Cambria (Nanyang Technological University)Amir Hussain (University of Stirling),"1992239148,2166408775,1974519269,2116749196","Technology has enabled anyone with an Internet connection to easily create and share their ideas, opinions and content with millions of other people around the world. Much of the content being posted and consumed online is multimodal. With billions of phones, tablets and PCs shipping today with built-in cameras and a host of new video-equipped wearables like Google Glass on the horizon, the amount of video on the Internet will only continue to increase. It has become increasingly difficult for researchers to keep up with this deluge of multimodal content, let alone organize or make sense of it. Mining useful knowledge from video is a critical need that will grow exponentially, in pace with the global growth of content. This is particularly important in sentiment analysis, as both service and product reviews are gradually shifting from unimodal to multimodal. We present a novel method to extract features from visual and textual modalities using deep convolutional neural networks. By feeding such features to a multiple kernel learning classifier, we significantly outperform the state of the art of multimodal emotion recognition and sentiment analysis on different datasets.",2016,International Conference on Data Mining,Fields of study: kernelvisualizationfeature extractionsentiment analysismultimediadata miningmachine learningcomputer science
What Drives Consumer Choices? Mining Aspects and Opinions on Large Scale Review Data Using Distributed Representation of Words,"Kasturi Bhattacharjee (University of California, Berkeley)Linda R. Petzold (University of California, Santa Barbara)","2232210404,2075742177","With the increasing popularity of online review sites, developing methods to mine and analyze information contained in the vast amounts of noisy user-generated reviews becomes a necessity. In this work, we develop a method to uncover the various aspects of a product or service reviewed by a user, and the opinions associated with them, in an automated fashion. We use the neural network model Word2Vec to build a vector space representation of a large corpus of user-generated, online restaurant reviews, and harness these distributed representations for aspect-based sentiment analysis. User generated text data is intrinsically noisy, with misspellings, informal language, and digressions. Because of the many variations in spelling and expression, the data is also very sparse. Despite these inherent challenges we are able to represent the reviews by key drivers of consumer sentiment, allowing for highly accurate sentiment prediction using a method that is both scalable and human interpretable.",2016,International Conference on Data Mining,Fields of study: noise measurementsentiment analysisdata scienceworld wide webdata miningmachine learningcomputer science
"Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View That Includes Motifs, Discords and Shapelets","Chin-Chia Michael Yeh (Center for Information Technology)Yan Zhu (Shanghai Jiao Tong University)Liudmila Ulanova (University of California, Riverside)Nurjahan Begum (University of California, Riverside)Yifei DingHoang Anh Dau (University of California, Riverside)Diego Furtado Silva (Spanish National Research Council)Abdullah Mueen (University of New Mexico)Eamonn J. Keogh (University of California, Riverside)","2107817180,2678804180,2089139422,2157373250,2342796293,2712909183,2138204294,2083987245,2170070822","The all-pairs-similarity-search (or similarity join) problem has been extensively studied for text and a handful of other datatypes. However, surprisingly little progress has been made on similarity joins for time series subsequences. The lack of progress probably stems from the daunting nature of the problem. For even modest sized datasets the obvious nested-loop algorithm can take months, and the typical speed-up techniques in this domain (i.e., indexing, lower-bounding, triangular-inequality pruning and early abandoning) at best produce one or two orders of magnitude speedup. In this work we introduce a novel scalable algorithm for time series subsequence all-pairs-similarity-search. For exceptionally large datasets, the algorithm can be trivially cast as an anytime algorithm and produce high-quality approximate solutions in reasonable time. The exact similarity join algorithm computes the answer to the time series motif and time series discord problem as a side-effect, and our algorithm incidentally provides the fastest known algorithm for both these extensively-studied problems. We demonstrate the utility of our ideas for two time series data mining problems, including motif discovery and novelty discovery.",2016,International Conference on Data Mining,Fields of study: euclidean distancedatabase indexcluster analysistime seriesapproximation algorithmdata miningmachine learningstatisticsalgorithmcomputer sciencemathematics
Self-Grouping Multi-network Clustering,Jingchao Ni (Case Western Reserve University)Wei Cheng (University of North Carolina at Chapel Hill)Wei Fan (Baidu)Xiang Zhang (Case Western Reserve University),"2223717457,2620045292,2422054197,2553248206","Joint clustering of multiple networks has been shown to be more accurate than performing clustering on individual networks separately. Many multi-view and multi-domain network clustering methods have been developed for joint multi-network clustering. These methods typically assume there is a common clustering structure shared by all networks, and different networks can provide complementary information on this underlying clustering structure. However, this assumption is too strict to hold in many emerging real-life applications, where multiple networks have diverse data distributions. More popularly, the networks in consideration belong to different underlying groups. Only networks in the same underlying group share similar clustering structures. Better clustering performance can be achieved by considering such groups differently. As a result, an ideal method should be able to automatically detect network groups so that networks in the same group share a common clustering structure. To address this problem, we propose a novel method, ComClus, to simultaneously group and cluster multiple networks. ComClus treats node clusters as features of networks and uses them to differentiate different network groups. Network grouping and clustering are coupled and mutually enhanced during the learning process. Extensive experimental evaluation on a variety of synthetic and real datasets demonstrates the effectiveness of our method.",2016,International Conference on Data Mining,Fields of study: hierarchical clustering of networksflame clusteringbrown clusteringdbscancorrelation clusteringhierarchical network modelconstrained clusteringdata stream clusteringcure data clustering algorithmfuzzy clusteringclustering high dimensional datasymmetric matrixstresscluster analysismeasurementconsensus clusteringbiclusteringconceptual clusteringbioinformaticsdata miningmachine learningmathematics
Using Machine Learning to Accelerate Data Wrangling,Shilpi AhujaMary Roth (IBM)Rashmi GangadharaiahPeter M. Schwarz (IBM)Rafael Bastidas,"2584200727,2475917068,2716771019,2135035649,2525598919","70% Of the time spent on data analytics is not actually spent on data analytics, but rather, in data wrangling: the process of finding, interpreting, extracting, preparing and recombining the data to be analyzed. For data that is collected as free-form text, the lack of standards or competing standards often results in a variety of formats for expressing the same type of data, making the data wrangling step a tedious and error-prone process. For example, US street addresses may be expressed with a house number, PO Box, rural or military route, and/or a direction – all of which can be abbreviated or spelled out in a variety of ways. In this paper, we present an algorithm that uses machine learning to efficiently and automatically identify categories of attributes, such as geo-spatial, that are present in a data file and we discuss results on a variety of real data sets. Our implementation can be used to automatically prepare data for consumption by other tools and services, such as mapping and visualization tools, and is motivated by and in support of a customizable severe weather alerting service.",2016,International Conference on Data Mining,Fields of study: data cleansingdata analysisgeospatial analysisdata sciencedata miningdatabasemachine learningcomputer science
Toward Time-Evolving Feature Selection on Dynamic Networks,Jundong Li (Arizona State University)Xia Hu (Texas A&M University)Ling Jian (China University of Petroleum)Huan Liu (Arizona State University),"2149809093,2161448330,2642846495,2122391114","Recent years have witnessed the prevalence of networked data in various domains. Among them, a large number of networks are not only topologically structured but also have a rich set of features on nodes. These node features are usually of high dimensionality with noisy, irrelevant and redundant information, which may impede the performance of other learning tasks. Feature selection is useful to alleviate these critical issues. Nonetheless, a vast majority of existing feature selection algorithms are predominantly designed in a static setting. In reality, real-world networks are naturally dynamic, characterized by both topology and content changes. It is desirable to capture these changes to find relevant features tightly hinged with network structure continuously, which is of fundamental importance for many applications such as disaster relief and viral marketing. In this paper, we study a novel problem of time-evolving feature selection for dynamic networks in an unsupervised scenario. Specifically, we propose a TeFS framework by leveraging the temporal evolution property of dynamic networks to update the feature selection results incrementally. Experimental results show the superiority of TeFS over the state-of-the-art batch-mode unsupervised feature selection algorithms.",2016,International Conference on Data Mining,Fields of study: noise measurementnetwork topologyfeaturefeature extractionlinear programmingdata miningpattern recognitionmachine learningcomputer science
Mining Summaries for Knowledge Graph Search,"Qi SongYinghui Wu (University of California, Santa Barbara)Xin Luna Dong","2584213035,2134127457,2585679071","Mining and searching heterogeneous and large knowledge graphs is challenging under real-world resource constraints such as response time. This paper studies a framework that discover to facilitate knowledge graph search. 1) We introduce a class of summaries characterized by graph patterns. In contrast to conventional summaries defined by frequent subgraphs, the summaries are capable of adaptively summarize entities with similar neighbors up to a bounded hop. 2) We formulate the computation of graph summarization as a bi-criteria pattern mining problem. Given a knowledge graph G, the problem is to discover k diversified summaries that maximizes the informativeness measure. Although this problem is NP-hard, we show that it is 2-approximable. We also introduce an online mining algorithm that trade-off speed and accuracy, under given resource constraints. 3) We develop query evaluation algorithms that make use of the summaries as views. These algorithms efficiently compute (approximate) answers with high accuracy, and only refer to a small number of summaries. Our experimental study verifies that online mining over large knowledge graphs is feasible, and can suggest bounded search in knowledge graphs.",2016,International Conference on Data Mining,Fields of study: inspectionredundancyknowledge based systemsapproximation algorithmdata sciencedata miningmachine learningcomputer science
Will I Get in? Modeling the Graduate Admission Process for American Universities,Narender Gupta (University of Illinois at Urbana–Champaign)Aman Sawhney (University of Delaware)Dan Roth (University of Illinois at Urbana–Champaign),"2664355010,2584412704,2122007671","We study the graduate admission process in American universities from students' perspective. Our goal is to build a decision support model that provides candidates with pertinent information as well as the ability to assess their choices during the application process. This model is driven by extensive machine learning based analysis of large amounts of historic data available on the web. Our analysis considers factors such as standardized test scores and GPA as well as world knowledge such as university reputation. The learning problem is modeled as a binary classification problem with latent variables that account for hidden information, such as multiple graduate programs within the same institution. An additional contribution of this paper is the collection of a new dataset of more than 25,000 students, with 6 applications per student on average and, hence, amounting to more than 150,000 applications spanning across more than 3000 source institutions. The dataset covers hundreds of target universities over several years, and allows us to develop models that provide insight into student application behavior and university decision patterns. Our experimental study reveals some key factors in the decision process of programs that provide applicants the ability to make an informed decision during application, with high confidence of being accepted.",2016,International Conference on Data Mining,Fields of study: data modelinglatent variabledecision treefeature extractioncomputational modelmeasurementmathematical modeldecision support systemdata sciencedata miningmachine learningsimulationstatisticscomputer science
Subspace Outlier Detection in Linear Time with Randomized Hashing,Saket Sathe (IBM)Charu C. Aggarwal (IBM),"2478550524,2146335907","Outlier detection algorithms are often computationally intensive because of their need to score each point in the data. Even simple distance-based algorithms have quadratic complexity. High-dimensional outlier detection algorithms such as subspace methods are often even more computationally intensive because of their need to explore different subspaces of the data. In this paper, we propose an exceedingly simple subspace outlier detection algorithm, which can be implemented in a few lines of code, and whose complexity is linear in the size of the data set and the space requirement is constant. We show that this outlier detection algorithm is much faster than both conventional and high-dimensional algorithms and also provides more accurate results. The approach uses randomized hashing to score data points and has a neat subspace interpretation. Furthermore, the approach can be easily generalized to data streams. We present experimental results showing the effectiveness of the approach over other state-of-the-art methods.",2016,International Conference on Data Mining,Fields of study: data modelingrobustnessdetectordata miningpattern recognitionmachine learningcomputer science
Incorporating Expert Feedback into Active Anomaly Discovery,Shubhomoy Das (Oregon State University)Weng-Keen Wong (Oregon State University)Thomas G. Dietterich (Oregon State University)Alan Fern (Oregon State University)Andrew Emmott (Oregon State University),"2121364888,2102128069,160031478,2139785505,2338058579","Unsupervised anomaly detection algorithms search for outliers and then predict that these outliers are the anomalies. When deployed, however, these algorithms are often criticized for high false positive and high false negative rates. One cause of poor performance is that not all outliers are anomalies and not all anomalies are outliers. In this paper, we describe an Active Anomaly Discovery (AAD) method for incorporating expert feedback to adjust the anomaly detector so that the outliers it discovers are more in tune with the expert user's semantic understanding of the anomalies. The AAD approach is designed to operate in an interactive data exploration loop. In each iteration of this loop, our algorithm first selects a data instance to present to the expert as a potential anomaly and then the expert labels the instance as an anomaly or as a nominal data point. Our algorithm updates its internal model with the instance label and the loop continues until a budget of B queries is spent. The goal of our approach is to maximize the total number of true anomalies in the B instances presented to the expert. We show that when compared to other state-of-the-art algorithms, AAD is consistently one of the best performers.",2016,International Conference on Data Mining,Fields of study: data modelingfeature extractiondetectoralgorithm designmathematical modellinear programmingdata miningartificial intelligencemachine learningcomputer science
A Probabilistic View of Neighborhood-Based Recommendation Methods,Jun Wang (University of Luxembourg)Qiang Tang (University of Luxembourg),"2293519386,2132485330","Probabilistic graphic model is an elegant framework to compactly present complex real-world observations by modeling uncertainty and logical flow (conditionally independent factors). In this paper, we present a probabilistic framework of neighborhood-based recommendation methods (PNBM) in which similarity is regarded as an unobserved factor. Thus, PNBM leads the estimation of user preference to maximizing a posterior over similarity. We further introduce a novel multi-layer similarity descriptor which models and learns the joint influence of various features under PNBM, and name the new framework MPNBM. Empirical results on real-world datasets show that MPNBM allows very accurate estimation of user preferences.",2016,International Conference on Data Mining,Fields of study: divergence from randomness modelprobabilistic relevance modelprobabilistic ctlmanganeseprobabilistic logicsiliconestimationmathematical modelrecommender systemdata miningmachine learningstatisticscomputer sciencemathematics
Blind Men and The Elephant: Thurstonian Pairwise Preference for Ranking in Crowdsourcing,Xiaolong Wang (University of Illinois at Urbana–Champaign)Jingjing Wang (University of Illinois at Urbana–Champaign)Luo Jie (Yahoo!)Chengxiang Zhai (University of Illinois at Urbana–Champaign)Yi Chang (Yahoo!),"2591453536,2140412951,2095673574,2152766206,2168000538","Crowdsourcing services make it possible to collect huge amount of annotations from less trained crowd workers in an inexpensive and efficient manner. However, unlike making binary or pairwise judgements, labeling complex structures such as ranked lists by crowd workers is subject to large variance and low efficiency, mainly due to the huge labeling space and the annotators' non-expert nature. Yet ranked lists offer the most informative knowledge for training and testing in various data mining and information retrieval tasks such as learning to rank. In this paper, we propose a novel generative model called ""Thurstonian Pairwise Preference"" (TPP) to infer the true ranked list out of a collection of crowdsourced pairwise annotations. The key challenges that TPP addresses are to resolve the inevitable incompleteness and inconsistency of judgements, as well as to model variable query difficulty and different labeling quality resulting from workers' domain expertise and truthfulness. Experimental results on both synthetic and real-world datasets demonstrate that TPP can effectively bind pairwise preferences of the crowd into rankings and substantially outperforms previously published methods.",2016,International Conference on Data Mining,Fields of study: crowdsourcingrankinglabeling theorynoise measurementsoftware testingdata sciencedata miningmachine learningstatisticscomputer science
On Dense Subgraphs in Signed Network Streams,Jose Cadena (Virginia Tech)Anil Kumar S. Vullikanti (Virginia Tech)Charu C. Aggarwal (IBM),"2153027628,393896382,2146335907","Signed networks remain relatively under explored despite the fact that many real networks are of this kind. Here, we study the problem of subgraph density in signed networks and show connections to the event detection task. Notions of density have been used in prior studies on anomaly detection, but all existing methods have been developed for unsigned networks. We develop the first algorithms for finding dense subgraphs in signed networks using semi-definite programming based rounding. We give rigorous guarantees for our algorithms, and develop a heuristic EGOSCAN which is significantly faster. We evaluate the performance of EGOSCAN for different notions of density, and observe that it performs significantly better than natural adaptations of prior algorithms for unsigned networks. In particular, the improvement in edge density over previous methods is as much as 85% and usually over 50%. These results are consistent across signed and unsigned networks in different domains. The improvement in performance is even more significant for a constrained version of the problem involving finding subgraphs containing a subset of query nodes. We also develop an event detection method for signed and unsigned networks based on subgraph density. We apply this to three different temporal datasets, and show that our method based on EGOSCAN significantly outperforms existing approaches and baseline methods in terms of the precision-recall tradeoff (by as much as 25-50% in some instances).",2016,International Conference on Data Mining,Fields of study: programmingquadratic programmingtheoretical computer sciencedistributed computingmachine learningmathematics
Auditing Black-Box Models for Indirect Influence,Philip Adler (Haverford College)Casey Falk (Haverford College)Sorelle A. Friedler (Haverford College)Gabriel Rybeck (Haverford College)Carlos Scheidegger (University of Arizona)Brandon Smith (Haverford College)Suresh Venkatasubramanian (University of Utah),"2582792512,2274101533,2622481509,2280708623,2119064567,2273670039,2090109395","Data-trained predictive models see widespread use, but for the most part they are used as black boxes which output a prediction or score. It is therefore hard to acquire a deeper understanding of model behavior, and in particular how different features influence the model prediction. This is important when interpreting the behavior of complex models, or asserting that certain problematic attributes (like race or gender) are not unduly influencing decisions. In this paper, we present a technique for auditing black-box models, which lets us study the extent to which existing models take advantage of particular features in the dataset, without knowing how the models work. Our work focuses on the problem of indirect influence: how some features might indirectly influence outcomes via other, related features. As a result, we can find attribute influences even in cases where, upon further direct examination of the model, the attribute is not referred to by the model at all. Our approach does not require the black-box model to be retrained. This is important if (for example) the model is only accessible via an API, and contrasts our work with other methods that investigate feature influence like feature selection. We present experimental evidence for the effectiveness of our procedure using a variety of publicly available datasets and models. We also validate our procedure using techniques from interpretable learning and feature selection, as well as against other black-box auditing procedures.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingcomputational modelsoftware testingdata sciencedata miningmachine learningsimulationstatisticscomputer science
Interpretable Clustering via Discriminative Rectangle Mixture Model,Junxiang Chen (Northeastern University)Yale Chang (Northeastern University)Brian Hobbs (Harvard University)Peter J. Castaldi (Brigham and Women's Hospital)Michael H. Cho (Brigham and Women's Hospital)Edwin K. Silverman (Brigham and Women's Hospital)Jennifer G. Dy (Northeastern University),"2577579223,2148142019,2119966696,2080945126,2116921408,2091874529,2239241780","Clustering is a technique that is usually applied as a tool for exploratory data analysis. Because of the exploratory nature of this task, it would be beneficial if a clustering method generates interpretable results, and allows incorporating domain knowledge. This motivates us to develop a probabilistic discriminative model that learns a rectangular decision rule for each cluster, we call Discriminative Rectangle Mixture (DReaM) model. DReaM gives interpretable clustering results, because the rectangular decision rules discovered explicitly illustrate how one cluster is defined and differs from other clusters. It also facilitates us to take advantage of existing rules because we can choose informative prior distributions for the rectangular rules. Moreover, DReaM allows that the features for generating rules do not have to be the same as the features for discovering cluster structure. We approximate the distribution for the rules discovered via variational inference. Experimental results demonstrate that DReaM gives more interpretable clustering results, and yet its performance is comparable to existing clustering methods when solving traditional clustering. Furthermore, in real applications, DReaM is able to effectively take advantage of domain knowledge, and to generate reasonable clustering results.",2016,International Conference on Data Mining,Fields of study: brown clusteringcanopy clustering algorithmcorrelation clusteringconstrained clusteringcure data clustering algorithmfuzzy clusteringdata modelingclustering high dimensional dataprobabilistic logicdecision treecluster analysismathematical modelconceptual clusteringgenomicsdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Efficient Sampling-Based Kernel Mean Matching,Swarup Chandra (University of Texas at Dallas)Ahsanul Haque (University of Texas at Dallas)Latifur Khan (University of Texas at Dallas)Charu Aggarwal (IBM),"2307411638,2132111568,2155983610,2146335907","Many real-world applications exhibit scenarios where distributions represented by training and test data are not similar, but related by a covariate shift, i.e., having equal class conditional distribution with unequal covariate distribution. Traditional data mining techniques suffer to learn a good predictive model in the presence of covariate shift. Recent studies have proposed approaches to address this challenge by weighing training instances based on density ratio between test and training data distributions. Kernel Mean Matching (KMM) is a well known method for estimating density ratio, but has time complexity cubic in the size of training data. Therefore, KMM is not suitable in real-world applications, especially in cases where the predictive model needs to be updated periodically with large training data. We address this challenge by taking fixed-size samples from training and test data, performing independent computations on these samples, and combining the results to obtain overall density ratio estimates. Our empirical evaluation demonstrates a large gain in execution time, while also achieving competitive accuracy on numerous benchmark datasets.",2016,International Conference on Data Mining,Fields of study: bootstrap aggregatingtraining setmemory managementscalabilitykerneltime complexityeconometricsdata miningmachine learningstatisticscomputer science
Context-Aware Sequential Recommendation,Qiang Liu (Chinese Academy of Sciences)Shu Wu (Chinese Academy of Sciences)Diyi WangZhaokang LiLiang Wang (Chinese Academy of Sciences),"2698910997,2122580694,2522055496,2700323474,2226151461","Since sequential information plays an important role in modeling user behaviors, various sequential recommendation methods have been proposed. Methods based on Markov assumption are widely-used, but independently combine several most recent components. Recently, Recurrent Neural Networks (RNN) based methods have been successfully applied in several sequential modeling tasks. However, for real-world applications, these methods have difficulty in modeling the contextual information, which has been proved to be very important for behavior modeling. In this paper, we propose a novel model, named Context-Aware Recurrent Neural Networks (CA-RNN). Instead of using the constant input matrix and transition matrix in conventional RNN models, CA-RNN employs adaptive context-specific input matrices and adaptive context-specific transition matrices. The adaptive context-specific input matrices capture external situations where user behaviors happen, such as time, location, weather and so on. And the adaptive context-specific transition matrices capture how lengths of time intervals between adjacent behaviors in historical sequences affect the transition of global sequential features. Experimental results show that the proposed CA-RNN model yields significant improvements over state-of-the-art sequential recommendation methods and context-aware recommendation methods on two public datasets, i.e., the Taobao dataset and the Movielens-1M dataset.",2016,International Conference on Data Mining,Fields of study: recurrent neural networkcontext modelmathematical modeldata miningartificial intelligencemachine learningstatisticscomputer science
HogWild++: A New Mechanism for Decentralized Asynchronous Stochastic Gradient Descent,Huan ZhangCho-Jui Hsieh (University of Texas at Austin)Venkatesh Akella,"2250563402,2148022289,2638599163","Stochastic Gradient Descent (SGD) is a popular technique for solving large-scale machine learning problems. In order to parallelize SGD on multi-core machines, asynchronous SGD (Hogwild!) has been proposed, where each core updates a global model vector stored in a shared memory simultaneously, without using explicit locks. We show that the scalability of Hogwild! on modern multi-socket CPUs is severely limited, especially on NUMA (Non-Uniform Memory Access) system, due to the excessive cache invalidation requests and false sharing. In this paper we propose a novel decentralized asynchronous SGD algorithm called HogWild++ that overcomes these drawbacks and shows almost linear speedup on multi-socket NUMA systems. The main idea in HogWild++ is to replace the global model vector with a set of local model vectors that are shared by a cluster (a set of cores), keep them synchronized through a decentralized token-based protocol that minimizes remote memory access conflicts and ensures convergence. We present the design and experimental evaluation of HogWild++ on a variety of datasets and show that it outperforms state-of-the-art parallel SGD implementations in terms of efficiency and scalability.",2016,International Conference on Data Mining,Fields of study: multi core processorinstruction setscalabilityalgorithm designcomputational modelparallel computingdistributed computingdata miningreal time computingmachine learningcomputer science
Structural Patterns in the Rise of Germany’s New Right on Facebook,Sebastian SchelterFelix BiessmannMalisa ZobelNedelina Teneva (University of Chicago),"2717894272,2683983720,2670015880,1957652709","In the last years a new right-wing, populist and eurosceptic party emerged in Germany, the 'Alternative fur Deutschland'. Topics that were used by the party to draw attention to their program included the Euro-crisis and the so-called 'refugee crisis'. We investigate some aspects of social media use of the AfD. Our goal is to relate the rise of this party to some quantitative measures of their social media usage. A particular focus will be placed on users that interact with AfD content as well as with content of other parties. Our analysis is based on more than 11 million interactions of more than one million users with the public Facebook pages of the major German political parties during the years 2014 and 2015. Investigating the time courses of social media activity and user interaction, we find that the rise of the AfD can be associated with an amount of social media coverage and user engagement that is unprecedented in the German political landscape. One main effect of this campaign is a substantial increase of user interactions with other parties from the right spectrum, suggesting a migration of voters from established right wing parties. In order to better interpret the dynamics of social media activity, we relate the analysed metrics to the textual content of the posts and classical survey data. These results suggest that the intense use of social media platforms poses a major success factor of this newly emerging right-wing party.",2016,International Conference on Data Mining,Fields of study: votingmeasurementworld wide webdata mining
Causal Inference by Compression,Kailash Budhathoki (Max Planck Society)Jilles Vreeken (Max Planck Society),"2244427771,1971070670","Causal inference is one of the fundamental problems in science. In recent years, several methods have been proposed for discovering causal structure from observational data. These methods, however, focus specifically on numeric data, and are not applicable on nominal or binary data. In this work, we focus on causal inference for binary data. Simply put, we propose causal inference by compression. To this end we propose an inference framework based on solid information theoretic foundations, i.e. Kolmogorov complexity. However, Kolmogorov complexity is not computable, and hence we propose a practical and computable instantiation based on the Minimum Description Length (MDL) principle. To apply the framework in practice, we propose ORIGO, an efficient method for inferring the causal direction from binary data. ORIGO employs the lossless PACK compressor, works directly on the data and does not require assumptions about neither distributions nor the type of causal relations. Extensive evaluation on synthetic, benchmark, and real-world data shows that ORIGO discovers meaningful causal relations, and outperforms state-of-the-art methods by a wide margin.",2016,International Conference on Data Mining,Fields of study: informaticsbenchmarkdecision treeinformation theorytheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Mining the Opinionated Web: Classification and Detection of Aspect Contexts for Aspect Based Sentiment Analysis,Oscar Araque (Technical University of Madrid)Ganggao Zhu (Grupo México)Manuel García-AmadoCarlos Angel Iglesias (Technical University of Madrid),"2084795745,2562541542,2583886850,2310226436","Aspect Based Sentiment Analysis (ABSA) provides further insight into the analysis of social media. Understanding user opinion about different aspects of products, services or policies can be used for improving and innovating in an effective way. Thus, it is becoming an increasingly important task in the Natural Language Processing (NLP) realm. The standard pipeline of aspect-based sentiment analysis consists of three phases: aspect category detection, Opinion Target Extraction (OTE) and sentiment polarity classification. In this article, we propose an alternative pipeline: OTE, aspect classification, aspect context detection and sentiment classification. As it can be observed, the opinionated words are first detected and then are classified into aspects. In addition, the opinionated fragment of every aspect is delimited before performing the sentiment analysis. This paper is focused on the aspect classification and aspect context detection phases and proposes a twofold contribution. First, we propose a hybrid model consisting of a word embeddings model used in conjunction with semantic similarity measures in order to develop an aspect classifier module. Second, we extend the context detection algorithm by Mukherjee et al. to improve its performance. The system has been evaluated using the SemEval2016 datasets. The evaluation shows through several experiments that the use of hybrid techniques that aggregate different sources of information improves the classification performance.",2016,International Conference on Data Mining,Fields of study: feature extractionestimationsentiment analysissemanticsdata sciencedata miningpattern recognitioncomputer science
Dynamic Poisson Factor Analysis,Yizhe Zhang (Duke University)Yue ZhaoLawrence David (Harvard University)Ricardo Henao (Duke University)Lawrence Carin (Duke University),"2515564654,2585187995,2375066224,2099325229,657437189","We introduce a novel dynamic model for discrete time-series data, in which the temporal sampling may be nonuniform. The model is specified by constructing a hierarchy of Poisson factor analysis blocks, one for the transitions between latent states and the other for the emissions between latent states and observations. Latent variables are binary and linked to Poisson factor analysis via Bernoulli-Poisson specifications. The model is derived for count data but can be readily modified for binary observations. We derive efficient inference via Markov chain Monte Carlo, that scales with the number of non-zeros in the data and latent binary states, yielding significant acceleration compared to related models. Experimental results on benchmark data show the proposed model achieves state-of-the-art predictive performance. Additional experiments on microbiome data demonstrate applicability of the proposed model to interesting problems in computational biology where interpretability is of utmost importance.",2016,International Conference on Data Mining,Fields of study: probabilistic latent semantic analysislatent class modeldata modelingcorrelationcomputational modelhidden markov modeleconometricsmachine learningstatisticscomputer science
Sparse Gaussian Markov Random Field Mixtures for Anomaly Detection,Tsuyoshi Ide (IBM)Ankush Khandelwal (University of Minnesota)Jayant Kalagnanam (IBM),"2107715069,2135294117,1129663990","We propose a new approach to anomaly detection from multivariate noisy sensor data. We address two major challenges: To provide variable-wise diagnostic information and to automatically handle multiple operational modes. Our task is a practical extension of traditional outlier detection, which is to compute a single scalar for each sample. To consistently define the variable-wise anomaly score, we leverage a predictive conditional distribution. We then introduce a mixture of Gaussian Markov random field and its Bayesian inference, resulting in a sparse mixture of sparse graphical models. Our anomaly detection method is capable of automatically handling multiple operational modes while removing unwanted nuisance variables. We demonstrate the utility of our approach using real equipment data from the oil industry.",2016,International Conference on Data Mining,Fields of study: variable order markov modelnoise measurementnormal distributionmathematical modeldata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Fixing the Convergence Problems in Parallel Asynchronous Dual Coordinate Descent,Huan ZhangCho-Jui Hsieh (University of Texas at Austin),"2250563402,2148022289","Solving L2-regularized empirical risk minimization (e.g., linear SVMs and logistic regression) using multiple cores has become an important research topic. Among all the existing algorithms, Parallel ASynchronous Stochastic dual Co-Ordinate DEscent (PASSCoDe) demonstrates superior performance compared with other methods. Although PASSCoDe is fast when it converges, the algorithm has been observed to diverge on several cases especially when a relatively large number of threads are used. This is mainly due to the delayed parameter access problem — the parameters used for the current update may be delayed and are not the latest ones. In theory, the algorithm converges only when the delay is small enough, but in practice the delay depends on the underlying parallel computing environment and cannot be guaranteed. In this work, we propose a simple and computational efficient way to fix the convergence problem of PASSCoDe. Instead of allowing all worker threads to conduct asynchronous updates wildly, we add periodic check points to the procedure, where all workers need to stop and refine the current solution at each check point. The resulting ""semi-asynchronous"" algorithm is guaranteed to converge for any problem even when PASSCoDe diverges, and for the cases where PASSCoDe converges they have almost identical speed.",2016,International Conference on Data Mining,Fields of study: instruction setlogisticssupport vector machineconvergencerisk managementtheoretical computer sciencedistributed computingdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
FacetsViewer: A Tool for Multi-faceted Decomposition of Complex Networks,Boon-Siew Seah (Nanyang Technological University)Sourav S. Bhowmick (Nanyang Technological University)Huey Eng Chua (Nanyang Technological University)Mengxuan ChenC. Forbes Dewey (Massachusetts Institute of Technology),"2061247836,2168903744,2113547901,2679126650,2098460508","The availability of large-scale network data has given rise to the opportunity to investigate higher level organization of these networks using graph theoretic analysis. In this paper, we demonstrate a novel network decomposition tool called FacetsViewer in order to make sense of the deluge of network data. In contrast to traditional graph clustering techniques, it finds not just a single decomposition of the network, but a multi-faceted atlas of semantically meaningful decompositions that portray alternative perspectives of the landscape of the underlying network. Each facet in the atlas represents a distinct interpretation of how the network can be meaningfully decomposed and organized. To this end, FacetsViewer maximizes interpretative value of the atlas by optimizing inter-facet semantic and structural orthogonality. Specifically, we demonstrate various features of FacetsViewer and its superior ability to generate and visualize multi-faceted atlas of complex networks.",2016,International Conference on Data Mining,Fields of study: ontologyvisualizationorganizationcluster analysisdata visualizationsemanticsdata sciencedata miningmachine learningcomputer science
Matrix Profile III: The Matrix Profile Allows Visualization of Salient Subsequences in Massive Time Series,"Chin-Chia Michael Yeh (Center for Information Technology)Helga Van Herle (University of California, Davis)Eamonn J. Keogh (University of California, Riverside)","2107817180,1534603910,2170070822","Multidimensional Scaling (MDS) is one of the most versatile tools used for exploratory data mining. It allows a first glimpse of possible structure in the data, which can inform the choice of analyses used. Its uses are multiple. It can give the user an idea as to the clusterability or linear separability of the data. It can help spot outliers, or can hint at the intrinsic dimensionality of the data. Moreover, it can sometimes reveal unexpected latent dimensions in the data. With all these uses, MDS is increasingly used in areas as diverse as marketing, medicine, genetics, music and linguistics. One of the strengths of MDS is that it is essentially agnostic to data type, as we can use any distance measure to create the distance matrix, which is the only required input to the MDS algorithm. In spite of this generality, we make the following claim. MDS is not (well) defined for an increasingly important data type, time series subsequences. In this work we explain why this is the case, and we propose a scalable solution. We demonstrate the utility of our ideas on several diverse real-world datasets. At the core of our approach is a novel Minimum Description Length (MDL) subsequence extraction algorithm. Beyond MDS visualization, this subsequence extraction subroutine may be a useful tool in its own right.",2016,International Conference on Data Mining,Fields of study: heart rate variabilitycluster analysisalgorithm designtime seriesdata visualizationdata sciencetheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
The Development of a Smart Taxicab Scheduling System: A Multi-source Data Fusion Perspective,Yang Wang (University of Science and Technology of China)Binxin Liang (University of Science and Technology of China)Wei Zheng (University of Wisconsin-Madison)Liusheng Huang (University of Science and Technology of China)Hengchang Liu (University of Science and Technology of China),"2675046740,2516679256,2490516200,2166308156,2201582336","Recent advances in vehicular networks, GPS and smartphone technologies have changed the paradigm of intelligent taxicab systems. Indeed, taxicab trajectories and online calling information have enabled us to provide more efficient and personalized services. However, existing approaches are not sufficient in exploiting cooperative scheduling techniques and utilizing real time calling information. To this end, in this paper, we model the time-varying regularities of traffic flows, activity ratios of passengers, and unoccupied taxicabs of road segments by mining statistical data on taxicab trajectories. Along this line, we propose a novel approach to calculate the expected revenue of possible routes for individual taxicabs while considering the influence of others, and at the same time, advance a dynamic taxicab scheduling mechanism with online taxicab calling information. Finally, we evaluate our algorithm on real-world taxicab data. Experimental results demonstrate that our approach outperforms existing alternative solutions in terms of average revenue of taxi drivers.",2016,International Conference on Data Mining,Fields of study: trajectoryschedulingdata miningreal time computingsimulationcomputer science
TENET: A Machine Learning-Based System for Target Characterization in Signaling Networks,Huey Eng Chua (Nanyang Technological University)Sourav S. Bhowmick (Nanyang Technological University)Lisa Tucker-Kellogg (National University of Singapore)C. Forbes Dewey (Massachusetts Institute of Technology),"2113547901,2168903744,169658354,2098460508","Target characterization of a biological network identifies characteristics that distinguish targets (nodes that can serve as molecular targets of drugs) from other nodes. In this demonstration, we present TENET (Target charactErization using NEtwork Topology), a software that facilitates topological features-based characterization of known targets in signaling networks modelling dynamic interactions within biological systems. TENET is based on a support vector machine (SVM)-based approach and generates a characterization model. These models specify topological features that can discriminate known targets and how these features are combined to quantify the likelihood of a node being a target. Hence, TENET can be used for prioritizing targets and for identifying novel candidate targets that share similar characteristics with known targets. The interactive user interface that TENET provides facilitates users' study and understanding of topological characteristics of targets in signaling networks.",2016,International Conference on Data Mining,Fields of study: support vector machinegraphical user interfacepredictive modellingcomputational modelbioinformaticsdata miningmachine learningcomputer science
Five Year Life Expectancy Calculator for Older Adults,Ankit Agrawal (Northwestern University)Jason Scott Mathias (Northwestern University)David Baker (Northwestern University)Alok N. Choudhary (Northwestern University),"2160807299,2048543092,2128597979,2147783234","Incorporating accurate prognostic information into clinical decision making could advance evidence-based, person-centered healthcare by more effectively targeting healthcare services to those patients most likely to benefit. Here we describe the deployment of predictive models for five year life expectancy of patients, built on electronic health records (EHR) of nearly 7,500 patients aged 50 and above, with one or more visits to a large, academic, multispeciality hospital in a year, exploring more than 75 modeling configurations. The online web-tool takes a non-redundant subset of 24 patient attributes as input and generates a patient-specific prediction of 5-year survival. The online five year life expectancy calculator is available at http://info.eecs.northwestern.edu/FiveYearLifeExpectancyCalculator.",2016,International Conference on Data Mining,Fields of study: cancerpredictive modellingensemble learningsupervised learningdata sciencedata miningmachine learningsimulationcomputer science
Differential Location Privacy for Sparse Mobile Crowdsensing,Leye Wang (Institut Mines-Télécom)Daqing Zhang (Peking University)Dingqi Yang (University of Fribourg)Brian Y. Lim (Carnegie Mellon University)Xiaojuan Ma (Hong Kong University of Science and Technology),"2117335613,2156097516,2720673230,2144006707,2171908633","Sparse Mobile Crowdsensing (MCS) has become a compelling approach to acquire and make inference on urban-scale sensing data. However, participants risk their location privacy when reporting data with their actual sensing positions. To address this issue, we adopt e-differential-privacy in Sparse MCS to provide a theoretical guarantee for participants' location privacy regardless of an adversary's prior knowledge. Furthermore, to reduce the data quality loss caused by differential location obfuscation, we propose a privacypreserving framework with three components. First, we learn a data adjustment function to fit the original sensing data to the obfuscated location. Second, we apply a linear program to select an optimal location obfuscation function, which aims to minimize the uncertainty in data adjustment. We also propose a fast approximated variant. Third, we propose an uncertaintyaware inference algorithm to improve the inference accuracy of obfuscated data. Evaluations with real environment and traffic datasets show that our optimal method reduces the data quality loss by up to 42% compared to existing differential privacy methods.",2016,International Conference on Data Mining,Fields of study: servermobile telephonyprivacyuncertaintyinformation privacyinternet privacycomputer securitydata miningcomputer science
Bayesian Rule Sets for Interpretable Classification,Tong Wang (Massachusetts Institute of Technology)Cynthia Rudin (Massachusetts Institute of Technology)Finale Velez-DoshiYimin Liu (Ford Motor Company)Erica KlampflPerry MacNeille,"2653077625,2141705163,2584993580,2155316287,2686512140,2668692975","A Rule Set model consists of a small number of short rules for interpretable classification, where an instance is classified as positive if it satisfies at least one of the rules. The rule set provides reasons for predictions, and also descriptions of a particular class. We present a Bayesian framework for learning Rule Set models, with prior parameters that the user can set to encourage the model to have a desired size and shape in order to conform with a domain-specific definition of interpretability. We use an efficient inference approach for searching for the MAP solution and provide theoretical bounds to reduce computation. We apply Rule Set models to ten UCI data sets and compare the performance with other interpretable and non-interpretable models.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingsimulated annealingcomputational modeldata miningpattern recognitionmachine learningcomputer sciencemathematics
Markov Switching Copula Models for Longitudinal Data,Alfredo Cuesta-Infante (King Juan Carlos University)Kalyan Veeramachaneni (Massachusetts Institute of Technology),"2002923295,161637196","In this paper we present a novel Markov Switching generative model for continuous multivariate time series and longitudinal data based on Gaussian copula functions. We assume that the values of the multivariate time series at every time slice are sampled out of a joint probability distribution that is selected by the latent state. The use of Gaussian copula functions give the flexibility of individual marginals for each time series and a common dependence structure given by a correlation matrix. The transition matrix together with all the observation models are learned by means of Gibbs sampling. We also test the method both with synthetic and real data sets, and compare them with other usual techniques. Results show that models assuming normality in real data sets are not a good approach when marginals are not Gaussian, and they are outranked by our proposal.",2016,International Conference on Data Mining,Fields of study: econometricsdata miningpattern recognitionstatisticscomputer sciencemathematics
Robust Automated Human Activity Recognition and Its Application to Sleep Research,"Aarti Sathyanarayana (Qatar Computing Research Institute)Ferda Ofli (Qatar Computing Research Institute)Luis Fernández-Luque (Qatar Computing Research Institute)Jaideep Srivastava (Qatar Computing Research Institute)Ahmed K. Elmagarmid (Qatar Computing Research Institute)Teresa Arora (Qatar Computing Research Institute)Shahrad Taheri (Weil, Gotshal & Manges)","2602190313,2311284797,2535695792,2684568503,2057816297,2612487028,2626719040","Human Activity Recognition (HAR) is a powerful tool for understanding human behaviour. Pervasive sensors, such as wearable devices, have an increasing market penetration and generate a tremendous amount of data. The myriad of available clinical and consumer-grade wearables generate a continuous time series of a person's daily physical exertion and rest. Applying HAR to the activity time series can provide new insights by enriching the feature set in health studies, and enhancing the personalisation and effectiveness of health, wellness, and fitness applications. The analyses of complex health behaviours such as sleep, traditionally require a time-consuming manual interpretation by experts. This manual work is necessary due to the erratic periodicity and persistent noisiness of human behaviour. In this paper, we present a robust automated human activity recognition algorithm, which we call RAHAR. We test our algorithm in the application area of sleep research by providing a novel framework for evaluating sleep quality and examining the correlation between the aforementioned and an individual's physical activity. Our results improve the state-of-the-art procedure in sleep research by 15% for area under ROC and by 30% for F1 score on average. However, application of RAHAR is not limited to sleep analysis and can be used for understanding other health problems such as obesity, diabetes, and cardiac diseases.",2016,International Conference on Data Mining,Fields of study: accelerometersensorrobustnessalgorithm designtime seriesdata miningartificial intelligencesimulationstatisticscomputer science
Binary Classifier Calibration Using an Ensemble of Near Isotonic Regression Models,Mahdi Pakdaman Naeini (University of Tehran)Gregory F. Cooper (University of Pittsburgh),"2104073635,2137326150","Learning accurate probabilistic models from data is crucial in many practical tasks in data mining. In this paper we present a new non-parametric calibration method called Ensemble of Near Isotonic Regression (ENIR). The method can be considered as an extension of BBQ, a recently proposed calibration method, as well as the commonly used calibration method based on isotonic regression (IsoRegC). ENIR is designed to address the key limitation of IsoRegC which is the monotonicity assumption of the predictions. Similar to BBQ, the method post-processes the output of a binary classifier to obtain calibrated probabilities. Thus it can be used with many existing classification models to generate accurate probabilistic predictions. We demonstrate the performance of ENIR on synthetic and real datasets for commonly applied binary classification models. Experimental results show that the method outperforms several common binary classifier calibration methods. In particular on the real data, ENIR commonly performs statistically significantly better than the other methods, and never worse. It is able to improve the calibration power of classifiers, while retaining their discrimination power. The method is also computationally tractable for large scale datasets, as it is O(N log N) time, where N is the number of samples.",2016,International Conference on Data Mining,Fields of study: data modelingprobabilistic logichistogramcalibrationpredictive modellingcomputational modelprobabilistic classificationdata miningpattern recognitionmachine learningstatisticscomputer science
DeBot: Twitter Bot Detection via Warped Correlation,Nikan Chavoshi (University of New Mexico)Hossein Hamooni (University of New Mexico)Abdullah Mueen (University of New Mexico),"2203691504,308734036,2083987245","We develop a warped correlation finder to identify correlated user accounts in social media websites such as Twitter. The key observation is that humans cannot be highly synchronous for a long duration, thus, highly synchronous user accounts are most likely bots. Existing bot detection methods are mostly supervised, which requires a large amount of labeled data to train, and do not consider cross-user features. In contrast, our bot detection system works on activity correlation without requiring labeled data. We develop a novel lag-sensitive hashing technique to cluster user accounts into correlated sets in near real-time. Our method, named DeBot, detects thousands of bots per day with a 94% precision and generates reports online everyday. In September 2016, DeBot has accumulated about 544,868 unique bots in the previous one year. We compare our detection technique with per-user techniques and with Twitter's suspension system. We observe that some bots can avoid Twitter's suspension mechanism and remain active for months, and, more alarmingly, we show that DeBot detects bots at a rate higher than the rate Twitter is suspending them.",2016,International Conference on Data Mining,Fields of study: internet privacyworld wide webdata miningsimulationcomputer science
Toward Representation Independent Analytics over Structured Data,Yodsawalai Chodpathumwan (University of Illinois at Urbana–Champaign)Jose Picado (Oregon State University)Arash Termehchy (Oregon State University)Alan Fern (Oregon State University)Yizhou Sun (Northeastern University),"33543605,2226491996,146765738,2139785505,2131539564","Database analytics algorithms leverage quantifiable structural properties of the data to predict interesting concepts and relationships. The same information, however, can be represented using many different structures and the structural properties observed over particular representations do not necessarily hold for alternative structures. Because these algorithms tend to be highly effective over some choices of structure, such as that of the databases used to validate them, but not so effective with others, database analytics has largely remained the province of experts who can find the desired forms for these algorithms. We argue that in order to make database analytics usable, we should use or develop algorithms that are effective over a wide range of choices of structural organizations. We introduce the notion of representation independence and empirically analyze the amount of representation independence of some popular database analytics algorithms. Our results indicate that most algorithms are not generally representation independent and find some characteristics of more representation independent heuristics.",2016,International Conference on Data Mining,Fields of study: predictionalgorithm designapproximation algorithmdata sciencedata miningmachine learningstatisticscomputer science
"Modeling Ambiguity, Subjectivity, and Diverging Viewpoints in Opinion Question Answering Systems","Mengting Wan (University of California, San Diego)Julian McAuley (University of California, San Diego)","2294194149,2041520510","Product review websites provide an incredible lens into the wide variety of opinions and experiences of different people, and play a critical role in helping users discover products that match their personal needs and preferences. To help address questions that can't easily be answered by reading others' reviews, some review websites also allow users to pose questions to the community via a question-answering (QA) system. As one would expect, just as opinions diverge among different reviewers, answers to such questions may also be subjective, opinionated, and divergent. This means that answering such questions automatically is quite different from traditional QA tasks, where it is assumed that a single 'correct' answer is available. While recent work introduced the idea of question-answering using product reviews, it did not account for two aspects that we consider in this paper: (1) Questions have multiple, often divergent, answers, and this full spectrum of answers should somehow be used to train the system, and (2) What makes a 'good' answer depends on the asker and the answerer, and these factors should be incorporated in order for the system to be more personalized. Here we build a new QA dataset with 800 thousand questions—and over 3.1 million answers—and show that explicitly accounting for personalization and ambiguity leads both to quantitatively better answers, but also a more nuanced view of the range of supporting, but subjective, opinions.",2016,International Conference on Data Mining,Fields of study: lenspredictive modellingknowledge extractionknowledge managementworld wide webinformation retrievaldata miningmachine learningcomputer science
Microblog Sentiment Topic Model,Aman AhujaWei Wei (Carnegie Mellon University)Kathleen M. Carley (Carnegie Mellon University),"2565024679,2235903388,2098520675","With the prevalence of social media, such as Twitter, short-length text like microblogs have become an important mode of text on the Internet. In contrast to other forms of media, such as newspaper, the text in these social media posts usually contains fewer words, and is concentrated on a much narrower selection of topics. For these reasons, traditional LDA-based sentiment and topic modeling techniques generally do not work well in case of social media data. Another characteristic feature of this data is the use of special meta tokens, such as hashtags, which contain unique semantic meanings that are not captured by other ordinary words. In the recent years, many topic modeling techniques have been proposed for social media data, but the majority of this work does not take into account the specialty of tokens, such as hashtags, and treats them as ordinary words. In this paper, we propose probabilistic graphical models to address the problem of discovering latent topics and their sentiment from social media data, mainly microblogs like Twitter. We first propose MTM (Microblog Topic Model), a generative model that assumes each social media post generates from a single topic, and models both words and hashtags separately. We then propose MSTM (Microblog Sentiment Topic Model), an extension of MTM, which also embodies the sentiment associated with the topics. We evaluated our models using Twitter dataset, and experimental results show that our models outperform the existing techniques.",2016,International Conference on Data Mining,Fields of study: data modelingmathematical modelsentiment analysissemanticsinternet privacyworld wide webdata miningcomputer science
Integrated Analysis of Research Publications and Patents for Strategic Decision Making,Nidhi SaraswatLipika Dey (Harvard University)Ishan Verma (Tata Consultancy Services)Hemant Gupta (Harvard University),"2658921054,2305939289,2119443153,2477209169","In this extremely competitive era, it has become imperative for organizations to keep themselves informed about the technological advancements and their implications in their domain. It is important that they take advantage of the vast amount of knowledge out there on the web for business and strategy planning. This paper proposes methodologies for analyzing patenting and publishing data jointly to predict how advances in research or technology are likely to affect the future of commercialization across industrial sectors. It proposes predictive methods to identify the technology trends for various sectors and also proposes methods to identify the current ""white spaces"" or promising research areas with high application potential that are yet to be exploited fully. The results presented in this paper are with respect to the area of Computer Science though the methods are generic.",2016,International Conference on Data Mining,Fields of study: algorithm designmarket researchmanagement scienceoperations researchdata miningcomputer science
Robust Graph-Theoretic Clustering Approaches Using Node-Based Resilience Measures,"John Matta (Southern Illinois University Edwardsville)Tayo Obafemi-Ajayi (Missouri University of Science and Technology)Jeffrey Borwey (Southern Illinois University Edwardsville)Donald C. Wunsch (Missouri University of Science and Technology)Gunes Ercal (University of California, Los Angeles)","2503480545,2428839664,349827689,2127870723,602904139","This paper examines a schema for graph-theoretic clustering using node-based resilience measures. Node-based resilience measures optimize an objective based on a critical set of nodes whose removal causes some severity of disconnection in the network. Beyond presenting a general framework for the usage of node based resilience measures for variations of clustering problems, we emphasize the unique potential of such methods to accomplish the following properties: (i) clustering a graph in one step without knowing the number of clusters a priori, and (ii) removing noise from noisy data. We first present results of clustering experiments using a β-parametrized generalization of vertex attack tolerance, showing high clustering accuracy for both real datasets and equal density synthetic data sets, as well as successful removal of noise nodes. It is shown that arbitrarily increasing β increases the number of noise nodes removed in some cases, and that internal validation measures can be used to determine the correct number of clusters in a class of datasets. Further results are presented using five different resilience measures with a general node-based resilience clustering technique. In a subset of cases a resilience measure, such as integrity, is able to cluster to high accuracy in one step, giving the correct clustering while also determining the correct number of clusters. Integrity is also shown to be promising with respect to noise removal, removing up to 80% of noise on some datasets.",2016,International Conference on Data Mining,Fields of study: k medians clusteringcanopy clustering algorithmcorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmfuzzy clusteringclustering high dimensional datanoise measurementscatteringcluster analysispsychological resiliencetheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Randomized Response and Balanced Bloom Filters for Privacy Preserving Record Linkage,Rainer Schnell (University of Duisburg-Essen)Christian Borgs (University of Duisburg-Essen),"2250090818,2540532416","In most European settings, record linkage across different institutions is based on encrypted personal identifiers - such as names, birthdays, or places of birth - to protect privacy. However, in practice up to 20% of the records may contain errors in identifiers. Thus, exact record linkage on encrypted identifiers usually results in the loss of large subsets of the data. Such losses usually imply biased statistical estimates since the causes of errors might be correlated with the variables of interest in many applications. Over the past 10 years, the field of Privacy Preserving Record Linkage (PPRL) has developed different techniques to link data without revealing the identity of the described entity. However, only few techniques are suitable for applied research with large data bases that include millions of records, which is typical for administrative or medical data bases. Bloom filters were found to be one successful technique for PPRL when large scale applications are concerned. Yet, Bloom filters have been subject to cryptographic attacks. Previous research has shown that the straight application of Bloom filters has a non-zero re-identification risk. We present new results on recently developed techniques defying all known attacks on PPRL Bloom filters. The computationally inexpensive algorithms modify personal identifiers by combining different cryptographic techniques. The paper demonstrates these new algorithms and demonstrates their performance concerning precision, recall, and re-identification risk on large data bases.",2016,International Conference on Data Mining,Fields of study: hamming weightcascading style sheetsprivacycryptographyinformation privacyinternet privacyworld wide webdata miningstatisticscomputer science
ADAGIO: Fast Data-Aware Near-Isometric Linear Embeddings,Jaroslaw BlasiokCharalampos E. Tsourakakis (Harvard University),"2661444579,750472553","Many important applications, including signal reconstruction, parameter estimation, and signal processing in a compressed domain, rely on a low-dimensional representation of the dataset that preserves all pairwise distances between the data points and leverages the inherent geometric structure that is typically present. Recently Hedge, Sankaranarayanan, Yin and Baraniuk [19] proposed the first data-aware near-isometric linear embedding which achieves the best of both worlds. However, their method NuMax does not scale to large-scale datasets. Our main contribution is a simple, data-aware, near-isometric linear dimensionality reduction method which significantly outperforms a state-of-the-art method [19] with respect to scalability while achieving high quality near-isometries. Furthermore, our method comes with strong worst-case theoretical guarantees that allow us to guarantee the quality of the obtained nearisometry. We verify experimentally the efficiency of our method on numerous real-world datasets, where we find that our method (9 hours) on medium scale datasets with 60 000 datapoints in 784 dimensions. Finally, we use our method as a preprocessing step to increase the computational efficiency of a classification application and for speeding up approximate nearest neighbor queries.",2016,International Conference on Data Mining,Fields of study: nonlinear distortionprincipal component analysisalgorithm designestimation theorymachine learningmathematical optimizationstatisticscomputer sciencemathematics
Scalable Privacy-Preserving Linking of Multiple Databases Using Counting Bloom Filters,Dinusha Vatsalan (Australian National University)Peter Christen (Australian National University)Erhard Rahm (Leipzig University),"145048928,2023765750,2158742306","The integration, mining, and analysis of person-specific data can provide enormous opportunities for organizations, governments, and researchers to leverage today's massive data collections. However, the use of personal or otherwise sensitive data also raises concerns about the privacy, confidentiality, and potential discrimination of people. Privacy-preserving record linkage (PPRL) is a growing research area that aims at integrating sensitive information from multiple disparate databases held by different organizations while preserving the privacy of the individuals in these databases by not revealing their identities and thereby preventing re-identification and discrimination. PPRL approaches are increasingly required in many real-world application areas ranging from healthcare to national security. Previous approaches to PPRL have mostly focused on linking only two databases. Scaling PPRL to several databases is an open challenge since privacy threats as well as the computation and communication costs increase significantly with the number of databases involved. We thus propose a new encoding method of sensitive data based on Counting Bloom Filters (CBF) to improve privacy for multi-party PPRL (MP-PPRL). We investigate optimizations to reduce computation and communication costs for CBF-based MP-PPRL. Our empirical evaluation with real datasets demonstrates the viability of our approach in terms of scalability, linkage quality, and privacy.",2016,International Conference on Data Mining,Fields of study: scalabilitycouplingcommunications protocolprivacyinformation privacyinternet privacyworld wide webdata miningcomputer science
Learning Compatibility Across Categories for Heterogeneous Item Recommendation,"Ruining He (University of California, San Diego)Charles PackerJulian McAuley (University of California, San Diego)","2265624539,2321256530,2041520510","Identifying relationships between items is a key task of an online recommender system, in order to help users discover items that are functionally complementary or visually compatible. In domains like clothing recommendation, this task is particularly challenging since a successful system should be capable of handling a large corpus of items, a huge amount of relationships among them, as well as the high-dimensional and semantically complicated features involved. Furthermore, the human notion of ""compatibility"" to capture goes beyond mere similarity: For two items to be compatible—whether jeans and a t-shirt, or a laptop and a charger—they should be similar in some ways, but systematically different in others. In this paper we propose a novel method, Monomer, to learn complicated and heterogeneous relationships between items in product recommendation settings. Recently, scalable methods have been developed that address this task by learning similarity metrics on top of the content of the products involved. Here our method relaxes the metricity assumption inherent in previous work and models multiple localized notions of 'relatedness,' so as to uncover ways in which related items should be systematically similar, and systematically different. Quantitatively, we show that our system achieves state-of-the-art performance on large-scale compatibility prediction tasks, especially in cases where there is substantial heterogeneity between related items.",2016,International Conference on Data Mining,Fields of study: data modelingvisualizationcomputational modelrecommender systemmultimediaworld wide webinformation retrievaldata miningmachine learningcomputer science
Unsupervised Feature Selection for Outlier Detection by Modelling Hierarchical Value-Feature Couplings,"Guansong Pang (University of Technology, Sydney)Longbing Cao (University of Technology, Sydney)Ling Chen (University of Technology, Sydney)Huan Liu (Arizona State University)","2583648180,2115085568,2717954821,2122391114","Proper feature selection for unsupervised outlier detection can improve detection performance but is very challenging due to complex feature interactions, the mixture of relevant features with noisy/redundant features in imbalanced data, and the unavailability of class labels. Little work has been done on this challenge. This paper proposes a novel Coupled Unsupervised Feature Selection framework (CUFS for short) to filter out noisy or redundant features for subsequent outlier detection in categorical data. CUFS quantifies the outlierness (or relevance) of features by learning and integrating both the feature value couplings and feature couplings. Such value-to-feature couplings capture intrinsic data characteristics and distinguish relevant features from those noisy/redundant features. CUFS is further instantiated into a parameter-free Dense Subgraph-based Feature Selection method, called DSFS. We prove that DSFS retains a 2-approximation feature subset to the optimal subset. Extensive evaluation results on 15 real-world data sets show that DSFS obtains an average 48% feature reduction rate, and enables three different types of pattern-based outlier detection methods to achieve substantially better AUC improvements and/or perform orders of magnitude faster than on the original feature set. Compared to its feature selection contender, on average, all three DSFS-based detectors achieve more than 20% AUC improvement.",2016,International Conference on Data Mining,Fields of study: data modelingnoise measurementcouplingfeaturefeature extractiondetectordata miningpattern recognitionmachine learningcomputer sciencemathematics
Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins,"Yan Zhu (Shanghai Jiao Tong University)Zachary Zimmerman (Azusa Pacific University)Nader Shakibay SenobariChin-Chia Michael Yeh (Center for Information Technology)Gareth FunningAbdullah Mueen (University of New Mexico)Philip Brisk (University of California, Riverside)Eamonn J. Keogh (University of California, Riverside)","2678804180,2316597706,2585336708,2107817180,2659342773,2083987245,114158945,2170070822","Time series motifs have been in the literature for about fifteen years, but have only recently begun to receive significant attention in the research community. This is perhaps due to the growing realization that they implicitly offer solutions to a host of time series problems, including rule discovery, anomaly detection, density estimation, semantic segmentation, etc. Recent work has improved the scalability to the point where exact motifs can be computed on datasets with up to a million data points in tenable time. However, in some domains, for example seismology, there is an insatiable need to address even larger datasets. In this work we show that a combination of a novel algorithm and a high-performance GPU allows us to significantly improve the scalability of motif discovery. We demonstrate the scalability of our ideas by finding the full set of exact motifs on a dataset with one hundred million subsequences, by far the largest dataset ever mined for time series motifs. Furthermore, we demonstrate that our algorithm can produce actionable insights in seismology and other domains.",2016,International Conference on Data Mining,Fields of study: scalabilitydatabase indextime seriesdata sciencebioinformaticsdata miningmachine learningcomputer science
One-Pass Logistic Regression for Label-Drift and Large-Scale Classification on Distributed Systems,Vu Nguyen (Deakin University)Tu Dinh Nguyen (Deakin University)Trung Le (University of Canberra)Svetha Venkatesh (Deakin University)Dinh Q. Phung (Deakin University),"2097300135,2151001456,2130077519,2146461601,2314522249","Logistic regression (LR) for classification is the workhorse in industry, where a set of predefined classes is required. The model, however, fails to work in the case where the class labels are not known in advance, a problem we term label-drift classification. Label-drift classification problem naturally occurs in many applications, especially in the context of streaming settings where the incoming data may contain samples categorized with new classes that have not been previously seen. Additionally, in the wave of big data, traditional LR methods may fail due to their expense of running time. In this paper, we introduce a novel variant of LR, namely one-pass logistic regression (OLR) to offer a principled treatment for label-drift and large-scale classifications. To handle largescale classification for big data, we further extend our OLR to a distributed setting for parallelization, termed sparkling OLR (Spark-OLR). We demonstrate the scalability of our proposed methods on large-scale datasets with more than one hundred million data points. The experimental results show that the predictive performances of our methods are comparable orbetter than those of state-of-the-art baselines whilst the executiontime is much faster at an order of magnitude. In addition, the OLR and Spark-OLR are invariant to data shuffling and have no hyperparameter to tune that significantly benefits data practitioners and overcomes the curse of big data cross-validationto select optimal hyperparameters.",2016,International Conference on Data Mining,Fields of study: data modelinglogisticsestimationbig datadata sciencedata miningmachine learningstatisticscomputer science
Explode: An Extensible Platform for Differentially Private Data Analysis,"Emir Esmerdag (Istanbul Technical University)Mehmet Emre Gursoy (University of California, Los Angeles)Ali Inan (University of Texas at Dallas)Yucel Saygin (Sabancı University)","2487156254,2086769572,2138288751,1576981941","Differential privacy (DP) has emerged as a popular standard for privacy protection and received great attention from the research community. However, practitioners often find DP cumbersome to implement, since it requires additional protocols (e.g., for randomized response, noise addition) and changes to existing database systems. To avoid these issues we introduce Explode, a platform for differentially private data analysis. The power of Explode comes from its ease of deployment and use: The data owner can install Explode on top of an SQL server, without modifying any existing components. Explode then hosts a web application that allows users to conveniently perform many popular data analysis tasks through a graphical user interface, e.g., issuing statistical queries, classification, correlation analysis. Explode automatically converts these tasks to collections of SQL queries, and uses the techniques in [3] to determine the right amount of noise that should be added to satisfy DP while producing high utility outputs. This paper describes the current implementation of Explode, together with potential improvements and extensions.",2016,International Conference on Data Mining,Fields of study: serversensitivitycorrelationprivacyalgorithm designdata analysisworld wide webdata miningdatabasecomputer science
Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation,"Ruining He (University of California, San Diego)Julian McAuley (University of California, San Diego)","2265624539,2041520510","Predicting personalized sequential behavior is a key task for recommender systems. In order to predict user actions such as the next product to purchase, movie to watch, or place to visit, it is essential to take into account both long-term user preferences and sequential patterns (i.e., short-term dynamics). Matrix Factorization and Markov Chain methods have emerged as two separate but powerful paradigms for modeling the two respectively. Combining these ideas has led to unified methods that accommodate long-and short-term dynamics simultaneously by modeling pairwise user-item and item-item interactions. In spite of the success of such methods for tackling dense data, they are challenged by sparsity issues, which are prevalent in real-world datasets. In recent years, similarity-based methods have been proposed for (sequentially-unaware) item recommendation with promising results on sparse datasets. In this paper, we propose to fuse such methods with Markov Chains to make personalized sequential recommendations. We evaluate our method, Fossil, on a variety of large, real-world datasets. We show quantitatively that Fossil outperforms alternative algorithms, especially on sparse datasets, and qualitatively that it captures personalized dynamics and is able to make meaningful recommendations.",2016,International Conference on Data Mining,Fields of study: sparse matrixpredictive modellingpredictionmarkov processdata scienceworld wide webinformation retrievaldata miningmachine learningstatisticscomputer sciencemathematics
Aligned Matrix Completion: Integrating Consistency and Independency in Multiple Domains,Linli Xu (University of Science and Technology of China)Zaiyi ChenQi Zhou (University of Science and Technology of China)Enhong Chen (University of Science and Technology of China)Nicholas Jing Yuan (Microsoft)Xing Xie (Microsoft),"2326517690,2526528798,2424514021,2136372366,2096490164,2125800575","Matrix completion is the task of recovering a data matrix from a sample of entries, and has received significant attention in theory and practice. Normally, matrix completion considers a single matrix, which can be a noisy image or a rating matrix in recommendation. In practice however, data is often obtained from multiple domains rather than a single domain. For example, in recommendation, multiple matrices may exist as user x movie and user x book, while correlations among the multiple domains can be reasonably exploited to improve the quality of matrix completion. In this paper, we consider the problem of aligned matrix completion, where multiple matrices are recovered that correspond to different representations of the same group of objects. In the proposed model, we maintain consistency of multiple domains with a shared latent structure, while allowing independent patterns for each separate domain. In addition, we impose the low-rank structure of a matrix with a novel regularizer which provides better approximation than the standard nuclear norm relaxation.",2016,International Conference on Data Mining,Fields of study: document term matrixeight point algorithmdistance matrixnoise measurementcorrelationconvergencealgorithm designtheoretical computer sciencedata miningmathematical optimizationcomputer sciencemathematics
A Genetic Algorithm to Discover Flexible Motifs with Support,Joan Serra (Spanish National Research Council)Aleksandar Matic (Telefónica)Josep Lluis Arcos (Spanish National Research Council)Alexandros Karatzoglou (Telefónica),"2387781884,1457737264,2156157011,14841688","Finding repeated patterns or motifs in a time series is an important unsupervised task that has still a number of open issues, starting by the definition of motif. In this paper, we revise the notion of motif support, characterizing it as the number of patterns or repetitions that define a motif. We then propose GENMOTIF, a genetic algorithm to discover motifs with support which, at the same time, is flexible enough to accommodate other motif specifications and task characteristics. GENMOTIF is an anytime algorithm that easily adapts to many situations: searching in a range of segment lengths, applying uniform scaling, dealing with multiple dimensions, using different similarity and grouping criteria, etc. GENMOTIF is also parameter-friendly: it has only two intuitive parameters which, if set within reasonable bounds, do not substantially affect its performance. We demonstrate the value of our approach in a number of synthetic and real-world settings, considering traffic volume measurements, accelerometer signals, and telephone call records.",2016,International Conference on Data Mining,Fields of study: database indexinterpolationtime seriesgenetic algorithmapproximation algorithmtheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Robust Local Scaling Using Conditional Quantiles of Graph Similarities,Jayaraman J. Thiagarajan (Lawrence Livermore National Laboratory)Prasanna Sattigeri (Arizona State University)Karthikeyan Natesan Ramamurthy (IBM)Bhavya Kailkhura (Syracuse University),"2147911925,2000084203,2030434656,302486252","Spectral analysis of neighborhood graphs is one of the most widely used techniques for exploratory data analysis, with applications ranging from machine learning to social sciences. In such applications, it is typical to first encode relationships between the data samples using an appropriate similarity function. Popular neighborhood construction techniques such as k-nearest neighbor (k-NN) graphs are known to be very sensitive to the choice of parameters, and more importantly susceptible to noise and varying densities. In this paper, we propose the use of quantile analysis to obtain local scale estimates for neighborhood graph construction. To this end, we build an auto-encoding neural network approach for inferring conditional quantiles of a similarity function, which are subsequently used to obtain robust estimates of the local scales. In addition to being highly resilient to noise or outlying data, the proposed approach does not require extensive parameter tuning unlike several existing methods. Using applications in spectral clustering and single-example label propagation, we show that the proposed neighborhood graphs outperform existing locally scaled graph construction approaches.",2016,International Conference on Data Mining,Fields of study: matrix decompositionrobustnessdata analysisartificial neural networkdata miningmachine learningstatisticscomputer sciencemathematics
"Transfer Learning for Survival Analysis via Efficient L2,1-Norm Regularized Cox Regression",Yan Li (University of Michigan)Lu Wang (Wayne State University)Jie Wang (University of Michigan)Jieping Ye (University of Michigan)Chandan K. Reddy (Virginia Tech),"2607418379,2504125423,2471893859,2305258894,2100435683","In survival analysis, the primary goal is to monitor several entities and model the occurrence of a particular event of interest. In such applications, it is quite often the case that the event of interest may not always be observed during the study period and this gives rise to the problem of censoring which cannot be easily handled in the standard regression approaches. In addition, obtaining sufficient labeled training instances for learning a robust prediction model is a very time consuming process and can be extremely difficult in practice. In this paper, we propose a transfer learning based Cox method, called Transfer-Cox, which uses auxiliary data to augment learning when there are insufficient amount of training examples. The proposed method aims to extract ""useful"" knowledge from the source domain and transfer it to the target domain, thus potentially improving the prediction performance in such time-to-event data. The proposed method uses the l_2,1-norm penalty to encourage multiple predictors to share similar sparsity patterns, thus learns a shared representation across source and target domains, potentially improving the model performance on the target task. To speedup the computation, we apply the screening approach and extend the strong rule to sparse survival analysis models in multiple high-dimensional censored datasets. We demonstrate the performance of the proposed transfer learning method using several synthetic and high-dimensional microarray gene expression benchmark datasets and compare with other related competing state-of-the-art methods. Our results show that the proposed screening approach significantly improves the computational efficiency of the proposed algorithm without compromising the prediction performance. We also demonstrate the scalability of the proposed approach and show that the time taken to obtain the results is linear with respect to both the number of instances and features.",2016,International Conference on Data Mining,Fields of study: multi task learningtransfer of learningdata modelingclustering high dimensional dataregularizationhazardsurvival analysisregressionpredictive modellingpredictionsemi supervised learningeconometricsdata miningmachine learningstatisticscomputer science
Outlier Detection from Network Data with Subnetwork Interpretation,"Xuan Hong Dang (Aarhus University)Arlei Silva (Universidade Federal de Minas Gerais)Ambuj K. Singh (University of California, Santa Barbara)Ananthram Swami (United States Army Research Laboratory)Prithwish Basu (BBN Technologies)","1964285635,2166555088,2099219664,2059211748,2111459030","Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why a given network is exceptional, expressed in the form of subnetwork, is also equally important. We develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that help discriminate it from nearby samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace/subgraph discovery. We also show that the developed method converges to a global optimum. Empirical evaluation on various real-world network datasets demonstrates the advantages of our algorithm over various baseline methods.",2016,International Conference on Data Mining,Fields of study: network segmentationnetwork simulationsupport vector machinenetwork topologyalgorithm designlinear programmingdata miningpattern recognitionmachine learningcomputer sciencemathematics
Modeling Time Lags in Citation Networks,Tao-Yang FuZhen LeiWang-Chien Lee (Pennsylvania State University),"2637755136,2693907289,2143778659","The extant work on network analyses has thus far paid little attention to the heterogeneity in time lags and speed of information propagation along edges. In this paper, we study this novel problem, modeling the time dimension and lags on network edges, in the context of paper and patent citation networks where the variation in the speed of knowledge flows between connected nodes is apparent. We propose to model time lags in knowledge diffusions in citation networks in one of the two ways: deterministic lags and probabilistic lags. Then, we discuss two approaches of computationally working with time lags in edges of citation networks. Experimentally, we study two different applications to demonstrate the importance of the time dimension and lags in citations: (1) HITS algorithm and (2) patent citation recommendation. We conduct experiments on millions of U. S. patent data and Web of Science (WOS) paper data. Our experiments show that incorporating time dimension and lags in edges significantly improve network modeling and analyses.",2016,International Conference on Data Mining,Fields of study: probabilistic logiccomputational modelknowledge engineeringdata miningartificial intelligencemachine learningsimulationcomputer science
Analysing Political Opinions Using Redescription Mining,Esther Galbrun (Boston University)Pauli Miettinen (Max Planck Society),"2276244909,2015634213","Understanding the socio-economical background of voters supporting a certain cause or, vice versa, understanding the political stance of people from a certain socio-economical niche are important questions in political sciences. Traditionally, answering these questions has required the researcher to fix either the political stance or the socio-economical background. In this paper, we propose using redescription mining to automatically find the stances and niches that correspond to each other. We show how redescription mining can be applied to open data from voting advice applications, providing insights about the position of the candidates to parliamentary elections. Furthermore, we show that these insights are not only descriptive, but that they also generalize well to new data.",2016,International Conference on Data Mining,Fields of study: informaticsvotingdata analysisdata sciencedata miningstatistics
Mutual Reinforcement of Academic Performance Prediction and Library Book Recommendation,Defu Lian (University of Electronic Science and Technology of China)Yuyang YeWenya ZhuQi Liu (University of Science and Technology of China)Xing Xie (Microsoft)Hui Xiong (Rutgers–Newark),"2110195189,2583918026,2654502215,2420624292,2125800575,2153710278","The prediction of academic performance is one of the most important tasks in educational data mining, and has been widely studied in MOOCs and intelligent tutoring systems. Academic performance could be affected with factors like personality, skills, social environment, the use of library books and so on. However, it is still less investigated that how could the use of library books affect academic performance of college students and even leverage book-loan history for predicting academic performance. To this end, we propose a supervised content-aware matrix factorization for mutual reinforcement of academic performance prediction and library book recommendation. This model not only addresses the sparsity challenge by explainable dimension reduction techniques, but also promotes library book recommendation by recommending ""right"" books for students based on their performance levels and book meta information. Finally, we evaluate the proposed model on three years of the book-loan history and cumulative grade point average of 13,047 undergraduate students in one university. The results show that the proposed model outperforms the competing baselines on both tasks, and that academic performance is not only predictable from the book-loan history but also improves the recommendation of library books for students.",2016,International Conference on Data Mining,Fields of study: predictive modellingpredictionlinear programmingdata sciencemultimediadata miningartificial intelligencemachine learningcomputer science
Probabilistic Formulations of Regression with Mixed Guidance,"Aubrey Gress (University of California, Davis)Ian Davidson (University of California, Davis)","2226299968,2560595684","Regression problems assume every instanceisannotated(labeled)witharealvalue, aformof annotation we call strong guidance. In order for these annotations to be accurate, they must be the result of a precise experiment or measurement. However, in some cases additional weak guidance might be given by imprecise measurements, a domain expert or even crowd sourcing. Current formulations of regression are unable to use both types of guidance. We propose a regression framework that can also incorporate weak guidance based on relative orderings, bounds, neighboring and similarity relations. Consider learning to predict ages from portrait images, these new types of guidanceallowweakerformsofguidancesuchasstating a person is in their 20s or two people are similar in age. These types of annotations can be easier to generate than strong guidance. We introduce a probabilistic formulation for these forms of weak guidance and show that the resulting optimization problems are convex. Our experimental results show the benefits of these formulations on several data sets.",2016,International Conference on Data Mining,Fields of study: logisticsprobabilistic logicrandom variablemaximum likelihoodmathematical modeldata miningmachine learningmathematical optimizationstatisticsmathematics
Predicting COPD Failure by Modeling Hazard in Longitudinal Clinical Data,Jianfei Zhang (Université de Sherbrooke)Shengrui Wang (Université de Sherbrooke)Josiane Courteau (Université de Sherbrooke)Lifei Chen (Fujian Normal University)Aurelien BachAlain Vanasse (Université de Sherbrooke),"2311674678,2106818440,2161221774,2699319152,2585690658,1626633780","Chronic obstructive pulmonary disease (COPD) accounts for the highest rate of hospital readmissions and is the third leading cause of death in Canada, the United States and worldwide. Predicting COPD failure provides a prognostic warning of death or readmission, and is crucial to early intervention and decision-making. The aim of this study is to perform COPD failure prediction on longitudinal data. To address the inappropriate estimation of Cox hazard in current approaches, we propose a new representation of hazard to capture the relationship between survival probability and time-varying risk factors in a concise but effective way. To optimize model parameters, we design and maximize a new joint likelihood that comprises two components used to estimate survival status separately for failure and censored patients. A regularized optimization is performed on the joint likelihood to prevent overfitting arising from model learning. Our approach is applied to a real-life COPD data set and outperforms the current state-of-the-art prediction models in terms of the survival AUC, concordance index and Birer score metrics, this reveals that the great promise of our approach for clinical prediction.",2016,International Conference on Data Mining,Fields of study: data modelinghazarddatabase indexpredictive modellingmathematical modeleconometricsdata miningmachine learningstatisticscomputer science
Hyperbolae are No Hyperbole: Modelling Communities That are Not Cliques,Saskia Metzler (Max Planck Society)Stephan Gunnemann (Carnegie Mellon University)Pauli Miettinen (Max Planck Society),"2156792870,316694267,2015634213","Cliques are frequently used to model communities: a community is a set of nodes where each pair is equally likely to be connected. But studying real-world communities reveals that they have more structure than that. In particular, the nodes can be ordered in such a way that (almost) all edges in the community lie below a hyperbola. In this paper we present three new models for communities that capture this phenomenon. Our models explain the structure of the communities differently, but we also prove that they are identical in their expressive power. Our models fit to real-world data much better than traditional block models or previously-proposed hyperbolic models, both of which are a special case of our model. Our models also allow for intuitive interpretation of the parameters, enabling us to summarize the shapes of the communities in graphs effectively.",2016,International Conference on Data Mining,Fields of study: informaticsdata modelingcommunity structureprobabilistic logiccomputational modelshapetheoretical computer sciencecombinatoricsworld wide webdata miningmachine learningstatisticscomputer sciencemathematics
What You Will Gain By Rounding: Theory and Algorithms for Rounding Rank,Stefan NeumannRainer Gemulla (Max Planck Society)Pauli Miettinen (Max Planck Society),"2591944711,344318172,2015634213","When factorizing binary matrices, we often have to make a choice between using expensive combinatorial methods that retain the discrete nature of the data and using continuous methods that can be more efficient but destroy the discrete structure. Alternatively, we can first compute a continuous factorization and subsequently apply a rounding procedure to obtain a discrete representation. But what will we gain by rounding? Will this yield lower reconstruction errors? Is it easy to find a low-rank matrix that rounds to a given binary matrix? Does it matter which threshold we use for rounding? Does it matter if we allow for only non-negative factorizations? In this paper, we approach these and further questions by presenting and studying the concept of rounding rank. We show that rounding rank is related to linear classification, dimensionality reduction, and nested matrices. We also report on an extensive experimental study that compares different algorithms for finding good factorizations under the rounding rank model.",2016,International Conference on Data Mining,Fields of study: round off errorinformaticssymmetric matrixprobabilistic logicmatrix decompositiondiscrete mathematicscombinatoricsdata miningmathematical optimizationalgorithmmathematics
Distributed Mining and Modeling of Dynamic Lead-Lag Relations in Evolving Entities,Tian Guo (École Polytechnique Fédérale de Lausanne)Jean-Paul Calbimonte (École Polytechnique Fédérale de Lausanne)Karl Aberer (École Polytechnique Fédérale de Lausanne),"2166312522,671254235,150096297","Discovering and modeling lead-lag relations is a critical task in a variety of domains, including energy management, financial markets and environment monitoring. This task becomes more challenging when processing massive and highly dynamic data sources, often produced by sensors and live feeds that collect data about evolving entities in the real world. To cope with this data volume and velocity, distributed real-time computation systems have been proposed in the last years, although the problem of the lead-lag relation mining and modeling has not been deeply explored in this context. In this paper, we propose DL2-Miner, a novel distributed data mining framework for lead-lag relations based on this computational paradigm. DL2-Miner addresses the fundamental data mining task of uncovering interactions in evolving entities, and encompasses a lead-lag relation detection module with communication and computation optimization and a probabilistic model for lead-lag relation occurrence inference. It is implemented on top of the open source distributed real-time computation system Apache Storm, and preliminary experiments show promising results of our approach.",2016,International Conference on Data Mining,Fields of study: data modelingcorrelationleadcomputational modeltime seriesdata sciencedata miningdatabasemachine learningcomputer sciencemathematics
A Formation Energy Predictor for Crystalline Materials Using Ensemble Data Mining,Ankit Agrawal (Northwestern University)Bryce Meredig (Northwestern University)Chris Wolverton (Northwestern University)Alok N. Choudhary (Northwestern University),"2160807299,2023233987,1451069057,2147783234","Formation energy is one of the most important properties of a compound that is directly related to its stability. More negative the formation energy, the more stable the compound is likely to be. Here we describe the development and deployment of predictive models for formation energy, given the chemical composition of the material. The data-driven models described here are built using nearly 100,000 Density Functional Theory (DFT) calculations, which is a quantum mechanical simulation technique based on the electron density within the crystal structure of the material. These models are deployed in an online web-tool that takes a list of material compositions as input, generates over hundred composition-based attributes for each material and feeds them into the predictive models to obtain the predictions of formation energy. The online formation energy predictor is available at http://info.eecs.northwestern.edu/FEpredictor.",2016,International Conference on Data Mining,Fields of study: materials informaticschemical elementinformaticsdata modelingdensity functional theorypredictive modellingcomputational modelensemble learningsupervised learningdata sciencetheoretical computer sciencedata miningmachine learningstatisticscomputer science
LSHDB: a parallel and distributed engine for record linkage and similarity search,Dimitrios Karapiperis (Hellenic Open University)Aris Gkoulalas-Divanis (IBM)Vassilios S. Verykios (Hellenic Open University),"1879788522,57288862,77221159","In this paper, we present LSHDB, the first parallel and distributed engine for record linkage and similarity search. LSHDB materializes an abstraction layer to hide the mechanics of the Locality-Sensitive Hashing (a popular method for detecting similar items in high dimensions) which is used as the underlying similarity search engine. LSHDB creates the appropriate data structures from the input data and persists these structures on disk using a noSQL engine. It inherently supports the parallel processing of distributed queries, is highly extensible, and is easy to use.We will demonstrate LSHDB both as the underlying system for detecting similar records in the context of Record Linkage (and of Privacy-Preserving Record Linkage) tasks, as well as a search engine for identifying string values that are similar to submitted queries.",2016,International Conference on Data Mining,Fields of study: concretejavacouplingdatabase search engineparallel processingtheoretical computer scienceworld wide webdata miningdatabasecomputer science
Holistic Entity Clustering for Linked Data,Markus Nentwig (Leipzig University)Anika GroBErhard Rahm (Leipzig University),"2233119047,2585413963,2158742306",Pairwise link discovery approaches for the Web of Data do not scale to many sources thereby limiting the potential for data integration. We thus propose a holistic approach for linking many data sources based on a clustering of entities representing the same real-world object. Our clustering approach utilizes existing links and can deal with entities of different semantic types. The approach is able to identify errors in existing links and can find numerous additional links. An initial evaluation on real-world linked data shows the effectiveness of the proposed holistic entity matching.,2016,International Conference on Data Mining,Fields of study: data integrationcluster analysismaintenance engineeringsemanticsinformation retrievaldata miningdatabasemachine learningcomputer science
Regularized Content-Aware Tensor Factorization Meets Temporal-Aware Location Recommendation,Defu Lian (University of Electronic Science and Technology of China)Zhenyu ZhangYong Ge (University of North Carolina at Charlotte)Fuzheng Zhang (Microsoft)Nicholas Jing Yuan (Microsoft)Xing Xie (Microsoft),"2110195189,2639970337,2218492437,2110384818,2096490164,2125800575","Although weighted tensor factorization tailored to implicit feedback has shown its superior performance in temporal-aware location recommendation, it suffers from three critical challenges. First, it doesn't distinguish the confidence of negative preference for time-dependent unvisited locations from that for fully unvisited ones. Second, discontinuity arises from time discretization, and thus an infinitely large margin may exist between different bins of time. Third, geographical constraints of neighbor locations are not taken into account. To address these challenges, we propose a regularized content-aware tensor factorization (RCTF) algorithm, which exploits three strategies to address the corresponding challenges. First, it introduces a novel interaction regularization, second, it represents each bin of time by a derived feature vector from eigen decomposition of a time-bin similarity matrix, to capture the proximity of neighbor bins of time, third, it encodes geographical information of locations by discrete spatial distributions, so that spatial proximity constraints can be satisfied by simply feeding them into location content. The proposed algorithm is then evaluated for time-aware location recommendation on two large scale location-based social network datasets. The experimental results show the superiority of the proposed algorithm to several competing time-aware recommendation baselines, and verify the significant benefit of three strategies in the proposed algorithm.",2016,International Conference on Data Mining,Fields of study: symmetric matrixgraphical modelcollaborationmatrix decompositiondistribution functionstressdata miningmachine learningmathematical optimizationstatisticsmathematics
Recommending Packages to Groups,Shuyao Qi (University of Hong Kong)Nikos Mamoulis (University of Hong Kong)Evaggelia Pitoura (University of Ioannina)Panayiotis Tsaparas (University of Ioannina),"2146889459,18851973,2242762518,2234654910","The success of recommender systems has made them the focus of a massive research effort in both industry and academia. Recent work has generalized recommendations to suggest packages of items to single users, or single items to groups of users. However, to the best of our knowledge, the interesting problem of recommending a package to a group of users (P2G) has not been studied to date. This is a problem with several practical applications, such as recommending vacation packages to tourist groups, entertainment packages to groups of friends, or sets of courses to groups of students. In this paper, we formulate the P2G problem, and we propose probabilistic models that capture the preference of a group towards a package, incorporating factors such as user impact and package viability. We also investigate the issue of recommendation fairness. This is a novel consideration that arises in our setting, where we require that no user is consistently slighted by the item selection in the package. We present aggregation algorithms for finding the best packages and compare our suggested models with baseline approaches stemming from previous work. The results show that our models find packages of high quality which consider all special requirements of P2G recommendation.",2016,International Conference on Data Mining,Fields of study: probabilistic logicalgorithm designcomputational modelmathematical modelrecommender systemworld wide webdata miningmachine learningsimulationcomputer science
Efficient Distributed SGD with Variance Reduction,"Soham De (University of Maryland, College Park)Tom Goldstein (University of Maryland, College Park)","2193432646,2149306980","Stochastic Gradient Descent (SGD) has become one of the most popular optimization methods for training machine learning models on massive datasets. However, SGD suffers from two main drawbacks: (i) The noisy gradient updates have high variance, which slows down convergence as the iterates approach the optimum, and (ii) SGD scales poorly in distributed settings, typically experiencing rapidly decreasing marginal benefits as the number of workers increases. In this paper, we propose a highly parallel method, CentralVR, that uses error corrections to reduce the variance of SGD gradient updates, and scales linearly with the number of worker nodes. CentralVR enjoys low iteration complexity, provably linear convergence rates, and exhibits linear performance gains up to hundreds of cores for massive datasets. We compare CentralVR to state-of-the-art parallel stochastic optimization methods on a variety of models and datasets, and find that our proposed methods exhibit stronger scaling than other SGD variants.",2016,International Conference on Data Mining,Fields of study: serverdatabase indexerror detection and correctionconvergencecomputational modelapproximation algorithmstochastic processtheoretical computer sciencemachine learningmathematical optimizationstatisticscomputer science
Product-Based Neural Networks for User Response Prediction,Yanru QuHan Cai (Shanghai Jiao Tong University)Kan Ren (Shanghai Jiao Tong University)Weinan Zhang (University College London)Yong Yu (Shanghai Jiao Tong University)Ying WenJun Wang (University College London),"2633427306,2584166797,2277084468,2527611484,2119244895,2468632242,2557836567","Predicting user responses, such as clicks and conversions, is of great importance and has found its usage inmany Web applications including recommender systems, websearch and online advertising. The data in those applicationsis mostly categorical and contains multiple fields, a typicalrepresentation is to transform it into a high-dimensional sparsebinary feature representation via one-hot encoding. Facing withthe extreme sparsity, traditional models may limit their capacityof mining shallow patterns from the data, i.e. low-order featurecombinations. Deep models like deep neural networks, on theother hand, cannot be directly applied for the high-dimensionalinput because of the huge feature space. In this paper, we proposea Product-based Neural Networks (PNN) with an embeddinglayer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between interfieldcategories, and further fully connected layers to explorehigh-order feature interactions. Our experimental results on twolarge-scale real-world ad click datasets demonstrate that PNNsconsistently outperform the state-of-the-art models on various metrics.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingencodingartificial neural networkdata sciencedata miningmachine learningstatisticscomputer science
Faster Kernels for Graphs with Continuous Attributes via Hashing,Christopher MorrisNils M. Kriege (Technical University of Dortmund)Kristian Kersting (Technical University of Dortmund)Petra Mutzel (Technical University of Dortmund),"2529370454,738094605,2252032993,2257800988","While state-of-the-art kernels for graphs with discrete labels scale well to graphs with thousands of nodes, the few existing kernels for graphs with continuous attributes, unfortunately, do not scale well. To overcome this limitation, we present hash graph kernels, a general framework to derive kernels for graphs with continuous attributes from discrete ones. The idea is to iteratively turn continuous attributes into discrete labels using randomized hash functions. We illustrate hash graph kernels for the Weisfeiler-Lehman subtree kernel and for the shortest-path kernel. The resultingnovel graph kernels are shown to be, both, able to handle graphs with continuous attributes and scalable to large graphs and data sets. This is supported by our theoretical analysis and demonstrated by an extensive experimental evaluation.",2016,International Conference on Data Mining,Fields of study: graph kernelgraph productmodular decompositionkernelimage analysistheoretical computer sciencediscrete mathematicsdata miningmachine learningcomputer sciencemathematics
Background Check: A General Technique to Build More Reliable and Versatile Classifiers,Miquel Perello-NietoTelmo de Menezes e Silva FilhoMeelis Kull (University of Bristol)Peter A. Flach (University of Bristol),"2585840810,2678185079,2588360585,1814273096","We introduce a powerful technique to make classifiers more reliable and versatile. Background Check equips classifiers with the ability to assess the difference of unlabelled test data from the training data. In particular, Background Check gives classifiers the capability to (i) perform cautious classification with a reject option, (ii) identify outliers, and (iii) better assess the confidence in their predictions. We derive the method from first principles and consider four particular relationships between background and foreground distributions. One of these assumes an affine relationship with two parameters, and we show how this bivariate parameter space naturally interpolates between the above capabilities. We demonstrate the versatility of the approach by comparing it experimentally with published special-purpose solutions for outlier detection and confident classification on 41 benchmark datasets. Results show that Background Check can match and in many cases surpass the performances of specialised approaches.",2016,International Conference on Data Mining,Fields of study: data modelingtraining setmulticlass classificationreliabilityestimationprobabilityanomaly detectiondata miningpattern recognitionmachine learningstatisticscomputer science
Mining Graphlet Counts in Online Social Networks,Xiaowei Chen (The Chinese University of Hong Kong)John C. S. Lui (The Chinese University of Hong Kong),"2233607739,2045404162","Counting subgraphs is a fundamental analysis task for online social networks (OSNs). Given the sheer size and restricted access of online social network data, efficient computation of subgraph counts is highly challenging. Although a number of algorithms have been proposed to estimate the relative counts of subgraphs in OSNs with restricted access, there are only few works which try to solve a more general problem, i.e., counting subgraph frequencies. In this paper, we propose an efficient random walk-based framework to estimate the subgraph counts. Our framework generates samples by leveraging consecutive steps of the random walk as well as by observing neighbors of visited nodes. Using the importance sampling technique, we derive unbiased estimators of the subgraph counts. To make better use of the degree information of visited nodes, we also design an improved estimator, which increases the efficiency of the estimate at no additional cost. We conduct extensive experimental evaluation on real-world OSNs to confirm our theoretical claims. The experiment results show that our estimators are unbiased, accurate, efficient and better than the state-of-the-art algorithm. For the Weibo graph with more than 58 million nodes, our method produces estimate of triangle count with an error less than 5% using only 20 thousands sampled nodes. Detailed comparison with the state-of-the-art method demonstrates that our algorithm is 4 to 5 times more accurate.",2016,International Conference on Data Mining,Fields of study: markov processalgorithm designcomputational modelmonte carlo methoddata miningmachine learningstatisticscomputer sciencemathematics
Graph Mining for Complex Data Analytics,Andre Petermann (Leipzig University)Martin Junghanns (Leipzig University)Stephan KemperKevin Gomez (Leipzig University)Niklas Teichmann (Leipzig University)Erhard Rahm (Leipzig University),"1977393309,2033289091,2584896354,2538001320,2534470754,2158742306","Complex data analytics that involve data mining often comprise not only a single algorithm but also further data processing steps, for example, to restrict the search space or to filter the result. We demonstrate graph mining with Gradoop, the first scalable system supporting declarative analytical programs composed from multiple graph operations. We use a business intelligence example including frequent subgraph mining to highlight the analytical capabilities enabled by such programs. The results can be visualized and, to show its ease of use, the program can be modified on visitors request. Gradoop is built on top of state-of-the-art big data technology and out-of-the-box horizontally scalable. Its source code is publicly available and designed for easy extensibility. We offer to the graph mining community, to apply Gradoop in large scale use cases and to contribute further algorithms.",2016,International Conference on Data Mining,Fields of study: molecule miningdata modelingalgorithm designconcept miningdata stream miningtext miningbusiness intelligencedata sciencedata miningdatabasemachine learningcomputer science
Gaussian Component Based Index for GMMs,Linfei Zhou (Ludwig Maximilian University of Munich)Bianca Wackersreuther (Ludwig Maximilian University of Munich)Frank Fiedler (University of Mainz)Claudia Plant (Florida State University)Christian Bohm (Ludwig Maximilian University of Munich),"2565336067,160997069,2531866330,2122910652,2486446532","Efficient similarity search for uncertain data is a challenging task in many modern data mining applications like image retrieval, speaker recognition and stock market analysis. A common way to model the uncertainty of data objects is using probability density functions in the form of Gaussian Mixture Models (GMMs), which have an ability to approximate arbitrary distribution. However, due to the possible unequal length of mixture models, the use of existing index techniques has serious problems for the objects modeled by GMMs. Either the techniques cannot handle GMMs or they have too many limitations. Hence, we propose a dynamic index structure, Gaussian Component based Index (GCI), for GMMs. GCI decomposes GMMs into the single, pairs, or n-lets of Gaussian components, stores these components into well studied index trees such as U-tree and Gauss-Tree, and refines the corresponding GMMs in a conservative but tight way. GCI supports both k-most-likely queries and probability threshold queries by means of Matching Probability. Extensive experimental evaluations of GCI demonstrate a considerable speed-up of similarity search on both synthetic and real-world data sets.",2016,International Conference on Data Mining,Fields of study: mixture modeldata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
"Predicting the Outcome of Startups: Less Failure, More Success",Amar Krishna (Northwestern University)Ankit Agrawal (Northwestern University)Alok N. Choudhary (Northwestern University),"2610727267,2160807299,2147783234","On an average 9 out of 10 startups fail(industry standard). Several reasons are responsible for the failure of a startup including bad management, lack of funds, etc. This work aims to create a predictive model for startups based on many key things involved at various stages in the life of a startup. It is highly desirable to increase the success rate of startups and not much work have been done to address the same. We propose a method to predict the outcome of a startups based on many key factors like seed funding amount, seed funding time, Series A funding, factors contributing to the success and failure of the company at every milestone. We can have created several models based on the data that we have carefully put together from various sources like Crunchbase, Tech Crunch, etc. Several data mining classification techniques were used on the preprocessed data along with various data mining optimizations and validations. We provide our analysis using techniques such as Random Forest, ADTrees, Bayesian Networks, and so on. We evaluate the correctness of our models based on factors like area under the ROC curve, precision and recall. We show that a startup can use our models to decide which factors they need to focus more on, in order to hit the success mark.",2016,International Conference on Data Mining,Fields of study: accuracy and precisiondata sciencedata miningstatisticscomputer sciencemathematics
Mining Effective Subsequences with Application in Marketing Attribution,Zi YinYing Li (IBM)Pietro MazzoleniYuanyuan Shen,"2585579244,2126240026,2649191484,2583948093","In this paper, we present a new data mining framework for discovering sequence effects. In particular, we focus on the sequences consisting of actions that are taken in chronological order, like sequences of clinical procedures or marketing actions. Each sequence is associated with a binary outcome, a success or a failure. We investigate the hypothesis that certain subsequences of actions contribute to successes, which we call effective subsequences. A generic data mining algorithm for extracting effective subsequences is proposed, which is verified both quantitatively and qualitatively. We experimented our effective subsequence mining algorithm on a real sales opportunity dataset. Based on the subsequence model, a market campaign attribution model is proposed, with application to the same sales dataset.",2016,International Conference on Data Mining,Fields of study: data modelingalgorithm designsoftware testingdata sciencebioinformaticsdata miningmachine learningcomputer science
Direct Mining of Subjectively Interesting Relational Patterns,Tias Guns (Katholieke Universiteit Leuven)Achille AkninJefrey Lijffijt (University of Bristol)Tijl De Bie (University of Bristol),"2087834039,2584090588,115479936,2080198120","Data is typically complex and relational. Therefore, the development of relational data mining methods is an increasingly active topic of research. Recent work has resulted in new formalisations of patterns in relational data and in a way to quantify their interestingness in a subjective manner, taking into account the data analyst's prior beliefs about the data. Yet, a scalable algorithm to find such most interesting patterns is lacking. We introduce a new algorithm based on two notions: (1) the use of Constraint Programming, which results in a notably shorter development time, faster runtimes, and more flexibility for extensions such as branch-and-bound search, and (2), the direct search for the most interesting patterns only, instead of exhaustive enumeration of patterns before ranking them. Through empirical evaluation, we find that our novel bounds yield speedups up to several orders of magnitude, especially on dense data with a simple schema. This makes it possible to mine the most subjectively-interesting relational patterns present in databases where this was previously impractical or impossible.",2016,International Conference on Data Mining,Fields of study: change data capturerelational databasealgorithm designprogrammingstatistical relational learningdata sciencedata miningdatabasemachine learningcomputer science
Prefix and Suffix Invariant Dynamic Time Warping,"Diego Furtado Silva (Spanish National Research Council)Gustavo E. A. P. A. Batista (University of São Paulo)Eamonn J. Keogh (University of California, Riverside)","2138204294,2165222361,2170070822","While there exist a plethora of classification algorithms for most data types, there is an increasing acceptance that the unique properties of time series mean that the combination of nearest neighbor classifiers and Dynamic Time Warping (DTW) is very competitive across a host of domains, from medicine to astronomy to environmental sensors. While there has been significant progress in improving the efficiency and effectiveness of DTW in recent years, in this work we demonstrate that an underappreciated issue can significantly degrade the accuracy of DTW in real-world deployments. This issue has probably escaped the attention of the very active time series research community because of its reliance on static highly contrived benchmark datasets, rather than real world dynamic datasets where the problem tends to manifest itself. In essence, the issue is that DTW's eponymous invariance to warping is only true for the main ""body"" of the two time series being compared. However, for the ""head"" and ""tail"" of the time series, the DTW algorithm affords no warping invariance. The effect of this is that tiny differences at the beginning or end of the time series (which may be either consequential or simply the result of poor ""cropping"") will tend to contribute disproportionally to the estimated similarity, producing incorrect classifications. In this work, we show that this effect is real, and reduces the performance of the algorithm. We further show that we can fix the issue with a subtle redesign of the DTW algorithm, and that we can learn an appropriate setting for the extra parameter we introduced. We further demonstrate that our generalization is amiable to all the optimizations that make DTW tractable for large datasets.",2016,International Conference on Data Mining,Fields of study: dynamic time warpingtimetime seriesstatistical classificationspeech recognitiondata miningmachine learningstatisticscomputer science
On Efficient External-Memory Triangle Listing,Yi CuiDi XiaoDmitri Loguinov (Texas A&M University),"2585262431,2584992047,314230453","Discovering triangles in large graphs is a well-studied area, however, both external-memory performance of existing methods and our understanding of the complexity involved leave much room for improvement. To shed light on this problem, we first generalize the existing in-memory algorithms into a single framework of 18 triangle-search techniques. We then develop a novel external-memory approach, which we call Pruned Companion Files (PCF), that supports operation of all 18 algorithms, while significantly reducing I/O compared to the common methods in this area. After finding the best node-traversal order, we build an implementation around it using SIMD instructions for list intersection and PCF for I/O. This method runs 5-10 times faster than the best available implementation and exhibits orders of magnitude less I/O. In one of our graphs, the program finds 1 trillion triangles in 237 seconds using a desktop CPU.",2016,International Conference on Data Mining,Fields of study: nickelredundancytaxonomytheoretical computer sciencedata miningmachine learningalgorithmcomputer science
Finding Large Matchings in Semi-Streaming,"Hossein Esfandiari (University of Maryland, College Park)MohammadTaghi Hajiaghayi (University of Maryland, College Park)Morteza Monemizadeh (Charles University in Prague)","2080182890,2312546782,2518461445","One of the most appealing open problems in the graph streaming area (see Problem 60 in [1]) is to close the gap between the approximation factor (i.e., lower bound) of 0:5 (achieved by a simple greedy algorithm) [2] and the hardness result (i.e., upper bound) of 1 1=e ' 0:63 [3], [4] for the classical problem of the maximum matching in the semistreaming model. Interestingly, for a long time closing this gap even using 2 passes over an adversarial stream was open until very recently that Konrad, Magniez, and Mathieu in [5] made progress toward answering this question.We develop a 0:583-approximation 2-pass streaming algorithm to find the maximum matching in bipartite graphs, using O(n) space. Using the same technique we give a 0:605-approximation 3-pass streaming algorithm to find the maximum matching in bipartite graphs, using O(n) space. Our results improve upon the 0:505-approximation 2-pass algorithm proposed in [5]. Our 3-pass algorithm is the first 3-pass streaming algorithm that achieves an approximation factor better than 0:6.In the first pass of our algorithm we find a maximal matching M. In the second pass, for every unmatched vertex we keep a small number of edges (so-called, golden edges) incident to distinct matched vertices in M. Every matched vertex of M is incident to at most one golden edge. At the end of second pass, we invoke an optimal matching algorithm on the union of matched and golden edges. For the analysis, let M be a maximum cardinality matching of G. We show that golden edges help to find a good fraction of augmenting paths of length 3 inM[M and also they build many new augmenting paths of length 3 using augmenting paths of length at least 5 and other alternating paths of M [ M. Our 3-pass algorithm simply repeats the process of the second pass.",2016,International Conference on Data Mining,Fields of study: hopcroft karp algorithm3 dimensional matchingblossom algorithmdata modelingbipartite graphmatchinggreedy algorithmcomputational modelapproximation algorithmdiscrete mathematicscombinatoricsmachine learningmathematical optimizationcomputer sciencemathematics
Spatio-Temporal Site Recommendation,Guolei YangAndreas Zufle (Ludwig Maximilian University of Munich),"2674606347,79808299","Recommendation systems have become extremely common in recent years, and are utilized in a variety of areas to predict the ""rating"" or ""preference"" that a user would give to a point of interest (PoI), such as a restaurant, a hotel, or a bar. Such systems typically produce a list of recommendations by considering previous ratings of the user, as well as ratings of other users. Not every person rates every point of interest they visit. In this work, we want to explore the use of spatio-temporal data to improve recommendation systems: We postulate that spatio-temporal user data may indicate the liking or disliking of a point of interest. Clearly, if a user frequently visits the same PoI, stays at the PoI for long times, and is willing to travel a long distance to visit a PoI, that might indicate that user likes that PoI. Thus, we propose to extract user-PoI relation features from spatio-temporal trajectory data only. Using these features, we use out-of-the-box data mining and machine learning solutions, to estimate the popularity of a PoI. Our experimental evaluation shows, that the features extracted from spatio-temporal data able to accurately predict the popularity of a PoI, using ground-truth data from FourSquare as a baseline.",2016,International Conference on Data Mining,Fields of study: world wide webdata miningcomputer science
Detection of Cyber-Physical Faults and Intrusions from Physical Correlations,Andrey Y. LokhovNathan Lemons (Los Alamos National Laboratory)Thomas C. McAndrewAric A. Hagberg (Los Alamos National Laboratory)Scott Backhaus (Los Alamos National Laboratory),"2628162971,2305480781,2514270791,1538394340,2176190026","Cyber-physical systems are critical infrastructures that are crucial both to the reliable delivery of resources such as energy, and to the stable functioning of automatic and control architectures. These systems are composed of interdependent physical, control and communications networks described by disparate mathematical models creating scientific challenges that go well beyond the modeling and analysis of the individual networks. A key challenge in cyber-physical defense is a fast online detection and localization of faults and intrusions without prior knowledge of the failure type. We describe a set of techniques for the efficient identification of faults from correlations in physical signals, assuming only a minimal amount of available system information. The performance of our detection method is illustrated on data collected from a large building automation system.",2016,International Conference on Data Mining,Fields of study: cyber physical systemcorrelationtime seriesmathematical modeltheoretical computer sciencecomputer securityartificial intelligencesimulationstatisticsengineeringmathematics
From Sets of Good Redescriptions to Good Sets of Redescriptions,Janis Kalofolias (Max Planck Society)Esther Galbrun (Boston University)Pauli Miettinen (Max Planck Society),"2585492630,2276244909,2015634213","Redescription mining aims at finding pairs of queries over data variables that describe roughly the same set of observations. These redescriptions can be used to obtain different views on the same set of entities. So far, redescription mining methods have aimed at listing all redescriptions supported by the data. Such an approach can result in many redundant redescriptions and hinder the user's ability to understand the overall characteristics of the data. In this work, we present an approach to find a good set of redescriptions, instead of finding a set of good redescriptions. That is, we present a way to remove the redundant redescriptions from a given set of redescriptions. We measure the redundancy using a framework inspired by the subjective interestingness based on maximum-entropy distributions as proposed by De Bie in 2011. Redescriptions, however, raise their unique requirements on the framework, and our solution differs significantly from the existing ones. Notably, our approach can handle disjunctions and conjunctions in the queries, whereas the existing approaches are limited only to conjunctive queries. The framework also reduces the redundancy in the redescription mining results, as we show in our empirical evaluation.",2016,International Conference on Data Mining,Fields of study: informaticsdata modelingentropycomputational modeltheoretical computer sciencedata miningdatabasecomputer science
Multi-label Learning with Emerging New Labels,Yue Zhu (Nanjing University)Kai Ming Ting (Monash University)Zhi-Hua Zhou (Nanjing University),"2152538905,2121496889,2286237009","Multi-label learning is widely applied in many tasks, where an object possesses multiple concepts with each represented by a class label. Previous studies on multi-label learning have focused on a fixed set of class labels, i.e., the class label set of test data is the same as that in the training set. In many applications, however, the environment is open and new concepts may emerge with previously unseen instances. In order to maintain good predictive performance in this environment, a multi-label learning method must have the ability to detect and classify those instances with emerging new labels. To this end, we propose a new approach called Multi-label learning with Emerging New Labels (MuENL). It builds models with three functions: classify instances on currently known labels, detect the emergence of a new label in new instances, and construct a new classifier for each new label that works collaboratively with the classifier for known labels. Our empirical evaluation shows the effectiveness of MuENL.",2016,International Conference on Data Mining,Fields of study: stabilitydata modelingcorrelationpredictive modellingrobustnessdetectordata miningpattern recognitionmachine learningcomputer science
Towards Visualizing Hidden Structures,Remy Dautriche (STMicroelectronics)Alexandre Termier (Centre national de la recherche scientifique)Renaud BlanchMiguel Santana (STMicroelectronics),"2230848647,99113242,2657466791,2298691976","There is an increasing need to quickly understand the contents log data. A wide range of patterns can be computed and provide valuable information: for example existence of repeated sequences of events or periodic behaviors. However patternminingtechniquesoftenproducemanypatternsthathave to be examined one by one, which is time consuming for experts. On the other hand, visualization techniques are easier to understand, but cannot provide the in-depth understanding provided by pattern mining approaches. Our contribution is to propose a novel visualanalytics methodthat allows toimmediately visualize hidden structures such as repeated sets/sequences and periodicity, allowing to quickly gain a deep understanding of the log.",2016,International Conference on Data Mining,Fields of study: visualizationdata visualizationdata sciencebioinformaticsdata miningcomputer science
Steady Patterns,Willy UgarteAlexandre Termier (Centre national de la recherche scientifique)Miguel Santana (STMicroelectronics),"2687342398,99113242,2298691976","Skypatterns are an elegant answer to the pattern explosion issue, when a set of measures can be provided. Skypatterns for all possible measure combinations can be explored thanks to recent work on the skypattern cube. However, this leads to too many skypatterns, where it is difficult to quickly identify which ones are more important. First, we introduce a new notion of pattern steadiness which measures the conservation of the skypattern property across the skypattern cube, allowing to see which are the ""most universal"" skypatterns. Then, we extended this notion to partitions of the dataset, and show in our experiments that this both allows to discover especially stable skypatterns, and identify interesting differences between the partitions.",2016,International Conference on Data Mining,Fields of study: robustnesslatticetheoretical computer sciencedata miningstatisticscomputer sciencemathematics
Correlation-Based Streaming Anomaly Detection in Cyber-Security,Jordan NobleNiall M. Adams (Imperial College London),"2584081453,2145214992","Methodology for statistical analysis of enterprise network data is becoming more important in cyber-security. The volume and velocity of enterprise network data sources puts a premium on streaming analytics - procedures that pass over the data once, while handling temporal variation in the process. In this paper we sketch SCAD: a procedure for streaming anomaly detection in the correlation between a pair of variables. This procedure is intended to detect anomalies on individual edges of the network graph. The approach is illustrated on real Netflow data, where novel ideas are introduced to assess performance on a single edge. The procedure is then successfully extended to combine and score anomalies across multiple edges.",2016,International Conference on Data Mining,Fields of study: data modelingcorrelationmaximum likelihooddata miningmachine learningstatisticscomputer sciencemathematics
Concept Based Short Text Stream Classification with Topic Drifting Detection,Peipei Li (Hefei University of Technology)Lu HeXuegang Hu (Hefei University of Technology)Yuhong Zhang (Hefei University of Technology)Lei Li (Macquarie University)Xindong Wu (Hefei University of Technology),"2291939811,2583952330,2167288354,2320430060,2688675929,2123651450","Short text stream classification is a challengingand significant task due to the characteristics of short length, weak signal, high velocity and especially topic drifting in short text stream. However, this challenge has received little attention from the research community. Motivated by this, we propose a new feature extension approach for short text stream classification using a large scale, general purpose semantic network obtained from a web corpus. Our approach is built on an incremental ensemble classification model. First, in terms of the open semantic network, we introduce more semantic contexts in short texts to make up of the data sparsity. Meanwhile, we disambiguate terms by their semantics to reduce the noise impact. Second, to effectively track hidden topic drifts, we propose a concept cluster based topic drifting detection method. Finally, extensive experiments demonstratethat our approach can detect topic drifts effectively compared to several well-known concept drifting detection methods in data streams. Meanwhile, our approach can perform best in the classification of text data streams compared to several stateof-the-art short text classification approaches.",2016,International Conference on Data Mining,Fields of study: cluster analysismathematical modeltaxonomysemanticsinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Sequential Ensemble Learning for Outlier Detection: A Bias-Variance Perspective,Shebuti Rayana (Stony Brook University)Wen ZhongLeman Akoglu (Stony Brook University),"1722036351,2569943631,2288278917","Ensemble methods for classification have been effectively used for decades, while for outlier detection it has only been studied recently. In this work, we design a new ensemble approach for outlier detection in multi-dimensional point data, which provides improved accuracy by reducing error through both bias and variance by considering outlier detection as a binary classification task with unobserved labels. In this paper, we propose a sequential ensemble approach called CARE that employs a two-phase aggregation of the intermediate results in each iteration to reach the final outcome. Unlike existing outlier ensembles, our ensemble incorporates both the parallel and sequential building blocks to reduce bias as well as variance by (i) successively eliminating outliers from the original dataset to build a better data model on which outlierness is estimated (sequentially), and (ii) combining the results from individual base detectors and across iterations (parallelly). Through extensive experiments on 16 real-world datasets mainly from the UCI machine learning repository [1], we show that CARE performs significantly better than or at least similar to the individual baselines as well as the existing state-of-the-art outlier ensembles.",2016,International Conference on Data Mining,Fields of study: bootstrap aggregatingdata modelingfeature extractiondetectordata miningpattern recognitionmachine learningstatisticscomputer science
Service Usage Analysis in Mobile Messaging Apps: A Multi-label Multi-view Perspective,Yanjie Fu (Rutgers University)Junming Liu (Rutgers–Newark)Xiaolin Li (Nanjing University)Xinjiang Lu (Northwestern Polytechnical University)Jingci MingChu Guan (University of Science and Technology of China)Hui Xiong (Rutgers–Newark),"2168873515,2226988312,2682482835,2105521496,2583628330,2644629888,2153710278","The service usage analysis, aiming at identifying customers' messaging behaviors based on encrypted App traffic flows, has become a challenging and emergent task for service providers. Prior literature usually starts from segmenting a traffic sequence into single-usage subsequences, and then classify the subsequences into different usage types. However, they could suffer from inaccurate traffic segmentations and mixed-usage subsequences. To address this challenge, we exploit a multi-label multi-view learning strategy and develop an enhanced frame-work for in-App usage analytics. Specifically, we first devise an enhanced traffic segmentation method to reduce mixed-usage sub-sequences. Besides, we develop a multi-label multi-view logistic classification method, which comprises two alignments. The first alignment is to make use of the classification consistency between packet-length view and time-delay view of traffic subsequences and improve classification accuracy. The second alignment is to combine the classification of single-usage subsequence and the post-classification of mixed-usage subsequences into a unified multi-label logistic classification problem. Finally, we present extensive experiments with real-world datasets to demonstrate the effectiveness of our approach.",2016,International Conference on Data Mining,Fields of study: logisticsmobile telephonythe internetdata collectionfeature extractioncluster analysisworld wide webdata miningdatabasemachine learningcomputer science
POI Recommendation: A Temporal Matching between POI Popularity and User Regularity,Zijun Yao (Rutgers–Newark)Yanjie Fu (Rutgers University)Bin Liu (Rutgers University)Yanchi Liu (University of Science and Technology Beijing)Hui Xiong (Rutgers–Newark),"2229271911,2168873515,2428181972,2159798580,2153710278","Point of interest (POI) recommendation, which provides personalized recommendation of places to mobile users, is an important task in location-based social networks (LBSNs). However, quite different from traditional interest-oriented merchandise recommendation, POI recommendation is more complex due to the timing effects: we need to examine whether the POI fits a user's availability. While there are some prior studies which included the temporal effect into POI recommendations, they overlooked the compatibility between time-varying popularity of POIs and regular availability of users, which we believe has a non-negligible impact on user decision-making. To this end, in this paper, we present a novel method which incorporates the degree of temporal matching between users and POIs into personalized POI recommendations. Specifically, we first profile the temporal popularity of POIs to show when a POI is popular for visit by mining the spatio-temporal human mobility and POI category data. Secondly, we propose latent user regularities to characterize when a user is regularly available for exploring POIs, which is learned with a user-POI temporal matching function. Finally, results of extensive experiments with real-world POI check-in and human mobility data demonstrate that our proposed user-POI temporal matching method delivers substantial advantages over baseline models for POI recommendation tasks.",2016,International Conference on Data Mining,Fields of study: pattern matchingmobile telephonymobile computinginternet privacyworld wide webcomputer science
Scalable and Distributed Sea Port Operational Areas Estimation from AIS Data,Leonardo M. Millefiori (NATO)Dimitrios Zissis (NATO)Luca Cazzanti (University of Washington)Gianfranco Arcieri (NATO),"2222069441,2584572628,2023344625,2007534792","Seaports are spatial units that do not remain static over time. They are constantly in flux, evolving according to environmental and connectivity patterns both in size and operational capacity. As such any valid decision making regarding port investment and policy making, essentially needs to take into account port evolution over time and space, thus, accurately defining a seaport's exact location, operational boundaries, capacity, connectivity indicators, environmental impact and overall throughput. In this work, we apply a data driven approach to defining a seaport's extended area of operation based on data collected though the Automatic Identification System (AIS). Specifically, we present our adaptation of the well-known KDE algorithm to the MapReduce paradigm, and report results on the port of Rotterdam.",2016,International Conference on Data Mining,Fields of study: operations researchdata miningartificial intelligencecomputer science
Query-Based Evolutionary Graph Cuboid Outlier Detection,"Ayushi Dalmia (International Institute of Information Technology, Hyderabad)Manish Gupta (Microsoft)Vasudeva Varma (International Institute of Information Technology, Hyderabad)","2021021613,2664163432,2146554912","Graph-OLAP is an online analytical framework which allows us to obtain various projections of a graph, each of which helps us view the graph along multiple dimensions and multiple levels. Given a series of snapshots of a temporal heterogeneous graph, we aim to find interesting projections of the graph which have anomalous evolutionary behavior. Detecting anomalous projections in a series of such snapshots can be helpful for an analyst to understand the regions of interest from the temporal graph. Identifying such semantically related regions in the graph allows the analyst to derive insights from temporal graphs which enables her in making decisions. While most of the work on temporal outlier detection is performed on nodes, subgraphs and communities, we are the first to propose detection of evolutionary graph cuboid outliers. Further, we perform this detection in a query sensitive manner. Thus, an evolutionary graph cuboid outlier is a projection (or cuboid) of a snapshot of the temporal graph such that it contains an unexpected number of matches for the query with respect to other cuboids both in the same snapshot as well as in the other snapshots. Identifying such outliers is challenging because (1) the number of cuboids per snapshot could be large, and (2) number of snapshots could itself be large. We model the problem by predicting the outlier score for each cuboid in each snapshot. We propose to build subspace ensemble regression models to learn (a) the behavior of a cuboid across different snapshots, and (b) the behavior of all the cuboids in a given snapshot. Experimental results on both synthetic and real datasets show the effectiveness of the proposed algorithm in discovering evolutionary graph cuboid outliers.",2016,International Conference on Data Mining,Fields of study: intersection graphorganizationpredictive modellinglatticesemanticsdata miningpattern recognitionmachine learningcomputer sciencemathematics
Probabilistic-Mismatch Anomaly Detection: Do One’s Medications Match with the Diagnoses,Lingxiao Zhang (Peking University)Xiang Li (IBM)Haifeng Liu (IBM)Jing Mei (IBM)Gang HuJunfeng Zhao (Peking University)Yanzhen Zou (Peking University)Bing Xie (Peking University)Guotong Xie (IBM),"2231988080,2304760860,2281948475,2132541161,2697040662,2130574673,2166382162,2125625937,2095693315","Anomaly detection in healthcare data like patient records is no trivial task. The anomalies in these datasets are often caused by mismatches between different types of feature, e.g., medications that do not match with the diagnoses. Existing anomaly detection methods do not perform well when detecting ""mismatches"" between multiple types of feature, especially when the feature space is high-dimensional and sparse. This paper introduces a novel anomaly detection paradigm: Probabilistic-Mismatch Anomaly Detection (PMAD), which detects mismatches between features by modeling a normal instance with a common latent probability distribution that governs the generation of all types of feature. Under this paradigm, the target of anomaly detection is to find instances with dissimilar latent distributions. We further propose Topical PMAD based on an extended Latent Dirichlet Allocation (LDA) model, which is able to capture the latent relationship between features in a high-dimensional space. Experiments on both synthetic data and real-world patient records show that Topical PMAD can effectively detect anomalies with mismatched features, and is highly robust against high-dimensional data as well as inaccurate model selection. The real-world anomalies detected on a patient record dataset show a promising application prospect.",2016,International Conference on Data Mining,Fields of study: data modelingcontext modelsolid modelingfeature extractiondata miningpattern recognitionmachine learningcomputer science
Compressing Random Forests,Amichai Painsky (Tel Aviv University)Saharon Rosset (Tel Aviv University),"2185567478,2129867074","Ensemble methods are considered among the state-of-the-art predictive modeling approaches. Applied to modern big data, these methods often require a large number of sub-learners, where the complexity of each learner typically grows with the size of the dataset. This phenomenon results in an increasing demand for storage space, which may be very costly. This problem mostly manifests in a subscriber based environment, where a user-specific ensemble needs to be stored on a personal device with strict storage limitations (such as a cellular device). In this work we introduce a novel method for lossless compression of tree-based ensemble methods, focusing on Random Forests. Our suggested method is based on probabilistic modeling of the ensemble's trees, followed by model clustering via Bregman divergence. This allows us to find a minimal set of models that provides an accurate description of the trees, and at the same time is small enough to store and maintain. Our compression scheme demonstrates high compression rates on a variety of modern datasets. Importantly, our scheme enables predictions from the compressed format and a perfect reconstruction of the original ensemble.",2016,International Conference on Data Mining,Fields of study: vegetationprobabilistic logicencodingprobability distributionmathematical modelensemble learningtheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Spell: Streaming Parsing of System Event Logs,Min Du (University of Utah)Feifei Li (University of Utah),"2307715693,2472728339","System event logs have been frequently used as a valuable resource in data-driven approaches to enhance system health and stability. A typical procedure in system log analytics is to first parse unstructured logs, and then apply data analysis on the resulting structured data. Previous work on parsing system event logs focused on offline, batch processing of raw log files. But increasingly, applications demand online monitoring and processing. We propose an online streaming method Spell, which utilizes a longest common subsequence based approach, to parse system event logs. We show how to dynamically extract log patterns from incoming logs and how to maintain a set of discovered message types in streaming fashion. Evaluation results on large real system logs demonstrate that even compared with the offline alternatives, Spell shows its superiority in terms of both efficiency and effectiveness.",2016,International Conference on Data Mining,Fields of study: von neumann stability analysisdata analysisworld wide webdata miningdatabasecomputer sciencemathematics
Cognito: Automated Feature Engineering for Supervised Learning,"Udayan Khurana (University of Maryland, College Park)Deepak S. Turaga (IBM)Horst Samulowitz (IBM)Srinivasan Parthasrathy","1634039761,2303897886,1209940156,2584312586","Feature engineering involves constructing novel features from given data with the goal of improving predictive learning performance. Feature engineering is predominantly a human-intensive and time consuming step that is central to the data science workflow. In this paper, we present a novel system called ""Cognito"", that performs automatic feature engineering on a given dataset for supervised learning. The system explores various feature construction choices in a hierarchical and non-exhaustive manner, while progressively maximizing the accuracy of the model through a greedy exploration strategy. Additionally, the system allows users to specify domain or data specific choices to prioritize the exploration. Cognito is capable of handling large datasets through sampling and built-in parallelism, and integrates well with a state-of-the-art model selection strategy. We present the design and operation of Cognito, along with experimental results on eight real datasets to demonstrate its efficacy.",2016,International Conference on Data Mining,Fields of study: data modelingatmospheric modelpredictive modellingsupervised learningdata sciencedata miningmachine learningcomputer science
Ensemble of Heterogeneous Classifiers for Improving Automated Tweet Classification,Renhao Cui (Ohio State University)Gagan Agrawal (Ohio State University)Rajiv Ramnath (Ohio State University)Vinh Ngoc Khuc (Ohio State University),"2409605315,2154982890,2041942109,2231252625","Twitter is widely used by businesses to communicate with and obtain feedback from their customers, almost in real time. Automated analysis is necessary to deal with the large volumes of tweets in a timely manner, and an insightful classification is a first step in this analysis. This paper presents an ensemble method that combines classifier outputs by including the individual probability distributions with an additional learning layer, as opposed to an arithmetic combination of weighted probabilities. Besides using probabilities generated by individual classifiers, we also show that the use of tweet vectors helps with the ensemble learning step. In addition, we have described a mapping method to employ a cloud taxonomy service as an additional classifier. We include LLDA, Naive Bayes, and the cloud taxonomy service for the ensemble method, and have applied our methods on a real industry tweet dataset. The proposed ensemble model is able to outperform several widely used probability based ensemble methods, i.e., Weighted Sum and Product of Experts (PoE). The ensemble model is also more adaptive than previous models in handling the variations in the probability distributions output from the individual classifiers. In addition to the algorithms used and the improved results, this paper's contribution is in insights from the application of models on a unique, real dataset.",2016,International Conference on Data Mining,Fields of study: random subspace methoddata modelingprobabilistic logiccomputational modelprobability distributionensemble learningtaxonomydata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Inferring Variable Labels Considering Co-occurrence of Variable Labels in Data Jackets,Teruaki Hayashi (University of Tokyo),2154577981,"Data Jacket (DJ) is a technique for sharing information about data and for considering the potential value of datasets, allowing data itself hidden, by describing the summary of data in natural language. In DJs, variables in datasets are described as variable labels (VLs), which is the name/meaning of variables. In the context of data utilization and exchange, the utility of data can be discussed upon the VLs to consider the combination of data stored in different domains. However, due to the lack of VLs in some DJs, DJs essentially related to each other cannot be formed to have linkage through string matching of VLs, which makes it difficult to think of feasible plans of data analyses and combinations. In this paper, we propose a method for inferring VLs in DJs whose VLs are missing or unknown, using the content of the outlines of DJs written in free texts. Specifically, we focus on the co-occurrence of VLs in DJs. The co-occurrence of VLs is a feature that there may be a highly frequent pair of VLs appearing at the same time, e.g., ""year"" and ""day"", or ""name"" and ""gender"". By focusing on the co-occurrence of VLs and the similarity of the outlines of data in training data of DJs, we demonstrate that our proposed method works significantly better than the method introducing only the similarity of outlines of datasets.",2016,International Conference on Data Mining,Fields of study: stakeholdertraining setinformation privacydata scienceworld wide webdata miningmachine learningstatisticscomputer science
Topic Extraction Method from Millions of Tweets Based on Fast Feature Selection Technique CWC,"Takako Hashimoto (Chiba University of Commerce)Dave Shepard (University of California, Los Angeles)Tetsuji Kuboyama (Gakushuin University)Kilho Shin (University of Tokyo)","2159281985,2223292679,2022906189,2591283321","Social media offers a wealth of insight into how significant topics such as the Great East Japan Earthquake, the Arab Spring, and the Boston Bombing affect individuals. The scale of available data, however, can be intimidating: during the Great East Japan Earthquake, over 8 million tweets were sent each day from Japan alone. Conventional word vector-based topic-detection techniques for social media that use Latent Semantic Analysis, Latent Dirichlet Allocation, or graph community detection often cannot scale to such a large volume of data due to their space and time complexity. To alleviate this problem, we have already proposed an efficient method for topic extraction by leveraging our original fast feature selection algorithm, CWC, which vastly reduces the number of features to track. While we begin with word count vectors of authors and words for each time slot (in our case, every 30 minutes), we make clusters from each time slot by a matrix decomposition technique to identify clusters and adapt CWC to extract discriminative words from each cluster. This method makes it possible to detect topics from high dimensional datasets. In this paper, to demonstrate our method's effectiveness, we extract topics from a dataset of over two hundred million tweets sent following the Great East Japan Earthquake and compare them with the result extracted by LDA, the current most popular topic extraction method. With CWC, we can identify topics from this dataset with great speed and accuracy.",2016,International Conference on Data Mining,Fields of study: matrix decompositionfeature extractiontime seriesdata scienceworld wide webdata miningmachine learningstatisticscomputer sciencemathematics
Similarity Tree Pruning: A Novel Dynamic Ensemble Selection Approach,Anil Narassiguin (Centre national de la recherche scientifique)Haytham Elghazel (University of Lyon)Alex Aussem (University of Lyon),"2398051742,2291370321,1210402752","Dynamic ensemble selection (or dynamic pruning) is a learning paradigm that reduces the size of an ensemble of classifiers for each test pattern as input. The purpose of this approach is to improve the performances of the ensemble method by eliminating dynamically all the weak learners for a specific input. As of now, most of the dynamic pruning methods use information about the validation data and intermediate performances of the ensemble's classifiers on it, but none of them take the advantage of the intrinsic information given by those classifiers. In this paper we propose a new dynamic ensemble selection framework based on a tree internal supervised measure. This implies that our approach works on homogeneous ensemble methods with trees as base learners. This approach is motivated by the fact that in high dimensional datasets, usual metrics like euclidean distance suffer from the curse of dimensionality. Moreover, a similarity measure based on decision tree structure can be considered as supervised, which is well suited for supervised learning. Our framework is called ST-DES for Similarity Tree Dynamic Ensemble Selection. In this work, we use one of the best ensemble algorithm, Random Forest, as the base ensemble generator. We then compare the performance in terms of accuracy of ST-DES against the best known approaches in literature on different UCI datasets. We show that our approach outperforms the existing ones especially for high dimensional datasets. Besides, we show that this approach is not disturbed by random noise in features.",2016,International Conference on Data Mining,Fields of study: vegetationradio frequencydecision treepredictionensemble learningdata miningpattern recognitionmachine learningstatisticscomputer science
DESQ: Frequent Sequence Mining with Subsequence Constraints,Kaustubh Beedkar (Max Planck Society)Rainer Gemulla (Max Planck Society),"1259768269,344318172","Frequent sequence mining methods often make use of constraints to control which subsequences should be mined, e.g., length, gap, span, regular-expression, and hierarchy constraints. We show that many subsequence constraints—including and beyond those considered in the literature—can be unified in a single framework. In more detail, we propose a set of simple and intuitive ""pattern expressions"" to describe subsequence constraints and explore algorithms for efficiently mining frequent subsequences under such general constraints. A unified treatment allows researchers to study jointly many types of subsequence constraints (instead of each one individually) and helps to improve usability of pattern mining systems for practitioners.",2016,International Conference on Data Mining,Fields of study: usabilitycomputational modelbioinformaticsdata miningdatabasecomputer science
Budgeted Batch Bayesian Optimization,Vu Nguyen (Deakin University)Santu Rana (Deakin University)Sunil Kumar Gupta 0001 (Deakin University)Cheng Li (Deakin University)Svetha Venkatesh (Deakin University),"2097300135,2142238370,2119406083,2307881337,2146461601","Parameter settings profoundly impact the performance of machine learning algorithms and laboratory experiments. The classical trial-error methods are exponentially expensive in large parameter spaces, and Bayesian optimization (BO) offers an elegant alternative for global optimization of black box functions. In situations where the functions can be evaluated at multiple points simultaneously, batch Bayesian optimization is used. Current batch BO approaches are restrictive in fixing the number of evaluations per batch, and this can be wasteful when the number of specified evaluations is larger than the number of real maxima in the underlying acquisition function. We present the budgeted batch Bayesian optimization (B3O) for hyper-parameter tuning and experimental design - we identify the appropriate batch size for each iteration in an elegant way. In particular, we use the infinite Gaussian mixture model (IGMM) for automatically identifying the number of peaks in the underlying acquisition functions. We solve the intractability of estimating the IGMM directly from the acquisition function by formulating the batch generalized slice sampling to efficiently draw samples from the acquisition function. We perform extensive experiments for benchmark functions and two real world applications - machine learning hyper-parameter tuning and experimental design for alloy hardening. We show empirically that the proposed B3O outperforms the existing fixed batch BO approaches in finding the optimum whilst requiring a fewer number of evaluations, thus saving cost and time.",2016,International Conference on Data Mining,Fields of study: mixture modeldata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Feature Selection in Environments with Limited Voluntary Information Sharing,"Nicholay TopinKaran K. Budhraja (University of Maryland, Baltimore)Tim Oates (University of Maryland, Baltimore County)","2682520556,1516424914,2217452330","Feature selection is a form of both data reduction and attribute prioritization. It is modeled in existing work as a game between agents (buyers and sellers of information) in a corporate environment where information is accessible at a price. However, the interactions are typically moderated by a trusted third-party agent. Extending that work, we observe behavior in an unmoderated environment, integrated with information sharing. Existing models of information sharing among agents enforce an obligation to provide information upon request. For a corporate setting (such as an e-marketplace), this mandate is not necessarily true, and is introduced in this work as an incentive-based provision. To further incorporate real-world settings, information sharing happens only by request. Our work explores agent behaviors in this environment and the ability of sellers to gain utility. In an environment consisting of non-malicious agents, incentive-based information sharing removes the requirement to explicitly model reputation. It also allows agents to keep certain information private. Evaluation of different levels of incentive produces varied behavior across sellers.",2016,International Conference on Data Mining,Fields of study: group information managementgamesinformation exchangeorganizationcomputational modelmathematical modelinformation managementknowledge managementdata miningstatisticscomputer science
SOAL: Second-Order Online Active Learning,"Shuji Hao (Nanyang Technological University)Peilin Zhao (Agency for Science, Technology and Research)Jing Lu (Singapore Management University)Steven C. H. Hoi (Singapore Management University)Chunyan Miao (Nanyang Technological University)Chi Zhang","2223900961,2096910461,2668328581,108406206,2154137932,2645693360","This paper investigates the problem of online active learning for training classification models from sequentially arriving data. This is more challenging than conventional online learning tasks since the learner not only needs to figure out how to effectively update the classifier but also needs to decide when is the best time to query the label of an incoming instance given limited label budget. The existing online active learning approaches are often based on first-order online learning methods which generally fall short in slow convergence rate and sub-optimal exploitation of available information when querying the labeled data. To overcome the limitations, in this paper, we present a new framework of Second-order Online Active Learning (SOAL), which fully exploits both first-order and second-order information to achieve high learning accuracy with low labeling cost. We conduct both theoretical analysis and empirical studies for evaluating the proposed SOAL algorithm extensively. The encouraging results show clear advantages of the proposed algorithm over a family of state-of-the-art online active learning algorithms.",2016,International Conference on Data Mining,Fields of study: online machine learningstabilitywake sleep algorithminductive transfermulti task learningrobot learningsynchronous learningactive learninggeneralization errorlabeling theoryalgorithm designcomputational modelmathematical modelerror driven learningactive learningalgorithmic learning theoryproactive learninglearning classifier systemsemi supervised learningcomputational learning theoryinstance based learningunsupervised learningdata miningartificial intelligencemachine learningcomputer science
Efficient Rectangular Maximal-Volume Algorithm for Rating Elicitation in Collaborative Filtering,Alexander FonarevAlexander MikhalevPavel Serdyukov (Yandex)Gleb Gusev (Yandex)Ivan V. Oseledets (Russian Academy of Sciences),"2534129380,2648309305,2130450538,2005728791,691356644","Cold start problem in Collaborative Filtering can be solved by asking new users to rate a small seed set of representative items or by asking representative users to rate a new item. The question is how to build a seed set that can give enough preference information for making good recommendations. One of the most successful approaches, called Representative Based Matrix Factorization, is based on Maxvol algorithm. Unfortunately, this approach has one important limitation — a seed set of a particular size requires a rating matrix factorization of fixed rank that should coincide with that size. This is not necessarily optimal in the general case. In the current paper, we introduce a fast algorithm for an analytical generalization of this approach that we call Rectangular Maxvol. It allows the rank of factorization to be lower than the required size of the seed set. Moreover, the paper includes the theoretical analysis of the method's error, the complexity analysis of the existing methods and the comparison to the state-of-the-art approaches.",2016,International Conference on Data Mining,Fields of study: collaborationmatrix decompositionfilterpredictionalgorithm designmathematical modeldata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Correlating Social Interconnections of Users with Spatio-Temporal Check-Ins Behavior,Sonia Khetarpaul (Indian Institute of Technology Delhi)S. K. Gupta (Indian Institute of Technology Delhi)L. Venkata Subramaniam (IBM),"18872161,2128855107,2110721182","Acquiring the knowledge about the relationship among friendship network properties and check-in behavior of users (connected in the friendship network) has several benefits such as planning advertising strategies and recommending the friends or places. This paper aims to find the impact of structural patterns hidden in the nodes of a friendship network and external environment changes in the check-in patterns of the users. First, we categorize each spatial check-in event based on its cause into either self reinforcing behavior or social influence or external effect. Then, we explore how network and spatial properties and external factors affect the number of check-ins and influences. Using check-ins data from four major cities/states and its users' friendship graph, we show how network and spatial properties like centrality, network neighborhood overlap, spatial check-ins overlap, strong ties effects the check-ins and influential behavior of individuals.",2016,International Conference on Data Mining,Fields of study: weighted networknickelcorrelationmathematics
Sublinear Dual Coordinate Ascent for Regularized Loss Minimization,Liu Liu (Information Technology University)Dacheng Tao (University of Sydney),"2555699466,2104129307","We present a sublinear version of the dual coordinate ascent method for solving a group of regularized loss minimization problems in machine learning. The proposed method seamlessly integrates sampling techniques, the dual coordinate ascent method, and a multiplicative update algorithm. The sampling techniques choose the ""expected"" examples, and estimate the corresponding inner products. The dual coordinate ascent method generates an updated iterative step, which outperforms the time-learning step used in the previous sublinear perceptron algorithm. The multiplicative update algorithm updates the example weighting. The proposed method is implemented with an iterative step of order O(log(n)), where n is the size of examples, and achieves a better result than other methods, with high probability. We present a theoretical analysis of the sublinear iterative in order to justify its benefits. We then apply the proposed optimization method to support vector machine and conduct experiments on three large-scale datasets. Our experimental results validate our theoretical findings.",2016,International Conference on Data Mining,Fields of study: algorithm designdata miningmachine learningmathematical optimizationstatisticsalgorithmcomputer sciencemathematics
Multi-resolution Spatial Event Forecasting in Social Media,"Liang Zhao (Virginia Tech)Feng Chen (University at Albany, SUNY)Chang-Tien Lu (Virginia Tech)Naren Ramakrishnan (Virginia Tech)","2619584304,2601749234,2112878203,2199255697","Social media has become a significant surrogate forspatial event forecasting. The accuracy and discernibility of aspatial event forecasting model are two key concerns, whichrespectively determine how accurate and how detailed themodel's predictions could be. Existing work pays most attentionon the accuracy alone, seldom considering the accuracyand discernibility simultaneously, because this would requiresa considerably more sophisticated model while still sufferingfrom several challenges: 1) the precise formulation of thetrade-off between accuracy and discernibility, 2) the scarcityof social media data with a high spatial resolution, and 3)the characterization of spatial correlation and heterogeneity. This paper proposes a novel feature learning model thatconcurrently addresses all the above challenges by formulatingprediction tasks for different locations with different spatialresolutions, allowing the heterogeneous relationships amongthe tasks to be characterized. This characterization is thenintegrated into our new model based on multitask learning, whose parameters are optimized by our proposed algorithmbased on the Alternative Direction Method of Multipliers(ADMM). Extensive experimental evaluations on 11 datasetsfrom different domains demonstrated the effectiveness of ourproposed approach.",2016,International Conference on Data Mining,Fields of study: sensorpredictive modellingforecastingimage resolutioneconometricsdata miningmachine learningsimulationstatisticscomputer science
To be or Not to be Friends: Exploiting Social Ties for Venture Investments,Hao Zhong (Rutgers University)Chuanren Liu (Drexel University)Xinjiang Lu (Northwestern Polytechnical University)Hui Xiong (Rutgers–Newark),"2523559495,2169554947,2105521496,2153710278","Recent years have witnessed the boom of venture capital industry. Venture capitalists can attain great financial rewards if their invested companies exit successfully, via being acquired or going IPO (Initial Public Offering). The literature has revealed that, from both financial and managerial perspectives, decision-making process and successful rates of venture capital (VC) investments can be greatly improved if the investors well know the team members of target startups. However, much less efforts have been made on understanding the impact of prominent social ties between the members of VC firms and start-up companies on investment decisions. To this end, we propose to study such social relationship and see how this information can contribute to foreseeing investment deals. We aim at providing analytical guidance for the venture capitalists in choosing right investment targets. Specifically, we develop a Social-Adjusted Probabilistic Matrix Factorization (PMF) model to exploit members social connections information from VC firms and startups for investment recommendations. Unlike previous studies, we make use of the directed relationship between any pair of connected members from the two institutions respectively and quantify the variety of social network groups. As a result, it brings in much more flexibility, and the modeling results inherently provide meaningful managerial implications for the operators of VC firms and startups. Finally, we evaluate our model on both synthetic and real-world data. The results demonstrate that our approach outperforms the baseline algorithms with a significant margin.",2016,International Conference on Data Mining,Fields of study: social venture capitalventure capitalinvestment
A Graph-Based Approach to Spatiotemporal Event Sequence Mining,Berkay Aydin (Georgia State University)Rafal A. Angryk (Georgia State University),"2155808976,586699529","Sequential pattern mining from spatiotemporal data has received much attention in recent years due to its broad application domains such as targeted advertising, location prediction for taxi services, and urban planning. The characteristics of spatiotemporal sequences vary widely depending on the discovered knowledge type. Most of the recent approaches focus on the point-based spatiotemporal data presumably because of its greater availability. However, the region-based spatiotemporal data, primarily obtained from scientific resources, has not received much attention. In this work, we introduce an algorithm for mining spatiotemporal event sequences (STESs) from trajectory-based event instances. We consider each instance to be associated with an event type. We propose a graph-based mining algorithm, which transforms the sequences of spatiotemporal trajectories into a directed acyclic graph, and discovers the frequently occurring sequences of event types. Our proposed algorithm adopts a pattern-growth based approach utilizing the directed edges from the graph and discovers the event sequences without expensive candidate generation steps.",2016,International Conference on Data Mining,Fields of study: trajectorydata sciencedata miningmachine learning
Designing Sketches for Similarity Filtering,Vladimir Mic (Masaryk University)David Novak (Masaryk University)Pavel Zezula (Masaryk University),"2340521400,2312116117,683790044","The amounts of currently produced data emphasize the importance of techniques for efficient data processing. Searching big data collections according to similarity of data well corresponds to human perception. This paper is focused on similarity search using the concept of sketches – a compact bit string representations of data objects compared by Hamming distance, which can be used for filtering big datasets. The object-to-sketch transformation is a form of the dimensionality reduction and thus there are two basic contradictory requirements: (1) The length of the sketches should be small for efficient manipulation, but (2) longer sketches retain more information about the data objects. First, we study various sketching methods for data modeled by metric space and we analyse their quality. Specifically, we study importance of several sketch properties for similarity search and we propose a high quality sketching technique. Further, we focus on the length of sketches by studying mutual influence of sketch properties such as correlation of their bits and the intrinsic dimensionality of a set of sketches. The outcome is an equation that allows us to estimate a suitable length of sketches for an arbitrary given dataset. Finally, we empirically verify proposed approach on two real-life datasets.",2016,International Conference on Data Mining,Fields of study: hamming distancecorrelationtheoretical computer sciencedata miningmachine learningcomputer sciencemathematics
Regularized Large Margin Distance Metric Learning,Ya Li (University of Science and Technology of China)Xinmei Tian (University of Science and Technology of China)Dacheng Tao (University of Sydney),"2467377790,2133558835,2104129307","Distance metric learning plays an important role in many applications, such as classification and clustering. In this paper, we propose a novel distance metric learning using two hinge losses in the objective function. One is the constraint of the pairs which makes the similar pairs (the same label) closer and the dissimilar (different labels) pairs separated as far as possible. The other one is the constraint of the triplets which makes the largest distance between pairs intra the class larger than the smallest distance between pairs inter the classes. Previous works only consider one of the two kinds of constraints. Additionally, different from the triplets used in previous works, we just need a small amount of such special triplets. This improves the efficiency of our proposed method. Consider the situation in which we might not have enough labeled samples, we extend the proposed distance metric learning into a semi-supervised learning framework. Experiments are conducted on several landmark datasets and the results demonstrate the effectiveness of our proposed method.",2016,International Conference on Data Mining,Fields of study: jaro winkler distanceintrinsic metricdistanceeuclidean distanceprincipal component analysislinear programmingpattern recognitionmachine learningmathematical optimizationmathematics
Topic Discovery for Short Texts Using Word Embeddings,Guangxu Xun (University at Buffalo)Vishrawas GopalakrishnanFenglong Ma (University at Buffalo)Yaliang Li (University at Buffalo)Jing Gao (University at Buffalo)Aidong Zhang (University at Buffalo),"2223419831,2643663569,2227076362,2116094297,2096731881,2228514421","Discovering topics in short texts, such as news titles and tweets, has become an important task for many content analysis applications. However, due to the lack of rich context information in short texts, the performance of conventional topic models on short texts is usually unsatisfying. In this paper, we propose a novel topic model for short text corpus using word embeddings. Continuous space word embeddings, which is proven effective at capturing regularities in language, is incorporated into our model to provide additional semantics. Thus we model each short document as a Gaussian topic over word embeddings in the vector space. In addition, considering that background words in a short text are usually not semantically related, we introduce a discrete background mode over word types to complement the continuous Gaussian topics. We evaluate our model on news titles from data sources like abcnews, showing that our model is able to extract more coherent topics from short texts compared with the baseline methods and learn better topic representation for each short document.",2016,International Conference on Data Mining,Fields of study: encyclopediathe internetnormal distributionelectronic publishingsemanticsnatural language processingspeech recognitioninformation retrievalstatisticscomputer science
Triply Stochastic Variational Inference for Non-linear Beta Process Factor Analysis,Kai Fan (Duke University)Yizhe Zhang (Duke University)Ricardo Henao (Duke University)Katherine A. Heller (Duke University),"2420008042,2515564654,2099325229,2158760032","We propose a non-linear extension to factor analysis with beta process priors for improved data representation ability. This non-linear Beta Process Factor Analysis (nBPFA) allows data to be represented as a non-linear transformation of a standard sparse factor decomposition. We develop a scalable variational inference framework, which builds upon the ideas of the variational auto-encoder, by allowing latent variables of the model to be sparse. Our framework can be readily used for real-valued, binary and count data. We show theoretically and with experiments that our training scheme, with additive or multiplicative noise on observations, improves performance and prevents overfitting. We benchmark our algorithms on image, text and collaborative filtering datasets. We demonstrate faster convergence rates and competitive performance compared to standard gradient-based approaches.",2016,International Conference on Data Mining,Fields of study: normal distributionconvergencecomputational modelstochastic processeconometricsdata miningmachine learningstatisticsmathematics
Lexicon Knowledge Extraction with Sentiment Polarity Computation,"Zhaoxia Wang (Agency for Science, Technology and Research)Victor Joo Chuan TongPingcheng RuanFang Li","2679606565,2715148124,2651642689,2583159034","Sentiment analysis is one of the most popular natural language processing techniques. It aims to identify the sentiment polarity (positive, negative, neutral or mixed) within a given text. The proper lexicon knowledge is very important for the lexicon-based sentiment analysis methods since they hinge on using the polarity of the lexical item to determine a text's sentiment polarity. However, it is quite common that some lexical items appear positive in the text of one domain but appear negative in another. In this paper, we propose an innovative knowledge building algorithm to extract sentiment lexicon knowledge through computing their polarity value based on their polarity distribution in text dataset, such as in a set of domain specific reviews. The proposed algorithm was tested by a set of domain microblogs. The results demonstrate the effectiveness of the proposed method. The proposed lexicon knowledge extraction method can enhance the performance of knowledge based sentiment analysis.",2016,International Conference on Data Mining,Fields of study: speechthe internetalgorithm designsentiment analysisnatural language processingdata miningpattern recognitioncomputer science
Uncertainty Aware Clustering for Behaviour in Enterprise Networks,Maha Bakoben (Imperial College London)Niall M. Adams (Imperial College London)Anthony Bellotti (Imperial College London),"2324897798,2145214992,2507720246","Understanding relationships between entities in a computer network is an important task in enterprise cyber-security. This paper presents a novel procedure for exploring similarity relationships in Netflow behaviour - activity over time. We demonstrate a two-stage procedure. First, a statistical model is used as a summary of raw data. Naturally, the parameters of such a model are subject to estimation uncertainty. The second stage develops a similarity metric that incorporates this uncertainty. Standard clustering procedures then become available. We illustrate the method using connection-based data derived from Netflow records, from a recently released public domain data set.",2016,International Conference on Data Mining,Fields of study: ellipsoidac powercommunications protocoltime seriesuncertaintydata sciencedata miningmachine learningstatisticscomputer sciencemathematics
Regularizing Deep Convolutional Neural Networks with a Structured Decorrelation Constraint,Wei Xiong (Wuhan University)Bo Du (Wuhan University)Lefei Zhang (Wuhan University)Ruimin Hu (Wuhan University)Dacheng Tao (University of Sydney),"2511103540,2157883762,2104063197,2654096140,2104129307","Deep convolutional networks have achieved successful performance in data mining field. However, training large networks still remains a challenge, as the training data may be insufficient and the model can easily get overfitted. Hence the training process is usually combined with a model regularization. Typical regularizers include weight decay, Dropout, etc. In this paper, we propose a novel regularizer, named Structured Decorrelation Constraint (SDC), which is applied to the activations of the hidden layers to prevent overfitting and achieve better generalization. SDC impels the network to learn structured representations by grouping the hidden units and encouraging the units within the same group to have strong connections during the training procedure. Meanwhile, it forces the units in different groups to learn non-redundant representations by minimizing the cross-covariance between them. Compared with Dropout, SDC reduces the co-adaptions between the hidden units in an explicit way. Besides, we propose a novel approach called Reg-Conv that can help SDC to regularize the complex convolutional layers. Experiments on extensive datasets show that SDC significantly reduces overfitting and yields very meaningful improvements on classification performance (on CIFAR-10 6.22% accuracy promotion and on CIFAR-100 9.63% promotion).",2016,International Conference on Data Mining,Fields of study: decorrelationdata modelingcorrelationdata miningartificial intelligencemachine learningsimulationstatisticscomputer science
MeGS: Partitioning Meaningful Subgraph Structures Using Minimum Description Length,Sebastian Goebl (Ludwig Maximilian University of Munich)Annika TonchChristian Bohm (Ludwig Maximilian University of Munich)Claudia Plant (Florida State University),"119557107,2400573723,2486446532,2122910652","How can we fully structure a graph into pieces of meaningful information? Into structures that provide us with insights and carry a meaning beyond simple clustering. How can we also exploit these patterns to compress the graph for fast transmission and easier storage? In many applications of graph analysis like network analysis or medical information extraction we are searching for special patterns. Here, it is not sufficient to extract only parts of the relevant information in a graph, but to understand the complete underlying structure. Therefore, we propose our algorithm MeGS (Partitioning Meaningful Subgraph Structures using Minimum Description Length) to fully understand how a graph is constructed. The most common primitives (clique, hub, tree, bipartite, and sparse) serve as models to split a graph into meaningful structures. Using the principle of Minimum Description Length (MDL) structure types and counts are determined by the best fitting model. These structures achieve the best compression of the adjacency matrix. As result, every node is part of exactly one structure and has an interpretable context. No unknown areas remain in the graph. The higher a model compresses its section of the graph, the stronger its match with the corresponding structural assumption. MeGS, a fast and parameter-free split-and-merge algorithm, automatically finds the optimal structures achieving the best compression. We compare to state-of-the-art algorithms to prove MeGS' ability for interpretation and compression.",2016,International Conference on Data Mining,Fields of study: distance hereditary graphstrength of a graphvoltage graphcomplement graphgraph bandwidthmoral graphnull graphclique widthadjacency matrixgraphvegetationgraph partitionchannel codeentropytheoretical computer sciencedata miningmachine learningcomputer sciencemathematics
Interactive Independent Topic Analysis for Service,Takahiro Nishigaki (Tokyo Institute of Technology)Katsumi Nitta (Tokyo Institute of Technology)Takashi Onoda (Central Research Institute of Electric Power Industry),"2149702136,2107774876,2079405904","In this paper, we propose a interactive constrained independent topic analysis in text mining. Independent Topic Analysis (ITA) is a method for extracting the independent topics from the document data by using the independent component analysis. In the independent topic analysis, it is possible to extract the most independent topics between each topic. By extracting the independent topic, it is easy to manage the document such as a large number of text data. For example, there are document access support system and document management system. However, the extracted topics by ITA are different from the topic a user requests. In the case of service to the people, interactive system for reflecting the user requests is necessary. We cover the user requests as follows. For example, it is assumed resultant three topics, topic A and topic B and topic C. If a user thought to be close a content of the topic A and topic B, a user wants to merge the topic A and topic B as one of the topic D. In addition, if a user wanted to analyze topic A in more detail, a user would like to separate topic A to topic E and topic F. In that case, it is necessary to incorporate these requests to the ITA. To that end, we define the Merge Link constraints and Separate Link constraints as the user requests. Merge Link constraints is a constraint that merges two topics into one topic. Separate Link constraint is a constraint that separates two topics from one topic. In this paper, we propose a method of extracting a highly independent topic that meets these constraints. We conducted evaluation experiments on proposed methods, and obtained results to show the effectiveness of our approach.",2016,International Conference on Data Mining,Fields of study: matrix decompositioncorrelationdocument clusteringworld wide webinformation retrievaldata miningcomputer sciencemathematics
Measuring Patient Similarities via a Deep Architecture with Medical Concept Embedding,Zihao ZhuChangchang YinBuyue QianYu Cheng (Northwestern University)Jishang WeiFei Wang (University of Connecticut),"2655663308,2633424124,2676585976,2544119651,2653836362,2465953593","Evaluating the clinical similarities between pairwisepatients is a fundamental problem in healthcare informatics. Aproper patient similarity measure enables various downstreamapplications, such as cohort study and treatment comparative effectiveness research. One major carrier for conductingpatient similarity research is the Electronic Health Records(EHRs), which are usually heterogeneous, longitudinal, andsparse. Though existing studies on learning patient similarityfrom EHRs have shown being useful in solving real clinicalproblems, their applicability is limited due to the lack of medicalinterpretations. Moreover, most previous methods assume avector based representation for patients, which typically requiresaggregation of medical events over a certain time period. As aconsequence, the temporal information will be lost. In this paper, we propose a patient similarity evaluation framework based ontemporal matching of longitudinal patient EHRs. Two efficientmethods are presented, unsupervised and supervised, both ofwhich preserve the temporal properties in EHRs. The supervisedscheme takes a convolutional neural network architecture, andlearns an optimal representation of patient clinical recordswith medical concept embedding. The empirical results on real-world clinical data demonstrate substantial improvement overthe baselines.",2016,International Conference on Data Mining,Fields of study: artificial neural networkdata sciencedata miningartificial intelligencemachine learningcomputer science
A Fast Iterative Algorithm for Improved Unsupervised Feature Selection,Bruno Ordozgoiti (Technical University of Madrid)Sandra Gomez Canaval (Technical University of Madrid)Alberto Mozo (Technical University of Madrid),"2494885827,2097527562,2117307335","Dimensionality reduction is often a crucial step for the successfulapplication of machine learning and data mining methods. One way toachieve said reduction is feature selection. Due to the impossibilityof labelling many data sets, unsupervised approaches arefrequently the only option. The column subset selection problemtranslates naturally to this purpose, and has received considerableattention over the last few years, as it provides simple linear modelsfor data reconstruction. Existing methods, however, often achieveapproximation errors that are far from the optimum. In this paper wepresent a novel algorithm for column subset selection thatconsistently outperforms state-of-the-art methods in approximationerror. We present a series of key derivations that allow anefficient implementation, making it comparable in speed and in somecases faster than other algorithms. We also prove results that make itpossible to deal with huge matrices, which has strong implications for otheralgorithms of this type in the big data field. We validate our claimsthrough experiments on a wide variety of well-known data sets.",2016,International Conference on Data Mining,Fields of study: matrix decompositionprototypealgorithm designlinear programmingdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
TrendTracker: Modelling the Motion of Trends in Space and Time,Klaus Arthur Schmid (Ludwig Maximilian University of Munich)Christian FreyFengchao PengMichael Weiler (Ludwig Maximilian University of Munich)Andreas Zufle (Ludwig Maximilian University of Munich)Lei Chen (Hong Kong University of Science and Technology)Matthias Renz (Ludwig Maximilian University of Munich),"2191395951,2581781727,2697822167,2570757024,79808299,2318776917,2150497105","Both the current trends in technology such as smart phones, general mobile devices, stationary sensors and satellites as well as a new user mentality of utilizing this technology to voluntarily share information produce a huge flood of geo-textual data. Such data includes microblogging platforms such as Twitter, social networks such as Facebook, and data from news stations. Such geo-textual data allows to immediately detect and react to new and emerging trends. A trend is a set of keywords associated with a time interval where the frequency of these keywords is increased significantly. In this paper, we investigate the dissemination of trends over space and time. For this purpose, we employ a four-step framework. In the first step, we employ existing solutions to mine a large number of trends. Second, for each trend we create a spatio-temporal dissemination model, which describes the motion of this trend over space and time. To model this dissemination, we employ a (flow-source, flow-destination, time, trend) tensor. In the third step, we cluster these trend-tensors, to identify groups of archetype trends. For each archetype, we aggregate all tensors of the same archetype, and employ a tensor factorization approach to describe this archetype by its latent features. As the fourth step, we propose an algorithm which can classify the trend-archetype of a new trend, in order to predict the future dissemination of this trend. In our experiments, we are able to show that the space of trends does exhibit clusters, each corresponding to a trend-archetype such as political trends, disaster trends and celebrity trends. We show that by identifying the trend-archetype of a trend, we caneffectively predict the future of this trend.",2016,International Conference on Data Mining,Fields of study: stressmarket researchdata miningsimulationcomputer science
Augmented LSTM Framework to Construct Medical Self-Diagnosis Android,Chaochun Liu (Baidu)Huan Sun (Ohio State University)Nan Du (Baidu)Shulong Tan (Zhejiang University)Hongliang FeiWei Fan (Baidu)Tao Yang (Arizona State University)Hao WuYaliang Li (University at Buffalo)Chenwei Zhang (University of Illinois at Chicago),"2591552934,2594620155,2711557452,2161400417,2705017717,2422054197,2688435411,2673412512,2116094297,2558611428","Given a health-related question (such as ""I have a bad stomach ache. What should I do?""), a medical self-diagnosis Android inquires further information from the user, diagnoses the disease, and ultimately recommend best solutions. One practical challenge to build such an Android is to ask correct questions and obtain most relevant information, in order to correctly pinpoint the most likely causes of health conditions. In this paper, we tackle this challenge, named ""relevant symptom question generation"": Given a limited set of patient described symptoms in the initial question (e.g., ""stomach ache""), what are the most critical symptoms to further ask the patient, in order to correctly diagnose their potential problems? We propose an augmented long short-term memory (LSTM) framework, where the network architecture can naturally incorporate the inputs from embedding vectors of patient described symptoms and an initial disease hypothesis given by a predictive model. Then the proposed framework generates the most important symptom questions. The generation process essentially models the conditional probability to observe a new and undisclosed symptom, given a set of symptoms from a patient as well as an initial disease hypothesis. Experimental results show that the proposed model obtains improvements over alternative methods by over 30% (both precision and mean ordinal distance).",2016,International Conference on Data Mining,Fields of study: humanoid robotcorrelationpredictive modellingdata miningartificial intelligencemachine learningsimulationcomputer sciencemathematics
Subspace Clustering Ensembles through Tensor Decomposition,Dominik MautzChristian Bohm (Ludwig Maximilian University of Munich)Claudia Plant (Florida State University),"2667898261,2486446532,2122910652","In recent years many different subspace clusteringalgorithms and related methods have been proposed. Theypromise to not only find hidden structures in data sets, but also toselect for each structure the features, which are most prominent. Yet, most of these methods suffer from the same problem:finding a satisfactory clustering result heavily depends on anadequate configuration of the parameters. In case of insufficientparameterization, a result is potentially hard to interpret andmight contain hundreds of clusters. For traditional clustering al-gorithms different ensemble methods have been developed, whichmitigate these effects by incorporating multiple clustering outputsinto a consensus result. However, most of these methods cannotbe straightforwardly adopted to include subspace information. We propose a novel subspace clustering ensemble algorithmSubCluEns based on the minimum description length principle. It allows combining multiple results of subspace and projectedclustering algorithms into a consensus clustering.",2016,International Conference on Data Mining,Fields of study: k medians clusteringsubclubrown clusteringcanopy clustering algorithmcorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmfuzzy clusteringdata modelingclustering high dimensional datastresscluster analysisencodingalgorithm designconsensus clusteringbiclusteringdata miningpattern recognitionmachine learningcomputer sciencemathematics
Model-Based Approaches for Independence-Enhanced Recommendation,Toshihiro Kamishima (National Institute of Advanced Industrial Science and Technology)Shotaro Akaho (National Institute of Advanced Industrial Science and Technology)Hideki Asoh (National Institute of Advanced Industrial Science and Technology)Issei Sato (University of Tokyo),"119156578,2589577,2431831898,2148390776","This paper studies a new approach to enhance recommendation independence. Such approaches are useful in ensuring adherence to laws and regulations, fair treatment of content providers, and exclusion of unwanted information. For example, recommendations that match an employer with a job applicant should not be based on socially sensitive information, such as gender or race, from the perspective of social fairness. An algorithm that could exclude the influence of such sensitive information would be useful in this case. We previously gave a formal definition of recommendation independence and proposed a method adopting a regularizer that imposes such an independence constraint. As no other options than this regularization approach have been put forward, we here propose a new model-based approach, which is based on a generative model that satisfies the constraint of recommendation independence. We apply this approach to a latent class model and empirically show that the model-based approach can enhance recommendation independence. Recommendation algorithms based on generative models, such as topic models, are important, because they have a flexible functionality that enables them to incorporate a wide variety of information types. Our new model-based approach will broaden the applications of independence-enhanced recommendation by integrating the functionality of generative models.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingrandom variablelinear programmingknowledge managementdata miningartificial intelligencemachine learningstatisticscomputer science
SpreadViz: Analytics and Visualization of Spreading Processes in Social Networks,Konstantinos Skianis (École Polytechnique)Maria-Evgenia G. Rossi (École Polytechnique)Fragkiskos D. Malliaros (École Polytechnique)Michalis Vazirgiannis (École Polytechnique),"2344791761,2518962736,6790893,1914497179","In this paper, we propose SpreadViz, a web tool for exploration and visualization of spreading processes in social networks. SpreadViz consists of three main modules, namely graph exploration and analytics, detection of influential nodes, and interactive visualization. More precisely, SpreadViz offers the following functionalities: (i) It computes and visualizes various centrality criteria towards understanding how the position of a node in the network affects its spreading properties, (ii) It offers a wide range of criteria for the detection of single and multiple influential nodes and comparison among them, (iii) It effectively visualizes the spread of influence in the network as well as the performance of each method. In our demonstration, we invite the audience to interact with SpreadViz, exploring, analyzing, and visualizing the spreading processes over various real-world social networks. The tool is available online.",2016,International Conference on Data Mining,Fields of study: visualizationalgorithm designcomputational modelvisual analyticsdata visualizationhuman computer interactionworld wide webdata miningmachine learningstatisticscomputer science
AWarp: Fast Warping Distance for Sparse Time Series,Abdullah Mueen (University of New Mexico)Nikan Chavoshi (University of New Mexico)Noor Abu-El-Rub (University of New Mexico)Hossein Hamooni (University of New Mexico)Amanda J. Minnich (University of New Mexico),"2083987245,2203691504,2561684608,308734036,2129326886","Dynamic Time Warping (DTW) distance has been effectively used in mining time series data in a multitude of domains. However, in its original formulation DTW is extremely inefficient in comparing long sparse time series, containing mostly zeros and some unevenly spaced non-zero observations. Original DTW distance does not take advantage of this sparsity, leading to redundant calculations and a prohibitively large computational cost for long time series. We derive a new time warping similarity measure (AWarp) for sparse time series that works on the run-length encoded representation of sparse time series. The complexity of AWarp is quadratic on the number of observations as opposed to the range of time of the time series. Therefore, AWarp can be several orders of magnitude faster than DTW on sparse time series. AWarp is exact for binary-valued time series and a close approximation of the original DTW distance for any-valued series. We discuss useful variants of AWarp: bounded (both upper and lower), constrained, and multidimensional. We show applications of AWarp to three data mining tasks including clustering, classification, and outlier detection, which are otherwise not feasible using classic DTW, while producing equivalent results. Potential areas of application include bot detection, human activity classification, and unusual review pattern mining.",2016,International Conference on Data Mining,Fields of study: dynamic time warpingtimesparse matrixencodingtime seriesspeech recognitiondata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Detecting Change Processes in Dynamic Networks by Frequent Graph Evolution Rule Mining,Erik ScharwächterEmmanuel Müller (Karlsruhe Institute of Technology)Jonathan F. DongesMarwan Hassani (RWTH Aachen University)Thomas Seidl 0001 (RWTH Aachen University),"2716268158,2112493600,2642762636,2159472396,2140301036","The analysis of the temporal evolution of dynamic networks is a key challenge for understanding complex processes hidden in graph structured data. Graph evolution rules capture such processes on the level of small subgraphs by describing frequently occurring structural changes within a network. Existing rule discovery methods make restrictive assumptions on the change processes present in networks. We propose EvoMine, a frequent graph evolution rule mining method that, for the first time, supports networks with edge insertions and deletions as well as node and edge relabelings. EvoMine defines embedding-based and event-based support as two novel measures to assess the frequency of rules. These measures are based on novel mappings from dynamic networks to databases of union graphs that retain all evolution information relevant for rule mining. Using these mappings the rule mining problem can be solved by frequent subgraph mining. We evaluate our approach and two baseline algorithms on several real datasets. To the best of our knowledge, this is the first empirical comparison of rule mining algorithmsfor dynamic networks.",2016,International Conference on Data Mining,Fields of study: molecule miningnetwork topologydata miningpattern recognitionmachine learningcomputer sciencemathematics
SmartVideoRanking: Video Search by Mining Emotions from Time-Synchronized Comments,Kosetsu Tsukuda (National Institute of Advanced Industrial Science and Technology)Hamasaki MasahiroMasataka Goto (National Institute of Advanced Industrial Science and Technology),"2515680162,2584935387,2140422315","Many people search for and watch videos on videosharing Web sites, where users input a query and rank videos onthe basis of metrics such as view count and rating. However, it isnot always easy to find the desired video with a conventionalsearch. One approach that enables users to more intuitivelysearch for videos they desire is to index them according toemotions. Previous studies have used several predefined emotioncategories, such as ""fear"" and ""funny"", for this purpose. However, viewers' emotions tend to be more diverse and specific. In thispaper, we dynamically detect emotions in accordance with aninput query and implement SmartVideoRanking, which enablesusers to search for videos on the basis of the detected emotions. We estimate viewer emotions from time-synchronized commentson videos and estimate the usefulness of each emotion by usingsupport vector machine regression. Experimental results showthat: (1) Spearman's rank correlation between the estimatedusefulness scores and gold standard data was 0.7547, (2) emotions associated with videos vary from one query to anotherand it is therefore meaningful to detect emotions according to aninput query, and (3) rankings based on viewer emotions enableusers to browse videos that do not appear at the top ofconventional search results. We also conduct a user study anddemonstrate SmartVideoRanking's capability to search for videos.",2016,International Conference on Data Mining,Fields of study: visualizationdatabase indexsynchronizationfeature extractionmultimediaworld wide webcomputer visiondata miningmachine learningcomputer science
Scalable Block Scheduling for Efficient Multi-database Record Linkage,Thilina Ranbaduge (Australian National University)Dinusha Vatsalan (Australian National University)Peter Christen (Australian National University),"993935970,145048928,2023765750",Record linkage (RL) is a task in data integration that aims to identify matching records that refer to the same entity from different databases. When records from more than two databases are to be linked RL is significantly challenged by the intrinsic exponential growth in the number of potential record comparisons to be conducted. We propose a scalable meta blocking protocol to be used for Multi-Database RL (MDRL) to significantly reduce the complexity of the matching (comparison and classification) phase. Our approach uses a graph structure to schedule the comparison of pairs of blocks with the aim of minimizing the number of repeated and superfluous comparisons between records. We provide an analysis of our approach and conduct an empirical study on large real-world databases.,2016,International Conference on Data Mining,Fields of study: schedulecouplingcommunications protocolencodingdistributed databasetheoretical computer sciencedata miningdatabasecomputer science
Can Active Learning Experience Be Transferred,Hong-Min ChuHsuan-Tien Lin (National Taiwan University),"2531563096,2127632057","Active learning is an important machine learning problem in reducing the human labeling effort. Current active learning strategies are designed from human knowledge, and are applied on each dataset in an immutable manner. In other words, experience about the usefulness of strategies cannot be updated and transferred to improve active learning on other datasets. This paper initiates a pioneering study on whether active learning experience can be transferred. We first propose a novel active learning model that linearly aggregates existing strategies. The linear weights can then be used to represent the active learning experience. We equip the model with the popular linear upper-confidence-bound (LinUCB) algorithm for contextual bandit to update the weights. Finally, we extend our model to transfer the experience across datasets with the technique of biased regularization. Empirical studies demonstrate that the learned experience not only is competitive with existing strategies on most single datasets, but also can be transferred across datasets to improve the performance on future learning tasks.",2016,International Conference on Data Mining,Fields of study: multi task learninggeneralization errorlabeling theorycontext modelprobabilistic logicalgorithm designuncertaintyerror driven learningactive learningproactive learningsemi supervised learningdata miningartificial intelligencemachine learningstatisticscomputer sciencemathematics
Random Walk with Restart over Dynamic Graphs,Weiren Yu (Imperial College London)Julie A. McCann,"2111026807,2714845422","Random Walk with Restart (RWR) is an appealing measure of proximity between nodes based on graph structures. Since real graphs are often large and subject to minor changes, it is prohibitively expensive to recompute proximities from scratch. Previous methods use LU decomposition and degree reordering heuristics, entailing O(|V|3) time and O(|V|2) memory to compute all (|V|2) pairs of node proximities in a static graph. In this paper, a dynamic scheme to assess RWR proximities is proposed: (1) For unit update, we characterize the changes to all-pairs proximities as the outer product of two vectors. We notice that the multiplication of an RWR matrix and its transition matrix, unlike traditional matrix multiplications, is commutative. This can greatly reduce the computation of all-pairs proximities from O(|V|3) to O(|Δ|) time for each update without loss of accuracy, where |Δ| (",2016,International Conference on Data Mining,Fields of study: symmetric matrixtimenoise measurementmatrix decompositioncomputational modeltheoretical computer sciencediscrete mathematicscombinatoricsmathematics
Personalized Ranking in Signed Networks Using Signed Random Walk with Restart,Jinhong Jung (Seoul National University)Woojeong JinLee SaelU Kang (KAIST),"2227697221,2287136851,2675333320,2615132872","How can we rank users in signed social networks? Relationships between nodes in a signed network are represented as positive (trust) or negative (distrust) edges. Many social networks have adopted signed networks to express trust between users. Consequently, ranking friends or enemies in signed networks has received much attention from the data mining community. The ranking problem, however, is challenging because it is difficult to interpret negative edges. Traditional random walk based methods such as PageRank and Random Walk with Restart cannot provide effective rankings in signed networks since they assume only positive edges. Although several methods have been proposed by modifying traditional ranking models, they also fail to account for proper rankings due to the lack of ability to consider complex edge relations. In this paper, we propose Signed Random Walk with Restart, a novel model for personalized ranking in signed networks. We introduce a signed random surfer so that she considers negative edges by changing her sign for walking. Our model provides proper rankings reflecting signed edges based on the signed surfer. Through extensive experiments, we demonstrate that SRWR achieves the best accuracy (up to 87%) for sign prediction, and predicts trolls 4× more accurately than other ranking models.",2016,International Conference on Data Mining,Fields of study: nickeliterative methodcomputational modelmathematical modeltheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
The Time-Varying Dependency Patterns of NetFlow Statistics,Alexander J. Gibberd (University College London)Marina Evangelou (Imperial College London)James D. B. Nelson (University College London),"2226188225,2148694256,2228453109","We investigate where and how key dependency structure between measures of network activity change throughout the course of daily activity. Our approach to data-mining is probabilistic in nature, we formulate the identification of dependency patterns as a regularised statistical estimation problem. The resulting model can be interpreted as a set of time-varying graphs and provides a useful visual interpretation of network activity. We believe this is the first application of dynamic graphical modelling to network traffic of this kind. Investigations are performed on 9 days of real-world network traffic across a subset of IP's. We demonstrate that dependency between features may change across time and discuss how these change at an intra and inter-day level. Such variation in feature dependency may have important consequences for the design and implementation of probabilistic intrusion detection systems.",2016,International Conference on Data Mining,Fields of study: data modelingprobabilistic logicfeature extractiontheoretical computer sciencedata miningmachine learningcomputer science
Classification Rule Mining Supported by Ontology for Discrimination Discovery,Binh Thanh Luong (Institute for Advanced Study)Salvatore Ruggieri (University of Pisa)Franco Turini (University of Pisa),"2131252910,1968619696,2241902680","Discrimination discovery from data consists of designing data mining methods for the actual discovery of discriminatory situations and practices hidden in a large amount of historical decision records. Approaches based on classification rule mining consider items at a flat concept level, with no exploitation of background knowledge on the hierarchical and inter-relational structure of domains. On the other hand, ontologies are a widespread and ever increasing means for expressing such a knowledge. In this paper, we propose a framework for discrimination discovery from ontologies, where contexts of prima-facie evidence of discrimination are summarized in the form of generalized classification rules at different levels of abstraction. Throughout the paper, we adopt a motivating and intriguing case study based on discriminatory tariffs applied by the U. S. Harmonized Tariff Schedules on imported goods.",2016,International Conference on Data Mining,Fields of study: k optimal pattern discoveryontologyhigh temperature superconductivitysemanticsdata sciencedata miningartificial intelligencemachine learningcomputer science
Clustering Based on MultiView Diffusion Maps,Ofir Lindenbaum (Tel Aviv University)Arie Yeredor (Tel Aviv University)Amir Averbuch (Tel Aviv University),"293987154,246233213,69708645","We consider a reduced dimensionality representation based on multiple views of the same underlying process. These multiple views can be obtained, for example, using several different modalities, measured with different instrumentation or generated based on different methods of feature extractions. Our framework is based on a cross-view random walk process which is restrained to hop between the different views in each time step. The random walk model is constructed using the intrinsic relation within each view as well as the mutual relations between views. Within this framework, multiview diffusion distances are defined which lead to reduced representations for each view. The reduced representations are exploited to perform clustering. The applicability of the multiview approach for clustering is demonstrated on both artificial and real data.",2016,International Conference on Data Mining,Fields of study: symmetric matrixkernelmatrix decompositioncorrelationdiscrete mathematicscombinatoricsmachine learningmathematical optimizationstatisticsmathematics
Mining Statistically Significant Attribute Associations in Attributed Graphs,Jihwan LeeKeehwan ParkSunil Prabhakar (Purdue University),"2560207967,2130760815,2119765128","Graphs are widely used to represent many differentkinds of real world data such as social networks, protein-proteininteractions, and road networks. In many cases, each node in agraph is associated with a set of its attributes and it is criticalto not only consider the link structure of a graph but also usethe attribute information to achieve more meaningful results invarious graph mining tasks. Most previous works dealing withattributed graphs take into account attribute relationships onlybetween individually connected nodes. However, it should begreatly valuable to find out which sets of attributes are associatedwith each other and whether or not they are statistically signifi-cant over an entire graph. Mining such significant associations, we can uncover novel relationships among the sets of attributes inthe graph. We propose an algorithm that can find those attributeassociations efficiently and effectively, and show experimentalresults that confirm the high efficacy of the proposed algorithm.",2016,International Conference on Data Mining,Fields of study: probabilitydata scienceworld wide webdata miningmachine learningstatisticscomputer sciencemathematics
Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis,Young Woong Park (Southern Methodist University)Diego Klabjan (Northwestern University),"2105639671,134296357","Principal component analysis (PCA) is often used to reduce the dimension of data by selecting a few orthonormal vectors that explain most of the variance structure of the data. L1 PCA uses the L1 norm to measure error, whereas the conventional PCA uses the L2 norm. For the L1 PCA problem minimizing the fitting error of the reconstructed data, we propose an exact reweighted and an approximate algorithm based on iteratively reweighted least squares. We provide convergence analyses, and compare their performance against benchmark algorithms in the literature. The computational experiment shows that the proposed algorithms consistently perform best.",2016,International Conference on Data Mining,Fields of study: sparse pcaiteratively reweighted least squaresbenchmarkprincipal component analysisiterative methodalgorithm designlinear programmingeconometricsmathematical optimizationstatisticscomputer sciencemathematics
Financial Data Analysis with PGMs Using AMIDST,Rafael Cabanas (University of Granada)Ana M. Martinez (University of Castilla–La Mancha)Andres R. Masegosa (Norwegian University of Science and Technology)Dario Ramos-Lopez (University of Almería)Antonio SameronThomas D. Nielsen (Aalborg University)Helge Langseth (Norwegian University of Science and Technology)Anders L. Madsen (Aalborg University),"2115382858,2239008456,2331637970,1850935109,2583943763,2098001594,705532035,2150224916","The AMIDST Toolbox an open source Java 8 library for scalable learning of probabilistic graphical models (PGMs) based on both batch and streaming data. An important application domain with streaming data characteristics is the banking sector, where we may want to monitor individual customers (based on their financial situation and behavior) as well as the general economic climate. Using a real financial data set from a Spanish bank, we have previously proposed and demonstrated a novel PGM framework for performing this type of data analysis with particular focus on concept drift. The framework is implemented in the AMIDST Toolbox, which was also used to conduct the reported analyses. In this paper, we provide an overview of the toolbox and illustrate with code examples how the toolbox can be used for setting up and performing analyses of this particular type.",2016,International Conference on Data Mining,Fields of study: data modelingprobabilistic logicdata analysishidden markov modeldata sciencedata miningmachine learningsimulationstatisticscomputer science
A Novel Bayesian Ensemble Pruning Method,Zhengshen Jiang (Peking University)Hongzhi Liu (Peking University)Bin Fu (Peking University)Zhonghai Wu (Peking University),"2584371781,2096263457,2294712623,2125103526","In ensemble learning, ensemble pruning is a procedure that aims at removing the unnecessary base classifiers and retaining the best subset of the base classifiers. We presented a two-step ensemble pruning framework, in which the optimal size of the pruned ensemble is first decided, and then with the optimal size as input, the optimal ensemble is selected. For the first step to find the optimal ensemble size, we presented an algorithm that can be proved to be able to find the Bayesian optimal ensemble size. For the second step, we developed two greedy forward pruning methods, i.e., the Bayesian Pruning (BP) method and the Bayesian Independent Pruning (BIP) method. In the BP method, we assumed that the probability of a candidate ensemble to be the optimal ensemble follows the Generalized Beta distribution. And in the BIP method, we further assumed that whether a base classifier belongs to the optimal ensemble is independent to the other base classifiers. Experimental results on twenty benchmark data sets showed that the BP and BIP methods achieved competitive performance in contrast to other state-of-the-art algorithms.",2016,International Conference on Data Mining,Fields of study: predictionsamplingensemble learningdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Efficient Algorithms for the Three Locus Problem in Genome-Wide Association Study,Sanguthevar Rajasekaran (University of Connecticut)Subrata Saha (University of Connecticut),"2171202298,2304603059","Using the recent advances in sequencing technology thousands of genomes have been sequenced. This sequence data can be fruitfully employed in diagnosis, drug design, etc. Genome-wide Association Study (GWAS) focuses on this important problem of extracting useful information from genomic data. As an example, a comparison of different genomes could throw light on causes for different diseases. Human variabilities happen due to single nucleotide polymorphisms (SNPs). Thus it might suffice to focus on these SNPs while comparing different genomes. One of the important problems in GWAS is that of identifying the correlation between genotypes (SNPs for example) and phenotypes (i.e., different characteristics such as addiction, the presence of cancer, etc.) Different approaches exist for addressing this problem. One important approach is via modeling this problem as the k-locus problem (k being any integer). The case of k = 1 has been studied widely. Some algorithms also exist for solving the case of k = 2. The real cause for a disease could be more than two SNPs. The case of k > 2 has not been studied in the literature. For the first time, in this paper we present an efficient algorithm for solving the 3-locus problem that is several orders of magnitude faster than the brute force algorithm. All the software can be obtained from: engr.uconn.edu/~rajasek/ThreeLocus.",2016,International Conference on Data Mining,Fields of study: hamming distanceforcecorrelationgenomicsbioinformaticsdata miningcomputer sciencemathematics
Score Look-Alike Audiences,Qiang Ma (Rutgers University)Eeshan WaghJiayi WenZhen XiaRobert Ormandi (University of Szeged)Datong Chen,"2246118604,2583170323,2670915931,2584838828,324999736,2660217561","Look-alike models, which are efficient tools for finding similar users from a smaller user set, are quickly revolutionizing the online programmatic advertising industry. The datasets in these contexts exhibit extremely sparse feature spaces on a massive scale, so traditionally, the state-of-the-art look-alike models have used pairwise similarities to construct these similar user sets. One of the key challenges of the similarity-based models is that they do not provide a way to measure the potential value of the users to an advertiser, which is crucial in an advertising context. We propose methods to score users within the expanded audience in a way which relates directly to the business metric that the advertiser wants to optimize. We present three scoring models and show that, through empirical evaluation using real-world, large-scale data, by incorporating the potential value of a user to an advertiser into our scoring model, we can significantly improve the performance of the look-alike models over methods which only use pairwise similarities of users.",2016,International Conference on Data Mining,Fields of study: data modelingcontext modelcomputational modelapproximation algorithmdata scienceworld wide webdata miningmachine learningcomputer science
Laplacian SVM for Learning from Label Proportions,Limeng Cui (Chinese Academy of Sciences)Zhensong Chen (Chinese Academy of Sciences)Fan Meng (Chinese Academy of Sciences)Yong Shi (Chinese Academy of Sciences),"2491106104,2500239555,2518417853,1986476467","Proportion-SVM has been deeply studied due to its broad application prospects, such as modeling voting behaviors and spam filtering. However, the geometric information has been widely ignored. Thus, current methods usually show sensitivity to noises. To address these problems, in this paper, we combine the proportion learning framework with Laplacian term. We exploit the advantages of Laplacian term. Extensive experiments show the effectiveness of our method.",2016,International Conference on Data Mining,Fields of study: data modelingkernelsupport vector machinedata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Website Classification Using Latent Dirichlet Allocation and Its Application for Internet Advertising,Sotaro Katsumata (Osaka University)Eiji MotohashiAkihiro Nishimoto (Kwansei Gakuin University)Eiji Toyosawa,"2511104211,2660638905,2590554431,2584609484","This study proposes a model for website classification using website content, and discusses applications for internet advertising (ad) strategies. Internet ad agencies have many ad-spaces embedded in many websites and can choose where to place advertisements. Therefore, ad agencies have to know the properties and topics of each website in order to optimize advertising submission strategy. However, since website content is in natural languages, they have to convert these qualitative sentences into quantitative data if they want to classify websites using statistical models. To address this issue, this study applies statistical analysis to website information written in natural languages. We apply a dictionary of neologisms in order to decompose website sentences into words and create a dataset of 0, 1 indicator matrices to classify the websites. From the dataset, we estimate the topics of each website using latent Dirichlet allocation. Finally, we discuss how to apply the results obtained to optimize ad strategies.",2016,International Conference on Data Mining,Fields of study: mediathe internetmathematical modelinternet privacyworld wide webdata miningcomputer science
Towards Scalable Network Delay Minimization,"Sourav MedyaPetko Bogdanov (University of California, Santa Barbara)Ambuj K. Singh (University of California, Santa Barbara)","2342828630,2247548115,2099219664","Reduction of end-to-end network delays is an optimization task with applications in multiple domains. Low delays enable improved information flow in social networks, quick spread of ideas in collaboration networks, low travel times for vehicles on road networks and increased rate of packets in communication networks. Delay reduction can be achieved by both improving the propagation capabilities of individual nodes and adding additional edges in the network. One of the main challenges in such design problems is that the effects of local changes are not independent, and as a consequence, there is a combinatorial search space of possible improvements. Thus, minimizing the cumulative propagation delay requires novel scalable and data-driven approaches. In this paper, we consider the problem of network delay minimization via node upgrades. Although the problem is NP-hard, we show that probabilistic approximation for a restricted version can be obtained. We design scalable and high-quality techniques for the general setting based on sampling that are targeted to different models of delay distribution. Our methods scale almost linearly with the graph size and consistently outperform competitors in quality.",2016,International Conference on Data Mining,Fields of study: network delaycomputational modelapproximation algorithmtheoretical computer sciencedistributed computingmathematical optimizationcomputer science
A Novel Uncertainty Sampling Algorithm for Cost-Sensitive Multiclass Active Learning,Kuan-Hao Huang (National Taiwan University)Hsuan-Tien Lin (National Taiwan University),"2113276713,2127632057","Active learning is a setup that allows the learning algorithm to iteratively and strategically query the labels of some instances for reducing human labeling efforts. One fundamental strategy, called uncertainty sampling, measures the uncertainty of each instance when making querying decisions. Traditional active learning algorithms focus on binary or multiclass classification, but few works have studied active learning for cost-sensitive multiclass classification (CSMCC), which allows charging different costs for different types of misclassification errors. The few works are generally based on calculating the uncertainty of each instance by probability estimation, and can suffer from the inaccuracy of the estimation. In this paper, we propose a novel active learning algorithm that relies on a different way of calculating the uncertainty. The algorithm is based on our newly-proposed cost embedding approach (CE) for CSMCC. CE embeds the cost information in the distance measure of a special hidden space with non-metric multidimensional scaling, and deals with both symmetric and asymmetric cost information by our carefully designed mirroring trick. The embedding allows the proposed algorithm, active learning with cost embedding (ALCE), to define a cost-sensitive uncertainty measure from the distance in the hidden space. Extensive experimental results demonstrate that ALCE selects more useful instances by taking the cost information into account through the embedding and is superior to existing cost-sensitive active learning algorithms.",2016,International Conference on Data Mining,Fields of study: measurement uncertaintysymmetric matrixpredictionalgorithm designuncertaintyestimationactive learningdata miningmachine learningmathematical optimizationstatisticsmathematics
Canonical Consistent Weighted Sampling for Real-Value Weighted Min-Hash,"Wei Wu (University of Technology, Sydney)Bin Li (University of Technology, Sydney)Ling Chen (University of Technology, Sydney)Chengqi Zhang (University of Technology, Sydney)","2441504174,2565587667,2691089318,2166080598","Min-Hash, as a member of the Locality Sensitive Hashing (LSH) family for sketching sets, plays an important role in the big data era. It is widely used for efficiently estimating similarities of bag-of-words represented data and has been extended to dealing with multi-sets and real-value weighted sets. Improved Consistent Weighted Sampling (ICWS) has been recognized as the state-of-the-art for real-value weighted Min-Hash. However, the algorithmic implementation of ICWS is flawed because it violates the uniformity of the Min-Hash scheme. In this paper, we propose a Canonical Consistent Weighted Sampling (CCWS) algorithm, which not only retains the same theoretical complexity as ICWS but also strictly complies with the definition of Min-Hash. The experimental results demonstrate that the proposed CCWS algorithm runs faster than the state-of-the-arts while achieving similar classification performance on a number of real-world text data sets.",2016,International Conference on Data Mining,Fields of study: database indexbig datatheoretical computer sciencedata miningmachine learningstatisticsalgorithmcomputer sciencemathematics
Modeling Real Estate for School District Identification,Fei Tan (Zhejiang University)Chaoran Cheng (New Jersey Institute of Technology)Zhi Wei (New Jersey Institute of Technology),"2292729112,2363752216,2126219825","The affiliated school district of a real estate property is often a crucial concern. How to automate the identification of residential homes located in a favorable educational environment, however, is largely unexplored until now. The availability of heterogeneous estate-related data offers a great opportunity for this task. Nevertheless, it is such heterogeneity that poses significant challenges to their amalgamation in a unified fashion. To this end, we develop G-LRMM model to integrate digital price, textual comments, and geographical location information together. The proposed approach is able to capture the in-depth interaction among multi-type data greatly. The evaluation on the dataset of Beijing property market justifies the benefits of our approach over baselines. The further comparison among different components is also conducted and demonstrates their important roles. Moreover, the proposed model can offer useful insights into modeling heterogeneous data sources.",2016,International Conference on Data Mining,Fields of study: data modelingmixture modelcomputational modelestimation theorymathematical modeldata miningsimulationstatisticscomputer sciencemathematics
Differentially Private Regression Diagnostics,Yan Chen (Duke University)Ashwin Machanavajjhala (Duke University)Jerome P. Reiter (Duke University)Andres F. Barrientos,"2665327571,2073648588,1905884054,2624145105","Linear and logistic regression are popular statistical techniques for analyzing multi-variate data. Typically, analysts do not simply posit a particular form of the regression model, estimate its parameters, and use the results for inference orprediction. Instead, they first use a variety of diagnostic techniques to assess how well the model fits the relationships in the data and how well it can be expected to predict outcomes for out-of-sample records, revising the model as necessary to improve fit and predictive power. In this article, we develop e-differentially private diagnostics for regression, beginning to fill a gap in privacy-preserving data analysis. Specifically, we create differentially private versions of residual plots for linear regression and of receiver operating characteristic (ROC) curves for logistic regression. The former helps determine whether or not the data satisfy the assumptions underlying the linear regression model, and the latter is used to assess the predictive power of the logistic regression model. These diagnostics improve the usefulness of algorithms for computing differentially private regression output, which alone does not allow analysts to assess the quality of the posited model. Our empirical studies show that these algorithms are adequate for diagnosing the fit and predictive power of regression models on representative datasets when the size of the dataset times the privacy parameter (e) is at least 1000.",2016,International Conference on Data Mining,Fields of study: proper linear modelpath coefficientregression diagnosticmultinomial logistic regressionmultivariate adaptive regression splinesdata modelingnonparametric regressionlinear modelpredictive modellingprivacylinear regressionalgorithm designcomputational modelregression analysisinformation privacyeconometricsdata miningmachine learningstatisticscomputer science
Cut Tree Construction from Massive Graphs,Takuya Akiba (University of Tokyo)Yoichi Iwata (University of Tokyo)Yosuke SameshimaNaoto Mizuno (University of Tokyo)Yosuke Yano (University of Tokyo),"2149787982,2124793788,2551397170,2125072240,2366236231","The construction of cut trees (also known as Gomory-Hu trees) for a given graph enables the minimum-cut size of the original graph to be obtained for any pair of vertices. Cut trees are a powerful back-end for graph management and mining, as they support various procedures related to the minimum cut, maximum flow, and connectivity. However, the crucial drawback with cut trees is the computational cost of their construction. In theory, a cut tree is built by applying a maximum flow algorithm for n times, where n is the number of vertices. Therefore, naive implementations of this approach result in cubic time complexity, which is obviously too slow for today's large-scale graphs. To address this issue, in the present study, we propose a new cut-tree construction algorithm tailored to real-world networks. Using a series of experiments, we demonstrate that the proposed algorithm is several orders of magnitude faster than previous algorithms and it can construct cut trees for billion-scale graphs.",2016,International Conference on Data Mining,Fields of study: link cut treetremaux treegomory hu treegraph bandwidthpseudoforestpathwidthchordal graphmaximum cutcutinformaticsindependent settreetime complexitygraph theorydiscrete mathematicscombinatoricsdata miningmachine learningalgorithmcomputer sciencemathematics
Clustering with the Levy Walk: “Hunting” for Clusters,Benjamin SchellingClaudia Plant (Florida State University),"2583289053,2122910652","The Levy Walk (or Levy flight) is a concept fromBiomathematics to describe the hunting–behaviour of manypredatory species. It is a very efficient way to find prey in avery short time frame. We now want to use this concept ina clustering–context to – if you so will – ""hunt"" for clusters. We describe how we convert this concept into an efficient wayto find cluster centres by linking the data points through thepath the Levy Walk takes. The clusters are then created bystatistical analysis of the links between the data points. The resultis a Clustering algorithm that works on massive datasets withextremely high level of noise. It is not dependent on any form ofcluster shape and is almost free of parameters. The only choiceone has to make is the precision of the Clustering, which in turndetermines the runtime.",2016,International Conference on Data Mining,Fields of study: correlation clusteringsynchronizationcluster analysisprobability density functionshapemathematical modelartificial intelligencesimulationstatisticscomputer sciencemathematics
Knowledge Graph Constraints for Multi-label Graph Classification,Martin Ringsquandl (Siemens)Steffen Lamparter (Karlsruhe Institute of Technology)Ingo ThonRaffaello Lepratti (Siemens)Peer Kroger (Ludwig Maximilian University of Munich),"2562966357,2680091355,2652441377,2050858192,2100673337","Graph classification methods have gained increasing attention in different domains, such as classifying functions of molecules or detection of bugs in software programs. Similarly, predicting events in manufacturing operations data can be compactly modeled as graph classification problem. Feature representations of graphs are usually found by mining discriminative sub-graph patterns that are non-uniformly distributed across class labels. However, as these feature selection approaches are computationally expensive for multiple labels, prior knowledge about label correlations should be exploited as much as possible. In this work, we introduce a new approach for mining discriminative sub-graph patterns with constraints that are extracted from links between labels in knowledge graphs which indicate label correlations. The incorporation of these constraints allows to prune the search space and ensures extraction of consistent patterns. Therefore, constraint checking remains efficient and more robust classification results can be obtained. We evaluate our approach on both, one public and one custom simulated data set. Evaluation confirms that incorporation of constraints still results in efficient pattern mining and can increase performance of state-of-the-art approaches.",2016,International Conference on Data Mining,Fields of study: manufacturingcorrelationfeature extractionlinear programmingdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Structure Selection for Convolutive Non-negative Matrix Factorization Using Normalized Maximum Likelihood Coding,Atsushi SuzukiKohei Miyaguchi (University of Tokyo)Kenji Yamanishi (University of Tokyo),"2585120349,2230191217,2302798453","Convolutive non-negative matrix factorization (CNMF) is a promising method for extracting features from sequential multivariate data. Conventional algorithms for CNMF require that the structure, or the number of bases for expressing the data, be specified in advance. We are concerned with the issue of how we can select the best structure of CNMF from given data. We first introduce a framework of probabilistic modeling of CNMF and reduce this issue to statistical model selection. The problem is here that conventional model selection criteria such as AIC, BIC, MDL cannot straightforwardly be applied since the probabilistic model for CNMF is irregular in the sense that parameters are not uniquely identifiable. We overcome this problem to propose a novel criterion for best structure selection for CNMF. The key idea is to apply the technique of latent variable completion in combination with normalized maximum likelihood coding criterion under the minimum description length principle. We empirically demonstrate the effectiveness of our method using artificial and real data sets.",2016,International Conference on Data Mining,Fields of study: data modelingprobabilistic logicconvolutionfeature extractionencodinginformation sciencedata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Robust Multi-View Feature Selection,Hongfu Liu (Northeastern University)Haiyi Mao (Northeastern University)Yun Fu (Northeastern University),"2108071053,2535563821,2123131494","High-throughput technologies have enabled us to rapidly accumulate a wealth of diverse data types. These multi-view data contain much more information to uncover the cluster structure than single-view data, which draws raising attention in data mining and machine learning areas. On one hand, many features are extracted to provide enough information for better representations, on the other hand, such abundant features might result in noisy, redundant and irrelevant information, which harms the performance of the learning algorithms. In this paper, we focus on a new topic, multi-view unsupervised feature selection, which aims to discover the discriminative features in each view for better explanation and representation. Although there are some exploratory studies along this direction, most of them employ the traditional feature selection by putting the features in different views together and fail to evaluate the performance in the multi-view setting. The features selected in this way are difficult to explain due to the meaning of different views, which disobeys the goal of feature selection as well. In light of this, we intend to give a correct understanding of multi-view feature selection. Different from the existing work, which either incorrectly concatenates the features from different views, or takes huge time complexity to learn the pseudo labels, we propose a novel algorithm, Robust Multi-view Feature Selection (RMFS), which applies robust multi-view K-means to obtain the robust and high quality pseudo labels for sparse feature selection in an efficient way. Nontrivially we give the solution by taking the derivatives and further provide a K-means-like optimization to update several variables in a unified framework with the convergence guarantee. We demonstrate extensive experiments on three real-world multi-view data sets, which illustrate the effectiveness and efficiency of RMFS in terms of both single-view and multi-view evaluations by a large margin.",2016,International Conference on Data Mining,Fields of study: featurerobustnessfeature extractioncluster analysisalgorithm designdata miningpattern recognitionmachine learningstatisticscomputer science
New Probabilistic Multi-graph Decomposition Model to Identify Consistent Human Brain Network Modules,Dijun Luo (University of Texas at Arlington)Zhouyuan Huo (University of Texas at Arlington)Yang Wang (Medical College of Wisconsin)Andrew J. Saykin (Indiana University School of Medicine)Li Shen (Indiana University School of Medicine)Heng Huang (University of Texas at Arlington),"2166799549,2645196171,2617134368,2171622173,2121150543,2137533801","Many recent scientific efforts have been devoted to constructing the human connectome using Diffusion Tensor Imaging (DTI) data for understanding large-scale brain networks that underlie higher-level cognition in human. However, suitable network analysis computational tools are still lacking in human brain connectivity research. To address this problem, we propose a novel probabilistic multi-graph decomposition model to identify consistent network modules from the brain connectivity networks of the studied subjects. At first, we propose a new probabilistic graph decomposition model to address the high computational complexity issue in existing stochastic block models. After that, we further extend our new probabilistic graph decomposition model for multiple networks/graphs to identify the shared modules cross multiple brain networks by simultaneously incorporating multiple networks and predicting the hidden block state variables. We also derive an efficient optimization algorithm to solve the proposed objective and estimate the model parameters. We validate our method by analyzing both the weighted fiber connectivity networks constructed from DTI images and the standard human face image clustering benchmark data sets. The promising empirical results demonstrate the superior performance of our proposed method.",2016,International Conference on Data Mining,Fields of study: diffusion mridata modelingprobabilistic logiccomputational modelstochastic processtheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Method for Extraction of Purchase Behavior and Product Character Using Dynamic Topic Model,Mamoru Emoto (University of Tokyo),2283052578,"In this study, we focus on extraction of latent topic transition from POS data. POS analysis is conducted to obtain the frequent pattern of customer's behavior. The fundamental method for POS analysis is to conduct market basket analysis. By doing Market basket analysis, the sets of products that are often bought at the same time can be extracted. In market basket analysis, however, the effect of time series is not considered. We conducted the experiment based on two hypotheses. One is that each product has several topics. The other is that the proportion of each product on a topic changes as the period changes. To extract topics and their changes, we use Dynamic Topic Model (DTM), which is an extended model of Latent Dirichlet Allocation (LDA). Then we obtain the change of the topic-word distribution on each topic. Different topic has different characters, but it seems that there is a relationship between each topic. Therefore, we conduct correlation analysis to several items. From the result of visualization of product features vector of several items, we can obtain that each product has unique time-series change of product feature. This study is also conducted to reveal product features vector based on Customer Purchase Behavior. By using DTM, each basket is transformed into probability distribution vector, and we use this topic vectors as each basket's evaluation result of topic features. We divide POS data into 12 groups by purchasing time and create a heat map that indicates changes of topic proportion as time advances. By conducting this analysis, we can grasp customer behavior based on the topic vector space. These analysises reveals product features are created based on topic correlations and its change and customer behavior can be extracted as the change of topic proportion, so the results show that the presented method is promising in the extraction of products' features and customer behavior.",2016,International Conference on Data Mining,Fields of study: data modelingprobabilistic logiccorrelationfeature extractiondata sciencedata miningmachine learningcomputer science
Personal Identification with Face and Voice Features Extracted through Kinect Sensor,Eisuke Kita (Nagoya University)Yi Zuo (Nagoya University)Fumiya SaitoXuanang Feng (Nagoya University),"2090389445,2258350279,2584204138,2585143794","The personal identification from the features of personal face and voice is described in this study. The face area is detected from the picture including both the face and the complicated background by using Microsoft Kinect sensor. The personal voice is also recorded from Kinect microphone array, which is used for the personal identification. The features of the personal face are calculated from the position vectors of the face parts such as eyes, nose, mouth and so on. The mel-frequency cepstrum coefficients, the logarithmic power and their related values are calculated from the personal voice. The personal identification algorithm is defined by neural network and support vector machine. The identification accuracy of the algorithms are confirmed by the face and the voice data observed from 20 examinees. The results show that the best accuracy can be observed when both face and voice data are adopted and the algorithm is defined by the neural network.",2016,International Conference on Data Mining,Fields of study: cepstrumsupport vector machinefacefeature extractionartificial neural networkspeech recognitioncomputer visionmachine learningcomputer science
Knowledge Representation Learning via Dynamic Relation Spaces,Zhen TanXiang Zhao (University of New South Wales)Yang FangWeidong XiaoJiuyang Tang (National University of Defense Technology),"2584740511,2692865339,2460193512,2674103298,2644242134","Knowledge graphs are an important part in AI domain, and contain large scale of structured knowledge, but they are far from completeness. Previous translation models, such as TransE, TransH, TransR/CTransR and TransD, use a relation vector to translate head entity vector, the result of translation is close to tail entity vector. Compared with other classical models, these translation models achieve state-of-the-art performance. In this paper, we propose a more flexible model named TransDR, which is an improvement of TransD. In TransDR, we use two vectors to represent each entity and three vectors to represent relation. Compared with TransD, TransDR adds another vector for each relation which could not only represent model more flexibly but also reduce the noise from other relation spaces. In experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Experiment results show significant and consistent improvements compared to previous state-of-the-art models.",2016,International Conference on Data Mining,Fields of study: predictive modellingstressmathematical modelsemanticsdata miningartificial intelligencemachine learningalgorithmcomputer sciencemathematics
Ligand-Based Virtual Screening with Co-regularised Support Vector Regression,Katrin UllrichMichael Kamp (Fraunhofer Society)Thomas Gartner (Fraunhofer Society)Martin Vogt (University of Bonn)Stefan Wrobel (Fraunhofer Society),"2539338950,2294794987,1891115510,2064165665,2113978936","We consider the problem of ligand affinity prediction as a regression task, typically with few labelled examples, many unlabelled instances, and multiple views on the data. In chemoinformatics, the prediction of binding affinities for protein ligands is an important but also challenging task. As protein-ligand bonds trigger biochemical reactions, their characterisation is a crucial step in the process of drug discovery and design. However, the practical determination of ligand affinities is very expensive, whereas unlabelled compounds are available in abundance. Additionally, many different vectorial representations for compounds (molecular fingerprints) exist that cover different sets of features. To this task we propose to apply a co-regularisation approach, which extracts information from unlabelled examples by ensuring that individual models trained on different fingerprints make similar predictions. We extend support vector regression similarly to the existing co-regularised least squares regression (CoRLSR) and obtain a co-regularised support vector regression (CoSVR). We empirically evaluate the performance of CoSVR on various protein-ligand datasets. We show that CoSVR outperforms CoRLSR as well as existing state-of-the-art approaches that do not take unlabelled molecules into account. Additionally, we provide a theoretical bound on the Rademacher complexity for CoSVR.",2016,International Conference on Data Mining,Fields of study: kernelsupport vector machinebioinformaticsdata miningmachine learningcomputer sciencemathematics
Waddling Random Walk: Fast and Accurate Mining of Motif Statistics in Large Graphs,Guyue HanHarish Sethu (Drexel University),"2679936574,1244039458","Algorithms for mining very large graphs, such as those representing online social networks, to discover the relative frequency of small subgraphs within them are of high interest to sociologists, computer scientists and marketeers alike. However, the computation of these network motif statistics via naive enumeration is infeasible for either its prohibitive computational costs or access restrictions on the full graph data. Methods to estimate the motif statistics based on random walks by sampling only a small fraction of the subgraphs in the large graph address both of these challenges. In this paper, we present a new algorithm, called the Waddling Random Walk (WRW), which estimates the concentration of motifs of any size. It derives its name from the fact that it sways a little to the left and to the right, thus also sampling nodes not directly on the path of the random walk. The WRW algorithm achieves its computational efficiency by not trying to enumerate subgraphs around the random walk but instead using a randomized protocol to sample subgraphs in the neighborhood of the nodes visited by the walk. In addition, WRW achieves significantly higher accuracy (measured by the closeness of its estimate to the correct value) and higher precision (measured by the low variance in its estimations) than the current state-of-the-art algorithms for mining subgraph statistics. We illustrate these advantages in speed, accuracy and precision using simulations on well-known and widely used graph datasets representing real networks.",2016,International Conference on Data Mining,Fields of study: microstructurecommunications protocolestimationprobabilitytheoretical computer sciencecombinatoricsmachine learningstatisticscomputer sciencemathematics
A Robust Framework for Classifying Evolving Document Streams in an Expert-Machine-Crowd Setting,Muhammad Imran (Qatar Computing Research Institute)Sanjay Chawla (Qatar Computing Research Institute)Carlos Castillo (Qatar Computing Research Institute),"2112905073,2201421368,2479708560","An emerging challenge in the online classification of social media data streams is to keep the categories used for classification up-to-date. In this paper, we propose an innovative framework based on an Expert-Machine-Crowd (EMC) triad to help categorize items by continuously identifying novel concepts in heterogeneous data streams often riddled with outliers. We unify constrained clustering and outlier detection by formulating a novel optimization problem: COD-Means. We design an algorithm to solve the COD-Means problem and show that COD-Means will not only help detect novel categories but also seamlessly discover human annotation errors and improve the overall quality of the categorization process. Experiments on diverse real data sets demonstrate that our approach is both effective and efficient.",2016,International Conference on Data Mining,Fields of study: social mediaelectromagnetic compatibilitylabeling theorycluster analysisalgorithm designtaxonomydata sciencedata miningmachine learningcomputer science
ROM: A Robust Online Multi-task Learning Approach,"Chi ZhangPeilin Zhao (Agency for Science, Technology and Research)Shuji Hao (Nanyang Technological University)Yeng Chai SohBu Sung Lee","2645693360,2096910461,2223900961,2714359897,2687369767","A series of online multi-task learning (OMTL) algorithms have been proposed to avoid the expensive training cost and poor adaptability of traditional batch multi-task learning (MTL) algorithms in recent years. However, these OMTL algorithms usually assume that all tasks are closely related, which may not hold in practical scenarios. More importantly, their theoretical reliability is weakened due to the lack of proof on the cumulative regrets. To overcome these limitations, we present a robust online multi-task classification framework (ROM) and its two optimization algorithms (ROM-PGD, ROM-RDA). The proposed algorithms can not only automatically capture the common features among all tasks and individual features for each task, but also identify the potential existence of outlier task. Theoretically, we prove that the regret bounds of these two algorithms are sub-linear compared with the best separating algorithm in hindsight. Empirical studies on both synthetic and real-world datasets also demonstrate the effectiveness of our proposed algorithms when compared with the state-of-the-art OMTL algorithms.",2016,International Conference on Data Mining,Fields of study: quality control and genetic algorithmsrandomized algorithms as zero sum gamesanalysis of parallel algorithmsprobabilistic analysis of algorithmsread only memorymatrix decompositionrobustnesspredictionalgorithm designtheoretical computer sciencedata miningmachine learningstatisticscomputer science
Whether This Participant will Attract You to This Event? Exploiting Participant Influence for Event Recommendation,Yi Liao (The Chinese University of Hong Kong)Xinshi Lin (The Chinese University of Hong Kong)Wai Lam (The Chinese University of Hong Kong),"2715519101,2567695724,2702705269","When a user is making a decision on whether to participate an event in Event-based Social Networks (EBSN), one of the common considerations is who have agreed to join this event. The reason is that existing participants of the event affect the decision of the user, to which we refer as participant influence. However, participant influence is not well studied by previous works. In this paper, we propose an event recommendation model which considers participant influence, exploiting the influence of existing participants, on the decisions of new participants. Specifically, we investigate participant influence in relation to several commonly used contextual aspects of the event based on Poisson factorization. We have conducted extensive experiments on some datasets extracted from a real-world EBSN. The results demonstrate that the consideration of participant influence can improve event recommendation.",2016,International Conference on Data Mining,Fields of study: probabilistic logicsparse matrixstressmathematical modelworld wide webdata miningcomputer sciencemathematics
Heterogeneous Representation Learning with Structured Sparsity Regularization,Pei Yang (Arizona State University)Jingrui He,"2705969941,2712973463","Motivated by real applications, heterogeneous learning has emerged as an important research area, which aims to model the co-existence of multiple types of heterogeneity. In this paper, we propose a HEterogeneous REpresentation learning model with structured Sparsity regularization (HERES) to learn from multiple types of heterogeneity. HERES aims to leverage two kinds of information to build a robust learning system. One is the rich correlations among heterogeneous data such as task relatedness, view consistency, and label correlation. The other is the prior knowledge of the data in the form of, e.g., the soft-clustering of the tasks. HERES is a generic framework for heterogeneous learning, which integrates multi-task, multi-view, and multi-label learning into a principled framework based on representation learning. The objective of HERES is to minimize the reconstruction loss of using the factor matrices to recover the input matrix for heterogeneous data, regularized by the structured sparsity constraint. The resulting optimization problem is challenging due to the non-smoothness and non-separability of structured sparsity. We develop an iterative updating method to solve the problem. Furthermore, we prove that the reformulation of structured sparsity is separable, which leads to a family of efficient and scalable algorithms for solving structured sparsity penalized problems. The experimental results in comparison with state-of-the-art methods demonstrate the effectiveness of the proposed approach.",2016,International Conference on Data Mining,Fields of study: data modelingmatrix decompositioncorrelationrobustnessencodingpattern recognitionmachine learningmathematical optimizationcomputer sciencemathematics
Functional Regression with Mode-Sparsity Constraint,Pei Yang (Arizona State University)Jingrui He,"2705969941,2679294848","Functional data is ubiquitous in many domains such as healthcare, social media, manufacturing process, sensor networks, etc. Functional data analysis involves the analysis of data which is treated as infinite-dimensional continuous functions rather than discrete, finite-dimensional vectors. In this paper, we propose a novel function-on-function regression model based on mode-sparsity regularization. The main idea is to represent the regression coefficient function between predictor and response as the double expansion of basis functions, and then use mode-sparsity constraint to automatically filter out the irrelevant basis functions for both predictors and responses. The mode-sparsity regularization covers a wide spectrum of sparse models for function-on-function regression. The resulting optimization problem is challenging due to the non-smooth property of the mode-sparsity. We develop an efficient and convergence-guaranteed algorithm to solve the problem. The effectiveness of the proposed approach is verified on benchmark functional data sets in various domains.",2016,International Conference on Data Mining,Fields of study: data modelingfood additivepredictive modellingconvergencelinear programmingdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Foundations of Perturbation Robust Clustering,Jarrod MooreMargareta Ackerman (University of Waterloo),"2549134806,2130881427","Clustering is a fundamental data mining tool that aims to divide data into groups of similar items. Intuition about clustering reflects the ideal case – exact data sets endowed with flawless dissimilarity between individual instances. In practice however, these cases are in the minority, and clustering applications are typically characterized by noisy data sets with approximate pairwise dissimilarities. As such, the efficacy of clustering methods necessitates robustness to perturbations. In this paper, we address foundational questions on perturbation robustness, studying to what extent can clustering techniques exhibit this desirable characteristic. Our results also demonstrate the type of cluster structures required for robustness of popular clustering paradigms.",2016,International Conference on Data Mining,Fields of study: flame clusteringbrown clusteringcanopy clustering algorithmdetermining the number of clusters in a data setdbscancorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmaffinity propagationfuzzy clusteringhamming distanceclustering high dimensional datafood additivehierarchical clusteringrobustnesscluster analysisalgorithm designconsensus clusteringbiclusteringconceptual clusteringstatistical classificationtheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Bi-Level Rare Temporal Pattern Detection,Dawei Zhou (Arizona State University)Jingrui He (Arizona State University)Yu CaoJae Sun Seo,"2303436841,2693123770,2679993904,2641893702","Nowadays, temporal data is generated at an unprecedentedspeed from a variety of applications, such as wearable devices, sensor networks, wireless networks, etc. In contrast to suchlarge amount of temporal data, it is usually the case that onlya small portion of them contains information of interest. Forexample, for the ECG signals collected by wearable devices, most of them collected from healthy people are normal, andonly a small number of them collected from people with certain heart diseases are abnormal. Furthermore, even forthe abnormal temporal sequences, the abnormal patterns mayonly be present in a few time segments and are similar amongthemselves, forming a rare category of temporal patterns. Forexample, the ECG signal collected from an individual with acertain heart disease may be normal in most time segments, and abnormal in only a few time segments, exhibiting similarpatterns. What is even more challenging is that such raretemporal patterns are often non-separable from the normalones. Existing works on outlier detection for temporal datafocus on detecting either the abnormal sequences as a whole, orthe abnormal time segments directly, ignoring the relationshipbetween abnormal sequences and abnormal time segments.Moreover, the abnormal patterns are typically treated asisolated outliers instead of a rare category with self-similarity. In this paper, for the first time, we propose a bi-level(sequence-level/ segment-level) model for rare temporal patterndetection. It is based on an optimization frameworkthat fully exploits the bi-level structure in the data, i.e., therelationship between abnormal sequences and abnormal timesegments. Furthermore, it uses sequence-specific simple hiddenMarkov models to obtain segment-level labels, and leverages the similarity among abnormal time segments to estimate the model parameters. To solve the optimization framework, we propose the unsupervised algorithm BIRAD, and also thesemi-supervised version BIRAD-K which learns from a single labeled example. Experimental results on both synthetic andreal data sets demonstrate the performance of the proposedalgorithms from multiple aspects, outperforming state-of-the-arttechniques on both temporal outlier detection and rarecategory analysis.",2016,International Conference on Data Mining,Fields of study: time serieshidden markov modeldata miningartificial intelligencemachine learningstatisticscomputer sciencemathematics
ConTrack: A Scalable Method for Tracking Multiple Concepts in Large Scale Multidimensional Data,"Ali ZonooziQirong Ho (Agency for Science, Technology and Research)Shonali Krishnaswamy (Monash University)Gao Cong (Nanyang Technological University)","2585323215,2680888243,1998595072,2295915604","In industrial domains such as finance, telecommunications, the internet, and sensor monitoring, large volumes of unlabeled temporal data are continuously generated, such as financial transactions, sensor measurements and user activities. From a data analysis standpoint, there is significant utility to be gained by detecting and understanding changes in the data, such as physical activity recognition and content consumption behavior, or anomalies and faults in robots and sensors. However, because the data is unlabeled, it is challenging to visualize and understand in a way that produces interpretable insights, furthermore, the large volume of data imposes a scalability requirement. In the concept drift and stream mining literature, existing methods may focus on one or two, but rarely all three, of the aforementioned aspects: unlabeled data, interpretable output, scalability. Addressing this need, we propose ConTrack, an unsupervised method that tracks multiple evolving concepts in temporal data, and which is parallelized over a cluster of machines. To enhance interpretability, our method structures its output at a per-user (or actor) level, where users subscribe to one or more evolving concepts. Our method applies to problem settings (multiple concepts, unsupervised data, temporal data, user-oriented data) that cannot be handled by existing concept drift and stream mining methods, and outperforms popular unsupervised baselines from the wider Data Mining and Machine Learning literature.",2016,International Conference on Data Mining,Fields of study: data modelingscalabilityalgorithm designactivity recognitiondata stream miningdata sciencedata miningmachine learningstatisticscomputer science
A Combinatorial Approach to Role Discovery,Albert ArockiasamyAristides Gionis (Aalto University)Nikolaj Tatti (Aalto University),"2280494886,737311942,1367500519","We provide a new formulation for theproblem of role discovery in graphs. Our definition is structural:two vertices should be assigned to the same roleif the roles of their neighbors, when viewed as multi-sets, are similar enough. An attractive characteristic of our approachis that it is based on optimizing a well-defined objective function, and thus, contrary to previous approaches, the role-discovery task can be studied with the tools of combinatorial optimization. We demonstrate that, when fixing the number of roles to be used, the proposed role-discovery problem is np-hard, while another (seemingly easier) version of the problem is np-hard to approximate. On the positive side, despite the recursive nature of our objective function, we can show that finding a perfect (zero-cost) role assignmentwith the minimum number of roles can be solved in polynomial time. We do this by connecting the zero-cost role assignment with the notion of equitable partition. For the more practical version of the problem with fixed number of roleswe present two natural heuristic methods, and discuss how to make them scalable in large graphs.",2016,International Conference on Data Mining,Fields of study: vehicle dynamicscluster analysislinear programmingcombinatoricsmachine learningmathematical optimizationalgorithmcomputer sciencemathematics
Fractality of Massive Graphs: Scalable Analysis with Sketch-Based Box-Covering Algorithm,Takuya Akiba (University of Tokyo)Kenko NakamuraTaro Takaguchi,"2149787982,2525123485,2524774679","Analysis and modeling of networked objects are fundamental pieces of modern data mining. Most real-world networks, from biological to social ones, are known to have common structural properties. These properties allow us to model the growth processes of networks and to develop useful algorithms. One remarkable example is the fractality of networks, which suggests the self-similar organization of global network structure. To determine the fractality of a network, we need to solve the so-called box-covering problem, where preceding algorithms are not feasible for large-scale networks. The lack of an efficient algorithm prevents us from investigating the fractal nature of large-scale networks. To overcome this issue, we propose a new box-covering algorithm based on recently emerging sketching techniques. We theoretically show that it works in near-linear time with a guarantee of solution accuracy. In experiments, we have confirmed that the algorithm enables us to study the fractality of million-scale networks for the first time. We have observed that its outputs are sufficiently accurate and that its time and space requirements are orders of magnitude smaller than those of previous algorithms.",2016,International Conference on Data Mining,Fields of study: greedy algorithmfractalalgorithm designapproximation algorithmtheoretical computer sciencecombinatoricsdata miningmachine learningmathematical optimizationalgorithmcomputer sciencemathematics
Flexible Similarity Search for Enriched Trajectories,Hideaki OhashiToshiyuki Shimizu (University of Tokyo)Masatoshi Yoshikawa (Kyoto University),"2653697060,2139847331,2307105024","In this study, we focus on a method of searching for similar trajectories. In most previous works on searching for similar trajectories, only raw trajectory data have been used. However, to obtain deeper insights, additional time-dependent trajectory features should be utilized depending on the search intent. For instance, to identify soccer players who have similar dribbling patterns, such additional features include the correlations between players' speeds and directions. In addition, when finding similar combination plays, the additional features include the team players' movements. In this paper, we develop a framework to flexibly search for similar trajectories associated with time-dependent features, called enriched trajectories. In this framework, weights, which represent the relative importance of each feature, can be flexibly input. Moreover, to facilitate fast searching, we propose a lower bounding measure of the DTW distance between enriched trajectories. We evaluate the effectiveness of the lower bounding measure using soccer data and synthetic data. Our experimental results suggest that the proposed lower bounding measure is superior to the existing measure and works very well.",2016,International Conference on Data Mining,Fields of study: informaticstrajectorytimedata miningmachine learningsimulation
Multiscale Analysis of Supply Network at Central Region in Japan,Yi Zuo (Nagoya University)Yuya Kajikawa,"2699490716,2669510412","Over the past decades, efficient supply chain management is recognized as a key strategic technology and resource in firms' success. Recent studies have been increasingly conducted network analysis in the fields of supply chain management and supplier-customer relationships. It is crucial to analyze interactional relationships and topological characteristics between suppliers and customers in supply networks rather than in traditionally linear supply chains. For this purpose, we involve a real-world supply network at central region in Japan in this paper and investigate different network structures of suppliercustomer relationships using network analysis techniques from three different scales. Firstly from the macro-scale, the network analysis approach provides clarity concerning network feature such as average path length. This feature can estimate the efficiency of material flow in the supply network, which also reveals the cost how passed to the final customers. Secondly from the meso-scale, we apply a network clustering algorithm to detect communities from the whole supply network, which is separated into five main supplier-customer communities. We also mark for individual communities via cross-location and crossindustry, which reveals the different features to bridge different business communities. Finally from the micro-scale, we extract core firms of each community using node degree-prior based on location-specific and industry-specific. We estimate the robustness of supply network by sequential elimination choice strategy of these hubs, which can also deliver efficient and effective support to supply network design and management.",2016,International Conference on Data Mining,Fields of study: service managementsupply chainmanufacturingmeasurementsupply chain management
Improved and Scalable Bradley-Terry Model for Collaborative Ranking,Jun HuPing Li,"2669332616,2658214974","In collaborative ranking, the Bradley-Terry (BT) model is widely used for modeling pairwise user preferences. However, when this model is combined with matrix factorization on sparsely observed ratings, a challenging identifiability issue arises since the optimization will involve non-convex constraints. Besides, in some situations, fitting the Bradley-Terry model yields a numerical challenge as it may include an objective function that is unbounded from below. In this paper, we will discuss and develop a simple strategy to resolve these issues. Specifically, we propose an Improved-BT model by adding a penalty term, and we develop two parallel algorithms to make Improved-BT model scalable. Through extensive experiments on benchmark datasets, we show that our proposed method outperforms many considered state-of-the-art collaborative ranking approaches in terms of both ranking performance and time efficiency.",2016,International Conference on Data Mining,Fields of study: collaborationsparse matrixpredictive modellingcomputational modellinear programmingdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Context-Specific Recommendation System for Predicting Similar PubMed Articles,Shahin Mohammadi (Purdue University)Sudhir B. Kylasa (Purdue University)Giorgios Kollias (University of Patras)Ananth Grama (Purdue University),"2151785273,708144890,2132498279,2714146875","Prioritizing a database of items in response to a given query object is a fundamental task in information retrieval and machine learning. We examine a specific realization of this problem in the context of a collection of biomedical articles. Given a query PubMed article, we investigate the problem of identifying and ranking recommended papers that are topically related to the query article. The two major classes of existing methods for this task are based on Natural Language Processing (NLP) techniques (including algebraic analyses), and those that incorporate structural information among articles, such as their co-citation networks or content similarity. In this paper, we propose a statistically rigorous method, called Context Specific Recommendation System (CSRS), along with associated algorithmic machinery to integrate structural and context-based sources of information to construct a single context-specific interaction network. We utilize this specialized network to rank papers (nodes) in terms of their similarity to query papers. Using a manually curated dataset of PubMed articles, we show that our method significantly outperforms other methods based on either the citation networks or content similarity of articles. Our methods provide a general framework that can be used to integrate other types of relationships into the recommendation process.",2016,International Conference on Data Mining,Fields of study: context modelprobabilistic logiccomputational modelworld wide webinformation retrievaldata miningmachine learningcomputer science
Semantic Enabled Recommender System for Micro-Blog Users,Stefano Faralli (University of Mannheim)Giorgia Di TommasoPaola Velardi (Sapienza University of Rome),"2531902733,2199060334,299152467","Quite a number of recent works have concentrated on the task of recommending to Twitter users whom they should follow, among which, the WTF (Who To Follow) service provided by Twitter. Recommenders are based either on the user's network structure, or on some notion of topical similarity with other users, or on both. We present a method for analysis of Twitter users supported by a hierarchical representation of their interests, which we call a Twixonomy. The use of Twixonomy casts both problems of user classification and recommendation as one of itemset mining, where items are either users' authoritative friends or semantic categories associated to friends. In addition to evaluating our profiler and recommender on several populations, we also show that semantic categories allow for very fine-grained population studies, and make it possible to recommend not only whom to follow, but also topics of interest, users interested in the same topic, and more.",2016,International Conference on Data Mining,Fields of study: encyclopediathe internetfeature extractionelectronic publishingsemanticsworld wide webinformation retrievaldata miningmachine learningcomputer science
Inferring Latent Network from Cascade Data for Dynamic Social Recommendation,"Qin Zhang (University of Technology, Sydney)Jia Wu (University of Technology, Sydney)Peng Zhang (University of Technology, Sydney)Guodong Long (University of Technology, Sydney)Ivor W. Tsang (Nanyang Technological University)Chengqi Zhang (University of Technology, Sydney)","2319377525,2151584597,2120503182,2570481200,2066523793,2166080598","Social recommendation explores social information to improve the quality of a recommender system. It can be further divided into explicit and implicit social network recommendation. The former assumes the existence of explicit social connections between users in addition to the rating data. The latter one assumes the availability of only the ratings but not the social connections between users since the explicit social information data may not necessarily be available and usually are binary decision values (e.g., whether two people are friends), while the strength of their relationships is missing. Most of the works in this field use only rating data to infer the latent social networks. They ignore the dynamic nature of users that the preferences of users drift over time distinctly. To this end, we propose a new Implicit Dynamic Social Recommendation (IDSR) model, which infers latent social network from cascade data. It can sufficiently mine the information contained in time by mining the cascade data and identify the dynamic changes in the users in time by using the latest updated social network to make recommendations. Experiments and comparisons on three real-world datasets show that the proposed model outperforms the state-of-the-art solutions in both explicit and implicit scenarios.",2016,International Conference on Data Mining,Fields of study: dynamic network analysisdata modelingprobabilistic logicpredictive modellingrecommender systemdata scienceworld wide webdata miningmachine learningcomputer science
Time-Based Ensembles for Prediction of Rare Events in News Stream,Nuno Moniz (Delgado Community College)Luis Torgo (University of Porto)Magdalini Eirinaki (San Jose State University),"1973478283,1973271071,242208127","Thousands of news are published everyday reporting worldwide events. Most of these news obtain a low level of popularity and only a small set of events become highly popular in social media platforms. Predicting rare cases of highly popular news is not a trivial task due to shortcomings of standard learning approaches and evaluation metrics. So far, the standard task of predicting the popularity of news items has been tackled by either of two distinct strategies related to the publication time of news. The first strategy, a priori, is focused on predicting the popularity of news upon their publication when related social feedback is unavailable. The second strategy, a posteriori, is focused on predicting the popularity of news using related social feedback. However, both strategies present shortcomings related to data availability and time of prediction. To overcome such shortcomings, we propose a hybrid strategy of time-based ensembles using models from both strategies. Using news data from Google News and popularity data from Twitter, we show that the proposed ensembles significantly improve the early and accurate prediction of rare cases of highly popular news.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingmeasurementdata scienceworld wide webdata miningmachine learningcomputer science
Partition Aware Connected Component Computation in Distributed Systems,Ha-Myung Park (KAIST)Namyong ParkSung-Hyon Myaeng (KAIST)U. Kang (KAIST),"2229610034,2632415566,2062572430,2615132872","How can we find all connected components in an enormous graph with billions of nodes and edges?Finding connected components is a fundamental operation for various graph computation tasks such as pattern recognition, reachability, graph compression, etc. Many algorithms have been proposed for decades, but most of them are not scalable enough to process recent web scale graphs. Recently, a MapReduce algorithm was proposed to handle such large graphs. However, the algorithm repeatedly reads and writes numerous intermediate data that cause network overload and prolong the running time. In this paper, we propose PACC (Partition-Aware Connected Components), a new distributed algorithm based on graph partitioning for load-balancing and edge-filtering. Experimental results show that PACC significantly reduces the intermediate data, and provides up to 10 times faster performance than the current state-of-the-art MapReduce algorithm on real world graphs.",2016,International Conference on Data Mining,Fields of study: graph partitionmemory managementalgorithm designcomputational modeldistributed databasedistributed algorithmtheoretical computer scienceparallel computingdistributed computingdata miningmachine learningcomputer science
The Optimal Distribution of Electric-Vehicle Chargers across a City,Chen Liu (RMIT University)Ke Deng (RMIT University)Chaojie Li (RMIT University)Jianxin Li (University of Western Australia)Yanhua Li (Worcester Polytechnic Institute)Jun Luo (Chinese Academy of Sciences),"2684110550,2688213377,2658886796,2647118311,2160296268,2658879683","It has been estimated that the cumulative sales of Electric Vehicles (EVs) will be up to 5.9 million and the stock of EVs will be up to 20 million by 2020 [1]. As the number of EVs is expanding, there is a growing need for widely distributed, publicly accessible, EV charging facilities. The public EV Chargers (EVCs) are expected to be found and will be needed where there is on-street parking, at taxi stands, in parking lots at places of employment, hotels, airports, shopping centres, convenience shops, fast food restaurants, and coffee houses, etc. In this work, we aim to optimize the distribution of public EVCs across the city such that (i) the overall revenue generated by the EVCs is maximized, subject to (ii) the overall driver discomfort (e.g., queueing time) for EV charging is minimized. This is the first study on EVC distribution where EVCs are assumed to be installed in almost all regions across a city. The problem is formulated using a bilevel optimization model. We propose an alternating framework to solve it and have proved that a local minima is achievable. Moreover, this work introduces novel methods to extract information to understand the discomfort of petroleum car drivers, EV charging demands, parking time and parking fees across the city. The source data explored include the trajectories of taxis, the distribution of petroleum stations and various local features. The empirical study uses the real data sets from Shenzhen City, one of the largest cities in China. The extensive tests verify the superiority of the proposed bilevel optimization model in all aspects.",2016,International Conference on Data Mining,Fields of study: petroleumbilevel optimizationsimulationcomputer sciencemathematics
Visualization Method Based on Contour Map,Rui YangYukio Ohsawa (University of Tokyo),"2585555651,2166087681","With the development of data science, the market of data also plays a significant role in the data mining domain gradually. This paper focus on how to use a visualization method based on contour map to seek the relationship between Data Jackets in order to create an innovative chance for data transaction. The analysis of results by questionnaires can illustrate the feasibility of this visualization tool for Data Jacket reasonably.",2016,International Conference on Data Mining,Fields of study: data flow diagramsingular value decompositionmatrix decompositioninformation visualizationdata visualizationsemanticsdata sciencedata miningmachine learningsimulationstatisticscomputer sciencemathematics
Generalized Independent Subspace Clustering,Wei Ye (Ludwig Maximilian University of Munich)Samuel Maurus (Technische Universität München)Nina Hubig (Technische Universität München)Claudia Plant (Florida State University),"2299720385,1989291604,2229410474,2122910652",Data can encapsulate different object groupings in subspaces of arbitrary dimension and orientation. Finding such subspaces and the groupings within them is the goal of generalized subspace clustering. In this work we present a generalized subspace clustering technique capable of finding multiple non-redundant clusterings in arbitrarily-oriented subspaces. We use Independent Subspace Analysis (ISA) to find the subspace collection that minimizes the statistical dependency (redundancy) between clusterings. We then cluster in the arbitrarily-oriented subspaces identified by ISA. Our algorithm ISAAC (Independent Subspace Analysis and Clustering) uses the Minimum Description Length principle to automatically choose parameters that are otherwise difficult to set. We comprehensively demonstrate the effectiveness of our approach on synthetic and real-world data.,2016,International Conference on Data Mining,Fields of study: data modelingkernelredundancyprincipal component analysiscluster analysisprobability density functionrandom variabledata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Structure-Preserved Multi-source Domain Adaptation,Hongfu Liu (Northeastern University)Ming Shao (Northeastern University)Yun Fu (Northeastern University),"2108071053,2106967882,2123131494","Domain adaptation has achieved promising results in many areas, such as image classification and object recognition. Although a lot of algorithms have been proposed to solve the task with different domain distributions, it remains a challenge for multi-source unsupervised domain adaptation. In addition, most of the existing algorithms learn a classifier on the source domain and predict the labels for the target data, which indicates that only the knowledge derived from the hyperplane is transferred to the target domain and the structure information is ignored. In light of this, we propose a novel algorithm for multi-source unsupervised domain adaptation. Generally speaking, we aim to preserve the whole structure from source domains and transfer it to serve the task on the target domain. The source and target data are put together for clustering, which simultaneously explores the structures of the source and target domains. The structure-preserved information from source domain further guides the clustering process on the target domain. Extensive experiments on two widely used databases on object recognition and face identification show the substantial improvement of our proposed approach over several state-of-the-art methods. Especially, our algorithm can take use of multi-source domains and achieve robust and better performance compared with the single source domain adaptation methods.",2016,International Conference on Data Mining,Fields of study: robustnesspredictioncluster analysislinear programmingdata miningpattern recognitionmachine learningstatisticscomputer science
A Pattern Growth-Based Approach for Mining Spatiotemporal Co-occurrence Patterns,Shah Muhammad HamdiBerkay Aydin (Georgia State University)Rafal A. Angryk (Georgia State University),"2398078868,2155808976,586699529","Spatiotemporal co-occurrence pattern (STCOP) mining refers to discovering the subsets of event types whose instances frequently co-locate in a spatial context and coincide in a temporal context. STCOP mining is the spatiotemporal extension to Frequent Itemset Mining (FIM). Unlike the classical FIM approaches, which are applied on transactional databases, STCOP mining is applied on the spatiotemporal datasets comprised of event instances which are represented by evolving region trajectories. Previous STCOP mining algorithms are Apriori-based, where the number of candidate patterns can grow exponentially with the number of event types. In this work, we present a pattern growth-based approach for mining STCOPs, which allows us to discover STCOPs without computationally expensive candidate generation processes. We experimented our algorithm with four real-life solar event datasets and compared its performance with the earlier Apriori-based approach.",2016,International Conference on Data Mining,Fields of study: trajectorysearch engine indexingalgorithm designdata sciencedata miningmachine learningcomputer science
Scalable Online-Offline Stream Clustering in Apache Spark,Omar BackhoffEirini Ntoutsi (Ludwig Maximilian University of Munich),"2583398726,147176459","Two of the most popular approaches for dealing with big data are distributed computing and stream mining. In this paper, we incorporate both approaches in order to bring a competitive stream clustering algorithm, namely CluStream, into a modern framework for distributed computing, namely, Apache Spark. CluStream is one of the most popular clustering approaches for stream clustering and the one that introduced the online-offline mining process: the online phase summarizes the stream through statistical summaries and the offline phase generates the final clusters upon these summaries. We obtain a scalable stream clustering method which is open source and can be used by the Apache Spark community. Our experiments show that our adaptation, our achieves similar quality to the original approach, while it is more efficient.",2016,International Conference on Data Mining,Fields of study: canopy clustering algorithmdata stream clusteringcure data clustering algorithmcluster analysisalgorithm designdata stream miningbig dataworld wide webdata miningdatabasecomputer science
HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles for Time Series Classification,Jason Lines (University of East Anglia)Sarah TaylorAnthony Bagnall (University of East Anglia),"1984663852,2657080138,2171856547","There have been many new algorithms proposed over the last five years for solving time series classification (TSC) problems. A recent experimental comparison of the leading TSC algorithms has demonstrated that one approach is significantly more accurate than all others over 85 datasets. That approach, the Flat Collective of Transformation-based Ensembles (Flat-COTE), achieves superior accuracy through combining predictions of 35 individual classifiers built on four representations of the data into a flat hierarchy. Outside of TSC, deep learning approaches such as convolutional neural networks (CNN) have seen a recent surge in popularity and are now state of the art in many fields. An obvious question is whether CNNs could be equally transformative in the field of TSC. To test this, we implement a common CNN structure and compare performance to Flat-COTE and a recently proposed time series-specific CNN implementation. We find that Flat-COTE is significantly more accurate than both deep learning approaches on 85 datasets. These results are impressive, but Flat-COTE is not without deficiencies. We improve the collective by adding new components and proposing a modular hierarchical structure with a probabilistic voting scheme that allows us to encapsulate the classifiers built on each transformation. We add two new modules representing dictionary and interval-based classifiers, and significantly improve upon the existing frequency domain classifiers with a novel spectral ensemble. The resulting classifier, the Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE) is significantly more accurate than Flat-COTE and represents a new state of the art for TSC. HIVE-COTE captures more sources of possible discriminatory features in time series and has a more modular, intuitive structure.",2016,International Conference on Data Mining,Fields of study: predictiontime seriesstatistical classificationdata miningartificial intelligencemachine learningstatisticscomputer sciencemathematics
Selecting Valuable Customers for Merchants in E-Commerce Platforms,Yijun WangLe Wu (University of Science and Technology of China)Zongda Wu (Wenzhou University)Enhong Chen (University of Science and Technology of China)Qi Liu (University of Science and Technology of China),"2583949938,2181678313,2162511255,2136372366,2420624292","An e-commerce website provides a platform for merchants to sell products to customers. While most existing research focuses on providing customers with personalized product suggestions by recommender systems, in this paper, we consider the role of merchants and introduce a parallel problem, i.e., how to select the most valuable customers for a merchant? Accurately answering this question can not only help merchants to gain more profits, but also benefit the ecosystem of e-commence platforms. To deal with this problem, we propose a general approach by taking into consideration the interest and profit of each customer to the merchant, i.e., select the customers who are not only interested in the merchant to ensure the visit of the merchant, but also capable of making good profits. Specifically, we first generate candidate customers for a given merchant by using traditional recommendation techniques. Then we select a set of the valuable customers from candidate customers, which has the balanced maximization between the interest and the profit metrics. Given the NP-hardness of the balanced maximization formulation, we further introduce efficient techniques to solve this maximization problem by exploiting the inherent submodularity property. Finally, extensive experimental results on a real-world dataset demonstrate the effectiveness of our proposed approach.",2016,International Conference on Data Mining,Fields of study: collaborationmeasurementmathematical modelrecommender systemdata miningstatisticscomputer sciencemathematics
Sparse Factorization Machines for Click-through Rate Prediction,Zhen PanEnhong Chen (University of Science and Technology of China)Qi Liu (University of Science and Technology of China)Tong Xu (University of Science and Technology of China)Haiping Ma (University of Science and Technology of China)Hongjie Lin,"2583360825,2136372366,2420624292,2291800725,2106930699,2719197278","With the rapid development of E-commerce, recent years have witnessed the booming of online advertising industry, which raises extensive concerns of both academic and business circles. Among all the issues, the task of Click-through rates (CTR) prediction plays a central role, as it may influence the ranking and pricing of online ads. To deal with this task, the Factorization Machines (FM) model is designed for better revealing proper combinations of basic features. However, the sparsity of ads transaction data, i.e., a large proportion of zero elements, may severely disturb the performance of FM models. To address this problem, in this paper, we propose a novel Sparse Factorization Machines (SFM) model, in which the Laplace distribution is introduced instead of traditional Gaussian distribution to model the parameters, as Laplace distribution could better fit the sparse data with higher ratio of zero elements. Along this line, it will be beneficial to select the most important features or conjunctions with the proposed SFM model. Furthermore, we develop a distributed implementation of our SFM model on Spark platform to support the prediction task on mass dataset in practice. Comprehensive experiments on two large-scale real-world datasets clearly validate both the effectiveness and efficiency of our SFM model compared with several state-of-the-art baselines, which also proves our assumption that Laplace distribution could be more suitable to describe the online ads transaction data.",2016,International Conference on Data Mining,Fields of study: data modelingfrequency modulationpredictive modellingnormal distributionmathematical modeldata miningmachine learningsimulationstatisticscomputer sciencemathematics
Segmenting Sequences of Node-Labeled Graphs,Sorour E. AmiriLiangzhe Chen (Virginia Tech)B. Aditya Prakash (Virginia Tech),"2583757764,2229907346,2124002246","Detection of the changes in pattern of disease spread over a population network, Meme-tracking and opinion spread on the Twitter network and product-rating-cascade over a social network are a few among the many embodiments of graph sequence segmentation problem with labeled nodes. Most of the previous approaches to network sequence segmentation are on plain graphs without considerations for the dynamics of propagation process. These approaches either fix observation scales or extract a long list of expensive features. In this paper, we propose SNAPNETS a parameter free, and comprehensive algorithm, to find segmentation of networks sequences with node labels such that adjacent segments are different in characteristics of nodes of each label. Our method leverages a principled, multi-level, flexible framework which maps the original problem to a path optimization problem over a weighted DAG. Extensive experiments on several diverse real datasets show that our method finds cut points matching ground-truth or meaningful external signals outperforming non-trivial baselines.",2016,International Conference on Data Mining,Fields of study: feature extractiondata miningpattern recognitionmachine learningstatisticscomputer science
Identifying Warning Behaviors of Violent Lone Offenders in Written Communication,Lisa Kaati (Fruit of Islam)Amendra Shrestha (Uppsala University)Tony Sardella,"297243639,2161520532,2584288339","Violent lone offenders such as school shooters and lone actor terrorists pose a threat to the modern society but since they act alone or with minimal help form others they are very difficult to detect. Previous research has shown that violent lone offenders show signs of certain psychological warning behaviors that can be viewed as indicators of an increasing or accelerating risk of committing targeted violence. In this work, we use a machine learning approach to identify potential violent lone offenders based on their written communication. The aim of this work is to capture psychological warning behaviors in written text and identify texts written by violent lone offenders. We use a set of features that are psychologically meaningful based on the different categories in the text analysis tool Linguistic Inquiry and Word Count (LIWC). Our study only contains a small number of known perpetrators and their written communication but the results are promising and there are many interesting directions for future work in this area.",2016,International Conference on Data Mining,Fields of study: terrorismpragmaticstext miningcomputer securitycomputer science
Asymptotic Analysis of Equivalences and Core-Structures in Kronecker-Style Graph Models,Alex J. ChinTimothy D. Goodrich (North Carolina State University)Michael P. OBrien (North Carolina State University)Felix Reidl (RWTH Aachen University)Blair D. Sullivan (North Carolina State University)Andrew van der Poel,"2630592937,2553233028,2510350849,174249309,2097060976,2554316483","Growing interest in modeling large, complexnetworks has spurred significant research into generative graphmodels. Kronecker-style models (e.g. SKG and R-MAT) are oftenused due to their scalability and ability to mimic key propertiesof real-world networks. Although a few papers theoreticallyestablish these models' behavior for specific parameters, manyclaims used to justify their use are supported only empirically. In this work, we prove several results using asymptotic analysiswhich illustrate that empirical studies may not fully capture thetrue behavior of the models. Paramount to the widespread adoption of Kronecker-stylemodels was the introduction of a linear-time edge-samplingvariant (R-MAT), which existing literature typically treats asinterchangeable with SKG. We prove that although several R-MAT formulations are asymptotically equivalent, their behaviordiverges from that of SKG. Further, we show these resultsare observable even at relatively small graph sizes. Second, weconsider a case where asymptotic analysis reveals unexpectedbehavior within a given model.",2016,International Conference on Data Mining,Fields of study: limitingdata modelingsparse matrixcomputational modelstochastic processcombinatoricseconometricsmachine learningstatisticscomputer sciencemathematics
Learning Task Relational Structure for Multi-task Feature Learning,De Wang (University of Texas at Arlington)Feiping Nie (University of Texas at Arlington)Heng Huang (University of Texas at Arlington),"2147695980,2245267964,2137533801","In multi-task learning, it is paramount to discover the relational structure of tasks and utilize the learned task structure. Previous works have been using the low-rank latent feature subspace to capture the task relations, and some of them aim to learn the group based relational structure of tasks. However, in many cases, the low-rank subspace may not exist for the specific group of tasks, thus using this paradigm would not work. To discover the task relational structures, we propose a novel multi-task learning method using the structured sparsity-inducing norms to automatically uncover the relations of tasks. Instead of imposing the low-rank constraint, our new model uses a more meaningful assumption, in which the tasks from the same relational group should share the common feature subspace. We can discover the group relational structure of tasks and learn the shared feature subspace for each task group, which help to improve the predictive performance. Our proposed algorithm avoids the high computational complexity of integer programming, thus it converges very fast. Empirical studies conducted on both synthetic and real-world data show that our method consistently outperforms related multi-task learning methods.",2016,International Conference on Data Mining,Fields of study: multi task learningalgorithm designcomputational modelstatistical relational learninglinear programmingdata miningpattern recognitionmachine learningcomputer science
Learning Deep Networks from Noisy Labels with Dropout Regularization,Ishan Jindal (Wayne State University)Matthew S. NoklebyXuewen Chen,"2589072683,2640131058,2585861288","Large datasets often have unreliable labels—such as those obtained from Amazon's Mechanical Turk or social media platforms—and classifiers trained on mislabeled datasets often exhibit poor performance. We present a simple, effective technique for accounting for label noise when training deep neural networks. We augment a standard deep network with a softmax layer that models the label noise statistics. Then, we train the deep network and noise model jointly via end-to-end stochastic gradient descent on the (perhaps mislabeled) dataset. The augmented model is underdetermined, so in order to encourage the learning of a non-trivial noise model, we apply dropout regularization to the weights of the noise model during training. Numerical experiments on noisy versions of the CIFAR-10 and MNIST datasets show that the proposed dropout technique outperforms state-of-the-art methods.",2016,International Conference on Data Mining,Fields of study: noise measurementcomputational modeldeep learningsupervised learningspeech recognitionpattern recognitionmachine learningstatisticscomputer science
HLGPS: A Home Location Global Positioning System in Location-Based Social Networks,Yulong Gu (Tsinghua University)Jiaxing Song (Tsinghua University)Weidong Liu (Tsinghua University)Lixin Zou,"2529910450,2153428977,2699457322,2553379489","The rapid spread of mobile internet and location-acquisition technologies have led to the increasing popularity of Location-Based Social Networks(LBSNs). Users in LBSNs can share their life by checking in at various venues at any time. In LBSNs, identifying home locations of users is significant for effective location-based services like personalized search, targeted advertisement, local recommendation and so on. In this paper, we propose a Home Location Global Positioning System called HLGPS to tackle with the home location identification problem in LBSNs. Firstly, HLGPS uses an influence model named as IME to model edges in LBSNs. Then HLGPS uses a global iteration algorithm based on IME model to position home location of users so that the joint probability of generating all the edges in LBSNs is maximum. Extensive experiments on a large real-world LBSN dataset demonstrate that HLGPS significantly outperforms state-of-the-art methods by 14.7%.",2016,International Conference on Data Mining,Fields of study: data modelingatmospheric modelglobal positioning systemmathematical modeldata miningsimulationcomputer science
One-Class SVM with Privileged Information and Its Application to Malware Detection,Evgeny Burnaev (Russian Academy of Sciences)Dmitry Smolyakov,"2187681102,2658075939","A number of important applied problems in engineering, finance and medicine can be formulated as a problem of anomaly detection. A classical approach to the problem is to describe a normal state using a one-class support vector machine. Then to detect anomalies we quantify a distance from a new observation to the constructed description of the normal class. In this paper we present a new approach to the one-class classification. We formulate a new problem statement and a corresponding algorithm that allow taking into account a privileged information during the training phase. We evaluate performance of the proposed approach using a synthetic dataset, as well as the publicly available Microsoft Malware Classification Challenge dataset.",2016,International Conference on Data Mining,Fields of study: malwaresupport vector machinefeature extractioncomputer securitydata miningmachine learningcomputer science
Tovel: Distributed Graph Clustering for Word Sense Disambiguation,Alessio Guerrieri (University of Trento)Fatemeh Rahimian (Swedish Institute of Computer Science)Sarunas Girdzijauskas (Royal Institute of Technology)Alberto Montresor (University of Trento),"2115388923,2042985758,2466695098,1308236497","Word sense disambiguation is a fundamental problem in natural language processing (NLP). In this problem, a large corpus of documents contains mentions to well-known (non-ambiguous) words, together with mentions to ambiguous ones. The goal is to compute a clustering of the corpus, such that documents that refer to the same meaning appear in the same cluster, subsequentially, each cluster is assigned to a different semantic meaning. In this paper, we propose a mechanism for word sense disambiguation based on distributed graph clustering that is incremental in nature and can scale to big data. A novel, heuristic vertex-centric algorithm based on the metaphor of the water cycle is used to cluster the graph. Our approach is evaluated on real datasets in both centralized and decentralized environments.",2016,International Conference on Data Mining,Fields of study: semevalcluster analysisnatural language processinginformation retrievaldata miningmachine learningcomputer science
House Price Modeling over Heterogeneous Regions with Hierarchical Spatial Functional Analysis,Bang LiuBorislav MavrinDi NiuLinglong Kong (University of Alberta),"2668340917,2585321462,2650039868,2133169385","Online real-estate information systems such as Zillow and Trulia have gained increasing popularity in recent years. One important feature offered by these systems is the online home price estimate through automated data-intensive computation based on housing information and comparative market value analysis. State-of-the-art approaches model house prices as a combination of a latent land desirability surface and a regression from house features. However, by using uniformly damping kernels, they are unable to handle irregularly shaped regions or capture land value discontinuities within the same region due to the existence of implicit sub-communities, which are common in real-world scenarios. In this paper, we explore the novel application of recent advances in spatial functional analysis to house price modeling and propose the Hierarchical Spatial Functional Model (HSFM), which decomposes house values into land desirability at both the global scale and hidden local scales as well as the feature regression component. We propose statistical learning algorithms based on finite-element spatial functional analysis and spatial constrained clustering to train our model. Extensive evaluations based on housing data in a major Canadian city show that our proposed approach can reduce the mean relative house price estimation error down to 6.60%.",2016,International Conference on Data Mining,Fields of study: data modelingkernelsolid modelingcomputational modeleconometricsdata miningmachine learningsimulationstatisticscomputer sciencemathematics
A Probabilistic Address Parser Using Conditional Random Fields and Stochastic Regular Grammar,"Minlue Wang (Goldsmiths, University of London)Valeriia Haberland (Goldsmiths, University of London)Amos YeoAndrew O. Martin (University of London)John Howroyd (Goldsmiths, University of London)J. Mark Bishop (Goldsmiths, University of London)","2592727671,2617214115,2583392915,2154469602,2057684122,2153638239","Automatic semantic annotation of data from databases or the web is an important pre-process for data cleansing and record linkage. It can be used to resolve the problem of imperfect field alignment in a database or identify comparable fields for matching records from multiple sources. The annotation process is not trivial because data values may be noisy, such as abbreviations, variations or misspellings. In particular, overlapping features usually exist in a lexicon-based approach. In this work, we present a probabilistic address parser based on linear-chain conditional random fields (CRFs), which allow more expressive token-level features compared to hidden Markov models (HMMs). In additions, we also proposed two general enhancement techniques to improve the performance. One is taking original semi-structure of the data into account. Another is post-processing of the output sequences of the parser by combining its conditional probability and a score function, which is based on a learned stochastic regular grammar (SRG) that captures segment-level dependencies. Experiments were conducted by comparing the CRF parser to a HMM parser and a semi-Markov CRF parser in two real-world datasets. The CRF parser out-performed the HMM parser and the semi-Markov CRF in both datasets in terms of classification accuracy. Leveraging the structure of the data and combining the linear-chain CRF with the SRG further improved the parser to achieve an accuracy of 97% on a postal dataset and 96% on a company dataset.",2016,International Conference on Data Mining,Fields of study: glr parsersimple lr parserparser combinatortop down parsingrecursive descent parserlr parsergrammarcouplingsemanticsnatural language processingdata miningpattern recognitionmachine learningcomputer science
Steering Social Media Promotions with Effective Strategies,Kun KuangMeng Jiang (Tsinghua University)Peng Cui (Tsinghua University)Shiqiang Yang (Tsinghua University),"2584736634,2115305989,2113115369,2127183023","On social media platforms, companies, organizations and individuals are using the function of sharing or retweeting information to promote their products, policies, and ideas. While a growing body of research has focused on identifying the promoters from millions of users, the promoters themselves are seeking to know what strategies can improve promotional effectiveness, which is rarely studied in literature. In this work, we study a new problem of promotional strategy effect estimation which is challenging in identifying and quantifying promotional strategies, as well as estimating effectiveness of promotional strategies with selection bias in observational data. Here we study a series of strategies on both context and content levels. To alleviate the selection bias issue, we propose a method based on Propensity Score Matching (PSM) to evaluate the effect of each promotional strategy. Our data study provides three interpretable and insightful ideas on steering social media promotions, including (1) three significant and stable strategies, (2) a critical trade-off, and (3) different concerns for promoters of different popularity. These results provided comprehensive suggestions to the practitioners to steer social media promotions with effective strategies.",2016,International Conference on Data Mining,Fields of study: estimationdata miningstatisticscomputer sciencemathematics
Mining Vessel Tracking Data for Maritime Domain Applications,Alfredo Alessandrini (Institute for the Protection and Security of the Citizen)Marlene Alvarez (Judge Rotenberg Educational Center)Harm Greidanus (Judge Rotenberg Educational Center)Vincenzo Gammieri (Judge Rotenberg Educational Center)Virginia Fernandez Arguedas (Queen Mary University of London)Fabio Mazzarella (Judge Rotenberg Educational Center)Carlos Santamaria (Judge Rotenberg Educational Center)Mattia Stasolla (Judge Rotenberg Educational Center)Dario Tarchi (Judge Rotenberg Educational Center)Michele Vespe (Judge Rotenberg Educational Center),"2591164771,2114697385,2304903040,2515546510,1439591068,2080410797,2608140273,2343023118,2013521881,2067067675","The growing number of remote sensing systems and ship reporting technologies (e.g. Automatic Identification System, Long Range Identification and Tracking, radar tracking, Earth Observation) are generating an overwhelming amount of spatio-temporal and geographically distributed data related to vessels and their movements. Research on reliable data mining techniques has proven essential to the discovery of knowledge from such increasingly available information on ship traffic at sea. Data driven knowledge discovery has very recently demonstrated its value in fields that go beyond the original maritime safety and security remits of such data. They include, but are not limited to, fisheries management, maritime spatial planning, gridding ship emissions, mapping activities at sea, risk assessment of offshore platforms, and trade indicators. The extraction of useful information from maritime Big Data is thus a key element in providing operational authorities, policy-makers and scientists with supporting tools to understand what is happening at sea and improve maritime knowledge. This work will provide a survey of the recent JRC research activities relevant to automatic anomaly detection and knowledge discovery in the maritime domain. Data mining, data analytics and predictive analysis examples are introduced using real data. In addition, this paper presents approaches to detect anomalies in reporting messages and unexpected behaviours at sea.",2016,International Conference on Data Mining,Fields of study: radar trackerknowledge extractioninformation securitydata scienceoperations researchdata miningcomputer science
Predicting User Roles in Social Networks Using Transfer Learning with Feature Transformation,Jun SunJerome Kunegis (Technical University of Berlin)Steffen Staab (University of Southampton),"2583944580,2232072325,2649946695","How can we recognise social roles of people, given a completely unlabelled social network? We may train a role classification algorithm on another dataset, but then that dataset may have largely different values of its features, for instance, the degrees in the other network may be distributed in a completely different way than in the first network. Thus, a way to transfer the features of different networks to each other or to a common feature space is needed. This type of setting is called transfer learning. In this paper, we present a transfer learning approach to network role classification based on feature transformations from each network's local feature distribution to a global feature space. We implement our approach and show experiments on real-world networks of discussions on Wikipedia as well as online forums. We also show a concrete application of our approach to an enterprise use case, where we predict the user roles in ARIS Community, the online platform for customers of Software AG, the second-largest German software vendor. Evaluation results show that our approach is suitable for transferring knowledge of user roles across networks.",2016,International Conference on Data Mining,Fields of study: dynamic network analysismatrix decompositionfeature extractioncluster analysisalgorithm designknowledge engineeringdata sciencedata miningmachine learningcomputer science
Multi-sentiment Modeling with Scalable Systematic Labeled Data Generation via Word2Vec Clustering,Dhruv MayankKanchana Padmanabhan (North Carolina State University)Koushik Pal,"2584393295,2160647508,2687490837","Social networks are now a primary source for news and opinions on topics ranging from sports to politics. Analyzing opinions with an associated sentiment is crucial to the success of any campaign (product, marketing, or political). However, there are two significant challenges that need to be overcome. First, social networks produce large volumes of data at high velocities. Using traditional (semi-) manual methods to gather training data is, therefore, impractical and expensive. Second, humans express more than two emotions, therefore, the typical binary good/bad or positive/negative classifiers are no longer sufficient to address the complex needs of the social marketing domain. This paper introduces a hugely scalable approach to gathering training data by using emojis as proxy for user sentiments. This paper also introduces a systematic Word2Vec based clustering method to generate emoji clusters that arguably represent different human emotions (multi-sentiment). Finally, this paper also introduces a threshold-based formulation to predicting one or two class labels (multi-label) for a given document. Our scalable multi-sentiment multi-label model produces a cross-validation accuracy of 71.55% (± 0.22%). To compare against other models in the literature, we also trained a binary (positive vs. negative) classifier. It produces a cross-validation accuracy of 84.95% (± 0.17%), which is arguably better than several results reported in literature thus far.",2016,International Conference on Data Mining,Fields of study: data scienceworld wide webdata miningmachine learningstatisticscomputer science
Risk Mining: Company-Risk Identification from Unstructured Sources,Timothy Nugent (Thomson Reuters)Jochen L. Leidner (Thomson Reuters),"2282930443,1530681346","Risk permeates all aspects of doing business. However, support tools capable of systematically identifying the complete spectrum of risks that a company might face are currently lacking. Such a tool would need to reliably identify company-risk relationships from unstructured sources, therefore providing a qualitative assessment of risk exposure. We propose a supervised learning approach that combines a weakly-supervised risk taxonomy, named entity tagging and dependency tree analysis in order to perform company-risk relationship classification. We demonstrate that a support vector machine using a tree kernel, trained on hand-annotated articles from Reuters News Archive, is capable of significantly outperforming a selection of alternative classification algorithms. To our knowledge, this is the first example of company-risk relationship extraction.",2016,International Conference on Data Mining,Fields of study: processor registerlogisticskernelsupport vector machinetaxonomydata sciencedata miningpattern recognitionmachine learningcomputer science
A Bayesian Nonparametric Approach to Dynamic Dyadic Data Prediction,Fengyuan Zhu (The Chinese University of Hong Kong)Guangyong Chen (The Chinese University of Hong Kong)Pheng-Ann Heng (The Chinese University of Hong Kong),"2308431903,2100465665,2166341251","An important issue of using matrix factorization for recommender systems is to capture the dynamics of user preference over time for more accurate prediction. We find that considering the existence of clusters among users with respect to evolution behavior of their preference can improve performance effectively. This is especially important to commercial recommender systems, where the evolution of preference for different users is heterogeneous, and historical ratings are not enough to estimate the preference of each user individually. Based on this, we propose a novel Bayesian nonparametric method based on the Dirichlet process, to detect users sharing the same evolution behavior of their preference. For each community, we use vector autoregressive model (VAR) to capture the evolution to explore higher-order dependency on historical user preference, and incorporate this feature with a novel adaptive prior strategy. We also derive variational inference approach to infer our method. Finally, we conduct extensive empirical experiments to show the advantage of our method over state-of-the-art algorithms.",2016,International Conference on Data Mining,Fields of study: ac powergoldkalman filtereconometricsdata miningmachine learningstatisticscomputer science
Detecting Performance Degradation of Software-Intensive Systems in the Presence of Trends and Long-Range Dependence,Alexey Artemov (Yandex)Evgeny Burnaev (Russian Academy of Sciences),"2234320037,2187681102","As contemporary software-intensive systems reach increasingly large scale, it is imperative that failure detection schemes be developed to help prevent costly system downtimes. A promising direction towards the construction of such schemes is the exploitation of easily available measurements of system performance characteristics such as average number of processed requests and queue size per unit of time. In this work, we investigate a holistic methodology for detection of abrupt changes in time series data in the presence of quasi-seasonal trends and long-range dependence with a focus on failure detection in computer systems. We propose a trend estimation method enjoying optimality properties in the presence of long-range dependent noise to estimate what is considered ""normal"" system behaviour. To detect change-points and anomalies, we develop an approach based on the ensembles of ""weak"" detectors. We demonstrate the performance of the proposed change-point detection scheme using an artificial dataset, the publicly available Abilene dataset as well as the proprietary geoinformation system dataset.",2016,International Conference on Data Mining,Fields of study: principal component analysistime seriesmaximum likelihoodmarket researcheconometricsdata miningsimulationstatisticsmathematics
Streaming Model Selection via Online Factorized Asymptotic Bayesian Inference,Chunchen Liu (NEC)Lu Feng (NEC)Ryohei Fujimaki,"2666162098,2490264489,2670092663","Recent growing needs for real time data analytics have increased importance of streaming model selection. Real-world streaming observations are often obtained by dynamically-changing or heterogeneous data sources, and learning machines must identify the complexities of the data generation processes on the fly without prior knowledge. This paper proposes online FAB (OFAB) inference as a general framework for streaming model selection of latent variable models. The key idea in OFAB inference is degeneration, i.e. it intentionally considers a ""redundant"" latent space anddynamically derives a ""non-redundant"" latent sub-space using a FAB-unique shrinkage mechanism on demand. By integrating the idea of stochastic variational inference, OFAB automatically and dynamically selects the best dimensionality of latent variables in a streaming and Bayesian principled manner. Empirical results on two applications, density estimation and abnormal detection, show that online FAB (OFAB) outperformed the state-of-the-art online inference methods.",2016,International Conference on Data Mining,Fields of study: frequentist inferencedata modelinghidden markov modelstochastic processeconometricsdata miningmachine learningstatisticscomputer science
Optimizing the Multiclass F-Measure via Biconcave Programming,Harikrishna Narasimhan (Indian Institute of Science)Weiwei PanPurushottam Kar (Indian Institute of Technology Kanpur)Pavlos ProtopapasHarish G. Ramaswamy (Indian Institute of Science),"2687957994,2583669159,2136781283,2720129894,1982179918","The F-measure and its variants are performance measures of choice for evaluating classification and retrieval tasks in the presence of severe class imbalance. It is thus highly desirable to be able to directly optimize these performance measures on large-scale data. Recent advances have shown that this is possible in the simple binary classification setting. However, scant progress exists in multiclass settings with a large number of classes where, in addition, class-imbalance is much more severe. The lack of progress is especially conspicuous for the macro-averaged F-measure, which is the widely preferred F-measure variant in multiclass settings due to its equal emphasis on rare classes. Known methods of optimization scale poorly for macro F-measure, often requiring run times that are exponential in the number of classes. We develop BEAM-F, the first efficient method for directly optimizing the macro F-measure in multiclass settings. The challenge here is the intractability of optimizing a sum of fractional-linear functions over the space of confusion matrices. We overcome this difficulty by formulating the problem as a biconcave maximization program and solve it using an efficient alternating maximization approach that involves a Frank-Wolfe based iterative solver. Our approach offers guaranteed convergence to a stationary point and experiments show that, for a range synthetic data sets and real-world applications, our method offers superior performance on problems exhibiting large class imbalance.",2016,International Conference on Data Mining,Fields of study: support vector machineharmonic analysisdata miningmachine learningmathematical optimizationstatisticsalgorithmmathematics
Unsupervised Exceptional Attributed Sub-Graph Mining in Urban Data,Ahmed Anes BendimeradMarc Plantevit (University of Lyon)Celine Robardet (University of Lyon),"2585650547,107359601,1976373341","Geo-located social media provide a wealth of information that describes urban areas based on user descriptions and comments. Such data makes possible to identify meaningful city neighborhoods on the basis of the footprints left by a large and diverse population that uses this type of media. In this paper, we present some methods to exhibit the predominantactivities and their associated urban areas to automatically describe a whole city. Based on a suitable attributed graph model, our approach identifies neighborhoods with homogeneous and exceptional characteristics. We introduce the novel problem of exceptional sub-graph mining in attributed graphs and propose a complete algorithm that takes benefits from new upper bounds and pruning properties. We also propose an approach to sample the space of exceptional sub-graphs within a given time-budget. Experiments performed on 10 real datasets are reported and demonstrate the relevancy and the limits of both approaches.",2016,International Conference on Data Mining,Fields of study: space explorationalgorithm designupper and lower boundsdata sciencedata miningmachine learningcomputer sciencemathematics
Stereotypical Motor Movement Detection in Dynamic Feature Space,Nastaran Mohammadian RadSeyed Mostafa KiaCalogero Zarbo (fondazione bruno kessler)Giuseppe Jurman (fondazione bruno kessler)Paola Venuti (University of Trento)Cesare Furlanello (fondazione bruno kessler),"2566318278,2700480599,2585942964,125273320,2153396133,11746710","Stereotypical Motor Movements (SMMs) are abnormal postural or motor behaviors that interfere with learning and social interaction in Autism Spectrum Disorder patients. An automatic SMM detection system, employing inertial sensing technology, provides a useful tool for real-time alert on the onset of these atypical behaviors, therefore facilitating personalized intervention therapies. To tackle critical issues with inter-subject variability, in this study, we propose to combine long short-term memory (LSTM) with convolutional neural network (CNN) to model the temporal patterns in the sequence of multi-axes IMU signals. Our results, on one simulated and two experimental datasets, show that transferring the raw feature space to a dynamic feature space via the proposed architecture enhances the performance of automatic SMM detection system especially for skewed training data. These findings facilitate the application of SMM detection system in real-time scenarios.",2016,International Conference on Data Mining,Fields of study: accelerometerfeature extractiondetectoractivity recognitioncomputer visionmachine learningsimulationcomputer science
Vertex Centric Asynchronous Belief Propagation Algorithm for Large-Scale Graphs,Gabriel P. Gimenes (Spanish National Research Council)Hugo Gualdron (Spanish National Research Council)Jose F. Rodrigues (University of São Paulo),"2092667848,437589578,2132218131","Inference problems on networks and their algorithms were always important subjects, but more so now with so much data available and so little time to make sense of it. Common applications range from product recommendation to social networks and protein interaction. One of the main inferences in this types of networks is the guilty-by-association method, where labeled nodes propagate their information throughout the network, towards unlabeled nodes. While there is a widely used algorithm for this context, called Belief Propagation, it lacks the necessary convergence guarantees for loopy-networks. More recently, a new alternative method was proposed, called LinBP and while it solved the convergence issue, the scalability for large graphs that do not fit memory remains a challenge. Additionally, most works that try to use BP considering large scale graphs rely on specific infrastructure such as supercomputers and computational clusters. Therefore we propose a new algorithm, that leverages state-of-the-art asynchronous vertex-centric parallel processing techniques in conjunction with the state-of-the-art BP alternative LinBP, to provide a scalable framework for large graph inference that runs on a single commodity machine. Our results show that our algorithm is up to 200 times faster than LinBP's SQL implementation on tested networks, while achieving the same accuracy rate. We also show that due to the asynchronous processing, our algorithm actually needs less iterations to converge when compared to LinBP when using the same parameters. Finally, we believe that our methodology highlights the yet not fully explored parallelism available on commodity machines, leaning towards a more cost-efficient computational paradigm.",2016,International Conference on Data Mining,Fields of study: belief propagationcouplingconvergencealgorithm designcomputational modelparallel processingtheoretical computer sciencedistributed computingdata miningmachine learningstatisticscomputer sciencemathematics
Regression on High-Dimensional Inputs,Alexander P. Kuleshov (National Research University – Higher School of Economics)Alexander V. Bernstein (National Research University – Higher School of Economics),"2111845301,2109320356","Consider unknown smooth function which maps high-dimensional inputs, whose values lie on unknown Input manifold of lower dimensionality embedded in an ambient high-dimensional space, to multi-dimensional outputs. Given training dataset consisting of 'input-output' pairs, κegression on input manifold problem is to estimate the unknown function and its Jacobian matrix, as well to estimate the Input manifold. Transforming the high-dimensional inputs to their low-dimensional features, the problem is reduced to certain regression on feature space problem. The paper presents a new geometrically motivated method for solution of both interrelated regression problems.",2016,International Conference on Data Mining,Fields of study: manifold alignmentmanifolddata analysisaerodynamicscontrol theorydata miningmachine learningmathematical optimizationmathematics
Interactive Multi-task Relationship Learning,Kaixiang Lin (Michigan State University)Jiayu Zhou,"2671270035,2722712928","Multi-task learning (MTL) is a learning paradigm that provides a principled way to improve the generalization performance of a set of related machine learning tasks by transferring knowledge among the tasks. The past decade has witnessed many successful applications of MTL in different domains. In the center of MTL algorithms is how the relatedness of tasks are modeled and encoded in learning formulations to facilitate knowledge transfer. Among the MTL algorithms, the multi-task relationship learning (MTRL) attracted much attention in the community because it learns task relationship from data to guide knowledge transfer, instead of imposing a prior task relatedness assumption. However, this method heavily depends on the quality of training data. When there is insufficient training data or the data is too noisy, the algorithm could learn an inaccurate task relationship that misleads the learning towards suboptimal models. To address the aforementioned challenge, in this paper we propose a novel interactive multi-task relationship learning (iMTRL) framework that efficiently solicits partial order knowledge of task relationship from human experts, effectively incorporates the knowledge in a proposed knowledge-aware MTRL formulation. We propose an efficient optimization algorithm for kMTRL and comprehensively study query strategies that identify the critical pairs that are most influential to the learning. We present extensive empirical studies on both synthetic and real datasets to demonstrate the effectiveness of proposed framework.",2016,International Conference on Data Mining,Fields of study: online machine learningstabilityinductive transfermulti task learninggeneralization errordata modelingpredictive modellingactive learningerror driven learningsemi supervised learninginstance based learningunsupervised learningdata miningartificial intelligencemachine learningcomputer science
Tracking Language Mobility in the Twitter Landscape,Izabela Moise (ETH Zurich)Edward GaereRuben MerzStefan KochEvangelos Pournaras (Delft University of Technology),"2543155928,2584490175,2717641915,2583385880,683237000","The unprecedented data explosion has drastically changed the data science landscape. At the same time, Big Data analytics have reshaped the design and implementation of the applications that analyse the data. In this paper, we explore the use of Big Data tools for extracting value from Twitter data. We acquire a large set of Twitter data (10TB in size) and process it by relying on Spark DataFrame. The purpose of our analytics pipeline is to study the mobility of languages as captured by the Twitter signal. We study the evolution of languages from both a temporal and a spatial perspective, by applying density-based clustering and Self-Organising Maps techniques. The analysis enabled the detection of tourism trends and real-world events, as perceived through the Twitter lens.",2016,International Conference on Data Mining,Fields of study: pipeline transportbig datadata scienceworld wide webdata miningcomputer science
L-EnsNMF: Boosted Local Topic Discovery via Ensemble of Nonnegative Matrix Factorization,Sangho Suh (Korea University)Jaegul Choo (Korea University)Joonseok Lee (Google)Chandan K. Reddy (Wayne State University),"2614190758,2148380128,2141663339,2100435683","Nonnegative matrix factorization (NMF) has beenwidely applied in many domains. In document analysis, it hasbeen increasingly used in topic modeling applications, where aset of underlying topics are revealed by a low-rank factor matrixfrom NMF. However, it is often the case that the resulting topicsgive only general topic information in the data, which tends notto convey much information. To tackle this problem, we proposea novel ensemble model of nonnegative matrix factorizationfor discovering high-quality local topics. Our method leveragesthe idea of an ensemble model, which has been successfulin supervised learning, into an unsupervised topic modelingcontext. That is, our model successively performs NMF givena residual matrix obtained from previous stages and generatesa sequence of topic sets. Our algorithm for updating the inputmatrix has novelty in two aspects. The first lies in utilizing theresidual matrix inspired by a state-of-the-art gradient boostingmodel, and the second stems from applying a sophisticatedlocal weighting scheme on the given matrix to enhance thelocality of topics, which in turn delivers high-quality, focusedtopics of interest to users. We evaluate our proposed method bycomparing it against other topic modeling methods, such as afew variants of NMF and latent Dirichlet allocation, in termsof various evaluation measures representing topic coherence, diversity, coverage, computing time, and so on. We also presentqualitative evaluation on the topics discovered by our methodusing several real-world data sets.",2016,International Conference on Data Mining,Fields of study: matrix decompositionensemble learningdata miningpattern recognitionmachine learningcomputer sciencemathematics
Improving the Prediction Cost of Drift Handling Algorithms by Abstaining,Pierre-Xavier Loeffel (University of Paris)Vincent Lemaire (Orange S.A.)Christophe Marsala (Pierre-and-Marie-Curie University)Marcin Detyniecki (Pierre-and-Marie-Curie University),"2228415384,2096732835,2143746085,225995244","The problem considered in this paper is regression with a constraint on the precision of each prediction in the framework of data streams subject to concept drifts (when the hidden distribution which generates the observations can change over time). Concept drifts can diminish the reliability of the predictions over time and it might not be possible to output a prediction which satisfies the constraints on the precision. In this case, we claim that if the costs associated with a good and with a bad prediction are known beforehand, the overall prediction cost can be improved by allowing the regressor to abstain. To this end, we propose a generic method, compatible with any regressor, which uses an ensemble of reliability estimators to estimate whether the constraints on the precision of a given prediction can be met or not. In the later case, the regressor is allowed to abstain. Empirical results on 30 datasets including different types of drifts back our claim.",2016,International Conference on Data Mining,Fields of study: predictionreliabilityeconometricsdata miningmachine learningstatisticscomputer sciencemathematics
Real-Time Top-View People Counting Based on a Kinect and NVIDIA Jetson TK1 Integrated Platform,Guangqin LiPeng RenXinrong LyuHe Zhang,"2698157840,2630231706,2232019728,2655204770","In this paper, we describe how to establish an embedded framework for real-time top-view people counting. The development of our system consists of two parts, i.e. establishing an embedded signal processing platform and designing a people counting algorithm for the embedded system. For the hardware platform construction, we use Kinect as the camera and exploit NVIDIA Jetson TK1 board as the embedded processing platform. We describe how to build a channel to make Kinect for windows version 2.0 communicate with Jetson TK1. Based on the embedded system, we adapt a water filling based scheme for top-view people counting, which integrates head detection based on water drop, people tracking and counting. Gaussian Mixture Model is used to construct and update the background model. The moving people in each video frame are extracted using background subtraction method. Additionally, the water filling algorithm is used to segment head area as Region Of Interest(ROI). Tracking and counting people are performed by calculating the distance of ROI center point before and after the frame. The whole framework is flexible and practical for real-time application.",2016,International Conference on Data Mining,Fields of study: headimage resolutionembedded systemcomputer graphics imagescomputer hardwarecomputer science
A Deep Learning Approach for the Prediction of Retail Store Sales,Yuta KanekoKatsutoshi Yada (Kansai University),"2568232080,2079431324","The purpose of this research is to construct a sales prediction model for retail stores using the deep learning approach, which has gained significant attention in the rapidly developing field of machine learning in recent years. Using such a model for analysis, an approach to store management could be formulated. The present study uses three years' worth of point-of-sale (POS) data from a retail store to construct a sales prediction model that, given the sales of a particular day, predicts the changes in sales on the following day. As a result, a deep learning model that considers the L1 regularization achieved a sale forecasting accuracy rate of 86%. The products at the retail store have been finely categorized. Even if the attributes of the product categories are increased in number from tens to thousands, the predictive accuracy did not fall by more than about 7%. In contrast, the accuracy decreased by around 13% when the logistic regression model was used. These results indicate that deep learning is highly suitable for constructing models that include multi-attribute variables. The present research demonstrates that deep learning is effective for analyzing the POS data of retail stores.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingwaterdata sciencedata miningmachine learningcomputer science
Towards Information Profiling: Data Lake Content Metadata Management,Ayman Alserafi (Teradata)Alberto Abello (Polytechnic University of Catalonia)Oscar O. Romero (Polytechnic University of Catalonia)Toon Calders (Université libre de Bruxelles),"2088820739,2148989113,2124168510,2064105222","There is currently a burst of Big Data (BD) processed and stored in huge raw data repositories, commonly called Data Lakes (DL). These BD require new techniques of data integration and schema alignment in order to make the data usable by its consumers and to discover the relationships linking their content. This can be provided by metadata services which discover and describe their content. However, there is currently a lack of a systematic approach for such kind of metadata discovery and management. Thus, we propose a framework for the profiling of informational content stored in the DL, which we call information profiling. The profiles are stored as metadata to support data analysis. We formally define a metadata management process which identifies the key activities required to effectively handle this. We demonstrate the alternative techniques and performance of our process using a prototype implementation handling a real-life case-study from the OpenML DL, which showcases the value and feasibility of our approach.",2016,International Conference on Data Mining,Fields of study: meta data servicesmetadata repositorydata elementdata mappingcontent managementrdfsystematicsontologymetadataprototypeworld wide webdata miningdatabasecomputer science
Regression Techniques for Modelling Conception in Seasonally Calving Dairy Cows,Caroline Fenlon (University College Dublin)Luke OGrady (University College Dublin)Michael Doherty (University College Dublin)Stephen Butler (Teagasc)Laurence Shalloo (Teagasc)John Dunnion (University College Dublin),"2338409733,2465132313,2134335461,2609729903,2157722471,2044002902","Reproductive performance is important for the economic efficiency of pasture-based dairy farms. In these seasonal calving systems, a concise period of breeding is essential to ensure the alignment of peak grass availability with peak lactating cow energy demands. Trials and statistical analysis have identified the factors affecting overall reproductive performance, but few studies have analysed performance at the individual service level. In this paper, four binary models of service outcome are described, incorporating age, stage of lactation, calving events, and measures of energy balance and milk production. Random effects at the cow, sire and herd level were included. Logistic regression and generalised additive models were created, both as stand-alone predictors and using ensemble learning in the form of bagging. The four models were evaluated in terms of calibration and discrimination using an external dataset of nine dairy herds representing the typical Irish pasture-based system. Logistic regression (with and without bagging) and generalised additive modelling with bagging all performed satisfactorily and would be useful as stand-alone models or in whole-farm simulation. Logistic regression is suggested as the most useful model for farmers and their advisers due to ease of interpretation. This model will be used as part of a PhD project to create simulation software for seasonally calving dairy animals.",2016,International Conference on Data Mining,Fields of study: econometricsdata miningsimulationcomputer science
BRPS: A Big Data Placement Strategy for Data Intensive Applications,Lihui LiuJunping Song (Chinese Academy of Sciences)Haibo Wang (Chinese Academy of Sciences)Pin Lv (Chinese Academy of Sciences),"2585228072,2625324907,2639015302,2134718210","The Market of Data is an environment where data are reasonably deal with. Some data in the market of data are large and hard to analyze. How to efficiently analyze and organize such large scale data in the market of data is a difficult problem. When using Hadoop to analyze these massive data, if input data of a data mining task are not locally available in a processing node, data have to be migrated via network interconnects to node that performs the data processing operations. These data movement obviously has a bad effect on system performance. In this paper, we propose BRPS (Big data Replicas Placement Strategy), a strategy that improves data intensive tasks parallel execution performance by reducing data movement across multiple machines. The simulation results show that BRPS can greatly reduce the data movement cost and promote workload balance slightly.",2016,International Conference on Data Mining,Fields of study: data virtualizationdata stream miningbig datadata warehouseparallel processingdata miningdatabasereal time computingcomputer science
Sequence-to-Sequence Model with Attention for Time Series Classification,Yujin TangJianfeng XuKazunori Matsumoto (Toshiba)Chihiro Ono (Keio University),"2619615462,2583830556,2287970190,2103492503","Encouraged by recent waves of successful applications of deep learning, some researchers have demonstrated the effectiveness of applying convolutional neural networks (CNN) to time series classification problems. However, CNN and other traditional methods require the input data to be of the same dimension which prevents its direct application on data of various lengths and multi-channel time series with different sampling rates across channels. Long short-term memory (LSTM), another tool in the deep learning arsenal and with its design nature, is more appropriate for problems involving time series such as speech recognition and language translation. In this paper, we propose a novel model incorporating a sequence-to-sequence model that consists two LSTMs, one encoder and one decoder. The encoder LSTM accepts input time series of arbitrary lengths, extracts information from the raw data and based on which the decoder LSTM constructs fixed length sequences that can be regarded as discriminatory features. For better utilization of the raw data, we also introduce the attention mechanism into our model so that the feature generation process can peek at the raw data and focus its attention on the part of the raw data that is most relevant to the feature under construction. We call our model S2SwA, as the short for Sequence-to-Sequence with Attention. We test S2SwA on both uni-channel and multi-channel time series datasets and show that our model is competitive with the state-of-the-art in real world tasks such as human activity recognition.",2016,International Conference on Data Mining,Fields of study: data modelinglogic gatetime seriesspeech recognitiondata miningartificial intelligencemachine learningstatisticscomputer sciencemathematics
A Fast Factorization-Based Approach to Robust PCA,Chong Peng (Southern Illinois University Carbondale)Zhao Kang (Southern Illinois University Carbondale)Qiang Cheng (Southern Illinois University Carbondale),"2104710458,2162933773,2102340508","Robust principal component analysis (RPCA) has been widely used for recovering low-rank matrices in many data mining and machine learning problems. It separates a data matrix into a low-rank part and a sparse part. The convex approach has been well studied in the literature. However, state-of-the-art algorithms for the convex approach usually have relatively high complexity due to the need of solving (partial) singular value decompositions of large matrices. A non-convex approach, AltProj, has also been proposed with lighter complexity and better scalability. Given the true rank r of the underlying low rank matrix, AltProj has a complexity of O(r2dn), where d × n is the size of data matrix. In this paper, we propose a novel factorization-based model of RPCA, which has a complexity of O(kdn), where k is an upper bound of the true rank. Our method does not need the precise value of the true rank. From extensive experiments, we observe that AltProj can work only when r is precisely known in advance, however, when the needed rank parameter r is specified to a value different from the true rank, AltProj cannot fully separate the two parts while our method succeeds. Even when both work, our method is about 4 times faster than AltProj. Our method can be used as a light-weight, scalable tool for RPCA in the absence of the precise value of the true rank.",2016,International Conference on Data Mining,Fields of study: combinatoricsdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Investors Attention and the Effects on Stock Market: An Empirical Study Based on Stock Forum,Wen Long (Chinese Academy of Sciences)Lijing Guan (Chinese Academy of Sciences)Lingxiao Cui (Chinese Academy of Sciences),"2658232617,2585926573,2575576466","This paper studies the relationship between China stock market performances and investors' attention, where the attention is measured by the page view of China's largest stock forum. The results show that trading volume, intraday volatility and liquidity have positive effects on investors' attention, while the effects of stock return to the attention is not significant. Finally, we demonstrate that investor attention is a significant alpha factor by using supervised learning algorithm.",2016,International Conference on Data Mining,Fields of study: non qualified stock optionstock market bubblemarket makerstock exchangestockrestricted stockac powerdatabase indexthe internetdata miningcomputer science
Vehicle Classification from Low Frequency GPS Data,Matteo SimonciniFrancesco Sambo (University of Padua)Leonardo TaccariLuca BraviSamuele SaltiAlessandro Lori,"2585143312,2021348858,2704749067,2698953500,2694414413,2659301360","Inferring the type of vehicles on a road is a fundamental task within several applications. Some recent works have exploited Global Positioning System (GPS) devices and used classification of GPS traces to tackle the problem. Existing approaches based on GPS data make use of GPS trajectories sampled at high frequency (about 1 sample per second), but GPS trackers currently installed on public and commercial fleets acquire GPS positions at lower frequency (about 1 sample per minute). In this paper, we target the more challenging scenario of low frequency GPS data, which has not been tackled yet in the literature, and explore how this kind of data can be used to effectively categorise vehicles into light-duty and heavy-duty. We define several distance-, speed-, and acceleration-based features, inspired by the literature on related problems like travel mode detection, and add novel features based on road type. Features are aggregated over a GPS track with several aggregation functions. We identify the most effective combinations of features and aggregation functions with a data-driven approach, by applying Recursive Feature Elimination in a cross validation framework. Furthermore, we combine predictions of all tracks of a vehicle to boost classification performance. Experimental results on a large dataset show that the selected features are indeed effective and that the high and low frequency GPS scenarios greatly differ in terms of relevant features.",2016,International Conference on Data Mining,Fields of study: axleglobal positioning systemaccelerationfeature extractionestimationdata miningmachine learningsimulationstatisticscomputer science
Inference of Partial Canonical Correlation Networks with Application to Stock Market Portfolio Selection,Gregory BreardNatallia Katenka (University of Rhode Island),"2096835635,2068216664","In recent years, association networks and their applications have received increasing interest. The relationships in a network should ideally be ascertained without any preconceptions about the existence of a connection a priori. This would allow interpretations to be based on the underlying structure rather than on assumptions. Furthermore, a method that discounts outside influence on the relationships is desirable. Partial correlation is one method that meets these criteria, however, this approach is limited to a single attribute. We propose that examining the multi-attribute partial canonical correlations is a superior strategy for capturing the complex relationships found in real world data. As a motivating application, we choose the problem of stock market portfolio selection. Diversification is a core principle of any sound investment strategy, the purpose being to minimize risk and maximize returns. To create a diverse portfolio, the interrelations between corporations and the industrial sectors that they comprise must be understood. To model these relationships we induce a partial canonical correlation network (PCCN) using recent market data and select portfolios algorithmically based on finding the least dependent but related companies. We compare the risk of portfolios selected from the PCCN, partial correlation networks, and randomly. We find that the PCCN based-approach results in comparatively less risky portfolios.",2016,International Conference on Data Mining,Fields of study: correlationsoftware testingactuarial sciencestatisticsmathematics
Scalable and Real-Time Sentiment Analysis of Twitter Data,Maria KaranasouAnneta AmplaChristos Doulkeridis (University of Piraeus)Maria Halkidi (Athens University of Economics and Business),"2251057665,2585247817,167530315,339332626","In this paper, we present a system for scalable and real-time sentiment analysis of Twitter data. The proposed system relies on feature extraction from tweets, using both morphological features and semantic information. For the sentiment analysis task, we adopt a supervised learning approach, where we train various classifiers based on the extracted features. Finally, we present the design and implementation of a real-time system architecture in Storm, which contains the feature extraction and classification tasks, and scales well with respect to input data size and data arrival rate. By means of an experimental evaluation, we demonstrate the merits of the proposed system, both in terms of classification accuracy as well as scalability and performance.",2016,International Conference on Data Mining,Fields of study: feature extractionsentiment analysissemanticsworld wide webinformation retrievaldata miningcomputer science
Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications,Xin Luo (Chongqing University)Mingsheng Shang (University of Electronic Science and Technology of China)Shuai Li (Hong Kong Polytechnic University),"2213122850,2143795187,2549440108","High-dimensional and sparse (HiDS) matrices are commonly encountered in many big data-related industrial applications like recommender systems. When acquiring useful patterns from them, non-negative matrix factorization (NMF) models have proven to be highly effective because of their fine representativeness of non-negative data. However, current NMF techniques suffer from a) inefficiency in addressing HiDS matrices, and b) constrained training schemes lack of flexibility, extensibility and adaptability. To address these issues, this work proposes to factorize industrial-size sparse matrices via a novel Inherently Non-negative Latent Factor (INLF) model. It connects the output factors and decision variables via a single-element-dependent sigmoid function, thereby innovatively removing the non-negativity constraints from its training process without impacting the solution accuracy. Hence, its training process is unconstrained, highly flexible and compatible with general learning schemes. Experimental results on five HiDS matrices generated by industrial applications indicate that INLF is able to acquire non-negative latent factors from them in a more efficient manner than any existing method does.",2016,International Conference on Data Mining,Fields of study: manganeseestimationdata miningmachine learningsimulationstatisticscomputer sciencemathematics
Random Projection Clustering on Streaming Data,Lee A. Carraher (University of Cincinnati)Philip A. Wilsey (University of Cincinnati)Anindya Moitra (University of Cincinnati)Sayantan Dey (University of Cincinnati),"983132182,266758180,2224709579,2228805387","Clustering streaming data has gained importance in recent years due to an expanding opportunity to discover knowledge in widely available data streams. As streams are potentially evolving and unbounded sequence of data objects, clustering algorithms capable of performing fast and incremental processing of data points are necessary. This paper presents a method of clustering high-dimensional data streams using approximate methods called streamingRPHash. streamingRPHash combines random projections with locality-sensitivity hashing to construct a high-performance clustering method. streamingRPHash is amenable to distributed processing frameworks such as Map-Reduce, and also has the benefits of constrained overall complexity growth. This paper describes streamingRPHash algorithm and its various configurations. The clustering performance of streamingRPHash is compared to several alternatives. Experimental results show that streamingRPHash has comparable clustering accuracy and substantially lower runtime and memory usage.",2016,International Conference on Data Mining,Fields of study: flame clusteringbrown clusteringcanopy clustering algorithmdetermining the number of clusters in a data setdbscancorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmaffinity propagationfuzzy clusteringclustering high dimensional datacluster analysisalgorithm designconsensus clusteringbiclusteringapproximation algorithmdata structuretheoretical computer sciencedata miningmachine learningcomputer science
Sacrificing Overall Classification Quality to Improve Classification Accuracy of Well-Sought Classes,Kevin Michael Amaral (University of Massachusetts Boston)Ping Chen (University of Massachusetts Boston)Wei Ding 0003 (University of Massachusetts Boston)Rajani Sadasivam,"2144026405,2421542224,2116574971,2621631653","Classification has been an active field in machine learning for decades. With many methods proposed for various topics in classification, this paper intends to show some initial ideas and findings in one classification scenario where accuracy of only one or a few classes is greatly valued, while the other classes are not important. Using a neural network model and challenging real world dataset, our preliminary results showed the accuracy of important class was significantly improved by sacrificing the accuracy of unimportant classes.",2016,International Conference on Data Mining,Fields of study: one class classificationlabeling theorylogisticssoftware testingartificial neural networkdata miningartificial intelligencemachine learningcomputer science
Scalable Discrete Supervised Hash Learning with Asymmetric Matrix Factorization,Shifeng Zhang (Tsinghua University)Jianmin Li (Tsinghua University)Jinma Guo (Tsinghua University)Bo Zhang,"2499341432,2695500353,2242186946,2708652570","Hashing methods map similar data to binary hashcodes with smaller hamming distance, and it has received a broad attention due to its low storage cost and fast retrieval speed. However, the existing limitations make the present algorithms difficult to deal with large-scale datasets: (1) discrete constraints are involved in the learning of the hash function, (2) pairwise or triplet similarity is adopted to generate efficient hashcodes, resulting both time and space complexity are greater than O(n2). To address these issues, we propose a novel discrete supervised hash learning framework which can be scalable to large-scale datasets. First, the learning procedure is decomposed into a binary classifier learning scheme and hashcodes learning scheme. Second, we adopt the Asymmetric Low-rank Matrix Factorization and propose the Fast Clustering-based Batch Coordinate Descent method, such that the time and space complexity is reduced to O(n). The proposed framework also provides a flexible paradigm to incorporate with arbitrary hash function, including deep neural networks. Experiments on large-scale datasets demonstrate that the proposed method is superior or comparable with state-of-the-art hashing algorithms.",2016,International Conference on Data Mining,Fields of study: k independent hashingrolling hash2 choice hashingfeature hashingdouble hashingdynamic perfect hashingperfect hash functionuniversal hashinghash functiontraining sethash tablebinary codematrix decompositionsemanticsartificial neural networktheoretical computer sciencedata miningpattern recognitionmachine learningcomputer science
Informed Design Platform: Interpreting “Big Data” to Adaptive Place Designs,Linlin You (Singapore University of Technology and Design)Bige Tuncer,"2564527289,2631286649","As a novel concept, ""Informed Design"" is proposed in a multidisciplinary project ""Livable Places"" in Singapore to innovate place design from empirical to evidential by harnessing geo-referenced ""Big Data"" for a responsive design. As a final delivery, an Informed Design Platform (IDP) is being implemented as a design support tool interpreting multi-source big data to adaptive urban designs for a more livable place. Due to the complexity in ""Objects"", which include physical devices and virtual services to generate space related data, ""Data"", which are massive and heterogenous to be interlinked and analyzed for valuable insights, and ""Services"", which integrate back-end and front-end service modules for innovative services, IDP collaborates them through dedicated mechanisms proposed by a Smart Service Orchestration Architecture (SSOA) to achieve a high scalability in data collection, integration, analysis, and visualization. In this paper, the overall design and currently available services of IDP are presented.",2016,International Conference on Data Mining,Fields of study: strategic designcloud computingdata modelingsensorbig datadata scienceworld wide webdata miningcomputer science
Construction of a Semi-Naive Model to Predict Early Readmission of COPD Patients by Using Quality Care Information,Pablo Bermejo (University of Castilla–La Mancha)José A. Gámez (University of Castilla–La Mancha)José Miguel Puerta (University of Castilla–La Mancha)Marco A. EsquiviasPedro J. Tárraga,"2137632762,2149808126,2150251006,2652291806,1987804729","The quality of inpatient care in emergency rooms has proved a major factor to be taken into account upon hospital admission. Several studies show that early readmission of Chronic Obstructive Pulmonary Disease patients after discharge can be predicted according to information on the assistance quality received during the patient's hospital stay, however, these studies use many variables to be captured, from admission to discharge dates, which makes it difficult, or even impossible, to follow the track and record all the information. We propose an algorithm to construct a Semi-Naive model capable of both selecting and aggregating attributes related to inpatient care quality to result in a selection of very few attributes, while overcoming the performance of other early readmission prediction models.",2016,International Conference on Data Mining,Fields of study: niobiumpredictive modellingmathematical modelmachine learningstatisticscomputer science
Semi-Supervised Similarity Preserving Co-Selection,Raywat Makkhongkaew (University of Lyon)Khalid Benabdeslem (University of Lyon),"2231642408,230725257","Semi-supervised learning is the required paradigm when data are partially labeled. It is more adapted for large domain applications when labels are hardly and costly to obtain. In addition, when data are large, feature selection and instance selection are two important dual operations for removing irrelevant information. To address theses challenges together, we propose a unified framework, called sCOs, for semi-supervised co-selection of features and instances, simultaneously. In particular, we propose a novel cost function based on l2, 1-norm regularization and similarity preserving selection of both features and instances. Experimental results on some known benchmark datasets are provided for validating sCOs and comparing it with some representative methods in the state-of-the art.",2016,International Conference on Data Mining,Fields of study: algorithm designgenetic algorithmdata miningpattern recognitionmachine learningcomputer science
Event Series Prediction via Non-Homogeneous Poisson Process Modelling,James Goulding (University of Nottingham)Simon Preston (University of Nottingham)Gavin Smith (University of Nottingham),"2000341103,2160724470,2117936650","Data streams whose events occur at random arrival times rather than at the regular, tick-tock intervals of traditional time series are increasingly prevalent. Event series are continuous, irregular and often highly sparse, differing greatly in nature to the regularly sampled time series traditionally the concern of hard sciences. As mass sets of such data have become more common, so interest in predicting future events in them has grown. Yet repurposing of traditional forecasting approaches has proven ineffective, in part due to issues such as sparsity, but often due to inapplicable underpinning assumptions such as stationarity and ergodicity. In this paper we derive a principled new approach to forecasting event series that avoids such assumptions, based upon: 1. The processing of event series datasets in order to produce a first parameterized mixture model of non-homogeneous Poisson processes, and 2. Application of a technique called parallel forecasting that uses these processes' rate functions to directly generate accurate temporal predictions for new query realizations. This approach uses forerunners of a stochastic process to shed light on the distribution of future events, not for themselves, but for realizations that subsequently follow in their footsteps.",2016,International Conference on Data Mining,Fields of study: mixture modelpredictive modellingforecastingmarkov processtime serieseconometricsdata miningmachine learningstatisticscomputer sciencemathematics
A Theoretical Analysis of the Fuzzy K-Means Problem,Johannes Blomer (University of Paderborn)Sascha BrauerKathrin Bujna (University of Paderborn),"138736257,2299307526,101389126","One of the most popular fuzzy clustering techniques is the fuzzy K-means algorithm (also known as fuzzy-c-means or FCM algorithm). In contrast to the K-means and K-median problem, the underlying fuzzy K-means problem has not been studied from a theoretical point of view. In particular, there are no algorithms with approximation guarantees similar to the famous K-means++ algorithm known for the fuzzy K-means problem. This work initiates the study of the fuzzy K-means problem from an algorithmic and complexity theoretic perspective. We show that optimal solutions for the fuzzy K-means problem cannot, in general, be expressed by radicals over the input points. Surprisingly, this already holds for simple inputs in one-dimensional space. Hence, one cannot expect to compute optimal solutions exactly. We give the first (1+eps)-approximation algorithms for the fuzzy K-means problem. First, we present a deterministic approximation algorithm whose runtime is polynomial in N and linear in the dimension D of the input set, given that K is constant, i.e. a polynomial time approximation scheme (PTAS) for fixed K. We achieve this result by showing that for each soft clustering there exists a hard clustering with similar properties. Second, by using techniques known from coreset constructions for the K-means problem, we develop a deterministic approximation algorithm that runs in time almost linear in N but exponential in the dimension D. We complement these results with a randomized algorithm which imposes some natural restrictions on the sought solution and whose runtime is comparable to some of the most efficient approximation algorithms for K-means, i.e. linear in the number of points and the dimension, but exponential in the number of clusters.",2016,International Conference on Data Mining,Fields of study: type 2 fuzzy sets and systemscorrelation clusteringfuzzy numberfrequency modulationcluster analysisalgorithm designalgorithmicsapproximation algorithmdiscrete mathematicscombinatoricsdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Modelling Sentence Generation from Sum of Word Embedding Vectors as a Mixed Integer Programming Problem,Lyndon White (University of Western Australia)Roberto Togneri (University of Western Australia)Wei Liu (University of Western Australia)Mohammed Bennamoun (University of Western Australia),"2342984155,2100214064,2527394672,431907532","Converting a sentence to a meaningful vector representation has uses in many NLP tasks, however very few methods allow that representation to be restored to a human readable sentence. Being able to generate sentences from the vector representations demonstrates the level of information maintained by the embedding representation – in this case a simple sum of word embeddings. We introduce such a method for moving from this vector representation back to the original sentences. This is done using a two stage process, first a greedy algorithm is utilised to convert the vector to a bag of words, and second a simple probabilistic language model is used to order the words to get back the sentence. To the best of our knowledge this is the first work to demonstrate quantitatively the ability to reproduce text from a large corpus based directly on its sentence embeddings.",2016,International Conference on Data Mining,Fields of study: recurrent neural networknatural languagelinear programmingnatural language processingspeech recognitionmachine learningcomputer sciencemathematics
Beyond Points and Paths: Counting Private Bodies,Maryam Fanaeepour (University of Melbourne)Benjamin I. P. Rubinstein (University of Melbourne),"266336517,617941202","Mining of spatial data is an enabling technology for mobile services, Internet-connected cars, and the Internet of Things. But the very distinctiveness of spatial data that drives utility, comes at the cost of user privacy. In this work, we continue the tradition of privacy-preserving spatial analytics, focusing not on point or path data, but on planar spatial regions. Such data represents the area of a user's most frequent visitation—such as ""around home and nearby shops"". Specifically we consider the differentially-private release of data structures that support range queries for counting users' spatial regions. Counting planar regions leads to unique challenges not faced in existing work. A user's spatial region that straddles multiple data structure cells can lead to duplicate counting at query time. We provably avoid this pitfall by leveraging the Euler characteristic. To address the increased sensitivity of range queries to spatial region data, we calibrate privacy-preserving noise using bounded user region size and a constrained inference that uses robust least absolute deviations. Our novel constrained inference reduces noise and introduces covertness by (privately) imposing consistency. We provide a full end-to-end theoretical analysis of both differential privacy and high-probability utility for our approach using concentration bounds. A comprehensive experimental study on several real-world datasets establishes practical validity.",2016,International Conference on Data Mining,Fields of study: spatial querytrajectoryhistogramfaceprivacyinformation privacydata structureworld wide webdata miningdatabasecomputer science
"Homophily, Structure, and Content Augmented Network Representation Learning","Daokun Zhang (University of Technology, Sydney)Jie Yin (Commonwealth Scientific and Industrial Research Organisation)Xingquan Zhu (Florida Atlantic University)Chengqi Zhang (University of Technology, Sydney)","2140738150,2150861151,2618356905,2166080598","Advances in social networking and communication technologies have witnessed an increasing number of applications where data is not only characterized by rich content information, but also connected with complex relationships representing social roles and dependencies between individuals. To enable knowledge discovery from such networked data, network representation learning (NRL) aims to learn vector representations for network nodes, such that off-the-shelf machine learning algorithms can be directly applied. To date, existing NRL methods either primarily focus on network structure or simply combine node content and topology for learning. We argue that in information networks, information is mainly originated from three sources: (1) homophily, (2) topology structure, and (3) node content. Homophily states social phenomenon where individuals sharing similar attributes (content) tend to be directly connected through local relational ties, while topology structure emphasizes more on global connections. To ensure effective network representation learning, we propose to augment three information sources into one learning objective function, so that the interplay roles between three parties are enforced by requiring the learned network representations (1) being consistent with node content and topology structure, and also (2) following the social homophily constraints in the learned space. Experiments on multi-class node classification demonstrate that the representations learned by the proposed method consistently outperform state-of-the-art NRL methods, especially for very sparsely labeled networks.",2016,International Conference on Data Mining,Fields of study: logical topologycontext modelnetwork topologydata miningmachine learningcomputer science
Patterns in Cognitive Rehabilitation of Traumatic Brain Injury Patients: A Text Mining Approach,Alejandro Garcia RudolphAlberto Garcia Molina (Autonomous University of Barcelona)Eloy Opisso (University of Alabama at Birmingham)Josep Maria Tormos (University of Alabama at Birmingham),"2643676434,2167038832,1836274144,2510486092","Traumatic Brain Injury (TBI) is a leading cause of disability worldwide, there is one TBI case every 15 seconds and in every 5 minutes someone becomes permanently disabled due to it. Brain injuries lack of surgical or pharmacological therapies, therefore Cognitive Rehabilitation (CR) is the generally adopted treatment. Computerized CR tasks are increasingly replacing traditional ""paper and pencil"" approaches. Nevertheless, CR plans are manually designed by clinicians from scratch based on their own experience. There is very little research on the amount and type of practice that occurs during computerized CR treatments and its relationship to patients' outcomes. While task repetition is not the only important feature, it is becoming clear that neuroplastic change and functional improvement occur after specific tasks are performed, but do not occur with others. In this work we focus on the preprocessing, patterns and knowledge extraction phases of a Knowledge Discovery in Databases (KDD) framework. We propose considering CR programs as sequences of sessions and pattern searching (association rules, classification models, clustering and shallow neural models) to support clinicians in the selection of specific interventions (e.g. tasks assignations). The proposed framework is applied to 40000 tasks executions from real clinical setting. Results show different execution patterns on patients with positive and negative responses to treatment, predictive models outperform previous recent research, therapists are provided with new insights and tools for tasks selection criteria and design of CR programs.",2016,International Conference on Data Mining,Fields of study: tag cloudvisualizationcomputational modeltext miningdata miningartificial intelligencemachine learningsimulationcomputer science
"Learning Independent, Diverse Binary Hash Functions: Pruning and Locality","Ramin Raziperchikolaei (University of California, Merced)Miguel A. Carreira-Perpinan (University of California, Merced)","408765343,2071708429","Information retrieval in large databases of complex objects, such as images, audio or documents, requires approximate search algorithms in practice, in order to return semantically similar objects to a given query in a reasonabletime. One practical approach is supervised binary hashing, where each object is mapped onto a small binary vector so that Hamming distances approximate semantic similarities, and the search is done in the binary space more efficiently. Much work has focused on designing objective functions and optimization algorithms for learning b-bit hash functions from a dataset. Recent work has shown that comparable or better results can be obtained by training b hash functions independently from each other and making them cooperate by introducing diversity with ensemble learning techniques. We show that this can be further improved by two techniques: pruning an ensemble of hash functions, and learning local hash functions. We show how it is possible to train our improved algorithms in datasets orders of magnitude larger than those used by most works on supervised binary hashing.",2016,International Conference on Data Mining,Fields of study: security of cryptographic hash functionsk independent hashingrolling hashcityhash2 choice hashingswiffthash filterprimary clusteringfeature hashingdouble hashinghash treedynamic perfect hashinglinear hashingperfect hash functionuniversal hashinglocality sensitive hashinghash functionhash tablebinary codelinear programmingtheoretical computer sciencedata miningpattern recognitionmachine learningcomputer sciencemathematics
Applying Conditional Independence Maps to Improve Sepsis Prognosis,Carles Morales (Polytechnic University of Catalonia)Vicent J. Ribas (Polytechnic University of Catalonia)Alfredo Vellido (Polytechnic University of Catalonia),"2585380492,2019092295,170241628","Sepsis has become a major challenge to medicine and day-to-day clinical practice due to its prevalence in the Intensive Care Unit. This transversal condition has high prevalence and considerable risk of death in its most developed stages. Sepsis has recently been officially redefined and an important new trait of this updated definition is that organ dysfunction is now taken into account, replacing the focus on Systemic Inflammatory Response Syndrome of the previous definition. In this brief study, we analyze one of the biggest available multi-centre sepsis databases using Conditional Independence Maps methods. With this, we aim to explore potential causal relationships between the measured variables and the survival outcome and also to validate the changes in the new definition of sepsis.",2016,International Conference on Data Mining,Fields of study: blood pressureimmune system
A Semi-Supervised Ensemble Approach for Multi-label Learning,Ouadie Gharroudi (University of Lyon)Haytham Elghazel (University of Lyon)Alexandre Aussem (University of Lyon),"242989042,2291370321,1878983072","In this paper, we present a new ensemble approach for semi-supervised multi-label classification which exploits both the dependencies between the class labels and the unlabeled instances to enhance the multi-label classification performance. Our approach combines both data resampling (bagging) and label random subspace strategies for generating a committee of multi-label models in a co-training style algorithm. The key ideas behind this approach are to i) promote and maintain diversity in the multi-label base-classifiers committee, ii) define a new cost oriented metric to estimate the prediction confidence for each label, and iii) use a new multi-label out-of-bag feature importance measure that makes full use of labeled and unlabeled in the semi-supervised setting. Experimental results on various benchmark data sets approved that the proposed approach outperforms recent state-of-the-art supervised and semi-supervised multi-label algorithms over different multi-label metrics.",2016,International Conference on Data Mining,Fields of study: data modelingcorrelationmeasurementhidden markov modeldata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Adaptive Threshold Selection for Trust-Based Detection Systems,Younghun Chae (University of Rhode Island)Natallia Katenka (University of Rhode Island)Lisa Cingiser DiPippo (University of Rhode Island),"2232022416,2068216664,1965559995","Data analysis of complex behaviors, intrusion attacks and system failures inherent in the Information Technology systems became one of the key strategies for ensuring the security of cyber assets. Data-driven anomaly detection methods can offer an appealing alternative to existing signature-based intrusion detection systems by capturing known and previously unseen attacks. In this paper, we try to develop efficient rules that distinguish between normal and abnormal behavior in a given period and over time that can also adapt to relational and dynamic changes in cyber environment. Specifically, we represent the network flow data as a bipartite graph and then adopt an outlier detection approach for heavy-tailed distributions to develop an adaptive threshold method for node behavior characterization. Further, we introduce a trust management scheme for aggregation of node behaviors over time and evaluation of overall node 'trustworthiness' over full time period. Using the data collected by European Internet Service Provider, we demonstrate superior performance of the proposed adaptive threshold selection method for Trust-based detection systems. Overall, the proposed framework can adjust to changing conditions of the system and can be used for detection of anomalous node behaviors in real-time.",2016,International Conference on Data Mining,Fields of study: anomaly based intrusion detection systemintrusion detection systembipartite graphadaptive systemdistributed computingcomputer securitydata miningartificial intelligencemachine learningcomputer science
A Semi-Supervised AUC Optimization Method with Generative Models,Akinori Fujino (Nippon Telegraph and Telephone)Naonori Ueda (Nippon Telegraph and Telephone),"2142558357,2147735823","This paper presents a semi-supervised learning method for improving the performance of AUC-optimized classifiers by using both labeled and unlabeled samples. In actual binary classification tasks, there is often an imbalance between the numbers of positive and negative samples. For such imbalanced tasks, the area under the ROC curve (AUC) is an effective measure with which to evaluate binary classifiers. The proposed method utilizes generative models to assist the incorporation of unlabeled samples in AUC-optimized classifiers. The generative models provide prior knowledge that helps learn the distribution of unlabeled samples. To evaluate the proposed method in text classification, we employed naive Bayes models as the generative models. Our experimental results using three test collections confirmed that the proposed method provided better classifiers for imbalanced tasks than supervised AUC-optimized classifiers and semi-supervised classifiers trained to maximize the classification accuracy of labeled samples. Moreover, the proposed method improved the effect of using unlabeled samples for AUC optimization especially when we used appropriate generative models.",2016,International Conference on Data Mining,Fields of study: generative modelrandom subspace methoddata modelingcomputational modelprobability distributionestimation theorydata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
A Fast Distributed Classification Algorithm for Large-Scale Imbalanced Data,Huihui Wang (Nanjing University)Yang Gao (Nanjing University)Yinghuan Shi (Nanjing University)Hao Wang (Nanjing University),"2558894503,2410080050,2118805678,2599526299","The Alternating Direction Method of Multipliers (ADMM) has been developed recently for distributed classification. Nevertheless, the widely-existing class imbalance problem has not been well investigated. Furthermore, previous imbalanced classification methods lack of efforts in studying the complex imbalance problem in a distributed environment. In this paper, we consider the imbalance problem as distributed data imbalance which includes three imbalance issues: (i) within-node class imbalance, (ii)between-node class imbalance, and (iii) between-node structure imbalance. In order to adequately deal with imbalanced data as well as improve time efficiency, a novel distributed Cost-Sensitive classification algorithm via Group-based ADMM (CS-GADMM) is proposed. Briefly, CS-GADMM derives the classification problem as a series of sub-problems with within-node class imbalance. To alleviate the time delay caused by between-node class imbalance, we propose a extension of dual coordinate descent method for the sub-problem optimization. Meanwhile, for between-node structure imbalance, we discreetly study the relationship between local functions, and combine the resulting local variables intra-group to update the global variables for prediction. The experimental results on various imbalanced datasets validate that CS-GADMM could be a efficient algorithm for imbalanced classification.",2016,International Conference on Data Mining,Fields of study: support vector machineconvergencedistributed databasedata miningpattern recognitionmachine learningcomputer science
Efficient and Scalable Detection of Overlapping Communities in Big Networks,Tianshu LyuLidong Bing (The Chinese University of Hong Kong)Zhao ZhangYan Zhang (Peking University),"2583296295,2160800796,2640648058,2686606814","Community detection is a hot topic for researchers in the fields including graph theory, social networks and biological networks. Generally speaking, a community refers to a group of densely linked nodes in the network. Nodes usually have more than one community label, indicating their multiple roles or functions in the network. Unfortunately, existing solutions aiming at overlapping-community-detection are not capable of scaling to large-scale networks with millions of nodes and edges. In this paper, we propose a fast overlapping-communitydetection algorithm — FOX. In the experiment on a network with 3.9 millions nodes and 20 millions edges, the detection finishes in 14 minutes and provides the most qualified results. The second fastest algorithm, however, takes ten times longer to run. As for another network with 22 millions nodes and 127 millions edges, our algorithm is the only one that can provide an overlapping community detection result and it only takes 238 minutes. Our algorithm draws lessons from potential games, a concept in game theory. We measure the closeness of a node to a community by counting the number of triangles formed by the node and two other nodes form the community. Potential games ensure that the algorithm can reach convergence. We also extend the exploitation of triangle to open-triangle, which enlarges the scale of the detected communities.",2016,International Conference on Data Mining,Fields of study: clique percolation methodcommunity structuregamescluster analysisgame theorytheoretical computer sciencedata miningmachine learningsimulationcomputer science
Hierarchical Aggregation Approach for Distributed Clustering of Spatial Datasets,Malika Bendechache (University College Dublin)Nhien-An Le-Khac (University College Dublin)M-Tahar Kechadi (University College Dublin),"2224668763,2068831938,2192798605","In this paper, we present a new approach of distributed clustering for spatial datasets, based on an innovative and efficient aggregation technique. This distributed approach consists of two phases: 1) local clustering phase, where each node performs a clustering on its local data, 2) aggregation phase, where the local clusters are aggregated to produce global clusters. This approach is characterised by the fact that the local clusters are represented in a simple and efficient way. And The aggregation phase is designed in such a way that the final clusters are compact and accurate while the overall process is efficient in both response time and memory allocation. We evaluated the approach with different datasets and compared it to well-known clustering techniques. The experimental results show that our approach is very promising and outperforms all those algorithms.",2016,International Conference on Data Mining,Fields of study: flame clusteringk medians clusteringbrown clusteringcanopy clustering algorithmcorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmsingle linkage clusteringaffinity propagationfuzzy clusteringclustering high dimensional datacluster analysisshapeconsensus clusteringdistributed databasedata sciencedata miningmachine learningcomputer science
Characterization of In-season Elite Football Trainings by GPS Features: The Identity Card of a Short-Term Football Training Cycle,Alessio Rossi (University of Milan)Enrico Perri (University of Milan)Athos Trecroci (University of Milan)Marco SavinoGiampietro Alberti (University of Milan)Marcello Fedon Iaia,"2417967475,2519158174,2346762932,2672611206,2168856780,2585879978","Football training periodization is widely acknowledged as crucial to obtain the best performance throughout matches and to reduce the risk of injuries. Thus, the aim of this study is to detect the in-season short-term training cycles in an Italian elite football team. 80 trainings of 26 elite football players were monitored during 23 in-season weeks by a global position system (GPS). Machine learning process and autocorrelation analyses were performed in order to detect pattern inside in-season football trainings. Extra tree random forest classifier (ETRFC) was used to create a supervised machine learning process able to describe the football trainings cycle. This analytical model allows us to produce reliable decisions and results learning from historical relationships and trends in the data. In addition, the autocorrelation analysis allows us to detect similarity between observations between the data. Based on these analysis, it was found that the in-season football trainings are characterized by a series of short-term cycles. This kind of periodization follows a sinusoidal model because the short-term cycle detected in the in-season trainings is composed of two parts with different training loads. In particular, in the days long before the match football players perform higher training loads than in the close ones. To enhance performance and reduce risk of injuries, it would be essential to provide correct stimuli in each short-term cycle per day. Thus, developing a valid method able to define the correct training loads in each training day may be central for coaches and athletic trainers to periodize correctly the football trainings.",2016,International Conference on Data Mining,Fields of study: global positioning systemaccelerationcorrelationfeature extractionalgorithm designartificial intelligencemachine learningsimulationcomputer science
Bayesian Deep Convolution Belief Networks for Subjectivity Detection,Iti Chaturvedi (Nanyang Technological University)Erik Cambria (Nanyang Technological University)Soujanya Poria (Nanyang Technological University)Rajiv Bajpai (Nanyang Technological University),"2166408775,1974519269,1992239148,2151276216","Subjectivity detection aims to distinguish natural language as either opinionated (positive or negative) or neutral. In word vector based convolutional neural network models, a word meaning is simply a signal that helps to classify larger entities such as a document. Previous works do not usually consider prior distribution when using sliding windows to learn word embedding's and, hence, they are unable to capture higher-order and long-range features in text. In this paper, we employ dynamic Gaussian Bayesian networks to learn significant network motifs of words and concepts. These motifs are used to pre-train the convolutional neural network and capture the dynamics of discourse across several sentences.",2016,International Conference on Data Mining,Fields of study: kernelconvolutionfeature extractionartificial neural networknatural language processingdata miningpattern recognitionmachine learningcomputer sciencemathematics
Effective and Unsupervised Fractal-Based Feature Selection for Very Large Datasets: Removing Linear and Non-linear Attribute Correlations,Antonio C. FraideinberzeJose F. Rodrigues (University of São Paulo)Robson L. F. Cordeiro (University of São Paulo),"2517063184,2132218131,2165171050","Given a very large dataset of moderate-to-high dimensionality, how to mine useful patterns from it? In such cases, dimensionality reduction is essential to overcome the ""curse of dimensionality"". Although there exist algorithms to reduce the dimensionality of Big Data, unfortunately, they all fail to identify/eliminate non-linear correlations between attributes. This paper tackles the problem by exploring concepts of the Fractal Theory and massive parallel processing to present Curl-Remover, a novel dimensionality reduction technique for very large datasets. Our contributions are: Curl-Remover eliminates linear and non-linear attribute correlations as well as irrelevant ones, it is unsupervised and suits for analytical tasks in general – not only classification, it presents linear scale-up, it does not require the user to guess the number of attributes to be removed, and, it preserves the attributes' semantics. We performed experiments on synthetic and real data spanning up to 1.1 billion points and Curl-Remover outperformed a PCA-based algorithm, being up to 8% more accurate.",2016,International Conference on Data Mining,Fields of study: dimensionality reductioncorrelationprincipal component analysisfractalbig dataparallel processingdata miningpattern recognitionmachine learningstatisticscomputer science
Aggregating Tree for Searching in Billion Scale High Dimensional Data,Shicong Liu (Shanghai Jiao Tong University)Junru Shao (Shanghai Jiao Tong University)Hongtao Lu (Shanghai Jiao Tong University),"2147514655,2102962635,2009627569","We present a novel nearest neighbor search scheme named aggregating tree (A-Tree) for high dimensional data that uses vector quantization encodings (VQ-encodings) to build a radix tree, and perform the nearest neighbor search by beam search. To search accurately and efficiently, we suggest VQ-encodings to satisfy locally aggregating encoding criterion: for any node of the corresponding A-Tree, neighboring vectors should aggregate in fewer subtrees to make beam search efficient. We suggest another two criteria for effective VQ-encodings which resembles balanced and uncorrelated bit criteria for hashing codes. We use generalized residual vector quantization (GRVQ) encodings to build A-Tree to meet the suggested criteria, and this combination shows significantly better performances. Our methods are validated on several standard benchmark datasets, including one containing a billion vectors. Experimental results show the superior efficiency and effectiveness of our proposed methods compared to the state-of-the-art.",2016,International Conference on Data Mining,Fields of study: nearest neighbor searchtheoretical computer sciencedata miningmachine learningstatisticscomputer sciencemathematics
Fraud Detection in Voice-Based Identity Authentication Applications and Services,Saeid Safavi (University of Hertfordshire)Hock GanIosif Mporas (University of Hertfordshire)Reza Sotudeh (University of Hertfordshire),"2630403861,2667973481,2604901101,151093042","Keeping track of the multiple passwords, PINs, memorable dates and other authentication details needed to gainremote access to accounts is one of modern life's less appealingchallenges. The employment of a voice-based verification as abiometric technology for both children and adults could be agood replacement to the old fashioned memory dependentprocedure. Using voice for authentication could be beneficial inseveral application areas, including, security, protection, education, call-based and web-based services. Voice-basedbiometric applications are subject to different types of spoofingattacks. The most accessible and affordable type of spoofing for avoice-based biometrics system is a replay attack. Replay, which isto playback a pre-recorded speech sample, presents a genuinerisk to automatic speaker verification technology. This workpresents two architectures for detecting frauds caused by replayattacks in a voice-based biometrics authentication systems. Experimental results confirmed that obtained performancesfrom both methods could further improve by applying a machinelearning algorithm for performing fusion at the score level. Theperformance of both methods further improved by fusion usingindependent sources of scores in different architectures.",2016,International Conference on Data Mining,Fields of study: challenge response authenticationspeechauthenticationfeature extractionhidden markov modelinternet privacyspeech recognitioncomputer securitydata miningmachine learningcomputer science
Learning a Secure Classifier against Evasion Attack,Zeinab Khorshidpour (Shiraz University)Sattar Hashemi (Iran University of Science and Technology)Ali Hamzeh (Shiraz University),"2274692844,2097659959,2101701688","In security sensitive applications, there is a crafty adversary component which intends to mislead the detection system. The presence of an adversary component conflicts with the stationary data assumption that is a common assumption in most machine learning methods. Since machine learning methods are not inherently adversary-aware, it necessitates to investigate security evaluation of machine learning based detection systems in the adversarial environment. Research in adversarial environment mostly focused on modeling adversarial attacks and evaluating impact of them on learning algorithms, only few studies have devised learning algorithms with improved security. In this paper we propose a secure learning model against evasion attacks on the application of PDF malware detection. The experimental results acknowledge that the proposed method significantly improves the robustness of the learning system against manipulating data and evasion attempts at test time.",2016,International Conference on Data Mining,Fields of study: online machine learningmalwaredata modelingsupport vector machinerobustnessmathematical modelactive learningcomputational learning theoryinstance based learninginformation securitycomputer securitydata miningmachine learningcomputer science
Exploiting a Determinant-Based Metric to Evaluate a Word-Embeddings Matrix of Items,Ludovico Boratto (University of Cagliari)Salvatore Carta (University of Cagliari)Gianni Fenu (University of Cagliari)Roberto Saia,"2089389847,1218257387,2062477293,1970865272","In order to generate effective results, it is essential for a recommender system to model the information about the user interests (user profiles). A profile usually contains preferences that reflect the recommendation technique, so collaborative systems represent a user with the ratings given to items, while content-based approaches assign a score to semantic/text-based features of the evaluated items. Even though semantic technologies are rapidly evolving and word embeddings (i.e., vector representations of the words in a corpus) are effective in numerous information filtering tasks, at the moment collaborative approaches (such as SVD) still generate more accurate recommendations. However, this might happen because, by employing classic profiles in form of vectors that collect all the preferences of a user, the power of word embeddings at modeling texts could be affected. In this paper we represent a profile as a matrix of word-embedding vectors of the items a user evaluated, and present a novel determinant-based metric that measures the similarity between an unevaluated item and those in the matrix-based user profile, in order to generate effective content-based recommendations. Experiments performed on three datasets show the capability of our approach to perform a better ranking of the items w.r.t. collaborative filtering, both when compared to a latent-factor-based approach (SVD) and to a classic neighborhood user-based system.",2016,International Conference on Data Mining,Fields of study: collaborationfeature extractionmeasurementsemanticsworld wide webinformation retrievaldata miningmachine learningcomputer science
Factorizing Complex Discrete Data “with Finesse”,Samuel Maurus (Technische Universität München)Claudia Plant (Florida State University),"1989291604,2122910652","Can we mine latent patterns from discrete, non-numeric heterogeneous data? Many modern data sets contain heterogeneous non-numerical information measured over Boolean, ordinal and ternary scales. Values for features like these are ""mixable"" in the sense that they have intuitive non-linear analogs to classical ""addition"" (e.g. logical OR for Boolean data). We present a novel, general and extensible matrix factorization framework for any such ""mixable"" features. The framework lets us support heterogeneous data and encourages us to deduce other interesting ""mixable"" features, like those which encapsulate sub-trees over an ontology. We present Finesse, an algorithm with linear run-time complexity in the size of the data. Finesse outperforms state-of-the-art techniques in the special cases in terms of effectiveness and efficiency, and yields insightful patterns from its novel application to large real-world heterogeneous data.",2016,International Conference on Data Mining,Fields of study: ontologyvegetationfrequency modulationlinear programmingtheoretical computer sciencediscrete mathematicsdata miningmachine learningstatisticsalgorithmcomputer sciencemathematics
KNN Classifier with Self Adjusting Memory for Heterogeneous Concept Drift,Viktor Losing (Bielefeld University)Barbara Hammer (Citec)Heiko Wersing (Honda),"2223780949,2134858009,84405521","Data Mining in non-stationary data streams is gaining more attentionrecently, especially in the context of Internet of Things and Big Data. It is a highly challenging task, since the fundamentally different typesof possibly occurring drift undermine classical assumptions such asi.i.d. data or stationary distributions. Available algorithms are either struggling with certain forms of drift or require a priori knowledge in terms of a task specific setting. We propose the Self Adjusting Memory (SAM) model for the k Nearest Neighbor (kNN) algorithm since kNN constitutes a proven classifier within the streaming setting. SAM-kNN can deal with heterogeneous concept drift, i.e different drift types and rates, using biologically inspiredmemory models and their coordination. It can be easilyapplied in practice since an optimization of the meta parameters is not necessary. The basic idea is to construct dedicated models for thecurrent and former concepts and apply them according tothe demands of the given situation. An extensive evaluation on various benchmarks, consisting of artificial streamswith known drift characteristics as well as real world datasets is conducted. Thereby, we explicitly add new benchmarks enabling a precise performance evaluation on multiple types of drift. The highly competitive results throughout all experiments underline the robustness of SAM-kNN as well as its capabilityto handle heterogeneous concept drift.",2016,International Conference on Data Mining,Fields of study: benchmarkpredictive modellingpredictiondata miningartificial intelligencemachine learningstatisticscomputer science
New Robust Clustering Model for Identifying Cancer Genome Landscapes,Hongchang Gao (University of Texas at Arlington)Xiaoqian Wang (University of Texas at Arlington)Heng Huang (University of Texas at Arlington),"2169884944,2149602155,2137533801","In recent decades, the availability of comprehensive genomic data has facilitated the insight of molecular portraits of cancer. Specifically, by conducting cancer clustering, cancer samples can be divided into several groups according to their differences and similarities in molecular characteristics. Traditional cancer clustering usually analyzes cancer samples from a single tissue, but such analysis cannot reveal the connections among different types of cancer. Landscape analysis across human cancers can help discover molecular signatures shared across cancer tissues, providing an opportunity to design new gene therapy tailored for different cancer patients. However, the noise level in genomic data is high. The robust clustering method is crucial to tackle this problem. In this paper, we propose a new robust clustering method to approach the landscape analysis for TCGA cancer data from a novel view, which is to eliminate the noise and then perform clustering on the cleaned data rather than weaken the effect of noise as existing noise-resistant norm methods. Extensive experiments on both genomic datasets and clustering benchmark datasets confirm the effectiveness and correctness of our proposed method.",2016,International Conference on Data Mining,Fields of study: matrix decompositioncancerrobustnessconsensus clusteringgenomicsdata sciencebioinformaticsdata miningcomputer science
Overlapping Community Detection by Local Decentralised Vertex-Centred Process,Mael Canu (University of Paris)Marie-Jeanne Lesot (Pierre-and-Marie-Curie University)Adrien Revault DAllonnes (Pierre-and-Marie-Curie University),"2289373214,2308574049,2079708142","This paper focuses on the identification of overlapping communities, allowing nodes to simultaneously belong to several communities, in a decentralised way. To that aim it proposes LOCNeSs, an algorithm specially designed to run in a decentralised environment and to limit propagation, two essential characteristics to be applied in mobile networks. It is based on the exploitation of the preferential attachment mechanism in networks. Experimental results show that LOCNeSs is stable and achieves good overlapping vertex identification.",2016,International Conference on Data Mining,Fields of study: complex networkalgorithm designworld wide webdistributed computingdata miningcomputer science
On the Interest of Data Mining for an Integrity Assessment of AIS Messages,Clement Iphar (Mines ParisTech)Aldo Napoli (Mines ParisTech)Cyril Ray (United States Naval Academy),"1477219497,2169113076,2250406251","Put in place by the International Maritime Organization, the Automatic Identification System is a worldwide maritime electronic system that sends radio broadcasted messages at a high rate between the stations, either on board the vessels or on shores. However, some misuses of the system such as identity theft, localization spoofing or disappearances have been demonstrated. The high rate of transmission implies a considerable amount of data to process in order to point out those irregularities. This paper proposes a method based on data mining and clustering methods combined to an integrity assessment of AIS messages for anomaly detection, with a proposition of software architecture for a data processing done both on-the-fly and with archived data. The computation of confidence coefficients and the use of data mining techniques will lead to behaviour characterization with the purpose of enhance the maritime situational awareness.",2016,International Conference on Data Mining,Fields of study: automatic identification systemradio navigationcognitive neuroscience of visual object recognitioncomputer securitydata miningcomputer science
Learning Hierarchically Decomposable Concepts with Active Over-Labeling,Yuji Mo (University of Nebraska–Lincoln)Stephen D. Scott (University of Nebraska–Lincoln)Doug Downey,"2585385811,2128334894,2637724210","Many classification tasks target high-level concepts that can be decomposed into a hierarchy of finer-grained sub-concepts. For example, some string entities that are Locations are also Attractions, some Attractions are Museums, etc. Such hierarchies are common in named entity recognition (NER), document classification, and biological sequence analysis. We present a new approach for learning hierarchically decomposable concepts. The approach learns a high-level classifier (e.g., location vs. non-location) by seperately learning multiple finer-grained classifiers (e.g., museum vs. non-museum), and then combining the results. Soliciting labels at a finer level of granularity than that of the target concept is a new approach to active learning, which we term active over-labeling. In experiments in NER and document classification tasks, we show that active over-labeling substantially improves area under the precision-recall curve when compared with standard passive or active learning. Finally, because finer-grained labels may be more expensive to obtain, we also present a cost-sensitive active learner that uses a multi-armed bandit approach to dynamically choose the label granularity to target, and show that the bandit-based learner is robust to differences in label cost and labeling budget.",2016,International Conference on Data Mining,Fields of study: active learningmaterial properties of diamondlabeling theorycost benefit analysisactive learningsemi supervised learningdata miningartificial intelligencemachine learningcomputer science
Link Prediction in the Twitter Mention Network: Impacts of Local Structure and Similarity of Interest,Hadrien HoursEric Fleury (École normale supérieure de Lyon)Marton Karsai (Aalto University),"2657017199,2299987037,2508019023",The creation of social ties is driven by several factors which can arguably be related to individual preferences and to the common social environment of individuals. Effects of homophily and triadic closure mechanisms are claimed to be important in terms of initiating new social interactions and in turn to shape the global social structure. This way they eventually provide some potential to predict the creation of social ties between disconnected people sharing common friends or common subjects of interest. In this paper we analyze a large Twitter data corpus and quantify similarities between people by considering the set of their common friends and the set of their commonly shared hashtags in order to predict mention links among them. We show that these similarity measures are correlated among connected people and that the combination of contextual and local structural features provides better predictions as compared to cases where they are considered separately. These results help us to better understand the evolution of egocentric and global social networks and provide advances in the design of better recommendation systems and resource allocation plans.,2016,International Conference on Data Mining,Fields of study: accelerationmeasurementresource managementworld wide webdata miningmachine learning
A Novel Pre-Classification Based kNN Algorithm,Huahua XieDong Liang (China Mobile)Zhaojing Zhang (Peking University)Hao Jin (Peking University)Chen LuYi Lin,"2531107328,2566776570,2223852718,2720173366,2531583394,2713587373","kNN (k nearest neighbors) is widely adopted because of its simplicity. However, its shortcomings can not be neglected, especially its time complexity. Consequently a great amount of approaches emerged in large numbers in decades to cope with this issue with a tradeoff in performance of the classification. In this paper, a novel improved kNN algorithm is proposed with a better performance than traditional kNN when its time complexity is meanwhile reduced. In the proposed algorithm, a pre-classification which cost little time is to be conducted before proposed kNN algorithm. Then the training set can be divided into several parts according to the classification probability with some thresholds. After that the parts with probability nearer to 1 or 0 are selected to be training sets. The accuracy rate and the area under the ROC curve (the receiver operating characteristic curve) of the proposed algorithm is calculated and compared with basic kNN algorithm in the experiments. The experiment results show that not only the pre-classification based kNN algorithm greatly reduced the time cost, but it also performs better than the original kNN algorithm in accuracy and AUC (the area under the ROC curve).",2016,International Conference on Data Mining,Fields of study: decision treesensitivitytime complexitypredictionstatistical classificationdata miningpattern recognitionmachine learningstatisticscomputer science
Group Preference Aggregation: A Nash Equilibrium Approach,Hongke Zhao (University of Science and Technology of China)Qi Liu (University of Science and Technology of China)Yong Ge (University of North Carolina at Charlotte)Ruoyan KongEnhong Chen (University of Science and Technology of China),"2223484430,2420624292,2218492437,2584860097,2136372366","Group-oriented services such as group recommendations aim to provide services for a group of users. For these applications, how to aggregate the preferences of different group members is the toughest yet most important problem. Inspired by game theory, in this paper, we propose to explore the idea of Nash equilibrium to simulate the selections of members in a group by a game process. Along this line, we first compute the preferences (group-dependent optimal selections) of each individual member in a given group scene, i.e., an equilibrium solution of this group, with the help of two pruning approaches. Then, to get the aggregated unitary preference of each group from all group members, we design a matrix factorization-based method which aggregates the preferences in latent space and estimates the final group preference in rating space. After obtaining the group preference, group-oriented services (e.g., group recommendation) can be directly provided. Finally, we construct extensive experiments on two real-world data sets from multiple aspects. The results clearly demonstrate the effectiveness of our method.",2016,International Conference on Data Mining,Fields of study: best responseequilibrium selectionnash equilibriumgamesprototypecomputational modelmathematical economicssimulationcomputer sciencemathematics
Reliable Gender Prediction Based on Users’ Video Viewing Behavior,Jie Zhang (New Jersey Institute of Technology)Kuang DuRuihua ChengZhi Wei (New Jersey Institute of Technology)Chenguang QinHuaxin YouSha Hu,"2700304305,2585990865,2711177340,2126219825,2583914507,2679101021,2720630546","With the growth of the digital advertising market, it has become more important than ever to target the desired audiences. Among various demographic traits, gender information plays a key role in precisely targeting the potential consumers in online advertising and ecommerce. However, such personal information is generally unavailable to digital media sellers. In this paper, we propose a novel task-specific multi-task learning algorithm to predict users' gender information from their video viewing behaviors. To detect as many desired users as possible, while controlling the Type I error rate at a user-specified level, we further propose Bayes testing and decision procedures to efficiently identify male and female users, respectively. Comprehensive experiments have justified the effectiveness and reliability of our framework.",2016,International Conference on Data Mining,Fields of study: mediadata modelingreliabilityinternet privacymultimediacomputer science
Structural Combination of Neural Network Models,Juan RendonLilian M. de Menezes,"2584594597,2696932880","Forecasts combinations normally use point forecasts that were obtained from different models or sources ([1], [2],[3]). This paper explores the incorporation of internal structure parameters of feed-forward neural network (NN) models as anapproach to combine their forecasts via ensembles. First, the generated NN models that could be part of the ensembles are subjectto a clustering algorithm that uses the structure parameters and, from each of the clusters obtained, a small set of models is selectedand their forecasts are combined in a two-stage procedure. Secondly, in an alternative and simpler implementation, a subset of the generated NN models is selected by using several reference points in the model structure parameter space. The choice of thereference points is optimised through a genetic algorithm and the models selected are averaged. Hourly electricity demand timeseries is used to assess multi-step ahead forecasting performance for up to a 12 hours horizon. Results are compared against severalstatistical benchmarks, the average of the individual forecasts and the best models in the ensembles. Results show that the cluster-based (CB) structural combinations do better than the genetic algorithm (GA) structural combinations in outperforming the average forecast, which is the traditional point forecast from an ensemble.",2016,International Conference on Data Mining,Fields of study: consensus forecastweather forecastingdata modelingpredictive modellingforecastinguncertaintymathematical modelartificial neural networkeconometricsdata miningmachine learningstatisticscomputer sciencemathematics
Graph-Structured Sparse Optimization for Connected Subgraph Detection,Baojian ZhouFeng Chen,"2650831512,2646924766","Structured sparse optimization is an important and challenging problem for analyzing high-dimensional data in a variety of applications such as bioinformatics, medical imaging, social networks, and astronomy. Although a number of structured sparsity models have been explored, such as trees, groups, clusters, and paths, connected subgraphs have been rarely explored in the current literature. One of the main technical challenges is that there is no structured sparsity-inducing norm that can directly model the space of connected subgraphs, and there is no exact implementation of a projection oracle for connected subgraphs due to its NP-hardness. In this paper, we explore efficient approximate projection oracles for connected subgraphs, and propose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to optimize a generic nonlinear objective function subject to connectivity constraint on the support of the variables. Our proposed algorithms enjoy strong guarantees analogous to several current methods for sparsity-constrained optimization, such as Projected Gradient Descent (PGD), Approximate Model Iterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit (GHTP) with respect to convergence rate and approximation accuracy. We apply our proposed algorithms to optimize several well-known graph scan statistics in several applications of connected subgraph detection as a case study, and the experimental results demonstrate that our proposed algorithms outperform state-of-the-art methods.",2016,International Conference on Data Mining,Fields of study: siliconalgorithm designmathematical modelapproximation algorithmtheoretical computer sciencecombinatoricsdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Communities in Preference Networks: Refined Axioms and Beyond,Gang Zeng (Chinese Academy of Sciences)Yuyi Wang (ETH Zurich)Juhua PuXingwu Liu (Chinese Academy of Sciences)Xiaoming Sun (Chinese Academy of Sciences)Jialin Zhang (Chinese Academy of Sciences),"2534299757,2483503127,2629154885,2671120554,2184028660,2130509011","Borgs et al. [2016] investigated essential requirements for communities in preference networks. They defined six axioms on community functions, i.e., community detection rules. Though having elegant properties, the practicality of this axiomsystem is compromised by the intractability of checking twocritical axioms, so no nontrivial consistent community functionwas reported in [Borgs et al., 2016]. By adapting the two axioms in a natural way, we propose two new axioms that are efficiently-checkable. We show that most of the desirable properties of the original axiom system are preserved. More importantly, the new axioms provide a general approach to constructing consistent community functions. We further find a natural consistent community function that is also enumerable and samplable, answering an open problem in the literature.",2016,International Conference on Data Mining,Fields of study: separation axiomarmstrong s axiomslatticecluster analysisdiscrete mathematicscombinatoricsdata miningmachine learningalgorithmcomputer sciencemathematics
Cluster-Based Sorted Neighborhood for Efficient Duplicate Detection,Ahmad Samiei (Hasso Plattner Institute)Felix Naumann (Hasso Plattner Institute),"2476290279,2099727678","Duplicate detection intends to find multiple and syntactically different representations of the same real-world entities in a dataset. The naive way of duplicate detection entails a quadratic number of pair-wise record comparisons to identify the duplicates. This number of comparisons might take hours even for an average sized dataset. As today's databases grow very fast, different candidate-selection methods, such as sorted neighborhood, blocking, canopy clustering and their variations, address this problem by shrinking the comparison space. The volume and velocity of data-change require ever faster and more flexible methods of duplicate detection. In particular, they need dynamic indices that can be updated efficiently as new data arrives. We present a novel approach, which combines the idea of cluster-based methods with the well-known sorted neighborhood method. It carefully filters out irrelevant candidate pairs, which are less likely to yield duplicates, by pre-clustering records based not only on their proximity after sorting, but also on their similarity in selected attributes. An empirical evaluation on synthetic and real-world datasets shows that our approach improves the overall runtime over existing approaches while maintaining comparable result quality. Meanwhile, it uses a dynamic indices, that in turns make it useful for deduplicating streaming data.",2016,International Conference on Data Mining,Fields of study: database indexsortingmeasurementinformation retrievaldata miningmachine learningstatisticscomputer science
Selecting the Top-k Discriminative Features Using Principal Component Analysis,Aminata KaneNematollaah Shiri (Concordia University),"2609164821,2207586587","Feature selection is important for dimensionality reduction, analysis, and pattern discovery applications. We consider multivariate time series data and propose an unsupervised learning technique to identify the top-k discriminative features. The proposed technique uses statistics drawn from the Principal Component Analysis (PCA) of the input data to leverage the relative importance of the principal components along with the coefficients within the principal directions of the data to uncover the ranking of the features. We conduct numerous experiments using various benchmark datasets to study the performance of the proposed technique in terms of the discriminant power of the selected features and its ability to minimize the original data reconstruction error. Compared to major existing techniques, our results indicate increased accuracy and efficiency. We also show that our technique yields improved classification accuracy.",2016,International Conference on Data Mining,Fields of study: sparse pcamultiple correspondence analysiscorrespondence analysissingular value decompositionmatrix decompositionprincipal component analysisfeature extractiontime seriesdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Temporal Data Mining on the Stay Time of Outpatients and Treatment Processes,Shoji Hirano (Shimane University),2127173244,"In this paper, we attempt to analyze the relationships between the stay time of outpatients and treatment processes they received based on the temporal pattern mining algorithm proposed by Batal et al. We could observe MPTPs (Minimal Predictive Temporal Patterns) of treatment processes containing 'co-occur' relations as well as injections in the classes where the patients spent long time in receiving outpatient services. It suggested that a visit needs long time if treatments or examinations should be executed during the consultation, or if injections such as intravenous drips were involved in the process.",2016,International Conference on Data Mining,Fields of study: predictiontime seriesoperations researchdata miningstatisticsmathematics
Machine Learning for Modeling the Biomechanical Behavior of Human Soft Tissue,José David Martín-Guerrero (University of Valencia)María J. Rupérez-MorenoFrancisco Martínez-Martínez (Polytechnic University of Valencia)Delia Lorente-GarridoAntonio J. Serrano-López (University of Valencia)Carlos Monserrat (Polytechnic University of Valencia)Sandra Martínez-Sanchis (Polytechnic University of Valencia)Marcelino Martínez-Sober (University of Valencia),"303836356,2583432758,2140052406,2583218420,2345512697,2041495549,2329073614,1796130816","An accurate modeling of the biomechanical properties of human soft tissue is crucial in many clinical applications, such as, radiotherapy administration or surgery. The finite element method (FEM) is the usual choice to carry out such modeling due to its high accuracy. However, FEM is computationally very costly, and hence, its application in real-time or even off-line with short delays are still challenges to overcome. This paper proposes a framework based on Machine Learning to learn FEM modeling, thus having a tool able to yield results that may be sufficiently fast for clinical applications. In particular, the use of ensembles of Decision Trees has shown its suitability in modeling the behavior of the liver and the breast.",2016,International Conference on Data Mining,Fields of study: data modelingfinite element methodsimulationcomputer science
Research on Sentiment Analysis: The First Decade,Oskar Ahlgren (Aalto University),2062099451,The first publications on sentiment analysis and opinion mining were published roughly a decade ago. Now it is time to lookback on the achievements so far. This paper presents statistics on the evolution of sentiment analysis. What kind of topics have beendiscussed? How has their popularity changed over time? Who have been the leading researchers? Answers to these questions areprovided by statistical analysis on keywords and by applying Latent Dirichlet Allocation to the titles and abstracts of the publications. The aim of this paper is to provide background information on the big picture of semantic analysis and its development over time.,2016,International Conference on Data Mining,Fields of study: latent dirichlet allocationprobabilitysentiment analysisresource managementsemanticsdata scienceinformation retrievaldata miningmachine learningcomputer science
Event Grounding from Multimodal Social Network Fusion,Hyunsouk Cho (Pohang University of Science and Technology)Jinyoung Yeo (Pohang University of Science and Technology)Seung-Won Hwang (Yonsei University),"2161882573,2232531623,2168667670","This paper studies the problem of extracting real world event information from social media streams. Although existing work focuses on event signals of bursty mentions extracted from a single-source of textual streams, these signals are likely to be noisy due to ambiguous occurrences of individual mentions. To extract accurate event signals, we propose a framework capable of ""grounding"" mentions to unique event using multiple social networks with complementary strength. We show that our framework jointly using multiple sources outperforms state-of-the-arts using publicly available datasets.",2016,International Conference on Data Mining,Fields of study: groundmetadatalatticeworld wide webinformation retrievaldata miningcomputer science
DFA-G: A Unified Programming Model for Vertex-Centric Parallel Graph Processing,Bo Suo (Northwestern Polytechnical University)Jing SuQun Chen (Northwestern Polytechnical University)Zhanhuai LiWei Pan (Northwestern Polytechnical University),"2160527877,2585051082,2676941794,2634062324,2301951490","Many systems have been built for vertex-centric parallel graph processing. Based on the Bulk Synchronous Parallel (BSP) model, they execute user-defined operations at vertices iteratively and exchange information between vertices by messages. Even though the native BSP systems (e.g. Pregel and Giraph) execute the operations on vertices synchronously within an iteration, many other platforms (e.g. Grace, Blogel and GraphHP) have proposed asynchronous execution for improved efficiency. However, they also bring about an undesirable side effect: a program designed for synchronous platforms may not run properly on asynchronous platforms. In this demo, we present DFA-G(Deterministic F inite A utomaton for G raph processing), a unified programming model for vertex-centric parallel graph processing. Built on DFA, DFA-G expresses the computation at a vertex as a process of message-driven state transition. A program modeled after DFA-G can run properly on both synchronous and asynchronous platforms. We demonstrate how to build DFA-G models using a graphical user interface and also how to automatically translate them into BSP programs.",2016,International Conference on Data Mining,Fields of study: data modelingautomatongraphical user interfacecomputational modelprogrammingtheoretical computer scienceparallel computingdistributed computingdata miningmachine learningcomputer science
Finding Heaviest k-Subgraphs and Events in Social Media,Matthaios LetsiosOana Denisa Balalau (Institut Mines-Télécom)Maximilien Danisch (Institut Mines-Télécom)Emmanuel OrsiniMauro Sozio (Institut Mines-Télécom),"2584180429,2227051084,2563802996,2584227261,2661201427","In recent years, social media have become a useful tool to stay in contact with friends, to share thoughts but also to be informed about events. Users can follow news channels, but they can be the ones reporting updates, which distinguishes social media from traditional media. In this paper, we use a graph mining approach for finding events in a graph constructed starting from posts of users. We develop an exact algorithm for solving the heaviest k-subgraph problem which is an NP-hard problem. Our experimental analysis on large real-world graphs shows that our algorithm is able to compute the exact solutions for k up to 15 or more depending on the structure of the graph. We also develop an approximation version of our algorithm scaling to larger k. In comparison, for this setting, the classical heuristic based on weighted core decomposition only leads to sub-optimal solutions. Finally, we show that our algorithm can be used to find relevant events in Twitter. Indeed, as an event is usually described by a small number of words, our algorithm is a useful tool to detect them.",2016,International Conference on Data Mining,Fields of study: algorithm designupper and lower boundsapproximation algorithmtheoretical computer sciencedata miningmachine learningalgorithmcomputer sciencemathematics
Smart Phone User Behaviour Characterization Based on Autoencoders and Self Organizing Maps,Deepthi RajashekarA. Nur Zincir-Heywood (Dalhousie University)Malcolm I. Heywood (Dalhousie University),"2650450367,1253439217,2282981389","Building applications that are cognizant of temporal and spatial changes in human behaviour under a one-class learning restriction represents a requirement for many user centric systems. We are particularly motivated to demonstrate the utility of algorithms for the self identification of smart phones. A framework is designed to quantify: (i) the dissimilarity in behaviours among any two users, (ii) the exclusivity of each user's behaviour (inclass) from the world (outclass). A central element of the proposed framework is to first identify a discriminating representation for each user. To this end, an autoencoder is employed in which the goal is to identify an encoding that rebuilds the original data with maximum accuracy/ least loss. The hypothesis of this work is that such an autoencoding step provides an effective mechanism for discovering good data representations prior to the application of a data description technique, such as clustering. Both the autoencoder and the clustering steps are performed relative to a single user. We construct a user specific behavioural model using the most frequently used applications, cell towers and websites. We demonstrate that relative to the most up-to-date publicly available smart phone data set, the resulting behavioural models are capable of uniquely identifying each user under a one-class learning constraint.",2016,International Conference on Data Mining,Fields of study: encodinghidden markov modeldata miningmachine learningsimulationcomputer science
Historical Data Integration a Study of WWI Canadian Soldiers,Luiza Antonie (University of Guelph)Harshavardhan GadgilGary William Grewal (University of Guelph)Kris Inwood (University of Guelph),"2059445384,2521899979,2099677557,1806620639","Record linkage is the process of identifying and linking records that refer to the same entities across several databases. In this paper we integrate three historical data sources (Canadian soldiers in the Canadian Expeditionary Force (CEF) who served in World War I, CEF casualties of World War I, and the Canadian census of 1901) to study the Canadian soldiers and casualties of World War I. We link the soldiers dataset to the casualties one to be able to identify the soldiers that died in WWI. In addition, we link the soldiers dataset to the Canadian census of 1901 to enrich the available attributes. The goal is to generate longitudinal data about the Canadian soldiers that would allow researchers to perform a systematic analysis of who lived and who died. The imprecision of historical data, along with the unavailability of expert links and a limited number of attributes make the linkage process a challenging task. We present in this paper methodology to integrate the three data sources and a preliminary analysis of the longitudinal data.",2016,International Conference on Data Mining,Fields of study: systematicscouplingoperations researchdata miningcomputer science
Multi-view Clustering via Concept Factorization with Local Manifold Regularization,Hao WangYan Yang (Southwest Jiaotong University)Tianrui Li (Southwest Jiaotong University),"2708286127,2490442693,2170560173","Real-world datasets often have representations in multiple views or come from multiple sources. Exploiting consistent or complementary information from multi-view data, multi-view clustering aims to get better clustering quality rather than relying on the individual view. In this paper, we propose a novel multi-view clustering method called multi-view concept clustering based on concept factorization with local manifold regularization, which drives a common consensus representation for multiple views. The local manifold regularization is incorporated into concept factorization to preserve the locally geometrical structure of the data space. Moreover, the weight of each view is learnt automatically and a co-normalized approach is designed to make fusion meaningful in terms of driving the common consensus representation. An iterative optimization algorithm based on the multiplicative rules is developed to minimize the objective function. Experimental results on nine reality datasets involving different fields demonstrate that the proposed method performs better than several state-of-the-art multi-view clustering methods.",2016,International Conference on Data Mining,Fields of study: canopy clustering algorithmcorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmfuzzy clusteringmanifoldsymmetric matrixkernelsparse matrixcluster analysisconsensus clusteringconceptual clusteringlinear programmingcombinatoricsmachine learningmathematical optimizationmathematics
Modeling Satire in English Text for Automatic Detection,Aishwarya N. Reganti (Indian Institutes of Information Technology)Tushar Maheshwari (Australian National Drag Racing Association)Upendra Kumar (Indian Institutes of Information Technology)Amitava Das (Jadavpur University)Rajiv Bajpai (Nanyang Technological University),"2583266160,2292859840,2241034697,2170389495,2151276216","According to the Merriam-Webster dictionary, satire is a trenchant wit, irony, or sarcasm used to expose and discredit vice or folly. Though it is an important language aspect used in everyday communication, the study of satire detection in natural text is often ignored. In this paper, we identify key value components and features for automatic satire detection. Our experiments have been carried out on three datasets, namely, tweets, product reviews and newswire articles. We examine the impact of a number of state-of-the-art features as well as new generalized textual features. By using these features, we outperform the state of the art by a significant 6% margin.",2016,International Conference on Data Mining,Fields of study: data modelingfeature extractionpragmaticsspeech recognitiondata miningcomputer science
A Scalable and Generic Framework to Mine Top-k Representative Subgraph Patterns,Dheepikaa NatarajanSayan Ranu (Indian Institute of Technology Madras),"2584562456,2096541091","Mining subgraph patterns is an active area of research. Existing research has primarily focused on mining all subgraph patterns in the database. However, due to the exponential subgraph search space, the number of patterns mined, typically, is too large for any human mediated analysis. Consequently, deriving insights from the mined patterns is hard for domain scientists. In addition, subgraph pattern mining is posed in multiple forms: the function that models if a subgraph is a pattern varies based on the application and the database could be over multiple graphs or a single, large graph. In this paper, we ask the following question: Given a subgraph importance function and a budget k, which are the k subgraph patterns that best represent all other patterns of interest? Weshow that the problem is NP-hard, and propose a generic framework called RESLING that adapts to arbitrary subgraphimportance functions and generalizable to both transactional graph databases as well as single, large graphs. Experimentsshow that RESLING is up to 20 times more representative of the pattern space and 2 orders of magnitude faster than the state-of-the-art techniques. The executables for the tool are available at http://www.cse.iitm.ac.in/~ayan/software.html.",2016,International Conference on Data Mining,Fields of study: maximum common subgraph isomorphism problemsubgraph isomorphism problemredundancytheoretical computer sciencedata miningdatabasecomputer science
Applying Deep Learning to Stereotypical Motor Movement Detection in Autism Spectrum Disorders,Nastaran Mohammadian RadCesare Furlanello (fondazione bruno kessler),"2566318278,11746710","Autism Spectrum Disorders (ASD) are often associated with specific atypical postural or motor behaviors, of which Stereotypical Motor Movements (SMMs) interfere with learning and social interaction. Wireless inertial sensing technology offers a valid infrastructure for real-time SMM detection, whose automation would provide support for tuned intervention and possibly early alert on the onset of meltdown events. The identification and the quantification of SMM patterns remains complex due to strong inter-subject and intra-subject variability, in particular when handcrafted features are considered. This study aims at developing automatic SMM detection systems in a real world setting, based on a deep learning architecture. Here, after a review of the current state of the art of automatic SMM detection, we propose to employ the deep learning paradigm in order to learn the discriminating features from multi-sensor accelerometer signals. Our results with convolutional neural networks provided the preliminary evidence that feature learning and transfer learning embedded in deep architectures can provide accurate SMM detectors in longitudinal scenarios.",2016,International Conference on Data Mining,Fields of study: autismconvolutionfeature extractionartificial intelligencemachine learningsimulationcomputer science
Feature Grouping Using Weighted l1 Norm for High-Dimensional Data,Bhanukiran Vinzamuri (Wayne State University)Karthik K. Padthe (Wayne State University)Chandan K. Reddy (Wayne State University),"23137369,2538008682,2100435683","Building effective predictive models from high-dimensional data is an important problem in several domains such as in bioinformatics, healthcare analytics and general regression analysis. Extracting feature groups automatically from such data with several correlated features is necessary, in order to use regularizers such as the group lasso which can exploit this deciphered grouping structure to build effective prediction models. Elastic net, fused-lasso and Octagonal Shrinkage Clustering Algorithm for Regression (oscar) are some of the popular feature grouping methods proposed in the literature which recover both sparsity and feature groups from the data. However, their predictive ability is affected adversely when the regression coefficients of adjacent feature groups are similar, but not exactly equal. This happens as these methods merge such adjacent feature groups erroneously, which is also called the misfusion problem. In order to solve this problem, in this paper, we propose a weighted l1 norm-based approach which is effective at recovering feature groups, despite the proximity of the coefficients of adjacent feature groups, building extremely accurate predictive models. This convex optimization problem is solved using the fast iterative soft-thresholding algorithm (FISTA). We depict how our approach is more effective at resolving the misfusion problem on synthetic datasets compared to existing feature grouping methods such as the elastic net, fused-lasso and oscar. We also evaluate the goodness of the model on real-world breast cancer gene expression and the 20-Newsgroups datasets.",2016,International Conference on Data Mining,Fields of study: clustering high dimensional dataregularizationregressionfeaturedata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Generating Time-Varying Road Network Data Using Sparse Trajectories,Elif EserFurkan KocayusufogluBahaeddin Eravci (Bilkent University)Hakan Ferhatosmanoglu (Bilkent University)Josep-Lluís Larriba-Pey,"2418226199,2585525369,2308284180,217414012,2695030833","While research on time-varying graphs has attracted recent attention, the research community has limited or no access to real datasets to develop effective algorithms and systems. Using noisy and sparse GPS traces from vehicles, we develop a time-varying road network data set where edge weights differ over time. We present our methodology and share this dataset, along with a graph manipulation tool. We estimate the traffic conditions using the sparse GPS data available by characterizing the sparsity issues and assessing the properties of travel sequence data frequency domain. We develop interpolation methods to complete the sparse data into a complete graph dataset with realistic time-varying edge values. We evaluate the performance of time-varying and static shortest path solutions over the generated dynamic road network. The shortest paths using the dynamic graph produce very different results than the static version. We provide an independent Java API and a graph database to analyze and manipulate the generated time-varying graph data easily, not requiring any knowledge about the inners of the graph database system. We expect our solution to support researchers to pursue problems of time-varying graphs in terms of theoretical, algorithmic, and systems aspects. The data and Java API are available at: http://elif.eser.bilkent.edu.tr/roadnetwork.",2016,International Conference on Data Mining,Fields of study: graph databasevehicle dynamicstrajectoryglobal positioning systemalgorithm designtheoretical computer sciencedata miningmachine learningcomputer science
Data Mining Based Product Marketing Technique for Banking Products,Merve Mitik (Middle East Technical University)Ozan Korkmaz (Middle East Technical University)Pinar Karagoz (Middle East Technical University)Ismail Hakki Toroslu (Middle East Technical University)Ferhat Yucel,"2585432363,2709044729,2068042486,2065608331,2585118214","In direct marketing, in order to increase the return rate of a marketing campaign, the massive customer dataset is needed to be analyzed, to make best product offers to the customers through the most proper channels. However, this problem is very challenging, since, usually only for very small portions of the whole dataset, some positive returns are received. This paper studies the similar problem for bank product marketing. The proposed approach is a two layer system, which first clusters the customers and then, constructs a classification model for product and communication channel offers. Experimental analysis on real life banking campaign dataset shows promising results.",2016,International Conference on Data Mining,Fields of study: predictive modellingcluster analysispersonalized marketingdata miningmachine learningcomputer science
Relief of Spatiotemporal Accessibility Overloading with Optimal Resource Placement,Chien-Wei Chang (National Cheng Kung University)Hao-Yi ChihDean ChouYu-Chen ShuKun-Ta Chuang (National Cheng Kung University),"2231931080,2709896256,2710958393,2663876527,2124692862","With the effects of global warming, some epidemic diseases via mosquito (e.g. mosquito-borne diseases) become more serious, such as dengue fever and zika virus. It is reported that the epidemic disease may cause many challenges to the hospital management due to the unexpected burst with uncertain reasons. Furthermore, the imperfect cares during the propagation of epidemic diseases, such as dengue fever (so far the appropriate treatment is not well established), may lead to the increasing mortality rate which should be avoided. In this paper, a novel paradigm for optimizing the placement of medical resource is proposed in pursuit of reducing the overloading cases in hospitals during the epidemic outbreak in the urban area. In this paper we explore the first paper to explore two important issues, including the strategy to evaluate the service quality and the solution to dynamically dispatch the medical resource, along with the spatial variation of epidemic outbreak. As validated in our experimental results in real data of dengue outbreak happening in Tainan (2015), we present the feasibility of our framework to deploy a dynamic placement strategy for medical resource assignment.",2016,International Conference on Data Mining,Fields of study: graphical modeldistribution functionresource managementoperations researchdata miningmachine learningsimulationcomputer science
Text Network Exploration via Heterogeneous Web of Topics,Junxian HeYing HuangChangfeng Liu (Shanghai Jiao Tong University)Jiaming Shen (Shanghai Jiao Tong University)Yuting JiaXinbing Wang (Shanghai Jiao Tong University),"2619127829,2527714108,2513102232,2517617340,2597145273,2114846615","A text network refers to a data type that each vertex is associated with a text document and the relationship between documents is represented by edges. The proliferation of text networks such as hyperlinked webpages and academic citation networks has led to an increasing demand for quickly developing a general sense of a new text network, namely text network exploration. In this paper, we address the problem of text network exploration through constructing a heterogeneous web of topics, which allows people to investigate a text network associating word level with document level. To achieve this, a probabilistic generative model for text and links is proposed, where three different relationships in the heterogeneous topic web are quantified. We also develop a prototype demo system named TopicAtlas to exhibit such heterogeneous topic web, and demonstrate how this system can facilitate the task of text network exploration. Extensive qualitative analyses are included to verify the effectiveness of this heterogeneous topic web. Besides, we validate our model on real-life text networks, showing that it preserves good performance on objective evaluation metrics.",2016,International Conference on Data Mining,Fields of study: co occurrence networksnoisy text analyticsprobabilistic logicnickelprototypecomputational modeltext miningdata scienceworld wide webdata miningmachine learningcomputer science
airVLC: An Application for Visualizing Wind-Sensitive Interpolation of Urban Air Pollution Forecasts,Lidia Contreras-OchandoCesar Ferri (Polytechnic University of Valencia),"2585840281,2643711545","Air pollution has been identified as a major source of health problems for people living in cities. In this sense, it is important to identify the areas of the city that present high levels of pollutants in order to avoid them. airVLC is an application for predicting and interpolating real-time urban air pollution forecasts for the city of Valencia (Spain). We compare different regression models in order to predict the levels of four pollutants (NO, NO2, SO2, O3) in the six measurement stations of the city. Since wind is a key feature in the dispersion of the pollution, we study different techniques to incorporate this factor in the models. Finally, we are able to interpolate forecasts all around the city. For this goal, we propose a new interpolation method that takes wind direction into account, improving well-known methods like IDW or Kriging. By using these pollution estimates, we are able to generate real-time pollution maps of the city of Valencia and publish them into a public website.",2016,International Conference on Data Mining,Fields of study: air pollutioninterpolationpredictive modellingmachine learningcomputer science
Visual Context Learning with Big Data Analytics,Mayanka Chandrashekar (University of Missouri–Kansas City)Yugyung Lee (University of Missouri–Kansas City),"2311788989,2113943634","Understanding contextual information composed of both text and images is very useful for multimedia information processing. However, capturing such contexts is not trivial, especially while dealing with real datasets. Existing solutions such as using ontologies (e.g., WordNet) are mainly interested in individual terms, but they do not support identifying a group of terms that describe a specific context available at runtime. Within our knowledge, there are very limited solutions regarding the integration of contextual information from both images and text. Furthermore, existing solutions are not scalable due to the computationally intensive tasks and are prone to data sparsity. In this paper, we propose a semantic framework, called VisContextthat is based on a contextual model combined with images and text. The VisContext framework is based on the scalable pipeline that is composed of the primary components as follows: (i)Natural Language Processing (NLP), (ii) Feature extraction usingTerm Frequency-Inverse Document Frequency (TF-IDF), (iii)Feature association using unsupervised learning algorithms including K-Means clustering (KM) and Expectation-Maximization(EM) algorithms, iv) Validation of visual context models using supervised learning algorithms (Naive Bayes, Decision Trees, Random Forests). The proposed VisContext framework has been implemented with the Spark MLlib and CoreNLP. We have evaluated the effectiveness of the framework in visual understanding with three large datasets (IAPR, Flick3k, SBU) containing more than one million images and their annotations. The results are reported in the discovery of the contextual association of terms and images, image context visualization, and image classification based on contexts.",2016,International Conference on Data Mining,Fields of study: context modelvisualizationfeature extractionbig datasemanticsdata sciencedata miningmachine learningcomputer science
A Scalable Framework for Stylometric Analysis Query Processing,Sarana NutanongChenyun Yu (City University of Hong Kong)Raheem SarwarPeter XuDickson Chow,"2682711756,2314664805,2556686639,2676719362,2585439651","Stylometry is the statistical analyses of variationsin the author's literary style. The technique has been used inmany linguistic analysis applications, such as, author profiling, authorship identification, and authorship verification. Over thepast two decades, authorship identification has been extensivelystudied by researchers in the area of natural language processing. However, these studies are generally limited to (i) a small number of candidate authors, and (ii) documents with similar lengths. In this paper, we propose a novel solution by modeling authorship attribution as a set similarity problem to overcome the two stated limitations. We conducted extensive experimental studies on a real dataset collected from an online book archive, Project Gutenberg. Experimental results show that in comparison to existing stylometry studies, our proposed solution can handlea larger number of documents of different lengths written by alarger pool of candidate authors with a high accuracy.",2016,International Conference on Data Mining,Fields of study: writingprobabilistic logicfeature extractiondata scienceinformation retrievaldata miningmachine learningcomputer science
The Truth and Nothing But the Truth: Multimodal Analysis for Deception Detection,Mimansa JaiswalSairam TabibuRajiv Bajpai (Nanyang Technological University),"2584824868,2585768211,2151276216","We propose a data-driven method for automatic deception detection in real-life trial data using visual and verbal cues. Using OpenFace with facial action unit recognition, we analyze the movement of facial features of the witness when posed with questions and the acoustic patterns using OpenSmile. We then perform a lexical analysis on the spoken words, emphasizing the use of pauses and utterance breaks, feeding that to a Support Vector Machine to test deceit or truth prediction. We then try out a method to incorporate utterance-based fusion of visual and lexical analysis, using string based matching.",2016,International Conference on Data Mining,Fields of study: visualizationsupport vector machinefeature extractionfacial recognition systemhidden markov modelspeech recognitionpattern recognitionmachine learningcomputer science
Semi-Supervised Multi-label Dimensionality Reduction,Baolin GuoChenping Hou (National University of Defense Technology)Feiping Nie (Northwestern Polytechnical University)Dongyun Yi (National University of Defense Technology),"2585723835,2169743412,2245267964,2120705723","Multi-label data with high dimensionality arise frequently in data mining and machine learning. It is not only time consuming but also computationally unreliable when we use high-dimensional data directly. Supervised dimensionality reduction approaches are based on the assumption that there are large amounts of labeled data. It is infeasible to label a large number of training samples in practice especially in multi-label learning. To address these challenges, we propose a novel algorithm, namely Semi-Supervised Multi-Label Dimensionality Reduction (SSMLDR), which can utilize the information from both labeled data and unlabeled data in an effective way. First, the proposed algorithm enlarges the multi-label information from the labeled data to the unlabeled data through a special designed label propagation method. It then learns a transformation matrix to perform dimensionality reduction by incorporating the enlarged multi-label information. Extensive experiments on a broad range of datasets validate the effectiveness of our approach against other well-established algorithms.",2016,International Conference on Data Mining,Fields of study: diffusion mapdimensionality reductioncorrelationpredictionconvergencealgorithm designsemi supervised learningdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Dynamic Contextual Multi Arm Bandits in Display Advertisement,Hongxia YangQuan Lu,"2701469130,2676612536","We model the ad selection task as a multi-armed bandit problem. Standard assumptions in the multi-armed bandit (MAB) setting are that samples drawn from each arm areindependent and identically distributed, rewards (or conversionrates in our scenario) are stationary and rewards feedback areimmediate. Although the payoff function of an arm is allowed toevolve over time, the evolution is assumed to be slow. Display ads, on the other hand, are regularly created while others are removed from circulation. This can occur when budgets run out, campaign goal changes, holiday season ends and many other latent factors that go beyond the control of the ad selection system. Another big challenge is that the set of available ads is often extremely huge but standard multi-armed bandit strategies converge with linear time complexity that cannot accommodate the usually dynamic changes. Due to the above challenges and the restrictions of the original MAB, we propose a novel dynamic contextual MAB which tightly integrates components of dynamic conversion rates prediction, contextual learning and arm overlapping modeling in a principled framework. Besides we propose an accompaniedmeta analyses framework that allows us to conclude experiments in a more statistically robust manner. We demonstrate on a world leading demand side platform (DSP) that our framework can effectively discriminate premium arms and significantly outperform some standard variations of MAB to these settings.",2016,International Conference on Data Mining,Fields of study: digital signal processingpredictive modellingalgorithm designstochastic processdata miningartificial intelligencemachine learningsimulationstatisticscomputer science
SemStim: Exploiting Knowledge Graphs for Cross-Domain Recommendation,"Benjamin Heitmann (National University of Ireland, Galway)Conor Hayes (National University of Ireland, Galway)","2311535950,2099954206","In this paper we introduce SemStim, an unsupervised graph-based algorithm that addresses the cross-domain recommendation task. In this task, preferences from one conceptual domain (e.g. movies) are used to recommend items belonging to another domain (e.g. music). SemStim exploits the semantic links found in a knowledge graph (e.g. DBpedia), to connect domains and thus generate recommendations. As a key benefit, our algorithm does not require (1) ratings in the target domain, thus mitigating the cold-start problem and (2) overlap between users or items from the source and target domains. In contrast, current state-of-the-art personalisation approaches either have an inherent limitation to one domain or require rating data in the source and target domains. We evaluate SemStim by comparing its accuracy to state-of-the-art algorithms for the top-k recommendation task, for both single-domain and cross-domain recommendations. We show that SemStim enables cross-domain recommendation, and that in addition, it has a significantly better accuracy than the baseline algorithms.",2016,International Conference on Data Mining,Fields of study: mediaalgorithm designsemanticsworld wide webinformation retrievaldata miningmachine learningcomputer science
Database Integrated Analytics Using R: Initial Experiences with SQL-Server + R,Josep Lluis Berral (Polytechnic University of Catalonia)Nicolás Poggi (Birmingham–Southern College),"2026048867,160053592","Most data scientists use nowadays functional or semi-functional languages like SQL, Scala or R to treat data, obtained directly from databases. Such process requires to fetch data, process it, then store again, and such process tends to be done outside the DB, in often complex data-flows. Recently, database service providers have decided to integrate ""R-as-a-Service"" in their DB solutions. The analytics engine is called directly from the SQL query tree, and results are returned as part of the same query. Here we show a first taste of such technology by testing the portability of our ALOJA-ML analytics framework, coded in R, to Microsoft SQL-Server 2016, one of the SQL+R solutions released recently. In this work we discuss some data-flow schemes for porting a local DB + analytics engine architecture towards Big Data, focusing specially on the new DB Integrated Analytics approach, and commenting the first experiences in usability and performance obtained from such new services and capabilities.",2016,International Conference on Data Mining,Fields of study: software analyticsanalyticssqlbig dataworld wide webdata miningdatabasecomputer science
College Student Scholarships and Subsidies Granting: A Multi-modal Multi-label Approach,Han-Jia Ye (Nanjing University)De-Chuan Zhan (Nanjing University)Xiaolin LiZhen-Chuan HuangYuan Jiang (Nanjing University),"2226363573,2131836931,2584483830,2584411200,2100145838","Scholarships and financial aids in modern universities are the basic administrative plans to ensure and promote the completion of academic training and studies for students. Traditional grants allocation procedures are based on manual determination, which costs lots of human resources. In this paper, we investigate an assistance model for helping improve the scheme of granting. We first collect students information from multi-modal channels, including their behaviors of campus consumption, internet usage, daily trajectory together with their enrollment information. The approval status and amount of funds granted are converted as labels. We propose the College Student Scholarships and Subsidies Granting (CS3G) approach to address the concrete problem. CS3G approach overcomes 3 obstacles, i.e., complicated multi-label influences, private modal information protection and difficulties in label collection. In detail, based on the facts that scholarships mainly depend on academic achievements, subsidies granting is generally based on students financial hardships as well as credits, and there are implicit influences among scholarships and subsidies, the CS3G approach handles types of interactions between multiple labels, it is notable that data from different modalities are collected by different divisions of a university, privacy protection is considered in CS3G, i.e., no interaction between features from different modalities in the model training phase. Besides, due to the confidentiality of the concrete types/amounts of granting, only a portion of labels is collected in this application, CS3G is trained in a semi-supervised style. Empirical investigations show good generalization ability of CS3G on benchmark datasets, and a real assessment of a university also validates the power of our approach for tackling this type of problem well.",2016,International Conference on Data Mining,Fields of study: concretetrajectorythe internetfeature extractionresource managementoperations researchdata miningmachine learningsimulationcomputer science
Stick Must Fall: Using Machine Learning to Predict Human Error in Virtual Balancing Task,Irina ZgonnikovaArkady Zgonnikov (University of Aizu)Shigeru Kanemoto (University of Aizu),"2584407246,148368325,2146866594","This work presents a new approach to prediction of human control error in unstable systems. We consider virtual inverted pendulum (stick) as a characteristic example of such system. The proposed approach is based on applying classification via machine learning to distinguish between the samples of human control corresponding to successful balancing and critical control errors (resulting in stick fall). To illustrate the approach, we analyze the previously collected data on human balancing of virtual overdamped stick. The obtained results demonstrate that, at least in the considered balancing problem, as much as 73% of human control errors can be successfully predicted in advance (as early as one second before the stick fall).",2016,International Conference on Data Mining,Fields of study: predictionfeature extractiontime seriescontrol systemreal time computingartificial intelligencemachine learningsimulationstatisticscomputer sciencemathematics
Medical Image Denoising Using Convolutional Denoising Autoencoders,Lovedeep Gondara,2719566006,"Image denoising is an important pre-processing step in medical image analysis. Different algorithms have been proposed in past three decades with varying denoising performances. More recently, having outperformed all conventional methods, deep learning based models have shown a great promise. These methods are however limited for requirement of large training sample size and high computational costs. In this paper we show that using small sample size, denoising autoencoders constructed using convolutional layers can be used for efficient denoising of medical images. Heterogeneous images can be combined to boost sample size for increased denoising performance. Simplest of networks can reconstruct images with corruption levels so high that noise and signal are not differentiable to human eye.",2016,International Conference on Data Mining,Fields of study: non local meansvideo denoisingnoise measurementnoise reductionconvolutional codemedical imagingcomputer visionpattern recognitionmachine learningcomputer science
"Adaptive Neighborhood Propagation by Joint L2,1-Norm Regularized Sparse Coding for Representation and Classification",Lei Jia (Soochow University)Zhao Zhang (Soochow University)Lei Wang (Soochow University)Weiming Jiang (Soochow University)Mingbo Zhao (City University of Hong Kong),"2460321101,2490460293,2646445567,2222532096,2147449693","We propose a new transductive label propagation method, termed Adaptive Neighborhood Propagation (Adaptive-NP) by joint L2,1-norm regularized sparse coding, for semi-supervised classification. To make the predicted soft labels more accurate for predicting the labels of samples and to avoid the tricky process of choosing the optimal neighborhood size or kernel width for graph construction, Adaptive-NP seamlessly integrates sparse coding and neighborhood propagation into a unified framework. That is, the sparse reconstruction error and classification error are combined for joint minimization, which clearly differs from traditional methods that explicitly separate graph construction and label propagation into independent steps, which may result in inaccurate predictions. Note that our Adaptive-NP alternately optimize the sparse codes and soft labels matrices, where the sparse codes are used as adaptive weights for neighborhood propagation at each iteration, so the tricky process of determining neighborhood size or kernel width is avoided. Besides, for enhancing sparse coding, we use the L2,1-norm constraint on the sparse coding coefficients and the reconstruction error at the same time for delivering more accurate and robust representations. Extensive simulations show that our model can deliver state-of-the-art performances on several public datasets for classification.",2016,International Conference on Data Mining,Fields of study: sparse approximationmanifoldkernelsparse matrixrobustnessencodingpattern recognitionmachine learningmathematical optimizationstatisticsmathematics
Incorporate Hashing with Multi-view Learning,Jingjing TangDewei Li,"2584446109,2584259980","Multi-view learning concentrates on multiple distinct feature sets mainly following either the consensus principle or the complementary principle. SVM-2K, as a typical SVM-based multi-view learning model, extends SVM for multi-view learning by combining Kernel Canonical Correlation Analysis (KCCA). However, SVM-2K cannot fully unleash the power of the complementary information among different feature views. Recently, a framework of Predictable Dual-View Hashing (PDH) has been proposed to process two-view data sharing the complementary information. Motivated by PDH, we propose a novel strategy: Incorporate Hashing with Multi-view Learning (IHMVL). The specific implementation of IHMVL is to incorporate the PDH algorithm with SVM-2K for two-view classification, which suffices to both the consensus and complementary principles. This is the first work that extends hashing to multi-view learning. Experimental results on the synthetic data sets confirm the effectiveness of the proposed method.",2016,International Conference on Data Mining,Fields of study: feature hashingbinary codekernelsupport vector machinepredictionalgorithm designdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
MoCham: Robust Hierarchical Clustering Based on Multi-objective Optimization,Tomas BartonTomas BrunaPavel Kordik,"2635008445,2584198008,2562369882","Many clustering evaluation methods are computed as a ratio between two objectives, typically these objectives express the compactness of all clusters while trying to maximize the separation between individual clusters. However, the clustering process itself is typically implemented as a single objective problem: optimizing a linear combination of between-points closeness. We propose MoCham - a hierarchical clustering algorithm that uses a multi-objective optimization for finding the optimal data points to merge. Our results suggest that a careful candidate selection of Pareto dominating pairs leads to more robust clustering results.",2016,International Conference on Data Mining,Fields of study: hierarchical clustering of networksflame clusteringk medians clusteringbrown clusteringcanopy clustering algorithmdetermining the number of clusters in a data setdbscancorrelation clusteringconstrained clusteringdata stream clusteringcure data clustering algorithmsingle linkage clusteringaffinity propagationfuzzy clusteringclustering high dimensional datahierarchical clusteringsortingcluster analysisalgorithm designmeasurementconsensus clusteringbiclusteringdata miningmachine learningmathematical optimizationcomputer sciencemathematics
Traffic Speed Prediction and Congestion Source Exploration: A Deep Learning Method,Jingyuan WangQian GuJunjie WuGuannan LiuZhang Xiong,"2713165764,2622198377,2631224207,2660553958,2695089386","Traffic speed prediction is a long-standing and critically important topic in the area of Intelligent Transportation Systems (ITS). Recent years have witnessed the encouraging potentials of deep neural networks for real-life applications of various domains. Traffic speed prediction, however, is still in its initial stage without making full use of spatio-temporal traffic information. In light of this, in this paper, we propose a deep learning method with an Error-feedback Recurrent Convolutional Neural Network structure (eRCNN) for continuous traffic speed prediction. By integrating the spatio-temporal traffic speeds of contiguous road segments as an input matrix, eRCNN explicitly leverages the implicit correlations among nearby segments to improve the predictive accuracy. By further introducing separate error feedback neurons to the recurrent layer, eRCNN learns from prediction errors so as to meet predictive challenges rising from abrupt traffic events such as morning peaks and traffic accidents. Extensive experiments on real-life speed data of taxis running on the 2nd and 3rd ring roads of Beijing city demonstrate the strong predictive power of eRCNN in comparison to some state-of-the-art competitors. The necessity of weight pre-training using a transfer learning notion has also been testified. More interestingly, we design a novel influence function based on the deep learning model, and showcase how to leverage it to recognize the congestion sources of the ring roads in Beijing.",2016,International Conference on Data Mining,Fields of study: floating car dataconvolutionfeature extractiondata miningartificial intelligencemachine learningsimulationcomputer science
Towards Data-Driven Football Player Assessment,Rade Stanojevic (Qatar Computing Research Institute)Laszlo Gyarmati (Qatar Computing Research Institute),"2613939440,2550338640","Understanding the value of a football player is a challenging problem. Player valuation is not only critical for scouting, bidding and negotiation processes but also attracts a large media and fan interest. Due to the complexities which arise from the fact that player pool is distributed over hundreds of different leagues and many different playing positions, many clubs hire domain experts (often retired professional players) in order to evaluate the value of potential players. We argue that such human-based scouting has several drawbacks including high cost, inability to scale to thousands of active players and inevitable subjective biases. In this paper we present a methodology for data-driven player market value estimation which tackles these drawbacks. To examine the quality of the proposed methodology and demonstrate that our data-driven valuation outperforms widely used transfermarkt.com market value estimates in predicting the team performance.",2016,International Conference on Data Mining,Fields of study: performance measurementcost accountinggamesfeature extractiondata miningmachine learningsimulationcomputer science
Domain Driven Forecasting: Applying Theory Into Practice,Praveen Venkateswaran (Birla Institute of Technology and Science)Vikrant Shimpi (Tata Research Development and Design Centre)Maitreya Natu (Tata Research Development and Design Centre)Vaishali P. Sadaphal (Tata Research Development and Design Centre),"2304784614,2278727726,2259461383,88305006","In this paper, we present our experiences in applying state-of-the-art forecasting solutions to meet the forecasting needs of various business domains. We present four real-world case-studies varying in the business objectives, forecasting needs, and domain properties. Each case-study presented unique challenges in translating theory into practice and translating forecasting observations into domain-specific recommendations. We summarize the lessons learnt while deploying across various case-studies, and demonstrate how the state-of-the-art solutions coupled with industry best practices can deliver powerful solutions to meet forecasting needs of any business domain.",2016,International Conference on Data Mining,Fields of study: serverforecastingplanningmeasurementdemand forecastingmarket researchmanagement sciencedata miningstatisticscomputer science
Centrality-Based Approach for Supervised Term Weighting,Niloofer ShanavasHui Wang (Ulster University)Zhiwei Lin (Ulster University)Glenn I. Hawe (Ulster University),"280628789,2524404606,2494229131,2089227122","The huge amount of text documents has made the manual organization of text data a tedious task. Automatic text classification helps to easily handle the large number of documents by organising them automatically into predefined classes. The effectiveness and efficiency of automatic text classification largely depends on the way text documents are represented. A text document is usually viewed as a bag of terms (or words) and represented as a vector using the vector space model where terms are assumed unordered and independent and term frequencies (or weights) are used in the representation. Graphs are another text representation scheme that considers the structure of terms in the text document which is important for natural language. Terms weighted on the basis of graph representation increase the performance of text classification. In this paper, we present a novel approach for graph-based supervised term weighting which considers information relevant for the classification task using node centrality in the co-occurrence graphs built from the labelled training documents. Our experimental evaluation of the proposed term weighting scheme on four benchmark datasets shows the scheme has consistently superior performance over the state-of-the-art term weighting methods for text classification.",2016,International Conference on Data Mining,Fields of study: noisy text analyticstime frequency analysisnatural languagetext graphtext mininginformation retrievaldata miningpattern recognitionmachine learningcomputer science
Incorporating Pre-Training in Long Short-Term Memory Networks for Tweets Classification,Shuhan Yuan (Tongji University)Xintao Wu (University of Arkansas)Yang Xiang (Tongji University),"2226023482,2623789330,2708409344","The paper presents deep learning models for tweets binary classification. Our approach is based on the Long Short-Term Memory (LSTM) recurrent neural network and hence expects to be able to capture long-term dependencies among words. We develop two models for tweets classification. The basic model, called LSTM-TC, takes word embeddings as input, uses the LSTM layer to derive semantic tweet representation, and applies logistic regression to predict tweet label. The basic LSTM-TC model, like other deep learning models, requires a large amount of well-labeled training data to achieve good performance. To address this challenge, we further develop an improved model, called LSTM-TC*, that incorporates a large amount of weakly-labeled data for classifying tweets. We present two approaches of constructing the weakly-labeled data. One is based on hashtag information and the other is based on the prediction output of some traditional classifier that does not need a large amount of well-labeled training data. Our LSTM-TC* model first learns tweet representation based on the weakly-labeled data, and then trains the logistic regression classifier based on the small amount of well-labeled data. Experimental results show that: (1) the proposed method can be successfully used for tweets classification and outperform existing state-of-the-art methods, (2) pre-training tweet representation, which utilizes weakly-labeled tweets, can significantly improve the accuracy of tweets classification.",2016,International Conference on Data Mining,Fields of study: data modelinglogic gatelogisticssemanticsdata sciencedata miningmachine learningcomputer science
Learning from User Workflows for the Characterization and Prediction of Software Crashes,Chloe AdamAntoine AliottiPaul-Henry Cournede,"2584090924,2584937986,2646025233","Reducing as much as possible the rate of software crashes is crucial especially in medical applications. In this paper, we make the assumption that crashes result from the user workflow, that is to say the sequence of user actions. Our objective is thus to identify root causes of crashes and to anticipate them in real-time, based on the analysis of the sequences of user actions. For these purposes, we introduce two methods. The first one consists in using graph-based representations to detect combinations of user actions having a high probability to provoke a software crash, thus identifying crash signatures and helping for problem resolution. The second one, based on clustering of user sessions, is a real-time monitoring method, computing a crash probability at each new user action. Test cases show promising results for both methods. Our representation of user session as 'Graph-of-Actions' enabled the identification of some significant crash signatures while revealing the impact of successive actions dependence on crash causes. Likewise, our clustering based method for session monitoring resulted in promising values of sensitivity and specificity for some specific clustering configurations.",2016,International Conference on Data Mining,Fields of study: user modelingmedical imagingworld wide webcomputer securitydata miningmachine learningsimulationcomputer science
Weakly Supervised Hand Pose Recovery with Domain Adaptation by Low-Rank Alignment,Chaoqun Hong (Xiamen University of Technology)Jun YuRongsheng Xie (Xiamen University of Technology)Dapeng Tao,"2707899495,2694426239,2107597282,2649528492","Human hand pose recovery (HPR) in depth images is usually conducted by constructing mappings between 2D depth images and 3D hand poses. It is a challenging task since the feature spaces of 2D images and 3D poses are different. Therefore, a large number of labeled data is required for training, especially for popular frameworks such as deep learning. In this paper, we propose an HPR method with weak supervision. It is based on neural network and domain adaptation is introduced to enhance the trained model. To achieve domain adaptation, we propose low-rank alignment, which aligns the testing samples to the distribution of labeled samples. In this process, autoencoders are used to extract 2D image features and low-rank representation is used to describe this feature space. Therefore, the proposed method is named as Domain Adaptation with Low-Rank Alignment (DALA). In this way, we obtain a robust and non-linear mapping from 2D images to 3D poses. Experiments are conducted on two challenging benchmark datasets MSRA and ICVL. Both the results on a single dataset and across datasets show the outstanding performance of DALA.",2016,International Conference on Data Mining,Fields of study: manifoldfeature extractionsoftware testingartificial neural networkcomputer visiondata miningpattern recognitionmachine learningcomputer science
Competition-Wide Evaluation of Individual and Team Movements in Soccer,Laszlo Gyarmati (Qatar Computing Research Institute)Mohamed Hefeeda (Qatar Computing Research Institute),"2550338640,2047114949","It is challenging to get access to datasets related to the physical performance of soccer players. The teams consider such information highly confidential, especially if it covers in-game performance. Hence, most analysis and evaluation of the players' performance do not contain much information on the physical aspect of the game. We propose a novel method to solve this issue by deriving individual and team movements in soccer. We use event-based datasets allowing us to analyze the movement profiles of potentially tens of thousands of players. By analyzing the similarity of players based on their movements we find that C. Ronaldo and Ruben Castro were extremely similar despite having two orders of magnitude in their market values, 29 players are more similar to Ronaldo than the most similar counterpart of Messi based on the consistency and uniqueness of their trajectories, and that teams use an abundance of unique attacking schemes, 8909 unique attacks were launched in the 2012/13 season of the Spanish league. Our study reveals novel, actionable insights for the soccer industry at an unprecedented scale.",2016,International Conference on Data Mining,Fields of study: social movementgamestrajectorytrackingdata acquisitionmultimediasimulation
A Novel Method for Assessing Event Impacts on Event-Driven Time Series,Lianhua Chi (Huazhong University of Science and Technology)Saket SatheBo HanYun Wang,"2171352450,2652623270,2585681489,2584881461","Many real-world applications, such as service execution, data centre monitoring, remote sensing, traffic control, customer behaviour, have to deal with the time series which include the values occurring at random time points driven by events. These kinds of time series are sometimes also referred to as event-driven time series. Although estimating the correlation between two time series has been well studied, the correlation between events and time series has been understudied. This paper introduces a novel method for assessing event impacts on event-driven time series. In this paper, we estimate the actual event impact time on a time series using a novel and generic algorithm SPEAK. Furthermore, we propose a novel metric Ascore to qualitatively and quantitatively measure the event impact. Our experiments on real-world datasets suggest the combination of Ascore and SPEAK achieved much more accurate results compared to benchmarks.",2016,International Conference on Data Mining,Fields of study: benchmarktimecorrelationtime seriesdata miningsimulationstatisticsmathematics
Authenticating Web User’s Identity through Browsing Sequences Modeling,Peihai ZhaoChungang Yan (Tongji University)Changjun Jiang,"2705079591,2124021327,2650817507","With the number of users on the Web increasing sharply, how to effectively verify users' identities in order to prevent account theft as well as identity fraud is urging. In this paper, we utilize the web browsing sequences of users, which can directly reflect the logical trajectories of individuals in cyberspace, to depict the profile for each user. Based on these profiles, two approaches are proposed to authenticate the web user's identity. The first one is MSIA (Markov Sequence based Identity Authentication). In MSIA, we construct a behavioral Markov model to depict each user's logical behavior. The second one is SPIA (Sequence and Preference based Identity Authentication). In SPIA, two non-sequential features, i.e. the browsing time and the classes of web pages, are further included in MSIA to strengthen the modeling ability. In addition, both of these two approaches are user-friendly, which means the process of behavioral authenticating is running as daemons. The daemons verify user's identity continuously and invisibly during the whole browsing period, instead of one-time authentication at login stage. Based on the behavioral data of 1000 users collected from China Internet Network Information Center, we verify the proposed methods on 1,496,758 test sequences. The experimental results show that the average accuracy of both authentication methods is up to 90%.",2016,International Conference on Data Mining,Fields of study: web pageauthenticationmarkov processcomputational modelinternet privacyworld wide webcomputer securitydata miningstatisticscomputer science
Online Outlier Detection of Energy Data Streams Using Incremental and Kernel PCA Algorithms,Jeremiah D. Deng,2683579544,"Outlier detection or anomaly detection is an important and challenging issue in data mining, even so in the domain of energy data mining where data are often collected in large amounts but with little labeled information. This paper presents a couple of online outlier detection algorithms based on principal component analysis. Novel algorithmic treatments are introduced to build incremental PCA and kernel PCA algorithms with online learning abilities. Some preliminary experimental results obtained from a real-world household consumption dataset have produced some promising performance for the proposed algorithms.",2016,International Conference on Data Mining,Fields of study: kernelprincipal component analysisalgorithm designsoftware testingdata miningpattern recognitionmachine learningcomputer science
Sentiment Lexica from Paired Comparisons,Christoph DalitzKatrin E. Bednarek,"2679215068,2585748906","The method of paired comparison is an established method in psychology for assigning ranks or inherent score values to different stimuli. This article describes how this method can be used for building a sentiment lexicon and for extending the lexicon with arbitrary new words. An initial lexicon with n=200 German words is created from a two-fold all-pair comparison experiment with ten different test persons. A cross-validation experiment suggests that only two-fold log_2(n)+8=16 comparisons are necessary to estimate the score of a new, yet unknown word. We make the new lexicon available and compare it with the corpus-based lexica SentiWS and SenticNet.",2016,International Conference on Data Mining,Fields of study: method of momentsdistribution functionsiliconestimationspeech recognitiondata miningpattern recognitionstatisticsmathematics
Spectrum-Revealing Cholesky Factorization for Kernel Methods,Jianwei XiaoMing Gu,"2394544888,2584416282","Kernel methods represent some of the most popular machine learning tools for data analysis. Since exact kernel methods can be prohibitively expensive for large problems, reliable low-rank matrix approximations and high-performance implementations have become indispensable for practical applications of kernel methods. In this work, we introduce spectrum-revealing Cholesky factorization, a reliable low-rank matrix factorization, for kernel matrix approximation. We also develop an efficient and effective randomized algorithm for computing this factorization. Our numerical experiments demonstrate that this algorithm is as effective as other Cholesky factorization based kernel methods on machine learning problems, but significantly faster.",2016,International Conference on Data Mining,Fields of study: kernel embedding of distributionstree kernelgraph kernelpolynomial kernelminimum degree algorithmradial basis function kernelkernel methodkernelpredictionalgorithm designreliabilityapproximation algorithmtheoretical computer sciencemachine learningmathematical optimizationstatisticsmathematics
Reliable Semi-supervised Learning,Junming ShaoChen HuangQinli YangGuangchun Luo,"2654645914,2585915277,2715978720,2687313704","In this paper, we propose a Reliable Semi-Supervised Learning framework, called ReSSL, for both static and streaming data. Instead of relaxing different assumptions, we do model the reliability of cluster assumption, quantify the distinct importance of clusters (or evolving micro-clusters on data streams), and integrate the cluster-level information and labeled data for prediction with a lazy learning framework. Extensive experiments demonstrate that our method has good performance compared to state-of-the-art algorithms on data sets in both static and real streaming environments.",2016,International Conference on Data Mining,Fields of study: online machine learninggeneralization errordata modelingtraining setcluster analysisreliabilitysemi supervised learninginstance based learningsupervised learningunsupervised learningdata miningpattern recognitionmachine learningcomputer science
From Training to Match Performance: A Predictive and Explanatory Study on Novel Tracking Data,Javier Fernandez (Johnson & Johnson Pharmaceutical Research and Development)Daniel MedinaAntonio Gomez (Johnson & Johnson Pharmaceutical Research and Development)Marta Arias (Polytechnic University of Catalonia)Ricard Gavalda (Polytechnic University of Catalonia),"2270601187,2593207481,2140035133,2147210070,2253347400","The recent FIFA approval of the use of Electronic Performance and Tracking Systems (EPTS) during competition, has provided the availability of novel data regarding physical player performance. The analysis of this kind of information will provide teams with competitive advantages, by gaining a deeper understanding of the relation between training and match load, and individual player's fitness characteristics. In order to make sense of this physical data, which is inherently complex, machine learning algorithms that exploit both non-linear and linear relations among variables could be of great aid on building predictive and explanatory models. Also, the increasing availability of information brings the necessity and the challenge for successful interpretation of these models in order to be able to translate the findings into information that can be quickly applied by fast-paced practitioners, such as physical coaches. For season 2015-2016 F. C. Barcelona has collected both physical information from both training sessions and matches using EPTS devices. This study focuses primarily on evaluating up to what extent is possible to predict match performance from training and match physical information. Different machine learning algorithms are applied for building predictive regression models, in combination with feature selection techniques and Principal Component Analysis (PCA) for dimensionality reduction. Physical Variables are segmented into three groups: Locomotor, Metabolic and Mechanical variables, reaching successful prediction rates in 11 out of 17 total variables, based on a threshold determined by expert physical coaches. A normalized root mean square error metric is proposed that allows better understanding of results for practitioners. The second part of this study is focused on understanding the predictor variables that better explain each of the 17 analyzed match variables. It was found that specific variables can act as representatives of the set of highly correlated ones, so reducing greatly the amount of variables needed in the periodical physical analysis carried out by coaches, passing from 17 to 4 variables in average.",2016,International Conference on Data Mining,Fields of study: global positioning systemfeature selectiondata miningartificial intelligencemachine learningsimulationstatisticscomputer science
MobInsight: Understanding Urban Mobility with Crowd-Powered Neighborhood Characterizations,Souneil ParkMarc BourquiEnrique Frias-Martinez (Telefónica),"2637226287,2584202160,603370153","In this paper, we present MobInsight, an interactive visual tool for analyzing urban mobility. The tool aims to reveal the collective intelligence of the spatial choices expressed in the mobility patterns of the people that live in a city. It provides an analyst with a rich characterization of neighborhoods, enabling the analyst to compare the difference and infer possible reasons behind traveling behavior between the neighborhoods. MobInsight builds tailored neighborhood characterizations specific to the analyzed city by harnessing the geo-social annotations of the crowd. For the demonstration, MobInsight will feature Barcelona where the conference venue is located. Mobility patterns between the 70 neighborhoods of the city are extracted from real mobile network data of a large sample of residents, and the neighborhood characteristics are profiled by mining various online geo-social services and open government data.",2016,International Conference on Data Mining,Fields of study: mobile telephonycluster analysisalgorithm designmobile computingdata miningsimulationcomputer science
Multi-type Co-clustering of General Heterogeneous Information Networks via Nonnegative Matrix Tri-Factorization,Xianchao Zhang (Dalian University of Technology)Haixin Li (Dalian University of Technology)Wenxin Liang (Dalian University of Technology)Jiebo Luo,"2132650836,2554047175,2652291916,2694576134","Many kinds of real world data can be modeled by a heterogeneous information network (HIN) which consists of multiple types of objects. Clustering plays an important role in mining knowledge from HIN. Several HIN clustering algorithms have been proposed in recent years. However, these algorithms suffer from one or moreof the following problems: (1) inability to model general HINs, (2) inability to simultaneously generate clusters for all types of objects, (3) inability to use similarity information of the objects with the same type. In this paper, we propose a powerful HIN clustering algorithm which can handle general HINs, simultaneously generate clusters for all types of objects, and use the similarity information of the same type of objects. First, we transform a general HIN into a meta-path-encoded relationship set. Second, we propose a nonnegative matrix tri-factorization multi-type co-clustering method, HMFClus, to cluster all types of objects in HIN simultaneously. Third, we integrate the information between the objects with the same type into HMFClus by using a similarity regularization. Extensive experiments on real world datasets show that the proposed algorithm outperforms the state-of-the-art methods.",2016,International Conference on Data Mining,Fields of study: cluster analysissemanticstheoretical computer sciencedata miningmachine learningcomputer sciencemathematics
Location Recommendations for New Businesses Using Check-in Data,Bahaeddin Eravci (Bilkent University)Neslihan BulutCagri Etemoglu (Türk Telekom)Hakan Ferhatosmanoglu (Bilkent University),"2308284180,2659434418,2276922691,217414012","Location based social networks (LBSN) and mobile applications generate data useful for location oriented business decisions. Companies can get insights about mobility patterns of potential customers and their daily habits on shopping, dining, etc. to enhance customer satisfaction and increase profitability. We introduce a new problem of identifying neighborhoods with a potential of success in a line of business. After partitioning the city into neighborhoods, based on geographical and social distances, we use the similarities of the neighborhoods to identify specific neighborhoods as candidates for investment for a new business opportunity. We present two solutions for this new problem: i) a probabilistic approach based on Bayesian inference for location selection along with a voting based approximation, and ii) an adaptation of collaborative filtering using the similarity of neighborhoods based on co-existence of related venues and check-in patterns. We use Foursquare user check-in and venue location data to evaluate the performance of the proposed approach. Our experiments show promising results for identifying new opportunities and supporting business decisions using increasingly available check-in data sets.",2016,International Conference on Data Mining,Fields of study: collaborationprobabilistic logicnickelcorrelationdata miningmathematics
Low-Rank Sparse Feature Selection for Patient Similarity Learning,Mengting ZhanShilei CaoBuyue QianShiyu ChangJishang Wei,"2584846492,2583791594,2656678361,2689033784,2670189110","Comparing and identifying similar patients is a fundamental task in medical domains - an efficient technique can, for example, help doctors to track patient cohorts, compare the effectiveness of treatments, or predict medical outcomes. The goal of patient similarity learning is to derive a clinically meaningful measure to evaluate the similarity amongst patients represented by their key clinical indicators. However, it is challenging to learn such similarity, as medical data are usually high dimensional, heterogeneous, and complex. In addition, a desirable patient similarity is dependent on particular clinical settings, which implies supervised learning scheme is more useful in medical domains. To address these, in this paper we present a novel similarity learning approach formulated as the generalized Mahalanobis similarity function with pairwise constraints. Considering there always exists some features non-discriminative and contains redundant information, we encode a low-rank structure to our similarity function to perform feature selection. We evaluate the proposed model on both UCI benchmarks and a real clinical dataset for several medical tasks, including patient retrieval, classification, and cohort discovery. The results show that our similarity model significantly outperforms many state-of-the-art baselines, and is effective at removing noisy or redundant features.",2016,International Conference on Data Mining,Fields of study: similarity heuristicsparse matrixalgorithm designmeasurementlinear programmingdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Hierarchical Temporal Memory Method for Time-Series-Based Anomaly Detection,Jia WuWeiru ZengZhe ChenXue-Fei Tang,"2583711181,2583993053,2585961704,2601739357","Time-series-based anomaly detection is a quite important field that has been researched over years. Many techniques have been developed and applied successfully for certain application domains. However, there are still some challenges, such as continuously learning, tolerance to noise and generalization. This paper present Hierarchical Temporal Memory, a novel biological neural network, to time-series-based anomaly detection. HTM is able to learn the changing pattern of the data and incorporate contextual information from the past to make accurate prediction. We have evaluated HTM on real and artificial datasets. The experiment results show that HTM can successfully discover anomalies in time-series data.",2016,International Conference on Data Mining,Fields of study: robustnesspredictionalgorithm designmeasurementdata miningartificial intelligencemachine learningstatisticscomputer sciencemathematics
Incremental Time Series Prediction Using Error-Driven Informed Adaptation,Petra Vrablecova (Slovak University of Technology in Bratislava)Viera Rozinajova (Slovak University of Technology in Bratislava)Anna Bou Ezzeddine (Slovak University of Technology in Bratislava),"2231880727,26785348,2005470393","This paper presents an approach to predictive modeling of sequentially arriving data, also known as a stream. Because of their unique properties, this kind of data requires different mining techniques. The ultimate limitations are the memory and the time. Since the number of records can be infinite, it is not possible to store them all in memory or read them more than once. Hence, the prediction method should work incrementally. Another important aspect of these data is that their characteristics change over time. The identification of the ongoing change in the monitored data sequence, also called ""concept drift"", can significantly help to improve prediction accuracy by prediction model adaptation to the drifts. The challenge is to perform these model adaptations online. We have proposed an incremental adaptive method for time series prediction. Our approach is based on the adaptive learning scheme ""predict – diagnose – update"". The main concern was to find out whether our error-driven informed adaptation approach can equal the traditional blind adaptation approaches in accuracy and required resources such as time and memory. The results showed that informed adaptation can achieve comparable accuracy but uses less computational resources. We focused specifically on power demand forecasting but we showed that the approach is applicable also on time series with similar characteristics from other domains.",2016,International Conference on Data Mining,Fields of study: data modelingpredictive modellingforecastingtime seriesdata miningartificial intelligencemachine learningstatisticscomputer science
Adaptive Time Series Forecasting of Energy Consumption Using Optimized Cluster Analysis,Peter Laurinec (Slovak University of Technology in Bratislava)Marek Loderer (Slovak University of Technology in Bratislava)Petra Vrablecova (Slovak University of Technology in Bratislava)Maria Lucka (Slovak University of Technology in Bratislava)Viera Rozinajova (Slovak University of Technology in Bratislava)Anna Bou Ezzeddine (Slovak University of Technology in Bratislava),"2485390935,330081161,2231880727,2345364177,26785348,2005470393","The paper presents an improvement of incremental adaptive power load forecasting methods by performing cluster analysis prior to forecasts. For clustering the centroid based method K-means, with K-means++ centroids initialization, was used. Ten various forecasting methods were compared in order to find the most suitable ones to combine with clustering. The used data set comes from Ireland, where half-hourly measurements of electricity consumption of more than 3600 households during two years were at disposal. We have tested two types of aggregation: based on clustering and simple aggregation of all consumers. The achieved results proved our expectations. For energy consumption forecasting we have obtained significant improvement due to carrying out the cluster analysis before applying predictive techniques. The extent of improvement depends on the used forecasting method and on some other factors, which are discussed in the paper.",2016,International Conference on Data Mining,Fields of study: probabilistic forecastingpredictive modellingforecastingfeature extractiontime serieseconometricsdata miningmachine learningstatisticscomputer science
WEFEST: Word Embedding Feature Extension for Short Text Classification,Lei SangFei XieXiaojian LiuXindong Wu,"2719530363,2635765353,2585229854,2648443763","Short text classification is a crucial task for information retrieval, social medial text categorization, and many other applications. In reality, due to the inherent sparsity and the limited information available in the short texts, learning and classifying short texts is a significant challenge. In this paper, we propose a new framework, WEFEST, which expands short texts using word embedding for classification. WEFEST is rooted on the deep language model, which learns a new word embedding space, by using word correlations, such that semantically related words also have close feature vectors in the new space. By using word embedding features to help expand the short tests, WEFEST can enrich the word density in the short texts for effective learning, by following three major steps. First, each short text in the training dataset is enriched by using pre-trained word feature embedding. Then the semantic similarity between two short texts is calculated by using the statistical frequency information retrieved from the trained model. Finally, we use the nearest neighbor algorithm to achieve short text classification. Experimental results on Chinese news title dataset validate the effectiveness of the proposed method.",2016,International Conference on Data Mining,Fields of study: search enginecomputational modelsemanticsnatural language processingspeech recognitiondata miningpattern recognitionmachine learningcomputer science
HNP3: A Hierarchical Nonparametric Point Process for Modeling Content Diffusion over Social Media,Seyyed Abbas Hosseini (Sharif University of Technology)Ali Khodadadi (Sharif University of Technology)Ali ArabzadehHamid R. Rabiee (Sharif University of Technology),"2135783511,2543744255,2658922768,2032985511","This paper introduces a novel framework for modeling temporal events with complex longitudinal dependency that are generated by dependent sources. This framework takes advantage of multidimensional point processes for modeling time of events. The intensity function of the proposed process is a mixture of intensities, and its complexity grows with the complexity of temporal patterns of data. Moreover, it utilizes a hierarchical dependent nonparametric approach to model marks of events. These capabilities allow the proposed model to adapt its temporal and topical complexity according to the complexity of data, which makes it a suitable candidate for real world scenarios. An online inference algorithm is also proposed that makes the framework applicable to a vast range of applications. The framework is applied to a real world application, modeling the diffusion of contents over networks. Extensive experiments reveal the effectiveness of the proposed framework in comparison with state-of-the-art methods.",2016,International Conference on Data Mining,Fields of study: data modelingcomputational modeldata sciencedata miningmachine learningstatisticscomputer science
Discovering Multi-type Correlated Events with Time Series for Exception Detection of Complex Systems,Peng Xun (National University of Defense Technology)Pei-Dong Zhu (National University of Defense Technology)Cun-Lu LiHao-Yang Zhu (National University of Defense Technology),"2582991205,2637530827,2713192225,2519586739","With the increase of systems' complexity, exception detection becomes more important and difficult. For most complex systems, like cloud platform, exception detection is mainly conducted by analyzing a large amount of telemetry data collected from systems at runtime. Time series data and events data are two major types of telemetry data. Techniques of correlation analysis are important tools that are widely used by engineers for data-driven exception detection. Despite their importance, there has been little previous work addressing the correlations between two types of heterogeneous data for exception detection: continuous time series data and temporal events data. In this paper, we propose an approach to discovery the correlation between multi-type time series data and multi-type events data. Correlations between multi-type events data and multi-type time series data are used to detect systems' exceptions. Our experimental results on real data sets demonstrate the effectiveness of our method for exception detection.",2016,International Conference on Data Mining,Fields of study: telemetrycorrelationtime seriescomplex systemsdata sciencedata miningreal time computingstatisticscomputer sciencemathematics
"Football Market Strategies: Think Locally, Trade Globally",Giulio Rossetti (Istituto di Scienza e Tecnologie dell'Informazione)Vincenzo Caproni,"2120671011,2585275350","Every year football clubs trade players in order to build competitive rosters able to compete for success, increase the number of their supporters and amplify sponsors and media attention. In the complex system described by the football transfer market can we identify the strategies pursued by successful teams? Where do they search for new talents? Does it pay to constantly change the club roster? In this work we identify archetypal market strategies over 25 years of transfer market as depicted by UEFA professional clubs and study their impact on sportive success. Our analysis underline how, regardless from clubs' available budgets, transfer market strategies deeply impact – on the long run – football sportive performances.",2016,International Conference on Data Mining,Fields of study: read only memorycorrelationsimulationcomputer sciencemathematics
PaTSI: Pattern Mining of Time Series of Satellite Images in Knime,Maxime CollinFrederic Flouvat (University of New Caledonia)Nazha Selmaoui-Folcher (University of New Caledonia),"2585915541,2093516567,1967950925","In this paper, we present PaTSI, a tool for analyzing evolutions of objects in time series of satellite images. This tool is a plugin integrated in the KNIME Analytics Platform. PaTSI is a workflow composed of several nodes assembled together to form a whole KDD process (data selection, pre-processing, image segmentation, pattern mining and visualization). Input data consists of a time series of satellite images and GIS information on the studied area. This data is transformed in a single attributed directed acyclic graph (a-DAG), where nodes represent objects described by several attributes and edges represent temporal relationships. This graph is then mined to extract frequent evolutions (weighted path patterns) using an efficient graph mining algorithm. At the end of the process, extracted patterns can be filtered using regular expressions and displayed on the original images in order to facilitate the experts' interpretation of the results. In the present demo, the pertinence of PaTSI is illustrated through its application to soil erosion monitoring.",2016,International Conference on Data Mining,Fields of study: image segmentationsatellitetime seriesdata visualizationdata sciencecomputer visiondata miningmachine learningstatisticscomputer science
Time-Aware User Identification with Topic Models,Clement LesaegeFrancois SchnitzlerAnne LambertJean-Ronan Vigouroux,"2585506127,2700216843,2618064782,2675252543","Accounts are often shared by multiple users, eachof them having different item consumption and temporal habits. Identifying of the active user can lead to improvements ina variety of services by switching from account personalizedservices to user personalized services. To do so, we developa topic model extending the Latent Dirichlet Allocation usinga hidden variable representing the active user and assumingconsumption times to be generated by latent time topics. Wecreate a new dataset of composite accounts from real users totest the identification capabilities of our model. We show thatour model is able to learn temporal patterns from the whole setof accounts and infer the active user using both the consumptiontime and the consumed item.",2016,International Conference on Data Mining,Fields of study: televisionestimation theoryresource managementmultimediaworld wide webdata miningmachine learningsimulationstatisticscomputer sciencemathematics
Risk-Aware Dynamic Reserve Prices of Programmatic Guarantee in Display Advertising,Bowei Chen,2580439005,"Display advertising is one important online advertising type where banner advertisements (shortly ad) on websites are usually measured by how many times they are viewed by online users. There are two major channels to sell ad views. They can be auctioned off in real time or be directly sold through guaranteed contracts in advance. The former is also known as real-time bidding (RTB), in which media buyers come to a common marketplace to compete for a single ad view and this inventory will be allocated to a buyer in milliseconds by an auction model. Unlike RTB, buying and selling guaranteed contracts are not usually programmatic but through private negotiations as advertisers would like to customise their requests and purchase ad views in bulk. In this paper, we propose a simple model that facilitates the automation of direct sales. In our model, a media seller puts future ad views on sale and receives buy requests sequentially over time until the future delivery period. The seller maintains a hidden yet dynamically changing reserve price in order to decide whether to accept a buy request or not. The future supply and demand are assumed to be well estimated and static, and the model's revenue management is using inventory control theory where each computed reverse price is based on the updated supply and demand, and the unsold future ad views will be auctioned off in RTB to the meet the unfulfilled demand. The model has several desirable properties. First, it is not limited to the demand arrival assumption. Second, it will not affect the current equilibrium between RTB and direct sales as there are no posted guaranteed prices. Third, the model uses the expected revenue from RTB as a lower bound for inventory control and we show that a publisher can receive expected total revenue greater than or equal to those from only RTB if she uses the computed dynamic reserves prices for direct sales.",2016,International Conference on Data Mining,Fields of study: inventory controlmediasupply and demandcomputational modelmathematical economicsadvertisingcommercemicroeconomicsmarketingeconomicscomputer science
Parallelized Frequent Item Set Mining Using a Tall and Skinny Matrix,D. Pooja Janakiram,2583590981,"Big data applications consist of very large collection of small records, for example data from a retail website, data from movie streaming services, sensor data applications and many other such applications. Frequent item set mining is one of the common tools used for all these applications to generate recommendations to improve user experience of the website. Frequent itemset mining is also used to find interesting patterns on scientific databases such as gene expression database. One interesting way to represent such big data applications is by transforming them into tall and skinny matrices. In this paper we explore the concept of tall and skinny matrices to generate frequent item sets. The proposed algorithm is implemented on a map-reduce based framework such as Apache Spark and experiments are performed to test the scalability of the algorithm on a cloud platform.",2016,International Conference on Data Mining,Fields of study: scalabilityworld wide webdata miningdatabasecomputer science
Local Structure Preserving Using Manifold Regularization and Pairwise Constraints for Action Recognition,Xueqi MaZhengyang CaoWeifeng Liu,"2561970888,2584578557,2585036591","With the rapid development of Internet technology and smart devices, tremendous amounts of multimedia data (e.g. text, image, video, audio, etc.) are produced and uploaded online every day. Semi-supervised learning has been proved to be one effect and effective solution to manage the massive emerging multimedia, which usually leverages the performance by exploiting the local geometry of a small number of labelled and a large number of unlabeled samples. The representative local structure preserving methods include manifold regularization and pairwise constraints. In this paper, we propose a local structure preserving method that effectively integrates manifold regularization and pairwise constraints. Particularly, we construct a new graph Laplacian by combining the traditional Laplacian and pairwise constraints. The new graph Laplacian can better preserve the local geometry and then further boost the performance. Finally, we build new local structure preserving classifiers including kernel least squares and support vector machines. We conduct extensive experiments on Chinese Academy of Sciences - Yunnan University - Multimodal Human Action Database (CAS-YNU-MHAD) for action recognition, respectively. The experimental results demonstrate that the proposed algorithm outperforms the baseline algorithms.",2016,International Conference on Data Mining,Fields of study: hafniumdata miningpattern recognitionmachine learningcomputer sciencemathematics
Infer Mobility Patterns and Social Dynamics for Modelling Human Behaviour,Luca Luceri,2661968293,"Investigating human mobility patterns and comprehending the social dynamics that govern people movements is of high interest for multiple aspects and reasons. Location-based services, mobile network management, and urban planning are just few of the several applications that benefit fromthis kind of assessment. This work focuses on the stochasticanalysis of spatiotemporal and social network data in order tobuild a human behaviour model which aims to predict socialdynamics and to infer users' mobility patterns and interests.",2016,International Conference on Data Mining,Fields of study: mobility modeldata modelingmobile telephonypredictive modellingmobile computingdata miningartificial intelligencesimulationcomputer science
Relative Label Encoding for the Prediction of Airline Passenger Nationality,Alejandro MottiniRodrigo Acuna-Agost,"2705128823,2630677489","In the airline industry, a Passenger Name Record (PNR) stores the travel itinerary of an individual or group of passengers travelling together. A PNR always contains all the flight information regarding each segment of a journey, and may contain additional important information such as nationality, gender and age of the passengers. From a commercial point of view, these passenger attributes are of particular interest to all actors in the travel industry (e.g., airlines and airports). However, on average, only ten percent of PNR records have this information. Therefore, their prediction is of great interest. In this study we propose a methodology to predict the nationality of passengers based on PNR data. To avoid having to solve a classification problem with 195 classes, most of which will not be well represented in the data, we take advantage of a peculiarity of this data. In most cases, the nationality of a passenger will match the value of one or more of the other PNR attributes. Therefore, we can encode the target variable by transforming the nationality country code into the index of the feature it matches (e.g., country of origin or destination of the trip). The relative encoding of the target variable allows us to simplify the original problem significantly, while obtaining better classification accuracy. Since the new classes are non-exclusive, the problem falls in the multi-label classification paradigm. The proposed methodology was tested on PNR data of passengers passing through an important European airport, which handles more than twenty million passengers per year. The model performance was evaluated using three indicators. Results show that we are able to predict the nationalities with good accuracy, and outperform both a classical multi-class methodology and a ad-hoc rule-based algorithm used in the industry.",2016,International Conference on Data Mining,Fields of study: feature extractionencodingoperations researchdata miningmachine learningcomputer science
Faster Univariate Microaggregation for Power Law Distributions: k-Degree-Anonymity for Big Graphs,Julian Salas,2630832865,"Microaggregation is a well known and widely used statistical disclosure limitaton method. In the case of univariate microaggregation, there is a polynomial time algorithm that obtains optimal partitions by representing the optimal partition as a shortest path in a directed acyclic graph. Such algorithm is frequently used for obtaining optimal k-degree anonymizations of networks. Since there is a large and growing amount of information, and datasets are increasing in size and complexity, there is a need to obtain faster algorithms. Most of the times their precision is dropped for making them faster, this is not the case of our algorithm. We present a technique for obtaining optimal univariate microaggregation in such a way that the number of calculations is considerably reduced without affecting optimality. We apply this result for k-anonymization of the degree sequences of networks with a power law distribution. To show that this method increases its efficiency when increasing the size of the degree sequences, we generated discrete power law distributions for different exponents α with sizes of up to a billion vertices, and compared the reduction of the degree sequences obtained. Also we applied the method for real world networks to show its feasibility.",2016,International Conference on Data Mining,Fields of study: graphicsprivacydiscrete mathematicscombinatoricsdata miningmachine learningmathematical optimizationstatisticscomputer sciencemathematics
Structural Nonparallel Support Vector Machine Based on LSH for Large-Scale Prediction,Dandan Chen,2583550797,"Considering the fact that the underlying structural information in the training data within classes is vital for a good classifier in real-world classification problems, Structural Nonparallel Support Vector Machine (or SNPSVM, for short) has been proposed. By combining the structural information with nonparallel support vector machine (NPSVM), SNPSVM can fully exploit prior knowledge to directly improve the algorithm’s generalization capacity, each model of which considers not only the compactness in both classes by the structural information but also the separability between classes. In recent decades, discussions on how to train effective classifiers on huge amount of data has attracted more and more research works across several communities. However, the counterpart scalability issue how to apply big trained models efficiently on huge non annotated media collections has been reported rarely. In this paper, we address the problem of speeding-up the prediction phase of linear SNPSVM via Locality Sensitive Hashing (LSH). We propose building efficient hash-based classifiers that are applied in a first stage in order to approximate the exact results and filter the hypothesis space. Furthermore, SNPSVM is solved efficiently by an alternating optimization method, called the improved alternating direction method of multipliers (ADMM). The proposed SNPSVM based on LSH and the solving algorithm can guarantee that we can deal with large-scale classification problems with a huge number of instances as well as features. Experiments performed with millions of one-against-one classifiers show that the proposed hash-based classifier can be more than two orders of magnitude faster than the exact classifier with minor losses in quality.",2016,International Conference on Data Mining,Fields of study: training setsupport vector machineapproximation algorithmdata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Mining the Dark Web: Drugs and Fake Ids,Andres BaravalleMauro Sanchez LopezSin Wee Lee,"2660012928,2555720530,2717601771","In the last years, governmental bodies have been futilely trying to fight against dark web marketplaces. Shortly after the closing of ""The Silk Road"" by the FBI and Europol in 2013, new successors have been established. Through the combination of cryptocurrencies and nonstandard communication protocols and tools, agents can anonymously trade in a marketplace for illegal items without leaving any record. This paper presents a research carried out to gain insights on the products and services sold within one of the larger marketplaces for drugs, fake ids and weapons on the Internet, Agora. Our work sheds a light on the nature of the market, there is a clear preponderance of drugs, which accounts for nearly 80% of the total items on sale. The ready availability of counterfeit documents, while they make up for a much smaller percentage of the market, raises worries. Finally, the role of organized crime within Agora is discussed and presented.",2016,International Conference on Data Mining,Fields of study: the internetdata collectionworld wide webcomputer securitydata miningstatisticscomputer sciencemathematics
Discovering Spatial Regions of High Correlation,Prerna AgarwalRicha VermaVenkata M. V. Gunturi,"2655529547,2584860575,2615636548","Given a set of events of two different types (e.g. locations of crime incidents/road accidents) in geographic space and minimum density and area thresholds, spatial regions of high correlation discovery (RHC) aims to determine rectangular-shaped areas of high correlation between two event types. RHC discovery is important to many fields like transportation engineering, criminology, and epidemiology. Designing a scalable algorithm for RHC discovery is challenging mainly because of non-monotonicity of popular spatial statistical interest measures of association between events, one such measure being the cross-K function. This challenge makes Apriori-based pruning algorithms inapplicable. The large enumeration space is another challenge. To address these limitations, we propose a cross-K inspired interest measure and using that, a novel algorithm for RHC discovery. Real crime data is used for a case study to present the output of our algorithm. Experimental evaluation is done to show that the proposed algorithm cuts down on computation substantially as compared to the naive approach.",2016,International Conference on Data Mining,Fields of study: transportcorrelationcluster analysisalgorithm designdata sciencedata miningmachine learningsimulationcomputer science
Deep Convolutional Factor Analyser for Multivariate Time Series Modeling,Chao YuanAmit Chakraborty,"2505266043,2663953073","Deep generative models can perform dramatically better than traditional graphical models in a number of machine learning tasks. However, training such models remains challenging because their latent variables typically do not have an analytical posterior distribution, largely due to the nonlinear activation nodes. We present a deep convolutional factor analyser (DCFA) for multivariate time series modeling. Our network is constructed in a way that bottom layer nodes are independent. Through a process of up-sampling and convolution, higher layer nodes gain more temporal dependency. Our model can thus give a time series different representations at different depths. DCFA only consists of linear Gaussian nodes. Therefore, the posterior distributions of latent variables are also Gaussian and can be estimated easily using standard variational Bayes algorithm. We show that even without nonlinearity the proposed deep model can achieve state-of-the-art results in anomaly detection, classification and clustering using both synthetic and real-world datasets.",2016,International Conference on Data Mining,Fields of study: data modelingconvolutionnormal distributiontime serieshidden markov modeldata miningpattern recognitionmachine learningstatisticscomputer sciencemathematics
Activity Detection from Email Meta-Data Clustering,Mayur PatidarShaurya RohatgiAshish ChaudharyMahesh P. SinghPuneet Agarwal (Tata Consultancy Services)Gautam Shroff (Tata Consultancy Services),"2585976829,2642942841,2634115225,2595988636,2116856142,2080757065","Information workers in a large enterprise often deal with large volumes of e-mail traffic every day. In such a scenario, automatic detection of activities that they are involved in has many potential uses, and even presenting users with a summary of their current set of activities was found to be of value in itself. In this paper, we describe the problem of automatically detecting user activities from e-mails, while using only meta-data of e-mails, i.e., we do not process email contents. We present a novel two stage algorithm for automatic activity detection from users' e-mails: We first represent the e-mail dataset as a rectangular matrix using features such as other e-mails, people involved, and names of the documents attached in the e-mails. We next represent the emails in latent feature space using SVD, followed by further dimensionality reduction using t-Distributed Stochastic Neighbor embedding(t-SNE). We then cluster e-mails using density based clustering algorithm in t-SNE space. In the second stage we merge these clusters based on group properties and a community detection algorithm on the graph of clusters, to yield our set of automatically detected activities. We analyse public e-mail datasets and present benchmarks of our approach on real-life datasets collected from our target users, and also compare our algorithm with alternative approaches as well as those published in recent literature.",2016,International Conference on Data Mining,Fields of study: data modelingfeature extractioncluster analysisapproximation algorithmdata scienceworld wide webdata miningmachine learningcomputer science
Event Detection for Urban Dynamic Data Streams,Septimiu Nechifor (Siemens)Ioana StefanMarten FischerDan Puiu (Siemens),"2006722859,2687861048,2144440008,2296059845","This paper presents a framework for processing the data generated by Smart City sensors and IoT data streams in real-time. The scope of processing is to detect various event patterns from the raw data. The framework is extensible because at any moment new data sources can be registered or new specific event detection mechanism can be deployed. The framework offers a HTTP interface which can be used to provide details about each data stream. In order to connect to the heterogeneous data source end points and fetching the observations a concept of simple adaptable data wrappers is introduced. Having the streams registered into the framework, the domain expert can deploy (using a Java API) the event detection mechanism. The domain expert (maybe with some help from an application developer) has only to develop the data wrappers and event detection modules. Once the modules are developed, they can be deployed any time and on any numbers for different sensors of the same type, respective similar events to be detected.",2016,International Conference on Data Mining,Fields of study: complex event processingsoftware frameworkworld wide webdata miningreal time computingcomputer science
Learning from Your Network of Friends: A Trajectory Representation Learning Model Based on Online Social Ties,Basma Alharbi (King Abdullah University of Science and Technology)Xiangliang Zhang (King Abdullah University of Science and Technology),"2222004373,2129841492","Location-Based Social Networks (LBSNs) captureindividuals whereabouts for a large portion of the population. To utilize this data for user (location)-similarity based tasks, one must map the raw data into a low-dimensional uniformfeature space. However, due to the nature of LBSNs, manyusers have sparse and incomplete check-ins. In this work, we propose to overcome this issue by leveraging the networkof friends, when learning the new feature space. We firstanalyze the impact of friends on individuals's mobility, andshow that individuals trajectories are correlated with thoseof their friends and friends of friends (2-hop friends) inan online setting. Based on our observation, we propose amixed-membership model that infers global mobility patternsfrom users' check-ins and their network of friends, withoutimpairing the model's complexity. Our proposed model infersglobal patterns and learns new representations for both usersand locations simultaneously. We evaluate the inferred patternsand compare the quality of the new user representation againstbaseline methods on a social link prediction problem.",2016,International Conference on Data Mining,Fields of study: data modelinglabeling theorytrajectorysparse matrixsemanticsdata miningmachine learningcomputer science
Application of Fuzzy C-Means for Proactive Clustering of Electrical Power Systems,Mohammed AbdallatifS. SchrammJ. Götze,"2639663184,2584577207,2584192575","Clustering of electrical power systems can be used to analyze their stability and state estimation assessments. In emergency scenarios, correct splitting of power systems (Controlled Islanding) might be essential to avoid wide-area blackout scenarios and to ensure a secure and continuous power supply. Based on power flow calculation, possible proactive clustering variants were defined to set appropriate constraints to the clustering criteria, which were examined via a dynamic simulation to test their validity. To decrease clustering ambiguity, Spectral Clustering based on fuzzy c-means algorithm was applied and clustering quality was increased.",2016,International Conference on Data Mining,Fields of study: constrained clusteringcluster analysismachine learningmathematical optimizationcomputer sciencemathematics
Aware Environment for Workshop with Game Storming,Noriyuki Kushiro (Kyushu Institute of Technology)Tatsuya EhiraRei Kaihara,"2497082557,2552074665,2583520369","A context aware environment for workshop with game storming was developed with vision sensors and was evaluated its capability for supporting facilitator of workshop through feasibility test. In this paper, overview of the aware environment for workshop, basic capability of the environment, and results of feasibility test are described.",2016,International Conference on Data Mining,Fields of study: database indexsensorhuman computer interactionreal time computingsimulationcomputer science
EXTRACT: Strong Examples from Weakly-Labeled Sensor Data,Davis W. BlalockJohn V. Guttag,"2718592430,2651089530","Thanks to the rise of wearable and connected devices, sensor-generated time series comprise a large and growing fraction of the world's data. Unfortunately, extracting value from this data can be challenging, since sensors report low-level signals (e.g., acceleration), not the high-level events that are typically of interest (e.g., gestures). We introduce a technique to bridge this gap by automatically extracting examples of real-world events in low-level data, given only a rough estimate of when these events have taken place. By identifying sets of features that repeat in the same temporal arrangement, we isolate examples of such diverse events as human actions, power consumption patterns, and spoken words with up to 96% precision and recall. Our method is fast enough to run in real time and assumes only minimal knowledge of which variables are relevant or the lengths of events. Our evaluation uses numerous publicly available datasets and over 1 million samples of manually labeled sensor data.",2016,International Conference on Data Mining,Fields of study: accelerationsparse matrixfeature extractiontime seriesshapedata sciencedata miningmachine learningstatisticscomputer sciencemathematics
Graph-Based Term Weighting Scheme for Topic Modeling,Giannis BekoulisFrancois Rousseau,"2585720006,2585510497","LSI and LDA are widely used techniques to uncover the underlying topical structure of text. They traditionally rely on bag-of-words representation of documents and term frequency-based (TF) weighting schemes. In this paper, we represent documents as graph-of-words to capture the relationships between close words and propose the number of contexts of co-occurrences as alternative term weights (TW). Experiments with a downstream supervised task show that counting the importance of a node inside the graph results in statistically significant higher accuracy and macro-averaged F1score than with TF-based LSI and LDA.",2016,International Conference on Data Mining,Fields of study: probabilistic logicsemanticsinformation retrievaldata miningpattern recognitionmachine learningcomputer science
Online Semi-Supervised Multi-task Distance Metric Learning,Ya LiDacheng Tao,"2691603534,2661142595","Given several related tasks, multi-task learning can improve the performance of each task through sharing parameters or feature representations. In this paper, we apply multi-task learning to a particular case of distance metric learning, in which we have a small amount of labeled data. Consider the effectiveness of semi-supervised learning handling few labeled machine learning problems, we integrate semi-supervised learning with multi-task learning and distance metric learning. One of the defect of multi-task learning is its low training efficiency, as we need all the training examples from all tasks to train a model. We propose an online learning algorithm to overcome this drawback of multi-task learning. Experiments are conducted on one landmark multi-task learning dataset to demonstrate the efficiency and effectiveness of our online semi-supervised multi-task learning algorithm.",2016,International Conference on Data Mining,Fields of study: online machine learningstabilitywake sleep algorithmpreference learningmulti task learningrobot learninggeneralization errorcompetitive learningeuclidean distanceprincipal component analysiserror driven learningactive learningalgorithmic learning theorylearning classifier systemsemi supervised learningcomputational learning theoryinstance based learningsupervised learningunsupervised learningpattern recognitionartificial intelligencemachine learningcomputer science
An Empirical Analysis of Hubness in Unsupervised Distance-Based Outlier Detection,Arthur Flexer (Austrian Research Institute for Artificial Intelligence),2108214723,"Outlier detection is the task of automatic identification of unknown data not covered by training data (e.g. a previously unknown class in classification). We explore outlier detection in the presence of hubs and anti-hubs, i.e. data objects which appear to be either very close or very far from most other data due to a problem of measuring distances in high dimensions. We compare a classic distance based method to two new approaches, which have been designed to counter the negative effects of hubness, on six high-dimensional data sets. We show that mainly anti-hubs pose a problem for outlier detection and that this can be improved by using a hubness-aware approach based on re-scaling the distance space.",2016,International Conference on Data Mining,Fields of study: one class classificationtraining setparticle detectordata miningpattern recognitionmachine learningcomputer science
SeBPR: Semantics Enhanced Bayesian Personalized Ranking with Comparable Item Pairs,Penghua YuLanfen Lin,"2680505529,2638759883","Learning user preferences from their implicit feedbacks is crucial to enable recommendations in various online applications. The Bayesian personalized ranking (BPR) with pairwise preference learning has been reported as one of the most promising algorithms for this problem. It follows a fundamental assumption that a user prefers interacted items to the unobserved items, which feedbacks have not happened. Then in the item pair generation, it either uniformly samples negative samples from unobserved items or incorporate some heuristics for an observed item. This paradigm would obtain noisy item pairs thus lead to a biased solution and a prolonged training period. In this paper, we attempt to enhance BPR with semantics. We first introduce semantically comparable item pairs and elaborate why we should adopt them into pairwise learning. We then present what semantics can be utilized and how can they be modeled. Furthermore, we propose a new method named Semantics enhanced Bayesian Personalized Ranking (SeBPR) to incorporate semantically comparable item pairs into the BPR learning framework. Finally, experimental results demonstrate that the proposed methods could reduce the noisy relationships for learning and thus improve the recommendation accuracy.",2016,International Conference on Data Mining,Fields of study: noise measurementsemanticsinformation retrievaldata miningmachine learningstatisticscomputer science
Leave or Remain? Deciphering Brexit Deliberations on Twitter,Apalak Khatua (XLRI- Xavier School of Management)Aparup Khatua (University of Calcutta),"2310227097,2223718954","Twitter is becoming a popular microblogging platform for exploring various socio-political movements. We extract 2.7 million Brexit related tweets to decipher the European Union (EU) referendum deliberations. Our volumetric analysis correctly predicts the outcome of 2016 Brexit referendum. We also investigate whether Twitter discussion adequately reflects the socio-economic concerns related to the UK's decision to leave or remain in the EU. We consider hierarchical clustering analysis (HCA) to explore various underlying themes of this political discourse. To tackle a large portion of retweets in our corpus, we employ tanglegram framework to graphically compare HCA of unique tweets (after removing the duplicates tweets) and the entire corpus. We note finer variances between these two HCA.",2016,International Conference on Data Mining,Fields of study: market researchdata mining
The Prominent Role of Probe Data and Big Data in Modern Technology,Hideki Isetani,2584127209,"In today's society, the management of probe data and big data is becoming increasingly important with new technological advancements. This can be demonstrated in the ongoing development of automated driving systems and the dynamic map. The safety of these new systems depends on high quality data and a reliable shared platform. As the transition to artificial intelligence continues, it is the responsibility of humans to create a system that can effectively control information with minimal risks.",2016,International Conference on Data Mining,Fields of study: vehicle dynamicsbig datadata miningsimulationcomputer science
Data Exchange Platform to Fight Insurance Fraud on Blockchain,Indranil Nath,2585857695,The Paper introduces the concept of Blockchain and its application in sharing fraud intelligence data in Insurance marketplace.,2016,International Conference on Data Mining,Fields of study: insurancedistributed databaseactuarial sciencecomputer science
"ID-Link, an Enabler for Medical Data Marketplace",Ryuji Ito,2722199641,"Business value would be brought from data exchange and individual skill is indispensable to be aware of new idea by combining different data that brings benefit for new market. Based on the concept model, a data marketplace has been discussed in the area of commercial vehicles in Japan toward efficiency of commercial distribution. Similar to the model, a scheme of data marketplace in healthcare industry is introduced in this paper that has already been in operation, which is called as ""ID-Link"". The scheme is now developing a new business model to expand B2C business on the basis of ID-Link. Authors believe ID-Link would be a reference model for further type of data marketplace for business.",2016,International Conference on Data Mining,Fields of study: artifact centric business process modelstakeholderdata modelingdata miningcomputer science
