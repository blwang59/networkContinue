Duplicate detection in adverse drug reaction surveillance,G. Niklas Norén (Uppsala Monitoring Centre);Roland Orre (Stockholm University);Andrew Bate (Pfizer);I. Ralph Edwards (Uppsala Monitoring Centre);,"2038259707,1510144811,1973485669,2155523821","The WHO Collaborating Centre for International Drug Monitoring in Uppsala, Sweden, maintains and analyses the world's largest database of reports on suspected adverse drug reaction (ADR) incidents that occur after drugs are on the market. The presence of duplicate case reports is an important data quality problem and their detection remains a formidable challenge, especially in the WHO drug safety database where reports are anonymised before submission. In this paper, we propose a duplicate detection method based on the hit-miss model for statistical record linkage described by Copas and Hilton, which handles the limited amount of training data well and is well suited for the available data (categorical and numerical rather than free text). We propose two extensions of the standard hit-miss model: a hit-miss mixture model for errors in numerical record fields and a new method to handle correlated record fields, and we demonstrate the effectiveness both at identifying the most likely duplicate for a given case report (94.7% accuracy) and at discriminating true duplicates from random matches (63% recall with 71% precision). The proposed method allows for more efficient data cleaning in post-marketing drug safety data sets, and perhaps other knowledge discovery applications as well.",2007,Data Mining and Knowledge Discovery volume 14 issue 3 pp 305-328,pharmacovigilance;record linkage;mixture model;data quality;knowledge extraction;computer security;data mining;database;statistics;computer science;
Using metarules to organize and group discovered association rules,Abdelaziz Berrado (Arizona State University);George C. Runger (Arizona State University);,"2309876116,2005957266","The high dimensionality of massive data results in the discovery of a large number of association rules. The huge number of rules makes it difficult to interpret and react to all of the rules, especially because many rules are redundant and contained in other rules. We discuss how the sparseness of the data affects the redundancy and containment between the rules and provide a new methodology for organizing and grouping the association rules with the same consequent. It consists of finding metarules, rules that express the associations between the discovered rules themselves. The information provided by the metarules is used to reorganize and group related rules. It is based only on data-determined relationships between the rules. We demonstrate the suggested approach on actual manufacturing data and show its effectiveness on several benchmark data sets.",2007,Data Mining and Knowledge Discovery volume 14 issue 3 pp 409-431,association rule learning;biological classification;data mining;pattern recognition;machine learning;computer science;mathematics;
A fast and effective method to find correlations among attributes in databases,Elaine P. M. de Sousa (University of São Paulo);Caetano Traina (University of São Paulo);Agma J. M. Traina (University of São Paulo);Leejay Wu (Carnegie Mellon University);Christos Faloutsos (Carnegie Mellon University);,"2150460988,2108706841,2017812127,2149376957,2198983026","The problem of identifying meaningful patterns in a database lies at the very heart of data mining. A core objective of data mining processes is the recognition of inter-attribute correlations. Not only are correlations necessary for predictions and classifications --- since rules would fail in the absence of pattern --- but also the identification of groups of mutually correlated attributes expedites the selection of a representative subset of attributes, from which existing mappings allow others to be derived. In this paper, we describe a scalable, effective algorithm to identify groups of correlated attributes. This algorithm can handle non-linear correlations between attributes, and is not restricted to a specific family of mapping functions, such as the set of polynomials. We show the results of our evaluation of the algorithm applied to synthetic and real world datasets, and demonstrate that it is able to spot the correlated attributes. Moreover, the execution time of the proposed technique is linear on the number of elements and of correlations in the dataset.",2007,Data Mining and Knowledge Discovery volume 14 issue 3 pp 367-407,intrinsic dimension;fractal;feature selection;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Differential prioritization in feature selection and classifier aggregation for multiclass microarray datasets,Chia Huey Ooi (Monash University);Madhu Chetty (Monash University);Shyh Wei Teng (Monash University);,"2719646837,2119754102,2007383746","The high dimensionality of microarray datasets endows the task of multiclass tissue classification with various difficulties--the main challenge being the selection of features deemed relevant and non-redundant to form the predictor set for classifier training. The necessity of varying the emphases on relevance and redundancy, through the use of the degree of differential prioritization (DDP) during the search for the predictor set is also of no small importance. Furthermore, there are several types of decomposition technique for the feature selection (FS) problem--all-classes-at-once, one-vs.-all (OVA) or pairwise (PW). Also, in multiclass problems, there is the need to consider the type of classifier aggregation used--whether non-aggregated (a single machine), or aggregated (OVA or PW). From here, first we propose a systematic approach to combining the distinct problems of FS and classification. Then, using eight well-known multiclass microarray datasets, we empirically demonstrate the effectiveness of the DDP in various combinations of FS decomposition types and classifier aggregation methods. Aided by the variable DDP, feature selection leads to classification performance which is better than that of rank-based or equal-priorities scoring methods and accuracies higher than previously reported for benchmark datasets with large number of classes. Finally, based on several criteria, we make general recommendations on the optimal choice of the combination of FS decomposition type and classifier aggregation method for multiclass microarray datasets.",2007,Data Mining and Knowledge Discovery volume 14 issue 3 pp 329-366,microarray analysis techniques;multiclass classification;feature selection;data mining;pattern recognition;machine learning;computer science;
Genetic process mining: an experimental evaluation,Ana Karla A. de Medeiros (Eindhoven University of Technology);A. J. M. M. Weijters (Eindhoven University of Technology);Wil M. P. van der Aalst (Eindhoven University of Technology);,"2346083455,438057892,270949118","One of the aims of process mining is to retrieve a process model from an event log. The discovered models can be used as objective starting points during the deployment of process-aware information systems (Dumas et al., eds., Process-Aware Information Systems: Bridging People and Software Through Process Technology. Wiley, New York, 2005) and/or as a feedback mechanism to check prescribed models against enacted ones. However, current techniques have problems when mining processes that contain non-trivial constructs and/or when dealing with the presence of noise in the logs. Most of the problems happen because many current techniques are based on local information in the event log. To overcome these problems, we try to use genetic algorithms to mine process models. The main motivation is to benefit from the global search performed by this kind of algorithms. The non-trivial constructs are tackled by choosing an internal representation that supports them. The problem of noise is naturally tackled by the genetic algorithm because, per definition, these algorithms are robust to noise. The main challenge in a genetic approach is the definition of a good fitness measure because it guides the global search performed by the genetic algorithm. This paper explains how the genetic algorithm works. Experiments with synthetic and real-life logs show that the fitness measure indeed leads to the mining of process models that are complete (can reproduce all the behavior in the log) and precise (do not allow for extra behavior that cannot be derived from the event log). The genetic algorithm is implemented as a plug-in in the ProM framework.",2007,Data Mining and Knowledge Discovery volume 14 issue 2 pp 245-304,genetic representation;petri net;genetic algorithm;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Two topographic maps for data visualisation,Colin Fyfe (University of the West of Scotland);,669381866,"We review a new form of self-organizing map which is based on a nonlinear projection of latent points into data space, identical to that performed in the Generative Topographic Mapping (GTM) [Bishop et al. (1997) Neurl Comput 10(1): 215---234]. But whereas the GTM is an extension of a mixture of experts, our new model is an extension of a product of experts [Hinton (2000) Technical report GCNU TR 2000-004, Gatsby Computational Neuroscience Unit, University College, London]. We show visualisation results on some real data sets and compare with the GTM. We then introduce a second mapping based on harmonic averages and show that it too creates a topographic mapping of the data. We compare these mappings on real and artificial data sets.",2007,Data Mining and Knowledge Discovery volume 14 issue 2 pp 207-224,generative topographic map;topographic map;computational neuroscience;artificial intelligence;machine learning;computer science;
Evaluation of ordinal attributes at value level,Marko Robnik-Šikonja (University of Ljubljana);Koen Vanhoof (University of Hasselt);,"2034282898,2242613764","We propose a novel context sensitive algorithm for evaluation of ordinal attributes which exploits the information hidden in ordering of attributes' and class' values and provides a separate score for each value of the attribute. Similar to feature selection algorithm ReliefF, the proposed algorithm exploits the contextual information via selection of nearest instances. The ordEval algorithm outputs probabilistic factors corresponding to the effect an increase/decrease of attribute's value has on the class value. While the ordEval algorithm is general and can be used for analysis of any survey with graded answers, we show its utility on an important marketing problem of customer (dis)satisfaction. We develop a visualization technique and show how we can use it to detect and confirm several findings from marketing theory.",2007,Data Mining and Knowledge Discovery volume 14 issue 2 pp 225-243,variable and attribute;attribute domain;attribute value system;visualization;feature selection;data mining;pattern recognition;machine learning;computer science;
Locally adaptive metrics for clustering high dimensional data,"Carlotta Domeniconi (George Mason University);Dimitrios Gunopulos (University of California, Riverside);Sheng Ma (IBM);Bojun Yan (George Mason University);Muna Al-Razgan (George Mason University);Dimitris Papadopoulos (University of California, Riverside);","45678088,1656275121,2116699166,2103112977,2039497280,2167006157","Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves with respect to competitive methods, using both synthetic and real datasets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in gene expression data, and clustering of very high-dimensional data such as text data.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 63-97,k medians clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;clustering high dimensional data;curse of dimensionality;dimensionality reduction;cluster analysis;data mining;pattern recognition;machine learning;computer science;mathematics;
Non-derivable itemset mining,Tgk Toon Calders (University of Antwerp);B Goethals (University of Antwerp);,"2677969167,1992071743","All frequent itemset mining algorithms rely heavily on the monotonicity principle for pruning. This principle allows for excluding candidate itemsets from the expensive counting phase. In this paper, we present sound and complete deduction rules to derive bounds on the support of an itemset. Based on these deduction rules, we construct a condensed representation of all frequent itemsets, by removing those itemsets for which the support can be derived, resulting in the so called Non-Derivable Itemsets (NDI) representation. We also present connections between our proposal and recent other proposals for condensed representations of frequent itemsets. Experiments on real-life datasets show the effectiveness of the NDI representation, making the search for frequent non-derivable itemsets a useful and tractable alternative to mining all frequent itemsets.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 171-206,data science;data mining;database;computer science;mathematics;
Compression-based data mining of sequential data,"Eamonn J. Keogh (University of California, Riverside);Stefano Lonardi (University of California, Riverside);Chotirat Ann Ratanamahatana (Chulalongkorn University);Li Wei (University of California, Riverside);Sang-Hee Lee (University of California, Riverside);John Handley (Xerox);","2170070822,301234865,2091934636,2325104268,2168330173,1938937296","The vast majority of data mining algorithms require the setting of many input parameters. The dangers of working with parameter-laden algorithms are twofold. First, incorrect settings may cause an algorithm to fail in finding the true patterns. Second, a perhaps more insidious problem is that the algorithm may report spurious patterns that do not really exist, or greatly overestimate the significance of the reported patterns. This is especially likely when the user fails to understand the role of parameters in the data mining process. Data mining algorithms should have as few parameters as possible. A parameter-light algorithm would limit our ability to impose our prejudices, expectations, and presumptions on the problem at hand, and would let the data itself speak to us. In this work, we show that recent results in bioinformatics, learning, and computational theory hold great promise for a parameter-light data-mining paradigm. The results are strongly connected to Kolmogorov complexity theory. However, as a practical matter, they can be implemented using any off-the-shelf compression algorithm with the addition of just a dozen lines of code. We will show that this approach is competitive or superior to many of the state-of-the-art approaches in anomaly/interestingness detection, classification, and clustering with empirical tests on time series/DNA/text/XML/video datasets. As a further evidence of the advantages of our method, we will demonstrate its effectiveness to solve a real world classification problem in recommending printing services and products.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 99-129,source lines of code;computability theory;cluster analysis;data compression;time series;data stream mining;anomaly detection;data mining;machine learning;statistics;algorithm;computer science;mathematics;
The complexity of non-hierarchical clustering with instance and cluster level constraints,"Ian Davidson (University at Albany, SUNY);S. S. Ravi (University at Albany, SUNY);","2560595684,2695677490","Recent work has looked at extending clustering algorithms with instance level must-link (ML) and cannot-link (CL) background information. Our work introduces ? and ? cluster level constraints that influence inter-cluster distances and cluster composition. The addition of background information, though useful at providing better clustering results, raises the important feasibility question: Given a collection of constraints and a set of data, does there exist at least one partition of the data set satisfying all the constraints? We study the complexity of the feasibility problem for each of the above constraints separately and also for combinations of constraints. Our results clearly delineate combinations of constraints for which the feasibility problem is computationally intractable (i.e., NP-complete) from those for which the problem is efficiently solvable (i.e., in the computational class P). We also consider the ML and CL constraints in conjunctive and disjunctive normal forms (CNF and DNF respectively). We show that for ML constraints, the feasibility problem is intractable for CNF but efficiently solvable for DNF. Unfortunately, for CL constraints, the feasibility problem is intractable for both CNF and DNF. This effectively means that CL-constraints in a non-trivial form cannot be efficiently incorporated into clustering algorithms. To overcome this, we introduce the notion of a choice-set of constraints and prove that the feasibility problem for choice-sets is efficiently solvable for both ML and CL constraints. We also present empirical results which indicate that the feasibility problem occurs extensively in real world problems.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 25-61,constrained clustering;disjunctive normal form;hierarchical clustering;complexity;satisfiability;discrete mathematics;machine learning;algorithm;computer science;mathematics;
Privacy-preserving boosting,Sébastien Gambs (Université de Montréal);Balázs Kégl (Université de Montréal);Esma Aïmeur (Université de Montréal);,"2665514772,2308666198,317357871","We describe two algorithms, BiBoost (Bipartite Boosting) and MultBoost (Multiparty Boosting), that allow two or more participants to construct a boosting classifier without explicitly sharing their data sets. We analyze both the computational and the security aspects of the algorithms. The algorithms inherit the excellent generalization performance of AdaBoost. Experiments indicate that the algorithms are better than AdaBoost executed separately by the participants, and that, independently of the number of participants, they perform close to AdaBoost executed using the entire data set.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 131-170,boosting methods for object categorization;brownboost;lpboost;secure multi party computation;boosting;adaboost;theoretical computer science;data mining;machine learning;computer science;
An efficient approach to external cluster assessment with an application to Martian topography,Ricardo Vilalta (University of Houston);Tomasz F. Stepinski (Lunar and Planetary Institute);Murali-Krishna Achari (University of Houston);,"2124474760,229275057,2162483643","Automated tools for knowledge discovery are frequently invoked in databases where objects already group into some known (i.e., external) classification scheme. In the context of unsupervised learning or clustering, such tools delve inside large databases looking for alternative classification schemes that are meaningful and novel. An assessment of the information gained with new clusters can be effected by looking at the degree of separation between each new cluster and its most similar class. Our approach models each cluster and class as a multivariate Gaussian distribution and estimates their degree of separation through an information theoretic measure (i.e., through relative entropy or Kullback---Leibler distance). The inherently large computational cost of this step is alleviated by first projecting all data over the single dimension that best separates both distributions (using Fisher's Linear Discriminant). We test our algorithm on a dataset of Martian surfaces using the traditional division into geological units as external classes and the new, hydrology-inspired, automatically performed division as novel clusters. We find the new partitioning constitutes a formally meaningful classification that deviates substantially from the traditional classification.",2007,Data Mining and Knowledge Discovery volume 14 issue 1 pp 1-23,kullback leibler divergence;knowledge extraction;unsupervised learning;data mining;machine learning;statistics;computer science;mathematics;
Mining Knowledge in Computer Tomography Databases,Daniela Stan Raicu;,2708474881,-,2007,Data Mining and Knowledge Discovery,computer science;
Characteristic-Based Clustering for Time Series Data,"Xiaozhe Wang (Faculty of Information Technology, University Džemal Bijedić of Mostar);Kate A. Smith (Faculty of Information Technology, University Džemal Bijedić of Mostar);Rob J. Hyndman (Monash University, Clayton campus);","2305201898,2160175319,1925586815","With the growing importance of time series clustering research, particularly for similarity searches amongst long time series such as those arising in medicine or finance, it is critical for us to find a way to resolve the outstanding problems that make most clustering methods impractical under certain circumstances. When the time series is very long, some clustering algorithms may fail because the very notation of similarity is dubious in high dimension space; many methods cannot handle missing data when the clustering is based on a distance metric. This paper proposes a method for clustering of time series based on their structural characteristics. Unlike other alternatives, this method does not cluster point values using a distance metric, rather it clusters based on global features extracted from the time series. The feature measures are obtained from each individual series and can be fed into arbitrary clustering algorithms, including an unsupervised neural network algorithm, self-organizing map, or hierarchal clustering algorithm. Global measures describing the time series are obtained by applying statistical operations that best capture the underlying characteristics: trend, seasonality, periodicity, serial correlation, skewness, kurtosis, chaos, nonlinearity, and self-similarity. Since the method clusters using extracted global measures, it reduces the dimensionality of the time series and is much less sensitive to missing or noisy data. We further provide a search mechanism to find the best selection from the feature set that should be used as the clustering inputs. The proposed technique has been tested using benchmark time series datasets previously reported for time series clustering and a set of time series datasets with known characteristics. The empirical results show that our approach is able to yield meaningful clusters. The resulting clusters are similar to those produced by other methods, but with some promising and interesting variations that can be intuitively explained with knowledge of the global characteristics of the time series.",2006,Data Mining and Knowledge Discovery volume 13 issue 3 pp 335-364,flame clustering;k medians clustering;brown clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;fuzzy clustering;clustering high dimensional data;cluster analysis;time series;consensus clustering;data mining;machine learning;statistics;computer science;mathematics;
Mining in Anticipation for Concept Change: Proactive-Reactive Prediction in Data Streams,Ying Yang (Monash University);Xindong Wu (University of Vermont);Xingquan Zhu (University of Vermont);,"2140940508,2123651450,2618356905","Prediction in streaming data is an important activity in the modern society. Two major challenges posed by data streams are (1) the data may grow without limit so that it is difficult to retain a long history of raw data; and (2) the underlying concept of the data may change over time. The novelties of this paper are in four folds. First, it uses a measure of conceptual equivalence to organize the data history into a history of concepts. This contrasts to the common practice that only keeps recent raw data. The concept history is compact while still retains essential information for learning. Second, it learns concept-transition patterns from the concept history and anticipates what the concept will be in the case of a concept change. It then proactively prepares a prediction model for the future change. This contrasts to the conventional methodology that passively waits until the change happens. Third, it incorporates proactive and reactive predictions. If the anticipation turns out to be correct, a proper prediction model can be launched instantly upon the concept change. If not, it promptly resorts to a reactive mode: adapting a prediction model to the new data. Finally, an efficient and effective system RePro is proposed to implement these new ideas. It carries out prediction at two levels, a general level of predicting each oncoming concept and a specific level of predicting each instance's class. Experiments are conducted to compare RePro with representative existing prediction methods on various benchmark data sets that represent diversified scenarios of concept change. Empirical evidence offers inspiring insights and demonstrates the proposed methodology is an advisable solution to prediction in data streams.",2006,Data Mining and Knowledge Discovery volume 13 issue 3 pp 261-289,empirical evidence;predictive modelling;biological classification;proactive learning;data mining;artificial intelligence;machine learning;simulation;statistics;computer science;
Scalable Clustering Algorithms with Balancing Constraints,Arindam Banerjee (University of Minnesota);Joydeep Ghosh (University of Texas at Austin);,"2037585042,2148168557","Clustering methods for data-mining problems must be extremely scalable. In addition, several data mining applications demand that the clusters obtained be balanced, i.e., of approximately the same size or importance. In this paper, we propose a general framework for scalable, balanced clustering. The data clustering process is broken down into three steps: sampling of a small representative subset of the points, clustering of the sampled data, and populating the initial clusters with the remaining data followed by refinements. First, we show that a simple uniform sampling from the original data is sufficient to get a representative subset with high probability. While the proposed framework allows a large class of algorithms to be used for clustering the sampled set, we focus on some popular parametric algorithms for ease of exposition. We then present algorithms to populate and refine the clusters. The algorithm for populating the clusters is based on a generalization of the stable marriage problem, whereas the refinement algorithm is a constrained iterative relocation scheme. The complexity of the overall method is O(kN log N) for obtaining k balanced clusters from N data points, which compares favorably with other existing techniques for balanced clustering. In addition to providing balancing guarantees, the clustering performance obtained using the proposed framework is comparable to and often better than the corresponding unconstrained solution. Experimental results on several datasets, including high-dimensional (>20,000) ones, are provided to demonstrate the efficacy of the proposed framework.",2006,Data Mining and Knowledge Discovery volume 13 issue 3 pp 365-395,k medians clustering;flame clustering;brown clustering;canopy clustering algorithm;determining the number of clusters in a data set;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;stable marriage problem;fuzzy clustering;clustering high dimensional data;cluster analysis;consensus clustering;biclustering;document clustering;data science;data mining;machine learning;statistics;computer science;
Accelerated EM-based clustering of large data sets,Jakob J. Verbeek (French Institute for Research in Computer Science and Automation);Jan R. J. Nunnink (University of Amsterdam);Nikos Vlassis (University of Amsterdam);,"2145238836,1227111101,2193073850","Motivated by the poor performance (linear complexity) of the EM algorithm in clustering large data sets, and inspired by the successful accelerated versions of related algorithms like k-means, we derive an accelerated variant of the EM algorithm for Gaussian mixtures that: (1) offers speedups that are at least linear in the number of data points, (2) ensures convergence by strictly increasing a lower bound on the data log-likelihood in each learning step, and (3) allows ample freedom in the design of other accelerated variants. We also derive a similar accelerated algorithm for greedy mixture learning, where very satisfactory results are obtained. The core idea is to define a lower bound on the data log-likelihood based on a grouping of data points. The bound is maximized by computing in turn (i) optimal assignments of groups of data points to the mixture components, and (ii) optimal re-estimation of the model parameters based on average sufficient statistics computed over groups of data points. The proposed method naturally generalizes to mixtures of other members of the exponential family. Experimental results show the potential of the proposed method over other state-of-the-art acceleration techniques.",2006,Data Mining and Knowledge Discovery volume 13 issue 3 pp 291-307,k d tree;computational statistics;combinatorics;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
Learning Semi-Structured Document Categorization Using Bounded-Length Spectrum Sub-Sequence Kernels,Olivier Y. de Vel (Defence Science and Technology Organisation);,1968231690,"In this paper we report an investigation into the learning of semi-structured document categorization. We automatically discover low-level, short-range byte data structure patterns from a document data stream by extracting all byte sub-sequences within a sliding window to form an augmented (or bounded-length) string spectrum feature map and using a modified suffix trie data structure (called the coloured generalized suffix tree or CGST) to efficiently store and manipulate the feature map. Using the CGST we are able to efficiently compute the stream's bounded-length sequence spectrum kernel. We compare the performance of two classifier algorithms to categorize the data streams, namely, the SVM and Naive Bayes (NB) classifiers. Experiments have provided good classification performance results on a variety of document byte streams, particularly when using the NB classifier under certain parameter settings. Results indicate that the bounded-length kernel is superior to the standard fixed-length kernel for semi-structured documents.",2006,Data Mining and Knowledge Discovery volume 13 issue 3 pp 309-334,naive bayes classifier;support vector machine;computer forensics;digital forensics;data structure;data mining;pattern recognition;machine learning;computer science;
A systematic approach to the assessment of fuzzy association rules,Didier Dubois (United Parcel Service);Eyke Hüllermeier (University of Marburg);Henri Prade (United Parcel Service);,"2300659125,323026139,2082615088","In order to allow for the analysis of data sets including numerical attributes, several generalizations of association rule mining based on fuzzy sets have been proposed in the literature. While the formal specification of fuzzy associations is more or less straightforward, the assessment of such rules by means of appropriate quality measures is less obvious. Particularly, it assumes an understanding of the semantic meaning of a fuzzy rule. This aspect has been ignored by most existing proposals, which must therefore be considered as ad-hoc to some extent. In this paper, we develop a systematic approach to the assessment of fuzzy association rules. To this end, we proceed from the idea of partitioning the data stored in a database into examples of a given rule, counterexamples, and irrelevant data. Evaluation measures are then derived from the cardinalities of the corresponding subsets. The problem of finding a proper partition has a rather obvious solution for standard association rules but becomes less trivial in the fuzzy case. Our results not only provide a sound justification for commonly used measures but also suggest a means for constructing meaningful alternatives.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 167-192,fuzzy associative matrix;type 2 fuzzy sets and systems;fuzzy set operations;fuzzy measure theory;fuzzy mathematics;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;fuzzy number;membership function;association rule learning;neuro fuzzy;fuzzy logic;fuzzy set;data mining;artificial intelligence;machine learning;computer science;mathematics;
Hyperclique pattern discovery,Hui Xiong (Rutgers–Newark);Pang Ning Tan (Michigan State University);Vipin Kumar (University of Minnesota);,"2153710278,2113230973,2161062602","Existing algorithms for mining association patterns often rely on the support-based pruning strategy to prune a combinatorial search space. However, this strategy is not effective for discovering potentially interesting patterns at low levels of support. Also, it tends to generate too many spurious patterns involving items which are from different support levels and are poorly correlated. In this paper, we present a framework for mining highly-correlated association patterns called hyperclique patterns. In this framework, an objective measure called h-confidence is applied to discover hyperclique patterns. We prove that the items in a hyperclique pattern have a guaranteed level of global pairwise similarity to one another as measured by the cosine similarity (uncentered Pearson's correlation coefficient). Also, we show that the h-confidence measure satisfies a cross-support property which can help efficiently eliminate spurious patterns involving items with substantially different support levels. Indeed, this cross-support property is not limited to h-confidence and can be generalized to some other association measures. In addition, an algorithm called hyperclique miner is proposed to exploit both cross-support and anti-monotone properties of the h-confidence measure for the efficient discovery of hyperclique patterns. Finally, our experimental results show that hyperclique miner can efficiently identify hyperclique patterns, even at extremely low levels of support.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 219-242,genetic association;data science;data mining;machine learning;mathematics;
Mining top-K frequent itemsets from data streams,Raymond Chi-Wing Wong (The Chinese University of Hong Kong);Ada Wai-Chee Fu (The Chinese University of Hong Kong);,"2125027556,2165551961","Frequent pattern mining on data streams is of interest recently. However, it is not easy for users to determine a proper frequency threshold. It is more reasonable to ask users to set a bound on the result size. We study the problem of mining top K frequent itemsets in data streams. We introduce a method based on the Chernoff bound with a guarantee of the output quality and also a bound on the memory usage. We also propose an algorithm based on the Lossy Counting Algorithm. In most of the experiments of the two proposed algorithms, we obtain perfect solutions and the memory space occupied by our algorithms is very small. Besides, we also propose the adapted approach of these two algorithms in order to handle the case when we are interested in mining the data in a sliding window. The experiments show that the results are accurate.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 193-217,chernoff bound;sliding window protocol;randomized algorithm;data stream mining;data science;data mining;database;statistics;computer science;
VizRank: Data Visualization Guided by Machine Learning,Gregor Leban (University of Ljubljana);Blaž Zupan (University of Ljubljana);Gaj Vidmar (University of Ljubljana);Ivan Bratko (University of Ljubljana);,"1161821428,1975997033,1423739227,689465770","Data visualization plays a crucial role in identifying interesting patterns in exploratory data analysis. Its use is, however, made difficult by the large number of possible data projections showing different attribute subsets that must be evaluated by the data analyst. In this paper, we introduce a method called VizRank, which is applied on classified data to automatically select the most useful data projections. VizRank can be used with any visualization method that maps attribute values to points in a two-dimensional visualization space. It assesses possible data projections and ranks them by their ability to visually discriminate between classes. The quality of class separation is estimated by computing the predictive accuracy of k-nearest neighbor classifier on the data set consisting of x and y positions of the projected data points and their class information. The paper introduces the method and presents experimental results which show that VizRank's ranking of projections highly agrees with subjective rankings by data analysts. The practical use of VizRank is also demonstrated by an application in the field of functional genomics.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 119-136,exploratory data analysis;functional genomics;k nearest neighbors algorithm;data visualization;data science;data mining;machine learning;statistics;computer science;
Support measures for graph data,Natalia Vanetik (Ben-Gurion University of the Negev);Solomon Eyal Shimony (Ben-Gurion University of the Negev);Ehud Gudes (Ben-Gurion University of the Negev);,"2042215923,2333889049,195553551","The concept of support is central to data mining. While the definition of support in transaction databases is intuitive and simple, that is not the case in graph datasets and databases. Most mining algorithms require the support of a pattern to be no greater than that of its subpatterns, a property called anti-monotonicity, or admissibility. This paper examines the requirements for admissibility of a support measure. Support measures for mining graphs are usually based on the notion of an instance graph---a graph representing all the instances of the pattern in a database and their intersection properties. Necessary and sufficient conditions for support measure admissibility, based on operations on instance graphs, are developed and proved. The sufficient conditions are used to prove admissibility of one support measure--the size of the independent set in the instance graph. Conversely, the necessary conditions are used to quickly show that some other support measures, such as weighted count of instances, are not admissible.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 243-260,independent set;discrete mathematics;combinatorics;data mining;machine learning;computer science;mathematics;
A Model-Based Frequency Constraint for Mining Associations from Transaction Data,Michael Hahsler (Vienna University of Economics and Business);,280853906,"Mining frequent itemsets is a popular method for finding associated items in databases. For this method, support, the co-occurrence frequency of the items which form an association, is used as the primary indicator of the associations's significance. A single, user-specified support threshold is used to decided if associations should be further investigated. Support has some known problems with rare items, favors shorter itemsets and sometimes produces misleading associations. In this paper we develop a novel model-based frequency constraint as an alternative to a single, user-specified minimum support. The constraint utilizes knowledge of the process generating transaction data by applying a simple stochastic mixture model (the NB model) which allows for transaction data's typically highly skewed item frequency distribution. A user-specified precision threshold is used together with the model to find local frequency thresholds for groups of itemsets. Based on the constraint we develop the notion of NB-frequent itemsets and adapt a mining algorithm to find all NB-frequent itemsets in a database. In experiments with publicly available transaction databases we show that the new constraint provides improvements over a single minimum support threshold and that the precision threshold is more robust and easier to set and interpret by the user.",2006,Data Mining and Knowledge Discovery volume 13 issue 2 pp 137-166,mixture model;data science;data mining;database;computer science;
A Rule-Based Approach for Process Discovery: Dealing with Noise and Imbalance in Process Logs,Laura Măruşter (University of Groningen);A. J. M. M. (Ton) Weijters (Eindhoven University of Technology);Wil M. P. Van Der Aalst (Eindhoven University of Technology);Antal Van Den Bosch (Tilburg University);,"130718764,438057892,270949118,2161053677","Effective information systems require the existence of explicit process models. A completely specified process design needs to be developed in order to enact a given business process. This development is time consuming and often subjective and incomplete. We propose a method that constructs the process model from process log data, by determining the relations between process tasks. To predict these relations, we employ machine learning technique to induce rule sets. These rule sets are induced from simulated process log data generated by varying process characteristics such as noise and log size. Tests reveal that the induced rule sets have a high predictive accuracy on new data. The effects of noise and imbalance of execution priorities during the discovery of the relations between process tasks are also discussed. Knowing the causal, exclusive, and parallel relations, a process model expressed in the Petri net formalism can be built. We illustrate our approach with real world data in a case study.",2006,Data Mining and Knowledge Discovery volume 13 issue 1 pp 67-87,process architecture;petri net;knowledge extraction;rule based system;data mining;artificial intelligence;machine learning;computer science;
A Bit Level Representation for Time Series Data Mining with Shape Based Similarity,"Anthony J. Bagnall (University of East Anglia);Chotirat (Ann) Ratanamahatana (Chulalongkorn University);Eamonn J. Keogh (University of California, Riverside);Stefano Lonardi (University of California, Riverside);Gareth J. Janacek (University of East Anglia);","2171856547,2091934636,2170070822,301234865,2065044841","Clipping is the process of transforming a real valued series into a sequence of bits representing whether each data is above or below the average. In this paper, we argue that clipping is a useful and flexible transformation for the exploratory analysis of large time dependent data sets. We demonstrate how time series stored as bits can be very efficiently compressed and manipulated and that, under some assumptions, the discriminatory power with clipped series is asymptotically equivalent to that achieved with the raw data. Unlike other transformations, clipped series can be compared directly to the raw data series. We show that this means we can form a tight lower bounding metric for Euclidean and Dynamic Time Warping distance and hence efficiently query by content. Clipped data can be used in conjunction with a host of algorithms and statistical tests that naturally follow from the binary nature of the data. A series of experiments illustrate how clipped series can be used in increasingly complex ways to achieve better results than other popular representations. The usefulness of the proposed representation is demonstrated by the fact that the results with clipped data are consistently better than those achieved with a Wavelet or Discrete Fourier Transformation at the same compression ratio for both clustering and query by content. The flexibility of the representation is shown by the fact that we can take advantage of a variable Run Length Encoding of clipped series to define an approximation of the Kolmogorov complexity and hence perform Kolmogorov based clustering.",2006,Data Mining and Knowledge Discovery volume 13 issue 1 pp 11-40,clipping;run length encoding;dynamic time warping;compression ratio;discrete fourier transform;statistical hypothesis testing;time series;upper and lower bounds;discrete mathematics;data mining;machine learning;statistics;algorithm;computer science;mathematics;
"DOMpro: Protein Domain Prediction Using Profiles, Secondary Structure, Relative Solvent Accessibility, and Recursive Neural Networks","Jianlin Cheng (University of California, Irvine);Michael J. Sweredoski (University of California, Irvine);Pierre Baldi (University of California, Irvine);","2141057972,1974068642,2060797211","Protein domains are the structural and functional units of proteins. The ability to parse protein chains into different domains is important for protein classification and for understanding protein structure, function, and evolution. Here we use machine learning algorithms, in the form of recursive neural networks, to develop a protein domain predictor called DOMpro. DOMpro predicts protein domains using a combination of evolutionary information in the form of profiles, predicted secondary structure, and predicted relative solvent accessibility. DOMpro is trained and tested on a curated dataset derived from the CATH database. DOMpro correctly predicts the number of domains for 69% of the combined dataset of single and multi-domain chains. DOMpro achieves a sensitivity of 76% and specificity of 85% with respect to the single-domain proteins and sensitivity of 59% and specificity of 38% with respect to the two-domain proteins. DOMpro also achieved a sensitivity and specificity of 71% and 71% respectively in the Critical Assessment of Fully Automated Structure Prediction 4 (CAFASP-4) (Fisher et al., 1999; Saini and Fischer, 2005) and was ranked among the top ab initio domain predictors. The DOMpro server, software, and dataset are available at http://www.igb.uci.edu/servers/psss.html.",2006,Data Mining and Knowledge Discovery volume 13 issue 1 pp 1-10,protein structure prediction;domain;single domain;protein domain;protein structure;protein secondary structure;bioinformatics;data mining;machine learning;computer science;
Information Preserving Time Decompositions of Time Stamped Documents,"Parvathi Chundi (University of Nebraska Omaha);Daniel J. Rosenkrantz (University at Albany, SUNY);","2230771436,250841333","Extraction of sequences of events from news and other documents based on the publication times of these documents has been shown to be extremely effective in tracking past events. This paper addresses the issue of constructing an optimal information preserving decomposition of the time period associated with a given document set, i.e., a decomposition with the smallest number of subintervals, subject to no loss of information. We introduce the notion of the compressed interval decomposition, where each subinterval consists of consecutive time points having identical information content. We define optimality, and show that any optimal information preserving decomposition of the time period is a refinement of the compressed interval decomposition. We define several special classes of measure functions (functions that measure the prevalence of keywords in the document set and assign them numeric values), based on their effect on the information computed as document sets are combined. We give algorithms, appropriate for different classes of measure functions, for computing an optimal information preserving decomposition of a given document set. We studied the effectiveness of these algorithms by computing several compressed interval and information preserving decompositions for a subset of the Reuters---21578 document set. The experiments support the obvious conclusion that the temporal information gleaned from a document set is strongly dependent on the measure function used and on other user-defined parameters.",2006,Data Mining and Knowledge Discovery volume 13 issue 1 pp 41-65,self information;theoretical computer science;information retrieval;data mining;machine learning;statistics;mathematics;
On the use of Human-Computer Interaction for Projected Nearest Neighbor Search,Charu C. Aggarwal (IBM);,2146335907,"Nearest Neighbor search is an important and widely used technique in a number of important application domains. In many of these domains, the dimensionality of the data representation is often very high. Recent theoretical results have shown that the concept of proximity or nearest neighbors may not be very meaningful for the high dimensional case. Therefore, it is often a complex problem to find good quality nearest neighbors in such data sets. Furthermore, it is also difficult to judge the value and relevance of the returned results. In fact, it is hard for any fully automated system to satisfy a user about the quality of the nearest neighbors found unless he is directly involved in the process. This is especially the case for high dimensional data in which the meaningfulness of the nearest neighbors found is questionable. In this paper, we address the complex problem of high dimensional nearest neighbor search from the user perspective by designing a system which uses effective cooperation between the human and the computer. The system provides the user with visual representations of carefully chosen subspaces of the data in order to repeatedly elicit his preferences about the data patterns which are most closely related to the query point. These preferences are used in order to determine and quantify the meaningfulness of the nearest neighbors. Our system is not only able to find and quantify the meaningfulness of the nearest neighbors, but is also able to diagnose situations in which the nearest neighbors found are truly not meaningful.",2006,Data Mining and Knowledge Discovery volume 13 issue 1 pp 89-117,ball tree;nearest neighbor chain algorithm;fixed radius near neighbors;best bin first;cover tree;nearest neighbor graph;r tree;nearest neighbor search;clustering high dimensional data;external data representation;k nearest neighbors algorithm;satisfiability;data mining;pattern recognition;machine learning;computer science;mathematics;
Fast Distributed Outlier Detection in Mixed-Attribute Data Sets,Matthew Eric Otey (Ohio State University);Amol Ghoting (Ohio State University);Srinivasan Parthasarathy (Ohio State University);,"291982408,2102101334,2106796124","Efficiently detecting outliers or anomalies is an important problem in many areas of science, medicine and information technology. Applications range from data cleaning to clinical diagnosis, from detecting anomalous defects in materials to fraud and intrusion detection. Over the past decade, researchers in data mining and statistics have addressed the problem of outlier detection using both parametric and non-parametric approaches in a centralized setting. However, there are still several challenges that must be addressed. First, most approaches to date have focused on detecting outliers in a continuous attribute space. However, almost all real-world data sets contain a mixture of categorical and continuous attributes. Categorical attributes are typically ignored or incorrectly modeled by existing approaches, resulting in a significant loss of information. Second, there have not been any general-purpose distributed outlier detection algorithms. Most distributed detection algorithms are designed with a specific domain (e.g. sensor networks) in mind. Third, the data sets being analyzed may be streaming or otherwise dynamic in nature. Such data sets are prone to concept drift, and models of the data must be dynamic as well. To address these challenges, we present a tunable algorithm for distributed outlier detection in dynamic mixed-attribute data sets.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 203-228,concept drift;dynamic data;intrusion detection system;wireless sensor network;anomaly detection;data science;data mining;machine learning;computer science;
"Bridging Local and Global Data Cleansing: Identifying Class Noise in Large, Distributed Data Datasets",Xingquan Zhu (University of Vermont);Xindong Wu (University of Vermont);Qijun Chen (University of Vermont);,"2618356905,2123651450,2172131940","To cleanse mislabeled examples from a training dataset for efficient and effective induction, most existing approaches adopt a major set oriented scheme: the training dataset is separated into two parts (a major set and a minor set). The classifiers learned from the major set are used to identify noise in the minor set. The obvious drawbacks of such a scheme are twofold: (1) when the underlying data volume keeps growing, it would be either physically impossible or time consuming to load the major set into the memory for inductive learning; and (2) for multiple or distributed datasets, it can be either technically infeasible or factitiously forbidden to download data from other sites (for security or privacy reasons). Therefore, these approaches have severe limitations in conducting effective global data cleansing from large, distributed datasets. In this paper, we propose a solution to bridge the local and global analysis for noise cleansing. More specifically, the proposed effort tries to identify and eliminate mislabeled data items from large or distributed datasets through local analysis and global incorporation. For this purpose, we make use of distributed datasets or partition a large dataset into subsets, each of which is regarded as a local subset and is small enough to be processed by an induction algorithm at one time to construct a local model for noise identification. We construct good rules from each subset, and use the good rules to evaluate the whole dataset. For a given instance I k , two error count variables are used to count the number of times it has been identified as noise by all data subsets. The instance with higher error values will have a higher probability of being a mislabeled example. Two threshold schemes, majority and non-objection, are used to identify and eliminate the noisy examples. Experimental results and comparative studies on both real-world and synthetic datasets are reported to evaluate the effectiveness and efficiency of the proposed approach.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 275-308,data cleansing;global analysis;comparative research;data science;data mining;machine learning;statistics;computer science;
Sequential Pattern Mining in Multi-Databases via Multiple Alignment,Hye-Chung Kum (University of North Carolina at Chapel Hill);Joong Hyuk Chang (Yonsei University);Wei Wang (University of North Carolina at Chapel Hill);,"2009632042,2655177091,2315689540","To efficiently find global patterns from a multi-database, information in each local database must first be mined and summarized at the local level. Then only the summarized information is forwarded to the global mining process. However, conventional sequential pattern mining methods based on support cannot summarize the local information and is ineffective for global pattern mining from multiple data sources. In this paper, we present an alternative local mining approach for finding sequential patterns in the local databases of a multi-database. We propose the theme of approximate sequential pattern mining roughly defined as identifying patterns approximately shared by many sequences. Approximate sequential patterns can effectively summerize and represent the local databases by identifying the underlying trends in the data. We present a novel algorithm, ApproxMAP, to mine approximate sequential patterns, called consensus patterns, from large sequence databases in two steps. First, sequences are clustered by similarity. Then, consensus patterns are mined directly from each cluster through multiple alignment. We conduct an extensive and systematic performance study over synthetic and real data. The results demonstrate that ApproxMAP is effective and scalable in mining large sequences databases with long patterns. Hence, ApproxMAP can efficiently summarize a local database and reduce the cost for global mining. Furthremore, we present an elegant and uniform model to identify both high vote sequential patterns and exceptional sequential patterns from the collection of these consensus patterns from each local databases.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 151-180,sequential pattern mining;multiple sequence alignment;data science;bioinformatics;data mining;computer science;
Reinforcing Web-object Categorization Through Interrelationships,Gui-Rong Xue (Shanghai Jiao Tong University);Yong Yu (Shanghai Jiao Tong University);Dou Shen (Hong Kong University of Science and Technology);Qiang Yang (Hong Kong University of Science and Technology);Hua-Jun Zeng (Microsoft);Zheng Chen (Microsoft);,"2167947354,2119244895,2136428695,2109031554,2157931964,2425877144","Existing categorization algorithms deal with homogeneous Web objects, and consider interrelated objects as additional features when taking the interrelationships with other types of objects into account. However, focusing on any single aspect of the inter-object relationship is not sufficient to fully reveal the true categories of Web objects. In this paper, we propose a novel categorization algorithm, called the Iterative Reinforcement Categorization Algorithm (IRC), to exploit the full interrelationship between different types of Web objects on the Web, including Web pages and queries. IRC classifies the interrelated Web objects by iteratively reinforcing the individual classification results of different types of objects via their interrelationship. Experiments on a clickthrough-log dataset from the MSN search engine show that, in terms of the F1 measure, IRC achieves a 26.4% improvement over a pure content-based classification method. It also achieves a 21% improvement over a query-metadata-based method, as well as a 16.4% improvement on F1 measure over the well-known virtual document-based method. Our experiments show that IRC converges fast enough to be applicable to real world applications.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 229-248,categorization;web page;search engine;world wide web;information retrieval;data mining;machine learning;computer science;
Mining Multiple Data Sources: Local Pattern Analysis,Shichao Zhang;Mohammed Javeed Zaki (Rensselaer Polytechnic Institute);,"2677413781,2165917828",-,2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 121-125,world wide web;data mining;computer science;
Organizing Multiple Data Sources for Developing Intelligent e-Business Portals,Jia Hu (Maebashi Institute of Technology);Ning Zhong (Maebashi Institute of Technology);,"2326458255,2157949701","Enterprise applications usually involve huge, complex, and persistent data to work on, together with business rules and processes. In order to represent, integrate, and use the information coming from the huge, distributed, multiple sources, we present a conceptual model with dynamic multi-level workflows corresponding to a mining-grid centric multi-layer grid architecture, for multi-aspect analysis in building an e-business portal on the Wisdom Web. We show that this integrated model will help to dynamically organize status-based business processes that govern enterprise application integration. We also present two case studies to demonstrate the effectiveness of the proposed model in the real world. The first case study is about how to organize and mine multiple data sources for behavior-based online customer segmentation, which is the first crucial step of personalization and one-to-one marketing. The second case study is about how to evaluate and monitor data quality, which in return can optimize the knowledge discovery process for intelligent decision making. The proposed methodology attempts to orchestrate various mining agents on the mining-grid for integrating data and knowledge in a unified portal developed by a service-oriented architecture.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 127-150,data architecture;business rule;enterprise application integration;business process;service oriented architecture;data quality;conceptual model;knowledge management;world wide web;data mining;computer science;
Mining Adaptive Ratio Rules from Distributed Data Sources,Jun Yan (Peking University);Ning Liu (Tsinghua University);Qiang Yang (Hong Kong University of Science and Technology);Benyu Zhang (Microsoft);Qiansheng Cheng (Peking University);Zheng Chen (Microsoft);,"2636881954,2615714706,2109031554,2099847228,2151206843,2425877144","Different from traditional association-rule mining, a new paradigm called Ratio Rule (RR) was proposed recently. Ratio rules are aimed at capturing the quantitative association knowledge, We extend this framework to mining ratio rules from distributed and dynamic data sources. This is a novel and challenging problem. The traditional techniques used for ratio rule mining is an eigen-system analysis which can often fall victim to noise. This has limited the application of ratio rule mining greatly. The distributed data sources impose additional constraints for the mining procedure to be robust in the presence of noise, because it is difficult to clean all the data sources in real time in real-world tasks. In addition, the traditional batch methods for ratio rule mining cannot cope with dynamic data. In this paper, we propose an integrated method to mining ratio rules from distributed and changing data sources, by first mining the ratio rules from each data source separately through a novel robust and adaptive one-pass algorithm (which is called Robust and Adaptive Ratio Rule (RARR)), and then integrating the rules of each data source in a simple probabilistic model. In this way, we can acquire the global rules from all the local information sources adaptively. We show that the RARR technique can converge to a fixed point and is robust as well. Moreover, the integration of rules is efficient and effective. Both theoretical analysis and experiments illustrate that the performance of RARR and the proposed information integration procedure is satisfactory for the purpose of discovering latent associations in distributed dynamic data source.",2006,Data Mining and Knowledge Discovery volume 12 issue 2 pp 249-273,dynamic data;information integration;fixed point;robust statistics;association rule learning;system analysis;statistical model;data stream mining;data science;data mining;machine learning;statistics;computer science;
Computing LTS Regression for Large Data Sets,Peter J. Rousseeuw (University of Antwerp);Katrien Van Driessen (University of Antwerp);,"1973885181,1897926572","Data mining aims to extract previously unknown patterns or substructures from large databases. In statistics, this is what methods of robust estimation and outlier detection were constructed for, see e.g. Rousseeuw and Leroy (1987). Here we will focus on least trimmed squares (LTS) regression, which is based on the subset of h cases (out of n) whose least squares fit possesses the smallest sum of squared residuals. The coverage h may be set between n/2 and n. The computation time of existing LTS algorithms grows too much with the size of the data set, precluding their use for data mining. In this paper we develop a new algorithm called FAST-LTS. The basic ideas are an inequality involving order statistics and sums of squared residuals, and techniques which we call `selective iteration' and `nested extensions'. We also use an intercept adjustment technique to improve the precision. For small data sets FAST-LTS typically finds the exact LTS, whereas for larger data sets it gives more accurate results than existing algorithms for LTS and is faster by orders of magnitude. This allows us to apply FAST-LTS to large databases.",2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 29-45,least trimmed squares;outlier;robust statistics;explained sum of squares;order statistic;regression;linear model;least squares;anomaly detection;econometrics;data mining;machine learning;statistics;mathematics;
Data Clustering with Partial Supervision,Abdelhamid Bouchachia (Alpen-Adria-Universität Klagenfurt);Witold Pedrycz (University of Alberta);,"2062347845,136859070","Clustering with partial supervision finds its application in situations where data is neither entirely nor accurately labeled. This paper discusses a semi-supervised clustering algorithm based on a modified version of the fuzzy C-Means (FCM) algorithm. The objective function of the proposed algorithm consists of two components. The first concerns traditional unsupervised clustering while the second tracks the relationship between classes (available labels) and the clusters generated by the first component. The balance between the two components is tuned by a scaling factor. Comprehensive experimental studies are presented. First, the discrimination of the proposed algorithm is discussed before its reformulation as a classifier is addressed. The induced classifier is evaluated on completely labeled data and validated by comparison against some fully supervised classifiers, namely support vector machines and neural networks. This classifier is then evaluated and compared against three semi-supervised algorithms in the context of learning from partly labeled data. In addition, the behavior of the algorithm is discussed and the relation between classes and clusters is investigated using a linear regression model. Finally, the complexity of the algorithm is briefly discussed.",2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 47-78,k medians clustering;canopy clustering algorithm;determining the number of clusters in a data set;k medoids;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;fuzzy clustering;cluster analysis;linear regression;artificial neural network;data mining;pattern recognition;machine learning;computer science;
Structural Periodic Measures for Time-Series Data,Michail Vlachos (IBM);Philip S. Yu (IBM);Vittorio Castelli (IBM);Christopher Meek (Microsoft);,"2146138755,2125104194,2132335929,2422299352","This work motivates the need for more flexible structural similarity measures between time-series sequences, which are based on the extraction of important periodic features. Specifically, we present non-parametric methods for accurate periodicity detection and we introduce new periodic distance measures for time-series sequences. We combine these new measures with an effective metric tree index structure for efficiently answering k-Nearest-Neighbor queries. The goal of these tools and techniques are to assist in detecting, monitoring and visualizing structural periodic changes. It is our belief that these methods can be directly applicable in the manufacturing industry for preventive maintenance and in the medical sciences for accurate classification and anomaly detection.",2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 1-28,time series;anomaly detection;data mining;machine learning;statistics;computer science;mathematics;
Structural Hidden Markov Models Using a Relation of Equivalence: Application to Automotive Designs,Djamel Bouchaffra (Oakland University);Jun Tan (Oakland University);,"2310389295,2317008487","Standard hidden Markov models (HMM's) have been studied extensively in the last two decades. It is well known that these models assume state conditional independence of the observations. Therefore, they are inadequate for classification of complex and highly structured patterns. Nowadays, the need for new statistical models that are capable to cope with structural time series data is increasing. We propose in this paper a novel paradigm that we named ""structural hidden Markov model"" (SHMM). It extends traditional HMM's by partitioning the set of observation sequences into classes of equivalences. These observation sequences are related in the sense they all contribute to produce a particular local structure. We describe four basic problems that are assigned to a structural hidden Markov model: (1) probability evaluation, (2) statistical decoding, (3) local structure decoding, and (4) parameter estimation. We have applied SHMM in order to mine customers' preferences for automotive designs. The results reported in this application show that SHMM's outperform the traditional hidden Markov model with a 9% of increase in accuracy.",2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 79-96,variable order markov model;forward algorithm;maximum entropy markov model;hidden semi markov model;markov kernel;markov property;conditional independence;markov model;markov chain;markov process;time series;estimation theory;statistical model;hidden markov model;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
An Erratum on #x201C;Pushing Convertible Constraints in Frequent Itemset Mining#x201D;,Jian Pei (Simon Fraser University);Jiawei Han (University of Illinois at Urbana–Champaign);Laks V. S. Lakshmanan (University of British Columbia);,"2126330539,2121939561,2289816208",-,2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 119-119,world wide web;data mining;real time computing;
Erratum: Pushing convertible constraints in frequent itemset mining (Data Mining and Knowledge Discovery: An International Journal (May 2004) 8:3 (227-252)),Jian Pei (Simon Fraser University);Jiawei Han (Beckman Institute for Advanced Science and Technology);Laks V S Lakshmanan (University of British Columbia);,"2126330539,2121939561,2289816208",-,2006,Data Mining and Knowledge Discovery volume 12 issue 1,data science;information retrieval;data mining;
A Mathematical Morphology Based Scale Space Method for the Mining of Linear Features in Geographic Data,Min Wang (Nanjing Normal University);Yee Leung (The Chinese University of Hong Kong);Chenghu Zhou (Chinese Academy of Sciences);Tao Pei (Chinese Academy of Sciences);Jiancheng Luo (Chinese Academy of Sciences);,"2577709512,2682527320,2640162111,2721060300,2707063913","This paper presents a spatial data mining method MCAMMO and its extension L_MCAMMO designed for discovering linear and near linear features in spatial databases. L_MCAMMO can be divided into two basic steps: first, the most suitable re-segmenting scale is found by MCAMMO, which is a scale space method with mathematical morphology operators; second, the segmented result at this scale is re-segmented to obtain the final linear belts. These steps are essentially a multi-scale binary image segmentation process, and can also be treated as hierarchical clustering if we view the points under each connected component as one cluster. The final number of clusters is the one which survives (relatively, not absolutely) the longest scale range, and the clustering which first realizes this number of clusters is the most suitable segmentation. The advantages of MCAMMO in general and L_MCAMMO in particular, are: no need to pre-specify the number of clusters, a small number of simple inputs, capable of extracting clusters with arbitrary shapes, and robust to noise. The effectiveness of the proposed method is substantiated by the real-life experiments in the mining of seismic belts in China.",2006,Data Mining and Knowledge Discovery volume 12 issue 1 pp 97-118,cluster analysis;image analysis;data science;data mining;machine learning;statistics;computer science;mathematics;
Finding Frequent Patterns in a Large Sparse Graph,Michihiro Kuramochi (University of Minnesota);George Karypis (University of Minnesota);,"2074556247,219814910","Graph-based modeling has emerged as a powerful abstraction capable of capturing in a single and unified framework many of the relational, spatial, topological, and other characteristics that are present in a variety of datasets and application areas. Computationally efficient algorithms that find patterns corresponding to frequently occurring subgraphs play an important role in developing data mining-driven methodologies for analyzing the graphs resulting from such datasets. This paper presents two algorithms, based on the horizontal and vertical pattern discovery paradigms, that find the connected subgraphs that have a sufficient number of edge-disjoint embeddings in a single large undirected labeled sparse graph. These algorithms use three different methods for determining the number of edge-disjoint embeddings of a subgraph and employ novel algorithms for candidate generation and frequency counting, which allow them to operate on datasets with different characteristics and to quickly prune unpromising subgraphs. Experimental evaluation on real datasets from various domains show that both algorithms achieve good performance, scale well to sparse input graphs with more than 120,000 vertices or 110,000 edges, and significantly outperform previously developed algorithms.",2005,Data Mining and Knowledge Discovery volume 11 issue 3 pp 243-271,independent set;graph;theoretical computer science;data mining;machine learning;computer science;mathematics;
GenMax: An Efficient Algorithm for Mining Maximal Frequent Itemsets,Karam Gouda (Banha University);Mohammed Javeed Zaki (Rensselaer Polytechnic Institute);,"2120634949,2165917828","We present GenMax, a backtrack search based algorithm for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space. It uses a novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation. Systematic experimental comparison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efficient method to mine the exact set of maximal patterns.",2005,Data Mining and Knowledge Discovery volume 11 issue 3 pp 223-242,association rule learning;data mining;database;algorithm;computer science;mathematics;
Accurate Prediction of Protein Disordered Regions by Mining Protein Structure Data,"Jianlin Cheng (University of California, Irvine);Michael J. Sweredoski (University of California, Irvine);Pierre Baldi (University of California, Irvine);","2141057972,1974068642,2060797211","Intrinsically disordered regions in proteins are relatively frequent and important for our understanding of molecular recognition and assembly, and protein structure and function. From an algorithmic standpoint, flagging large disordered regions is also important for ab initio protein structure prediction methods. Here we first extract a curated, non-redundant, data set of protein disordered regions from the Protein Data Bank and compute relevant statistics on the length and location of these regions. We then develop an ab initio predictor of disordered regions called DISpro which uses evolutionary information in the form of profiles, predicted secondary structure and relative solvent accessibility, and ensembles of 1D-recursive neural networks. DISpro is trained and cross validated using the curated data set. The experimental results show that DISpro achieves an accuracy of 92.8% with a false positive rate of 5%. DISpro is a member of the SCRATCH suite of protein data mining tools available through http://www.igb.uci.edu/servers/psss.html.",2005,Data Mining and Knowledge Discovery volume 11 issue 3 pp 213-222,molecular recognition;protein structure prediction;protein data bank;cross validation;protein structure;protein secondary structure;data science;bioinformatics;data mining;computer science;
Making SVMs Scalable to Large Data Sets using Hierarchical Cluster Indexing,Hwanjo Yu (University of Iowa);Jiong Yang (Case Western Reserve University);Jiawei Han (University of Illinois at Urbana–Champaign);Xiaolei Li (University of Illinois at Urbana–Champaign);,"2703150452,2657574142,2121939561,2698759421","Support vector machines (SVMs) have been promising methods for classification and regression analysis due to their solid mathematical foundations, which include two desirable properties: margin maximization and nonlinear classification using kernels. However, despite these prominent properties, SVMs are usually not chosen for large-scale data mining problems because their training complexity is highly dependent on the data set size. Unlike traditional pattern recognition and machine learning, real-world data mining applications often involve huge numbers of data records. Thus it is too expensive to perform multiple scans on the entire data set, and it is also infeasible to put the data set in memory. This paper presents a method, Clustering-Based SVM (CB-SVM), that maximizes the SVM performance for very large data sets given a limited amount of resource, e.g., memory. CB-SVM applies a hierarchical micro-clustering algorithm that scans the entire data set only once to provide an SVM with high quality samples. These samples carry statistical summaries of the data and maximize the benefit of learning. Our analyses show that the training complexity of CB-SVM is quadratically dependent on the number of support vectors, which is usually much less than that of the entire data set. Our experiments on synthetic and real-world data sets show that CB-SVM is highly scalable for very large data sets and very accurate in terms of classification.",2005,Data Mining and Knowledge Discovery volume 11 issue 3 pp 295-321,test set;data pre processing;support vector machine;data stream mining;data mining;pattern recognition;machine learning;statistics;computer science;
Using Generalized Estimating Equation to Learn Decision Tree with Multivariate Responses,Seong Keon Lee (Korea University);Hyun-Cheol Kang (Hoseo University);Sang-Tae Han (Hoseo University);Kwang-Hwan Kim;,"2291512906,2163972410,2111461893,2696455298","Previous decision tree algorithms have used Mahalanobis distance for multiple continuous longitudinal response or generalized entropy index for multiple binary responses. However, these methods are limited to either continuous or binary responses. In this paper, we suggest a new tree-based method that can analyze any type of multiple responses by using a statistical approach, called GEE (generalized estimating equations). The value of this new technique is demonstrated with reference to an application using web-usage survey.",2005,Data Mining and Knowledge Discovery volume 11 issue 3 pp 273-293,mahalanobis distance;generalized estimating equation;decision tree;econometrics;machine learning;mathematical optimization;statistics;computer science;mathematics;
"Ordinal, Continuous and Heterogeneous k-Anonymity Through Microaggregation",Josep Domingo-Ferrer (Rovira i Virgili University);Vicenç Torra (Intel);,"275327080,2208460423","k-Anonymity is a useful concept to solve the tension between data utility and respondent privacy in individual data (microdata) protection. However, the generalization and suppression approach proposed in the literature to achieve k-anonymity is not equally suited for all types of attributes: (i) generalization/suppression is one of the few possibilities for nominal categorical attributes; (ii) it is just one possibility for ordinal categorical attributes which does not always preserve ordinality; (iii) and it is completely unsuitable for continuous attributes, as it causes them to lose their numerical meaning. Since attributes leading to disclosure (and thus needing k-anonymization) may be nominal, ordinal and also continuous, it is important to devise k-anonymization procedures which preserve the semantics of each attribute type as much as possible. We propose in this paper to use categorical microaggregation as an alternative to generalization/suppression for nominal and ordinal k-anonymization; we also propose continuous microaggregation as the method for continuous k-anonymization.",2005,Data Mining and Knowledge Discovery volume 11 issue 2 pp 195-212,econometrics;data mining;database;mathematics;
A Framework for Evaluating Privacy Preserving Data Mining Algorithms,Elisa Bertino (Purdue University);Igor Nai Fovino (University of Milan);Loredana Parasiliti Provenza (University of Milan);,"717547165,56151567,1177447894","Recently, a new class of data mining methods, known as privacy preserving data mining (PPDM) algorithms, has been developed by the research community working on security and knowledge discovery. The aim of these algorithms is the extraction of relevant knowledge from large amount of data, while protecting at the same time sensitive information. Several data mining techniques, incorporating privacy protection mechanisms, have been developed that allow one to hide sensitive itemsets or patterns, before the data mining process is executed. Privacy preserving classification methods, instead, prevent a miner from building a classifier which is able to predict sensitive data. Additionally, privacy preserving clustering techniques have been recently proposed, which distort sensitive numerical attributes, while preserving general features for clustering analysis. A crucial issue is to determine which ones among these privacy-preserving techniques better protect sensitive information. However, this is not the only criteria with respect to which these algorithms can be evaluated. It is also important to assess the quality of the data resulting from the modifications applied by each algorithm, as well as the performance of the algorithms. There is thus the need of identifying a comprehensive set of criteria with respect to which to assess the existing PPDM algorithms and determine which algorithm meets specific requirements. In this paper, we present a first evaluation framework for estimating and comparing different kinds of PPDM algorithms. Then, we apply our criteria to a specific set of algorithms and discuss the evaluation results we obtain. Finally, some considerations about future work and promising directions in the context of privacy preservation in data mining are discussed.",2005,Data Mining and Knowledge Discovery volume 11 issue 2 pp 121-154,privacy software;cluster analysis;knowledge extraction;internet privacy;world wide web;data mining;machine learning;computer science;
Probabilistic Information Loss Measures in Confidentiality Protection of Continuous Microdata,Josep Maria Mateo-Sanz (Rovira i Virgili University);Josep Domingo-Ferrer (Rovira i Virgili University);Francesc Sebé (Rovira i Virgili University);,"2054801584,275327080,2092464107","Inference control for protecting the privacy of microdata (individual data) should try to optimize the tradeoff between data utility (low information loss) and protection against disclosure (low disclosure risk). Whereas risk measures are bounded between 0 and 1, information loss measures proposed in the literature for continuous data are unbounded, which makes it awkward to trade off information loss for disclosure risk. We propose in this paper to use probabilities to define bounded information loss measures for continuous microdata.",2005,Data Mining and Knowledge Discovery volume 11 issue 2 pp 181-193,privacy;actuarial science;computer security;data mining;computer science;
Preserving the Confidentiality of Categorical Statistical Data Bases When Releasing Information for Association Rules,Stephen E. Fienberg (Carnegie Mellon University);Aleksandra B. Slavkovic (Pennsylvania State University);,"2591346928,211233220","In the statistical literature, there has been considerable development of methods of data releases for multivariate categorical data sets, where the releases come in the form of marginal tables corresponding to subsets of the categorical variables. Very recently some of the ideas have been extended to allow for the release of combinations of mixtures of marginal tables and conditional tables for subsets of variables. Association rules can be viewed as conditional tables. In this paper we consider possible inferences an intruder can make about confidential categorical data following the release of information on one or more association rules. We illustrate this with several examples.",2005,Data Mining and Knowledge Discovery volume 11 issue 2 pp 155-180,association rule learning;categorical variable;contingency table;algebraic geometry;data mining;database;machine learning;statistics;computer science;
Privacy in Data Mining,Josep Domingo-Ferrer (Rovira i Virgili University);Vicenç Torra (Intel);,"275327080,2208460423",-,2005,Data Mining and Knowledge Discovery volume 11 issue 2 pp 117-119,world wide web;computer security;data mining;computer science;
Automatic Subspace Clustering of High Dimensional Data,"Rakesh Agrawal (IBM);Johannes Gehrke (Cornell University);Dimitrios Gunopulos (University of California, Riverside);Prabhakar Raghavan (Yahoo!);","2138427228,2083845045,1656275121,2195048431","Data mining applications place special requirements on clustering algorithms including: the ability to find clusters embedded in subspaces of high dimensional data, scalability, end-user comprehensibility of the results, non-presumption of any canonical data distribution, and insensitivity to the order of input records. We present CLIQUE, a clustering algorithm that satisfies each of these requirements. CLIQUE identifies dense clusters in subspaces of maximum dimensionality. It generates cluster descriptions in the form of DNF expressions that are minimized for ease of comprehension. It produces identical results irrespective of the order in which input records are presented and does not presume any specific mathematical form for data distribution. Through experiments, we show that CLIQUE efficiently finds accurate clusters in large high dimensional datasets.",2005,Data Mining and Knowledge Discovery volume 11 issue 1 pp 5-33,k medians clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;fuzzy clustering;clustering high dimensional data;dimensionality reduction;cluster analysis;satisfiability;theoretical computer science;data mining;machine learning;statistics;computer science;mathematics;
Mining Customer Value: From Association Rules to Direct Marketing,Ke Wang Wong (Simon Fraser University);Senqiang Zhou (Simon Fraser University);Qiang Yang (Hong Kong University of Science and Technology);Jack Man Shun Yeung (Simon Fraser University);,"2278554369,2638641436,2109031554,2275962032","Direct marketing is a modern business activity with an aim to maximize the profit generated from marketing to a selected group of customers. A key to direct marketing is to select a subset of customers so as to maximize the profit return while minimizing the cost. Achieving this goal is difficult due to the extremely imbalanced data and the inverse correlation between the probability that a customer responds and the dollar amount generated by a response. We present a solution to this problem based on a creative use of association rules. Association rule mining searches for all rules above an interestingness threshold, as opposed to some rules in a heuristic-based search. Promising association rules are then selected based on the observed value of the customers they summarize. Selected association rules are used to build a model for predicting the value of a future customer. On the challenging KDD-CUP-98 dataset, this approach generates 41% more profit than the KDD-CUP winner and 35% more profit than the best result published thereafter, with 57.7% recall on responders and 78.0% recall on non-responders. The average profit per mail is 3.3 times that of the KDD-CUP winner.",2005,Data Mining and Knowledge Discovery volume 11 issue 1 pp 57-79,customer lifetime value;association rule learning;data mining;machine learning;computer science;
Data Mining for Inventory Item Selection with Cross-Selling Considerations,Raymond Chi-Wing Wong (The Chinese University of Hong Kong);Ada Wai-Chee Fu (The Chinese University of Hong Kong);Ke Wang (Simon Fraser University);,"2125027556,2165551961,2626264286","Association rule mining, studied for over ten years in the literature of data mining, aims to help enterprises with sophisticated decision making, but the resulting rules typically cannot be directly applied and require further processing. In this paper, we propose a method for actionable recommendations from itemset analysis and investigate an application of the concepts of association rules--maximal-profit item selection with cross-selling effect (MPIS). This problem is about choosing a subset of items which can give the maximal profit with the consideration of cross-selling effect. A simple approach to this problem is shown to be NP-hard. A new approach is proposed with consideration of the loss rule--a rule similar to the association rule--to model the cross-selling effect. We show that MPIS can be approximated by a quadratic programming problem. We also propose a greedy approach and a genetic algorithm to deal with this problem. Experiments are conducted, which show that our proposed approaches are highly effective and efficient.",2005,Data Mining and Knowledge Discovery volume 11 issue 1 pp 81-112,association rule learning;quadratic programming;data science;data mining;machine learning;statistics;computer science;
Neural and Wavelet Network Models for Financial Distress Classification,Victor M. Becerra (University of Reading);Roberto Kawakami Harrop Galvão (Instituto Tecnológico de Aeronáutica);Magda Abou-Seada (Middlesex University);,"2151519952,2019157960,1985041925","This work analyzes the use of linear discriminant models, multi-layer perceptron neural networks and wavelet networks for corporate financial distress prediction. Although simple and easy to interpret, linear models require statistical assumptions that may be unrealistic. Neural networks are able to discriminate patterns that are not linearly separable, but the large number of parameters involved in a neural model often causes generalization problems. Wavelet networks are classification models that implement nonlinear discriminant surfaces as the superposition of dilated and translated versions of a single ""mother wavelet"" function. In this paper, an algorithm is proposed to select dilation and translation parameters that yield a wavelet network classifier with good parsimony characteristics. The models are compared in a case study involving failed and continuing British firms in the period 1997--2000. Problems associated with over-parameterized neural networks are illustrated and the Optimal Brain Damage pruning technique is employed to obtain a parsimonious neural model. The results, supported by a re-sampling study, show that both neural and wavelet networks may be a valid alternative to classical linear discriminant models.",2005,Data Mining and Knowledge Discovery volume 11 issue 1 pp 35-55,discriminative model;time delay neural network;wavelet;network model;multilayer perceptron;linear model;biological classification;artificial neural network;data mining;artificial intelligence;machine learning;statistics;computer science;
Finding Frequent Patterns Using Length-Decreasing Support Constraints,Masakazu Seno (University of Minnesota);George Karypis (University of Minnesota);,"1985540934,219814910","Finding prevalent patterns in large amount of data has been one of the major problems in the area of data mining. Particularly, the problem of finding frequent itemset or sequential patterns in very large databases has been studied extensively over the years, and a variety of algorithms have been developed for each problem. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of these two problems. In general, patterns that contain only a few items will tend to be interesting if they have a high support, whereas long patterns can still be interesting even if their support is relatively small. Ideally, we want to find all the frequent patterns whose support decreases as a function of their length without having to find many uninteresting infrequent short patterns. Developing such algorithms is particularly challenging because the downward closure property of the constant support constraint cannot be used to prune short infrequent patterns.",2005,Data Mining and Knowledge Discovery volume 10 issue 3 pp 197-228,association rule learning;data processing;data science;data mining;database;computer science;
Sequential Activity Profiling: Latent Dirichlet Allocation of Markov Chains,Mark A. Girolami (University of Glasgow);Ata Kabán (University of Birmingham);,"2139051431,2082255270",To provide a parsimonious generative representation of the sequential activity of a number of individuals within a population there is a necessary tradeoff between the definition of individual specific and global representations. A linear-time algorithm is proposed that defines a distributed predictive model for finite state symbolic sequences which represent the traces of the activity of a number of individuals within a group. The algorithm is based on a straightforward generalization of latent Dirichlet allocation to time-invariant Markov chains of arbitrary order. The modelling assumption made is that the possibly heterogeneous behavior of individuals may be represented by a relatively small number of simple and common behavioral traits which may interleave randomly according to an individual-specific distribution. The results of an empirical study on three different application domains indicate that this modelling approach provides an efficient low-complexity and intuitively interpretable representation scheme which is reflected by improved prediction performance over comparable models.,2005,Data Mining and Knowledge Discovery volume 10 issue 3 pp 175-196,latent dirichlet allocation;mixture model;markov chain;econometrics;machine learning;statistics;computer science;mathematics;
On High Dimensional Projected Clustering of Data Streams,Charu C. Aggarwal (IBM);Jiawei Han (University of Illinois at Urbana–Champaign);Jianyong Wang (Tsinghua University);Philip S. Yu (IBM);,"2146335907,2121939561,2105625159,2125104194","The data stream problem has been studied extensively in recent years, because of the great ease in collection of stream data. The nature of stream data makes it essential to use algorithms which require only one pass over the data. Recently, single-scan, stream analysis methods have been proposed in this context. However, a lot of stream data is high-dimensional in nature. High-dimensional data is inherently more complex in clustering, classification, and similarity search. Recent research discusses methods for projected clustering over high-dimensional data sets. This method is however difficult to generalize to data streams because of the complexity of the method and the large volume of the data streams.",2005,Data Mining and Knowledge Discovery volume 10 issue 3 pp 251-273,data stream clustering;cure data clustering algorithm;clustering high dimensional data;cluster analysis;data stream mining;data science;data mining;database;machine learning;computer science;
HIL-Tree: A Hierarchical Structure for Guiding Search into Test and Measurement Data Archives,Hassan A. Artail (American University of Beirut);,117720832,"This paper describes a novel algorithm that uses discontinuity detection to discover index vectors in test and measurement data archives containing multidimensional data. The index vectors are generated from individual data series in the archive and hold location information about jumps and changes in trends (discontinuities). They are related in a hierarchical manner to form a tree-like structure based on the alignment of the location information across the vectors. We call such trees Hierarchical Index Locations trees (HIL-trees), which are useful in guiding navigation into the raw data and in speeding up the process of retrieving data subsets based on given criteria. To demonstrate the practical value of the algorithm, we present a case study through which the algorithm is applied to real automotive emission test data archives, and show how it works. We also compare the HIL-tree to the well-known R-tree index structure and show how HIL-trees are advantageous in many aspects.",2005,Data Mining and Knowledge Discovery volume 10 issue 3 pp 229-250,data segment;data science;data mining;database;machine learning;statistics;computer science;
Hierarchical Clustering Algorithms for Document Datasets,Ying Zhao (University of Minnesota);George Karypis (University of Minnesota);Usama M. Fayyad (University of Minnesota);,"2616987123,219814910,2683732562","Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, clustering algorithms that build meaningful hierarchies out of large document collections are ideal tools for their interactive visualization and exploration as they provide data-views that are consistent, predictable, and at different levels of granularity. This paper focuses on document clustering algorithms that build such hierarchical solutions and (i) presents a comprehensive study of partitional and agglomerative algorithms that use different criterion functions and merging schemes, and (ii) presents a new class of clustering algorithms called constrained agglomerative algorithms, which combine features from both partitional and agglomerative approaches that allows them to reduce the early-stage errors made by agglomerative methods and hence improve the quality of clustering solutions. The experimental evaluation shows that, contrary to the common belief, partitional algorithms always lead to better solutions than agglomerative algorithms; making them ideal for clustering large document collections due to not only their relatively low computational requirements, but also higher clustering quality. Furthermore, the constrained agglomerative methods consistently lead to better solutions than agglomerative methods alone and for many cases they outperform partitional methods, as well.",2005,Data Mining and Knowledge Discovery volume 10 issue 2 pp 141-168,hierarchical clustering of networks;brown clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;fuzzy clustering;hierarchical clustering;cluster analysis;biclustering;document clustering;interactive visualization;data science;data mining;machine learning;computer science;
Efficient Algorithms for Mining and Incremental Update of Maximal Frequent Sequences,Ben Kao (University of Hong Kong);Minghua Zhang (University of Hong Kong);Chi Lap Yip (University of Hong Kong);David W. Cheung (University of Hong Kong);Usama M. Fayyad (University of Hong Kong);,"1911907851,2295530721,2118924420,1979772396,2306498003","We study two problems: (1) mining frequent sequences from a transactional database, and (2) incremental update of frequent sequences when the underlying database changes over time. We review existing sequence mining algorithms including GSP, PrefixSpan, SPADE, and ISM. We point out the large memory requirement of Pref ixSpan, SPADE, and ISM, and evaluate the performance of GSP. We discuss the high I/O cost of GSP, particularly when the database contains long frequent sequences. To reduce the I/O requirement, we propose an algorithm MFS, which could be considered as a generalization of GSP. The general strategy of MFS is to first find an approximate solution to the set of frequent sequences and then perform successive refinement until the exact set of frequent sequences is obtained. We show that this successive refinement approach results in a significant improvement in I/O cost. We discuss how MFS can be applied to the incremental update problem. In particular, the result of a previous mining exercise can be used (by MFS) as a good initial approximate solution for the mining of an updated database. This results in an I/O efficient algorithm. To improve processing efficiency, we devise pruning techniques that, when coupled with GSP or MFS, result in algorithms that are both CPU and I/O efficient.",2005,Data Mining and Knowledge Discovery volume 10 issue 2 pp 87-116,gsp algorithm;sequential pattern mining;sequence;data mining;database;algorithm;computer science;
On the Use of Wavelet Decomposition for String Classification,Charu C. Aggarwal (IBM);Paul S. Bradley (IBM);,"2146335907,2491989320","In recent years, the technological advances in mapping genes have made it increasingly easy to store and use a wide variety of biological data. Such data are usually in the form of very long strings for which it is difficult to determine the most relevant features for a classification task. For example, a typical DNA string may be millions of characters long, and there may be thousands of such strings in a database. In many cases, the classification behavior of the data may be hidden in the compositional behavior of certain segments of the string which cannot be easily determined apriori. Another problem which complicates the classification task is that in some cases the classification behavior is reflected in global be havior of the string, whereas in others it is reflected in local patterns. Given the enormous variation in the behavior of the strings over different data sets, it is useful to develop an approach which is sensitive to both the global and local behavior of the strings for the purpose of classification. For this purpose, we will exploit the multi-resolution property of wavelet decomposition in order to create a scheme which can mine classification characteristics at different levels of granularity. The resulting scheme turns out to be very effective in practice on a wide range of problems.",2005,Data Mining and Knowledge Discovery volume 10 issue 2 pp 117-139,string kernel;biological data;wavelet;biological classification;theoretical computer science;data mining;machine learning;computer science;mathematics;
Data Mining for Imbalanced Datasets: An Overview,Nitesh V. Chawla (University of Notre Dame);,1979796846,-,2005,Data Mining and Knowledge Discovery pp 875-886,sampling;data science;data mining;pattern recognition;machine learning;computer science;
Mining Web Log Sequential Patterns with Position Coded Pre-Order Linked WAP-Tree,Christie I. Ezeife (University of Windsor);Yi Lu (University of Windsor);,"2515904849,2666449056","Sequential mining is the process of applying data mining techniques to a sequential database for the purposes of discovering the correlation relationships that exist among an ordered list of events. An important application of sequential mining techniques is web usage mining, for mining web log accesses, where the sequences of web page accesses made by different web users over a period of time, through a server, are recorded. Web access pattern tree (WAP-tree) mining is a sequential pattern mining technique for web log access sequences, which first stores the original web access sequence database on a prefix tree, similar to the frequent pattern tree (FP-tree) for storing non-sequential data. WAP-tree algorithm then, mines the frequent sequences from the WAP-tree by recursively re-constructing intermediate trees, starting with suffix sequences and ending with prefix sequences. This paper proposes a more efficient approach for using the WAP-tree to mine frequent sequences, which totally eliminates the need to engage in numerous re-construction of intermediate WAP-trees during mining. The proposed algorithm builds the frequent header node links of the original WAP-tree in a pre-order fashion and uses the position code of each node to identify the ancestor/descendant relationships between nodes of the tree. It then, finds each frequent sequential pattern, through progressive prefix sequence search, starting with its first prefix subsequence event. Experiments show huge performance gain over the WAP-tree technique.",2005,Data Mining and Knowledge Discovery volume 10 issue 1 pp 5-38,web accessibility;sequential pattern mining;web page;web mining;world wide web;data mining;database;computer science;
Geometric Methods for Feature Extraction and Dimensional Reduction,Christopher J. C. Burges (Microsoft);,2014469688,-,2005,Data Mining and Knowledge Discovery pp 59-91,kernel principal component analysis;spectral clustering;principal component regression;projection pursuit;multidimensional scaling;projection method;dimensionality reduction;principal component analysis;feature extraction;k nearest neighbors algorithm;feature selection;pattern recognition;machine learning;mathematical optimization;computer science;
Data Mining in Telecommunications,Gary M. Weiss (Fordham University);,2112185085,-,2005,Data Mining and Knowledge Discovery pp 1189-1201,fault detection and isolation;component based software engineering;data stream mining;data science;computer security;data mining;computer science;
K-Optimal Rule Discovery,Geoffrey I. Webb (Monash University);Songmao Zhang (National Institutes of Health);,"2126304162,2620359470",K-optimal rule discovery finds the K rules that optimize a user-specified measure of rule value with respect to a set of sample data and user-specified constraints. This approach avoids many limitations of the frequent itemset approach of association rule discovery. This paper presents a scalable algorithm applicable to a wide range of K-optimal rule discovery tasks and demonstrates its efficiency.,2005,Data Mining and Knowledge Discovery volume 10 issue 1 pp 39-79,k optimal pattern discovery;association rule learning;data mining;pattern recognition;machine learning;computer science;mathematics;
Frequent Set Mining,Bart Goethals (University of Antwerp);,1992071743,-,2005,Data Mining and Knowledge Discovery pp 321-338,k optimal pattern discovery;fsa red algorithm;apriori algorithm;association rule learning;machine learning;computer science;
Constraint-based Data Mining,Jean-Francois Boulicaut (Institut national des sciences Appliquées de Lyon);Baptiste Jeudy (University of Lyon);,"1971530415,2240884582",Summary. Knowledge Discovery in Databases (KDD) is a complex interactive process. The promising theoretical framework of inductive databases considers this is essentially a querying process. It is enabled by a query language which can deal either with raw data or patterns which hold in the data. Mining patterns turns to be the so-called inductive query evaluation process for which constraint-based Data Mining techniques have to be designed. An inductive query specifies declaratively the desired constraints and algorithms are used to compute the patterns satisfying the constraints in the data. We survey important results of this active research domain. This chapter emphasizes a real breakthrough for hard problems concerning local pattern mining under various constraints and it points out the current directions of research as well.,2005,Data Mining and Knowledge Discovery pp 339-354,sargable;rdf query language;web search query;query expansion;query optimization;query language;satisfiability;data stream mining;data science;data mining;database;computer science;
A Review of Web Document Clustering Approaches,Nora Oikonomakou (Athens University of Economics and Business);Michalis Vazirgiannis (Athens University of Economics and Business);,"2257877321,1914497179",-,2005,Data Mining and Knowledge Discovery pp 931-948,web 2 0;semantic web stack;web modeling;social semantic web;data web;web standards;web mapping;web application security;web development;web design;web navigation;information overload;web server;semantic web;web service;information needs;web page;cluster analysis;satisfiability;web intelligence;web mining;text mining;world wide web;information retrieval;data mining;computer science;
Data Mining Query Languages,Jean-Francois Boulicaut (Institut national des sciences Appliquées de Lyon);Cyrille Masson (Institut national des sciences Appliquées de Lyon);,"1971530415,2154194853","Many data mining algorithms enable to extract different types of patterns from data (e.g., local patterns like itemsets and association rules, models like classi- fiers). To support the whole knowledge discovery process, we need for integrated systems which can deal either with patterns and data. The inductive database approach has emerged as an unifying framework for such systems. Following this database perspective, knowledge discovery processes become querying pro- cesses for which query languages have to be designed. In the prolific field of association rule mining, different proposals of query languages have been made to support the more or less declarative specification of both data and pattern ma- nipulations. In this chapter, we survey some of these proposals. It enables to identify nowadays shortcomings and to point out some promising directions of research in this area.",2005,Data Mining and Knowledge Discovery pp 715-726,k optimal pattern discovery;query optimization;query language;association rule learning;data stream mining;data science;data mining;database;computer science;
LERS—A Data Mining System,Jerzy W. Grzymala-Busse (University of Kansas);,244148578,-,2005,Data Mining and Knowledge Discovery pp 1347-1351,data stream mining;web mining;data mining;computer science;
Support Vector Machines,Armin Shmilovici (Ben-Gurion University of the Negev);,2184642286,-,2005,Data Mining and Knowledge Discovery pp 231-247,margin classifier;structured support vector machine;graph kernel;polynomial kernel;radial basis function kernel;relevance vector machine;least squares support vector machine;perceptron;sequential minimal optimization;learning vector quantization;kernel method;support vector machine;feature vector;semi supervised learning;supervised learning;pattern recognition;machine learning;computer science;
Mining with Rare Cases,Gary M. Weiss (Fordham University);,2112185085,-,2005,Data Mining and Knowledge Discovery pp 747-757,medical diagnosis;data mining;computer science;
Data Mining for Target Marketing,Nissan Levin (Tel Aviv University);Jacob Zahavi (Tel Aviv University);,"2168521774,2034680710",-,2005,Data Mining and Knowledge Discovery pp 1261-1301,market timing;discrete choice;decision tree learning;survival analysis;decision tree;predictive modelling;data science;data mining;machine learning;computer science;
Data Mining for Intrusion Detection,Anoop Singhal (George Mason University);Sushil Jajodia (George Mason University);,"2103588732,2056441798",-,2005,Data Mining and Knowledge Discovery pp 1225-1237,anomaly based intrusion detection system;intrusion prevention system;network management;intrusion detection system;association rule learning;data warehouse;anomaly detection;computer security;data mining;database;computer science;
Identification of Critical Values in Latent Semantic Indexing.,April Kontostathis (Ursinus College);William M. Pottenger (Ursinus College);Brian D. Davison 0001 (Ursinus College);,"204288848,2211641527,2203702053",-,2005,Data Mining and Knowledge Discovery pp 333-346,probabilistic latent semantic analysis;latent semantic indexing;latent semantic analysis;critical value;singular value decomposition;sparse matrix;information retrieval;data mining;pattern recognition;statistics;computer science;mathematics;
Evolutionary Algorithms for Data Mining,Alex Alves Freitas (University of Kent);,2131502281,"Evolutionary Algorithms (EAs) are stochastic search algorithms inspired by the process of Darwinian evolution. The motivation for applying EAs to Data Mining is that they are robust, adaptive search techniques that perform a global search in the solution space. This chapter reviews mainly two kinds of EAs, viz. Genetic Algorithms (GAs) and Genetic Programming (GP), and discusses how EAs can be applied to several Data Mining tasks, namely: discovery of classification rules, clustering, attribute selection and attribute construction. It also discusses the basic idea of Multi-Objective EAs, based on the concept of Pareto dominance, which also has applications in Data Mining.",2005,Data Mining and Knowledge Discovery pp 435-467,computer programming;evolutionary algorithm;theoretical computer science;data mining;machine learning;computer science;
Information Fusion - Methods and Aggregation Operators,Vicenç Torra (Intel);,2208460423,-,2005,Data Mining and Knowledge Discovery pp 999-1008,data pre processing;model building;information extraction;data science;data mining;pattern recognition;computer science;
Mining Non-Redundant Association Rules,Mohammed Javeed Zaki (Rensselaer Polytechnic Institute);,2165917828,"The traditional association rule mining framework produces many redundant rules. The extent of redundancy is a lot larger than previously suspected. We present a new framework for associations based on the concept of closed frequent itemsets. The number of non-redundant rules produced by the new approach is exponentially (in the length of the longest frequent itemset) smaller than the rule set from the traditional approach. Experiments using several “hard” as well as “easy” real and synthetic databases confirm the utility of our framework in terms of reduction in the number of rules presented to the user, and in terms of time.",2004,Data Mining and Knowledge Discovery volume 9 issue 3 pp 223-248,association rule learning;data science;data mining;database;machine learning;computer science;mathematics;
Enhancing Product Recommender Systems on Sparse Binary Data,Ayhan Demiriz (Verizon Communications);,1932697447,"Commercial recommender systems use various data mining techniques to make appropriate recommendations to users during online, real-time sessions. Published algorithms focus more on the discrete user ratings instead of binary results, which hampers their predictive capabilities when usage data is sparse. The system proposed in this paper, e-VZpro, is an association mining-based recommender tool designed to overcome these problems through a two-phase approach. In the first phase, batches of customer historical data are analyzed through association mining in order to determine the association rules for the second phase. During the second phase, a scoring algorithm is used to rank the recommendations online for the customer. The second phase differs from the traditional approach and an empirical comparison between the methods used in e-VZpro and other collaborative filtering methods including dependency networks, item-based, and association mining is provided in this paper. This comparison evaluates the algorithms used in each of the above methods using two internal customer datasets and a benchmark dataset. The results of this comparison clearly show that e-VZpro performs well compared to dependency networks and association mining. In general, item-based algorithms with cosine similarity measures have the best performance.",2004,Data Mining and Knowledge Discovery volume 9 issue 2 pp 147-170,collaborative filtering;association rule learning;recommender system;data science;world wide web;data mining;machine learning;computer science;
Mining Surprising Periodic Patterns,Jiong Yang (University of Illinois at Urbana–Champaign);Wei Wang (University of North Carolina at Chapel Hill);Philip S. Yu (IBM);,"2115276518,2315689540,2125104194","In this paper, we focus on mining surprising periodic patterns in a sequence of events. In many applications, e.g., computational biology, an infrequent pattern is still considered very significant if its actual occurrence frequency exceeds the prior expectation by a large margin. The traditional metric, such as support, is not necessarily the ideal model to measure this kind of surprising patterns because it treats all patterns equally in the sense that every occurrence carries the same weight towards the assessment of the significance of a pattern regardless of the probability of occurrence. A more suitable measurement, information, is introduced to naturally value the degree of surprise of each occurrence of a pattern as a continuous and monotonically decreasing function of its probability of occurrence. This would allow patterns with vastly different occurrence probabilities to be handled seamlessly. As the accumulated degree of surprise of all repetitions of a pattern, the concept of information gain is proposed to measure the overall degree of surprise of the pattern within a data sequence. The bounded information gain property is identified to tackle the predicament caused by the violation of the downward closure property by the information gain measure and in turn provides an efficient solution to this problem. Furthermore, the user has a choice between specifying a minimum information gain threshold and choosing the number of surprising patterns wanted. Empirical tests demonstrate the efficiency and the usefulness of the proposed model.",2004,Data Mining and Knowledge Discovery volume 9 issue 2 pp 189-216,kullback leibler divergence;statistical significance;data mining;artificial intelligence;machine learning;statistics;mathematics;
Outlier Detection and Data Cleaning in Multivariate Non-Normal Samples: The PAELLA Algorithm,Manuel Castejón Limas (University of León);Joaquín Bienvenido Ordieres Meré (DIM);Francisco Javier Martínez de Pisón Ascacíbar;Eliseo Pablo Vergara González;,"2035005907,1268709491,1265238452,2152683974","A new method of outlier detection and data cleaning for both normal and non-normal multivariate data sets is proposed. It is based on an iterated local fit without a priori metric assumptions. We propose a new approach supported by finite mixture clustering which provides good results with large data sets. A multi-step structure, consisting of three phases, is developed. The importance of outlier detection in industrial modeling for open-loop control prediction is also described. The described algorithm gives good results both in simulations runs with artificial data sets and with experimental data sets recorded in a rubber factory. Finally, some discussion about this methodology is exposed.",2004,Data Mining and Knowledge Discovery volume 9 issue 2 pp 171-187,outlier;multivariate statistics;anomaly detection;econometrics;data mining;machine learning;statistics;computer science;mathematics;
On Leveraging User Access Patterns for Topic Specific Crawling,Charu C. Aggarwal (IBM);,2146335907,"In recent years, there has been considerable research on constructing crawlers which find resources satisfying specific conditions called predicates. Such a predicate could be a keyword query, a topical query, or some arbitrary contraint on the internal structure of the web page. Several techniques such as focussed crawling and intelligent crawling have recently been proposed for performing the topic specific resource discovery process. All these crawlers are linkage based, since they use the hyperlink behavior in order to perform resource discovery. Recent studies have shown that the topical correlations in hyperlinks are quite noisy and may not always show the consistency necessary for a reliable resource discovery process. In this paper, we will approach the problem of resource discovery from an entirely different perspective; we will mine the significant browsing patterns of world wide web users in order to model the likelihood of web pages belonging to a specified predicate. This user behavior can be mined from the freely available traces of large public domain proxies on the world wide web. For example, proxy caches such as Squid are hierarchical proxies which make their logs publically available. As we shall see in this paper, such traces are a rich source of information which can be mined in order to find the users that are most relevant to the topic of a given crawl. We refer to this technique as collaborative crawling because it mines the collective user experiences in order to find topical resources. Such a strategy turns out to be extremely effective because the topical consistency in world wide web browsing patterns turns out to very high compared to the noisy linkage information. In addition, the user-centered crawling system can be combined with linkage based systems to create an overall system which works more effectively than a system based purely on either user behavior or hyperlinks.",2004,Data Mining and Knowledge Discovery volume 9 issue 2 pp 123-145,distributed web crawling;crawling;public domain;web page;satisfiability;user experience design;world wide web;data mining;database;computer science;
Mining GPS Traces for Map Refinement,Stefan Schroedl (Daimler AG);Kiri Wagstaff (Daimler AG);Seth Rogers (Daimler AG);Pat Langley (Daimler AG);Christopher Wilson (Daimler AG);,"1746700504,2110892363,2120601119,2151465254,2307890209","Despite the increasing popularity of route guidance systems, current digital maps are still inadequate for many advanced applications in automotive safety and convenience. Among the drawbacks are the insufficient accuracy of road geometry and the lack of fine-grained information, such as lane positions and intersection structure. In this paper, we present an approach to induce high-precision maps from traces of vehicles equipped with differential GPS receivers. Since the cost of these systems is rapidly decreasing and wireless technology is advancing to provide the communication infrastructure, we expect that in the next few years large amounts of car data will be available inexpensively. Our approach consists of successive processing steps: individual vehicle trajectories are divided into road segments and intersections; a road centerline is derived for each segment; lane positions are determined by clustering the perpendicular offsets from it; and the transitions of traces between segments are utilized in the generation of intersection models. This paper describes an approach to this complex data-mining task in a contiguous manner. Among the new contributions are a spatial clustering algorithm for inferring the connectivity structure, more powerful lane finding algorithms that are able to handle lane splits and merges, and an approach to inferring detailed intersection models.",2004,Data Mining and Knowledge Discovery volume 9 issue 1 pp 59-87,floating car data;complex data type;global positioning system;digital mapping;telecommunications;data mining;simulation;computer science;
A Subsequence Matching Algorithm that Supports Normalization Transform in Time-Series Databases,Woong-Kee Loh (KAIST);Sang-Wook Kim (Hanyang University);Kyu-Young Whang (KAIST);,"2122055598,2114304489,1933211966","In this paper, an algorithm is proposed for subsequence matching that supports normalization transform in time-series databases. Normalization transform enables finding sequences with similar fluctuation patterns even though they are not close to each other before the normalization transform. Simple application of existing subsequence matching algorithms to support normalization transform is not feasible since the algorithms do not have information for normalization transform of subsequences of arbitrary lengths. Application of the existing whole matching algorithm supporting normalization transform to the subsequence matching is feasible, but requires an index for every possible length of the query sequence causing serious overhead on both storage space and update time. The proposed algorithm generates indexes only for a small number of different lengths of query sequences. For subsequence matching it selects the most appropriate index among them. Better search performance can be obtained by using more indexes. In this paper, the approach is called index interpolation. It is formally proved that the proposed algorithm does not cause false dismissal. The search performance can be traded off with storage space by adjusting the number of indexes. For performance evaluation, a series of experiments is conducted using the indexes for only five different lengths out of lengths 256~512 of the query sequence. The results show that the proposed algorithm outperforms the sequential scan by up to 2.4 times on the average when the selectivity of the query is 10?2 and up to 14.6 times when it is 10?5. Since the proposed algorithm performs better with smaller selectivities, it is suitable for practical situations, where the queries with smaller selectivities are much more frequent.",2004,Data Mining and Knowledge Discovery volume 9 issue 1 pp 5-28,time series;discrete mathematics;data mining;statistics;algorithm;mathematics;
Hypergraph Models and Algorithms for Data-Pattern-Based Clustering,Muhammet Mustafa Ozdal (University of Illinois at Urbana–Champaign);Cevdet Aykanat (Bilkent University);,"1203210335,156302704","In traditional approaches for clustering market basket type data, relations among transactions are modeled according to the items occurring in these transactions. However, an individual item might induce different relations in different contexts. Since such contexts might be captured by interesting patterns in the overall data, we represent each transaction as a set of patterns through modifying the conventional pattern semantics. By clustering the patterns in the dataset, we infer a clustering of the transactions represented this way. For this, we propose a novel hypergraph model to represent the relations among the patterns. Instead of a local measure that depends only on common items among patterns, we propose a global measure that is based on the cooccurences of these patterns in the overall data. The success of existing hypergraph partitioning based algorithms in other domains depends on sparsity of the hypergraph and explicit objective metrics. For this, we propose a two-phase clustering approach for the above hypergraph, which is expected to be dense. In the first phase, the vertices of the hypergraph are merged in a multilevel algorithm to obtain large number of high quality clusters. Here, we propose new quality metrics for merging decisions in hypergraph clustering specifically for this domain. In order to enable the use of existing metrics in the second phase, we introduce a vertex-to-cluster affinity concept to devise a method for constructing a sparse hypergraph based on the obtained clustering. The experiments we have performed show the effectiveness of the proposed framework.",2004,Data Mining and Knowledge Discovery volume 9 issue 1 pp 29-57,correlation clustering;fuzzy clustering;cluster analysis;theoretical computer science;data mining;machine learning;computer science;mathematics;
Incremental Maintenance on the Border of the Space of Emerging Patterns,"Jinyan Li (Agency for Science, Technology and Research);Thomas Manoukian (University of Melbourne);Guozhu Dong (Wright State University);Kotagiri Ramamohanarao (University of Melbourne);","2190567876,275334865,2164298414,123309386","Emerging patterns (EPs) are useful knowledge patterns with many applications. In recent studies on bio-medical profiling data, we have successfully used such patterns to solve difficult cancer diagnosis problems and produced higher classification accuracy when compared to alternative methods. However, the discovery of EPs is a challenging and computationally expensive problem. In this paper, we study how to incrementally modify and maintain the concise boundary descriptions of the space of all emerging patterns when small changes occur to the data. As EP spaces are convex, the maintenance on the bounds guarantees that no desired patterns are lost. We introduce algorithms to handle four types of changes: insertion of new data, deletion of old data, addition of new attributes, and deletion of old attributes. We compare these incremental algorithms, on six benchmark data sets, against an efficient algorithm that computes from scratch. The results show that the incremental algorithms are much faster than the From-Scratch method, often with tremendous speed-up rates.",2004,Data Mining and Knowledge Discovery volume 9 issue 1 pp 89-116,data mining;machine learning;algorithm;computer science;
On-Line Unsupervised Outlier Detection Using Finite Mixtures with Discounting Learning Algorithms,Kenji Yamanishi (NEC);Jun'ichi Takeuchi (NEC);Graham J. Williams (Commonwealth Scientific and Industrial Research Organisation);Peter Milne (Commonwealth Scientific and Industrial Research Organisation);,"1444602532,2152066928,2106893266,2303478343","Outlier detection is a fundamental issue in data mining, specifically in fraud detection, network intrusion detection, network monitoring, etc. SmartSifter is an outlier detection engine addressing this problem from the viewpoint of statistical learning theory. This paper provides a theoretical basis for SmartSifter and empirically demonstrates its effectiveness. SmartSifter detects outliers in an on-line process through the on-line unsupervised learning of a probabilistic model (using a finite mixture model) of the information source. Each time a datum is input SmartSifter employs an on-line discounting learning algorithm to learn the probabilistic model. A score is given to the datum based on the learned model with a high score indicating a high possibility of being a statistical outlier. The novel features of SmartSifter are: (1) it is adaptive to non-stationary sources of datas (2) a score has a clear statistical/information-theoretic meanings (3) it is computationally inexpensives and (4) it can handle both categorical and continuous variables. An experimental application to network intrusion detection shows that SmartSifter was able to identify data with high scores that corresponded to attacks, with low computational costs. Further experimental application has identified a number of meaningful rare cases in actual health insurance pathology data from Australia's Health Insurance Commission.",2004,Data Mining and Knowledge Discovery volume 8 issue 3 pp 275-300,network monitoring;intrusion detection system;mixture model;expectation maximization algorithm;statistical model;anomaly detection;data mining;pattern recognition;machine learning;statistics;computer science;
Pushing Convertible Constraints in Frequent Itemset Mining,Jian Pei (University at Buffalo);Jiawei Han (University of Illinois at Urbana–Champaign);Laks V. S. Lakshmanan (University of British Columbia);,"2126330539,2121939561,2289816208","Recent work has highlighted the importance of the constraint-based mining paradigm in the context of frequent itemsets, associations, correlations, sequential patterns, and many other interesting patterns in large databases. Constraint pushing techniques have been developed for mining frequent patterns and associations with antimonotonic, monotonic, and succinct constraints. In this paper, we study constraints which cannot be handled with existing theory and techniques in frequent pattern mining. For example, avg(S)θv, median(S)θv, sum(S)θv (S can contain items of arbitrary values, θ ∈ l>, <, ≤, ≥r and v is a real number.) are customarily regarded as “tough” constraints in that they cannot be pushed inside an algorithm such as Apriori. We develop a notion of convertible constraints and systematically analyze, classify, and characterize this class. We also develop techniques which enable them to be readily pushed deep inside the recently developed FP-growth algorithm for frequent itemset mining. Results from our detailed experiments show the effectiveness of the techniques developed.",2004,Data Mining and Knowledge Discovery volume 8 issue 3 pp 227-252,pruning;constraint;data mining;database;algorithm;computer science;
Maximum and Minimum Likelihood Hebbian Learning for Exploratory Projection Pursuit,Emilio Corchado (University of the West of Scotland);Donald MacDonald (University of the West of Scotland);Colin Fyfe (University of the West of Scotland);,"155781915,2563917501,669381866","In this paper, we review an extension of the learning rules in a Principal Component Analysis network which has been derived to be optimal for a specific probability density function. We note that this probability density function is one of a family of pdfs and investigate the learning rules formed in order to be optimal for several members of this family. We show that, whereas we have previously (Lai et al., 2000s Fyfe and MacDonald, 2002) viewed the single member of the family as an extension of PCA, it is more appropriate to view the whole family of learning rules as methods of performing Exploratory Projection Pursuit. We illustrate this on both artificial and real data sets.",2004,Data Mining and Knowledge Discovery volume 8 issue 3 pp 203-225,leabra;hebbian theory;competitive learning;projection pursuit;principal component analysis;probability density function;artificial neural network;artificial intelligence;machine learning;statistics;computer science;mathematics;
Building Association-Rule Based Sequential Classifiers for Web-Document Prediction,Qiang Yang (Simon Fraser University);Tianyi Li (Simon Fraser University);Ke Wang (Simon Fraser University);,"2109031554,2422367428,2626264286","Web servers keep track of web users' browsing behavior in web logs. From these logs, one can build statistical models that predict the users' next requests based on their current behavior. These data are complex due to their large size and sequential nature. In the past, researchers have proposed different methods for building association-rule based prediction models using the web logs, but there has been no systematic study on the relative merits of these methods. In this paper, we provide a comparative study on different kinds of sequential association rules for web document prediction. We show that the existing approaches can be cast under two important dimensions, namely the type of antecedents of rules and the criterion for selecting prediction rules. From this comparison we propose a best overall method and empirically test the proposed model on real web logs.",2004,Data Mining and Knowledge Discovery volume 8 issue 3 pp 253-273,association rule learning;predictive modelling;statistical model;comparative research;data science;world wide web;data mining;machine learning;computer science;
Fast and Robust General Purpose Clustering Algorithms,Vladimir Estivill-Castro (Griffith University);Jianhua Yang (Information Technology University);,"273506593,2636812367","General purpose and highly applicable clustering methods are usually required during the early stages of knowledge discovery exercises. k-MEANS has been adopted as the prototype of iterative model-based clustering because of its speed, simplicity and capability to work within the format of very large databases. However, k-MEANS has several disadvantages derived from its statistical simplicity. We propose an algorithm that remains very efficient, generally applicable, multidimensional but is more robust to noise and outliers. We achieve this by using medians rather than means as estimators for the centers of clusters. Comparison with k-MEANS, EXPECTATION and MAXIMIZATION sampling demonstrates the advantages of our algorithm.",2004,Data Mining and Knowledge Discovery volume 8 issue 2 pp 127-150,canopy clustering algorithm;medoid;cure data clustering algorithm;very large database;k means clustering;cluster analysis;expectation maximization algorithm;knowledge extraction;combinatorial optimization;data science;data mining;machine learning;statistics;computer science;
Efficient Multisplitting Revisited: Optima-Preserving Elimination of Partition Candidates,Tapio Elomaa (University of Helsinki);Juho Rousu (University of Helsinki);,"2303288923,2228020513","We consider multisplitting of numerical value ranges, a task that is encountered as a discretization step preceding induction and also embedded into learning algorithms. We are interested in finding the partition that optimizes the value of a given attribute evaluation function. For most commonly used evaluation functions this task takes quadratic time in the number of potential cut points in the numerical range. Hence, it is a potential bottleneck in data mining algorithms. We present two techniques that speed up the optimal multisplitting task. The first one aims at discarding cut point candidates in a quick linear-time preprocessing scan before embarking on the actual search. We generalize the definition of boundary points by Fayyad and Irani to allow us to merge adjacent example blocks that have the same relative class distribution. We prove for several commonly used evaluation functions that this processing removes only suboptimal cut points. Hence, the algorithm does not lose optimality. Our second technique tackles the quadratic-time dynamic programming algorithm, which is the best schema for optimizing many well-known evaluation functions. We present a technique that dynamically—i.e., during the search—prunes partitions of prefixes of the sorted data from the search space of the algorithm. The method works for all convex and cumulative evaluation functions. Together the use of these two techniques speeds up the multisplitting process considerably. Compared to the baseline dynamic programming algorithm the speed-up is around 50 percent on the average and up to 90 percent in some cases. We conclude that optimal multisplitting is fully feasible on all benchmark data sets we have encountered.",2004,Data Mining and Knowledge Discovery volume 8 issue 2 pp 97-126,convex function;discrete mathematics;data mining;machine learning;mathematical optimization;statistics;algorithm;computer science;mathematics;
Communication-Efficient Distributed Mining of Association Rules,Assaf Schuster (Technion – Israel Institute of Technology);Ran Wolff (Technion – Israel Institute of Technology);,"2135728993,2096432594","Mining for associations between items in large transactional databases is a central problem in the field of knowledge discovery. When the database is partitioned among several share-nothing machines, the problem can be addressed using distributed data mining algorithms. One such algorithm, called CD, was proposed by Agrawal and Shafer and was later enhanced by the FDM algorithm of Cheung, Han et al. The main problem with these algorithms is that they do not scale well with the number of partitions. They are thus impractical for use in modern distributed environments such as peer-to-peer systems, in which hundreds or thousands of computers may interact. In this paper we present a set of new algorithms that solve the Distributed Association Rule Mining problem using far less communication. In addition to being very efficient, the new algorithms are also extremely robust. Unlike existing algorithms, they continue to be efficient even when the data is skewed or the partition sizes are imbalanced. We present both experimental and theoretical results concerning the behavior of these algorithms and explain how they can be implemented in different settings.",2004,Data Mining and Knowledge Discovery volume 8 issue 2 pp 171-196,association rule learning;distributed algorithm;theoretical computer science;data mining;database;machine learning;computer science;
Ratio Selection for Classification Models,Roberto Kawakami Harrop Galvão (Instituto Tecnológico de Aeronáutica);Victor M. Becerra (University of Reading);Magda Abou-Seada (Middlesex University);,"2019157960,2151519952,1985041925","This paper is concerned with the selection of inputs for classification models based on ratios of measured quantities. For this purpose, all possible ratios are built from the quantities involved and variable selection techniques are used to choose a convenient subset of ratios. In this context, two selection techniques are proposed: one based on a pre-selection procedure and another based on a genetic algorithm. In an example involving the financial distress prediction of companies, the models obtained from ratios selected by the proposed techniques compare favorably to a model using ratios usually found in the financial distress literature.",2004,Data Mining and Knowledge Discovery volume 8 issue 2 pp 151-170,multivariate analysis;genetic algorithm;feature selection;linear discriminant analysis;econometrics;machine learning;statistics;computer science;
Efficient Mining of Frequent Patterns Using Ascending Frequency Ordered Prefix-Tree,Guimei Liu (Hong Kong University of Science and Technology);Hongjun Lu (Hong Kong University of Science and Technology);Wenwu Lou (Hong Kong University of Science and Technology);Yabo Xu (The Chinese University of Hong Kong);Jeffrey Xu Yu (The Chinese University of Hong Kong);,"2310117182,2131290459,2168899989,2697475474,2119358208","Mining frequent patterns, including mining frequent closed patterns or maximal patterns, is a fundamental and important problem in data mining area. Many algorithms adopt the pattern growth approach, which is shown to be superior to the candidate generate-and-test approach, especially when long patterns exist in the datasets. In this paper, we identify the key factors that influence the performance of the pattern growth approach, and optimize them to further improve the performance. Our algorithm uses a simple while compact data structure—ascending frequency ordered prefix-tree (AFOPT) to store the conditional databases, in which we use arrays to store single branches to further save space. The AFOPT structure is traversed in top-down depth-first order. Our analysis and experiment results show that the combination of the top-down traversal strategy and the ascending frequency order achieves significant performance improvement over previous works.",2004,Data Mining and Knowledge Discovery volume 9 issue 3 pp 249-274,association rule learning;top down and bottom up design;first order logic;data structure;data mining;database;machine learning;computer science;
Using Convex Sets for Exploratory Data Analysis and Visualization,Wojciech Grohman;,2706255140,"In this paper a new, abstract method for analysis and visualization of multidimensional data sets in pattern recognition problems is introduced. It can be used to determine the properties of an unknown, complex data set and to assist in finding the most appropriate recognition algorithm. Additionally, it can be employed to design layers of a feedforward artificial neural network or to visualize the higher-dimensional problems in 2-D and 3-D without losing relevant data set information. The method is derived from the convex set theory and works by considering convex subsets within the data and analyzing their respective positions in the original dimension. Its ability to describe certain set features that cannot be explicitly projected into lower dimensions sets it apart from many other visualization techniques. Two classical multidimensional problems are analyzed and the results show the usefulness of the presented method and underline its strengths and weaknesses.",2004,Data Mining and Knowledge Discovery volume 9 issue 3 pp 275-295,complex data type;convex set;exploratory data analysis;artificial neural network;theoretical computer science;data mining;machine learning;computer science;
Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach,Jiawei Han (University of Illinois at Urbana–Champaign);Jian Pei (University at Buffalo);Yiwen Yin (Simon Fraser University);Runying Mao (Microsoft);,"2121939561,2126330539,2169619881,2099591505","Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist a large number of patterns and/or long patterns. In this study, we propose a novel frequent-pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a condensed, smaller data structure, FP-tree which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern-fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent-pattern mining methods.",2004,Data Mining and Knowledge Discovery volume 8 issue 1 pp 53-87,tree structure;natural science;time series;data stream mining;data structure;data science;bioinformatics;data mining;computer science;
Tree Structures for Mining Association Rules,Frans Coenen (University of Liverpool);Graham Goulbourne (University of Liverpool);Paul H. Leng (University of Liverpool);,"1934644436,1984981405,2139721226","A well-known approach to Knowledge Discovery in Databases involves the identification of association rules linking database attributes. Extracting all possible association rules from a database, however, is a computationally intractable problem, because of the combinatorial explosion in the number of sets of attributes for which incidence-counts must be computed. Existing methods for dealing with this may involve multiple passes of the database, and tend still to cope badly with densely-packed database records. We describe here a class of methods we have introduced that begin by using a single database pass to perform a partial computation of the totals required, storing these in the form of a set enumeration tree, which is created in time linear to the size of the database. Algorithms for using this structure to complete the count summations are discussed, and a method is described, derived from the well-known Apriori algorithm. Results are presented demonstrating the performance advantage to be gained from the use of this approach. Finally, we discuss possible further applications of the method.",2004,Data Mining and Knowledge Discovery volume 8 issue 1 pp 25-51,database testing;apriori algorithm;database schema;database design;association rule learning;data science;data mining;database;machine learning;statistics;computer science;
Building an Association Rules Framework to Improve Product Assortment Decisions,Tom Brijs (University of Hasselt);Gilbert Swinnen (University of Hasselt);Koen Vanhoof (University of Hasselt);Geert Wets (University of Hasselt);,"2254849676,1976806762,2242613764,2088723926","It has been claimed that the discovery of association rules is well suited for applications of market basket analysis to reveal regularities in the purchase behaviour of customers. However today, one disadvantage of associations discovery is that there is no provision for taking into account the business value of an association. Therefore, recent work indicates that the discovery of interesting rules can in fact best be addressed within a microeconomic framework. This study integrates the discovery of frequent itemsets with a (microeconomic) model for product selection (PROFSET). The model enables the integration of both quantitative and qualitative (domain knowledge) criteria. Sales transaction data from a fully automated convenience store are used to demonstrate the effectiveness of the model against a heuristic for product selection based on product-specific profitability. We show that with the use of frequent itemsets we are able to identify the cross-sales potential of product items and use this information for better product selection. Furthermore, we demonstrate that the impact of product assortment decisions on overall assortment profitability can easily be evaluated by means of sensitivity analysis.",2004,Data Mining and Knowledge Discovery volume 8 issue 1 pp 7-23,association rule learning;data mining;computer science;
Comparing Latent Class Factor Analysis with Traditional Factor Analysis for Datamining,Jay Magidson (Tilburg University);Jeroen K. Vermunt (Tilburg University);,"2029439418,2126209104",-,2004,Data Mining and Knowledge Discovery,latent variable model;latent class model;factor analysis;machine learning;statistics;computer science;
Retrieval Using Texture Features in High Resolution Multi-spectral Satellite Imagery,Shawn Donald Newsam (Lawrence Livermore National Laboratory);Chandrika Kamath (Lawrence Livermore National Laboratory);,"2177731265,1978131604","Texture features have long been used in remote sensing applications to represent and retrieve image regions similar to a query region. Various representations of texture have been proposed based on the Fourier power spectrum, spatial co-occurrence, wavelets, Gabor filters, etc. These representations vary in their computational complexity and their suitability for representing different region types. Much of the work done thus far has focused on panchromatic imagery at low to moderate spatial resolutions, such as images from Landsat 1-7 which have a resolution of 15-30 m/pixel, and from SPOT 1-5 which have a resolution of 2.5-20 m/pixel. However, it is not clear which texture representation works best for the new classes of high resolution panchromatic (60-100 cm/pixel) and multi-spectral (4 bands for red, green, blue, and near infra-red at 2.4-4 m/pixel) imagery. It is also not clear how the different spectral bands should be combined. In this paper, we investigate the retrieval performance of several different texture representations using multi-spectral satellite images from IKONOS. A query-by-example framework, along with a manually chosen ground truth dataset, allows different combinations of texture representations and spectral bands to be compared. We focus on the specific problem of retrieving inhabited regions from images ofmore » urban and rural scenes. Preliminary results show that (1) the use of all spectral bands improves the retrieval performance, and (2) co-occurrence, wavelet and Gabor texture features perform comparably.« less",2004,Data Mining and Knowledge Discovery,texture filtering;image texture;image resolution;computer vision;computer science;
Self-adaptive parameters in genetic algorithms,Eric Pellerin;Luc Pigeon;Sylvain Delisle;,"2505431769,2661557939,2490222039",-,2004,Data Mining and Knowledge Discovery,meta optimization;quality control and genetic algorithms;population based incremental learning;fsa red algorithm;genetic representation;cultural algorithm;truncation selection;best first search;probabilistic analysis of algorithms;search algorithm;genetic algorithm;machine learning;computer science;
An evolutionary algorithmic approach to learning a Bayesian network from complete data,Ferat Sahin (Rochester Institute of Technology);Jason C. Tillett (Rochester Institute of Technology);Raghuveer M. Rao (Rochester Institute of Technology);T. Mohana Rao (Rochester Institute of Technology);,"2064835347,2294932067,2118955887,2161859607",-,2004,Data Mining and Knowledge Discovery,variable order bayesian network;wake sleep algorithm;bayesian network;particle swarm optimization;evolutionary algorithm;pattern recognition;machine learning;mathematical optimization;computer science;mathematics;
Bursty and Hierarchical Structure in Streams,Jon M. Kleinberg (Cornell University);,2261367123,"A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise—that the appearance of a topic in a document stream is signaled by a “burst of activity,” with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such “bursts,” in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitionss it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.",2003,Data Mining and Knowledge Discovery volume 7 issue 4 pp 373-397,data stream mining;text mining;data science;world wide web;data mining;machine learning;statistics;computer science;
On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration,"Eamonn J. Keogh (University of California, Riverside);Shruti Kasetty (University of California, Riverside);","2170070822,2307014398","In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of “improvement” that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details. To illustrate our point, we have undertaken the most exhaustive set of time series experiments ever attempted, re-implementing the contribution of more than two dozen papers, and testing them on 50 real world, highly diverse datasets. Our empirical results strongly support our assertion, and suggest the need for a set of time series benchmarks and more careful empirical evaluation in the data mining community.",2003,Data Mining and Knowledge Discovery volume 7 issue 4 pp 349-371,time series;data science;data mining;statistics;
Model-Based Clustering and Visualization of Navigation Patterns on a Web Site,"Igor V. Cadez (SPARTA, Inc.);David Heckerman (Microsoft);Christopher Meek (Microsoft);Padhraic Smyth (University of California, Irvine);Steven White (Microsoft);","1232485766,2021640924,2422299352,2137074633,2531653183","We present a new methodology for exploring and analyzing navigation patterns on a web site. The patterns that can be analyzed consist of sequences of URL categories traversed by users. In our approach, we first partition site users into clusters such that users with similar navigation paths through the site are placed into the same cluster. Then, for each cluster, we display these paths for users within that cluster. The clustering approach we employ is model-based (as opposed to distance-based) and partitions users according to the order in which they request web pages. In particular, we cluster users by learning a mixture of first-order Markov models using the Expectation-Maximization algorithm. The runtime of our algorithm scales linearly with the number of clusters and with the size of the datas and our implementation easily handles hundreds of thousands of user sessions in memory. In the paper, we describe the details of our method and a visualization tool based on it called WebCANVAS. We illustrate the use of our approach on user-traffic data from msnbc.com.",2003,Data Mining and Knowledge Discovery volume 7 issue 4 pp 399-424,web page;markov model;the internet;expectation maximization algorithm;first order logic;data visualization;data science;world wide web;data mining;machine learning;statistics;computer science;
Customer Lifetime Value Models for Decision Support,Saharon Rosset (Tel Aviv University);Einat Neumann (Tel Aviv University);Uri Eick;Nurit Vatnik;,"2129867074,2066963117,92296135,1175054095","We present and discuss the important business problem of estimating the effect of marketing activities on the Lifetime Value of a customer in the Telecommunications industry. We discuss the components of this problem, in particular customer value and length of service (or tenure) modeling, and present a novel segment-based approach, motivated by the segment-level view marketing analysts usually employ. We describe in detail how we build on this approach to estimate the effects of retention campaigns on Lifetime Value, and also discuss its application in other situations. Our solution has been successfully implemented by the Business Insight (BI) Professional Services.",2003,Data Mining and Knowledge Discovery volume 7 issue 3 pp 321-339,customer intelligence;customer advocacy;customer to customer;customer equity;business value;customer lifetime value;customer retention;marketing strategy;decision support system;
A Sequential Monte Carlo Method for Bayesian Analysis of Massive Datasets.,Greg Ridgeway (RAND Corporation);David Madigan (Rutgers University);,"1906399036,2232911153","Markov chain Monte Carlo (MCMC) techniques revolutionized statistical practice in the 1990s by providing an essential toolkit for making the rigor and flexibility of Bayesian analysis computationally practical. At the same time the increasing prevalence of massive datasets and the expansion of the field of data mining has created the need for statistically sound methods that scale to these large problems. Except for the most trivial examples, current MCMC methods require a complete scan of the dataset for each iteration eliminating their candidacy as feasible data mining techniques.",2003,Data Mining and Knowledge Discovery volume 7 issue 3 pp 301-319,data access;particle filter;importance sampling;proof of concept;markov chain monte carlo;mixture model;bayesian inference;posterior probability;bayesian probability;dynamical system;data science;data mining;machine learning;statistics;computer science;
DualMiner: A Dual-Pruning Algorithm for Itemsets with Constraints,Cristian Bucilă (Cornell University);Johannes Gehrke (Cornell University);Daniel Kifer (Cornell University);Walker White (University of Dallas);,"2324997465,2083845045,2049563562,2105825747","Recently, constraint-based mining of itemsets for questions like “find all frequent itemsets whose total price is at least d50” has attracted much attention. Two classes of constraints, monotone and antimonotone, have been very useful in this area. There exist algorithms that efficiently take advantage of either one of these two classes, but no previous algorithms can efficiently handle both types of constraints simultaneously. In this paper, we present DualMiner, the first algorithm that efficiently prunes its search space using both monotone and antimonotone constraints. We complement a theoretical analysis and proof of correctness of DualMiner with an experimental study that shows the efficacy of DualMiner compared to previous work.",2003,Data Mining and Knowledge Discovery volume 7 issue 3 pp 241-272,association rule learning;data mining;database;algorithm;computer science;mathematics;
Analysis of Pattern Discovery in Sequences Using a Bayes Error Framework,"Darya Chudova (University of California, Irvine);Padhraic Smyth (University of California, Irvine);","2065577647,2137074633","In this paper we investigate the general problem of discovering recurrent patterns that are embedded in categorical sequences. An important real-world problem of this nature is motif discovery in DNA sequences. There are a number of fundamental aspects of this data mining problem that can make discovery “easy” or “hard”—we characterize the difficulty of this problem using an analysis based on the Bayes error rate under a Markov assumption. The Bayes error framework demonstrates why certain patterns are much harder to discover than others. It also explains the role of different parameters such as pattern length and pattern frequency in sequential discovery. We demonstrate how the Bayes error can be used to calibrate existing discovery algorithms, providing a lower bound on achievable performance. We discuss a number of fundamental issues that characterize sequential pattern discovery in this context, present a variety of empirical results to complement and verify the theoretical analysis, and apply our methodology to real-world motif-discovery problems in computational biology.",2003,Data Mining and Knowledge Discovery volume 7 issue 3 pp 273-299,bayes error rate;word error rate;upper and lower bounds;dna sequencing;hidden markov model;bioinformatics;data mining;machine learning;statistics;computer science;
Extracting Share Frequent Itemsets with Infrequent Subsets,Brock Barber (University of Regina);Howard J. Hamilton (University of Regina);,"2191931192,2196958594","Itemset share has been proposed as an additional measure of the importance of itemsets in association rule mining (Carter et al., 1997). We compare the share and support measures to illustrate that the share measure can provide useful information about numerical values that are typically associated with transaction items, which the support measure cannot. We define the problem of finding share frequent itemsets, and show that share frequency does not have the property of downward closure when it is defined in terms of the itemset as a whole. We present algorithms that do not rely on the property of downward closure, and thus are able to find share frequent itemsets that have infrequent subsets. The algorithms use heuristic methods to generate candidate itemsets. They supplement the information contained in the set of frequent itemsets from a previous pass, with other information that is available at no additional processing cost. They count only those generated itemsets that are predicted to be frequent. The algorithms are applied to a large commercial database and their effectiveness is examined using principles of classifier evaluation from machine learning.",2003,Data Mining and Knowledge Discovery volume 7 issue 2 pp 153-185,association rule learning;data mining;database;pattern recognition;machine learning;computer science;
Building Decision Trees with Constraints,Minos N. Garofalakis (Bell Labs);Dongjoon Hyun (KAIST);Rajeev Rastogi (Bell Labs);Kyuseok Shim (Seoul National University);,"2089290244,2135244210,2651564987,2161168953","Classification is an important problem in data mining. Given a database of records, each with a class label, a classifier generates a concise and meaningful description for each class that can be used to classify subsequent records. A number of popular classifiers construct decision trees to generate class models. Frequently, however, the constructed trees are complex with hundreds of nodes and thus difficult to comprehend, a fact that calls into question an often-cited benefit that decision trees are easy to interpret. In this paper, we address the problem of constructing “simple” decision trees with few nodes that are easy for humans to interpret. By permitting users to specify constraints on tree size or accuracy, and then building the “best” tree that satisfies the constraints, we ensure that the final tree is both easy to understand and has good accuracy. We develop novel branch-and-bound algorithms for pushing the constraints into the building phase of classifiers, and pruning early tree nodes that cannot possibly satisfy the constraints. Our experimental results with real-life and synthetic data sets demonstrate that significant performance speedups and reductions in the number of nodes expanded can be achieved as a result of incorporating knowledge of the constraints into the building step as opposed to applying the constraints after the entire tree is built.",2003,Data Mining and Knowledge Discovery volume 7 issue 2 pp 187-214,incremental decision tree;grafting;branch and bound;constraint;synthetic data;decision tree learning;tree;decision tree;biological classification;satisfiability;data mining;machine learning;algorithm;computer science;mathematics;
Using Self-Similarity to Cluster Large Data Sets,Daniel Barbará (George Mason University);Ping Chen (University of Houston–Downtown);,"2144418927,2667957185","Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. In this paper, we present a new clustering algorithm, based in self-similarity properties of the data sets. Self-similarity is the property of being invariant with respect to the scale used to look at the data set. While fractals are self-similar at every scale used to look at them, many data sets exhibit self-similarity over a range of scales. Self-similarity can be measured using the fractal dimension. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same cluster have a great degree of self-similarity among them (and much less self-similarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with large data sets, high-dimensionality and noise and is capable of recognizing clusters of arbitrary shape.",2003,Data Mining and Knowledge Discovery volume 7 issue 2 pp 123-152,k medians clustering;flame clustering;canopy clustering algorithm;complete linkage clustering;determining the number of clusters in a data set;dbscan;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;fuzzy clustering;fractal dimension;clustering high dimensional data;self similarity;scalability;fractal analysis;cluster analysis;knowledge extraction;discrete mathematics;combinatorics;data mining;machine learning;computer science;mathematics;
Sampling and Subsampling for Cluster Analysis in Data Mining: With Applications to Sky Survey Data,"David M. Rocke (University of California, Davis);Jian J. Dai (University of California, Davis);","737792628,2096586808",This paper describes a clustering method for unsupervised classification of objects in large data sets. The new methodology combines the mixture likelihood approach with a sampling and subsampling strategy in order to cluster large data sets efficiently. This sampling strategy can be applied to a large variety of data mining methods to allow them to be used on very large data sets. The method is applied to the problem of automated star/galaxy classification for digital sky data and is tested using a sample from the Digitized Palomar Sky Survey (DPOSS) data. The method is quick and reliable and produces classifications comparable to previous work on these data using supervised clustering.,2003,Data Mining and Knowledge Discovery volume 7 issue 2 pp 215-232,k medians clustering;canopy clustering algorithm;clustering high dimensional data;cluster analysis;data science;data mining;pattern recognition;machine learning;computer science;
Free-Sets: A Condensed Representation of Boolean Data for the Approximation of Frequency Queries,Jean-François Boulicaut (Institut national des sciences Appliquées de Lyon);Artur Bykowski (Institut national des sciences Appliquées de Lyon);Christophe Rigotti (Institut national des sciences Appliquées de Lyon);,"1971530415,2078350171,2124275409","Given a large collection of transactions containing items, a basic common data mining problem is to extract the so-called frequent itemsets (i.e., sets of items appearing in at least a given number of transactions). In this paper, we propose a structure called free-sets, from which we can approximate any itemset support (i.e., the number of transactions containing the itemset) and we formalize this notion in the framework of e-adequate representations (H. Mannila and H. Toivonen, 1996. In Proc. of the Second International Conference on Knowledge Discovery and Data Mining (KDD'96), pp. 189–194). We show that frequent free-sets can be efficiently extracted using pruning strategies developed for frequent itemset discovery, and that they can be used to approximate the support of any frequent itemset. Experiments on real dense data sets show a significant reduction of the size of the output when compared with standard frequent itemset extraction. Furthermore, the experiments show that the extraction of frequent free-sets is still possible when the extraction of frequent itemsets becomes intractable, and that the supports of the frequent free-sets can be used to approximate very closely the supports of the frequent itemsets. Finally, we consider the effect of this approximation on association rules (a popular kind of patterns that can be derived from frequent itemsets) and show that the corresponding errors remain very low in practice.",2003,Data Mining and Knowledge Discovery volume 7 issue 1 pp 5-22,association rule learning;data science;data mining;database;computer science;mathematics;
A Taxonomy of Dirty Data,Won Y. Kim;Byoung-Ju Choi (Ewha Womans University);Eui Kyeong Hong (Seoul National University);Soo-Kyung Kim (Alcatel-Lucent);Doheon Lee (KAIST);,"2649713922,2128219450,2568755645,2503142364,2151057430","Today large corporations are constructing enterprise data warehouses from disparate data sources in order to run enterprise-wide data analysis applications, including decision support systems, multidimensional online analytical applications, data mining, and customer relationship management systems. A major problem that is only beginning to be recognized is that the data in data sources are often “dirty”. Broadly, dirty data include missing data, wrong data, and non-standard representations of the same data. The results of analyzing a database/data warehouse of dirty data can be damaging and at best be unreliable. In this paper, a comprehensive classification of dirty data is developed for use as a framework for understanding how dirty data arise, manifest themselves, and may be cleansed to ensure proper construction of data warehouses and accurate data analysis. The impact of dirty data on data mining is also explored.",2003,Data Mining and Knowledge Discovery volume 7 issue 1 pp 81-99,data virtualization;dirty data;data cleansing;data pre processing;data retrieval;data quality;missing data;data analysis;data stream mining;data warehouse;data science;data mining;database;computer science;
XTRACT: Learning Document Type Descriptors from XML Document Collections,Minos N. Garofalakis (Bell Labs);Aristides Gionis (Stanford University);Rajeev Rastogi (Bell Labs);S. Seshadri (Strand Bookstore);Kyuseok Shim (Southern Nazarene University);,"2089290244,2593877498,2651564987,2113997329,2161168953","XML is rapidly emerging as the new standard for data representation and exchange on the Web. Unlike HTML, tags in XML documents describe the semantics of the data and not how it is to be displayed. In addition, an XML document can be accompanied by a Document Type Descriptor (DTD) which plays the role of a schema for an XML data collection. DTDs contain valuable information on the structure of documents and thus have a crucial role in the efficient storage of XML data, as well as the effective formulation and optimization of XML queries. Despite their importance, however, DTDs are not mandatory, and it is frequently possible that documents in XML databases will not have accompanying DTDs. In this paper, we propose XTRACT, a novel system for inferring a DTD schema for a database of XML documents. Since the DTD syntax incorporates the full expressive power of regular expressions, naive approaches typically fail to produce concise and intuitive DTDs. Instead, the XTRACT inference algorithms employ a sequence of sophisticated steps that involve: (1) finding patterns in the input sequences and replacing them with regular expressions to generate “general” candidate DTDs, (2) factoring candidate DTDs using adaptations of algorithms from the logic optimization literature, and (3) applying the Minimum Description Length (MDL) principle to find the best DTD among the candidates. The results of our experiments with real-life and synthetic DTDs demonstrate the effectiveness of XTRACT's approach in inferring concise and semantically meaningful DTD schemas for XML databases.",2003,Data Mining and Knowledge Discovery volume 7 issue 1 pp 23-56,xml schema editor;document definition markup language;xml schema;xml catalog;well formed document;relax ng;xml validation;efficient xml interchange;xml framework;xml encryption;streaming xml;xml signature;simple api for xml;sgml;document type definition;xml database;document structure description;xml schema;xml;regular expression;information retrieval;data mining;database;computer science;
Data Squashing by Empirical Likelihood,Art B. Owen (Stanford University);,2562039803,"Data squashing was introduced by W. DuMouchel, C. Volinsky, T. Johnson, C. Cortes, and D. Pregibon, in Proceedings of the 5th International Conference on KDD (1999). The idea is to scale data sets down to smaller representative samples instead of scaling up algorithms to very large data sets. They report success in learning model coefficients on squashed data. This paper presents a form of data squashing based on empirical likelihood. This method reweights a random sample of data to match certain expected values to the population. The computation required is a relatively easy convex optimization. There is also a theoretical basis to predict when it will and won't produce large gains. In a credit scoring example, empirical likelihood weighting also accelerates the rate at which coefficients are learned. We also investigate the extent to which these benefits translate into improved accuracy, and consider reweighting in conjunction with boosted decision trees.",2003,Data Mining and Knowledge Discovery volume 7 issue 1 pp 101-113,decision tree;expected value;sampling;convex optimization;econometrics;data mining;machine learning;statistics;computer science;
Lifetime Value Models for Decision Support,Saharon Rosset (Tel Aviv University);Eric P. Neumann;Uri Eick;Nurit Vatnik;,"2129867074,2702616193,92296135,1175054095",-,2003,Data Mining and Knowledge Discovery,optimal decision;evidential reasoning approach;value of information;decision tree;decision analysis;data mining;computer science;
Cluster Detection in Databases: The Adaptive Matched Filter Algorithm and Implementation,Jeremy Kepner (Princeton University);Rita Kim (Princeton University);,"2136907378,2602781276","Matched filter techniques are a staple of modern signal and image processing. They provide a firm foundation (both theoretical and empirical) for detecting and classifying patterns in statistically described backgrounds. Application of these methods to databases has become increasingly common in certain fields (e.g. astronomy). This paper describes an algorithm (based on statistical signal processing methods), a software architecture (based on a hybrid layered approach) and a parallelization scheme (based on a client/server model) for finding clusters in large astronomical databases. The method has proved successful in identifying clusters in real and simulated data. The implementation is flexible and readily executed in parallel on a network of workstations.",2003,Data Mining and Knowledge Discovery volume 7 issue 1 pp 57-79,galaxy cluster;client server model;software architecture;statistical signal processing;matched filter;filter;parallel processing;theoretical computer science;distributed computing;data mining;database;computer science;
Discretization: An Enabling Technique,Huan Liu (National University of Singapore);Farhad Hussain (National University of Singapore);Chew Lim Tan (National University of Singapore);Manoranjan Dash (National University of Singapore);,"2122391114,2135070175,2125676828,2630917039","Discrete values have important roles in data mining and knowledge discovery. They are about intervals of numbers which are more concise to represent and specify, easier to use and comprehend as they are closer to a knowledge-level representation than continuous values. Many studies show induction tasks can benefit from discretization: rules with discrete values are normally shorter and more understandable and discretization can lead to improved predictive accuracy. Furthermore, many induction algorithms found in the literature require discrete features. All these prompt researchers and practitioners to discretize continuous features before or during a machine learning or data mining task. There are numerous discretization methods available in the literature. It is time for us to examine these seemingly different methods for discretization and find out how different they really are, what are the key components of a discretization process, how we can improve the current level of research for new development as well as the use of existing methods. This paper aims at a systematic study of discretization methods with their history of development, effect on classification, and trade-off between speed and accuracy. Contributions of this paper are an abstract description summarizing existing discretization methods, a hierarchical framework to categorize the existing methods and pave the way for further development, concise discussions of representative discretization methods, extensive experiments and their analysis, and some guidelines as to how to choose a discretization method under various circumstances. We also identify some issues yet to solve and future research for discretization.",2002,Data Mining and Knowledge Discovery volume 6 issue 4 pp 393-423,discretization of continuous features;discretization;biological classification;knowledge extraction;data science;data mining;machine learning;statistics;computer science;
Techniques of Cluster Algorithms in Data Mining,Johannes Grabmeier (University of Applied Sciences Deggendorf);Andreas Rudolph;,"2305304627,2638383674","An overview of cluster analysis techniques from a data mining point of view is given. This is done by a strict separation of the questions of various similarity and distance measures and related optimization criteria for clusterings from the methods to create and modify clusterings themselves. In addition to this general setting and overview, the second focus is used on discussions of the essential ingredients of the i>demographic cluster algorithm of IBM's Intelligent Miner, based i>Condorcet's criterion.",2002,Data Mining and Knowledge Discovery volume 6 issue 4 pp 303-360,cluster analysis;data science;data mining;machine learning;statistics;computer science;mathematics;
High-Performance Commercial Data Mining: A Multistrategy Machine Learning Application,William H. Hsu (Kansas State University);Michael Welge (National Center for Supercomputing Applications);Thomas Redman (National Center for Supercomputing Applications);David Clutter (National Center for Supercomputing Applications);,"2170645087,110373202,2570675700,2502804311","We present an application of inductive concept learning and interactive visualization techniques to a large-scale commercial data mining project. This paper focuses on design and configuration of high-level optimization systems (wrappers) for relevance determination and constructive induction, and on integrating these wrappers with elicited knowledge on attribute relevance and synthesis. In particular, we discuss decision support issues for the application (cost prediction for automobile insurance markets in several states) and report experiments using i>D2K, a Java-based visual programming system for data mining and information visualization, and several commercial and research tools. We describe exploratory clustering, descriptive statistics, and supervised decision tree learning in this application, focusing on a parallel genetic algorithm (GA) system, i>Jenesis, which is used to implement relevance determination (attribute subset selection). Deployed on several high-performance network-of-workstation systems (Beowulf clusters), i>Jenesis achieves a linear speedup, due to a high degree of task parallelism. Its test set accuracy is significantly higher than that of decision tree inducers alone and is comparable to that of the best extant search-space based wrappers.",2002,Data Mining and Knowledge Discovery volume 6 issue 4 pp 361-391,genetic algorithm;information visualization;interactive visualization;concept learning;data science;data mining;machine learning;computer science;
Support Vector Machines and the Bayes Rule in Classification,Yi Lin (University of Wisconsin-Madison);,2209437142,"The Bayes rule is the optimal classification rule if the underlying distribution of the data is known. In practice we do not know the underlying distribution, and need to “learn” classification rules from the data. One way to derive classification rules in practice is to implement the Bayes rule approximately by estimating an appropriate classification function. Traditional statistical methods use estimated log odds ratio as the classification function. Support vector machines (SVMs) are one type of large margin classifier, and the relationship between SVMs and the Bayes rule was not clear. In this paper, it is shown that the asymptotic target of SVMs are some interesting classification functions that are directly related to the Bayes rule. The rate of convergence of the solutions of SVMs to their corresponding target functions is explicitly established in the case of SVMs with quadratic or higher order loss functions and spline kernels. Simulations are given to illustrate the relation between SVMs and the Bayes rule in other cases. This helps understand the success of SVMs in many classification studies, and makes it easier to compare SVMs and traditional statistical methods.",2002,Data Mining and Knowledge Discovery volume 6 issue 3 pp 259-275,classification rule;bayes error rate;reproducing kernel hilbert space;bayes classifier;odds ratio;support vector machine;bayes theorem;rate of convergence;loss function;higher order logic;biological classification;data mining;pattern recognition;machine learning;statistics;computer science;mathematics;
Cubegrades: Generalizing Association Rules,Tomasz Imieliński (Rutgers University);Leonid Khachiyan (Rutgers University);Amin Abdulghani (Rutgers University);,"152915441,381257149,2345889923","Cubegrades are a generalization of association rules which represent how a set of measures (aggregates) is affected by modifying a cube through specialization (rolldown), generalization (rollup) and mutation (which is a change in one of the cube's dimensions). Cubegrades are significantly more expressive than association rules in capturing trends and patterns in data because they can use other standard aggregate measures, in addition to COUNT. Cubegrades are atoms which can support sophisticated “what if” analysis tasks dealing with behavior of arbitrary aggregates over different database segments. As such, cubegrades can be useful in marketing, sales analysis, and other typical data mining applications in business. In this paper we introduce the concept of cubegrades. We define them and give examples of their usage. We then describe in detail an important task for computing cubegrades: generation of significant cubes which is analogous to generating frequent sets. A novel Grid Based Pruning (GBP) method is employed for this purpose. We experimentally demonstrate the practicality of the method. We conclude with a number of open questions and possible extensions of the work.",2002,Data Mining and Knowledge Discovery volume 6 issue 3 pp 219-257,association rule learning;data science;data mining;database;machine learning;computer science;
Automated Remote Sensing with Near Infrared Reflectance Spectra: Carbonate Recognition,Joseph Ramsey (Carnegie Mellon University);Paul Gazis (Ames Research Center);Ted Roush (Ames Research Center);Peter Spirtes (Carnegie Mellon University);Clark Glymour (Carnegie Mellon University);,"2113768324,2599429269,2087805540,2264677196,2035346540","Reflectance spectroscopy is a standard tool for studying the mineral composition of rock and soil samples and for remote sensing of terrestrial and extraterrestrial surfaces. We describe research on automated methods of mineral identification from reflectance spectra and give evidence that a simple algorithm, adapted from a well-known search procedure for Bayes nets, identifies the most frequently occurring classes of carbonates with reliability equal to or greater than that of human experts. We compare the reliability of the procedure to the reliability of several other automated methods adapted to the same purpose. Evidence is given that the procedure can be applied to some other mineral classes as well. Since the procedure is fast with low memory requirements, it is suitable for on-board scientific analysis by orbiters or surface rovers.",2002,Data Mining and Knowledge Discovery volume 6 issue 3 pp 277-293,tetrad;mars exploration program;computer science;
Advances in Instance Selection for Instance-Based Learning Algorithms,Henry Brighton (University of Edinburgh);Chris Mellish (University of Edinburgh);,"2150498994,2109201565","The basic nearest neighbour classifier suffers from the indiscriminate storage of all presented training instances. With a large database of instances classification response time can be slow. When noisy instances are present classification accuracy can suffer. Drawing on the large body of relevant work carried out in the past 30 years, we review the principle approaches to solving these problems. By deleting instances, both problems can be alleviated, but the criterion used is typically assumed to be all encompassing and effective over many domains. We argue against this position and introduce an algorithm that rivals the most successful existing algorithm. When evaluated on 30 different problems, neither algorithm consistently outperforms the other: consistency is very hard. To achieve the best results, we need to develop mechanisms that provide insights into the structure of class definitions. We discuss the possibility of these mechanisms and propose some initial measures that could be useful for the data miner.",2002,Data Mining and Knowledge Discovery volume 6 issue 2 pp 153-172,forgetting;pruning;instance based learning;data mining;artificial intelligence;machine learning;statistics;computer science;
On Issues of Instance Selection,Huan Liu (Arizona State University);Hiroshi Motoda (Osaka University);,"2122391114,323689644","The digital technologies and computer advances with the booming internet uses have ledto massive data collection (corporate data, data warehouses, webs, just to name a few) andinformation (or misinformation) explosion. Szalay and Gray described this phenomenon as“drowning in data” (Szalay and Gray, 1999). They reported that each year the detectors attheCERNparticlecolliderinSwitzerlandrecord1petabyteofdata;andresearchersinareasof science from astronomy to the human genome are facing the same problems and chokingon information. A very natural question is “now that we have gathered so much data, whatdo we do with it?” Raw data is rarely of direct use and manual analysis simply cannotkeep pace with the fast growth of data. Data mining and knowledge discovery (KDD), as anew emerging ﬁeld comprising disciplines such as databases, statistics, machine learning,comes to the rescue. KDD attempts to turn raw data into nuggets and create special edgesin this ever competitive world for science discovery and business intelligence.TheKDDprocessisdeﬁnedinFayyadetal.(1996)as",2002,Data Mining and Knowledge Discovery volume 6 issue 2 pp 115-130,data science;world wide web;data mining;machine learning;computer science;
Adaptive Sampling Methods for Scaling Up Knowledge Discovery Algorithms,Carlos Domingo (Tokyo Institute of Technology);Ricard Gavalda (LSI Corporation);Osamu Watanabe (Tokyo Institute of Technology);,"2313237686,2253347400,2135939770","Scalability is a key requirement for any KDD and data mining algorithm, and one of the biggest research challenges is to develop methods that allow to use large amounts of data. One possible approach for dealing with huge amounts of data is to take a random sample and do data mining on it, since for many data mining applications approximate answers are acceptable. However, as argued by several researchers, random sampling is difficult to use due to the difficulty of determining an appropriate sample size. In this paper, we take a sequential sampling approach for solving this difficulty, and propose an adaptive sampling method that solves a general problem covering many actual problems arising in applications of discovery science. An algorithm following this method obtains examples sequentially in an on-line fashion, and it determines from the obtained examples whether it has already seen a large enough number of examples. Thus, sample size is not fixed a prioris instead, it i>adaptively depends on the situation. Due to this adaptiveness, if we are not in a worst case situation as fortunately happens in many practical applications, then we can solve the problem with a number of examples much smaller than required in the worst case. We prove the correctness of our method and estimates its efficiency theoretically. For illustrating its usefulness, we consider one concrete task requiring sampling, provide an algorithm based on our method, and show its efficiency experimentally.",2002,Data Mining and Knowledge Discovery volume 6 issue 2 pp 131-152,sequential analysis;scalability;sample size determination;sampling;data stream mining;knowledge extraction;data mining;machine learning;statistics;computer science;mathematics;
A Unifying View on Instance Selection,Thomas Reinartz (Daimler AG);,377513221,"In this paper, we consider instance selection as an important focusing task in the data preparation phase of knowledge discovery and data mining. Focusing generally covers all issues related to data reduction. First of all, we define a broader perspective on focusing tasks, choose instance selection as one particular focusing task, and outline the specification of concrete evaluation criteria to measure success of instance selection approaches. Thereafter, we present a unifying framework that covers existing approaches towards solutions for instance selection as instantiations. We describe specific examples of instantiations of this framework and discuss their strengths and weaknesses. Then, we outline an enhanced framework for instance selection, generic sampling, and summarize example evaluation results for several different instantiations of its implementation. Finally, we conclude with open issues and research challenges for instance selection as well as focusing in general.",2002,Data Mining and Knowledge Discovery volume 6 issue 2 pp 191-210,data reduction;sampling;data science;data mining;machine learning;statistics;computer science;
Likelihood-Based Data Squashing: A Modeling Approach to Instance Construction,David Madigan (Rutgers University);Nandini Raghavan (AT&T Labs);William Dumouchel (AT&T Labs);Martha Nason (University of Washington);Christian Posse;Greg Ridgeway (University of Washington);,"2232911153,2250291617,2272274628,2169072269,2498243315,1906399036","Squashing is a lossy data compression technique that preserves statistical information. Specifically, squashing compresses a massive dataset to a much smaller one so that outputs from statistical analyses carried out on the smaller (squashed) dataset reproduce outputs from the same statistical analyses carried out on the original dataset. Likelihood-based data squashing (LDS) differs from a previously published squashing algorithm insofar as it uses a statistical model to squash the data. The results show that LDS provides excellent squashing performance even when the target statistical analysis departs from the model used to squash the data.",2002,Data Mining and Knowledge Discovery volume 6 issue 2 pp 173-190,data compression;statistical model;data science;data mining;machine learning;statistics;computer science;
Discovery and Evaluation of Aggregate Usage Profiles for Web Personalization,Bamshad Mobasher (DePaul University);Honghua Dai (DePaul University);Tao Luo (DePaul University);Miki Nakagawa (DePaul University);,"1892801027,2304617503,2304850263,2077851658","Web usage mining, possibly used in conjunction with standard approaches to personalization such as collaborative filtering, can help address some of the shortcomings of these techniques, including reliance on subjective user ratings, lack of scalability, and poor performance in the face of high-dimensional and sparse data. However, the discovery of patterns from usage data by itself is not sufficient for performing the personalization tasks. The critical step is the effective derivation of good quality and useful (i.e., actionable) “aggregate usage profiles” from these patterns. In this paper we present and experimentally evaluate two techniques, based on clustering of user transactions and clustering of pageviews, in order to discover overlapping aggregate profiles that can be effectively used by recommender systems for real-time Web personalization. We evaluate these techniques both in terms of the quality of the individual profiles generated, as well as in the context of providing recommendations as an integrated part of a personalization engine. In particular, our results indicate that using the generated aggregate profiles, we can achieve effective personalization at early stages of users' visits to a site, based only on anonymous clickstream data and without the benefit of explicit input by these users or deeper knowledge about them.",2002,Data Mining and Knowledge Discovery volume 6 issue 1 pp 61-82,personalization;recommender system;world wide web;data mining;database;machine learning;computer science;
Discovery of Web Robot Sessions Based on their Navigational Patterns,Pang Ning Tan (University of Minnesota);Vipin Kumar (University of Minnesota);,"2113230973,2161062602","Web robots are software programs that automatically traverse the hyperlink structure of the World Wide Web in order to locate and retrieve information. There are many reasons why it is important to identify visits by Web robots and distinguish them from other users. First of all, e-commerce retailers are particularly concerned about the unauthorized deployment of robots for gathering business intelligence at their Web sites. In addition, Web robots tend to consume considerable network bandwidth at the expense of other users. Sessions due to Web robots also make it more difficult to perform clickstream analysis effectively on the Web data. Conventional techniques for detecting Web robots are often based on identifying the IP address and user agent of the Web clients. While these techniques are applicable to many well-known robots, they may not be sufficient to detect camouflaged and previously unknown robots. In this paper, we propose an alternative approach that uses the navigational patterns in the click-stream data to determine if it is due to a robot. Experimental results on our Computer Science department Web server logs show that highly accurate classification models can be built using this approach. We also show that these models are able to discover many camouflaged and previously unidentified robots.",2002,Data Mining and Knowledge Discovery volume 6 issue 1 pp 9-35,web 2 0;web modeling;robots exclusion standard;social semantic web;web analytics;data web;web accessibility initiative;web mapping;web application security;web development;user agent;web design;web navigation;web server;web service;biological classification;web intelligence;web mining;business intelligence;world wide web;data mining;simulation;computer science;
Efficient Adaptive-Support Association Rule Mining for Recommender Systems,Weiyang Lin (Microsoft);Sergio A. Alvarez (Boston College);Carolina Ruiz (Worcester Polytechnic Institute);,"2277644620,2170320455,2149401507","Collaborative recommender systems allow personalization for e-commerce by exploiting similarities and dissimilarities among customers' preferences. We investigate the use of association rule mining as an underlying technology for collaborative recommender systems. Association rules have been used with success in other domains. However, most currently existing association rule mining algorithms were designed with market basket analysis in mind. Such algorithms are inefficient for collaborative recommendation because they mine many rules that are not relevant to a given user. Also, it is necessary to specify the minimum support of the mined rules in advance, often leading to either too many or too few ruless this negatively impacts the performance of the overall system. We describe a collaborative recommendation technique based on a new algorithm specifically designed to mine association rules for this purpose. Our algorithm does not require the minimum support to be specified in advance. Rather, a target range is given for the number of rules, and the algorithm adjusts the minimum support for each user in order to obtain a ruleset whose size is in the desired range. Rules are mined for a specific target user, reducing the time required for the mining process. We employ associations between users as well as associations between items in making recommendations. Experimental evaluation of a system based on our algorithm reveals performance that is significantly better than that of traditional correlation-based approaches.",2002,Data Mining and Knowledge Discovery volume 6 issue 1 pp 83-105,association rule learning;recommender system;data science;world wide web;data mining;machine learning;computer science;
Web Mining,Ron Kohavi (Blue Martini Software);Brij Masand (Burlington Coat Factory);Myra Spiliopoulou (Graduate School of Management);Jaideep Srivastava (University of Minnesota);,"73615348,201836202,2672394148,2192802387",-,2002,Data Mining and Knowledge Discovery,data web;web intelligence;web mining;
Rough sets perspective on data and knowledge,Andrzej Skowron (University of Warsaw);Jan Komorowski (Norwegian University of Science and Technology);Zdzislaw Pawlak (Polish Academy of Sciences);Lech Polkowski (Institute of Mathematics);,"565168613,2569553810,702337841,2591293023","Rough set theory was proposed by Zdzislaw Pawlak (1982, 1991) in the early 1980s. Since then we have witnessed a systematic, worldwide growth of interest in rough set theory and its applications. The rough set approach has been introduced to deal with vague or imprecise concepts, to derive knowledge from data, and to reason about knowledge derived from data. In the first part of this chapter we outline the basic notions of rough sets, especially those that are related to knowledge extraction from data. Searching for knowledge is usually guided by some constraints (Langley et al., 1987). A wide class of such constraints can be expressed by discernibility of objects. Knowledge derived from data by the rough set approach consists of different constructs. Among them there are reducts, which are the central construct in the rough set approach, different kinds of rules (such as decision rules or association rules), dependencies, and patterns (templates), or classifiers. The reducts are of special importance since all other constructs can be derived from different kinds of reducts using the rough set approach. Strategies for searching reducts apply Boolean (propositional) reasoning (Brown, 1990), since the constraints (e.g., constraints related to the discernibility of objects) are expressible by propositional formulas. Moreover, using Boolean reasoning, minimal description-length data models (Mitchell, 1997; Rissanen, 1978) can be induced since they correspond to constructs of Boolean functions called prime implicants (or their approximations). The second part of this chapter includes illustrative examples of applications of this general scheme to inducing from data various forms of knowledge.",2002,Data Mining and Knowledge Discovery pp 134-149,rough set;dominance based rough set approach;discrete mathematics;data mining;machine learning;algorithm;computer science;mathematics;
"Using Site Semantics to Analyze, Visualize, and Support Navigation",Bettina Berendt (Humboldt University of Berlin);,2683720132,"To satisfy potential customers of a Web site and to lead them to the goods offered by the site, one should support them in the course of navigation they have embarked on. This paper presents the tool STRATDYN, developed as an add-on module to the Web Usage Miner WUM. WUM not only discovers frequent sequences, but it also allows the inspection of the different paths through the site. STRATDYN extends these capabilities: It tests differences between navigation patterns, described by a number of measures of success and strategy, for statistical significance. This can help to single out the relevant differences between users' behaviors, and it can determine whether a change in the site's design has had the desired effect. STRATDYN also exploits the site's semantics in the classification of navigation behavior and in the visualization of results, displaying navigation patterns as alternative paths through a strategy space. This helps to understand the Web logs, and to communicate analysis results to non-experts. Two case studies investigate search in an online catalog and interaction with an electronic shopping agent in an online store. They show how the results of analysis can lead to proposals for improving a Web site. These highlight the importance of investigating measures not only of eventual success, but also of process, to help users navigate towards the site's offers.",2002,Data Mining and Knowledge Discovery volume 6 issue 1 pp 37-59,web modeling;sequential pattern mining;visualization;statistical significance;satisfiability;web mining;world wide web;data mining;simulation;computer science;
Data mining and decision making,Andrew Kusiak (University of Iowa);,2038827167,-,2002,Data Mining and Knowledge Discovery,temporal database;data transformation;decision tree learning;concept mining;learning classifier system;data stream mining;text mining;data science;data mining;pattern recognition;statistics;computer science;
Data reduction: feature selection,Hiroshi Motoda (Osaka University);Huan Liu (Arizona State University);,"323689644,2122391114","Feature selection is introduced as a search problem that consists of feature subset generation, evaluation, and selection. The purpose of feature selection is three-fold: reducing the number of features, improving classification accuracy, and simplifying the learned representation. We review major evaluation measures and various feature selection approaches, list some existing methods, and show by example the role of feature selection in data mining.",2002,Data Mining and Knowledge Discovery pp 208-213,minimum redundancy feature selection;dimensionality reduction;data reduction;feature;feature extraction;feature selection;data mining;pattern recognition;machine learning;computer science;
Data visualization for domain exploration,Graham J. Wills (Bell Labs);Daniel A. Keim (University of Konstanz);,"2167012557,2147343253",-,2002,Data Mining and Knowledge Discovery,biological data visualization;geovisualization;information visualization;visual analytics;data visualization;statistics;computer science;
One-to-One Modeling and Simulation: A New Approach in Customer Relationship Management for Grocery Retail,Cem M. Baydar (Accenture);,2513832374,-,2002,Data Mining and Knowledge Discovery,enterprise relationship management;customer intelligence;customer advocacy;voice of the customer;customer equity;customer lifetime value;customer retention;loyalty business model;customer satisfaction;service quality;profitability index;conceptual framework;satisfiability;monte carlo method;relationship marketing;modeling and simulation;computer science;
Industry: using decision tree induction to minimize process delays in the printing industry,Robert B. Evans;Douglas Fisher (Vanderbilt University);,"2522026528,2337660473","Rotogravure printing involves rotating a chrome-plated, engraved copper cylinder in a bath of ink, scraping off the excess ink, and pressing a continuous supply of paper against the engraved cylinder with a rubber roller, thus transferring ink from the engraved image of the cylinder to the paper. The printing process is subject to many types of delays, one of which is cylinder banding. During the course of printing, grooves may become engraved into a cylinder surface. These grooves cause streaks or bands to be printed on the paper, thus ruining the final product. This article describes the application of decision tree induction to identify the conditions under which banding did and did not occur at the Gallatin, Tennessee plant of R. R. Donnelley and Sons, Once found, discovered rules were used to bias printing press parameters toward conditions identified as favorable. This approach has been primarily responsible for reducing bands from 538 in 1989 to 26 in 1998. This article describes the technical and social issues addressed in the banding application.",2002,Data Mining and Knowledge Discovery pp 874-881,computer science;
Processing Landsat TM data using complex valued neural networks,Howard E. Michel (University of Massachusetts Dartmouth);Shyamala Kunjithapatham (University of Massachusetts Dartmouth);,"2119271617,1999298322",-,2002,Data Mining and Knowledge Discovery,artificial neural network;computer vision;machine learning;computer science;
Knowledge Discovery in Grammatically Analysed Corpora,"Sean Wallis (Department of English, University of Dhaka);Gerald Nelson (University College London);","2098829520,2172579157","Collections of grammatically annotated texts (corpora), and in particular, i>parsed corpora, present a challenge to current methods of analysis. Such corpora are large and highly structured heterogeneous data sources. In this paper we briefly describe the parsed one-million word ICE-GB corpus, and the ICECUP query system. We then consider the application of i>knowledge discovery in databases (KDD) to text corpora. Following Cupit and Shadbolt (Proceedings 9th European Knowledge Acquisition Workshop, EKAW '96s Berlin: Springer Verlag, pp. 245–261, 1996), we argue that effective linguistic knowledge discovery must be based on a process of i>redescription or, more precisely, i>abstraction, based on the research question to be investigated. Abstraction maps relevant elements from the corpus to an abstract model of the research topic. This mapping may be implemented using a grammatical query representation such as ICECUP's i>Fuzzy Tree Fragments (FTFs). Since this abstractive process must be both experimental and expert-guided, ultimately a workbench is necessary to maintain, evaluate and refine the abstract model. We conclude with a pilot study, employing our approach, into aspects of noun phrase postmodifying clause structure. The data is analysed using the UNIT machine learning algorithm to search for significant interactions between domain variables. We show that our results are commensurable with those published in the linguistics literature, and discuss how the methodology may be improved.",2001,Data Mining and Knowledge Discovery volume 5 issue 4 pp 305-335,noun phrase;grammar;technology;knowledge;knowledge extraction;data science;natural language processing;data mining;machine learning;computer science;
iDiff: Informative Summarization of Differences in Multidimensional Aggregates,Sunita Sarawagi (Indian Institute of Technology Bombay);,156875573,"Multidimensional OLAP products provide an excellent opportunity for integrating mining functionality because of their widespread acceptance as a decision support tool and their existing heavy reliance on manual, user-driven analysis. Most OLAP products are rather simplistic and rely heavily on the user's intuition to manually drive the discovery process. Such ad hoc user-driven exploration gets tedious and error-prone as data dimensionality and size increases. Our goal is to automate these manual discovery processes. In this paper we present an example of such automation through a iDiff operator that in a single step returns summarized reasons for drops or increases observed at an aggregated level. We formulate this as a problem of summarizing the difference between two multidimensional arrays of real numbers. We develop a general framework for such summarization and propose a specific formulation for the case of OLAP aggregates. We develop an information theoretic formulation for expressing the reasons that is compact and easy to interpret. We design an efficient dynamic programming algorithm that requires only one pass of the data and uses a small amount of memory independent of the data size. This allows easy integration with existing OLAP products. Our prototype has been tested on the Microsoft OLAP server, DB2/UDB and Oracle 8i. Experiments using the OLAP benchmark demonstrate (1) scalability of our algorithm as the size and dimensionality of the cube increases and (2) feasibility of getting interactive answers with modest hardware resources.",2001,Data Mining and Knowledge Discovery volume 5 issue 4 pp 255-276,online analytical processing;data science;data mining;database;computer science;
Extensible Parallel Query Processing for Exploratory Geoscientific Data Mining,"Eddie C. Shek (HRL Laboratories);Richard R. Muntz (University of California, Los Angeles);Edmond Mesrobian (University of California, Los Angeles);","2306523563,2033368653,2208744254","Exploratory data mining and analysis requires a computing environment which provides facilities for the user-friendly expression and rapid execution of “scientific queries.” In this paper, we address research issues in the parallelization of scientific queries containing complex user-defined operations. In a parallel query execution environment, parallelizing a query execution plan involves determining how input data streams to evaluators implementing logical operations can be divided to be processed by clones of the same evaluator in parallel. We introduced the concept of “relevance window” that characterizes data lineage and data partitioning opportunities available for an user-defined evaluator. In addition, we developed a query parallelization framework by extending relational parallel query optimization algorithms to allow the parallelization characteristics of user-defined evaluators to guide the process of query parallelization in an extensible query processing environment. We demonstrated the utility of our system by performing experiments mining cyclonic activity, blocking events, and the upward wave-energy propagation features from several observational and model simulation datasets.",2001,Data Mining and Knowledge Discovery volume 5 issue 4 pp 277-304,sargable;web search query;web query classification;cyclone;query by example;query expansion;query optimization;query language;automatic parallelization;theoretical computer science;data mining;database;computer science;
Deterministic Generative Models for Fast Feature Discovery,Machiel Westerdijk (Radboud University Nijmegen);David Barber (Radboud University Nijmegen);Wim Wiegerinck (Radboud University Nijmegen);,"1977515466,2524043411,1977177148","We propose a vector quantisation method which does not only provide a compact description of data vectors in terms codebook vectors, but also gives an explanation of codebook vectors as binary combinations of elementary features. This corresponds to the intuitive notion that, in the real world, patterns can be usefully thought of as being constructed by compositions from simpler features. The model can be understood as a generative model, in which the codebook vector is generated by a hidden binary state vector. The model is non-probabilistic in the sense that it assigns each data vector to a single codebook vector. We describe exact and approximate learning algorithms for learning deterministic feature representations. In contrast to probabilistic models, the deterministic approach allows the use of message propagation algorithms within the learning scheme. These are compared with standard mean-field/Gibbs sampling learning. We show that Generative Vector Quantisation gives a good performance in large scale real world tasks like image compression and handwritten digit analysis with up to 400 data dimensions.",2001,Data Mining and Knowledge Discovery volume 5 issue 4 pp 337-363,linde buzo gray algorithm;gibbs sampling;mean field theory;image compression;feature vector;statistical model;data science;data mining;machine learning;statistics;computer science;mathematics;
Detecting Group Differences: Mining Contrast Sets,"Stephen D. Bay (University of California, Irvine);Michael J. Pazzani (University of California, Irvine);","2719938533,1996789426","A fundamental task in data analysis is understanding the differences between several contrasting groups. These groups can represent different classes of objects, such as male or female students, or the same group over time, e.g. freshman students in 1993 through 1998. We present the problem of mining contrast sets: conjunctions of attributes and values that differ meaningfully in their distribution across groups. We provide a search algorithm for mining contrast sets with pruning rules that drastically reduce the computational complexity. Once the contrast sets are found, we post-process the results to present a subset that are surprising to the user given what we have already shown. We explicitly control the probability of Type I error (false positives) and guarantee a maximum error rate for the entire analysis by using Bonferroni corrections.",2001,Data Mining and Knowledge Discovery volume 5 issue 3 pp 213-246,type i and type ii errors;association rule learning;data mining;machine learning;statistics;algorithm;computer science;mathematics;
Signature-Based Methods for Data Streams,Corinna Cortes (AT&T);Daryl Pregibon (AT&T);,"2134830209,2467880905","We have been developing signature-based methods in the telecommunications industry for the past 5 years. In this paper, we describe our work as it evolved due to improvements in technology and our aggressive attitude toward scale. We discuss the types of features that our signatures contain, nuances of how these are updated through time, our treatment of outliers, and the trade-off between time-driven and event-driven processing. We provide a number of examples, all drawn from the application of signatures to toll fraud detection.",2001,Data Mining and Knowledge Discovery volume 5 issue 3 pp 167-182,transaction data;world wide web;data mining;database;computer science;
Scaling Kernel-Based Systems to Large Data Sets,Volker Tresp (Siemens);,175204660,"In the form of the support vector machine and Gaussian processes, kernel-based systems are currently very popular approaches to supervised learning. Unfortunately, the computational load for training kernel-based systems increases drastically with the size of the training data set, such that these systems are not ideal candidates for applications with large data sets. Nevertheless, research in this direction is very active. In this paper, I review some of the current approaches toward scaling kernel-based systems to large data sets.",2001,Data Mining and Knowledge Discovery volume 5 issue 3 pp 197-211,kernel embedding of distributions;tree kernel;polynomial kernel;radial basis function kernel;kernel method;gaussian process;supervised learning;data mining;pattern recognition;machine learning;statistics;computer science;
Association Models for Web Mining,Paolo Giudici (University of Pavia);Robert Castelo (Utrecht University);,"2202747551,2110761727","We describe how statistical association models and, specifically, graphical models, can be usefully employed to model web mining data. We describe some methodological problems related to the implementation of discrete graphical models for web mining data. In particular, we discuss model selection procedures.",2001,Data Mining and Knowledge Discovery volume 5 issue 3 pp 183-196,graphical model;web mining;data science;data mining;machine learning;statistics;computer science;
Statistical Models for Data Mining,Paolo Giudici (University of Pavia);David Heckerman (Microsoft);Joe Whittaker (Lancaster University);,"2202747551,2021640924,2166329608","We review the background to the papers presented in this special issue and give a short introduction to each. We also briefly describe the workshop on “Statistical models for data mining”, held in Pavia (Italy), in October 2000, where the papers were presented.",2001,Data Mining and Knowledge Discovery volume 5 issue 3 pp 163-165,statistical model;knowledge extraction;data science;operations research;data mining;computer science;
E-Commerce Recommendation Applications,J. Ben Schafer (University of Minnesota);Joseph A. Konstan (University of Minnesota);John Riedl (University of Minnesota);,"2072158400,2681507483,1986422195","i>Recommender systems are being used by an ever-increasing number of E-commerce sites to help consumers find products to purchase. What started as a novelty has turned into a serious business tool. Recommender systems use product knowledge—either hand-coded knowledge provided by experts or “mined” knowledge learned from the behavior of consumers—to guide consumers through the often-overwhelming task of locating products they will like. In this article we present an explanation of how recommender systems are related to some traditional database analysis techniques. We examine how recommender systems help E-commerce sites increase sales and analyze the recommender systems at six market-leading sites. Based on these examples, we create a taxonomy of recommender systems, including the inputs required from the consumers, the additional knowledge required from the database, the ways the recommendations are presented to consumers, the technologies used to create the recommendations, and the level of personalization of the recommendations. We identify five commonly used E-commerce recommender application models, describe several open research problems in the field of recommender systems, and examine privacy implications of recommender systems technology.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 115-153,cross selling;loyalty business model;mass customization;personalization;user interface;privacy;recommender system;e commerce;world wide web;data mining;computer science;
Spatial clustering methods in data mining: a survey,Jiawei Han (University of Illinois at Urbana–Champaign);Micheline Kamber (Simon Fraser University);Anthony K. H. Tung (National University of Singapore);,"2121939561,1996151347,121171588",-,2001,Data Mining and Knowledge Discovery,cluster analysis;consensus clustering;data mining;computer science;
Personalization of Supermarket Product Recommendations,Richard D. Lawrence (IBM);George S. Almasi (IBM);Vladimir Kotlyar (IBM);Marisa Viveros (IBM);Sastry S. Duri (IBM);,"1965188977,593384113,2049362192,2128151167,2056982349","We describe a personalized recommender system designed to suggest new products to supermarket shoppers. The recommender functions in a pervasive computing environment, namely, a remote shopping system in which supermarket customers use Personal Digital Assistants (PDAs) to compose and transmit their orders to the store, which assembles them for subsequent pickup. The recommender is meant to provide an alternative source of new ideas for customers who now visit the store less frequently. Recommendations are generated by matching products to customers based on the expected appeal of the product and the previous spending of the customer. Associations mining in the product domain is used to determine relationships among product classes for use in characterizing the appeal of individual products. Clustering in the customer domain is used to identify groups of shoppers with similar spending histories. Cluster-specific lists of popular products are then used as input to the matching process. The recommender is currently being used in a pilot program with several hundred customers. Analysis of results to date have shown a 1.8% boost in program revenue as a result of purchases made directly from the list of recommended products. A substantial fraction of the accepted recommendations are from product classes new to the customer, indicating a degree of willingness to expand beyond present purchase patterns in response to reasonable suggestions.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 11-32,personalization;collaborative filtering;cluster analysis;recommender system;world wide web;data mining;machine learning;computer science;
Visualization and Analysis of Clickstream Data of Online Stores for Understanding Web Merchandising,Juhnyoung Lee (IBM);Mark Podlaseck (IBM);Edith Schonberg (IBM);Robert Hoch (IBM);,"2147154470,2107707720,2061408272,2141741082","Clickstreams are visitors' paths through a Web site. Analysis of clickstreams shows how a Web site is navigated and used by its visitors. Clickstream data of online stores contains information useful for understanding the effectiveness of marketing and merchandising efforts, such as how customers find the store, what products they see, and what products they purchase. In this paper, we present an interactive visualization system that provides users with greater abilities to interpret and explore clickstream data of online stores. This system visualizes the effectiveness of Web merchandising from two different points of view by using two different visualization techniques: visualization of sessions by using parallel coordinates and visualization of product performance by using starfield graphs. Furthermore, this system provides facilities for zooming, filtering, color-coding, dynamic querying and data sampling. It also provides summary information along with visualizations, and by maintaining a connection between visualizations and the source database, it dynamically updates the summary information. To demonstrate how the presented visualization system provides capabilities for examining online store clickstreams, we present a series of parallel coordinates and starfield visualizations that display clickstream data from an operating online retail store. A framework for understanding Web merchandising is briefly explained. A set of metrics referred to as i>micro-conversion rates, which are defined for Web merchandising analysis in our previous work (Lee et al., Electronic Markets, 2000), is also explained and used for the visualizations of online store effectiveness.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 59-84,parallel coordinates;visualization;visual system;interactive visualization;business intelligence;multimedia;world wide web;data mining;computer science;
Electronic commerce recommender applications,J. Ben Schafer (University of Northern Iowa);Joseph Konstan (University of Minnesota);John Riedl (University of Minnesota);,"2072158400,2002483998,1986422195",-,2001,Data Mining and Knowledge Discovery,e commerce;computer science;
Expert-Driven Validation of Rule-Based User Models in Personalization Applications,Gediminas Adomavicius (Courant Institute of Mathematical Sciences);Alexander Tuzhilin (New York University Stern School of Business);,"1988164005,2057138063","In many e-commerce applications, ranging from dynamic Web content presentation, to personalized ad targeting, to individual recommendations to the customers, it is important to build personalized profiles of individual users from their transactional histories. These profiles constitute models of individual user behavior and can be specified with sets of rules learned from user transactional histories using various data mining techniques. Since many discovered rules can be spurious, irrelevant, or trivial, one of the main problems is how to perform post-analysis of the discovered rules, i.e., how to validate user profiles by separating “good” rules from the “bad.” This validation process should be done with an explicit participation of the human expert. However, complications may arise because there can be very large numbers of rules discovered in the applications that deal with many users, and the expert cannot perform the validation on a rule-by-rule basis in a reasonable period of time. This paper presents a framework for building behavioral profiles of individual users. It also introduces a new approach to expert-driven validation of a very large number of rules pertaining to these users. In particular, it presents several types of validation operators, including rule grouping, filtering, browsing, and redundant rule elimination operators, that allow a human expert validate many individual rules at a time. By iteratively applying such operators, the human expert can validate a significant part of all the initially discovered rules in an acceptable time period. These validation operators were implemented as a part of a one-to-one profiling system. The paper also presents a case study of using this system for validating individual user rules discovered in a marketing application.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 33-58,profiling;personalization;data validation;user modeling;constitutive equation;e commerce;rule based system;world wide web;data mining;database;machine learning;computer science;
Applications of Data Mining to Electronic Commerce,Ron Kohavi (Blue Martini Software);Foster J. Provost (New York University);,"73615348,2158932634","Applications of Data Mining to Electronic Commerce R. Kohavi, F. Provost. Personalization of Supermarket Product Recommendations R.D. Lawrence, et al. Expert-Driven Validation of Rule-Based User Models in Personalization Applications G. Adomavicius, A. Tuzhilin. Visualization and Analysis of Clickstream Data of Online Stores for Understanding Web Merchandising J. Lee, et al. Data Mining for Measuring and Improving the Success of Web Sites M. Spiliopoulou, C. Pohle. E-Commerce Recommendation Applications J.B. Schafer, et al.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 5-10,legacy system;return on investment;business process;data collection;web mining;e commerce;world wide web;data mining;database;statistics;computer science;
Data Mining for Measuring and Improving the Success of Web Sites,Myra Spiliopoulou (Humboldt University of Berlin);Carsten Pohle (Humboldt University of Berlin);,"2672394148,2163181466","For many companies, competitiveness in e-commerce requires a successful presence on the web. Web sites are used to establish the company's image, to promote and sell goods and to provide customer support. The success of a web site affects and reflects directly the success of the company in the electronic market. In this study, we propose a methodology to improve the “success” of web sites, based on the exploitation of navigation pattern discovery. In particular, we present a theory, in which success is modelled on the basis of the navigation behaviour of the site's users. We then exploit WUM, a navigation pattern discovery miner, to study how the success of a site is reflected in the users' behaviour. With WUM we measure the success of a site's components and obtain concrete indications of how the site should be improved. We report on our first experiments with an online catalog, the success of which we have studied. Our mining analysis has shown very promising results, on the basis of which the site is currently undergoing concrete improvements.",2001,Data Mining and Knowledge Discovery volume 5 issue 1 pp 85-114,web development;energy conversion efficiency;web mining;e commerce;world wide web;data mining;computer science;
3 Fundamentals of spatial data warehousing for geographic knowledge discovery,Yvan Bédard;Tim Merrett;Jiawei Han;,"2575133436,2608152370,2680817133",-,2001,Data Mining and Knowledge Discovery,spatial analysis;knowledge extraction;data science;information retrieval;data mining;statistics;computer science;
Geographic data mining and knowledge discovery: an overview,Harvey J. Miller;Jae Woo Han;,"2720875899,2628838925",-,2001,Data Mining and Knowledge Discovery,knowledge extraction;data mining;computer science;
Algorithms and Applications for Spatial Data Mining,Martin Ester (Simon Fraser University);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);,"2067196623,1919135125",-,2001,Data Mining and Knowledge Discovery,software mining;spatial database;data;concept mining;data stream mining;web mining;knowledge extraction;data science;information retrieval;data mining;statistics;computer science;
Mining Association Rules Between Low-Level Image Features and High-Level Concepts,Ishwar K. Sethi (Oakland University);Ioana L. Coman (Wayne State University);,"2132312314,2618295011",-,2001,Data Mining and Knowledge Discovery,association rule learning;feature;data mining;pattern recognition;machine learning;computer science;
Paradigms for spatial and spatio-temporal data mining,John Roddick (Flinders University);Brian G Lees;,"2275978167,2634746396",-,2001,Data Mining and Knowledge Discovery,knowledge extraction;data science;information retrieval;data mining;computer science;
"Consistent and complete data and ""expert"" mining in medicine",Boris Kovalerchuk (Central Washington University);Evgenii Vityaev (Institute of Mathematics);James F. Ruiz (Central Washington University);,"2053495855,1889064551,2119365558",-,2001,Data Mining and Knowledge Discovery,data science;data mining;database;
Machine learning for information extraction from topographic maps,Donato Malerba (University of Bari);Floriana Esposito (University of Bari);Antonietta Lanza (University of Bari);Francesca A. Lisi (University of Bari);,"2360612151,2122401555,2103077917,300695800",-,2001,Data Mining and Knowledge Discovery,topographic map;information extraction;computer vision;pattern recognition;machine learning;computer science;
Geoinsight; an approach for developing a knowledge construction process based on the integration of GVis and KDD methods,M. Wachowicz (Wageningen University and Research Centre);,2681676522,-,2001,Data Mining and Knowledge Discovery,knowledge management;data mining;computer science;
Visual exploration in geography: analysis with light,Mark N. Gahegan;,2682342748,-,2001,Data Mining and Knowledge Discovery,visual geography;computer graphics images;computer vision;
Special Issue on Applications of data mining to electronic commerce,Ron Kohavi (Microsoft);Foster Provost (New York University);,"73615348,2158932634",-,2001,Data Mining and Knowledge Discovery,e commerce;data science;data mining;database;computer science;
Clustering based on data patterns using hypergraph models,Muhammet Mustafa Ozdal (Intel);Cevdet Aykanat (Bilkent University);,"1203210335,156302704",-,2001,Data Mining and Knowledge Discovery,correlation clustering;cure data clustering algorithm;single linkage clustering;fuzzy clustering;cluster analysis;pattern recognition;
Discovering Interesting Patterns for Investment Decision Making with GLOWER x-A Genetic Learner Overlaid with Entropy Reduction,Vasant Dhar (New York University Stern School of Business);Dashin Chou (New York University Stern School of Business);Foster J. Provost (New York University Stern School of Business);,"2736108007,2109310296,2158932634","Prediction in financial domains is notoriously difficult for a number of reasons. First, theories tend to be weak or non-existent, which makes problem formulation open ended by forcing us to consider a large number of independent variables and thereby increasing the dimensionality of the search space. Second, the weak relationships among variables tend to be nonlinear, and may hold only in limited areas of the search space. Third, in financial practice, where analysts conduct extensive manual analysis of historically well performing indicators, a key is to find the hidden interactions among variables that perform well in combination. Unfortunately, these are exactly the patterns that the greedy search biases incorporated by many standard rule learning algorithms will miss. In this paper, we describe and evaluate several variations of a new genetic learning algorithm (GLOWER) on a variety of data sets. The design of GLOWER has been motivated by financial prediction problems, but incorporates successful ideas from tree induction and rule learning. We examine the performance of several GLOWER variants on two UCI data sets as well as on a standard financial prediction problem (S&P500 stock returns), using the results to identify one of the better variants for further comparisons. We introduce a new (to KDD) financial prediction problem (predicting positive and negative earnings surprises), and experiment with GLOWER, contrasting it with tree- and rule-induction approaches. Our results are encouraging, showing that GLOWER has the ability to uncover effective patterns for difficult problems that have weak structure and significant nonlinearities.",2000,Data Mining and Knowledge Discovery volume 4 issue 4 pp 251-280,genetic algorithm;knowledge extraction;data mining;artificial intelligence;machine learning;statistics;computer science;mathematics;
Informix under CONTROL: Online Query Processing,"Joseph M. Hellerstein (University of California, Berkeley);Ron Avnur (University of California, Berkeley);Vijayshankar Raman (University of California, Berkeley);","2063640528,201926276,2112167796","The goal of the CONTROL project at Berkeley is to develop systems for interactive analysis of large data sets. We focus on systems that provide users with iteratively refining answers to requests and online control of processing, thereby tightening the loop in the data analysis process. This paper presents the database-centric subproject of CONTROL: a complete i>online query processing facility, implemented in a commercial Object-Relational DBMS from Informix. We describe the algorithms at the core of the system, and detail the end-to-end issues required to bring the algorithms together and deliver a complete system.",2000,Data Mining and Knowledge Discovery volume 4 issue 4 pp 281-314,online aggregation;interactivity;scientific control;data analysis;world wide web;data mining;database;statistics;computer science;
"Spatial Data Mining: Database Primitives, Algorithms and Efficient DBMS Support",Martin Ester (Ludwig Maximilian University of Munich);Alexander Frommelt (Ludwig Maximilian University of Munich);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);Jöorg Sander (Ludwig Maximilian University of Munich);,"2067196623,1988302111,1919135125,2573684072","Spatial data mining algorithms heavily depend on the efficient processing of neighborhood relations since the neighbors of many objects have to be investigated in a single run of a typical algorithm. Therefore, providing general concepts for neighborhood relations as well as an efficient implementation of these concepts will allow a tight integration of spatial data mining algorithms with a spatial database management system. This will speed up both, the development and the execution of spatial data mining algorithms. In this paper, we define neighborhood graphs and paths and a small set of database primitives for their manipulation. We show that typical spatial data mining algorithms are well supported by the proposed basic operations. For finding significant spatial patterns, only certain classes of paths “leading away” from a starting object are relevant. We discuss filters allowing only such neighborhood paths which will significantly reduce the search space for spatial data mining algorithms. Furthermore, we introduce neighborhood indices to speed up the processing of our database primitives. We implemented the database primitives on top of a commercial spatial database management system. The effectiveness and efficiency of the proposed approach was evaluated by using an analytical cost model and an extensive experimental study on a geographic database.",2000,Data Mining and Knowledge Discovery volume 4 issue 2 pp 193-216,object based spatial database;database schema;database design;spatial database;common spatial pattern;management system;spatial analysis;theoretical computer science;data mining;database;computer science;
Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications,Sunita Sarawagi (IBM);Shiby Thomas (IBM);Rakesh Agrawal (IBM);,"156875573,2723677196,2138427228","Data mining on large data warehouses is becoming increasingly important. In support of this trend, we consider a spectrum of architectural alternatives for coupling mining with database systems. These alternatives include: loose-coupling through a SQL cursor interfaces encapsulation of a mining algorithm in a stored procedures caching the data to a file system on-the-fly and minings tight-coupling using primarily user-defined functionss and SQL implementations for processing in the DBMS. We comprehensively study the option of expressing the mining algorithm in the form of SQL queries using Association rule mining as a case in point. We consider four options in SQL-92 and six options in SQL enhanced with object-relational extensions (SQL-OR). Our evaluation of the different architectural alternatives shows that from a performance perspective, the Cache option is superior, although the performance of the SQL-OR option is within a factor of two. Both the Cache and the SQL-OR approaches incur a higher storage penalty than the loose-coupling approach which performance-wise is a factor of 3 to 4 worse than Cache. The SQL-92 implementations were too slow to qualify as a competitive option. We also compare these alternatives on the basis of qualitative factors like automatic parallelization, development ease, portability and inter-operability. As a byproduct of this study, we identify some primitives for native support in database systems for decision-support applications.",2000,Data Mining and Knowledge Discovery volume 4 issue 2 pp 89-125,coupling;relational database management system;automatic parallelization;association rule learning;spectrum;decision support system;systems architecture;world wide web;data mining;database;computer science;
Using Linked Micromap Plots to Characterize Omernik Ecoregions,Daniel B. Carr (George Mason University);Anthony R. Olsen (United States Environmental Protection Agency);Suzanne M. Pierson (United States Environmental Protection Agency);Jean-Yves P. Courbois (Oregon State University);,"2104221692,2026575256,2102158543,864070364","The paper introduces linked micromap (LM) plots for presenting environmental summaries. The LM template includes parallel sequences of micromap, label, and statistical summary graphics panels with attention paid to perceptual grouping, sorting and linking of the summary components. The applications show LM plots for Omernik Level II Ecoregions. The summarized United States continental data includes USGS digital elevation, 30-year normal precipitation and temperature, and 8 million AVHRR pixels classified into 159 types of land cover. One LM plot uses a line-height glyph to represent all 159 land cover percentages per ecoregion. LM plots represent new visualization methodology that is useful in the data and knowledge based pattern representation and knowledge discovery process. The LM plots focus on providing an orienting overview. The overview provides a starting place for subsequent drilling down to what could otherwise be viewed as an overwhelming mass of data. The overview also provides a starting place to learn about the intellectual structure that lies behind the notion of ecoregions and begins to connect this abstract structure to quantitative methods.",2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 43-67,box plot;spatial analysis;multivariate statistics;quantitative research;statistical graphics;knowledge base;data mining;artificial intelligence;machine learning;statistics;computer science;
Visual Data Mining In Atmospheric Science Data,Márcia Macêdo (Iowa State University);Dianne Cook (Iowa State University);Timothy J. Brown (Desert Research Institute);,"2121528339,2118199879,2421595974","This paper discusses the use of simple visual tools to explore multivariate spatially-referenced data. It describes interactive approaches such as linked brushing, and dynamic methods such as the grand tour, applied to studying the Comprehensive Ocean-Atmosphere Data Set (COADS). This visual approach provides an alternative way to gain understanding of high-dimensional data. It also provides cross-validation and visual adjuncts to the more computationally intensive data mining techniques.",2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 69-80,interactive visual analysis;clustering high dimensional data;exploratory data analysis;cross validation;multivariate analysis;statistical graphics;data visualization;data science;computer graphics images;data mining;statistics;computer science;
Euclidean Distance Based Permutation Methods in Atmospheric Science,W Paul Mielke (Colorado State University);Kenneth J. Berry (Colorado State University);,"2134817765,2100151165","The majority of existing statistical methods inherently involve complex nonmetric analysis spaces due to their least squares regression origins consequently, the analysis space of such statistical methods is not consistent with the simple metric Euclidean geometry of the data space in question. The statistical methods presented in this paper are consistent with the data spaces in question. These alternative methods depend on exact and approximate permutation procedures for univariate and multivariate data involving cyclic phenomena, autoregressive patterns, covariate residual analyses including most linear model based experimental designs, and linear and nonlinear prediction model evaluations. Specific atmospheric science applications include climate change, Atlantic basin seasonal tropical cyclone predictions, analyses of weather modification experiments, and numerical model evaluations for phenomena such as cumulus clouds, clear-sky surface energy budgets, and mesoscale atmospheric predictions.",2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 7-27,multivariate statistics;design of experiments;euclidean geometry;combinatorics;econometrics;machine learning;statistics;mathematics;
Guest Editorial: Statistical Mining and Data Visualization in Atmospheric Sciences,Timothy J. Brown (Desert Research Institute);Paul W. Mielke (Colorado State University);,"2421595974,2153307748",-,2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 5-6,data visualization;data science;information retrieval;data mining;statistics;computer science;
Bootstrapping to Assess and Improve Atmospheric Prediction Models,J. Sunil Rao (Case Western Reserve University);,2123113405,"Bootstrapping is a simple technique typically used to assess accuracy of estimates of model parameters by using simple plug-in principles and replacing sometimes unwieldy theory by computer simulation. Common uses include variance estimation and confidence interval construction of model parameters. It also provides a way to estimate prediction accuracy of continuous and class-valued outcomes regression models. In this paper we will overview some of these applications of the bootstrap focusing on bootstrap estimates of prediction error, and also explore how the bootstrap can be used to improve prediction accuracy of unstable models like tree-structured classifiers through aggregation. The improvements can typically be attributed to variance reduction in the classical regression setting and more generally a smoothing of decision boundaries for the classification setting. These advancements have important implications in the way that atmospheric prediction models can be improved, and illustrations of this will be shown. For class-valued outcomes, an interesting graphic known as the CAT scan can be constructed to help understand the aggregated decision boundary. This will be illustrated using simulated data.",2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 29-41,tropical cyclone;variance reduction;instability;tree structure;mean squared prediction error;predictive modelling;confidence interval;biological classification;regression analysis;supervised learning;computer simulation;econometrics;data mining;machine learning;statistics;computer science;
Collaborative Recommendation via Adaptive Association Rule Mining,Wei-yang Lin (Microsoft);Sergio A. Alvarez (Boston College);Carolina Ruiz (Worcester Polytechnic Institute);,"2277644620,2170320455,2149401507",-,2000,Data Mining and Knowledge Discovery,affinity analysis;association rule learning;recommender system;world wide web;data mining;machine learning;computer science;
Value-based customer grouping from large retail data sets,Alexander L. Strehl (University of Texas at Austin);Joydeep Ghosh (University of Texas at Austin);,"2668006830,2148168557",-,2000,Data Mining and Knowledge Discovery,top down and bottom up design;data science;data mining;computer science;
Mining sequential patterns including time intervals,Mariko Yoshida;T. Iizuka;Hisako Shiohara;Masanori Ishiguro;,"2691624702,2600641709,2699084096,2701708397",-,2000,Data Mining and Knowledge Discovery,computer science;
Information tables with neighborhood semantics,Yiyu Yao (University of Regina);,2134033583,-,2000,Data Mining and Knowledge Discovery,cognitive models of information retrieval;human computer information retrieval;information integration;relevance;knowledge extraction;data science;information retrieval;data mining;computer science;
Electronic commerce rec-ommender applications,J. Ben Schafer (University of Northern Iowa);Joseph Konstan (University of Minnesota);John Riedl (University of Minnesota);,"2072158400,2002483998,1986422195",-,2000,Data Mining and Knowledge Discovery,e commerce;computer science;
Statistical Mining and Data Visualization in Atmospheric Sciences,Timothy J. Brown (Desert Research Institute);Paul W. Mielke (Colorado State University);,"2421595974,2153307748","Guest Editorial: Statistical Mining and Data Visualization in Atmospheric Sciences T.J. Brown, P.W. Mielke, Jr. Euclidean Distance Based Permutation Methods in Atmospheric Science P.W. Mielke, Jr., K.J. Berry. Bootstrapping to Assess and Improve Atmospheric Prediction Models J.S. Rao. Using Linked Micromap Plots to Characterize Omernik Ecoregions D.B. Carr, et al. Visual Data Mining in Atmospheric Science Data M. Macedo, et al.",2000,Data Mining and Knowledge Discovery volume 4 issue 1 pp 5-6,data science;data mining;statistics;
Systematic method to identify patterns in engineering data,Peter Hertkorn (University of Stuttgart);Stephan Rudolph (University of Stuttgart);,"1989800963,2134924352",-,2000,Data Mining and Knowledge Discovery,database design;data modeling;model building;natural science;concept mining;knowledge extraction;data science;bioinformatics;data mining;computer science;
Methods of Temporal Data Validation and Abstraction in High-Frequency Domains,Silvia Miksch (Vienna University of Technology);Andreas Seyfang (Vienna University of Technology);Werner Horn (University of Vienna);Christian Popow (University of Vienna);Franz Paky;,"193994343,2088893045,2148288937,2312374324,693338728",-,2000,Data Mining and Knowledge Discovery,temporal database;high frequency;computer science;
Distance functions in dynamic integration of data mining techniques,Seppo Puuronen (University of Jyväskylä);Alexey Tsymbal (Siemens);Vagan Y. Terziyan (University of Jyväskylä);,"1965931980,2062554273,116134149",-,2000,Data Mining and Knowledge Discovery,euclidean distance;metric;instance based learning;knowledge extraction;data mining;pattern recognition;machine learning;computer science;mathematics;
MSQL: A Query Language for Database Mining,Tomasz Imielinski (Rutgers University);Aashu Virmani (Rutgers University);,"152915441,2060894305","The tremendous number of rules generated in the mining process makes it necessary for any good data mining system to provide for powerful query primitives to post-process the generated rulebase, as well as for performing selective, query based generation. In this paper, we present the design and compilation of MSQL, the rule query language developed as part of the Discovery Board system.",1999,Data Mining and Knowledge Discovery volume 3 issue 4 pp 373-408,rdf query language;web search query;query by example;query expansion;query optimization;query language;association rule learning;world wide web;data mining;database;computer science;
The Role of Occam‘s Razor in Knowledge Discovery,Pedro M. Domingos (University of Washington);,2169012919,"Many KDD systems incorporate an implicit or explicit preference for simpler models, but this use of “Occam‘s razor” has been strongly criticized by several authors (e.g., Schaffer, 1993s Webb, 1996). This controversy arises partly because Occam‘s razor has been interpreted in two quite different ways. The first interpretation (simplicity is a goal in itself) is essentially correct, but is at heart a preference for more comprehensible models. The second interpretation (simplicity leads to greater accuracy) is much more problematic. A critical review of the theoretical arguments for and against it shows that it is unfounded as a universal principle, and demonstrably false. A review of empirical evidence shows that it also fails as a practical heuristic. This article argues that its continued use in KDD risks causing significant opportunities to be missed, and should therefore be restricted to the comparatively few applications where it is appropriate. The article proposes and reviews the use of domain constraints as an alternative for avoiding overfitting, and examines possible methods for handling the accuracy–comprehensibility trade-off.",1999,Data Mining and Knowledge Discovery volume 3 issue 4 pp 409-425,heuristic argument;overfitting;occam s razor;domain knowledge;model selection;multiple comparisons problem;empirical evidence;knowledge extraction;data mining;artificial intelligence;machine learning;statistics;algorithm;computer science;
DMajor—Application Programming Interface for Database Mining,Tomasz Imieliński (Rutgers University);Aashu Virmani (Rutgers University);Amin Abdulghani (Rutgers University);,"152915441,2060894305,2345889923","In the process of rule generation from databases, the volume of generated rules often greatly exceeds the size of the underlying database. Typically only a small fraction of that large volume of rules is of any interest to the user. We believe that the main challenge facing database mining is what to do with the rules after having generated them. Rule post-processing involves selecting rules which are relevant or interesting, building applications which use the rules and finally, combining rules together to form a larger and more meaningful statements. In this paper we propose an application programming interface which enables faster development of applications which rely on rules. We also provide a rule query language which allows both selective rule generation as well as retrieval of selected categories of rules from the pre-generated rule collections.",1999,Data Mining and Knowledge Discovery volume 3 issue 4 pp 347-372,production rule representation;application programming interface;association rule learning;world wide web;data mining;database;machine learning;computer science;
A Fast Parallel Clustering Algorithm for Large Spatial Databases,Xiaowei Xu (Siemens);Jochen Jäger (Ludwig Maximilian University of Munich);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);,"2645375510,2421537791,1919135125","The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper, we present PDBSCAN, a parallel version of this algorithm. We use the ‘shared-nothing’ architecture with multiple computers interconnected through a network. A fundamental component of a shared-nothing system is its distributed data structure. We introduce the dRa-tree, a distributed spatial index structure in which the data is spread among multiple computers and the indexes of the data are replicated on every computer. We implemented our method using a number of workstations connected via Ethernet (10 Mbit). A performance evaluation shows that PDBSCAN offers nearly linear speedup and has excellent scaleup and sizeup behavior.",1999,Data Mining and Knowledge Discovery volume 3 issue 3 pp 263-290,optics algorithm;dbscan;spatial database;parallel algorithm;distributed algorithm;theoretical computer science;data mining;database;computer science;
Parallel Formulations of Decision-Tree Classification Algorithms,Anurag Srivastava (Hitachi);Eui Hong Han (University of Minnesota);Vipin Kumar (University of Minnesota);Vineet Singh (Hitachi);,"2571814082,2243164899,2161062602,2308610918","Classification decision tree algorithms are used extensively for data mining in many domains such as retail target marketing, fraud detection, etc. Highly parallel algorithms for constructing classification decision trees are desirable for dealing with large data sets in reasonable amount of time. Algorithms for building classification decision trees have a natural concurrency, but are difficult to parallelize due to the inherent dynamic nature of the computation. In this paper, we present parallel formulations of classification decision tree learning algorithm based on induction. We describe two basic parallel formulations. One is based on Synchronous Tree Construction Approach and the other is based on Partitioned Tree Construction Approach. We discuss the advantages and disadvantages of using these methods and propose a hybrid method that employs the good features of these methods. We also provide the analysis of the cost of computation and communication of the proposed hybrid method. Moreover, experimental results on an IBM SP-2 demonstrate excellent speedups and scalability.",1999,Data Mining and Knowledge Discovery volume 3 issue 3 pp 237-261,incremental decision tree;id3 algorithm;classification tree method;decision tree learning;decision tree;parallel processing;theoretical computer science;data mining;machine learning;computer science;
Effect of Data Distribution in Parallel Mining of Associations,David Wai-lok Cheung (University of Hong Kong);Yongqiao Xiao (University of Hong Kong);,"1979772396,2143425637","Association rule mining is an important new problem in data mining. It has crucial applications in decision support and marketing strategy. We proposed an efficient parallel algorithm for mining association rules on a distributed share-nothing parallel system. Its efficiency is attributed to the incorporation of two powerful candidate set pruning techniques. The two techniques, distributed and global prunings, are sensitive to two data distribution characteristics: data skewness and workload balance. The prunings are very effective when both the skewness and balance are high. We have implemented FPM on an IBM SP2 parallel system. The performance studies show that FPM outperforms CD consistently, which is a parallel version of the representative Apriori algorithm (Agrawal and Srikant, 1994). Also, the results have validated our observation on the effectiveness of the two pruning techniques with respect to the data distribution characteristics. Furthermore, it shows that FPM has nice scalability and parallelism, which can be tuned for different business applications.",1999,Data Mining and Knowledge Discovery volume 3 issue 3 pp 291-314,association rule learning;decision support system;theoretical computer science;data mining;database;machine learning;computer science;
Parallel Learning of Belief Networks in Large and Difficult Domains,Yang Xiang (University of Regina);Tongsheng Chu (University of Regina);,"2679005713,2595252388","Learning belief networks from large domains can be expensive even with single-link lookahead search (SLLS). Since a SLLS cannot learn correctly in a class of problem domains, multi-link lookahead search (MLLS) is needed which further increases the computational complexity. In our experiment, learning in some difficult domains over more than a dozen variables took days. In this paper, we study how to use parallelism to speed up SLLS for learning in large domains and to tackle the increased complexity of MLLS for learning in difficult domains. We propose a natural decomposition of the learning task for parallel processing. We investigate two strategies for job allocation among processors to further improve load balancing and efficiency of the parallel system. For learning from very large datasets, we present a regrouping of the available processors such that slow data access through the file system can be replaced by fast memory access. Experimental results in a distributed memory MIMD computer demonstrate the effectiveness of the proposed algorithms.",1999,Data Mining and Knowledge Discovery volume 3 issue 3 pp 315-339,data access;distributed memory;bayesian network;load balancing;computational complexity theory;parallel processing;theoretical computer science;parallel computing;distributed computing;data mining;machine learning;computer science;
A Survey of Methods for Scaling Up Inductive Algorithms,Foster J. Provost (Association for Computing Machinery);Venkateswarlu Kolluri (University of Pittsburgh);,"2158932634,2308720007","One of the defining challenges for the KDD research community is to enable inductive learning algorithms to mine very large databases. This paper summarizes, categorizes, and compares existing work on scaling up inductive algorithms. We concentrate on algorithms that build decision trees and rule sets, in order to provide focus and specific detailss the issues and techniques generalize to other types of data mining. We begin with a discussion of important issues related to scaling up. We highlight similarities among scaling techniques by categorizing them into three main approaches. For each approach, we then describe, compare, and contrast the different constituent techniques, drawing on specific examples from published papers. Finally, we use the preceding analysis to suggest how to proceed when dealing with a large problem, and where to focus future research.",1999,Data Mining and Knowledge Discovery volume 3 issue 2 pp 131-169,multi task learning;decision tree;data science;data mining;machine learning;computer science;
A Scalable Parallel Algorithm for Self-Organizing Maps with Applicationsto Sparse Data Mining Problems,Richard D. Lawrence (IBM);George S. Almasi (IBM);Holly E. Rushmeier (IBM);,"1965188977,593384113,706175027","We describe a scalable parallel implementation of the self organizing map (SOM) suitable for data-mining applications involving clustering or segmentation against large data sets such as those encountered in the analysis of customer spending patterns. The parallel algorithm is based on the batch SOM formulation in which the neural weights are updated at the end of each pass over the training data. The underlying serial algorithm is enhanced to take advantage of the sparseness often encountered in these data sets. Analysis of a realistic test problem shows that the batch SOM algorithm captures key features observed using the conventional on-line algorithm, with comparable convergence rates. Performance measurements on an SP2 parallel computer are given for two retail data sets and a publicly available set of census data.These results demonstrate essentially linear speedup for the parallel batch SOM algorithm, using both a memory-contained sparse formulation as well as a separate implementation in which the mining data is accessed directly from a parallel file system. We also present visualizations of the census data to illustrate the value of the clustering information obtained via the parallel SOM method.",1999,Data Mining and Knowledge Discovery volume 3 issue 2 pp 171-195,parallel algorithm;sparse matrix;rate of convergence;cluster analysis;data visualization;parallel processing;theoretical computer science;data mining;machine learning;computer science;
Partitioning Nominal Attributes in Decision Trees,Don Coppersmith (IBM);Se June Hong (IBM);Jonathan R. M. Hosking (IBM);,"2037645014,2166867472,2089355880","To find the optimal branching of a nominal attribute at a node in an L-ary decision tree, one is often forced to search over all possible L-ary partitions for the one that yields the minimum impurity measure. For binary trees (L e 2) when there are just two classes a short-cut search is possible that is linear in n, the number of distinct values of the attribute. For the general case in which the number of classes, k, may be greater than two, Burshtein et al. have shown that the optimal partition satisfies a condition that involves the existence of({L\atop 2}) hyperplanes in the class probability space. We derive a property of the optimal partition for concave impurity measures (including in particular the Gini and entropy impurity measures) in terms of the existence ofL vectors in the dual of the class probability space, which implies the earlier condition. Unfortunately, these insights still do not offer a practical search method when n and k are large, even for binary trees. We therefore present a new heuristic search algorithm to find a good partition. It is based on ordering the attribute‘s values according to their principal component scores in the class probability space, and is linear in n. We demonstrate the effectiveness of the new method through Monte Carlo simulation experiments and compare its performance against other heuristic methods.",1999,Data Mining and Knowledge Discovery volume 3 issue 2 pp 197-217,ternary search tree;optimal binary search tree;random binary tree;impurity;binary tree;binary decision diagram;decision tree;entropy;biological classification;satisfiability;discrete mathematics;combinatorics;data mining;machine learning;mathematical optimization;statistics;computer science;mathematics;
CHAMP: A Prototype for Automated Cellular Churn Prediction,Brij M. Masand (Burlington Coat Factory);Piew Datta;D. R. Mani (Verizon Communications);Bin Li;,"201836202,2673751200,2614884056,2305141318","We describe CHAMP (CHurn Analysis, Modeling, and Prediction), an automated system for modeling cellular customer behavior on a large scale. Using historical data from GTE‘s data warehouse for cellular phone customers, every month CHAMP identifies churn factors for several geographic regions and updates models to generate churn scores predicting who is likely to churn within the near future. CHAMP is capable of developing customized monthly models and churn scores for over one hundred GTE cellular phone markets totaling over 5 million customers.",1999,Data Mining and Knowledge Discovery volume 3 issue 2 pp 219-225,predictive analytics;predictive modelling;data warehouse;knowledge extraction;data science;data mining;database;machine learning;computer science;
Discovery of frequent DATALOG patterns,Luc Dehaspe (Katholieke Universiteit Leuven);Hannu Toivonen (University of Helsinki);,"131954981,2250270171","Discovery of frequent patterns has been studied in a variety of data mining settings. In its simplest form, known from association rule mining, the task is to discover all frequent itemsets, i.e., all combinations of items that are found in a sufficient number of examples. The fundamental task of association rule and frequent set discovery has been extended in various directions, allowing more useful patterns to be discovered with special purpose algorithms. We present WARMR, a general purpose inductive logic programming algorithm that addresses frequent query discovery: a very general DATALOG formulation of the frequent pattern discovery problem. The motivation for this novel approach is twofold. First, exploratory data mining is well supported: WARMR offers the flexibility required to experiment with standard and in particular novel settings not supported by special purpose algorithms. Also, application prototypes based on WARMR can be used as benchmarks in the comparison and evaluation of new special purpose algorithms. Second, the unified representation gives insight to the blurred picture of the frequent pattern discovery domain. Within the DATALOG formulation a number of dimensions appear that relink diverged settings. We demonstrate the frequent query approach and its use on two applications, one in alarm analysis, and one in a chemical toxicology domain.",1999,Data Mining and Knowledge Discovery volume 3 issue 1 pp 7-36,k optimal pattern discovery;association rule learning;knowledge extraction;data mining;database;machine learning;computer science;
Feature construction with Inductive Logic Programming: A Study of Quantitative Predictions of Biological Activity Aided by Structural Attributes,Ashwin Srinivasan (University of Oxford);Ross D. King (Aberystwyth University);,"2270196177,2171780146","Recently, computer programs developed within the field of Inductive Logic Programming (ILP) have received some attention for their ability to construct restricted first-order logic solutions using problem-specific background knowledge. Prominent applications of such programs have been concerned with determining “structure-activity” relationships in the areas of molecular biology and chemistry. Typically the task here is to predict the “activity” of a compound (for example, toxicity), from its chemical structure. A summary of the research in the area is: (a) ILP programs have largely been restricted to qualitative predictions of activity (“high”, “low” etc.)s (b) When appropriate attributes are available, ILP programs have equivalent predictivity to standard quantitative analysis techniques like linear regression. However ILP programs usually perform better when such attributes are unavailables and (c) By using structural information as background knowledge, an ILP program can provide comprehensible explanations for biological activity. This paper examines the use of ILP programs as a method of “discovering” new attributes. These attributes could then be used by methods like linear regression, thus allowing for quantitative predictions while retaining the ability to use structural information as background knowledge. Using structure-activity tasks as a test-bed, the utility of ILP programs in constructing new features was evaluated by examining the prediction of biological activity using linear regression, with and without the aid of ILP learnt logical attributes. In three out of the five data sets examined the addition of ILP attributes produced statistically better results. In addition six important structural features that have escaped the attention of the expert chemists were discovered. The method used here to construct new attributes is not specific to the problem of predicting biological activity, and the results obtained suggest a wider role for ILP programs in aiding the process of scientific discovery.",1999,Data Mining and Knowledge Discovery volume 3 issue 1 pp 37-57,quantitative structure activity relationship;dummy variable;drug design;testbed;structure activity relationship;chemical structure;quantitative analysis;biological activity;linear regression;first order logic;data mining;machine learning;algorithm;computer science;
Scaling Up Inductive Logic Programming by Learning from Interpretations,Hendrik Blockeel (Katholieke Universiteit Leuven);Luc De Raedt (Katholieke Universiteit Leuven);Nico Jacobs (Katholieke Universiteit Leuven);Bart Demoen (Katholieke Universiteit Leuven);,"2049189351,189137728,2115552159,713720536","When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently. Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting). As a case study, we present two alternative implementations of the ILP system TILDE (Top-down Induction of Logical DEcision trees): TILDEclassic, which loads all data in main memory, and TILDELDS, which loads the examples one by one. We experimentally compare the implementations, showing TILDELDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.",1999,Data Mining and Knowledge Discovery volume 3 issue 1 pp 59-93,inductive bias;multi task learning;expressive power;logic programming;decision tree learning;top down and bottom up design;relational database;decision tree;first order logic;inductive programming;statistical relational learning;data mining;machine learning;algorithm;computer science;
A Study of Two Sampling Methods for Analyzing Large Datasets with ILP,Ashwin Srinivasan (University of Oxford);,2270196177,"This paper is concerned with problems that arise when submitting large quantities of data to analysis by an Inductive Logic Programming (ILP) system. Complexity arguments usually make it prohibitive to analyse such datasets in their entirety. We examine two schemes that allow an ILP system to construct theories by sampling from this large pool of data. The first, “subsampling”, is a single-sample design in which the utility of a potential rule is evaluated on a randomly selected sub-sample of the data. The second, “logical windowing”, is multiple-sample design that tests and sequentially includes errors made by a partially correct theory. Both schemes are derived from techniques developed to enable propositional learning methods (like decision trees) to cope with large datasets. The ILP system CProgol, equipped with each of these methods, is used to construct theories for two datasets—one artificial (a chess endgame) and the other naturally occurring (a language tagging problem). In each case, we ask the following questions of CProgol equipped with sampling: (1) Is its theory comparable in predictive accuracy to that obtained if all the data were used (that is, no sampling was employed)?s and (2) Is its theory constructed in less time than the one obtained with all the data? For the problems considered, the answers to these questions is “yes”. This suggests that an ILP program equipped with an appropriate sampling method could begin to address problems satisfactorily that have hitherto been inaccessible simply due to data extent.",1999,Data Mining and Knowledge Discovery volume 3 issue 1 pp 95-123,sampling design;decision tree;sampling;theoretical computer science;data mining;machine learning;statistics;algorithm;computer science;
Mapcubes: A visualization tool for spatial data warehouses,Shashi Shekhar (University of Minnesota);C.-T. Lu (Virginia Tech);Xinming Tan;Shuchi Chawla;Ranga Raju Vatsavai (University of Minnesota);,"2134885186,2112878203,2647992233,2643711361,2616883556",-,1999,Data Mining and Knowledge Discovery,spatial database;spatial analysis;statistics;computer science;
On Comparing Classifiers: A Critique of Current Research and Methods,Steven Salzberg (Johns Hopkins University);,1904680277,-,1999,Data Mining and Knowledge Discovery,very large database;design of experiments;data science;data mining;pattern recognition;computer science;
Mining for similarities in aligned time series using wavelets,Yka Huhtala (University of Helsinki);Juha Karkkainen (University of Helsinki);Hannu T. T. Toivonen (University of Helsinki);,"82314309,2006900429,2250270171",-,1999,Data Mining and Knowledge Discovery,time series;data science;data mining;pattern recognition;statistics;computer science;
Modeling Spatial Dependencies for Mining Geospatial Data: An Introduction,Sanjay Chawla (Qatar Computing Research Institute);Shashi Shekhar (University of Minnesota);Wei-Li Wu (University of Texas at Dallas);Uygar Ozesmi;,"2201421368,2134885186,2159309593,2581770039",-,1999,Data Mining and Knowledge Discovery,spatial descriptive statistics;spatial analysis;geospatial analysis;data science;data mining;statistics;
A study of two probabilistic methods for searching large spaces with ILP,Ashwin Srinivasan (IBM);,2270196177,-,1999,Data Mining and Knowledge Discovery,probabilistic logic network;probabilistic argumentation;probabilistic ctl;probabilistic method;logic programming;probabilistic logic;inductive programming;statistical relational learning;theoretical computer science;machine learning;algorithm;mathematics;
Knowledge discovery and validation in software metrics databases,Miyoung Shin (Syracuse University);Amrit L. Goel (Syracuse University);,"2495584294,2125252530",-,1999,Data Mining and Knowledge Discovery,software mining;database theory;software metric;database design;regression model validation;radial basis function;data science;data mining;database;machine learning;computer science;
IRIS: our prototype rule generation system,Betsy Singh (Northwestern University);Peter Scheuermann (Northwestern University);Bin Chen (Northwestern University);,"2128409809,797615088,2310214881",-,1999,Data Mining and Knowledge Discovery,semi structured data;association rule learning;data model;knowledge extraction;systems architecture;data science;data mining;pattern recognition;computer science;
Automatic Construction of Decision Trees from Data: A Multi-Disciplinary Survey,Sreerama K. Murthy (Siemens);,2663064898,"Decision trees have proved to be valuable tools for the description, classification and generalization of data. Work on constructing decision trees from data exists in multiple disciplines such as statistics, pattern recognition, decision theory, signal processing, machine learning and artificial neural networks. Researchers in these disciplines, sometimes working on quite different problems, identified similar issues and heuristics for decision tree construction. This paper surveys existing work on decision tree construction, attempting to identify the important issues involved, directions the work has taken and the current state of the art.",1998,Data Mining and Knowledge Discovery volume 2 issue 4 pp 345-389,information fuzzy networks;incremental decision tree;decision stump;id3 algorithm;classification tree method;alternating decision tree;data compaction;evidential reasoning approach;influence diagram;decision tree learning;decision tree;decision theory;biological classification;decision engineering;artificial neural network;signal processing;data mining;pattern recognition;machine learning;computer science;
Principal Direction Divisive Partitioning,Daniel Boley (University of Minnesota);,2022814076,"We propose a new algorithm capable of partitioning a set of documents or other samples based on an embedding in a high dimensional Euclidean space (i.e., in which every document is a vector of real numbers). The method is unusual in that it is divisive, as opposed to agglomerative, and operates by repeatedly splitting clusters into smaller clusters. The documents are assembled into a matrix which is very sparse. It is this sparsity that permits the algorithm to be very efficient. The performance of the method is illustrated with a set of text documents obtained from the World Wide Web. Some possible extensions are proposed for further investigation.",1998,Data Mining and Knowledge Discovery volume 2 issue 4 pp 325-344,euclidean space;data mining;pattern recognition;machine learning;computer science;mathematics;
A Microeconomic View of Data Mining,"Jon M. Kleinberg (Cornell University);Christos H. Papadimitriou (University of California, Berkeley);Prabhakar Raghavan (IBM);","2261367123,2220829341,2195048431","We present a rigorous framework, based on optimization, for evaluating data mining operations such as associations and clustering, in terms of their utility in decision-making. This framework leads quickly to some interesting computational problems related to sensitivity analysis, segmentation and the theory of games.",1998,Data Mining and Knowledge Discovery volume 2 issue 4 pp 311-324,market segmentation;sensitivity analysis;cluster analysis;data science;data mining;machine learning;computer science;
Mining Pharmacy Data Helps to Make Profits,Yukinobu Hamuro (Osaka Sangyo University);Naoki Katoh (Kyoto University);Yasuyuki Matsuda;Katsutoshi Yada (Kansai University);,"2115648015,2707648017,2570581246,2079431324","Pharma, a drugstore chain in Japan, has been remarkably successful in the effective use of data mining. From over one tera bytes of sales data accumulated in databases, it has derived much interesting and useful knowledge that in turn has been applied to produce profits. In this paper, we shall explain several interesting cases of knowledge discovery at Pharma. We then discuss the innovative features of the data mining system developed in Pharma that led to meaningful knowledge discovery.",1998,Data Mining and Knowledge Discovery volume 2 issue 4 pp 391-398,point of sale;knowledge extraction;pharmacy;data mining;computer science;
Extensions to the k-Means Algorithm for Clustering Large Data Sets with Categorical Values,Zhexue Huang (Commonwealth Scientific and Industrial Research Organisation);,2666363709,"The k-means algorithm is well known for its efficiency in clustering large data sets. However, working only on numeric values prohibits it from being used to cluster real world data containing categorical values. In this paper we present two algorithms which extend the k-means algorithm to categorical domains and domains with mixed numeric and categorical values. The k-modes algorithm uses a simple matching dissimilarity measure to deal with categorical objects, replaces the means of clusters with modes, and uses a frequency-based method to update modes in the clustering process to minimise the clustering cost function. With these extensions the k-modes algorithm enables the clustering of categorical data in a fashion similar to k-means. The k-prototypes algorithm, through the definition of a combined dissimilarity measure, further integrates the k-means and k-modes algorithms to allow for clustering objects described by mixed numeric and categorical attributes. We use the well known soybean disease and credit approval data sets to demonstrate the clustering performance of the two algorithms. Our experiments on two real world data sets with half a million objects each show that the two algorithms are efficient when clustering large data sets, which is critical to data mining applications.",1998,Data Mining and Knowledge Discovery volume 2 issue 3 pp 283-304,k medians clustering;flame clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;fuzzy clustering;k means clustering;clustering high dimensional data;cluster analysis;consensus clustering;data mining;pattern recognition;machine learning;computer science;mathematics;
Is Sampling Useful in Data Mining? A Case in the Maintenance of Discovered Association Rules,Sau Dan Lee (University of Hong Kong);David Wai-lok Cheung (University of Hong Kong);Ben Kao (University of Hong Kong);,"2192435601,1979772396,1911907851","By nature, sampling is an appealing technique for data mining, because approximate solutions in most cases may already be of great satisfaction to the need of the users. We attempt to use sampling techniques to address the problem of maintaining discovered association rules. Some studies have been done on the problem of maintaining the discovered association rules when updates are made to the database. All proposed methods must examine not only the changed part but also the unchanged part in the original database, which is very large, and hence take much time. Worse yet, if the updates on the rules are performed frequently on the database but the underlying rule set has not changed much, then the effort could be mostly wasted. In this paper, we devise an algorithm which employs sampling techniques to estimate the difference between the association rules in a database before and after the database is updated. The estimated difference can be used to determine whether we should update the mined association rules or not. If the estimated difference is small, then the rules in the original database is still a good approximation to those in the updated database. Hence, we do not have to spend the resources to update the rules. We can accumulate more updates before actually updating the rules, thereby avoiding the overheads of updating the rules too frequently. Experimental results show that our algorithm is very efficient and highly accurate.",1998,Data Mining and Knowledge Discovery volume 2 issue 3 pp 233-262,association rule learning;sampling;knowledge extraction;data science;data mining;database;computer science;
On the Complexity of Mining Quantitative Association Rules,Jef Wijsen (Vrije Universiteit Brussel);Robert Meersman (Vrije Universiteit Brussel);,"749393633,1969532832","The discovery of quantitative association rules in large databases is considered an interesting and important research problem. Recently, different aspects of the problem have been studied, and several algorithms have been presented in the literature, among others in (Srikant and Agrawal, 1996; Fukuda et al., 1996a; Fukuda et al., 1996b; Yoda et al., 1997; Miller and Yang, 1997). An aspect of the problem that has so far been ignored, is its computational complexity. In this paper, we study the computational complexity of mining quantitative association rules.",1998,Data Mining and Knowledge Discovery volume 2 issue 3 pp 263-281,association rule learning;computational complexity theory;bioinformatics;data mining;artificial intelligence;computer science;
A Tutorial on Support Vector Machines for Pattern Recognition,Christopher J. C. Burges (Bell Labs);,2338350011,"The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.",1998,Data Mining and Knowledge Discovery volume 2 issue 2 pp 121-167,margin classifier;relevance vector machine;least squares support vector machine;support vector machine;data mining;pattern recognition;machine learning;algorithm;computer science;mathematics;
Density-Based Clustering in Spatial Databases: The Algorithm GDBSCAN and Its Applications,Jörg Sander (Ludwig Maximilian University of Munich);Martin Ester (Ludwig Maximilian University of Munich);Hans-Peter Kriegel (Ludwig Maximilian University of Munich);Xiaowei Xu (Ludwig Maximilian University of Munich);,"2118842476,2067196623,1919135125,2645375510","The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper, we generalize this algorithm in two important directions. The generalized algorithm—called GDBSCAN—can cluster point objects as well as spatially extended objects according to both, their spatial and their nonspatial attributes. In addition, four applications using 2D points (astronomy), 3D points (biology), 5D points (earth science) and 2D polygons (geography) are presented, demonstrating the applicability of GDBSCAN to real-world problems.",1998,Data Mining and Knowledge Discovery volume 2 issue 2 pp 169-194,k medians clustering;flame clustering;subclu;canopy clustering algorithm;optics algorithm;k medoids;dbscan;correlation clustering;data stream clustering;cure data clustering algorithm;single linkage clustering;fuzzy clustering;spatial database;cluster analysis;efficiency;genetic algorithm;information technology;theoretical computer science;data mining;machine learning;computer science;mathematics;
An Extension to SQL for Mining Association Rules,Rosa Meo (Polytechnic University of Turin);Giuseppe Psaila (Polytechnic University of Turin);Stefano Ceri (Instituto Politécnico Nacional);,"2117349166,20413438,519054157","Data mining evolved as a collection of applicative problems and efficient solution algorithms relative to rather peculiar problems, all focused on the discovery of relevant information hidden in databases of huge dimensions. In particular, one of the most investigated topics is the discovery of association rules. This work proposes a unifying model that enables a uniform description of the problem of discovering association rules. The model provides a SQL-like operator, named MINE RULE, which is capable of expressing all the problems presented so far in the literature concerning the mining of association rules. We demonstrate the expressive power of the new operator by means of several examples, some of which are classical, while some others are fully original and correspond to novel and unusual applications. We also present the operational semantics of the operator by means of an extended relational algebra.",1998,Data Mining and Knowledge Discovery volume 2 issue 2 pp 195-224,k optimal pattern discovery;association rule learning;data science;data mining;database;computer science;
Frequent query discovery: a unifying ILP approach to association rule mining,Luc Dehaspe (Katholieke Universiteit Leuven);H Toivonen (University of Helsinki);,"131954981,2250270171",-,1998,Data Mining and Knowledge Discovery,k optimal pattern discovery;association rule learning;first order logic;data mining;pattern recognition;machine learning;computer science;
Real-world Data is Dirty: Data Cleansing and The Merge/Purge Problem,Mauricio A. Hernández (Columbia University);Salvatore J. Stolfo (Columbia University);,"2422367616,2021877992","The problem of merging multiple databases of information about common entities is frequently encountered in KDD and decision support applications in large commercial and government organizations. The problem we study is often called the Merge/Purge problem and is difficult to solve both in scale and accuracy. Large repositories of data typically have numerous duplicate information entries about the same entities that are difficult to cull together without an intelligent ’’equational theory‘‘ that identifies equivalent items by a complex, domain-dependent matching process. We have developed a system for accomplishing this Data Cleansing task and demonstrate its use for cleansing lists of names of potential customers in a direct marketing-type application. Our results for statistically generated data are shown to be accurate and effective when processing the data multiple times using different keys for sorting on each successive pass. Combing results of individual passes using transitive closure over the independent results, produces far more accurate results at lower cost. The system provides a rule programming module that is easy to program and quite good at finding duplicates especially in an environment with massive amounts of data. This paper details improvements in our system, and reports on the successful implementation for a real-world database that conclusively validates our results previously achieved for statistically generated data.",1998,Data Mining and Knowledge Discovery volume 2 issue 1 pp 9-37,data cleansing;decision support system;world wide web;data mining;database;computer science;
Beyond Market Baskets: Generalizing Association Rules to Dependence Rules,Craig Silverstein (Stanford University);Sergey Brin (Stanford University);Rajeev Motwani (Stanford University);,"2041650587,2052648321,2034912444","One of the more well-studied problems in data mining is the search for association rules in market basket data. Association rules are intended to identify patterns of the type: “A customer purchasing item A often also purchases item B.” Motivated partly by the goal of generalizing beyond market basket data and partly by the goal of ironing out some problems in the definition of association rules, we develop the notion of dependence rules that identify statistical dependence in both the presence and absence of items in itemsets. We propose measuring significance of dependence via the chi-squared test for independence from classical statistics. This leads to a measure that is upward-closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between dependent and independent itemsets in the lattice. We develop pruning strategies based on the closure property and thereby devise an efficient algorithm for discovering dependence rules. We demonstrate our algorithm‘s effectiveness by testing it on census data, text data (wherein we seek term dependence), and synthetic data.",1998,Data Mining and Knowledge Discovery volume 2 issue 1 pp 39-68,apriori algorithm;association rule learning;text mining;data mining;pattern recognition;machine learning;computer science;mathematics;
Brief Application Description. Neural Networks Based Forecasting Techniques for Inventory Control Applications,Kanti Bansal (Brandeis University);Sanjeev Vadhavkar (Massachusetts Institute of Technology);Amar Gupta (Massachusetts Institute of Technology);,"2287007648,2060291006,2116316273","An increasing number of organizations are involved in the development of information systems for effective linkages with their suppliers, customers, and other channel partners involved in transportation, distribution, warehousing and maintenance activities. We use neural network based data mining and knowledge discovery techniques to solve the problems of inventory in a large medical distribution company. The paper describes the use of traditional statistical techniques to evaluate the best neural network type. Based on the neural network model described in this paper, a prototype was conceived with data from a large decentralized organization. The prototype was successful in reducing the total level of inventory by 50% in the organization, while maintaining the same level of probability that a particular customer‘s demand will be satisfied.",1998,Data Mining and Knowledge Discovery volume 2 issue 1 pp 97-102,inventory control;information system;satisfiability;inventory theory;artificial neural network;data science;data mining;machine learning;computer science;
Discovering Robust Knowledge from Databases that Change,Chun-Nan Hsu (Arizona State University);Craig A. Knoblock (Information Sciences Institute);,"2171329927,1991211814","Many applications of knowledge discovery and data mining such as rule discovery for semantic query optimization, database integration and decision support, require the knowledge to be consistent with the data. However, databases usually change over time and make machine-discovered knowledge inconsistent. Useful knowledge should be robust against database changes so that it is unlikely to become inconsistent after database updates. This paper defines this notion of robustness in the context of relational databases and describes how robustness of first-order Horn-clause rules can be estimated. Experimental results show that our estimation approach can accurately identify robust rules. We also present a rule antecedent pruning algorithm that improves the robustness and applicability of machine discovered rules to demonstrate the usefulness of robustness estimation.",1998,Data Mining and Knowledge Discovery volume 2 issue 1 pp 69-95,k optimal pattern discovery;view;database theory;data integration;database design;robust statistics;relational database;robustness;first order logic;knowledge extraction;decision support system;information retrieval;data mining;database;computer science;
Density-Based Clustering in Spatial Databases: A New Algorithm and its Applications,Joerg Sander (University of Alberta);Martin Ester (Simon Fraser University);H.-P. Kriegel (Ludwig Maximilian University of Munich);,"2131158813,2067196623,1919135125",-,1998,Data Mining and Knowledge Discovery,spatiotemporal database;spatial query;spatial database;cluster analysis;computer science;
Real - world data is dirty: Data cleansing and the merge/purge problem for large databases,Mauricio A. Hernandez (IBM);Salvatore Stolfo (Columbia University);,"2422367616,2021877992",-,1998,Data Mining and Knowledge Discovery,data cleansing;internet privacy;data mining;database;computer science;
Extensions to the k-means algorithm for clustering large data sets with categorical values,Zih-Shun Haung;,2676496460,-,1998,Data Mining and Knowledge Discovery,fsa red algorithm;canopy clustering algorithm;data stream clustering;cure data clustering algorithm;k means clustering;discrete mathematics;data mining;pattern recognition;machine learning;computer science;
Density - based clustering in spatial AN EFFICIENT k - MEANS CLUSTERING ALGORITHM 1175 databases: th,Joerg Sander (University of Alberta);Martin Ester (Simon Fraser University);H.-P. Kriegel (Ludwig Maximilian University of Munich);Xuyan Xu;,"2131158813,2067196623,1919135125,2555801200",-,1998,Data Mining and Knowledge Discovery,flame clustering;k medians clustering;subclu;canopy clustering algorithm;dbscan;correlation clustering;cure data clustering algorithm;single linkage clustering;affinity propagation;k means clustering;clustering high dimensional data;hierarchical clustering;cluster analysis;consensus clustering;biclustering;machine learning;computer science;
Parallel Algorithms for Discovery of Association Rules,Mohammed Javeed Zaki (University of Rochester);Srinivasan Parthasarathy (University of Rochester);Mitsunori Ogihara (University of Rochester);Wei Li (Oracle Corporation);,"2165917828,2106796124,2123444417,2607728121","Discovery of association rules is an important data mining task. Several parallel and sequential algorithms have been proposed in the literature to solve this problem. Almost all of these algorithms make repeated passes over the database to determine the set of frequent itemsets (a subset of database items), thus incurring high I/O overhead. In the parallel case, most algorithms perform a sum-reduction at the end of each pass to construct the global counts, also incurring high synchronization cost. In this paper we describe new parallel association mining algorithms. The algorithms use novel itemset clustering techniques to approximate the set of potentially maximal frequent itemsets. Once this set has been identified, the algorithms make use of efficient traversal techniques to generate the frequent itemsets contained in each cluster. We propose two clustering schemes based on equivalence classes and maximal hypergraph cliques, and study two lattice traversal techniques based on bottom-up and hybrid search. We use a vertical database layout to cluster related transactions together. The database is also selectively replicated so that the portion of the database needed for the computation of associations is local to each processor. After the initial set-up phase, the algorithms do not need any further communication or synchronization. The algorithms minimize I/O overheads by scanning the local database portion only twice. Once in the set-up phase, and once when processing the itemset clusters. Unlike previous parallel approaches, the algorithms use simple intersection operations to compute frequent itemsets and do not have to maintain or search complex hash structures. Our experimental testbed is a 32-processor DEC Alpha cluster inter-connected by the Memory Channel network. We present results on the performance of our algorithms on various databases, and compare it against a well known parallel algorithm. The best new algorithm outperforms it by an order of magnitude.",1997,Data Mining and Knowledge Discovery volume 1 issue 4 pp 343-373,analysis of parallel algorithms;association rule learning;theoretical computer science;data mining;database;computer science;
High Performance OLAP and Data Mining on Parallel Computers,Sanjay Goil (Northwestern University);Alok N. Choudhary (Northwestern University);,"227227737,2147783234","On-Line Analytical Processing (OLAP) techniques are increasingly being used in decision support systems to provide analysis of data. Queries posed on such systems are quite complex and require different views of data. Analytical models need to capture the multidimensionality of the underlying data, a task for which multidimensional databases are well suited. Multidimensional OLAP systems store data in multidimensional arrays on which analytical operations are performed. Knowledge discovery and data mining requires complex operations on the underlying data which can be very expensive in terms of computation time. High performance parallel systems can reduce this analysis time. Precomputed aggregate calculations in a Data Cube can provide efficient query processing for OLAP applications. In this article, we present algorithms for construction of data cubes on distributed-memory parallel computers. Data is loaded from a relational database into a multidimensional array. We present two methods, sort-based and hash-based for loading the base cube and compare their performances. Data cubes are used to perform consolidation queries used in roll-up operations using dimension hierarchies. Finally, we show how data cubes are used for data mining using Attribute Focusing techniques. We present results for these on the IBM-SP2 parallel machine. Results show that our algorithms and techniques for OLAP and data mining on parallel systems are scalable to a large number of processors, providing a high performance platform for such applications.",1997,Data Mining and Knowledge Discovery volume 1 issue 4 pp 391-417,online analytical processing;data cube;distributed memory;relational database;decision support system;theoretical computer science;data mining;database;machine learning;computer science;
Halo World: Tools for Parallel Cluster Finding inAstrophysical N-body Simulations,David W. Pfitzner (Australian National University);John K. Salmon (California Institute of Technology);Thomas L. Sterling (California Institute of Technology);,"1983289887,1969861907,2172183228","Cosmological N-body simulations on parallel computers produce large datasets—gigabytes at each instant of simulated cosmological time, and hundreds of gigabytes over the course of a simulation. These large datasets require further analysis before they can be compared to astronomical observations. The “Halo World” tools include two methods for performing halo finding: identifying all of the gravitationally stable clusters in a point-sampled density field. One of these methods is a parallel implementation of the friends of friends (FOF) algorithm, widely used in the field of N-body cosmology. The new IsoDen method based on isodensity surfaces has been developed to overcome some of the shortcomings of FOF. Parallel processing is the only viable way of obtaining the necessary performance and storage capacity to carry out these analysis tasks. Ultimately, we must also plan to use disk storage as the only economically viable alternative for storing and manipulating such large data sets. Both IsoDen and friends of friends have been implemented on a variety of computer systems, with parallelism up to 512 processors, and successfully used to extract halos from simulations with up to 16.8 million particles.",1997,Data Mining and Knowledge Discovery volume 1 issue 4 pp 419-438,n body simulation;density estimation;cluster analysis;parallel processing;theoretical computer science;parallel computing;simulation;computer science;
A Distributed Algorithm for Content Based Indexing of Images by Projections on Ritz Primary Images,Haim Schweitzer (University of Texas at Austin);,2487801397,"Large collections of images can be indexed by their projections on a few “primary” images. The optimal primary images are the eigenvectors of a large covariance matrix. We address the problem of computing primary images when access to the images is expensive. This is the case when the images cannot be kept locally, but must be accessed through slow communication such as the Internet, or stored in a compressed form. A distributed algorithm that computes optimal approximations to the eigenvectors (known as Ritz vectors) in one pass through the image set is proposed. When iterated, the algorithm can recover the exact eigenvectors. The widely used SVD technique for computing the primary images of a small image set is a special case of the proposed algorithm. In applications to image libraries and learning, it is necessary to compute different primary images for several sub-categories of the image set. The proposed algorithm can compute these additional primary images “offline”, without the image data. Similar computation by other algorithms is impractical even when access to the images is inexpensive.",1997,Data Mining and Knowledge Discovery volume 1 issue 4 pp 375-390,shift and add;covariance matrix;eigenvalues and eigenvectors;distributed algorithm;image processing;theoretical computer science;information retrieval;computer vision;data mining;statistics;computer science;
Discovery of Frequent Episodes in Event Sequences,Heikki Mannila (University of Helsinki);Hannu Toivonen (University of Helsinki);A. Inkeri Verkamo (University of Helsinki);,"310734946,2250270171,411784570","Sequences of events describing the behavior and actions of users or systems can be collected in several domains. An episode is a collection of events that occur relatively close to each other in a given partial order. We consider the problem of discovering frequently occurring episodes in a sequence. Once such episodes are known, one can produce rules for describing or predicting the behavior of the sequence. We give efficient algorithms for the discovery of all frequent episodes from a given class of episodes, and present detailed experimental results. The methods are in use in telecommunication alarm management.",1997,Data Mining and Knowledge Discovery volume 1 issue 3 pp 259-289,partially ordered set;sequence analysis;bioinformatics;data mining;real time computing;
Adaptive Fraud Detection,Tom Fawcett (Hewlett-Packard);Foster J. Provost (New York University);,"2159035819,2158932634","One method for detecting fraud is to check for suspicious changes in user behavior. This paper describes the automatic design of user profiling methods for the purpose of fraud detection, using a series of data mining techniques. Specifically, we use a rule-learning program to uncover indicators of fraudulent behavior from a large database of customer transactions. Then the indicators are used to create a set of monitors, which profile legitimate customer behavior and indicate anomalies. Finally, the outputs of the monitors are used as features in a system that learns to combine evidence to generate high-confidence alarms. The system has been applied to the problem of detecting cellular cloning fraud based on a database of call records. Experiments indicate that this automatic approach performs better than hand-crafted methods for detecting fraud. Furthermore, this approach can adapt to the changing conditions typical of fraud detection environments.",1997,Data Mining and Knowledge Discovery volume 1 issue 3 pp 291-316,profiling;intrusion detection system;consumer behaviour;anomaly detection;information technology;world wide web;computer security;data mining;computer science;
Levelwise Search and Borders of Theories in KnowledgeDiscovery,Heikki Mannila (University of Helsinki);Hannu Toivonen (University of Helsinki);,"310734946,2250270171","One of the basic problems in knowledge discovery in databases (KDD) is the following: given a data set r, a class L of sentences for defining subgroups of r, and a selection predicate, find all sentences of L deemed interesting by the selection predicate. We analyze the simple levelwise algorithm for finding all such descriptions. We give bounds for the number of database accesses that the algorithm makes. For this, we introduce the concept of the border of a theory, a notion that turns out to be surprisingly powerful in analyzing the algorithm. We also consider the verification problem of a KDD process: given r and a set of sentences S ⊆ L determine whether S is exactly the set of interesting statements about r. We show strong connections between the verification problem and the hypergraph transversal problem. The verification problem arises in a natural way when using sampling to speed up the pattern discovery step in KDD.",1997,Data Mining and Knowledge Discovery volume 1 issue 3 pp 241-258,association rule learning;knowledge extraction;data mining;machine learning;algorithm;computer science;mathematics;
On Comparing Classifiers: Pitfalls toAvoid and a Recommended Approach,Steven L. Salzberg (Johns Hopkins University);,1904680277,"An important component of many data mining projects is finding a good classification algorithm, a process that requires very careful thought about experimental design. If not done very carefully, comparative studies of classification and other types of algorithms can easily result in statistically invalid conclusions. This is especially true when one is using data mining techniques to analyze very large databases, which inevitably contain some statistically unlikely data. This paper describes several phenomena that can, if ignored, invalidate an experimental comparison. These phenomena and the conclusions that follow apply not only to classification, but to computational experiments in almost any aspect of data mining. The paper also discusses why comparative analysis is more important in evaluating some types of algorithms than for others, and provides some suggestions about how to avoid the pitfalls suffered by many experimental studies.",1997,Data Mining and Knowledge Discovery volume 1 issue 3 pp 317-328,comparative research;data science;data mining;machine learning;computer science;
BIRCH: A New Data Clustering Algorithm and Its Applications,Tian Zhang (University of Wisconsin-Madison);Raghu Ramakrishnan (University of Wisconsin-Madison);Miron Livny (University of Wisconsin-Madison);,"2170645464,2164040783,228437624","Data clustering is an important technique for exploratory data analysis, and has been studied for several years. It has been shown to be useful in many practical domains such as data classification and image processing. Recently, there has been a growing emphasis on exploratory analysis of very large datasets to discover useful patterns and/or correlations among attributes. This is called data mining, and data clustering is regarded as a particular branch. However existing data clustering methods do not adequately address the problem of processing large datasets with a limited amount of resources (e.g., memory and cpu cycles). So as the dataset size increases, they do not scale up well in terms of memory requirement, running time, and result quality. In this paper, an efficient and scalable data clustering method is proposed, based on a new in-memory data structure called CF-tree, which serves as an in-memory summary of the data distribution. We have implemented it in a system called BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and studied its performance extensively in terms of memory requirements, running time, clustering quality, stability and scalability; we also compare it with other available methods. Finally, BIRCH is applied to solve two real-life problems: one is building an iterative and interactive pixel classification tool, and the other is generating the initial codebook for image compression.",1997,Data Mining and Knowledge Discovery volume 1 issue 2 pp 141-182,flame clustering;brown clustering;canopy clustering algorithm;correlation clustering;constrained clustering;data stream clustering;cure data clustering algorithm;affinity propagation;fuzzy clustering;very large database;clustering high dimensional data;exploratory data analysis;image compression;cluster analysis;consensus clustering;biclustering;conceptual clustering;data structure;image processing;data science;data mining;database;computer science;
Mathematical Programming in Data Mining,Olvi L. Mangasarian (University of Wisconsin-Madison);,1979429815,"Mathematical programming approaches to three fundamental problems will be described: feature selection, clustering and robust representation. The feature selection problem considered is that of discriminating between two sets while recognizing irrelevant and redundant features and suppressing them. This creates a lean model that often generalizes better to new unseen data. Computational results on real data confirm improved generalization of leaner models. Clustering is exemplified by the unsupervised learning of patterns and clusters that may exist in a given database and is a useful tool for knowledge discovery in databases (KDD). A mathematical programming formulation of this problem is proposed that is theoretically justifiable and computationally implementable in a finite number of steps. A resulting k-Median Algorithm is utilized to discover very useful survival curves for breast cancer patients from a medical database. Robust representation is concerned with minimizing trained model degradation when applied to new problems. A novel approach is proposed that purposely tolerates a small error in the training process in order to avoid overfitting data that may contain errors. Examples of applications of these concepts are given.",1997,Data Mining and Knowledge Discovery volume 1 issue 2 pp 183-201,breast cancer;cluster analysis;feature selection;unsupervised learning;data mining;pattern recognition;machine learning;statistics;computer science;
Brief Application Description; Visual Data Mining: Recognizing Telephone Calling Fraud,Kenneth C. Cox (Bell Labs);Stephen G. Eick (Bell Labs);Graham J. Wills (Bell Labs);Ronald J. Brachman (AT&T Labs);,"2303527180,2230662789,2167012557,2695655480","Human pattern recognition skills are remarkable and in many situations far exceed the ability of automated mining algorithms. By building domain-specific interfaces that present information visually, we can combine human detection with machines‘ far greater computational capacity. We illustrate our ideas by describing a suite of visual interfaces we built for telephone fraud detection.",1997,Data Mining and Knowledge Discovery volume 1 issue 2 pp 225-231,visualization;interaction;information visualization;visual analytics;data science;world wide web;data mining;machine learning;computer science;
A Simple Constraint-Based Algorithm for Efficiently Mining Observational Databases for Causal Relationships,Gregory F. Cooper (University of Pittsburgh);,2137326150,"This paper presents a simple, efficient computer-based method for discovering causal relationships from databases that contain observational data. Observational data is passively observed, as contrasted with experimental data. Most of the databases available for data mining are observational. There is great potential for mining such databases to discover causal relationships. We illustrate how observational data can constrain the causal relationships among measured variables, sometimes to the point that we can conclude that one variable is causing another variable. The presentation here is based on a constraint-based approach to causal discovery. A primary purpose of this paper is to present the constraint-based causal discovery method in the simplest possible fashion in order to (1) readily convey the basic ideas that underlie more complex constraint-based causal discovery techniques, and (2) permit interested readers to rapidly program and apply the method to their own databases, as a start toward using more elaborate causal discovery algorithms.",1997,Data Mining and Knowledge Discovery volume 1 issue 2 pp 203-224,observational study;data science;data mining;machine learning;computer science;mathematics;
"On Bias, Variance, 0/1—Loss, and the Curse-of-Dimensionality",Jerome H. Friedman (Stanford University);,2157091523,"The classification problem is considered in which an output variable y assumes discrete values with respective probabilities that depend upon the simultaneous values of a set of input variables x = {x_1,....,x_n}. At issue is how error in the estimates of these probabilities affects classification error when the estimates are used in a classification rule. These effects are seen to be somewhat counter intuitive in both their strength and nature. In particular the bias and variance components of the estimation error combine to influence classification in a very different way than with squared error on the probabilities themselves. Certain types of (very high) bias can be canceled by low variance to produce accurate classification. This can dramatically mitigate the effect of the bias associated with some simple estimators like “naive” Bayes, and the bias induced by the curse-of-dimensionality on nearest-neighbor procedures. This helps explain why such simple methods are often competitive with and sometimes superior to more sophisticated ones for classification, and why “bagging/aggregating” classifiers can often improve accuracy. These results also suggest simple modifications to these procedures that can (sometimes dramatically) further improve their classification performance.",1997,Data Mining and Knowledge Discovery volume 1 issue 1 pp 55-77,bayes error rate;bootstrap aggregating;naive bayes classifier;curse of dimensionality;variance;bias;k nearest neighbors algorithm;biological classification;pattern recognition;machine learning;statistics;computer science;mathematics;
Bayesian Networks for Data Mining,David Heckerman (Microsoft);,2021640924,"A Bayesian network is a graphical model that encodes probabilistic relationships among variables of interest. When used in conjunction with statistical techniques, the graphical model has several advantages for data modeling. One, because the model encodes dependencies among all variables, it readily handles situations where some data entries are missing. Two, a Bayesian network can be used to learn causal relationships, and hence can be used to gain understanding about a problem domain and to predict the consequences of intervention. Three, because the model has both a causal and probabilistic semantics, it is an ideal representation for combining prior knowledge (which often comes in causal form) and data. Four, Bayesian statistical methods in conjunction with Bayesian networks offer an efficient and principled approach for avoiding the overfitting of data. In this paper, we discuss methods for constructing Bayesian networks from prior knowledge and summarize Bayesian statistical methods for using data to improve these models. With regard to the latter task, we describe methods for learning both the parameters and structure of a Bayesian network, including techniques for learning with incomplete data. In addition, we relate Bayesian-network methods for learning to techniques for supervised and unsupervised learning. We illustrate the graphical-modeling approach using a real-world case study.",1997,Data Mining and Knowledge Discovery volume 1 issue 1 pp 79-119,variable order bayesian network;bayesian programming;dynamic bayesian network;bayesian hierarchical modeling;bayesian statistics;bayesian network;graphical model;unsupervised learning;data mining;pattern recognition;machine learning;statistics;computer science;
Statistical Themes and Lessons for Data Mining,"Clark Glymour (Carnegie Mellon University);David Madigan (University of Washington);Daryl Pregibon (AT&T);Padhraic Smyth (University of California, Irvine);","2035346540,2232911153,2467880905,2137074633","Data mining is on the interface of Computer Science and Statistics, utilizing advances in both disciplines to make progress in extracting information from large databases. It is an emerging field that has attracted much attention in a very short period of time. This article highlights some statistical themes and lessons that are directly relevant to data mining and attempts to identify opportunities where close cooperation between the statistical and computational communities might reasonably provide synergy for further progress in data analysis.",1997,Data Mining and Knowledge Discovery volume 1 issue 1 pp 11-28,variance;bias;uncertainty;systems modeling;data analysis;data science;data mining;statistics;computer science;
Advanced Scout: Data Mining and Knowledge Discovery in NBA Data,Inderpal S. Bhandari (IBM);Edward Colet (IBM);Jennifer Parker (IBM);Zachary Pines (IBM);Rajiv Pratap (IBM);Krishnakumar Ramanujam (IBM);,"6664034,2645686329,2583849771,2287300613,2157311336,2122554605","Advanced Scout is a PC-based data mining application used by National Basketball Association (NBA) coaching staffs to discover interesting patterns in basketball game data. We describe Advanced Scout software from the perspective of data mining and knowledge discovery. This paper highlights the pre-processing of raw data that the program performs, describes the data mining aspects of the software and how the interpretation of patterns supports the process of knowledge discovery. The underlying technique of attribute focusing as the basis of the algorithm is also described. The process of pattern interpretation is facilitated by allowing the user to relate patterns to video tape.",1997,Data Mining and Knowledge Discovery volume 1 issue 1 pp 121-125,basketball;knowledge extraction;data science;data mining;simulation;computer science;
"On Bias, Variance, 0/1Loss, and the Curse-of-Dimensionality",Jerome H. Friedman (Stanford University);Usama Fayyad (University of Hong Kong);,"2157091523,2306498003",-,1997,Data Mining and Knowledge Discovery,bayes error rate;naive bayes classifier;curse of dimensionality;k nearest neighbors algorithm;pattern recognition;machine learning;statistics;computer science;
A simple algorithm for efficiently mining observational databases for causal relationships,Gregory Cooper (University of Pittsburgh);,2137326150,-,1997,Data Mining and Knowledge Discovery,algorithm;
Data Mining and Knowledge Discovery,Jim Gray (Microsoft);Surajit Chaudhuri (Microsoft);Adam Bosworth (Microsoft);Andrew Layman (Microsoft);Don Reichart;Murali Venkatrao;Frank Pellow;Hamid Pirahesh (IBM);,"2131537204,2163909284,2156526725,2601705850,2129232831,357426854,51548440,2213038480",-,1997,Data Mining and Knowledge Discovery,k optimal pattern discovery;web mining;knowledge extraction;data mining;computer science;
New parallel algorithms for fast discovery of associ-ation rules,Mohammed Javeed Zaki (Rensselaer Polytechnic Institute);Srinivasan Parthasarathy (Ohio State University);Mitsunori Ogihara (University of Rochester);Wei Li (University of Rochester);,"2165917828,2106796124,2123444417,2607728121",-,1997,Data Mining and Knowledge Discovery,analysis of parallel algorithms;cost efficiency;parallel algorithm;computer science;
Discovering Interesting Patterns for Investment Decision Making with GLOWER-A Genetic Learner Overla,Vasant Dhar (University of Sydney);Dashin Chou (New York University Stern School of Business);Foster Provost (New York University);,"2401262112,2109310296,2158932634",-,1996,Data Mining and Knowledge Discovery,management science;artificial intelligence;computer science;
